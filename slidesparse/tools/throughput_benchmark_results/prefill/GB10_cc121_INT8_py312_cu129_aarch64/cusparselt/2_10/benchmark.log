
========== M=16 ==========
Time: 2026-01-25 18:41:46
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M16.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:41:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:41:50 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=292014) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=292014) 
(EngineCore_DP0 pid=292014) 
(EngineCore_DP0 pid=292014) ================================================================
(EngineCore_DP0 pid=292014) Internal Triton PTX codegen error
(EngineCore_DP0 pid=292014) `ptxas` stderr:
(EngineCore_DP0 pid=292014) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=292014) 
(EngineCore_DP0 pid=292014) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpu4q1svox.ptx -o /tmp/tmpu4q1svox.ptx.o
(EngineCore_DP0 pid=292014) 
(EngineCore_DP0 pid=292014) 
(EngineCore_DP0 pid=292014) //
(EngineCore_DP0 pid=292014) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=292014) //
(EngineCore_DP0 pid=292014) 
(EngineCore_DP0 pid=292014) .version 8.7
(EngineCore_DP0 pid=292014) .target sm_121a
(EngineCore_DP0 pid=292014) .address_size 64
(EngineCore_DP0 pid=292014) 
(EngineCore_DP0 pid=292014) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=292014) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=292014)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=292014) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=292014) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=292014) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=292014) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=292014) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=292014) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=292014) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=292014) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=292014) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=292014) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=292014) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=292014) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=292014) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=292014) )
(EngineCore_DP0 pid=292014) .reqntid 512
(EngineCore_DP0 pid=292014) {
(EngineCore_DP0 pid=292014) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=292014) 	.reg .b16 	%rs<32>;
(EngineCore_DP0 pid=292014) 	.reg .b32 	%r<123>;
(EngineCore_DP0 pid=292014) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=292014) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=292014) $L__func_begin0:
(EngineCore_DP0 pid=292014) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=292014) 
(EngineCore_DP0 pid=292014) // %bb.0:
(EngineCore_DP0 pid=292014) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=292014) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=292014) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=292014) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=292014) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=292014) $L__tmp0:
(EngineCore_DP0 pid=292014) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=292014) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=292014) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=292014) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=292014) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=292014) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=292014) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=292014) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=292014) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=292014) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=292014) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=292014) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=292014) 	mov.b32 	%r121, 0f2B8CBCCC;
(EngineCore_DP0 pid=292014) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=292014) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=292014) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=292014) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=292014) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=292014) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=292014) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=292014) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=292014) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=292014) 	add.s32 	%r44, %r34, %r33;
(EngineCore_DP0 pid=292014) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=292014) 	add.s32 	%r47, %r34, %r35;
(EngineCore_DP0 pid=292014) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=292014) 	mov.b32 	%r119, 0f00000000;
(EngineCore_DP0 pid=292014) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=292014) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=292014) 	mov.b32 	%r120, %r40;
(EngineCore_DP0 pid=292014) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=292014) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=292014) 	add.s32 	%r50, %r4, %r120;
(EngineCore_DP0 pid=292014) 	setp.lt.s32 	%p2, %r50, %r18;
(EngineCore_DP0 pid=292014) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=292014) 	mad.wide.s32 	%rd6, %r50, 2, %rd1;
(EngineCore_DP0 pid=292014) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=292014) 	// begin inline asm
(EngineCore_DP0 pid=292014) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=292014) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=292014) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=292014) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=292014) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=292014) 	// end inline asm
(EngineCore_DP0 pid=292014) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=292014) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=292014) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=292014) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=292014) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=292014) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=292014) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=292014) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=292014) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=292014) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=292014) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=292014) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=292014) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=292014) $L__tmp1:
(EngineCore_DP0 pid=292014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	bar.sync 	0;
(EngineCore_DP0 pid=292014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=292014) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=292014) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=292014) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=292014) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=292014) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=292014) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=292014) 	cvt.f32.bf16 	%r51, %rs23;
(EngineCore_DP0 pid=292014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	shfl.sync.bfly.b32 	%r52, %r51, 16, 31, -1;
(EngineCore_DP0 pid=292014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=292014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	shfl.sync.bfly.b32 	%r54, %r53, 8, 31, -1;
(EngineCore_DP0 pid=292014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=292014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	shfl.sync.bfly.b32 	%r56, %r55, 4, 31, -1;
(EngineCore_DP0 pid=292014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=292014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	shfl.sync.bfly.b32 	%r58, %r57, 2, 31, -1;
(EngineCore_DP0 pid=292014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=292014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	shfl.sync.bfly.b32 	%r60, %r59, 1, 31, -1;
(EngineCore_DP0 pid=292014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	max.f32 	%r45, %r59, %r60;
(EngineCore_DP0 pid=292014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	// begin inline asm
(EngineCore_DP0 pid=292014) 	@%p3 st.shared.b32 [ %r44 + 0 ], %r45;
(EngineCore_DP0 pid=292014) 	// end inline asm
(EngineCore_DP0 pid=292014) 	bar.sync 	0;
(EngineCore_DP0 pid=292014) 	// begin inline asm
(EngineCore_DP0 pid=292014) 	@%p4 ld.shared.b32 %r46, [ %r47 + 0 ];
(EngineCore_DP0 pid=292014) 	// end inline asm
(EngineCore_DP0 pid=292014) 	shfl.sync.bfly.b32 	%r61, %r46, 8, 31, -1;
(EngineCore_DP0 pid=292014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	max.f32 	%r62, %r46, %r61;
(EngineCore_DP0 pid=292014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	shfl.sync.bfly.b32 	%r63, %r62, 4, 31, -1;
(EngineCore_DP0 pid=292014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=292014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	shfl.sync.bfly.b32 	%r65, %r64, 2, 31, -1;
(EngineCore_DP0 pid=292014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=292014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	shfl.sync.bfly.b32 	%r67, %r66, 1, 31, -1;
(EngineCore_DP0 pid=292014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	max.f32 	%r49, %r66, %r67;
(EngineCore_DP0 pid=292014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292014) 	// begin inline asm
(EngineCore_DP0 pid=292014) 	@%p19 st.shared.b32 [ %r47 + 0 ], %r49;
(EngineCore_DP0 pid=292014) 	// end inline asm
(EngineCore_DP0 pid=292014) 	bar.sync 	0;
(EngineCore_DP0 pid=292014) 	ld.shared.b32 	%r68, [global_smem];
(EngineCore_DP0 pid=292014) $L__tmp2:
(EngineCore_DP0 pid=292014) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=292014) 	max.f32 	%r119, %r119, %r68;
(EngineCore_DP0 pid=292014) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=292014) 	add.s32 	%r120, %r120, 4096;
(EngineCore_DP0 pid=292014) 	setp.lt.s32 	%p6, %r120, %r19;
(EngineCore_DP0 pid=292014) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=292014) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=292014) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=292014) 	max.f32 	%r121, %r119, 0f2B8CBCCC;
(EngineCore_DP0 pid=292014) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=292014) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=292014) 	mov.b32 	%r70, 0f42FE0000;
(EngineCore_DP0 pid=292014) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=292014) 	div.full.f32 	%r71, %r121, %r70;
(EngineCore_DP0 pid=292014) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=292014) 	max.f32 	%r69, %r71, 0f37810204;
(EngineCore_DP0 pid=292014) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=292014) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=292014) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=292014) 	// begin inline asm
(EngineCore_DP0 pid=292014) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r69 };
(EngineCore_DP0 pid=292014) 	// end inline asm
(EngineCore_DP0 pid=292014) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=292014) 	shl.b32 	%r15, %r20, 2;
(EngineCore_DP0 pid=292014) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=292014) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=292014) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=292014) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=292014) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=292014) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=292014) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=292014) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=292014) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=292014) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=292014) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=292014) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=292014) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=292014) 	div.full.f32 	%r14, %r70, %r121;
(EngineCore_DP0 pid=292014) 	mov.b32 	%r122, 0;
(EngineCore_DP0 pid=292014) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=292014)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=292014) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=292014) 	add.s32 	%r75, %r3, %r122;
(EngineCore_DP0 pid=292014) 	setp.lt.s32 	%p13, %r75, %r15;
(EngineCore_DP0 pid=292014) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=292014) 	shr.s32 	%r76, %r75, 31;
(EngineCore_DP0 pid=292014) 	shr.u32 	%r77, %r76, 30;
(EngineCore_DP0 pid=292014) 	add.s32 	%r78, %r75, %r77;
(EngineCore_DP0 pid=292014) 	shr.s32 	%r79, %r78, 2;
(EngineCore_DP0 pid=292014) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=292014) 	and.b32 	%r80, %r78, 2147483644;
(EngineCore_DP0 pid=292014) 	sub.s32 	%r81, %r75, %r80;
(EngineCore_DP0 pid=292014) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=292014) 	shl.b32 	%r82, %r81, 1;
(EngineCore_DP0 pid=292014) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=292014) 	mad.lo.s32 	%r83, %r79, 10, %r82;
(EngineCore_DP0 pid=292014) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=292014) 	setp.lt.s32 	%p14, %r83, %r18;
(EngineCore_DP0 pid=292014) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=292014) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=292014) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=292014) 	mad.wide.s32 	%rd8, %r83, 2, %rd1;
(EngineCore_DP0 pid=292014) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=292014) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=292014) 	// begin inline asm
(EngineCore_DP0 pid=292014) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=292014) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=292014) 	// end inline asm
(EngineCore_DP0 pid=292014) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=292014) 	cvt.f32.bf16 	%r84, %rs24;
(EngineCore_DP0 pid=292014) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=292014) 	or.b32 	%r85, %r83, 1;
(EngineCore_DP0 pid=292014) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=292014) 	setp.lt.s32 	%p15, %r85, %r18;
(EngineCore_DP0 pid=292014) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=292014) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=292014) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=292014) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=292014) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=292014) 	// begin inline asm
(EngineCore_DP0 pid=292014) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=292014) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=292014) 	// end inline asm
(EngineCore_DP0 pid=292014) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=292014) 	cvt.f32.bf16 	%r86, %rs26;
(EngineCore_DP0 pid=292014) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=292014) 	add.s32 	%r87, %r83, 2;
(EngineCore_DP0 pid=292014) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=292014) 	setp.lt.s32 	%p16, %r87, %r18;
(EngineCore_DP0 pid=292014) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=292014) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=292014) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=292014) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=292014) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=292014) 	// begin inline asm
(EngineCore_DP0 pid=292014) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=292014) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=292014) 	// end inline asm
(EngineCore_DP0 pid=292014) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=292014) 	cvt.f32.bf16 	%r88, %rs28;
(EngineCore_DP0 pid=292014) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=292014) 	add.s32 	%r89, %r83, 3;
(EngineCore_DP0 pid=292014) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=292014) 	setp.lt.s32 	%p17, %r89, %r18;
(EngineCore_DP0 pid=292014) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=292014) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=292014) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=292014) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=292014) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=292014) 	// begin inline asm
(EngineCore_DP0 pid=292014) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=292014) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=292014) 	// end inline asm
(EngineCore_DP0 pid=292014) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=292014) 	cvt.f32.bf16 	%r90, %rs30;
(EngineCore_DP0 pid=292014) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=292014) 	mul.f32 	%r91, %r14, %r84;
(EngineCore_DP0 pid=292014) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=292014) 	cvt.rni.f32.f32 	%r92, %r91;
(EngineCore_DP0 pid=292014) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=292014) 	max.f32 	%r93, %r92, 0fC3000000;
(EngineCore_DP0 pid=292014) 	min.f32 	%r94, %r93, 0f42FE0000;
(EngineCore_DP0 pid=292014) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=292014) 	cvt.rzi.s32.f32 	%r95, %r94;
(EngineCore_DP0 pid=292014) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=292014) 	and.b32 	%r96, %r95, 255;
(EngineCore_DP0 pid=292014) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=292014) 	mul.f32 	%r97, %r14, %r86;
(EngineCore_DP0 pid=292014) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=292014) 	cvt.rni.f32.f32 	%r98, %r97;
(EngineCore_DP0 pid=292014) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=292014) 	mul.f32 	%r99, %r14, %r88;
(EngineCore_DP0 pid=292014) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=292014) 	cvt.rni.f32.f32 	%r100, %r99;
(EngineCore_DP0 pid=292014) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=292014) 	mul.f32 	%r101, %r14, %r90;
(EngineCore_DP0 pid=292014) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=292014) 	cvt.rni.f32.f32 	%r102, %r101;
(EngineCore_DP0 pid=292014) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=292014) 	max.f32 	%r103, %r102, 0fC3000000;
(EngineCore_DP0 pid=292014) 	min.f32 	%r104, %r103, 0f42FE0000;
(EngineCore_DP0 pid=292014) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=292014) 	cvt.rzi.s32.f32 	%r105, %r104;
(EngineCore_DP0 pid=292014) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=292014) 	max.f32 	%r106, %r100, 0fC3000000;
(EngineCore_DP0 pid=292014) 	max.f32 	%r107, %r98, 0fC3000000;
(EngineCore_DP0 pid=292014) 	min.f32 	%r108, %r107, 0f42FE0000;
(EngineCore_DP0 pid=292014) 	min.f32 	%r109, %r106, 0f42FE0000;
(EngineCore_DP0 pid=292014) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=292014) 	cvt.rzi.s32.f32 	%r110, %r109;
(EngineCore_DP0 pid=292014) 	cvt.rzi.s32.f32 	%r111, %r108;
(EngineCore_DP0 pid=292014) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=292014) 	shl.b32 	%r112, %r111, 8;
(EngineCore_DP0 pid=292014) 	shl.b32 	%r113, %r110, 16;
(EngineCore_DP0 pid=292014) 	and.b32 	%r114, %r113, 16711680;
(EngineCore_DP0 pid=292014) 	and.b32 	%r115, %r112, 65280;
(EngineCore_DP0 pid=292014) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=292014) 	or.b32 	%r116, %r115, %r96;
(EngineCore_DP0 pid=292014) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=292014) 	or.b32 	%r117, %r116, %r114;
(EngineCore_DP0 pid=292014) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=292014) 	shl.b32 	%r118, %r105, 24;
(EngineCore_DP0 pid=292014) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=292014) 	or.b32 	%r73, %r117, %r118;
(EngineCore_DP0 pid=292014) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=292014) 	mad.wide.s32 	%rd12, %r75, 4, %rd2;
(EngineCore_DP0 pid=292014) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=292014) 	// begin inline asm
(EngineCore_DP0 pid=292014) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r73 };
(EngineCore_DP0 pid=292014) 	// end inline asm
(EngineCore_DP0 pid=292014) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=292014) 	add.s32 	%r122, %r122, 512;
(EngineCore_DP0 pid=292014) 	setp.lt.s32 	%p18, %r122, %r15;
(EngineCore_DP0 pid=292014) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=292014) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=292014) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=292014) 	ret;
(EngineCore_DP0 pid=292014) $L__tmp3:
(EngineCore_DP0 pid=292014) $L__func_end0:
(EngineCore_DP0 pid=292014)                                         // -- End function
(EngineCore_DP0 pid=292014) }
(EngineCore_DP0 pid=292014) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=292014) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=292014) 	.section	.debug_abbrev
(EngineCore_DP0 pid=292014) 	{
(EngineCore_DP0 pid=292014) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=292014) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=292014) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=292014) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=292014) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=292014) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=292014) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=292014) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=292014) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=292014) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=292014) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=292014) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=292014) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=292014) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=292014) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=292014) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=292014) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=292014) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=292014) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=292014) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=292014) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=292014) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=292014) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=292014) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=292014) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=292014) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=292014) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=292014) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=292014) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=292014) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=292014) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=292014) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=292014) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=292014) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=292014) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=292014) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=292014) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=292014) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=292014) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=292014) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=292014) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=292014) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=292014) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=292014) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=292014) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=292014) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=292014) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=292014) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=292014) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=292014) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=292014) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=292014) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=292014) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=292014) 	}
(EngineCore_DP0 pid=292014) 	.section	.debug_info
(EngineCore_DP0 pid=292014) 	{
(EngineCore_DP0 pid=292014) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=292014) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=292014) .b8 0
(EngineCore_DP0 pid=292014) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=292014) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=292014) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=292014) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=292014) .b8 114
(EngineCore_DP0 pid=292014) .b8 105
(EngineCore_DP0 pid=292014) .b8 116
(EngineCore_DP0 pid=292014) .b8 111
(EngineCore_DP0 pid=292014) .b8 110
(EngineCore_DP0 pid=292014) .b8 0
(EngineCore_DP0 pid=292014) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=292014) .b8 0
(EngineCore_DP0 pid=292014) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=292014) .b8 117
(EngineCore_DP0 pid=292014) .b8 97
(EngineCore_DP0 pid=292014) .b8 110
(EngineCore_DP0 pid=292014) .b8 116
(EngineCore_DP0 pid=292014) .b8 95
(EngineCore_DP0 pid=292014) .b8 115
(EngineCore_DP0 pid=292014) .b8 108
(EngineCore_DP0 pid=292014) .b8 105
(EngineCore_DP0 pid=292014) .b8 100
(EngineCore_DP0 pid=292014) .b8 101
(EngineCore_DP0 pid=292014) .b8 95
(EngineCore_DP0 pid=292014) .b8 116
(EngineCore_DP0 pid=292014) .b8 117
(EngineCore_DP0 pid=292014) .b8 110
(EngineCore_DP0 pid=292014) .b8 101
(EngineCore_DP0 pid=292014) .b8 100
(EngineCore_DP0 pid=292014) .b8 95
(EngineCore_DP0 pid=292014) .b8 76
(EngineCore_DP0 pid=292014) .b8 108
(EngineCore_DP0 pid=292014) .b8 97
(EngineCore_DP0 pid=292014) .b8 109
(EngineCore_DP0 pid=292014) .b8 97
(EngineCore_DP0 pid=292014) .b8 51
(EngineCore_DP0 pid=292014) .b8 46
(EngineCore_DP0 pid=292014) .b8 50
(EngineCore_DP0 pid=292014) .b8 45
(EngineCore_DP0 pid=292014) .b8 49
(EngineCore_DP0 pid=292014) .b8 66
(EngineCore_DP0 pid=292014) .b8 46
(EngineCore_DP0 pid=292014) .b8 112
(EngineCore_DP0 pid=292014) .b8 121
(EngineCore_DP0 pid=292014) .b8 0
(EngineCore_DP0 pid=292014) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=292014) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=292014) .b8 114
(EngineCore_DP0 pid=292014) .b8 111
(EngineCore_DP0 pid=292014) .b8 111
(EngineCore_DP0 pid=292014) .b8 116
(EngineCore_DP0 pid=292014) .b8 47
(EngineCore_DP0 pid=292014) .b8 118
(EngineCore_DP0 pid=292014) .b8 108
(EngineCore_DP0 pid=292014) .b8 108
(EngineCore_DP0 pid=292014) .b8 109
(EngineCore_DP0 pid=292014) .b8 98
(EngineCore_DP0 pid=292014) .b8 101
(EngineCore_DP0 pid=292014) .b8 110
(EngineCore_DP0 pid=292014) .b8 99
(EngineCore_DP0 pid=292014) .b8 104
(EngineCore_DP0 pid=292014) .b8 47
(EngineCore_DP0 pid=292014) .b8 115
(EngineCore_DP0 pid=292014) .b8 108
(EngineCore_DP0 pid=292014) .b8 105
(EngineCore_DP0 pid=292014) .b8 100
(EngineCore_DP0 pid=292014) .b8 101
(EngineCore_DP0 pid=292014) .b8 115
(EngineCore_DP0 pid=292014) .b8 112
(EngineCore_DP0 pid=292014) .b8 97
(EngineCore_DP0 pid=292014) .b8 114
(EngineCore_DP0 pid=292014) .b8 115
(EngineCore_DP0 pid=292014) .b8 101
(EngineCore_DP0 pid=292014) .b8 47
(EngineCore_DP0 pid=292014) .b8 99
(EngineCore_DP0 pid=292014) .b8 115
(EngineCore_DP0 pid=292014) .b8 114
(EngineCore_DP0 pid=292014) .b8 99
(EngineCore_DP0 pid=292014) .b8 47
(EngineCore_DP0 pid=292014) .b8 102
(EngineCore_DP0 pid=292014) .b8 117
(EngineCore_DP0 pid=292014) .b8 115
(EngineCore_DP0 pid=292014) .b8 101
(EngineCore_DP0 pid=292014) .b8 100
(EngineCore_DP0 pid=292014) .b8 95
(EngineCore_DP0 pid=292014) .b8 113
(EngineCore_DP0 pid=292014) .b8 117
(EngineCore_DP0 pid=292014) .b8 97
(EngineCore_DP0 pid=292014) .b8 110
(EngineCore_DP0 pid=292014) .b8 116
(EngineCore_DP0 pid=292014) .b8 95
(EngineCore_DP0 pid=292014) .b8 115
(EngineCore_DP0 pid=292014) .b8 108
(EngineCore_DP0 pid=292014) .b8 105
(EngineCore_DP0 pid=292014) .b8 100
(EngineCore_DP0 pid=292014) .b8 101
(EngineCore_DP0 pid=292014) .b8 95
(EngineCore_DP0 pid=292014) .b8 116
(EngineCore_DP0 pid=292014) .b8 114
(EngineCore_DP0 pid=292014) .b8 105
(EngineCore_DP0 pid=292014) .b8 116
(EngineCore_DP0 pid=292014) .b8 111
(EngineCore_DP0 pid=292014) .b8 110
(EngineCore_DP0 pid=292014) .b8 47
(EngineCore_DP0 pid=292014) .b8 98
(EngineCore_DP0 pid=292014) .b8 117
(EngineCore_DP0 pid=292014) .b8 105
(EngineCore_DP0 pid=292014) .b8 108
(EngineCore_DP0 pid=292014) .b8 100
(EngineCore_DP0 pid=292014) .b8 47
(EngineCore_DP0 pid=292014) .b8 71
(EngineCore_DP0 pid=292014) .b8 66
(EngineCore_DP0 pid=292014) .b8 49
(EngineCore_DP0 pid=292014) .b8 48
(EngineCore_DP0 pid=292014) .b8 95
(EngineCore_DP0 pid=292014) .b8 99
(EngineCore_DP0 pid=292014) .b8 99
(EngineCore_DP0 pid=292014) .b8 49
(EngineCore_DP0 pid=292014) .b8 50
(EngineCore_DP0 pid=292014) .b8 49
(EngineCore_DP0 pid=292014) .b8 95
(EngineCore_DP0 pid=292014) .b8 112
(EngineCore_DP0 pid=292014) .b8 121
(EngineCore_DP0 pid=292014) .b8 51
(EngineCore_DP0 pid=292014) .b8 49
(EngineCore_DP0 pid=292014) .b8 50
(EngineCore_DP0 pid=292014) .b8 95
(EngineCore_DP0 pid=292014) .b8 99
(EngineCore_DP0 pid=292014) .b8 117
(EngineCore_DP0 pid=292014) .b8 49
(EngineCore_DP0 pid=292014) .b8 50
(EngineCore_DP0 pid=292014) .b8 57
(EngineCore_DP0 pid=292014) .b8 95
(EngineCore_DP0 pid=292014) .b8 97
(EngineCore_DP0 pid=292014) .b8 97
(EngineCore_DP0 pid=292014) .b8 114
(EngineCore_DP0 pid=292014) .b8 99
(EngineCore_DP0 pid=292014) .b8 104
(EngineCore_DP0 pid=292014) .b8 54
(EngineCore_DP0 pid=292014) .b8 52
(EngineCore_DP0 pid=292014) .b8 0
(EngineCore_DP0 pid=292014) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=292014) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=292014) .b8 113
(EngineCore_DP0 pid=292014) .b8 117
(EngineCore_DP0 pid=292014) .b8 97
(EngineCore_DP0 pid=292014) .b8 110
(EngineCore_DP0 pid=292014) .b8 116
(EngineCore_DP0 pid=292014) .b8 95
(EngineCore_DP0 pid=292014) .b8 115
(EngineCore_DP0 pid=292014) .b8 108
(EngineCore_DP0 pid=292014) .b8 105
(EngineCore_DP0 pid=292014) .b8 100
(EngineCore_DP0 pid=292014) .b8 101
(EngineCore_DP0 pid=292014) .b8 95
(EngineCore_DP0 pid=292014) .b8 105
(EngineCore_DP0 pid=292014) .b8 110
(EngineCore_DP0 pid=292014) .b8 116
(EngineCore_DP0 pid=292014) .b8 56
(EngineCore_DP0 pid=292014) .b8 95
(EngineCore_DP0 pid=292014) .b8 107
(EngineCore_DP0 pid=292014) .b8 101
(EngineCore_DP0 pid=292014) .b8 114
(EngineCore_DP0 pid=292014) .b8 110
(EngineCore_DP0 pid=292014) .b8 101
(EngineCore_DP0 pid=292014) .b8 108
(EngineCore_DP0 pid=292014) .b8 0
(EngineCore_DP0 pid=292014) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=292014) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=292014) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=292014) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=292014) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=292014) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=292014) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=292014) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=292014) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=292014) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=292014) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=292014) .b8 1
(EngineCore_DP0 pid=292014) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=292014) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=292014) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=292014) 	}
(EngineCore_DP0 pid=292014) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=292014) 
(EngineCore_DP0 pid=292014) ================================================================
(EngineCore_DP0 pid=292014) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=292014) 
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpu4q1svox.ptx', '-o', '/tmp/tmpu4q1svox.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866] 
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866] 
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866] 
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpu4q1svox.ptx -o /tmp/tmpu4q1svox.ptx.o
(EngineCore_DP0 pid=292014) ERROR 01-25 18:42:07 [core.py:866] 

STDERR:
[2026-01-25 18:41:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:41:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:41:50] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:41:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:41:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:41:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:41:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:41:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:41:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:41:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:41:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:41:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:41:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:41:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:41:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:41:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:41:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:41:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:41:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:41:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:41:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:41:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:41:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:41:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:41:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:41:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:41:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:41:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=292014) [2026-01-25 18:41:54] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=292014) [2026-01-25 18:41:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=292014) [2026-01-25 18:41:54] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=292014) [2026-01-25 18:41:54] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=292014) [2026-01-25 18:41:54] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=292014) [2026-01-25 18:41:54] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=292014) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=292014) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.90s/it]
(EngineCore_DP0 pid=292014) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.90s/it]
(EngineCore_DP0 pid=292014) 
(EngineCore_DP0 pid=292014) [2026-01-25 18:42:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=292014) [2026-01-25 18:42:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=292014) [2026-01-25 18:42:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=292014) [2026-01-25 18:42:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=292014) [2026-01-25 18:42:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=292014) [2026-01-25 18:42:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=292014) [2026-01-25 18:42:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=292014) [2026-01-25 18:42:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=292014) Process EngineCore_DP0:
(EngineCore_DP0 pid=292014) Traceback (most recent call last):
(EngineCore_DP0 pid=292014)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=292014)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=292014)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=292014)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=292014) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpu4q1svox.ptx', '-o', '/tmp/tmpu4q1svox.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=292014) 
(EngineCore_DP0 pid=292014) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=292014) 
(EngineCore_DP0 pid=292014) Traceback (most recent call last):
(EngineCore_DP0 pid=292014)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=292014)     self.run()
(EngineCore_DP0 pid=292014)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=292014)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=292014)     raise e
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=292014)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=292014)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=292014)     super().__init__(
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=292014)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=292014)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=292014)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=292014)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=292014)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=292014)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=292014)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=292014)     return func(*args, **kwargs)
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=292014)     return func(*args, **kwargs)
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=292014)     self.model_runner.profile_run()
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=292014)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=292014)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=292014)     return func(*args, **kwargs)
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=292014)     outputs = self.model(
(EngineCore_DP0 pid=292014)               ^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=292014)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=292014)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=292014)     model_output = self.model(
(EngineCore_DP0 pid=292014)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=292014)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=292014)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=292014)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=292014)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=292014)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=292014)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=292014)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=292014)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=292014)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=292014)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=292014)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=292014)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=292014)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=292014)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=292014)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=292014)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=292014)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=292014)     return self._linear_fn(
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=292014)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=292014)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=292014)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=292014)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=292014)     return fn(input, L)
(EngineCore_DP0 pid=292014)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=292014)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=292014)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=292014)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=292014)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=292014)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=292014)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=292014)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=292014)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=292014)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=292014)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=292014)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=292014)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292014)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=292014)     raise PTXASError(error)
(EngineCore_DP0 pid=292014) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=292014) `ptxas` stderr:
(EngineCore_DP0 pid=292014) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=292014) 
(EngineCore_DP0 pid=292014) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpu4q1svox.ptx -o /tmp/tmpu4q1svox.ptx.o
(EngineCore_DP0 pid=292014) 
[rank0]:[W125 18:42:07.733833076 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16

========== M=128 ==========
Time: 2026-01-25 18:42:09
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M128.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:42:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:42:12 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=292529) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=292529) 
(EngineCore_DP0 pid=292529) 
(EngineCore_DP0 pid=292529) ================================================================
(EngineCore_DP0 pid=292529) Internal Triton PTX codegen error
(EngineCore_DP0 pid=292529) `ptxas` stderr:
(EngineCore_DP0 pid=292529) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=292529) 
(EngineCore_DP0 pid=292529) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpkgaibpz9.ptx -o /tmp/tmpkgaibpz9.ptx.o
(EngineCore_DP0 pid=292529) 
(EngineCore_DP0 pid=292529) 
(EngineCore_DP0 pid=292529) //
(EngineCore_DP0 pid=292529) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=292529) //
(EngineCore_DP0 pid=292529) 
(EngineCore_DP0 pid=292529) .version 8.7
(EngineCore_DP0 pid=292529) .target sm_121a
(EngineCore_DP0 pid=292529) .address_size 64
(EngineCore_DP0 pid=292529) 
(EngineCore_DP0 pid=292529) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=292529) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=292529)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=292529) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=292529) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=292529) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=292529) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=292529) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=292529) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=292529) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=292529) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=292529) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=292529) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=292529) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=292529) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=292529) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=292529) )
(EngineCore_DP0 pid=292529) .reqntid 128
(EngineCore_DP0 pid=292529) {
(EngineCore_DP0 pid=292529) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=292529) 	.reg .b16 	%rs<64>;
(EngineCore_DP0 pid=292529) 	.reg .b32 	%r<177>;
(EngineCore_DP0 pid=292529) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=292529) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=292529) $L__func_begin0:
(EngineCore_DP0 pid=292529) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=292529) 
(EngineCore_DP0 pid=292529) // %bb.0:
(EngineCore_DP0 pid=292529) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=292529) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=292529) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=292529) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=292529) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=292529) $L__tmp0:
(EngineCore_DP0 pid=292529) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=292529) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=292529) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=292529) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=292529) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=292529) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=292529) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=292529) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=292529) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=292529) 	and.b32 	%r3, %r2, 127;
(EngineCore_DP0 pid=292529) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=292529) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=292529) 	mov.b32 	%r175, 0f2B8CBCCC;
(EngineCore_DP0 pid=292529) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=292529) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=292529) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=292529) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=292529) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=292529) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=292529) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=292529) 	and.b32 	%r38, %r37, 12;
(EngineCore_DP0 pid=292529) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=292529) 	add.s32 	%r57, %r39, %r38;
(EngineCore_DP0 pid=292529) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=292529) 	add.s32 	%r60, %r39, %r40;
(EngineCore_DP0 pid=292529) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=292529) 	mov.b32 	%r173, 0f00000000;
(EngineCore_DP0 pid=292529) 	setp.lt.u32 	%p5, %r2, 4;
(EngineCore_DP0 pid=292529) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=292529) 	mov.b32 	%r174, %r45;
(EngineCore_DP0 pid=292529) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=292529) 	.loc	1 299 19                        // quant_slide_tuned_Llama3.2-1B.py:299:19
(EngineCore_DP0 pid=292529) 	add.s32 	%r63, %r4, %r174;
(EngineCore_DP0 pid=292529) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=292529) 	add.s32 	%r64, %r63, 1024;
(EngineCore_DP0 pid=292529) 	setp.lt.s32 	%p2, %r63, %r23;
(EngineCore_DP0 pid=292529) 	setp.lt.s32 	%p3, %r64, %r23;
(EngineCore_DP0 pid=292529) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=292529) 	mad.wide.s32 	%rd6, %r63, 2, %rd1;
(EngineCore_DP0 pid=292529) 	add.s64 	%rd7, %rd6, 2048;
(EngineCore_DP0 pid=292529) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=292529) 	// begin inline asm
(EngineCore_DP0 pid=292529) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=292529) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=292529) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=292529) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=292529) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=292529) 	// end inline asm
(EngineCore_DP0 pid=292529) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=292529) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=292529) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=292529) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=292529) 	// begin inline asm
(EngineCore_DP0 pid=292529) 	mov.u32 %r49, %r45;
(EngineCore_DP0 pid=292529) 	mov.u32 %r50, %r45;
(EngineCore_DP0 pid=292529) 	mov.u32 %r51, %r45;
(EngineCore_DP0 pid=292529) 	mov.u32 %r52, %r45;
(EngineCore_DP0 pid=292529) 	@%p3 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=292529) 	// end inline asm
(EngineCore_DP0 pid=292529) 	mov.b32 	{%rs9, %rs10}, %r49;
(EngineCore_DP0 pid=292529) 	mov.b32 	{%rs11, %rs12}, %r50;
(EngineCore_DP0 pid=292529) 	mov.b32 	{%rs13, %rs14}, %r51;
(EngineCore_DP0 pid=292529) 	mov.b32 	{%rs15, %rs16}, %r52;
(EngineCore_DP0 pid=292529) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=292529) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=292529) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=292529) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=292529) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=292529) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=292529) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=292529) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=292529) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=292529) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=292529) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=292529) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=292529) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=292529) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=292529) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=292529) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=292529) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=292529) $L__tmp1:
(EngineCore_DP0 pid=292529) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292529) 	bar.sync 	0;
(EngineCore_DP0 pid=292529) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292529) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=292529) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=292529) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=292529) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=292529) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=292529) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=292529) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=292529) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=292529) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=292529) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=292529) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=292529) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=292529) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=292529) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=292529) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=292529) 	cvt.f32.bf16 	%r65, %rs47;
(EngineCore_DP0 pid=292529) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292529) 	shfl.sync.bfly.b32 	%r66, %r65, 16, 31, -1;
(EngineCore_DP0 pid=292529) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292529) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=292529) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292529) 	shfl.sync.bfly.b32 	%r68, %r67, 8, 31, -1;
(EngineCore_DP0 pid=292529) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292529) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=292529) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292529) 	shfl.sync.bfly.b32 	%r70, %r69, 4, 31, -1;
(EngineCore_DP0 pid=292529) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292529) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=292529) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292529) 	shfl.sync.bfly.b32 	%r72, %r71, 2, 31, -1;
(EngineCore_DP0 pid=292529) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292529) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=292529) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292529) 	shfl.sync.bfly.b32 	%r74, %r73, 1, 31, -1;
(EngineCore_DP0 pid=292529) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292529) 	max.f32 	%r58, %r73, %r74;
(EngineCore_DP0 pid=292529) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292529) 	// begin inline asm
(EngineCore_DP0 pid=292529) 	@%p4 st.shared.b32 [ %r57 + 0 ], %r58;
(EngineCore_DP0 pid=292529) 	// end inline asm
(EngineCore_DP0 pid=292529) 	bar.sync 	0;
(EngineCore_DP0 pid=292529) 	// begin inline asm
(EngineCore_DP0 pid=292529) 	@%p5 ld.shared.b32 %r59, [ %r60 + 0 ];
(EngineCore_DP0 pid=292529) 	// end inline asm
(EngineCore_DP0 pid=292529) 	shfl.sync.bfly.b32 	%r75, %r59, 2, 31, -1;
(EngineCore_DP0 pid=292529) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292529) 	max.f32 	%r76, %r59, %r75;
(EngineCore_DP0 pid=292529) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292529) 	shfl.sync.bfly.b32 	%r77, %r76, 1, 31, -1;
(EngineCore_DP0 pid=292529) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292529) 	max.f32 	%r62, %r76, %r77;
(EngineCore_DP0 pid=292529) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=292529) 	// begin inline asm
(EngineCore_DP0 pid=292529) 	@%p28 st.shared.b32 [ %r60 + 0 ], %r62;
(EngineCore_DP0 pid=292529) 	// end inline asm
(EngineCore_DP0 pid=292529) 	bar.sync 	0;
(EngineCore_DP0 pid=292529) 	ld.shared.b32 	%r78, [global_smem];
(EngineCore_DP0 pid=292529) $L__tmp2:
(EngineCore_DP0 pid=292529) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=292529) 	max.f32 	%r173, %r173, %r78;
(EngineCore_DP0 pid=292529) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=292529) 	add.s32 	%r174, %r174, 2048;
(EngineCore_DP0 pid=292529) 	setp.lt.s32 	%p7, %r174, %r24;
(EngineCore_DP0 pid=292529) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=292529) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=292529) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=292529) 	max.f32 	%r175, %r173, 0f2B8CBCCC;
(EngineCore_DP0 pid=292529) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=292529) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=292529) 	mov.b32 	%r80, 0f42FE0000;
(EngineCore_DP0 pid=292529) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=292529) 	div.full.f32 	%r81, %r175, %r80;
(EngineCore_DP0 pid=292529) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=292529) 	max.f32 	%r79, %r81, 0f37810204;
(EngineCore_DP0 pid=292529) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=292529) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=292529) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=292529) 	// begin inline asm
(EngineCore_DP0 pid=292529) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r79 };
(EngineCore_DP0 pid=292529) 	// end inline asm
(EngineCore_DP0 pid=292529) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=292529) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=292529) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=292529) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=292529) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=292529) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=292529) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=292529) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=292529) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=292529) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=292529) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=292529) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=292529) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=292529) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=292529) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=292529) 	div.full.f32 	%r14, %r80, %r175;
(EngineCore_DP0 pid=292529) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=292529) 	mov.b32 	%r176, 0;
(EngineCore_DP0 pid=292529) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=292529)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=292529) 	.loc	1 313 31                        // quant_slide_tuned_Llama3.2-1B.py:313:31
(EngineCore_DP0 pid=292529) 	add.s32 	%r85, %r16, %r176;
(EngineCore_DP0 pid=292529) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=292529) 	add.s32 	%r86, %r85, 1;
(EngineCore_DP0 pid=292529) 	setp.lt.s32 	%p18, %r85, %r15;
(EngineCore_DP0 pid=292529) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=292529) 	shr.s32 	%r87, %r85, 31;
(EngineCore_DP0 pid=292529) 	shr.u32 	%r88, %r87, 30;
(EngineCore_DP0 pid=292529) 	add.s32 	%r89, %r85, %r88;
(EngineCore_DP0 pid=292529) 	shr.s32 	%r90, %r89, 2;
(EngineCore_DP0 pid=292529) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=292529) 	shr.s32 	%r91, %r86, 31;
(EngineCore_DP0 pid=292529) 	shr.u32 	%r92, %r91, 30;
(EngineCore_DP0 pid=292529) 	add.s32 	%r93, %r86, %r92;
(EngineCore_DP0 pid=292529) 	and.b32 	%r94, %r93, 2147483644;
(EngineCore_DP0 pid=292529) 	sub.s32 	%r95, %r86, %r94;
(EngineCore_DP0 pid=292529) 	and.b32 	%r96, %r89, 2147483644;
(EngineCore_DP0 pid=292529) 	sub.s32 	%r97, %r85, %r96;
(EngineCore_DP0 pid=292529) 	.loc	1 319 22                        // quant_slide_tuned_Llama3.2-1B.py:319:22
(EngineCore_DP0 pid=292529) 	mul.lo.s32 	%r98, %r90, 10;
(EngineCore_DP0 pid=292529) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=292529) 	shl.b32 	%r99, %r97, 1;
(EngineCore_DP0 pid=292529) 	shl.b32 	%r100, %r95, 1;
(EngineCore_DP0 pid=292529) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=292529) 	add.s32 	%r101, %r98, %r100;
(EngineCore_DP0 pid=292529) 	add.s32 	%r102, %r98, %r99;
(EngineCore_DP0 pid=292529) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=292529) 	setp.lt.s32 	%p19, %r102, %r23;
(EngineCore_DP0 pid=292529) 	setp.lt.s32 	%p20, %r101, %r23;
(EngineCore_DP0 pid=292529) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=292529) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=292529) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=292529) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=292529) 	mad.wide.s32 	%rd9, %r102, 2, %rd1;
(EngineCore_DP0 pid=292529) 	mad.wide.s32 	%rd10, %r101, 2, %rd1;
(EngineCore_DP0 pid=292529) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=292529) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=292529) 	// begin inline asm
(EngineCore_DP0 pid=292529) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=292529) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=292529) 	// end inline asm
(EngineCore_DP0 pid=292529) 	// begin inline asm
(EngineCore_DP0 pid=292529) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=292529) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=292529) 	// end inline asm
(EngineCore_DP0 pid=292529) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=292529) 	cvt.f32.bf16 	%r103, %rs48;
(EngineCore_DP0 pid=292529) 	cvt.f32.bf16 	%r104, %rs50;
(EngineCore_DP0 pid=292529) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=292529) 	or.b32 	%r105, %r102, 1;
(EngineCore_DP0 pid=292529) 	or.b32 	%r106, %r101, 1;
(EngineCore_DP0 pid=292529) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=292529) 	setp.lt.s32 	%p21, %r105, %r23;
(EngineCore_DP0 pid=292529) 	setp.lt.s32 	%p22, %r106, %r23;
(EngineCore_DP0 pid=292529) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=292529) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=292529) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=292529) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=292529) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=292529) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=292529) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=292529) 	// begin inline asm
(EngineCore_DP0 pid=292529) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=292529) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=292529) 	// end inline asm
(EngineCore_DP0 pid=292529) 	// begin inline asm
(EngineCore_DP0 pid=292529) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=292529) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=292529) 	// end inline asm
(EngineCore_DP0 pid=292529) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=292529) 	cvt.f32.bf16 	%r107, %rs52;
(EngineCore_DP0 pid=292529) 	cvt.f32.bf16 	%r108, %rs54;
(EngineCore_DP0 pid=292529) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=292529) 	add.s32 	%r109, %r102, 2;
(EngineCore_DP0 pid=292529) 	add.s32 	%r110, %r101, 2;
(EngineCore_DP0 pid=292529) 	add.s32 	%r111, %r102, 3;
(EngineCore_DP0 pid=292529) 	add.s32 	%r112, %r101, 3;
(EngineCore_DP0 pid=292529) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=292529) 	setp.lt.s32 	%p23, %r112, %r23;
(EngineCore_DP0 pid=292529) 	setp.lt.s32 	%p24, %r111, %r23;
(EngineCore_DP0 pid=292529) 	setp.lt.s32 	%p25, %r110, %r23;
(EngineCore_DP0 pid=292529) 	setp.lt.s32 	%p26, %r109, %r23;
(EngineCore_DP0 pid=292529) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=292529) 	and.pred 	%p14, %p18, %p26;
(EngineCore_DP0 pid=292529) 	and.pred 	%p15, %p18, %p25;
(EngineCore_DP0 pid=292529) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=292529) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=292529) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=292529) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=292529) 	// begin inline asm
(EngineCore_DP0 pid=292529) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=292529) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=292529) 	// end inline asm
(EngineCore_DP0 pid=292529) 	// begin inline asm
(EngineCore_DP0 pid=292529) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=292529) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=292529) 	// end inline asm
(EngineCore_DP0 pid=292529) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=292529) 	cvt.f32.bf16 	%r113, %rs56;
(EngineCore_DP0 pid=292529) 	cvt.f32.bf16 	%r114, %rs58;
(EngineCore_DP0 pid=292529) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=292529) 	and.pred 	%p16, %p18, %p24;
(EngineCore_DP0 pid=292529) 	and.pred 	%p17, %p18, %p23;
(EngineCore_DP0 pid=292529) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=292529) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=292529) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=292529) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=292529) 	// begin inline asm
(EngineCore_DP0 pid=292529) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=292529) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=292529) 	// end inline asm
(EngineCore_DP0 pid=292529) 	// begin inline asm
(EngineCore_DP0 pid=292529) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=292529) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=292529) 	// end inline asm
(EngineCore_DP0 pid=292529) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=292529) 	cvt.f32.bf16 	%r115, %rs60;
(EngineCore_DP0 pid=292529) 	cvt.f32.bf16 	%r116, %rs62;
(EngineCore_DP0 pid=292529) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=292529) 	mul.f32 	%r117, %r14, %r103;
(EngineCore_DP0 pid=292529) 	mul.f32 	%r118, %r14, %r104;
(EngineCore_DP0 pid=292529) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=292529) 	cvt.rni.f32.f32 	%r119, %r117;
(EngineCore_DP0 pid=292529) 	cvt.rni.f32.f32 	%r120, %r118;
(EngineCore_DP0 pid=292529) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=292529) 	max.f32 	%r121, %r119, 0fC3000000;
(EngineCore_DP0 pid=292529) 	min.f32 	%r122, %r121, 0f42FE0000;
(EngineCore_DP0 pid=292529) 	max.f32 	%r123, %r120, 0fC3000000;
(EngineCore_DP0 pid=292529) 	min.f32 	%r124, %r123, 0f42FE0000;
(EngineCore_DP0 pid=292529) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=292529) 	cvt.rzi.s32.f32 	%r125, %r122;
(EngineCore_DP0 pid=292529) 	cvt.rzi.s32.f32 	%r126, %r124;
(EngineCore_DP0 pid=292529) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=292529) 	and.b32 	%r127, %r125, 255;
(EngineCore_DP0 pid=292529) 	and.b32 	%r128, %r126, 255;
(EngineCore_DP0 pid=292529) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=292529) 	mul.f32 	%r129, %r14, %r107;
(EngineCore_DP0 pid=292529) 	mul.f32 	%r130, %r14, %r108;
(EngineCore_DP0 pid=292529) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=292529) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=292529) 	cvt.rni.f32.f32 	%r132, %r130;
(EngineCore_DP0 pid=292529) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=292529) 	mul.f32 	%r133, %r14, %r113;
(EngineCore_DP0 pid=292529) 	mul.f32 	%r134, %r14, %r114;
(EngineCore_DP0 pid=292529) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=292529) 	cvt.rni.f32.f32 	%r135, %r133;
(EngineCore_DP0 pid=292529) 	cvt.rni.f32.f32 	%r136, %r134;
(EngineCore_DP0 pid=292529) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=292529) 	mul.f32 	%r137, %r14, %r115;
(EngineCore_DP0 pid=292529) 	mul.f32 	%r138, %r14, %r116;
(EngineCore_DP0 pid=292529) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=292529) 	cvt.rni.f32.f32 	%r139, %r137;
(EngineCore_DP0 pid=292529) 	cvt.rni.f32.f32 	%r140, %r138;
(EngineCore_DP0 pid=292529) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=292529) 	max.f32 	%r141, %r139, 0fC3000000;
(EngineCore_DP0 pid=292529) 	min.f32 	%r142, %r141, 0f42FE0000;
(EngineCore_DP0 pid=292529) 	max.f32 	%r143, %r140, 0fC3000000;
(EngineCore_DP0 pid=292529) 	min.f32 	%r144, %r143, 0f42FE0000;
(EngineCore_DP0 pid=292529) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=292529) 	cvt.rzi.s32.f32 	%r145, %r142;
(EngineCore_DP0 pid=292529) 	cvt.rzi.s32.f32 	%r146, %r144;
(EngineCore_DP0 pid=292529) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=292529) 	max.f32 	%r147, %r135, 0fC3000000;
(EngineCore_DP0 pid=292529) 	max.f32 	%r148, %r131, 0fC3000000;
(EngineCore_DP0 pid=292529) 	min.f32 	%r149, %r148, 0f42FE0000;
(EngineCore_DP0 pid=292529) 	min.f32 	%r150, %r147, 0f42FE0000;
(EngineCore_DP0 pid=292529) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=292529) 	cvt.rzi.s32.f32 	%r151, %r150;
(EngineCore_DP0 pid=292529) 	cvt.rzi.s32.f32 	%r152, %r149;
(EngineCore_DP0 pid=292529) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=292529) 	shl.b32 	%r153, %r152, 8;
(EngineCore_DP0 pid=292529) 	shl.b32 	%r154, %r151, 16;
(EngineCore_DP0 pid=292529) 	and.b32 	%r155, %r154, 16711680;
(EngineCore_DP0 pid=292529) 	and.b32 	%r156, %r153, 65280;
(EngineCore_DP0 pid=292529) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=292529) 	or.b32 	%r157, %r156, %r127;
(EngineCore_DP0 pid=292529) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=292529) 	max.f32 	%r158, %r136, 0fC3000000;
(EngineCore_DP0 pid=292529) 	max.f32 	%r159, %r132, 0fC3000000;
(EngineCore_DP0 pid=292529) 	min.f32 	%r160, %r159, 0f42FE0000;
(EngineCore_DP0 pid=292529) 	min.f32 	%r161, %r158, 0f42FE0000;
(EngineCore_DP0 pid=292529) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=292529) 	cvt.rzi.s32.f32 	%r162, %r161;
(EngineCore_DP0 pid=292529) 	cvt.rzi.s32.f32 	%r163, %r160;
(EngineCore_DP0 pid=292529) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=292529) 	shl.b32 	%r164, %r163, 8;
(EngineCore_DP0 pid=292529) 	shl.b32 	%r165, %r162, 16;
(EngineCore_DP0 pid=292529) 	and.b32 	%r166, %r165, 16711680;
(EngineCore_DP0 pid=292529) 	and.b32 	%r167, %r164, 65280;
(EngineCore_DP0 pid=292529) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=292529) 	or.b32 	%r168, %r167, %r128;
(EngineCore_DP0 pid=292529) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=292529) 	or.b32 	%r169, %r157, %r155;
(EngineCore_DP0 pid=292529) 	or.b32 	%r170, %r168, %r166;
(EngineCore_DP0 pid=292529) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=292529) 	shl.b32 	%r171, %r145, 24;
(EngineCore_DP0 pid=292529) 	shl.b32 	%r172, %r146, 24;
(EngineCore_DP0 pid=292529) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=292529) 	or.b32 	%r83, %r169, %r171;
(EngineCore_DP0 pid=292529) 	or.b32 	%r84, %r170, %r172;
(EngineCore_DP0 pid=292529) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=292529) 	mad.wide.s32 	%rd17, %r85, 4, %rd2;
(EngineCore_DP0 pid=292529) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=292529) 	// begin inline asm
(EngineCore_DP0 pid=292529) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r83, %r84 };
(EngineCore_DP0 pid=292529) 	// end inline asm
(EngineCore_DP0 pid=292529) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=292529) 	add.s32 	%r176, %r176, 256;
(EngineCore_DP0 pid=292529) 	setp.lt.s32 	%p27, %r176, %r15;
(EngineCore_DP0 pid=292529) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=292529) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=292529) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=292529) 	ret;
(EngineCore_DP0 pid=292529) $L__tmp3:
(EngineCore_DP0 pid=292529) $L__func_end0:
(EngineCore_DP0 pid=292529)                                         // -- End function
(EngineCore_DP0 pid=292529) }
(EngineCore_DP0 pid=292529) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=292529) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=292529) 	.section	.debug_abbrev
(EngineCore_DP0 pid=292529) 	{
(EngineCore_DP0 pid=292529) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=292529) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=292529) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=292529) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=292529) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=292529) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=292529) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=292529) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=292529) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=292529) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=292529) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=292529) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=292529) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=292529) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=292529) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=292529) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=292529) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=292529) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=292529) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=292529) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=292529) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=292529) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=292529) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=292529) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=292529) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=292529) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=292529) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=292529) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=292529) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=292529) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=292529) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=292529) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=292529) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=292529) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=292529) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=292529) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=292529) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=292529) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=292529) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=292529) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=292529) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=292529) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=292529) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=292529) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=292529) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=292529) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=292529) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=292529) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=292529) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=292529) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=292529) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=292529) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=292529) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=292529) 	}
(EngineCore_DP0 pid=292529) 	.section	.debug_info
(EngineCore_DP0 pid=292529) 	{
(EngineCore_DP0 pid=292529) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=292529) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=292529) .b8 0
(EngineCore_DP0 pid=292529) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=292529) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=292529) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=292529) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=292529) .b8 114
(EngineCore_DP0 pid=292529) .b8 105
(EngineCore_DP0 pid=292529) .b8 116
(EngineCore_DP0 pid=292529) .b8 111
(EngineCore_DP0 pid=292529) .b8 110
(EngineCore_DP0 pid=292529) .b8 0
(EngineCore_DP0 pid=292529) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=292529) .b8 0
(EngineCore_DP0 pid=292529) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=292529) .b8 117
(EngineCore_DP0 pid=292529) .b8 97
(EngineCore_DP0 pid=292529) .b8 110
(EngineCore_DP0 pid=292529) .b8 116
(EngineCore_DP0 pid=292529) .b8 95
(EngineCore_DP0 pid=292529) .b8 115
(EngineCore_DP0 pid=292529) .b8 108
(EngineCore_DP0 pid=292529) .b8 105
(EngineCore_DP0 pid=292529) .b8 100
(EngineCore_DP0 pid=292529) .b8 101
(EngineCore_DP0 pid=292529) .b8 95
(EngineCore_DP0 pid=292529) .b8 116
(EngineCore_DP0 pid=292529) .b8 117
(EngineCore_DP0 pid=292529) .b8 110
(EngineCore_DP0 pid=292529) .b8 101
(EngineCore_DP0 pid=292529) .b8 100
(EngineCore_DP0 pid=292529) .b8 95
(EngineCore_DP0 pid=292529) .b8 76
(EngineCore_DP0 pid=292529) .b8 108
(EngineCore_DP0 pid=292529) .b8 97
(EngineCore_DP0 pid=292529) .b8 109
(EngineCore_DP0 pid=292529) .b8 97
(EngineCore_DP0 pid=292529) .b8 51
(EngineCore_DP0 pid=292529) .b8 46
(EngineCore_DP0 pid=292529) .b8 50
(EngineCore_DP0 pid=292529) .b8 45
(EngineCore_DP0 pid=292529) .b8 49
(EngineCore_DP0 pid=292529) .b8 66
(EngineCore_DP0 pid=292529) .b8 46
(EngineCore_DP0 pid=292529) .b8 112
(EngineCore_DP0 pid=292529) .b8 121
(EngineCore_DP0 pid=292529) .b8 0
(EngineCore_DP0 pid=292529) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=292529) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=292529) .b8 114
(EngineCore_DP0 pid=292529) .b8 111
(EngineCore_DP0 pid=292529) .b8 111
(EngineCore_DP0 pid=292529) .b8 116
(EngineCore_DP0 pid=292529) .b8 47
(EngineCore_DP0 pid=292529) .b8 118
(EngineCore_DP0 pid=292529) .b8 108
(EngineCore_DP0 pid=292529) .b8 108
(EngineCore_DP0 pid=292529) .b8 109
(EngineCore_DP0 pid=292529) .b8 98
(EngineCore_DP0 pid=292529) .b8 101
(EngineCore_DP0 pid=292529) .b8 110
(EngineCore_DP0 pid=292529) .b8 99
(EngineCore_DP0 pid=292529) .b8 104
(EngineCore_DP0 pid=292529) .b8 47
(EngineCore_DP0 pid=292529) .b8 115
(EngineCore_DP0 pid=292529) .b8 108
(EngineCore_DP0 pid=292529) .b8 105
(EngineCore_DP0 pid=292529) .b8 100
(EngineCore_DP0 pid=292529) .b8 101
(EngineCore_DP0 pid=292529) .b8 115
(EngineCore_DP0 pid=292529) .b8 112
(EngineCore_DP0 pid=292529) .b8 97
(EngineCore_DP0 pid=292529) .b8 114
(EngineCore_DP0 pid=292529) .b8 115
(EngineCore_DP0 pid=292529) .b8 101
(EngineCore_DP0 pid=292529) .b8 47
(EngineCore_DP0 pid=292529) .b8 99
(EngineCore_DP0 pid=292529) .b8 115
(EngineCore_DP0 pid=292529) .b8 114
(EngineCore_DP0 pid=292529) .b8 99
(EngineCore_DP0 pid=292529) .b8 47
(EngineCore_DP0 pid=292529) .b8 102
(EngineCore_DP0 pid=292529) .b8 117
(EngineCore_DP0 pid=292529) .b8 115
(EngineCore_DP0 pid=292529) .b8 101
(EngineCore_DP0 pid=292529) .b8 100
(EngineCore_DP0 pid=292529) .b8 95
(EngineCore_DP0 pid=292529) .b8 113
(EngineCore_DP0 pid=292529) .b8 117
(EngineCore_DP0 pid=292529) .b8 97
(EngineCore_DP0 pid=292529) .b8 110
(EngineCore_DP0 pid=292529) .b8 116
(EngineCore_DP0 pid=292529) .b8 95
(EngineCore_DP0 pid=292529) .b8 115
(EngineCore_DP0 pid=292529) .b8 108
(EngineCore_DP0 pid=292529) .b8 105
(EngineCore_DP0 pid=292529) .b8 100
(EngineCore_DP0 pid=292529) .b8 101
(EngineCore_DP0 pid=292529) .b8 95
(EngineCore_DP0 pid=292529) .b8 116
(EngineCore_DP0 pid=292529) .b8 114
(EngineCore_DP0 pid=292529) .b8 105
(EngineCore_DP0 pid=292529) .b8 116
(EngineCore_DP0 pid=292529) .b8 111
(EngineCore_DP0 pid=292529) .b8 110
(EngineCore_DP0 pid=292529) .b8 47
(EngineCore_DP0 pid=292529) .b8 98
(EngineCore_DP0 pid=292529) .b8 117
(EngineCore_DP0 pid=292529) .b8 105
(EngineCore_DP0 pid=292529) .b8 108
(EngineCore_DP0 pid=292529) .b8 100
(EngineCore_DP0 pid=292529) .b8 47
(EngineCore_DP0 pid=292529) .b8 71
(EngineCore_DP0 pid=292529) .b8 66
(EngineCore_DP0 pid=292529) .b8 49
(EngineCore_DP0 pid=292529) .b8 48
(EngineCore_DP0 pid=292529) .b8 95
(EngineCore_DP0 pid=292529) .b8 99
(EngineCore_DP0 pid=292529) .b8 99
(EngineCore_DP0 pid=292529) .b8 49
(EngineCore_DP0 pid=292529) .b8 50
(EngineCore_DP0 pid=292529) .b8 49
(EngineCore_DP0 pid=292529) .b8 95
(EngineCore_DP0 pid=292529) .b8 112
(EngineCore_DP0 pid=292529) .b8 121
(EngineCore_DP0 pid=292529) .b8 51
(EngineCore_DP0 pid=292529) .b8 49
(EngineCore_DP0 pid=292529) .b8 50
(EngineCore_DP0 pid=292529) .b8 95
(EngineCore_DP0 pid=292529) .b8 99
(EngineCore_DP0 pid=292529) .b8 117
(EngineCore_DP0 pid=292529) .b8 49
(EngineCore_DP0 pid=292529) .b8 50
(EngineCore_DP0 pid=292529) .b8 57
(EngineCore_DP0 pid=292529) .b8 95
(EngineCore_DP0 pid=292529) .b8 97
(EngineCore_DP0 pid=292529) .b8 97
(EngineCore_DP0 pid=292529) .b8 114
(EngineCore_DP0 pid=292529) .b8 99
(EngineCore_DP0 pid=292529) .b8 104
(EngineCore_DP0 pid=292529) .b8 54
(EngineCore_DP0 pid=292529) .b8 52
(EngineCore_DP0 pid=292529) .b8 0
(EngineCore_DP0 pid=292529) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=292529) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=292529) .b8 113
(EngineCore_DP0 pid=292529) .b8 117
(EngineCore_DP0 pid=292529) .b8 97
(EngineCore_DP0 pid=292529) .b8 110
(EngineCore_DP0 pid=292529) .b8 116
(EngineCore_DP0 pid=292529) .b8 95
(EngineCore_DP0 pid=292529) .b8 115
(EngineCore_DP0 pid=292529) .b8 108
(EngineCore_DP0 pid=292529) .b8 105
(EngineCore_DP0 pid=292529) .b8 100
(EngineCore_DP0 pid=292529) .b8 101
(EngineCore_DP0 pid=292529) .b8 95
(EngineCore_DP0 pid=292529) .b8 105
(EngineCore_DP0 pid=292529) .b8 110
(EngineCore_DP0 pid=292529) .b8 116
(EngineCore_DP0 pid=292529) .b8 56
(EngineCore_DP0 pid=292529) .b8 95
(EngineCore_DP0 pid=292529) .b8 107
(EngineCore_DP0 pid=292529) .b8 101
(EngineCore_DP0 pid=292529) .b8 114
(EngineCore_DP0 pid=292529) .b8 110
(EngineCore_DP0 pid=292529) .b8 101
(EngineCore_DP0 pid=292529) .b8 108
(EngineCore_DP0 pid=292529) .b8 0
(EngineCore_DP0 pid=292529) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=292529) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=292529) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=292529) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=292529) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=292529) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=292529) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=292529) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=292529) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=292529) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=292529) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=292529) .b8 1
(EngineCore_DP0 pid=292529) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=292529) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=292529) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=292529) 	}
(EngineCore_DP0 pid=292529) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=292529) 
(EngineCore_DP0 pid=292529) ================================================================
(EngineCore_DP0 pid=292529) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=292529) 
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpkgaibpz9.ptx', '-o', '/tmp/tmpkgaibpz9.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866] 
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866] 
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866] 
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpkgaibpz9.ptx -o /tmp/tmpkgaibpz9.ptx.o
(EngineCore_DP0 pid=292529) ERROR 01-25 18:42:29 [core.py:866] 

STDERR:
[2026-01-25 18:42:12] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:42:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:42:12] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:42:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:42:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:42:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:42:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:42:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:42:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:42:16] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:42:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:42:16] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:42:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:42:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:42:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:42:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:42:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:42:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=292529) [2026-01-25 18:42:16] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=292529) [2026-01-25 18:42:16] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=292529) [2026-01-25 18:42:16] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=292529) [2026-01-25 18:42:16] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=292529) [2026-01-25 18:42:16] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=292529) [2026-01-25 18:42:16] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=292529) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=292529) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.99s/it]
(EngineCore_DP0 pid=292529) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.99s/it]
(EngineCore_DP0 pid=292529) 
(EngineCore_DP0 pid=292529) [2026-01-25 18:42:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=292529) [2026-01-25 18:42:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=292529) [2026-01-25 18:42:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=292529) [2026-01-25 18:42:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=292529) [2026-01-25 18:42:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=292529) [2026-01-25 18:42:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=292529) [2026-01-25 18:42:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=292529) [2026-01-25 18:42:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=292529) Process EngineCore_DP0:
(EngineCore_DP0 pid=292529) Traceback (most recent call last):
(EngineCore_DP0 pid=292529)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=292529)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=292529)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=292529)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=292529) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpkgaibpz9.ptx', '-o', '/tmp/tmpkgaibpz9.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=292529) 
(EngineCore_DP0 pid=292529) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=292529) 
(EngineCore_DP0 pid=292529) Traceback (most recent call last):
(EngineCore_DP0 pid=292529)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=292529)     self.run()
(EngineCore_DP0 pid=292529)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=292529)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=292529)     raise e
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=292529)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=292529)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=292529)     super().__init__(
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=292529)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=292529)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=292529)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=292529)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=292529)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=292529)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=292529)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=292529)     return func(*args, **kwargs)
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=292529)     return func(*args, **kwargs)
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=292529)     self.model_runner.profile_run()
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=292529)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=292529)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=292529)     return func(*args, **kwargs)
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=292529)     outputs = self.model(
(EngineCore_DP0 pid=292529)               ^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=292529)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=292529)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=292529)     model_output = self.model(
(EngineCore_DP0 pid=292529)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=292529)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=292529)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=292529)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=292529)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=292529)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=292529)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=292529)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=292529)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=292529)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=292529)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=292529)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=292529)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=292529)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=292529)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=292529)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=292529)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=292529)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=292529)     return self._linear_fn(
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=292529)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=292529)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=292529)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=292529)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=292529)     return fn(input, L)
(EngineCore_DP0 pid=292529)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=292529)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=292529)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=292529)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=292529)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=292529)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=292529)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=292529)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=292529)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=292529)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=292529)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=292529)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=292529)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=292529)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=292529)     raise PTXASError(error)
(EngineCore_DP0 pid=292529) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=292529) `ptxas` stderr:
(EngineCore_DP0 pid=292529) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=292529) 
(EngineCore_DP0 pid=292529) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpkgaibpz9.ptx -o /tmp/tmpkgaibpz9.ptx.o
(EngineCore_DP0 pid=292529) 
[rank0]:[W125 18:42:29.138077260 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=128

========== M=256 ==========
Time: 2026-01-25 18:42:31
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M256.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:42:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:42:35 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=293013) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=293013) 
(EngineCore_DP0 pid=293013) 
(EngineCore_DP0 pid=293013) ================================================================
(EngineCore_DP0 pid=293013) Internal Triton PTX codegen error
(EngineCore_DP0 pid=293013) `ptxas` stderr:
(EngineCore_DP0 pid=293013) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=293013) 
(EngineCore_DP0 pid=293013) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmphvlqktd7.ptx -o /tmp/tmphvlqktd7.ptx.o
(EngineCore_DP0 pid=293013) 
(EngineCore_DP0 pid=293013) 
(EngineCore_DP0 pid=293013) //
(EngineCore_DP0 pid=293013) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=293013) //
(EngineCore_DP0 pid=293013) 
(EngineCore_DP0 pid=293013) .version 8.7
(EngineCore_DP0 pid=293013) .target sm_121a
(EngineCore_DP0 pid=293013) .address_size 64
(EngineCore_DP0 pid=293013) 
(EngineCore_DP0 pid=293013) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=293013) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=293013)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=293013) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=293013) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=293013) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=293013) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=293013) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=293013) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=293013) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=293013) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=293013) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=293013) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=293013) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=293013) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=293013) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=293013) )
(EngineCore_DP0 pid=293013) .reqntid 1024
(EngineCore_DP0 pid=293013) {
(EngineCore_DP0 pid=293013) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=293013) 	.reg .b16 	%rs<20>;
(EngineCore_DP0 pid=293013) 	.reg .b32 	%r<120>;
(EngineCore_DP0 pid=293013) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=293013) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=293013) $L__func_begin0:
(EngineCore_DP0 pid=293013) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=293013) 
(EngineCore_DP0 pid=293013) // %bb.0:
(EngineCore_DP0 pid=293013) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=293013) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=293013) 	ld.param.b32 	%r17, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=293013) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=293013) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=293013) $L__tmp0:
(EngineCore_DP0 pid=293013) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=293013) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=293013) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=293013) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=293013) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=293013) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=293013) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=293013) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=293013) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=293013) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=293013) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=293013) 	mov.b32 	%r118, 0f2B8CBCCC;
(EngineCore_DP0 pid=293013) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=293013) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=293013) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=293013) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=293013) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=293013) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=293013) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=293013) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=293013) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=293013) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=293013) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=293013) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=293013) 	mov.b32 	%r116, 0f00000000;
(EngineCore_DP0 pid=293013) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=293013) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=293013) 	mov.b32 	%r117, %r37;
(EngineCore_DP0 pid=293013) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=293013) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=293013) 	add.s32 	%r45, %r3, %r117;
(EngineCore_DP0 pid=293013) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=293013) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=293013) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=293013) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=293013) 	// begin inline asm
(EngineCore_DP0 pid=293013) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=293013) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=293013) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=293013) 	// end inline asm
(EngineCore_DP0 pid=293013) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=293013) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=293013) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=293013) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=293013) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=293013) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=293013) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=293013) $L__tmp1:
(EngineCore_DP0 pid=293013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	bar.sync 	0;
(EngineCore_DP0 pid=293013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=293013) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=293013) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=293013) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=293013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=293013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=293013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=293013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=293013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=293013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=293013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=293013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=293013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=293013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=293013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	// begin inline asm
(EngineCore_DP0 pid=293013) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=293013) 	// end inline asm
(EngineCore_DP0 pid=293013) 	bar.sync 	0;
(EngineCore_DP0 pid=293013) 	// begin inline asm
(EngineCore_DP0 pid=293013) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=293013) 	// end inline asm
(EngineCore_DP0 pid=293013) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=293013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=293013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=293013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=293013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=293013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=293013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=293013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=293013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=293013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=293013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=293013) 	// begin inline asm
(EngineCore_DP0 pid=293013) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=293013) 	// end inline asm
(EngineCore_DP0 pid=293013) 	bar.sync 	0;
(EngineCore_DP0 pid=293013) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=293013) $L__tmp2:
(EngineCore_DP0 pid=293013) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=293013) 	max.f32 	%r116, %r116, %r65;
(EngineCore_DP0 pid=293013) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=293013) 	add.s32 	%r117, %r117, 4096;
(EngineCore_DP0 pid=293013) 	setp.lt.s32 	%p6, %r117, %r18;
(EngineCore_DP0 pid=293013) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=293013) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=293013) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=293013) 	max.f32 	%r118, %r116, 0f2B8CBCCC;
(EngineCore_DP0 pid=293013) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=293013) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=293013) 	mov.b32 	%r67, 0f42FE0000;
(EngineCore_DP0 pid=293013) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=293013) 	div.full.f32 	%r68, %r118, %r67;
(EngineCore_DP0 pid=293013) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=293013) 	max.f32 	%r66, %r68, 0f37810204;
(EngineCore_DP0 pid=293013) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=293013) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=293013) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=293013) 	// begin inline asm
(EngineCore_DP0 pid=293013) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=293013) 	// end inline asm
(EngineCore_DP0 pid=293013) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=293013) 	shl.b32 	%r14, %r19, 2;
(EngineCore_DP0 pid=293013) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=293013) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=293013) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=293013) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=293013) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=293013) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=293013) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=293013) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=293013) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=293013) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=293013) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=293013) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=293013) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=293013) 	div.full.f32 	%r13, %r67, %r118;
(EngineCore_DP0 pid=293013) 	mov.b32 	%r119, 0;
(EngineCore_DP0 pid=293013) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=293013)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=293013) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=293013) 	add.s32 	%r72, %r2, %r119;
(EngineCore_DP0 pid=293013) 	setp.lt.s32 	%p13, %r72, %r14;
(EngineCore_DP0 pid=293013) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=293013) 	shr.s32 	%r73, %r72, 31;
(EngineCore_DP0 pid=293013) 	shr.u32 	%r74, %r73, 30;
(EngineCore_DP0 pid=293013) 	add.s32 	%r75, %r72, %r74;
(EngineCore_DP0 pid=293013) 	shr.s32 	%r76, %r75, 2;
(EngineCore_DP0 pid=293013) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=293013) 	and.b32 	%r77, %r75, 2147483644;
(EngineCore_DP0 pid=293013) 	sub.s32 	%r78, %r72, %r77;
(EngineCore_DP0 pid=293013) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=293013) 	shl.b32 	%r79, %r78, 1;
(EngineCore_DP0 pid=293013) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=293013) 	mad.lo.s32 	%r80, %r76, 10, %r79;
(EngineCore_DP0 pid=293013) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=293013) 	setp.lt.s32 	%p14, %r80, %r17;
(EngineCore_DP0 pid=293013) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=293013) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=293013) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=293013) 	mad.wide.s32 	%rd8, %r80, 2, %rd1;
(EngineCore_DP0 pid=293013) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=293013) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=293013) 	// begin inline asm
(EngineCore_DP0 pid=293013) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=293013) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=293013) 	// end inline asm
(EngineCore_DP0 pid=293013) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=293013) 	cvt.f32.bf16 	%r81, %rs12;
(EngineCore_DP0 pid=293013) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=293013) 	or.b32 	%r82, %r80, 1;
(EngineCore_DP0 pid=293013) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=293013) 	setp.lt.s32 	%p15, %r82, %r17;
(EngineCore_DP0 pid=293013) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=293013) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=293013) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=293013) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=293013) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=293013) 	// begin inline asm
(EngineCore_DP0 pid=293013) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=293013) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=293013) 	// end inline asm
(EngineCore_DP0 pid=293013) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=293013) 	cvt.f32.bf16 	%r83, %rs14;
(EngineCore_DP0 pid=293013) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=293013) 	add.s32 	%r84, %r80, 2;
(EngineCore_DP0 pid=293013) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=293013) 	setp.lt.s32 	%p16, %r84, %r17;
(EngineCore_DP0 pid=293013) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=293013) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=293013) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=293013) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=293013) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=293013) 	// begin inline asm
(EngineCore_DP0 pid=293013) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=293013) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=293013) 	// end inline asm
(EngineCore_DP0 pid=293013) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=293013) 	cvt.f32.bf16 	%r85, %rs16;
(EngineCore_DP0 pid=293013) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=293013) 	add.s32 	%r86, %r80, 3;
(EngineCore_DP0 pid=293013) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=293013) 	setp.lt.s32 	%p17, %r86, %r17;
(EngineCore_DP0 pid=293013) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=293013) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=293013) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=293013) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=293013) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=293013) 	// begin inline asm
(EngineCore_DP0 pid=293013) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=293013) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=293013) 	// end inline asm
(EngineCore_DP0 pid=293013) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=293013) 	cvt.f32.bf16 	%r87, %rs18;
(EngineCore_DP0 pid=293013) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=293013) 	mul.f32 	%r88, %r13, %r81;
(EngineCore_DP0 pid=293013) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=293013) 	cvt.rni.f32.f32 	%r89, %r88;
(EngineCore_DP0 pid=293013) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=293013) 	max.f32 	%r90, %r89, 0fC3000000;
(EngineCore_DP0 pid=293013) 	min.f32 	%r91, %r90, 0f42FE0000;
(EngineCore_DP0 pid=293013) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=293013) 	cvt.rzi.s32.f32 	%r92, %r91;
(EngineCore_DP0 pid=293013) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=293013) 	and.b32 	%r93, %r92, 255;
(EngineCore_DP0 pid=293013) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=293013) 	mul.f32 	%r94, %r13, %r83;
(EngineCore_DP0 pid=293013) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=293013) 	cvt.rni.f32.f32 	%r95, %r94;
(EngineCore_DP0 pid=293013) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=293013) 	mul.f32 	%r96, %r13, %r85;
(EngineCore_DP0 pid=293013) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=293013) 	cvt.rni.f32.f32 	%r97, %r96;
(EngineCore_DP0 pid=293013) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=293013) 	mul.f32 	%r98, %r13, %r87;
(EngineCore_DP0 pid=293013) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=293013) 	cvt.rni.f32.f32 	%r99, %r98;
(EngineCore_DP0 pid=293013) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=293013) 	max.f32 	%r100, %r99, 0fC3000000;
(EngineCore_DP0 pid=293013) 	min.f32 	%r101, %r100, 0f42FE0000;
(EngineCore_DP0 pid=293013) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=293013) 	cvt.rzi.s32.f32 	%r102, %r101;
(EngineCore_DP0 pid=293013) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=293013) 	max.f32 	%r103, %r97, 0fC3000000;
(EngineCore_DP0 pid=293013) 	max.f32 	%r104, %r95, 0fC3000000;
(EngineCore_DP0 pid=293013) 	min.f32 	%r105, %r104, 0f42FE0000;
(EngineCore_DP0 pid=293013) 	min.f32 	%r106, %r103, 0f42FE0000;
(EngineCore_DP0 pid=293013) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=293013) 	cvt.rzi.s32.f32 	%r107, %r106;
(EngineCore_DP0 pid=293013) 	cvt.rzi.s32.f32 	%r108, %r105;
(EngineCore_DP0 pid=293013) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=293013) 	shl.b32 	%r109, %r108, 8;
(EngineCore_DP0 pid=293013) 	shl.b32 	%r110, %r107, 16;
(EngineCore_DP0 pid=293013) 	and.b32 	%r111, %r110, 16711680;
(EngineCore_DP0 pid=293013) 	and.b32 	%r112, %r109, 65280;
(EngineCore_DP0 pid=293013) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=293013) 	or.b32 	%r113, %r112, %r93;
(EngineCore_DP0 pid=293013) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=293013) 	or.b32 	%r114, %r113, %r111;
(EngineCore_DP0 pid=293013) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=293013) 	shl.b32 	%r115, %r102, 24;
(EngineCore_DP0 pid=293013) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=293013) 	or.b32 	%r70, %r114, %r115;
(EngineCore_DP0 pid=293013) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=293013) 	mad.wide.s32 	%rd12, %r72, 4, %rd2;
(EngineCore_DP0 pid=293013) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=293013) 	// begin inline asm
(EngineCore_DP0 pid=293013) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r70 };
(EngineCore_DP0 pid=293013) 	// end inline asm
(EngineCore_DP0 pid=293013) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=293013) 	add.s32 	%r119, %r119, 1024;
(EngineCore_DP0 pid=293013) 	setp.lt.s32 	%p18, %r119, %r14;
(EngineCore_DP0 pid=293013) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=293013) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=293013) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=293013) 	ret;
(EngineCore_DP0 pid=293013) $L__tmp3:
(EngineCore_DP0 pid=293013) $L__func_end0:
(EngineCore_DP0 pid=293013)                                         // -- End function
(EngineCore_DP0 pid=293013) }
(EngineCore_DP0 pid=293013) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=293013) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=293013) 	.section	.debug_abbrev
(EngineCore_DP0 pid=293013) 	{
(EngineCore_DP0 pid=293013) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=293013) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=293013) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=293013) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=293013) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=293013) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=293013) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=293013) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=293013) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=293013) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=293013) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=293013) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=293013) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=293013) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=293013) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=293013) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=293013) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=293013) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=293013) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=293013) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=293013) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=293013) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=293013) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=293013) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=293013) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=293013) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=293013) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=293013) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=293013) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=293013) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=293013) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=293013) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=293013) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=293013) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=293013) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=293013) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=293013) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=293013) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=293013) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=293013) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=293013) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=293013) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=293013) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=293013) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=293013) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=293013) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=293013) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=293013) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=293013) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=293013) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=293013) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=293013) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=293013) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=293013) 	}
(EngineCore_DP0 pid=293013) 	.section	.debug_info
(EngineCore_DP0 pid=293013) 	{
(EngineCore_DP0 pid=293013) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=293013) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=293013) .b8 0
(EngineCore_DP0 pid=293013) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=293013) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=293013) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=293013) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=293013) .b8 114
(EngineCore_DP0 pid=293013) .b8 105
(EngineCore_DP0 pid=293013) .b8 116
(EngineCore_DP0 pid=293013) .b8 111
(EngineCore_DP0 pid=293013) .b8 110
(EngineCore_DP0 pid=293013) .b8 0
(EngineCore_DP0 pid=293013) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=293013) .b8 0
(EngineCore_DP0 pid=293013) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=293013) .b8 117
(EngineCore_DP0 pid=293013) .b8 97
(EngineCore_DP0 pid=293013) .b8 110
(EngineCore_DP0 pid=293013) .b8 116
(EngineCore_DP0 pid=293013) .b8 95
(EngineCore_DP0 pid=293013) .b8 115
(EngineCore_DP0 pid=293013) .b8 108
(EngineCore_DP0 pid=293013) .b8 105
(EngineCore_DP0 pid=293013) .b8 100
(EngineCore_DP0 pid=293013) .b8 101
(EngineCore_DP0 pid=293013) .b8 95
(EngineCore_DP0 pid=293013) .b8 116
(EngineCore_DP0 pid=293013) .b8 117
(EngineCore_DP0 pid=293013) .b8 110
(EngineCore_DP0 pid=293013) .b8 101
(EngineCore_DP0 pid=293013) .b8 100
(EngineCore_DP0 pid=293013) .b8 95
(EngineCore_DP0 pid=293013) .b8 76
(EngineCore_DP0 pid=293013) .b8 108
(EngineCore_DP0 pid=293013) .b8 97
(EngineCore_DP0 pid=293013) .b8 109
(EngineCore_DP0 pid=293013) .b8 97
(EngineCore_DP0 pid=293013) .b8 51
(EngineCore_DP0 pid=293013) .b8 46
(EngineCore_DP0 pid=293013) .b8 50
(EngineCore_DP0 pid=293013) .b8 45
(EngineCore_DP0 pid=293013) .b8 49
(EngineCore_DP0 pid=293013) .b8 66
(EngineCore_DP0 pid=293013) .b8 46
(EngineCore_DP0 pid=293013) .b8 112
(EngineCore_DP0 pid=293013) .b8 121
(EngineCore_DP0 pid=293013) .b8 0
(EngineCore_DP0 pid=293013) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=293013) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=293013) .b8 114
(EngineCore_DP0 pid=293013) .b8 111
(EngineCore_DP0 pid=293013) .b8 111
(EngineCore_DP0 pid=293013) .b8 116
(EngineCore_DP0 pid=293013) .b8 47
(EngineCore_DP0 pid=293013) .b8 118
(EngineCore_DP0 pid=293013) .b8 108
(EngineCore_DP0 pid=293013) .b8 108
(EngineCore_DP0 pid=293013) .b8 109
(EngineCore_DP0 pid=293013) .b8 98
(EngineCore_DP0 pid=293013) .b8 101
(EngineCore_DP0 pid=293013) .b8 110
(EngineCore_DP0 pid=293013) .b8 99
(EngineCore_DP0 pid=293013) .b8 104
(EngineCore_DP0 pid=293013) .b8 47
(EngineCore_DP0 pid=293013) .b8 115
(EngineCore_DP0 pid=293013) .b8 108
(EngineCore_DP0 pid=293013) .b8 105
(EngineCore_DP0 pid=293013) .b8 100
(EngineCore_DP0 pid=293013) .b8 101
(EngineCore_DP0 pid=293013) .b8 115
(EngineCore_DP0 pid=293013) .b8 112
(EngineCore_DP0 pid=293013) .b8 97
(EngineCore_DP0 pid=293013) .b8 114
(EngineCore_DP0 pid=293013) .b8 115
(EngineCore_DP0 pid=293013) .b8 101
(EngineCore_DP0 pid=293013) .b8 47
(EngineCore_DP0 pid=293013) .b8 99
(EngineCore_DP0 pid=293013) .b8 115
(EngineCore_DP0 pid=293013) .b8 114
(EngineCore_DP0 pid=293013) .b8 99
(EngineCore_DP0 pid=293013) .b8 47
(EngineCore_DP0 pid=293013) .b8 102
(EngineCore_DP0 pid=293013) .b8 117
(EngineCore_DP0 pid=293013) .b8 115
(EngineCore_DP0 pid=293013) .b8 101
(EngineCore_DP0 pid=293013) .b8 100
(EngineCore_DP0 pid=293013) .b8 95
(EngineCore_DP0 pid=293013) .b8 113
(EngineCore_DP0 pid=293013) .b8 117
(EngineCore_DP0 pid=293013) .b8 97
(EngineCore_DP0 pid=293013) .b8 110
(EngineCore_DP0 pid=293013) .b8 116
(EngineCore_DP0 pid=293013) .b8 95
(EngineCore_DP0 pid=293013) .b8 115
(EngineCore_DP0 pid=293013) .b8 108
(EngineCore_DP0 pid=293013) .b8 105
(EngineCore_DP0 pid=293013) .b8 100
(EngineCore_DP0 pid=293013) .b8 101
(EngineCore_DP0 pid=293013) .b8 95
(EngineCore_DP0 pid=293013) .b8 116
(EngineCore_DP0 pid=293013) .b8 114
(EngineCore_DP0 pid=293013) .b8 105
(EngineCore_DP0 pid=293013) .b8 116
(EngineCore_DP0 pid=293013) .b8 111
(EngineCore_DP0 pid=293013) .b8 110
(EngineCore_DP0 pid=293013) .b8 47
(EngineCore_DP0 pid=293013) .b8 98
(EngineCore_DP0 pid=293013) .b8 117
(EngineCore_DP0 pid=293013) .b8 105
(EngineCore_DP0 pid=293013) .b8 108
(EngineCore_DP0 pid=293013) .b8 100
(EngineCore_DP0 pid=293013) .b8 47
(EngineCore_DP0 pid=293013) .b8 71
(EngineCore_DP0 pid=293013) .b8 66
(EngineCore_DP0 pid=293013) .b8 49
(EngineCore_DP0 pid=293013) .b8 48
(EngineCore_DP0 pid=293013) .b8 95
(EngineCore_DP0 pid=293013) .b8 99
(EngineCore_DP0 pid=293013) .b8 99
(EngineCore_DP0 pid=293013) .b8 49
(EngineCore_DP0 pid=293013) .b8 50
(EngineCore_DP0 pid=293013) .b8 49
(EngineCore_DP0 pid=293013) .b8 95
(EngineCore_DP0 pid=293013) .b8 112
(EngineCore_DP0 pid=293013) .b8 121
(EngineCore_DP0 pid=293013) .b8 51
(EngineCore_DP0 pid=293013) .b8 49
(EngineCore_DP0 pid=293013) .b8 50
(EngineCore_DP0 pid=293013) .b8 95
(EngineCore_DP0 pid=293013) .b8 99
(EngineCore_DP0 pid=293013) .b8 117
(EngineCore_DP0 pid=293013) .b8 49
(EngineCore_DP0 pid=293013) .b8 50
(EngineCore_DP0 pid=293013) .b8 57
(EngineCore_DP0 pid=293013) .b8 95
(EngineCore_DP0 pid=293013) .b8 97
(EngineCore_DP0 pid=293013) .b8 97
(EngineCore_DP0 pid=293013) .b8 114
(EngineCore_DP0 pid=293013) .b8 99
(EngineCore_DP0 pid=293013) .b8 104
(EngineCore_DP0 pid=293013) .b8 54
(EngineCore_DP0 pid=293013) .b8 52
(EngineCore_DP0 pid=293013) .b8 0
(EngineCore_DP0 pid=293013) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=293013) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=293013) .b8 113
(EngineCore_DP0 pid=293013) .b8 117
(EngineCore_DP0 pid=293013) .b8 97
(EngineCore_DP0 pid=293013) .b8 110
(EngineCore_DP0 pid=293013) .b8 116
(EngineCore_DP0 pid=293013) .b8 95
(EngineCore_DP0 pid=293013) .b8 115
(EngineCore_DP0 pid=293013) .b8 108
(EngineCore_DP0 pid=293013) .b8 105
(EngineCore_DP0 pid=293013) .b8 100
(EngineCore_DP0 pid=293013) .b8 101
(EngineCore_DP0 pid=293013) .b8 95
(EngineCore_DP0 pid=293013) .b8 105
(EngineCore_DP0 pid=293013) .b8 110
(EngineCore_DP0 pid=293013) .b8 116
(EngineCore_DP0 pid=293013) .b8 56
(EngineCore_DP0 pid=293013) .b8 95
(EngineCore_DP0 pid=293013) .b8 107
(EngineCore_DP0 pid=293013) .b8 101
(EngineCore_DP0 pid=293013) .b8 114
(EngineCore_DP0 pid=293013) .b8 110
(EngineCore_DP0 pid=293013) .b8 101
(EngineCore_DP0 pid=293013) .b8 108
(EngineCore_DP0 pid=293013) .b8 0
(EngineCore_DP0 pid=293013) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=293013) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=293013) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=293013) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=293013) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=293013) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=293013) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=293013) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=293013) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=293013) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=293013) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=293013) .b8 1
(EngineCore_DP0 pid=293013) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=293013) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=293013) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=293013) 	}
(EngineCore_DP0 pid=293013) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=293013) 
(EngineCore_DP0 pid=293013) ================================================================
(EngineCore_DP0 pid=293013) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=293013) 
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmphvlqktd7.ptx', '-o', '/tmp/tmphvlqktd7.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866] 
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866] 
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866] 
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmphvlqktd7.ptx -o /tmp/tmphvlqktd7.ptx.o
(EngineCore_DP0 pid=293013) ERROR 01-25 18:42:51 [core.py:866] 

STDERR:
[2026-01-25 18:42:35] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:42:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:42:35] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:42:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:42:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:42:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:42:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:42:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:42:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:42:38] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:42:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:42:38] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:42:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:42:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:42:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:42:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:42:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:42:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:42:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=293013) [2026-01-25 18:42:39] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=293013) [2026-01-25 18:42:39] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=293013) [2026-01-25 18:42:39] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=293013) [2026-01-25 18:42:39] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=293013) [2026-01-25 18:42:39] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=293013) [2026-01-25 18:42:39] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=293013) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=293013) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.77s/it]
(EngineCore_DP0 pid=293013) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.78s/it]
(EngineCore_DP0 pid=293013) 
(EngineCore_DP0 pid=293013) [2026-01-25 18:42:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=293013) [2026-01-25 18:42:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=293013) [2026-01-25 18:42:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=293013) [2026-01-25 18:42:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=293013) [2026-01-25 18:42:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=293013) [2026-01-25 18:42:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=293013) [2026-01-25 18:42:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=293013) [2026-01-25 18:42:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=293013) Process EngineCore_DP0:
(EngineCore_DP0 pid=293013) Traceback (most recent call last):
(EngineCore_DP0 pid=293013)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=293013)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=293013)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=293013)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=293013) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmphvlqktd7.ptx', '-o', '/tmp/tmphvlqktd7.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=293013) 
(EngineCore_DP0 pid=293013) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=293013) 
(EngineCore_DP0 pid=293013) Traceback (most recent call last):
(EngineCore_DP0 pid=293013)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=293013)     self.run()
(EngineCore_DP0 pid=293013)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=293013)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=293013)     raise e
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=293013)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=293013)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=293013)     super().__init__(
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=293013)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=293013)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=293013)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=293013)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=293013)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=293013)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=293013)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=293013)     return func(*args, **kwargs)
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=293013)     return func(*args, **kwargs)
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=293013)     self.model_runner.profile_run()
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=293013)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=293013)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=293013)     return func(*args, **kwargs)
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=293013)     outputs = self.model(
(EngineCore_DP0 pid=293013)               ^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=293013)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=293013)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=293013)     model_output = self.model(
(EngineCore_DP0 pid=293013)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=293013)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=293013)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=293013)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=293013)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=293013)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=293013)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=293013)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=293013)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=293013)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=293013)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=293013)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=293013)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=293013)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=293013)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=293013)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=293013)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=293013)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=293013)     return self._linear_fn(
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=293013)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=293013)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=293013)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=293013)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=293013)     return fn(input, L)
(EngineCore_DP0 pid=293013)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=293013)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=293013)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=293013)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=293013)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=293013)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=293013)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=293013)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=293013)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=293013)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=293013)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=293013)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=293013)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=293013)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=293013)     raise PTXASError(error)
(EngineCore_DP0 pid=293013) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=293013) `ptxas` stderr:
(EngineCore_DP0 pid=293013) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=293013) 
(EngineCore_DP0 pid=293013) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmphvlqktd7.ptx -o /tmp/tmphvlqktd7.ptx.o
(EngineCore_DP0 pid=293013) 
[rank0]:[W125 18:42:52.225030281 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=256

========== M=512 ==========
Time: 2026-01-25 19:06:04
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:06:07 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:06:07 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=324118) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=324118) 
(EngineCore_DP0 pid=324118) 
(EngineCore_DP0 pid=324118) ================================================================
(EngineCore_DP0 pid=324118) Internal Triton PTX codegen error
(EngineCore_DP0 pid=324118) `ptxas` stderr:
(EngineCore_DP0 pid=324118) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=324118) 
(EngineCore_DP0 pid=324118) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpoen7qy8m.ptx -o /tmp/tmpoen7qy8m.ptx.o
(EngineCore_DP0 pid=324118) 
(EngineCore_DP0 pid=324118) 
(EngineCore_DP0 pid=324118) //
(EngineCore_DP0 pid=324118) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=324118) //
(EngineCore_DP0 pid=324118) 
(EngineCore_DP0 pid=324118) .version 8.7
(EngineCore_DP0 pid=324118) .target sm_121a
(EngineCore_DP0 pid=324118) .address_size 64
(EngineCore_DP0 pid=324118) 
(EngineCore_DP0 pid=324118) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=324118) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=324118)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=324118) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=324118) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=324118) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=324118) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=324118) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=324118) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=324118) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=324118) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=324118) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=324118) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=324118) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=324118) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=324118) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=324118) )
(EngineCore_DP0 pid=324118) .reqntid 1024
(EngineCore_DP0 pid=324118) {
(EngineCore_DP0 pid=324118) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=324118) 	.reg .b16 	%rs<20>;
(EngineCore_DP0 pid=324118) 	.reg .b32 	%r<120>;
(EngineCore_DP0 pid=324118) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=324118) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=324118) $L__func_begin0:
(EngineCore_DP0 pid=324118) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=324118) 
(EngineCore_DP0 pid=324118) // %bb.0:
(EngineCore_DP0 pid=324118) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=324118) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=324118) 	ld.param.b32 	%r17, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=324118) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=324118) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=324118) $L__tmp0:
(EngineCore_DP0 pid=324118) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=324118) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=324118) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=324118) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=324118) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=324118) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=324118) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=324118) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=324118) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=324118) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=324118) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=324118) 	mov.b32 	%r118, 0f2B8CBCCC;
(EngineCore_DP0 pid=324118) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=324118) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=324118) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=324118) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=324118) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=324118) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=324118) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=324118) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=324118) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=324118) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=324118) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=324118) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=324118) 	mov.b32 	%r116, 0f00000000;
(EngineCore_DP0 pid=324118) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=324118) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=324118) 	mov.b32 	%r117, %r37;
(EngineCore_DP0 pid=324118) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=324118) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=324118) 	add.s32 	%r45, %r3, %r117;
(EngineCore_DP0 pid=324118) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=324118) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=324118) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=324118) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=324118) 	// begin inline asm
(EngineCore_DP0 pid=324118) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=324118) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=324118) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=324118) 	// end inline asm
(EngineCore_DP0 pid=324118) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=324118) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=324118) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=324118) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=324118) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=324118) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=324118) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=324118) $L__tmp1:
(EngineCore_DP0 pid=324118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	bar.sync 	0;
(EngineCore_DP0 pid=324118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=324118) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=324118) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=324118) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=324118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=324118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=324118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=324118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=324118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=324118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=324118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=324118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=324118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=324118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=324118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	// begin inline asm
(EngineCore_DP0 pid=324118) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=324118) 	// end inline asm
(EngineCore_DP0 pid=324118) 	bar.sync 	0;
(EngineCore_DP0 pid=324118) 	// begin inline asm
(EngineCore_DP0 pid=324118) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=324118) 	// end inline asm
(EngineCore_DP0 pid=324118) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=324118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=324118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=324118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=324118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=324118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=324118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=324118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=324118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=324118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=324118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324118) 	// begin inline asm
(EngineCore_DP0 pid=324118) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=324118) 	// end inline asm
(EngineCore_DP0 pid=324118) 	bar.sync 	0;
(EngineCore_DP0 pid=324118) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=324118) $L__tmp2:
(EngineCore_DP0 pid=324118) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=324118) 	max.f32 	%r116, %r116, %r65;
(EngineCore_DP0 pid=324118) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=324118) 	add.s32 	%r117, %r117, 4096;
(EngineCore_DP0 pid=324118) 	setp.lt.s32 	%p6, %r117, %r18;
(EngineCore_DP0 pid=324118) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=324118) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=324118) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=324118) 	max.f32 	%r118, %r116, 0f2B8CBCCC;
(EngineCore_DP0 pid=324118) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=324118) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=324118) 	mov.b32 	%r67, 0f42FE0000;
(EngineCore_DP0 pid=324118) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=324118) 	div.full.f32 	%r68, %r118, %r67;
(EngineCore_DP0 pid=324118) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=324118) 	max.f32 	%r66, %r68, 0f37810204;
(EngineCore_DP0 pid=324118) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=324118) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=324118) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=324118) 	// begin inline asm
(EngineCore_DP0 pid=324118) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=324118) 	// end inline asm
(EngineCore_DP0 pid=324118) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=324118) 	shl.b32 	%r14, %r19, 2;
(EngineCore_DP0 pid=324118) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=324118) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=324118) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=324118) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=324118) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=324118) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=324118) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=324118) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=324118) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=324118) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=324118) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=324118) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=324118) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=324118) 	div.full.f32 	%r13, %r67, %r118;
(EngineCore_DP0 pid=324118) 	mov.b32 	%r119, 0;
(EngineCore_DP0 pid=324118) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=324118)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=324118) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=324118) 	add.s32 	%r72, %r2, %r119;
(EngineCore_DP0 pid=324118) 	setp.lt.s32 	%p13, %r72, %r14;
(EngineCore_DP0 pid=324118) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=324118) 	shr.s32 	%r73, %r72, 31;
(EngineCore_DP0 pid=324118) 	shr.u32 	%r74, %r73, 30;
(EngineCore_DP0 pid=324118) 	add.s32 	%r75, %r72, %r74;
(EngineCore_DP0 pid=324118) 	shr.s32 	%r76, %r75, 2;
(EngineCore_DP0 pid=324118) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=324118) 	and.b32 	%r77, %r75, 2147483644;
(EngineCore_DP0 pid=324118) 	sub.s32 	%r78, %r72, %r77;
(EngineCore_DP0 pid=324118) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=324118) 	shl.b32 	%r79, %r78, 1;
(EngineCore_DP0 pid=324118) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=324118) 	mad.lo.s32 	%r80, %r76, 10, %r79;
(EngineCore_DP0 pid=324118) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=324118) 	setp.lt.s32 	%p14, %r80, %r17;
(EngineCore_DP0 pid=324118) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=324118) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=324118) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=324118) 	mad.wide.s32 	%rd8, %r80, 2, %rd1;
(EngineCore_DP0 pid=324118) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=324118) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=324118) 	// begin inline asm
(EngineCore_DP0 pid=324118) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=324118) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=324118) 	// end inline asm
(EngineCore_DP0 pid=324118) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=324118) 	cvt.f32.bf16 	%r81, %rs12;
(EngineCore_DP0 pid=324118) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=324118) 	or.b32 	%r82, %r80, 1;
(EngineCore_DP0 pid=324118) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=324118) 	setp.lt.s32 	%p15, %r82, %r17;
(EngineCore_DP0 pid=324118) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=324118) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=324118) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=324118) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=324118) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=324118) 	// begin inline asm
(EngineCore_DP0 pid=324118) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=324118) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=324118) 	// end inline asm
(EngineCore_DP0 pid=324118) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=324118) 	cvt.f32.bf16 	%r83, %rs14;
(EngineCore_DP0 pid=324118) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=324118) 	add.s32 	%r84, %r80, 2;
(EngineCore_DP0 pid=324118) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=324118) 	setp.lt.s32 	%p16, %r84, %r17;
(EngineCore_DP0 pid=324118) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=324118) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=324118) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=324118) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=324118) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=324118) 	// begin inline asm
(EngineCore_DP0 pid=324118) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=324118) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=324118) 	// end inline asm
(EngineCore_DP0 pid=324118) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=324118) 	cvt.f32.bf16 	%r85, %rs16;
(EngineCore_DP0 pid=324118) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=324118) 	add.s32 	%r86, %r80, 3;
(EngineCore_DP0 pid=324118) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=324118) 	setp.lt.s32 	%p17, %r86, %r17;
(EngineCore_DP0 pid=324118) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=324118) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=324118) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=324118) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=324118) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=324118) 	// begin inline asm
(EngineCore_DP0 pid=324118) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=324118) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=324118) 	// end inline asm
(EngineCore_DP0 pid=324118) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=324118) 	cvt.f32.bf16 	%r87, %rs18;
(EngineCore_DP0 pid=324118) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=324118) 	mul.f32 	%r88, %r13, %r81;
(EngineCore_DP0 pid=324118) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=324118) 	cvt.rni.f32.f32 	%r89, %r88;
(EngineCore_DP0 pid=324118) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=324118) 	max.f32 	%r90, %r89, 0fC3000000;
(EngineCore_DP0 pid=324118) 	min.f32 	%r91, %r90, 0f42FE0000;
(EngineCore_DP0 pid=324118) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=324118) 	cvt.rzi.s32.f32 	%r92, %r91;
(EngineCore_DP0 pid=324118) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=324118) 	and.b32 	%r93, %r92, 255;
(EngineCore_DP0 pid=324118) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=324118) 	mul.f32 	%r94, %r13, %r83;
(EngineCore_DP0 pid=324118) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=324118) 	cvt.rni.f32.f32 	%r95, %r94;
(EngineCore_DP0 pid=324118) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=324118) 	mul.f32 	%r96, %r13, %r85;
(EngineCore_DP0 pid=324118) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=324118) 	cvt.rni.f32.f32 	%r97, %r96;
(EngineCore_DP0 pid=324118) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=324118) 	mul.f32 	%r98, %r13, %r87;
(EngineCore_DP0 pid=324118) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=324118) 	cvt.rni.f32.f32 	%r99, %r98;
(EngineCore_DP0 pid=324118) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=324118) 	max.f32 	%r100, %r99, 0fC3000000;
(EngineCore_DP0 pid=324118) 	min.f32 	%r101, %r100, 0f42FE0000;
(EngineCore_DP0 pid=324118) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=324118) 	cvt.rzi.s32.f32 	%r102, %r101;
(EngineCore_DP0 pid=324118) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=324118) 	max.f32 	%r103, %r97, 0fC3000000;
(EngineCore_DP0 pid=324118) 	max.f32 	%r104, %r95, 0fC3000000;
(EngineCore_DP0 pid=324118) 	min.f32 	%r105, %r104, 0f42FE0000;
(EngineCore_DP0 pid=324118) 	min.f32 	%r106, %r103, 0f42FE0000;
(EngineCore_DP0 pid=324118) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=324118) 	cvt.rzi.s32.f32 	%r107, %r106;
(EngineCore_DP0 pid=324118) 	cvt.rzi.s32.f32 	%r108, %r105;
(EngineCore_DP0 pid=324118) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=324118) 	shl.b32 	%r109, %r108, 8;
(EngineCore_DP0 pid=324118) 	shl.b32 	%r110, %r107, 16;
(EngineCore_DP0 pid=324118) 	and.b32 	%r111, %r110, 16711680;
(EngineCore_DP0 pid=324118) 	and.b32 	%r112, %r109, 65280;
(EngineCore_DP0 pid=324118) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=324118) 	or.b32 	%r113, %r112, %r93;
(EngineCore_DP0 pid=324118) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=324118) 	or.b32 	%r114, %r113, %r111;
(EngineCore_DP0 pid=324118) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=324118) 	shl.b32 	%r115, %r102, 24;
(EngineCore_DP0 pid=324118) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=324118) 	or.b32 	%r70, %r114, %r115;
(EngineCore_DP0 pid=324118) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=324118) 	mad.wide.s32 	%rd12, %r72, 4, %rd2;
(EngineCore_DP0 pid=324118) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=324118) 	// begin inline asm
(EngineCore_DP0 pid=324118) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r70 };
(EngineCore_DP0 pid=324118) 	// end inline asm
(EngineCore_DP0 pid=324118) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=324118) 	add.s32 	%r119, %r119, 1024;
(EngineCore_DP0 pid=324118) 	setp.lt.s32 	%p18, %r119, %r14;
(EngineCore_DP0 pid=324118) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=324118) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=324118) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=324118) 	ret;
(EngineCore_DP0 pid=324118) $L__tmp3:
(EngineCore_DP0 pid=324118) $L__func_end0:
(EngineCore_DP0 pid=324118)                                         // -- End function
(EngineCore_DP0 pid=324118) }
(EngineCore_DP0 pid=324118) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=324118) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=324118) 	.section	.debug_abbrev
(EngineCore_DP0 pid=324118) 	{
(EngineCore_DP0 pid=324118) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=324118) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=324118) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=324118) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=324118) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=324118) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=324118) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=324118) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=324118) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=324118) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=324118) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=324118) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=324118) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=324118) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=324118) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=324118) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=324118) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=324118) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=324118) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=324118) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=324118) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=324118) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=324118) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=324118) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=324118) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=324118) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=324118) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=324118) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=324118) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=324118) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=324118) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=324118) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=324118) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=324118) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=324118) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=324118) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=324118) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=324118) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=324118) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=324118) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=324118) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=324118) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=324118) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=324118) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=324118) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=324118) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=324118) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=324118) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=324118) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=324118) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=324118) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=324118) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=324118) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=324118) 	}
(EngineCore_DP0 pid=324118) 	.section	.debug_info
(EngineCore_DP0 pid=324118) 	{
(EngineCore_DP0 pid=324118) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=324118) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=324118) .b8 0
(EngineCore_DP0 pid=324118) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=324118) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=324118) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=324118) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=324118) .b8 114
(EngineCore_DP0 pid=324118) .b8 105
(EngineCore_DP0 pid=324118) .b8 116
(EngineCore_DP0 pid=324118) .b8 111
(EngineCore_DP0 pid=324118) .b8 110
(EngineCore_DP0 pid=324118) .b8 0
(EngineCore_DP0 pid=324118) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=324118) .b8 0
(EngineCore_DP0 pid=324118) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=324118) .b8 117
(EngineCore_DP0 pid=324118) .b8 97
(EngineCore_DP0 pid=324118) .b8 110
(EngineCore_DP0 pid=324118) .b8 116
(EngineCore_DP0 pid=324118) .b8 95
(EngineCore_DP0 pid=324118) .b8 115
(EngineCore_DP0 pid=324118) .b8 108
(EngineCore_DP0 pid=324118) .b8 105
(EngineCore_DP0 pid=324118) .b8 100
(EngineCore_DP0 pid=324118) .b8 101
(EngineCore_DP0 pid=324118) .b8 95
(EngineCore_DP0 pid=324118) .b8 116
(EngineCore_DP0 pid=324118) .b8 117
(EngineCore_DP0 pid=324118) .b8 110
(EngineCore_DP0 pid=324118) .b8 101
(EngineCore_DP0 pid=324118) .b8 100
(EngineCore_DP0 pid=324118) .b8 95
(EngineCore_DP0 pid=324118) .b8 76
(EngineCore_DP0 pid=324118) .b8 108
(EngineCore_DP0 pid=324118) .b8 97
(EngineCore_DP0 pid=324118) .b8 109
(EngineCore_DP0 pid=324118) .b8 97
(EngineCore_DP0 pid=324118) .b8 51
(EngineCore_DP0 pid=324118) .b8 46
(EngineCore_DP0 pid=324118) .b8 50
(EngineCore_DP0 pid=324118) .b8 45
(EngineCore_DP0 pid=324118) .b8 49
(EngineCore_DP0 pid=324118) .b8 66
(EngineCore_DP0 pid=324118) .b8 46
(EngineCore_DP0 pid=324118) .b8 112
(EngineCore_DP0 pid=324118) .b8 121
(EngineCore_DP0 pid=324118) .b8 0
(EngineCore_DP0 pid=324118) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=324118) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=324118) .b8 114
(EngineCore_DP0 pid=324118) .b8 111
(EngineCore_DP0 pid=324118) .b8 111
(EngineCore_DP0 pid=324118) .b8 116
(EngineCore_DP0 pid=324118) .b8 47
(EngineCore_DP0 pid=324118) .b8 118
(EngineCore_DP0 pid=324118) .b8 108
(EngineCore_DP0 pid=324118) .b8 108
(EngineCore_DP0 pid=324118) .b8 109
(EngineCore_DP0 pid=324118) .b8 98
(EngineCore_DP0 pid=324118) .b8 101
(EngineCore_DP0 pid=324118) .b8 110
(EngineCore_DP0 pid=324118) .b8 99
(EngineCore_DP0 pid=324118) .b8 104
(EngineCore_DP0 pid=324118) .b8 47
(EngineCore_DP0 pid=324118) .b8 115
(EngineCore_DP0 pid=324118) .b8 108
(EngineCore_DP0 pid=324118) .b8 105
(EngineCore_DP0 pid=324118) .b8 100
(EngineCore_DP0 pid=324118) .b8 101
(EngineCore_DP0 pid=324118) .b8 115
(EngineCore_DP0 pid=324118) .b8 112
(EngineCore_DP0 pid=324118) .b8 97
(EngineCore_DP0 pid=324118) .b8 114
(EngineCore_DP0 pid=324118) .b8 115
(EngineCore_DP0 pid=324118) .b8 101
(EngineCore_DP0 pid=324118) .b8 47
(EngineCore_DP0 pid=324118) .b8 99
(EngineCore_DP0 pid=324118) .b8 115
(EngineCore_DP0 pid=324118) .b8 114
(EngineCore_DP0 pid=324118) .b8 99
(EngineCore_DP0 pid=324118) .b8 47
(EngineCore_DP0 pid=324118) .b8 102
(EngineCore_DP0 pid=324118) .b8 117
(EngineCore_DP0 pid=324118) .b8 115
(EngineCore_DP0 pid=324118) .b8 101
(EngineCore_DP0 pid=324118) .b8 100
(EngineCore_DP0 pid=324118) .b8 95
(EngineCore_DP0 pid=324118) .b8 113
(EngineCore_DP0 pid=324118) .b8 117
(EngineCore_DP0 pid=324118) .b8 97
(EngineCore_DP0 pid=324118) .b8 110
(EngineCore_DP0 pid=324118) .b8 116
(EngineCore_DP0 pid=324118) .b8 95
(EngineCore_DP0 pid=324118) .b8 115
(EngineCore_DP0 pid=324118) .b8 108
(EngineCore_DP0 pid=324118) .b8 105
(EngineCore_DP0 pid=324118) .b8 100
(EngineCore_DP0 pid=324118) .b8 101
(EngineCore_DP0 pid=324118) .b8 95
(EngineCore_DP0 pid=324118) .b8 116
(EngineCore_DP0 pid=324118) .b8 114
(EngineCore_DP0 pid=324118) .b8 105
(EngineCore_DP0 pid=324118) .b8 116
(EngineCore_DP0 pid=324118) .b8 111
(EngineCore_DP0 pid=324118) .b8 110
(EngineCore_DP0 pid=324118) .b8 47
(EngineCore_DP0 pid=324118) .b8 98
(EngineCore_DP0 pid=324118) .b8 117
(EngineCore_DP0 pid=324118) .b8 105
(EngineCore_DP0 pid=324118) .b8 108
(EngineCore_DP0 pid=324118) .b8 100
(EngineCore_DP0 pid=324118) .b8 47
(EngineCore_DP0 pid=324118) .b8 71
(EngineCore_DP0 pid=324118) .b8 66
(EngineCore_DP0 pid=324118) .b8 49
(EngineCore_DP0 pid=324118) .b8 48
(EngineCore_DP0 pid=324118) .b8 95
(EngineCore_DP0 pid=324118) .b8 99
(EngineCore_DP0 pid=324118) .b8 99
(EngineCore_DP0 pid=324118) .b8 49
(EngineCore_DP0 pid=324118) .b8 50
(EngineCore_DP0 pid=324118) .b8 49
(EngineCore_DP0 pid=324118) .b8 95
(EngineCore_DP0 pid=324118) .b8 112
(EngineCore_DP0 pid=324118) .b8 121
(EngineCore_DP0 pid=324118) .b8 51
(EngineCore_DP0 pid=324118) .b8 49
(EngineCore_DP0 pid=324118) .b8 50
(EngineCore_DP0 pid=324118) .b8 95
(EngineCore_DP0 pid=324118) .b8 99
(EngineCore_DP0 pid=324118) .b8 117
(EngineCore_DP0 pid=324118) .b8 49
(EngineCore_DP0 pid=324118) .b8 50
(EngineCore_DP0 pid=324118) .b8 57
(EngineCore_DP0 pid=324118) .b8 95
(EngineCore_DP0 pid=324118) .b8 97
(EngineCore_DP0 pid=324118) .b8 97
(EngineCore_DP0 pid=324118) .b8 114
(EngineCore_DP0 pid=324118) .b8 99
(EngineCore_DP0 pid=324118) .b8 104
(EngineCore_DP0 pid=324118) .b8 54
(EngineCore_DP0 pid=324118) .b8 52
(EngineCore_DP0 pid=324118) .b8 0
(EngineCore_DP0 pid=324118) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=324118) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=324118) .b8 113
(EngineCore_DP0 pid=324118) .b8 117
(EngineCore_DP0 pid=324118) .b8 97
(EngineCore_DP0 pid=324118) .b8 110
(EngineCore_DP0 pid=324118) .b8 116
(EngineCore_DP0 pid=324118) .b8 95
(EngineCore_DP0 pid=324118) .b8 115
(EngineCore_DP0 pid=324118) .b8 108
(EngineCore_DP0 pid=324118) .b8 105
(EngineCore_DP0 pid=324118) .b8 100
(EngineCore_DP0 pid=324118) .b8 101
(EngineCore_DP0 pid=324118) .b8 95
(EngineCore_DP0 pid=324118) .b8 105
(EngineCore_DP0 pid=324118) .b8 110
(EngineCore_DP0 pid=324118) .b8 116
(EngineCore_DP0 pid=324118) .b8 56
(EngineCore_DP0 pid=324118) .b8 95
(EngineCore_DP0 pid=324118) .b8 107
(EngineCore_DP0 pid=324118) .b8 101
(EngineCore_DP0 pid=324118) .b8 114
(EngineCore_DP0 pid=324118) .b8 110
(EngineCore_DP0 pid=324118) .b8 101
(EngineCore_DP0 pid=324118) .b8 108
(EngineCore_DP0 pid=324118) .b8 0
(EngineCore_DP0 pid=324118) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=324118) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=324118) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=324118) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=324118) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=324118) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=324118) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=324118) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=324118) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=324118) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=324118) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=324118) .b8 1
(EngineCore_DP0 pid=324118) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=324118) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=324118) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=324118) 	}
(EngineCore_DP0 pid=324118) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=324118) 
(EngineCore_DP0 pid=324118) ================================================================
(EngineCore_DP0 pid=324118) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=324118) 
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpoen7qy8m.ptx', '-o', '/tmp/tmpoen7qy8m.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866] 
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866] 
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866] 
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpoen7qy8m.ptx -o /tmp/tmpoen7qy8m.ptx.o
(EngineCore_DP0 pid=324118) ERROR 01-25 19:06:24 [core.py:866] 

STDERR:
[2026-01-25 19:06:07] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:06:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:06:07] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:06:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:06:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:06:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:06:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:06:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:06:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:06:10] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:06:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:06:11] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:06:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:06:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:06:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:06:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:06:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:06:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=324118) [2026-01-25 19:06:11] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=324118) [2026-01-25 19:06:11] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=324118) [2026-01-25 19:06:11] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=324118) [2026-01-25 19:06:11] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=324118) [2026-01-25 19:06:11] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=324118) [2026-01-25 19:06:11] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=324118) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=324118) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.90s/it]
(EngineCore_DP0 pid=324118) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.90s/it]
(EngineCore_DP0 pid=324118) 
(EngineCore_DP0 pid=324118) [2026-01-25 19:06:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=324118) [2026-01-25 19:06:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=324118) [2026-01-25 19:06:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=324118) [2026-01-25 19:06:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=324118) [2026-01-25 19:06:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=324118) [2026-01-25 19:06:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=324118) [2026-01-25 19:06:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=324118) [2026-01-25 19:06:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=324118) Process EngineCore_DP0:
(EngineCore_DP0 pid=324118) Traceback (most recent call last):
(EngineCore_DP0 pid=324118)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=324118)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=324118)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=324118)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=324118) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpoen7qy8m.ptx', '-o', '/tmp/tmpoen7qy8m.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=324118) 
(EngineCore_DP0 pid=324118) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=324118) 
(EngineCore_DP0 pid=324118) Traceback (most recent call last):
(EngineCore_DP0 pid=324118)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=324118)     self.run()
(EngineCore_DP0 pid=324118)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=324118)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=324118)     raise e
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=324118)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=324118)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=324118)     super().__init__(
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=324118)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=324118)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=324118)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=324118)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=324118)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=324118)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=324118)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=324118)     return func(*args, **kwargs)
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=324118)     return func(*args, **kwargs)
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=324118)     self.model_runner.profile_run()
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=324118)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=324118)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=324118)     return func(*args, **kwargs)
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=324118)     outputs = self.model(
(EngineCore_DP0 pid=324118)               ^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=324118)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=324118)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=324118)     model_output = self.model(
(EngineCore_DP0 pid=324118)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=324118)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=324118)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=324118)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=324118)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=324118)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=324118)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=324118)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=324118)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=324118)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=324118)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=324118)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=324118)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=324118)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=324118)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=324118)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=324118)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=324118)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=324118)     return self._linear_fn(
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=324118)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=324118)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=324118)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=324118)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=324118)     return fn(input, L)
(EngineCore_DP0 pid=324118)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=324118)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=324118)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=324118)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=324118)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=324118)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=324118)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=324118)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=324118)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=324118)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=324118)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=324118)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=324118)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324118)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=324118)     raise PTXASError(error)
(EngineCore_DP0 pid=324118) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=324118) `ptxas` stderr:
(EngineCore_DP0 pid=324118) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=324118) 
(EngineCore_DP0 pid=324118) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpoen7qy8m.ptx -o /tmp/tmpoen7qy8m.ptx.o
(EngineCore_DP0 pid=324118) 
[rank0]:[W125 19:06:24.928693847 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 19:06:26
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:06:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:06:30 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=324604) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=324604) 
(EngineCore_DP0 pid=324604) 
(EngineCore_DP0 pid=324604) ================================================================
(EngineCore_DP0 pid=324604) Internal Triton PTX codegen error
(EngineCore_DP0 pid=324604) `ptxas` stderr:
(EngineCore_DP0 pid=324604) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=324604) 
(EngineCore_DP0 pid=324604) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmplf4yygv1.ptx -o /tmp/tmplf4yygv1.ptx.o
(EngineCore_DP0 pid=324604) 
(EngineCore_DP0 pid=324604) 
(EngineCore_DP0 pid=324604) //
(EngineCore_DP0 pid=324604) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=324604) //
(EngineCore_DP0 pid=324604) 
(EngineCore_DP0 pid=324604) .version 8.7
(EngineCore_DP0 pid=324604) .target sm_121a
(EngineCore_DP0 pid=324604) .address_size 64
(EngineCore_DP0 pid=324604) 
(EngineCore_DP0 pid=324604) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=324604) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=324604)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=324604) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=324604) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=324604) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=324604) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=324604) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=324604) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=324604) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=324604) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=324604) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=324604) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=324604) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=324604) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=324604) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=324604) )
(EngineCore_DP0 pid=324604) .reqntid 512
(EngineCore_DP0 pid=324604) {
(EngineCore_DP0 pid=324604) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=324604) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=324604) 	.reg .b32 	%r<132>;
(EngineCore_DP0 pid=324604) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=324604) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=324604) $L__func_begin0:
(EngineCore_DP0 pid=324604) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=324604) 
(EngineCore_DP0 pid=324604) // %bb.0:
(EngineCore_DP0 pid=324604) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=324604) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=324604) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=324604) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=324604) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=324604) $L__tmp0:
(EngineCore_DP0 pid=324604) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=324604) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=324604) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=324604) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=324604) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=324604) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=324604) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=324604) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=324604) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=324604) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=324604) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=324604) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=324604) 	mov.b32 	%r130, 0f2B8CBCCC;
(EngineCore_DP0 pid=324604) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=324604) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=324604) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=324604) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=324604) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=324604) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=324604) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=324604) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=324604) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=324604) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=324604) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=324604) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=324604) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=324604) 	mov.b32 	%r128, 0f00000000;
(EngineCore_DP0 pid=324604) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=324604) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=324604) 	mov.b32 	%r129, %r40;
(EngineCore_DP0 pid=324604) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=324604) 	.loc	1 299 19                        // quant_slide_tuned_Llama3.2-1B.py:299:19
(EngineCore_DP0 pid=324604) 	add.s32 	%r58, %r4, %r129;
(EngineCore_DP0 pid=324604) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=324604) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=324604) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=324604) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=324604) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=324604) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=324604) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=324604) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=324604) 	// begin inline asm
(EngineCore_DP0 pid=324604) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=324604) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=324604) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=324604) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=324604) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=324604) 	// end inline asm
(EngineCore_DP0 pid=324604) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=324604) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=324604) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=324604) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=324604) 	// begin inline asm
(EngineCore_DP0 pid=324604) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=324604) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=324604) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=324604) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=324604) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=324604) 	// end inline asm
(EngineCore_DP0 pid=324604) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=324604) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=324604) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=324604) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=324604) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=324604) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=324604) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=324604) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=324604) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=324604) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=324604) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=324604) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=324604) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=324604) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=324604) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=324604) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=324604) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=324604) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=324604) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=324604) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=324604) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=324604) $L__tmp1:
(EngineCore_DP0 pid=324604) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	bar.sync 	0;
(EngineCore_DP0 pid=324604) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=324604) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=324604) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=324604) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=324604) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=324604) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=324604) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=324604) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=324604) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=324604) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=324604) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=324604) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=324604) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=324604) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=324604) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=324604) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=324604) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=324604) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=324604) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=324604) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=324604) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=324604) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=324604) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=324604) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=324604) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=324604) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=324604) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	// begin inline asm
(EngineCore_DP0 pid=324604) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=324604) 	// end inline asm
(EngineCore_DP0 pid=324604) 	bar.sync 	0;
(EngineCore_DP0 pid=324604) 	// begin inline asm
(EngineCore_DP0 pid=324604) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=324604) 	// end inline asm
(EngineCore_DP0 pid=324604) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=324604) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=324604) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=324604) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=324604) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=324604) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=324604) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=324604) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=324604) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=324604) 	// begin inline asm
(EngineCore_DP0 pid=324604) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=324604) 	// end inline asm
(EngineCore_DP0 pid=324604) 	bar.sync 	0;
(EngineCore_DP0 pid=324604) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=324604) $L__tmp2:
(EngineCore_DP0 pid=324604) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=324604) 	max.f32 	%r128, %r128, %r77;
(EngineCore_DP0 pid=324604) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=324604) 	add.s32 	%r129, %r129, 8192;
(EngineCore_DP0 pid=324604) 	setp.lt.s32 	%p7, %r129, %r19;
(EngineCore_DP0 pid=324604) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=324604) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=324604) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=324604) 	max.f32 	%r130, %r128, 0f2B8CBCCC;
(EngineCore_DP0 pid=324604) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=324604) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=324604) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=324604) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=324604) 	div.full.f32 	%r80, %r130, %r79;
(EngineCore_DP0 pid=324604) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=324604) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=324604) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=324604) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=324604) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=324604) 	// begin inline asm
(EngineCore_DP0 pid=324604) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=324604) 	// end inline asm
(EngineCore_DP0 pid=324604) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=324604) 	shl.b32 	%r15, %r20, 2;
(EngineCore_DP0 pid=324604) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=324604) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=324604) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=324604) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=324604) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=324604) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=324604) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=324604) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=324604) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=324604) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=324604) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=324604) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=324604) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=324604) 	div.full.f32 	%r14, %r79, %r130;
(EngineCore_DP0 pid=324604) 	mov.b32 	%r131, 0;
(EngineCore_DP0 pid=324604) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=324604)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=324604) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=324604) 	add.s32 	%r84, %r3, %r131;
(EngineCore_DP0 pid=324604) 	setp.lt.s32 	%p14, %r84, %r15;
(EngineCore_DP0 pid=324604) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=324604) 	shr.s32 	%r85, %r84, 31;
(EngineCore_DP0 pid=324604) 	shr.u32 	%r86, %r85, 30;
(EngineCore_DP0 pid=324604) 	add.s32 	%r87, %r84, %r86;
(EngineCore_DP0 pid=324604) 	shr.s32 	%r88, %r87, 2;
(EngineCore_DP0 pid=324604) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=324604) 	and.b32 	%r89, %r87, 2147483644;
(EngineCore_DP0 pid=324604) 	sub.s32 	%r90, %r84, %r89;
(EngineCore_DP0 pid=324604) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=324604) 	shl.b32 	%r91, %r90, 1;
(EngineCore_DP0 pid=324604) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=324604) 	mad.lo.s32 	%r92, %r88, 10, %r91;
(EngineCore_DP0 pid=324604) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=324604) 	setp.lt.s32 	%p15, %r92, %r18;
(EngineCore_DP0 pid=324604) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=324604) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=324604) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=324604) 	mad.wide.s32 	%rd9, %r92, 2, %rd1;
(EngineCore_DP0 pid=324604) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=324604) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=324604) 	// begin inline asm
(EngineCore_DP0 pid=324604) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=324604) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=324604) 	// end inline asm
(EngineCore_DP0 pid=324604) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=324604) 	cvt.f32.bf16 	%r93, %rs48;
(EngineCore_DP0 pid=324604) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=324604) 	or.b32 	%r94, %r92, 1;
(EngineCore_DP0 pid=324604) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=324604) 	setp.lt.s32 	%p16, %r94, %r18;
(EngineCore_DP0 pid=324604) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=324604) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=324604) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=324604) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=324604) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=324604) 	// begin inline asm
(EngineCore_DP0 pid=324604) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=324604) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=324604) 	// end inline asm
(EngineCore_DP0 pid=324604) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=324604) 	cvt.f32.bf16 	%r95, %rs50;
(EngineCore_DP0 pid=324604) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=324604) 	add.s32 	%r96, %r92, 2;
(EngineCore_DP0 pid=324604) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=324604) 	setp.lt.s32 	%p17, %r96, %r18;
(EngineCore_DP0 pid=324604) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=324604) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=324604) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=324604) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=324604) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=324604) 	// begin inline asm
(EngineCore_DP0 pid=324604) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=324604) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=324604) 	// end inline asm
(EngineCore_DP0 pid=324604) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=324604) 	cvt.f32.bf16 	%r97, %rs52;
(EngineCore_DP0 pid=324604) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=324604) 	add.s32 	%r98, %r92, 3;
(EngineCore_DP0 pid=324604) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=324604) 	setp.lt.s32 	%p18, %r98, %r18;
(EngineCore_DP0 pid=324604) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=324604) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=324604) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=324604) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=324604) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=324604) 	// begin inline asm
(EngineCore_DP0 pid=324604) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=324604) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=324604) 	// end inline asm
(EngineCore_DP0 pid=324604) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=324604) 	cvt.f32.bf16 	%r99, %rs54;
(EngineCore_DP0 pid=324604) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=324604) 	mul.f32 	%r100, %r14, %r93;
(EngineCore_DP0 pid=324604) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=324604) 	cvt.rni.f32.f32 	%r101, %r100;
(EngineCore_DP0 pid=324604) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=324604) 	max.f32 	%r102, %r101, 0fC3000000;
(EngineCore_DP0 pid=324604) 	min.f32 	%r103, %r102, 0f42FE0000;
(EngineCore_DP0 pid=324604) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=324604) 	cvt.rzi.s32.f32 	%r104, %r103;
(EngineCore_DP0 pid=324604) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=324604) 	and.b32 	%r105, %r104, 255;
(EngineCore_DP0 pid=324604) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=324604) 	mul.f32 	%r106, %r14, %r95;
(EngineCore_DP0 pid=324604) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=324604) 	cvt.rni.f32.f32 	%r107, %r106;
(EngineCore_DP0 pid=324604) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=324604) 	mul.f32 	%r108, %r14, %r97;
(EngineCore_DP0 pid=324604) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=324604) 	cvt.rni.f32.f32 	%r109, %r108;
(EngineCore_DP0 pid=324604) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=324604) 	mul.f32 	%r110, %r14, %r99;
(EngineCore_DP0 pid=324604) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=324604) 	cvt.rni.f32.f32 	%r111, %r110;
(EngineCore_DP0 pid=324604) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=324604) 	max.f32 	%r112, %r111, 0fC3000000;
(EngineCore_DP0 pid=324604) 	min.f32 	%r113, %r112, 0f42FE0000;
(EngineCore_DP0 pid=324604) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=324604) 	cvt.rzi.s32.f32 	%r114, %r113;
(EngineCore_DP0 pid=324604) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=324604) 	max.f32 	%r115, %r109, 0fC3000000;
(EngineCore_DP0 pid=324604) 	max.f32 	%r116, %r107, 0fC3000000;
(EngineCore_DP0 pid=324604) 	min.f32 	%r117, %r116, 0f42FE0000;
(EngineCore_DP0 pid=324604) 	min.f32 	%r118, %r115, 0f42FE0000;
(EngineCore_DP0 pid=324604) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=324604) 	cvt.rzi.s32.f32 	%r119, %r118;
(EngineCore_DP0 pid=324604) 	cvt.rzi.s32.f32 	%r120, %r117;
(EngineCore_DP0 pid=324604) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=324604) 	shl.b32 	%r121, %r120, 8;
(EngineCore_DP0 pid=324604) 	shl.b32 	%r122, %r119, 16;
(EngineCore_DP0 pid=324604) 	and.b32 	%r123, %r122, 16711680;
(EngineCore_DP0 pid=324604) 	and.b32 	%r124, %r121, 65280;
(EngineCore_DP0 pid=324604) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=324604) 	or.b32 	%r125, %r124, %r105;
(EngineCore_DP0 pid=324604) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=324604) 	or.b32 	%r126, %r125, %r123;
(EngineCore_DP0 pid=324604) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=324604) 	shl.b32 	%r127, %r114, 24;
(EngineCore_DP0 pid=324604) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=324604) 	or.b32 	%r82, %r126, %r127;
(EngineCore_DP0 pid=324604) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=324604) 	mad.wide.s32 	%rd13, %r84, 4, %rd2;
(EngineCore_DP0 pid=324604) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=324604) 	// begin inline asm
(EngineCore_DP0 pid=324604) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r82 };
(EngineCore_DP0 pid=324604) 	// end inline asm
(EngineCore_DP0 pid=324604) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=324604) 	add.s32 	%r131, %r131, 512;
(EngineCore_DP0 pid=324604) 	setp.lt.s32 	%p19, %r131, %r15;
(EngineCore_DP0 pid=324604) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=324604) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=324604) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=324604) 	ret;
(EngineCore_DP0 pid=324604) $L__tmp3:
(EngineCore_DP0 pid=324604) $L__func_end0:
(EngineCore_DP0 pid=324604)                                         // -- End function
(EngineCore_DP0 pid=324604) }
(EngineCore_DP0 pid=324604) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=324604) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=324604) 	.section	.debug_abbrev
(EngineCore_DP0 pid=324604) 	{
(EngineCore_DP0 pid=324604) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=324604) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=324604) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=324604) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=324604) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=324604) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=324604) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=324604) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=324604) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=324604) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=324604) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=324604) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=324604) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=324604) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=324604) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=324604) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=324604) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=324604) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=324604) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=324604) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=324604) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=324604) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=324604) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=324604) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=324604) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=324604) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=324604) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=324604) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=324604) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=324604) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=324604) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=324604) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=324604) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=324604) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=324604) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=324604) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=324604) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=324604) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=324604) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=324604) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=324604) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=324604) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=324604) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=324604) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=324604) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=324604) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=324604) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=324604) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=324604) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=324604) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=324604) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=324604) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=324604) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=324604) 	}
(EngineCore_DP0 pid=324604) 	.section	.debug_info
(EngineCore_DP0 pid=324604) 	{
(EngineCore_DP0 pid=324604) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=324604) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=324604) .b8 0
(EngineCore_DP0 pid=324604) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=324604) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=324604) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=324604) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=324604) .b8 114
(EngineCore_DP0 pid=324604) .b8 105
(EngineCore_DP0 pid=324604) .b8 116
(EngineCore_DP0 pid=324604) .b8 111
(EngineCore_DP0 pid=324604) .b8 110
(EngineCore_DP0 pid=324604) .b8 0
(EngineCore_DP0 pid=324604) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=324604) .b8 0
(EngineCore_DP0 pid=324604) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=324604) .b8 117
(EngineCore_DP0 pid=324604) .b8 97
(EngineCore_DP0 pid=324604) .b8 110
(EngineCore_DP0 pid=324604) .b8 116
(EngineCore_DP0 pid=324604) .b8 95
(EngineCore_DP0 pid=324604) .b8 115
(EngineCore_DP0 pid=324604) .b8 108
(EngineCore_DP0 pid=324604) .b8 105
(EngineCore_DP0 pid=324604) .b8 100
(EngineCore_DP0 pid=324604) .b8 101
(EngineCore_DP0 pid=324604) .b8 95
(EngineCore_DP0 pid=324604) .b8 116
(EngineCore_DP0 pid=324604) .b8 117
(EngineCore_DP0 pid=324604) .b8 110
(EngineCore_DP0 pid=324604) .b8 101
(EngineCore_DP0 pid=324604) .b8 100
(EngineCore_DP0 pid=324604) .b8 95
(EngineCore_DP0 pid=324604) .b8 76
(EngineCore_DP0 pid=324604) .b8 108
(EngineCore_DP0 pid=324604) .b8 97
(EngineCore_DP0 pid=324604) .b8 109
(EngineCore_DP0 pid=324604) .b8 97
(EngineCore_DP0 pid=324604) .b8 51
(EngineCore_DP0 pid=324604) .b8 46
(EngineCore_DP0 pid=324604) .b8 50
(EngineCore_DP0 pid=324604) .b8 45
(EngineCore_DP0 pid=324604) .b8 49
(EngineCore_DP0 pid=324604) .b8 66
(EngineCore_DP0 pid=324604) .b8 46
(EngineCore_DP0 pid=324604) .b8 112
(EngineCore_DP0 pid=324604) .b8 121
(EngineCore_DP0 pid=324604) .b8 0
(EngineCore_DP0 pid=324604) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=324604) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=324604) .b8 114
(EngineCore_DP0 pid=324604) .b8 111
(EngineCore_DP0 pid=324604) .b8 111
(EngineCore_DP0 pid=324604) .b8 116
(EngineCore_DP0 pid=324604) .b8 47
(EngineCore_DP0 pid=324604) .b8 118
(EngineCore_DP0 pid=324604) .b8 108
(EngineCore_DP0 pid=324604) .b8 108
(EngineCore_DP0 pid=324604) .b8 109
(EngineCore_DP0 pid=324604) .b8 98
(EngineCore_DP0 pid=324604) .b8 101
(EngineCore_DP0 pid=324604) .b8 110
(EngineCore_DP0 pid=324604) .b8 99
(EngineCore_DP0 pid=324604) .b8 104
(EngineCore_DP0 pid=324604) .b8 47
(EngineCore_DP0 pid=324604) .b8 115
(EngineCore_DP0 pid=324604) .b8 108
(EngineCore_DP0 pid=324604) .b8 105
(EngineCore_DP0 pid=324604) .b8 100
(EngineCore_DP0 pid=324604) .b8 101
(EngineCore_DP0 pid=324604) .b8 115
(EngineCore_DP0 pid=324604) .b8 112
(EngineCore_DP0 pid=324604) .b8 97
(EngineCore_DP0 pid=324604) .b8 114
(EngineCore_DP0 pid=324604) .b8 115
(EngineCore_DP0 pid=324604) .b8 101
(EngineCore_DP0 pid=324604) .b8 47
(EngineCore_DP0 pid=324604) .b8 99
(EngineCore_DP0 pid=324604) .b8 115
(EngineCore_DP0 pid=324604) .b8 114
(EngineCore_DP0 pid=324604) .b8 99
(EngineCore_DP0 pid=324604) .b8 47
(EngineCore_DP0 pid=324604) .b8 102
(EngineCore_DP0 pid=324604) .b8 117
(EngineCore_DP0 pid=324604) .b8 115
(EngineCore_DP0 pid=324604) .b8 101
(EngineCore_DP0 pid=324604) .b8 100
(EngineCore_DP0 pid=324604) .b8 95
(EngineCore_DP0 pid=324604) .b8 113
(EngineCore_DP0 pid=324604) .b8 117
(EngineCore_DP0 pid=324604) .b8 97
(EngineCore_DP0 pid=324604) .b8 110
(EngineCore_DP0 pid=324604) .b8 116
(EngineCore_DP0 pid=324604) .b8 95
(EngineCore_DP0 pid=324604) .b8 115
(EngineCore_DP0 pid=324604) .b8 108
(EngineCore_DP0 pid=324604) .b8 105
(EngineCore_DP0 pid=324604) .b8 100
(EngineCore_DP0 pid=324604) .b8 101
(EngineCore_DP0 pid=324604) .b8 95
(EngineCore_DP0 pid=324604) .b8 116
(EngineCore_DP0 pid=324604) .b8 114
(EngineCore_DP0 pid=324604) .b8 105
(EngineCore_DP0 pid=324604) .b8 116
(EngineCore_DP0 pid=324604) .b8 111
(EngineCore_DP0 pid=324604) .b8 110
(EngineCore_DP0 pid=324604) .b8 47
(EngineCore_DP0 pid=324604) .b8 98
(EngineCore_DP0 pid=324604) .b8 117
(EngineCore_DP0 pid=324604) .b8 105
(EngineCore_DP0 pid=324604) .b8 108
(EngineCore_DP0 pid=324604) .b8 100
(EngineCore_DP0 pid=324604) .b8 47
(EngineCore_DP0 pid=324604) .b8 71
(EngineCore_DP0 pid=324604) .b8 66
(EngineCore_DP0 pid=324604) .b8 49
(EngineCore_DP0 pid=324604) .b8 48
(EngineCore_DP0 pid=324604) .b8 95
(EngineCore_DP0 pid=324604) .b8 99
(EngineCore_DP0 pid=324604) .b8 99
(EngineCore_DP0 pid=324604) .b8 49
(EngineCore_DP0 pid=324604) .b8 50
(EngineCore_DP0 pid=324604) .b8 49
(EngineCore_DP0 pid=324604) .b8 95
(EngineCore_DP0 pid=324604) .b8 112
(EngineCore_DP0 pid=324604) .b8 121
(EngineCore_DP0 pid=324604) .b8 51
(EngineCore_DP0 pid=324604) .b8 49
(EngineCore_DP0 pid=324604) .b8 50
(EngineCore_DP0 pid=324604) .b8 95
(EngineCore_DP0 pid=324604) .b8 99
(EngineCore_DP0 pid=324604) .b8 117
(EngineCore_DP0 pid=324604) .b8 49
(EngineCore_DP0 pid=324604) .b8 50
(EngineCore_DP0 pid=324604) .b8 57
(EngineCore_DP0 pid=324604) .b8 95
(EngineCore_DP0 pid=324604) .b8 97
(EngineCore_DP0 pid=324604) .b8 97
(EngineCore_DP0 pid=324604) .b8 114
(EngineCore_DP0 pid=324604) .b8 99
(EngineCore_DP0 pid=324604) .b8 104
(EngineCore_DP0 pid=324604) .b8 54
(EngineCore_DP0 pid=324604) .b8 52
(EngineCore_DP0 pid=324604) .b8 0
(EngineCore_DP0 pid=324604) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=324604) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=324604) .b8 113
(EngineCore_DP0 pid=324604) .b8 117
(EngineCore_DP0 pid=324604) .b8 97
(EngineCore_DP0 pid=324604) .b8 110
(EngineCore_DP0 pid=324604) .b8 116
(EngineCore_DP0 pid=324604) .b8 95
(EngineCore_DP0 pid=324604) .b8 115
(EngineCore_DP0 pid=324604) .b8 108
(EngineCore_DP0 pid=324604) .b8 105
(EngineCore_DP0 pid=324604) .b8 100
(EngineCore_DP0 pid=324604) .b8 101
(EngineCore_DP0 pid=324604) .b8 95
(EngineCore_DP0 pid=324604) .b8 105
(EngineCore_DP0 pid=324604) .b8 110
(EngineCore_DP0 pid=324604) .b8 116
(EngineCore_DP0 pid=324604) .b8 56
(EngineCore_DP0 pid=324604) .b8 95
(EngineCore_DP0 pid=324604) .b8 107
(EngineCore_DP0 pid=324604) .b8 101
(EngineCore_DP0 pid=324604) .b8 114
(EngineCore_DP0 pid=324604) .b8 110
(EngineCore_DP0 pid=324604) .b8 101
(EngineCore_DP0 pid=324604) .b8 108
(EngineCore_DP0 pid=324604) .b8 0
(EngineCore_DP0 pid=324604) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=324604) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=324604) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=324604) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=324604) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=324604) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=324604) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=324604) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=324604) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=324604) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=324604) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=324604) .b8 1
(EngineCore_DP0 pid=324604) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=324604) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=324604) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=324604) 	}
(EngineCore_DP0 pid=324604) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=324604) 
(EngineCore_DP0 pid=324604) ================================================================
(EngineCore_DP0 pid=324604) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=324604) 
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmplf4yygv1.ptx', '-o', '/tmp/tmplf4yygv1.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866] 
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866] 
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866] 
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmplf4yygv1.ptx -o /tmp/tmplf4yygv1.ptx.o
(EngineCore_DP0 pid=324604) ERROR 01-25 19:06:46 [core.py:866] 

STDERR:
[2026-01-25 19:06:30] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:06:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:06:30] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:06:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:06:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:06:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:06:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:06:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:06:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:06:33] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:06:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:06:33] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:06:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:06:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:06:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:06:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:06:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:06:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=324604) [2026-01-25 19:06:34] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=324604) [2026-01-25 19:06:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=324604) [2026-01-25 19:06:34] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=324604) [2026-01-25 19:06:34] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=324604) [2026-01-25 19:06:34] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=324604) [2026-01-25 19:06:34] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=324604) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=324604) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.84s/it]
(EngineCore_DP0 pid=324604) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.84s/it]
(EngineCore_DP0 pid=324604) 
(EngineCore_DP0 pid=324604) [2026-01-25 19:06:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=324604) [2026-01-25 19:06:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=324604) [2026-01-25 19:06:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=324604) [2026-01-25 19:06:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=324604) [2026-01-25 19:06:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=324604) [2026-01-25 19:06:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=324604) [2026-01-25 19:06:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=324604) [2026-01-25 19:06:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=324604) Process EngineCore_DP0:
(EngineCore_DP0 pid=324604) Traceback (most recent call last):
(EngineCore_DP0 pid=324604)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=324604)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=324604)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=324604)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=324604) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmplf4yygv1.ptx', '-o', '/tmp/tmplf4yygv1.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=324604) 
(EngineCore_DP0 pid=324604) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=324604) 
(EngineCore_DP0 pid=324604) Traceback (most recent call last):
(EngineCore_DP0 pid=324604)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=324604)     self.run()
(EngineCore_DP0 pid=324604)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=324604)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=324604)     raise e
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=324604)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=324604)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=324604)     super().__init__(
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=324604)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=324604)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=324604)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=324604)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=324604)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=324604)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=324604)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=324604)     return func(*args, **kwargs)
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=324604)     return func(*args, **kwargs)
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=324604)     self.model_runner.profile_run()
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=324604)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=324604)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=324604)     return func(*args, **kwargs)
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=324604)     outputs = self.model(
(EngineCore_DP0 pid=324604)               ^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=324604)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=324604)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=324604)     model_output = self.model(
(EngineCore_DP0 pid=324604)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=324604)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=324604)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=324604)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=324604)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=324604)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=324604)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=324604)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=324604)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=324604)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=324604)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=324604)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=324604)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=324604)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=324604)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=324604)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=324604)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=324604)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=324604)     return self._linear_fn(
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=324604)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=324604)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=324604)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=324604)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=324604)     return fn(input, L)
(EngineCore_DP0 pid=324604)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=324604)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=324604)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=324604)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=324604)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=324604)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=324604)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=324604)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=324604)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=324604)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=324604)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=324604)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=324604)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=324604)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=324604)     raise PTXASError(error)
(EngineCore_DP0 pid=324604) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=324604) `ptxas` stderr:
(EngineCore_DP0 pid=324604) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=324604) 
(EngineCore_DP0 pid=324604) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmplf4yygv1.ptx -o /tmp/tmplf4yygv1.ptx.o
(EngineCore_DP0 pid=324604) 
[rank0]:[W125 19:06:47.456911100 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 19:06:48
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:06:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:06:53 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=325118) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=325118) 
(EngineCore_DP0 pid=325118) 
(EngineCore_DP0 pid=325118) ================================================================
(EngineCore_DP0 pid=325118) Internal Triton PTX codegen error
(EngineCore_DP0 pid=325118) `ptxas` stderr:
(EngineCore_DP0 pid=325118) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=325118) 
(EngineCore_DP0 pid=325118) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpjcarjz1v.ptx -o /tmp/tmpjcarjz1v.ptx.o
(EngineCore_DP0 pid=325118) 
(EngineCore_DP0 pid=325118) 
(EngineCore_DP0 pid=325118) //
(EngineCore_DP0 pid=325118) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=325118) //
(EngineCore_DP0 pid=325118) 
(EngineCore_DP0 pid=325118) .version 8.7
(EngineCore_DP0 pid=325118) .target sm_121a
(EngineCore_DP0 pid=325118) .address_size 64
(EngineCore_DP0 pid=325118) 
(EngineCore_DP0 pid=325118) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=325118) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=325118)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=325118) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=325118) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=325118) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=325118) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=325118) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=325118) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=325118) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=325118) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=325118) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=325118) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=325118) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=325118) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=325118) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=325118) )
(EngineCore_DP0 pid=325118) .reqntid 512
(EngineCore_DP0 pid=325118) {
(EngineCore_DP0 pid=325118) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=325118) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=325118) 	.reg .b32 	%r<132>;
(EngineCore_DP0 pid=325118) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=325118) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=325118) $L__func_begin0:
(EngineCore_DP0 pid=325118) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=325118) 
(EngineCore_DP0 pid=325118) // %bb.0:
(EngineCore_DP0 pid=325118) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=325118) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=325118) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=325118) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=325118) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=325118) $L__tmp0:
(EngineCore_DP0 pid=325118) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=325118) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=325118) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=325118) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=325118) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=325118) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=325118) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=325118) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=325118) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=325118) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=325118) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=325118) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=325118) 	mov.b32 	%r130, 0f2B8CBCCC;
(EngineCore_DP0 pid=325118) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=325118) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=325118) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=325118) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=325118) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=325118) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=325118) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=325118) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=325118) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=325118) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=325118) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=325118) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=325118) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=325118) 	mov.b32 	%r128, 0f00000000;
(EngineCore_DP0 pid=325118) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=325118) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=325118) 	mov.b32 	%r129, %r40;
(EngineCore_DP0 pid=325118) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=325118) 	.loc	1 299 19                        // quant_slide_tuned_Llama3.2-1B.py:299:19
(EngineCore_DP0 pid=325118) 	add.s32 	%r58, %r4, %r129;
(EngineCore_DP0 pid=325118) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=325118) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=325118) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=325118) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=325118) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=325118) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=325118) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=325118) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=325118) 	// begin inline asm
(EngineCore_DP0 pid=325118) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=325118) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=325118) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=325118) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=325118) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=325118) 	// end inline asm
(EngineCore_DP0 pid=325118) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=325118) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=325118) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=325118) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=325118) 	// begin inline asm
(EngineCore_DP0 pid=325118) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=325118) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=325118) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=325118) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=325118) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=325118) 	// end inline asm
(EngineCore_DP0 pid=325118) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=325118) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=325118) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=325118) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=325118) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=325118) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=325118) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=325118) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=325118) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=325118) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=325118) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=325118) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=325118) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=325118) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=325118) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=325118) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=325118) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=325118) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=325118) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=325118) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=325118) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=325118) $L__tmp1:
(EngineCore_DP0 pid=325118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	bar.sync 	0;
(EngineCore_DP0 pid=325118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=325118) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=325118) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=325118) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=325118) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=325118) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=325118) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=325118) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=325118) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=325118) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=325118) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=325118) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=325118) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=325118) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=325118) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=325118) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=325118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=325118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=325118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=325118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=325118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=325118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=325118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=325118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=325118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=325118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=325118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	// begin inline asm
(EngineCore_DP0 pid=325118) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=325118) 	// end inline asm
(EngineCore_DP0 pid=325118) 	bar.sync 	0;
(EngineCore_DP0 pid=325118) 	// begin inline asm
(EngineCore_DP0 pid=325118) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=325118) 	// end inline asm
(EngineCore_DP0 pid=325118) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=325118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=325118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=325118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=325118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=325118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=325118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=325118) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=325118) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325118) 	// begin inline asm
(EngineCore_DP0 pid=325118) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=325118) 	// end inline asm
(EngineCore_DP0 pid=325118) 	bar.sync 	0;
(EngineCore_DP0 pid=325118) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=325118) $L__tmp2:
(EngineCore_DP0 pid=325118) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=325118) 	max.f32 	%r128, %r128, %r77;
(EngineCore_DP0 pid=325118) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=325118) 	add.s32 	%r129, %r129, 8192;
(EngineCore_DP0 pid=325118) 	setp.lt.s32 	%p7, %r129, %r19;
(EngineCore_DP0 pid=325118) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=325118) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=325118) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=325118) 	max.f32 	%r130, %r128, 0f2B8CBCCC;
(EngineCore_DP0 pid=325118) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=325118) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=325118) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=325118) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=325118) 	div.full.f32 	%r80, %r130, %r79;
(EngineCore_DP0 pid=325118) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=325118) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=325118) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=325118) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=325118) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=325118) 	// begin inline asm
(EngineCore_DP0 pid=325118) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=325118) 	// end inline asm
(EngineCore_DP0 pid=325118) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=325118) 	shl.b32 	%r15, %r20, 2;
(EngineCore_DP0 pid=325118) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=325118) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=325118) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=325118) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=325118) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=325118) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=325118) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=325118) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=325118) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=325118) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=325118) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=325118) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=325118) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=325118) 	div.full.f32 	%r14, %r79, %r130;
(EngineCore_DP0 pid=325118) 	mov.b32 	%r131, 0;
(EngineCore_DP0 pid=325118) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=325118)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=325118) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=325118) 	add.s32 	%r84, %r3, %r131;
(EngineCore_DP0 pid=325118) 	setp.lt.s32 	%p14, %r84, %r15;
(EngineCore_DP0 pid=325118) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=325118) 	shr.s32 	%r85, %r84, 31;
(EngineCore_DP0 pid=325118) 	shr.u32 	%r86, %r85, 30;
(EngineCore_DP0 pid=325118) 	add.s32 	%r87, %r84, %r86;
(EngineCore_DP0 pid=325118) 	shr.s32 	%r88, %r87, 2;
(EngineCore_DP0 pid=325118) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=325118) 	and.b32 	%r89, %r87, 2147483644;
(EngineCore_DP0 pid=325118) 	sub.s32 	%r90, %r84, %r89;
(EngineCore_DP0 pid=325118) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=325118) 	shl.b32 	%r91, %r90, 1;
(EngineCore_DP0 pid=325118) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=325118) 	mad.lo.s32 	%r92, %r88, 10, %r91;
(EngineCore_DP0 pid=325118) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=325118) 	setp.lt.s32 	%p15, %r92, %r18;
(EngineCore_DP0 pid=325118) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=325118) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=325118) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=325118) 	mad.wide.s32 	%rd9, %r92, 2, %rd1;
(EngineCore_DP0 pid=325118) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=325118) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=325118) 	// begin inline asm
(EngineCore_DP0 pid=325118) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=325118) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=325118) 	// end inline asm
(EngineCore_DP0 pid=325118) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=325118) 	cvt.f32.bf16 	%r93, %rs48;
(EngineCore_DP0 pid=325118) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=325118) 	or.b32 	%r94, %r92, 1;
(EngineCore_DP0 pid=325118) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=325118) 	setp.lt.s32 	%p16, %r94, %r18;
(EngineCore_DP0 pid=325118) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=325118) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=325118) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=325118) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=325118) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=325118) 	// begin inline asm
(EngineCore_DP0 pid=325118) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=325118) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=325118) 	// end inline asm
(EngineCore_DP0 pid=325118) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=325118) 	cvt.f32.bf16 	%r95, %rs50;
(EngineCore_DP0 pid=325118) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=325118) 	add.s32 	%r96, %r92, 2;
(EngineCore_DP0 pid=325118) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=325118) 	setp.lt.s32 	%p17, %r96, %r18;
(EngineCore_DP0 pid=325118) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=325118) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=325118) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=325118) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=325118) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=325118) 	// begin inline asm
(EngineCore_DP0 pid=325118) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=325118) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=325118) 	// end inline asm
(EngineCore_DP0 pid=325118) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=325118) 	cvt.f32.bf16 	%r97, %rs52;
(EngineCore_DP0 pid=325118) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=325118) 	add.s32 	%r98, %r92, 3;
(EngineCore_DP0 pid=325118) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=325118) 	setp.lt.s32 	%p18, %r98, %r18;
(EngineCore_DP0 pid=325118) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=325118) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=325118) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=325118) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=325118) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=325118) 	// begin inline asm
(EngineCore_DP0 pid=325118) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=325118) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=325118) 	// end inline asm
(EngineCore_DP0 pid=325118) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=325118) 	cvt.f32.bf16 	%r99, %rs54;
(EngineCore_DP0 pid=325118) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=325118) 	mul.f32 	%r100, %r14, %r93;
(EngineCore_DP0 pid=325118) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=325118) 	cvt.rni.f32.f32 	%r101, %r100;
(EngineCore_DP0 pid=325118) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=325118) 	max.f32 	%r102, %r101, 0fC3000000;
(EngineCore_DP0 pid=325118) 	min.f32 	%r103, %r102, 0f42FE0000;
(EngineCore_DP0 pid=325118) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=325118) 	cvt.rzi.s32.f32 	%r104, %r103;
(EngineCore_DP0 pid=325118) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=325118) 	and.b32 	%r105, %r104, 255;
(EngineCore_DP0 pid=325118) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=325118) 	mul.f32 	%r106, %r14, %r95;
(EngineCore_DP0 pid=325118) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=325118) 	cvt.rni.f32.f32 	%r107, %r106;
(EngineCore_DP0 pid=325118) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=325118) 	mul.f32 	%r108, %r14, %r97;
(EngineCore_DP0 pid=325118) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=325118) 	cvt.rni.f32.f32 	%r109, %r108;
(EngineCore_DP0 pid=325118) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=325118) 	mul.f32 	%r110, %r14, %r99;
(EngineCore_DP0 pid=325118) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=325118) 	cvt.rni.f32.f32 	%r111, %r110;
(EngineCore_DP0 pid=325118) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=325118) 	max.f32 	%r112, %r111, 0fC3000000;
(EngineCore_DP0 pid=325118) 	min.f32 	%r113, %r112, 0f42FE0000;
(EngineCore_DP0 pid=325118) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=325118) 	cvt.rzi.s32.f32 	%r114, %r113;
(EngineCore_DP0 pid=325118) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=325118) 	max.f32 	%r115, %r109, 0fC3000000;
(EngineCore_DP0 pid=325118) 	max.f32 	%r116, %r107, 0fC3000000;
(EngineCore_DP0 pid=325118) 	min.f32 	%r117, %r116, 0f42FE0000;
(EngineCore_DP0 pid=325118) 	min.f32 	%r118, %r115, 0f42FE0000;
(EngineCore_DP0 pid=325118) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=325118) 	cvt.rzi.s32.f32 	%r119, %r118;
(EngineCore_DP0 pid=325118) 	cvt.rzi.s32.f32 	%r120, %r117;
(EngineCore_DP0 pid=325118) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=325118) 	shl.b32 	%r121, %r120, 8;
(EngineCore_DP0 pid=325118) 	shl.b32 	%r122, %r119, 16;
(EngineCore_DP0 pid=325118) 	and.b32 	%r123, %r122, 16711680;
(EngineCore_DP0 pid=325118) 	and.b32 	%r124, %r121, 65280;
(EngineCore_DP0 pid=325118) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=325118) 	or.b32 	%r125, %r124, %r105;
(EngineCore_DP0 pid=325118) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=325118) 	or.b32 	%r126, %r125, %r123;
(EngineCore_DP0 pid=325118) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=325118) 	shl.b32 	%r127, %r114, 24;
(EngineCore_DP0 pid=325118) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=325118) 	or.b32 	%r82, %r126, %r127;
(EngineCore_DP0 pid=325118) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=325118) 	mad.wide.s32 	%rd13, %r84, 4, %rd2;
(EngineCore_DP0 pid=325118) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=325118) 	// begin inline asm
(EngineCore_DP0 pid=325118) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r82 };
(EngineCore_DP0 pid=325118) 	// end inline asm
(EngineCore_DP0 pid=325118) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=325118) 	add.s32 	%r131, %r131, 512;
(EngineCore_DP0 pid=325118) 	setp.lt.s32 	%p19, %r131, %r15;
(EngineCore_DP0 pid=325118) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=325118) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=325118) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=325118) 	ret;
(EngineCore_DP0 pid=325118) $L__tmp3:
(EngineCore_DP0 pid=325118) $L__func_end0:
(EngineCore_DP0 pid=325118)                                         // -- End function
(EngineCore_DP0 pid=325118) }
(EngineCore_DP0 pid=325118) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=325118) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=325118) 	.section	.debug_abbrev
(EngineCore_DP0 pid=325118) 	{
(EngineCore_DP0 pid=325118) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=325118) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=325118) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=325118) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=325118) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=325118) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=325118) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=325118) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=325118) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=325118) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=325118) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=325118) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=325118) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=325118) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=325118) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=325118) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=325118) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=325118) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=325118) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=325118) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=325118) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=325118) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=325118) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=325118) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=325118) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=325118) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=325118) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=325118) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=325118) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=325118) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=325118) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=325118) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=325118) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=325118) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=325118) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=325118) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=325118) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=325118) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=325118) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=325118) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=325118) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=325118) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=325118) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=325118) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=325118) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=325118) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=325118) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=325118) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=325118) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=325118) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=325118) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=325118) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=325118) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=325118) 	}
(EngineCore_DP0 pid=325118) 	.section	.debug_info
(EngineCore_DP0 pid=325118) 	{
(EngineCore_DP0 pid=325118) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=325118) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=325118) .b8 0
(EngineCore_DP0 pid=325118) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=325118) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=325118) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=325118) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=325118) .b8 114
(EngineCore_DP0 pid=325118) .b8 105
(EngineCore_DP0 pid=325118) .b8 116
(EngineCore_DP0 pid=325118) .b8 111
(EngineCore_DP0 pid=325118) .b8 110
(EngineCore_DP0 pid=325118) .b8 0
(EngineCore_DP0 pid=325118) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=325118) .b8 0
(EngineCore_DP0 pid=325118) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=325118) .b8 117
(EngineCore_DP0 pid=325118) .b8 97
(EngineCore_DP0 pid=325118) .b8 110
(EngineCore_DP0 pid=325118) .b8 116
(EngineCore_DP0 pid=325118) .b8 95
(EngineCore_DP0 pid=325118) .b8 115
(EngineCore_DP0 pid=325118) .b8 108
(EngineCore_DP0 pid=325118) .b8 105
(EngineCore_DP0 pid=325118) .b8 100
(EngineCore_DP0 pid=325118) .b8 101
(EngineCore_DP0 pid=325118) .b8 95
(EngineCore_DP0 pid=325118) .b8 116
(EngineCore_DP0 pid=325118) .b8 117
(EngineCore_DP0 pid=325118) .b8 110
(EngineCore_DP0 pid=325118) .b8 101
(EngineCore_DP0 pid=325118) .b8 100
(EngineCore_DP0 pid=325118) .b8 95
(EngineCore_DP0 pid=325118) .b8 76
(EngineCore_DP0 pid=325118) .b8 108
(EngineCore_DP0 pid=325118) .b8 97
(EngineCore_DP0 pid=325118) .b8 109
(EngineCore_DP0 pid=325118) .b8 97
(EngineCore_DP0 pid=325118) .b8 51
(EngineCore_DP0 pid=325118) .b8 46
(EngineCore_DP0 pid=325118) .b8 50
(EngineCore_DP0 pid=325118) .b8 45
(EngineCore_DP0 pid=325118) .b8 49
(EngineCore_DP0 pid=325118) .b8 66
(EngineCore_DP0 pid=325118) .b8 46
(EngineCore_DP0 pid=325118) .b8 112
(EngineCore_DP0 pid=325118) .b8 121
(EngineCore_DP0 pid=325118) .b8 0
(EngineCore_DP0 pid=325118) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=325118) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=325118) .b8 114
(EngineCore_DP0 pid=325118) .b8 111
(EngineCore_DP0 pid=325118) .b8 111
(EngineCore_DP0 pid=325118) .b8 116
(EngineCore_DP0 pid=325118) .b8 47
(EngineCore_DP0 pid=325118) .b8 118
(EngineCore_DP0 pid=325118) .b8 108
(EngineCore_DP0 pid=325118) .b8 108
(EngineCore_DP0 pid=325118) .b8 109
(EngineCore_DP0 pid=325118) .b8 98
(EngineCore_DP0 pid=325118) .b8 101
(EngineCore_DP0 pid=325118) .b8 110
(EngineCore_DP0 pid=325118) .b8 99
(EngineCore_DP0 pid=325118) .b8 104
(EngineCore_DP0 pid=325118) .b8 47
(EngineCore_DP0 pid=325118) .b8 115
(EngineCore_DP0 pid=325118) .b8 108
(EngineCore_DP0 pid=325118) .b8 105
(EngineCore_DP0 pid=325118) .b8 100
(EngineCore_DP0 pid=325118) .b8 101
(EngineCore_DP0 pid=325118) .b8 115
(EngineCore_DP0 pid=325118) .b8 112
(EngineCore_DP0 pid=325118) .b8 97
(EngineCore_DP0 pid=325118) .b8 114
(EngineCore_DP0 pid=325118) .b8 115
(EngineCore_DP0 pid=325118) .b8 101
(EngineCore_DP0 pid=325118) .b8 47
(EngineCore_DP0 pid=325118) .b8 99
(EngineCore_DP0 pid=325118) .b8 115
(EngineCore_DP0 pid=325118) .b8 114
(EngineCore_DP0 pid=325118) .b8 99
(EngineCore_DP0 pid=325118) .b8 47
(EngineCore_DP0 pid=325118) .b8 102
(EngineCore_DP0 pid=325118) .b8 117
(EngineCore_DP0 pid=325118) .b8 115
(EngineCore_DP0 pid=325118) .b8 101
(EngineCore_DP0 pid=325118) .b8 100
(EngineCore_DP0 pid=325118) .b8 95
(EngineCore_DP0 pid=325118) .b8 113
(EngineCore_DP0 pid=325118) .b8 117
(EngineCore_DP0 pid=325118) .b8 97
(EngineCore_DP0 pid=325118) .b8 110
(EngineCore_DP0 pid=325118) .b8 116
(EngineCore_DP0 pid=325118) .b8 95
(EngineCore_DP0 pid=325118) .b8 115
(EngineCore_DP0 pid=325118) .b8 108
(EngineCore_DP0 pid=325118) .b8 105
(EngineCore_DP0 pid=325118) .b8 100
(EngineCore_DP0 pid=325118) .b8 101
(EngineCore_DP0 pid=325118) .b8 95
(EngineCore_DP0 pid=325118) .b8 116
(EngineCore_DP0 pid=325118) .b8 114
(EngineCore_DP0 pid=325118) .b8 105
(EngineCore_DP0 pid=325118) .b8 116
(EngineCore_DP0 pid=325118) .b8 111
(EngineCore_DP0 pid=325118) .b8 110
(EngineCore_DP0 pid=325118) .b8 47
(EngineCore_DP0 pid=325118) .b8 98
(EngineCore_DP0 pid=325118) .b8 117
(EngineCore_DP0 pid=325118) .b8 105
(EngineCore_DP0 pid=325118) .b8 108
(EngineCore_DP0 pid=325118) .b8 100
(EngineCore_DP0 pid=325118) .b8 47
(EngineCore_DP0 pid=325118) .b8 71
(EngineCore_DP0 pid=325118) .b8 66
(EngineCore_DP0 pid=325118) .b8 49
(EngineCore_DP0 pid=325118) .b8 48
(EngineCore_DP0 pid=325118) .b8 95
(EngineCore_DP0 pid=325118) .b8 99
(EngineCore_DP0 pid=325118) .b8 99
(EngineCore_DP0 pid=325118) .b8 49
(EngineCore_DP0 pid=325118) .b8 50
(EngineCore_DP0 pid=325118) .b8 49
(EngineCore_DP0 pid=325118) .b8 95
(EngineCore_DP0 pid=325118) .b8 112
(EngineCore_DP0 pid=325118) .b8 121
(EngineCore_DP0 pid=325118) .b8 51
(EngineCore_DP0 pid=325118) .b8 49
(EngineCore_DP0 pid=325118) .b8 50
(EngineCore_DP0 pid=325118) .b8 95
(EngineCore_DP0 pid=325118) .b8 99
(EngineCore_DP0 pid=325118) .b8 117
(EngineCore_DP0 pid=325118) .b8 49
(EngineCore_DP0 pid=325118) .b8 50
(EngineCore_DP0 pid=325118) .b8 57
(EngineCore_DP0 pid=325118) .b8 95
(EngineCore_DP0 pid=325118) .b8 97
(EngineCore_DP0 pid=325118) .b8 97
(EngineCore_DP0 pid=325118) .b8 114
(EngineCore_DP0 pid=325118) .b8 99
(EngineCore_DP0 pid=325118) .b8 104
(EngineCore_DP0 pid=325118) .b8 54
(EngineCore_DP0 pid=325118) .b8 52
(EngineCore_DP0 pid=325118) .b8 0
(EngineCore_DP0 pid=325118) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=325118) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=325118) .b8 113
(EngineCore_DP0 pid=325118) .b8 117
(EngineCore_DP0 pid=325118) .b8 97
(EngineCore_DP0 pid=325118) .b8 110
(EngineCore_DP0 pid=325118) .b8 116
(EngineCore_DP0 pid=325118) .b8 95
(EngineCore_DP0 pid=325118) .b8 115
(EngineCore_DP0 pid=325118) .b8 108
(EngineCore_DP0 pid=325118) .b8 105
(EngineCore_DP0 pid=325118) .b8 100
(EngineCore_DP0 pid=325118) .b8 101
(EngineCore_DP0 pid=325118) .b8 95
(EngineCore_DP0 pid=325118) .b8 105
(EngineCore_DP0 pid=325118) .b8 110
(EngineCore_DP0 pid=325118) .b8 116
(EngineCore_DP0 pid=325118) .b8 56
(EngineCore_DP0 pid=325118) .b8 95
(EngineCore_DP0 pid=325118) .b8 107
(EngineCore_DP0 pid=325118) .b8 101
(EngineCore_DP0 pid=325118) .b8 114
(EngineCore_DP0 pid=325118) .b8 110
(EngineCore_DP0 pid=325118) .b8 101
(EngineCore_DP0 pid=325118) .b8 108
(EngineCore_DP0 pid=325118) .b8 0
(EngineCore_DP0 pid=325118) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=325118) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=325118) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=325118) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=325118) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=325118) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=325118) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=325118) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=325118) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=325118) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=325118) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=325118) .b8 1
(EngineCore_DP0 pid=325118) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=325118) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=325118) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=325118) 	}
(EngineCore_DP0 pid=325118) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=325118) 
(EngineCore_DP0 pid=325118) ================================================================
(EngineCore_DP0 pid=325118) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=325118) 
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpjcarjz1v.ptx', '-o', '/tmp/tmpjcarjz1v.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866] 
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866] 
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866] 
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpjcarjz1v.ptx -o /tmp/tmpjcarjz1v.ptx.o
(EngineCore_DP0 pid=325118) ERROR 01-25 19:07:10 [core.py:866] 

STDERR:
[2026-01-25 19:06:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:06:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:06:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:06:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:06:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:06:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:06:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:06:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:06:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:06:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:06:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:06:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:06:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:06:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:06:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:06:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:06:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:06:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:06:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=325118) [2026-01-25 19:06:57] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=325118) [2026-01-25 19:06:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=325118) [2026-01-25 19:06:57] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=325118) [2026-01-25 19:06:57] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=325118) [2026-01-25 19:06:57] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=325118) [2026-01-25 19:06:57] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=325118) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=325118) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.95s/it]
(EngineCore_DP0 pid=325118) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.95s/it]
(EngineCore_DP0 pid=325118) 
(EngineCore_DP0 pid=325118) [2026-01-25 19:07:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=325118) [2026-01-25 19:07:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=325118) [2026-01-25 19:07:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=325118) [2026-01-25 19:07:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=325118) [2026-01-25 19:07:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=325118) [2026-01-25 19:07:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=325118) [2026-01-25 19:07:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=325118) [2026-01-25 19:07:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=325118) Process EngineCore_DP0:
(EngineCore_DP0 pid=325118) Traceback (most recent call last):
(EngineCore_DP0 pid=325118)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=325118)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=325118)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=325118)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=325118) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpjcarjz1v.ptx', '-o', '/tmp/tmpjcarjz1v.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=325118) 
(EngineCore_DP0 pid=325118) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=325118) 
(EngineCore_DP0 pid=325118) Traceback (most recent call last):
(EngineCore_DP0 pid=325118)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=325118)     self.run()
(EngineCore_DP0 pid=325118)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=325118)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=325118)     raise e
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=325118)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=325118)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=325118)     super().__init__(
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=325118)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=325118)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=325118)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=325118)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=325118)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=325118)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=325118)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=325118)     return func(*args, **kwargs)
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=325118)     return func(*args, **kwargs)
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=325118)     self.model_runner.profile_run()
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=325118)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=325118)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=325118)     return func(*args, **kwargs)
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=325118)     outputs = self.model(
(EngineCore_DP0 pid=325118)               ^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=325118)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=325118)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=325118)     model_output = self.model(
(EngineCore_DP0 pid=325118)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=325118)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=325118)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=325118)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=325118)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=325118)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=325118)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=325118)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=325118)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=325118)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=325118)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=325118)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=325118)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=325118)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=325118)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=325118)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=325118)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=325118)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=325118)     return self._linear_fn(
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=325118)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=325118)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=325118)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=325118)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=325118)     return fn(input, L)
(EngineCore_DP0 pid=325118)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=325118)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=325118)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=325118)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=325118)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=325118)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=325118)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=325118)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=325118)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=325118)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=325118)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=325118)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=325118)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325118)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=325118)     raise PTXASError(error)
(EngineCore_DP0 pid=325118) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=325118) `ptxas` stderr:
(EngineCore_DP0 pid=325118) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=325118) 
(EngineCore_DP0 pid=325118) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpjcarjz1v.ptx -o /tmp/tmpjcarjz1v.ptx.o
(EngineCore_DP0 pid=325118) 
[rank0]:[W125 19:07:10.514678180 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 19:07:11
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:07:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:07:16 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=325638) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=325638) 
(EngineCore_DP0 pid=325638) 
(EngineCore_DP0 pid=325638) ================================================================
(EngineCore_DP0 pid=325638) Internal Triton PTX codegen error
(EngineCore_DP0 pid=325638) `ptxas` stderr:
(EngineCore_DP0 pid=325638) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=325638) 
(EngineCore_DP0 pid=325638) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp5x4g1r36.ptx -o /tmp/tmp5x4g1r36.ptx.o
(EngineCore_DP0 pid=325638) 
(EngineCore_DP0 pid=325638) 
(EngineCore_DP0 pid=325638) //
(EngineCore_DP0 pid=325638) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=325638) //
(EngineCore_DP0 pid=325638) 
(EngineCore_DP0 pid=325638) .version 8.7
(EngineCore_DP0 pid=325638) .target sm_121a
(EngineCore_DP0 pid=325638) .address_size 64
(EngineCore_DP0 pid=325638) 
(EngineCore_DP0 pid=325638) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=325638) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=325638)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=325638) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=325638) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=325638) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=325638) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=325638) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=325638) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=325638) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=325638) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=325638) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=325638) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=325638) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=325638) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=325638) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=325638) )
(EngineCore_DP0 pid=325638) .reqntid 512
(EngineCore_DP0 pid=325638) {
(EngineCore_DP0 pid=325638) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=325638) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=325638) 	.reg .b32 	%r<132>;
(EngineCore_DP0 pid=325638) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=325638) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=325638) $L__func_begin0:
(EngineCore_DP0 pid=325638) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=325638) 
(EngineCore_DP0 pid=325638) // %bb.0:
(EngineCore_DP0 pid=325638) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=325638) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=325638) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=325638) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=325638) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=325638) $L__tmp0:
(EngineCore_DP0 pid=325638) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=325638) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=325638) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=325638) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=325638) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=325638) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=325638) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=325638) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=325638) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=325638) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=325638) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=325638) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=325638) 	mov.b32 	%r130, 0f2B8CBCCC;
(EngineCore_DP0 pid=325638) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=325638) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=325638) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=325638) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=325638) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=325638) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=325638) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=325638) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=325638) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=325638) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=325638) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=325638) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=325638) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=325638) 	mov.b32 	%r128, 0f00000000;
(EngineCore_DP0 pid=325638) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=325638) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=325638) 	mov.b32 	%r129, %r40;
(EngineCore_DP0 pid=325638) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=325638) 	.loc	1 299 19                        // quant_slide_tuned_Llama3.2-1B.py:299:19
(EngineCore_DP0 pid=325638) 	add.s32 	%r58, %r4, %r129;
(EngineCore_DP0 pid=325638) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=325638) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=325638) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=325638) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=325638) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=325638) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=325638) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=325638) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=325638) 	// begin inline asm
(EngineCore_DP0 pid=325638) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=325638) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=325638) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=325638) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=325638) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=325638) 	// end inline asm
(EngineCore_DP0 pid=325638) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=325638) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=325638) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=325638) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=325638) 	// begin inline asm
(EngineCore_DP0 pid=325638) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=325638) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=325638) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=325638) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=325638) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=325638) 	// end inline asm
(EngineCore_DP0 pid=325638) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=325638) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=325638) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=325638) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=325638) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=325638) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=325638) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=325638) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=325638) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=325638) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=325638) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=325638) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=325638) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=325638) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=325638) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=325638) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=325638) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=325638) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=325638) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=325638) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=325638) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=325638) $L__tmp1:
(EngineCore_DP0 pid=325638) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	bar.sync 	0;
(EngineCore_DP0 pid=325638) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=325638) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=325638) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=325638) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=325638) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=325638) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=325638) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=325638) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=325638) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=325638) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=325638) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=325638) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=325638) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=325638) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=325638) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=325638) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=325638) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=325638) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=325638) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=325638) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=325638) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=325638) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=325638) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=325638) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=325638) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=325638) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=325638) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	// begin inline asm
(EngineCore_DP0 pid=325638) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=325638) 	// end inline asm
(EngineCore_DP0 pid=325638) 	bar.sync 	0;
(EngineCore_DP0 pid=325638) 	// begin inline asm
(EngineCore_DP0 pid=325638) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=325638) 	// end inline asm
(EngineCore_DP0 pid=325638) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=325638) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=325638) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=325638) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=325638) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=325638) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=325638) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=325638) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=325638) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=325638) 	// begin inline asm
(EngineCore_DP0 pid=325638) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=325638) 	// end inline asm
(EngineCore_DP0 pid=325638) 	bar.sync 	0;
(EngineCore_DP0 pid=325638) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=325638) $L__tmp2:
(EngineCore_DP0 pid=325638) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=325638) 	max.f32 	%r128, %r128, %r77;
(EngineCore_DP0 pid=325638) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=325638) 	add.s32 	%r129, %r129, 8192;
(EngineCore_DP0 pid=325638) 	setp.lt.s32 	%p7, %r129, %r19;
(EngineCore_DP0 pid=325638) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=325638) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=325638) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=325638) 	max.f32 	%r130, %r128, 0f2B8CBCCC;
(EngineCore_DP0 pid=325638) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=325638) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=325638) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=325638) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=325638) 	div.full.f32 	%r80, %r130, %r79;
(EngineCore_DP0 pid=325638) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=325638) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=325638) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=325638) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=325638) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=325638) 	// begin inline asm
(EngineCore_DP0 pid=325638) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=325638) 	// end inline asm
(EngineCore_DP0 pid=325638) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=325638) 	shl.b32 	%r15, %r20, 2;
(EngineCore_DP0 pid=325638) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=325638) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=325638) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=325638) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=325638) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=325638) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=325638) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=325638) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=325638) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=325638) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=325638) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=325638) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=325638) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=325638) 	div.full.f32 	%r14, %r79, %r130;
(EngineCore_DP0 pid=325638) 	mov.b32 	%r131, 0;
(EngineCore_DP0 pid=325638) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=325638)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=325638) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=325638) 	add.s32 	%r84, %r3, %r131;
(EngineCore_DP0 pid=325638) 	setp.lt.s32 	%p14, %r84, %r15;
(EngineCore_DP0 pid=325638) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=325638) 	shr.s32 	%r85, %r84, 31;
(EngineCore_DP0 pid=325638) 	shr.u32 	%r86, %r85, 30;
(EngineCore_DP0 pid=325638) 	add.s32 	%r87, %r84, %r86;
(EngineCore_DP0 pid=325638) 	shr.s32 	%r88, %r87, 2;
(EngineCore_DP0 pid=325638) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=325638) 	and.b32 	%r89, %r87, 2147483644;
(EngineCore_DP0 pid=325638) 	sub.s32 	%r90, %r84, %r89;
(EngineCore_DP0 pid=325638) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=325638) 	shl.b32 	%r91, %r90, 1;
(EngineCore_DP0 pid=325638) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=325638) 	mad.lo.s32 	%r92, %r88, 10, %r91;
(EngineCore_DP0 pid=325638) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=325638) 	setp.lt.s32 	%p15, %r92, %r18;
(EngineCore_DP0 pid=325638) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=325638) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=325638) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=325638) 	mad.wide.s32 	%rd9, %r92, 2, %rd1;
(EngineCore_DP0 pid=325638) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=325638) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=325638) 	// begin inline asm
(EngineCore_DP0 pid=325638) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=325638) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=325638) 	// end inline asm
(EngineCore_DP0 pid=325638) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=325638) 	cvt.f32.bf16 	%r93, %rs48;
(EngineCore_DP0 pid=325638) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=325638) 	or.b32 	%r94, %r92, 1;
(EngineCore_DP0 pid=325638) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=325638) 	setp.lt.s32 	%p16, %r94, %r18;
(EngineCore_DP0 pid=325638) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=325638) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=325638) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=325638) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=325638) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=325638) 	// begin inline asm
(EngineCore_DP0 pid=325638) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=325638) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=325638) 	// end inline asm
(EngineCore_DP0 pid=325638) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=325638) 	cvt.f32.bf16 	%r95, %rs50;
(EngineCore_DP0 pid=325638) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=325638) 	add.s32 	%r96, %r92, 2;
(EngineCore_DP0 pid=325638) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=325638) 	setp.lt.s32 	%p17, %r96, %r18;
(EngineCore_DP0 pid=325638) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=325638) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=325638) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=325638) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=325638) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=325638) 	// begin inline asm
(EngineCore_DP0 pid=325638) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=325638) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=325638) 	// end inline asm
(EngineCore_DP0 pid=325638) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=325638) 	cvt.f32.bf16 	%r97, %rs52;
(EngineCore_DP0 pid=325638) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=325638) 	add.s32 	%r98, %r92, 3;
(EngineCore_DP0 pid=325638) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=325638) 	setp.lt.s32 	%p18, %r98, %r18;
(EngineCore_DP0 pid=325638) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=325638) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=325638) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=325638) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=325638) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=325638) 	// begin inline asm
(EngineCore_DP0 pid=325638) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=325638) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=325638) 	// end inline asm
(EngineCore_DP0 pid=325638) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=325638) 	cvt.f32.bf16 	%r99, %rs54;
(EngineCore_DP0 pid=325638) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=325638) 	mul.f32 	%r100, %r14, %r93;
(EngineCore_DP0 pid=325638) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=325638) 	cvt.rni.f32.f32 	%r101, %r100;
(EngineCore_DP0 pid=325638) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=325638) 	max.f32 	%r102, %r101, 0fC3000000;
(EngineCore_DP0 pid=325638) 	min.f32 	%r103, %r102, 0f42FE0000;
(EngineCore_DP0 pid=325638) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=325638) 	cvt.rzi.s32.f32 	%r104, %r103;
(EngineCore_DP0 pid=325638) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=325638) 	and.b32 	%r105, %r104, 255;
(EngineCore_DP0 pid=325638) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=325638) 	mul.f32 	%r106, %r14, %r95;
(EngineCore_DP0 pid=325638) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=325638) 	cvt.rni.f32.f32 	%r107, %r106;
(EngineCore_DP0 pid=325638) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=325638) 	mul.f32 	%r108, %r14, %r97;
(EngineCore_DP0 pid=325638) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=325638) 	cvt.rni.f32.f32 	%r109, %r108;
(EngineCore_DP0 pid=325638) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=325638) 	mul.f32 	%r110, %r14, %r99;
(EngineCore_DP0 pid=325638) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=325638) 	cvt.rni.f32.f32 	%r111, %r110;
(EngineCore_DP0 pid=325638) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=325638) 	max.f32 	%r112, %r111, 0fC3000000;
(EngineCore_DP0 pid=325638) 	min.f32 	%r113, %r112, 0f42FE0000;
(EngineCore_DP0 pid=325638) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=325638) 	cvt.rzi.s32.f32 	%r114, %r113;
(EngineCore_DP0 pid=325638) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=325638) 	max.f32 	%r115, %r109, 0fC3000000;
(EngineCore_DP0 pid=325638) 	max.f32 	%r116, %r107, 0fC3000000;
(EngineCore_DP0 pid=325638) 	min.f32 	%r117, %r116, 0f42FE0000;
(EngineCore_DP0 pid=325638) 	min.f32 	%r118, %r115, 0f42FE0000;
(EngineCore_DP0 pid=325638) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=325638) 	cvt.rzi.s32.f32 	%r119, %r118;
(EngineCore_DP0 pid=325638) 	cvt.rzi.s32.f32 	%r120, %r117;
(EngineCore_DP0 pid=325638) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=325638) 	shl.b32 	%r121, %r120, 8;
(EngineCore_DP0 pid=325638) 	shl.b32 	%r122, %r119, 16;
(EngineCore_DP0 pid=325638) 	and.b32 	%r123, %r122, 16711680;
(EngineCore_DP0 pid=325638) 	and.b32 	%r124, %r121, 65280;
(EngineCore_DP0 pid=325638) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=325638) 	or.b32 	%r125, %r124, %r105;
(EngineCore_DP0 pid=325638) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=325638) 	or.b32 	%r126, %r125, %r123;
(EngineCore_DP0 pid=325638) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=325638) 	shl.b32 	%r127, %r114, 24;
(EngineCore_DP0 pid=325638) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=325638) 	or.b32 	%r82, %r126, %r127;
(EngineCore_DP0 pid=325638) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=325638) 	mad.wide.s32 	%rd13, %r84, 4, %rd2;
(EngineCore_DP0 pid=325638) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=325638) 	// begin inline asm
(EngineCore_DP0 pid=325638) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r82 };
(EngineCore_DP0 pid=325638) 	// end inline asm
(EngineCore_DP0 pid=325638) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=325638) 	add.s32 	%r131, %r131, 512;
(EngineCore_DP0 pid=325638) 	setp.lt.s32 	%p19, %r131, %r15;
(EngineCore_DP0 pid=325638) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=325638) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=325638) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=325638) 	ret;
(EngineCore_DP0 pid=325638) $L__tmp3:
(EngineCore_DP0 pid=325638) $L__func_end0:
(EngineCore_DP0 pid=325638)                                         // -- End function
(EngineCore_DP0 pid=325638) }
(EngineCore_DP0 pid=325638) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=325638) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=325638) 	.section	.debug_abbrev
(EngineCore_DP0 pid=325638) 	{
(EngineCore_DP0 pid=325638) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=325638) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=325638) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=325638) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=325638) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=325638) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=325638) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=325638) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=325638) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=325638) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=325638) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=325638) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=325638) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=325638) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=325638) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=325638) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=325638) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=325638) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=325638) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=325638) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=325638) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=325638) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=325638) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=325638) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=325638) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=325638) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=325638) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=325638) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=325638) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=325638) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=325638) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=325638) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=325638) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=325638) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=325638) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=325638) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=325638) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=325638) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=325638) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=325638) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=325638) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=325638) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=325638) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=325638) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=325638) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=325638) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=325638) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=325638) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=325638) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=325638) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=325638) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=325638) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=325638) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=325638) 	}
(EngineCore_DP0 pid=325638) 	.section	.debug_info
(EngineCore_DP0 pid=325638) 	{
(EngineCore_DP0 pid=325638) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=325638) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=325638) .b8 0
(EngineCore_DP0 pid=325638) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=325638) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=325638) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=325638) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=325638) .b8 114
(EngineCore_DP0 pid=325638) .b8 105
(EngineCore_DP0 pid=325638) .b8 116
(EngineCore_DP0 pid=325638) .b8 111
(EngineCore_DP0 pid=325638) .b8 110
(EngineCore_DP0 pid=325638) .b8 0
(EngineCore_DP0 pid=325638) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=325638) .b8 0
(EngineCore_DP0 pid=325638) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=325638) .b8 117
(EngineCore_DP0 pid=325638) .b8 97
(EngineCore_DP0 pid=325638) .b8 110
(EngineCore_DP0 pid=325638) .b8 116
(EngineCore_DP0 pid=325638) .b8 95
(EngineCore_DP0 pid=325638) .b8 115
(EngineCore_DP0 pid=325638) .b8 108
(EngineCore_DP0 pid=325638) .b8 105
(EngineCore_DP0 pid=325638) .b8 100
(EngineCore_DP0 pid=325638) .b8 101
(EngineCore_DP0 pid=325638) .b8 95
(EngineCore_DP0 pid=325638) .b8 116
(EngineCore_DP0 pid=325638) .b8 117
(EngineCore_DP0 pid=325638) .b8 110
(EngineCore_DP0 pid=325638) .b8 101
(EngineCore_DP0 pid=325638) .b8 100
(EngineCore_DP0 pid=325638) .b8 95
(EngineCore_DP0 pid=325638) .b8 76
(EngineCore_DP0 pid=325638) .b8 108
(EngineCore_DP0 pid=325638) .b8 97
(EngineCore_DP0 pid=325638) .b8 109
(EngineCore_DP0 pid=325638) .b8 97
(EngineCore_DP0 pid=325638) .b8 51
(EngineCore_DP0 pid=325638) .b8 46
(EngineCore_DP0 pid=325638) .b8 50
(EngineCore_DP0 pid=325638) .b8 45
(EngineCore_DP0 pid=325638) .b8 49
(EngineCore_DP0 pid=325638) .b8 66
(EngineCore_DP0 pid=325638) .b8 46
(EngineCore_DP0 pid=325638) .b8 112
(EngineCore_DP0 pid=325638) .b8 121
(EngineCore_DP0 pid=325638) .b8 0
(EngineCore_DP0 pid=325638) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=325638) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=325638) .b8 114
(EngineCore_DP0 pid=325638) .b8 111
(EngineCore_DP0 pid=325638) .b8 111
(EngineCore_DP0 pid=325638) .b8 116
(EngineCore_DP0 pid=325638) .b8 47
(EngineCore_DP0 pid=325638) .b8 118
(EngineCore_DP0 pid=325638) .b8 108
(EngineCore_DP0 pid=325638) .b8 108
(EngineCore_DP0 pid=325638) .b8 109
(EngineCore_DP0 pid=325638) .b8 98
(EngineCore_DP0 pid=325638) .b8 101
(EngineCore_DP0 pid=325638) .b8 110
(EngineCore_DP0 pid=325638) .b8 99
(EngineCore_DP0 pid=325638) .b8 104
(EngineCore_DP0 pid=325638) .b8 47
(EngineCore_DP0 pid=325638) .b8 115
(EngineCore_DP0 pid=325638) .b8 108
(EngineCore_DP0 pid=325638) .b8 105
(EngineCore_DP0 pid=325638) .b8 100
(EngineCore_DP0 pid=325638) .b8 101
(EngineCore_DP0 pid=325638) .b8 115
(EngineCore_DP0 pid=325638) .b8 112
(EngineCore_DP0 pid=325638) .b8 97
(EngineCore_DP0 pid=325638) .b8 114
(EngineCore_DP0 pid=325638) .b8 115
(EngineCore_DP0 pid=325638) .b8 101
(EngineCore_DP0 pid=325638) .b8 47
(EngineCore_DP0 pid=325638) .b8 99
(EngineCore_DP0 pid=325638) .b8 115
(EngineCore_DP0 pid=325638) .b8 114
(EngineCore_DP0 pid=325638) .b8 99
(EngineCore_DP0 pid=325638) .b8 47
(EngineCore_DP0 pid=325638) .b8 102
(EngineCore_DP0 pid=325638) .b8 117
(EngineCore_DP0 pid=325638) .b8 115
(EngineCore_DP0 pid=325638) .b8 101
(EngineCore_DP0 pid=325638) .b8 100
(EngineCore_DP0 pid=325638) .b8 95
(EngineCore_DP0 pid=325638) .b8 113
(EngineCore_DP0 pid=325638) .b8 117
(EngineCore_DP0 pid=325638) .b8 97
(EngineCore_DP0 pid=325638) .b8 110
(EngineCore_DP0 pid=325638) .b8 116
(EngineCore_DP0 pid=325638) .b8 95
(EngineCore_DP0 pid=325638) .b8 115
(EngineCore_DP0 pid=325638) .b8 108
(EngineCore_DP0 pid=325638) .b8 105
(EngineCore_DP0 pid=325638) .b8 100
(EngineCore_DP0 pid=325638) .b8 101
(EngineCore_DP0 pid=325638) .b8 95
(EngineCore_DP0 pid=325638) .b8 116
(EngineCore_DP0 pid=325638) .b8 114
(EngineCore_DP0 pid=325638) .b8 105
(EngineCore_DP0 pid=325638) .b8 116
(EngineCore_DP0 pid=325638) .b8 111
(EngineCore_DP0 pid=325638) .b8 110
(EngineCore_DP0 pid=325638) .b8 47
(EngineCore_DP0 pid=325638) .b8 98
(EngineCore_DP0 pid=325638) .b8 117
(EngineCore_DP0 pid=325638) .b8 105
(EngineCore_DP0 pid=325638) .b8 108
(EngineCore_DP0 pid=325638) .b8 100
(EngineCore_DP0 pid=325638) .b8 47
(EngineCore_DP0 pid=325638) .b8 71
(EngineCore_DP0 pid=325638) .b8 66
(EngineCore_DP0 pid=325638) .b8 49
(EngineCore_DP0 pid=325638) .b8 48
(EngineCore_DP0 pid=325638) .b8 95
(EngineCore_DP0 pid=325638) .b8 99
(EngineCore_DP0 pid=325638) .b8 99
(EngineCore_DP0 pid=325638) .b8 49
(EngineCore_DP0 pid=325638) .b8 50
(EngineCore_DP0 pid=325638) .b8 49
(EngineCore_DP0 pid=325638) .b8 95
(EngineCore_DP0 pid=325638) .b8 112
(EngineCore_DP0 pid=325638) .b8 121
(EngineCore_DP0 pid=325638) .b8 51
(EngineCore_DP0 pid=325638) .b8 49
(EngineCore_DP0 pid=325638) .b8 50
(EngineCore_DP0 pid=325638) .b8 95
(EngineCore_DP0 pid=325638) .b8 99
(EngineCore_DP0 pid=325638) .b8 117
(EngineCore_DP0 pid=325638) .b8 49
(EngineCore_DP0 pid=325638) .b8 50
(EngineCore_DP0 pid=325638) .b8 57
(EngineCore_DP0 pid=325638) .b8 95
(EngineCore_DP0 pid=325638) .b8 97
(EngineCore_DP0 pid=325638) .b8 97
(EngineCore_DP0 pid=325638) .b8 114
(EngineCore_DP0 pid=325638) .b8 99
(EngineCore_DP0 pid=325638) .b8 104
(EngineCore_DP0 pid=325638) .b8 54
(EngineCore_DP0 pid=325638) .b8 52
(EngineCore_DP0 pid=325638) .b8 0
(EngineCore_DP0 pid=325638) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=325638) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=325638) .b8 113
(EngineCore_DP0 pid=325638) .b8 117
(EngineCore_DP0 pid=325638) .b8 97
(EngineCore_DP0 pid=325638) .b8 110
(EngineCore_DP0 pid=325638) .b8 116
(EngineCore_DP0 pid=325638) .b8 95
(EngineCore_DP0 pid=325638) .b8 115
(EngineCore_DP0 pid=325638) .b8 108
(EngineCore_DP0 pid=325638) .b8 105
(EngineCore_DP0 pid=325638) .b8 100
(EngineCore_DP0 pid=325638) .b8 101
(EngineCore_DP0 pid=325638) .b8 95
(EngineCore_DP0 pid=325638) .b8 105
(EngineCore_DP0 pid=325638) .b8 110
(EngineCore_DP0 pid=325638) .b8 116
(EngineCore_DP0 pid=325638) .b8 56
(EngineCore_DP0 pid=325638) .b8 95
(EngineCore_DP0 pid=325638) .b8 107
(EngineCore_DP0 pid=325638) .b8 101
(EngineCore_DP0 pid=325638) .b8 114
(EngineCore_DP0 pid=325638) .b8 110
(EngineCore_DP0 pid=325638) .b8 101
(EngineCore_DP0 pid=325638) .b8 108
(EngineCore_DP0 pid=325638) .b8 0
(EngineCore_DP0 pid=325638) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=325638) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=325638) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=325638) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=325638) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=325638) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=325638) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=325638) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=325638) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=325638) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=325638) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=325638) .b8 1
(EngineCore_DP0 pid=325638) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=325638) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=325638) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=325638) 	}
(EngineCore_DP0 pid=325638) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=325638) 
(EngineCore_DP0 pid=325638) ================================================================
(EngineCore_DP0 pid=325638) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=325638) 
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp5x4g1r36.ptx', '-o', '/tmp/tmp5x4g1r36.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866] 
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866] 
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866] 
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp5x4g1r36.ptx -o /tmp/tmp5x4g1r36.ptx.o
(EngineCore_DP0 pid=325638) ERROR 01-25 19:07:33 [core.py:866] 

STDERR:
[2026-01-25 19:07:16] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:07:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:07:16] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:07:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:07:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:07:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:07:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:07:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:07:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:07:20] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:07:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:07:20] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:07:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:07:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:07:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:07:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:07:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:07:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=325638) [2026-01-25 19:07:21] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=325638) [2026-01-25 19:07:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=325638) [2026-01-25 19:07:21] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=325638) [2026-01-25 19:07:21] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=325638) [2026-01-25 19:07:21] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=325638) [2026-01-25 19:07:21] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=325638) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=325638) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.80s/it]
(EngineCore_DP0 pid=325638) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.80s/it]
(EngineCore_DP0 pid=325638) 
(EngineCore_DP0 pid=325638) [2026-01-25 19:07:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=325638) [2026-01-25 19:07:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=325638) [2026-01-25 19:07:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=325638) [2026-01-25 19:07:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=325638) [2026-01-25 19:07:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=325638) [2026-01-25 19:07:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=325638) [2026-01-25 19:07:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=325638) [2026-01-25 19:07:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=325638) Process EngineCore_DP0:
(EngineCore_DP0 pid=325638) Traceback (most recent call last):
(EngineCore_DP0 pid=325638)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=325638)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=325638)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=325638)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=325638) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp5x4g1r36.ptx', '-o', '/tmp/tmp5x4g1r36.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=325638) 
(EngineCore_DP0 pid=325638) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=325638) 
(EngineCore_DP0 pid=325638) Traceback (most recent call last):
(EngineCore_DP0 pid=325638)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=325638)     self.run()
(EngineCore_DP0 pid=325638)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=325638)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=325638)     raise e
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=325638)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=325638)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=325638)     super().__init__(
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=325638)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=325638)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=325638)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=325638)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=325638)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=325638)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=325638)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=325638)     return func(*args, **kwargs)
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=325638)     return func(*args, **kwargs)
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=325638)     self.model_runner.profile_run()
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=325638)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=325638)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=325638)     return func(*args, **kwargs)
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=325638)     outputs = self.model(
(EngineCore_DP0 pid=325638)               ^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=325638)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=325638)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=325638)     model_output = self.model(
(EngineCore_DP0 pid=325638)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=325638)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=325638)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=325638)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=325638)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=325638)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=325638)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=325638)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=325638)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=325638)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=325638)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=325638)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=325638)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=325638)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=325638)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=325638)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=325638)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=325638)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=325638)     return self._linear_fn(
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=325638)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=325638)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=325638)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=325638)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=325638)     return fn(input, L)
(EngineCore_DP0 pid=325638)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=325638)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=325638)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=325638)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=325638)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=325638)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=325638)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=325638)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=325638)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=325638)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=325638)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=325638)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=325638)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=325638)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=325638)     raise PTXASError(error)
(EngineCore_DP0 pid=325638) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=325638) `ptxas` stderr:
(EngineCore_DP0 pid=325638) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=325638) 
(EngineCore_DP0 pid=325638) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp5x4g1r36.ptx -o /tmp/tmp5x4g1r36.ptx.o
(EngineCore_DP0 pid=325638) 
[rank0]:[W125 19:07:33.178606498 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 19:07:35
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:07:41 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:07:41 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=326184) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=326184) 
(EngineCore_DP0 pid=326184) 
(EngineCore_DP0 pid=326184) ================================================================
(EngineCore_DP0 pid=326184) Internal Triton PTX codegen error
(EngineCore_DP0 pid=326184) `ptxas` stderr:
(EngineCore_DP0 pid=326184) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=326184) 
(EngineCore_DP0 pid=326184) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp1jaf4nt4.ptx -o /tmp/tmp1jaf4nt4.ptx.o
(EngineCore_DP0 pid=326184) 
(EngineCore_DP0 pid=326184) 
(EngineCore_DP0 pid=326184) //
(EngineCore_DP0 pid=326184) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=326184) //
(EngineCore_DP0 pid=326184) 
(EngineCore_DP0 pid=326184) .version 8.7
(EngineCore_DP0 pid=326184) .target sm_121a
(EngineCore_DP0 pid=326184) .address_size 64
(EngineCore_DP0 pid=326184) 
(EngineCore_DP0 pid=326184) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=326184) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=326184)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=326184) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=326184) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=326184) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=326184) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=326184) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=326184) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=326184) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=326184) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=326184) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=326184) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=326184) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=326184) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=326184) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=326184) )
(EngineCore_DP0 pid=326184) .reqntid 512
(EngineCore_DP0 pid=326184) {
(EngineCore_DP0 pid=326184) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=326184) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=326184) 	.reg .b32 	%r<255>;
(EngineCore_DP0 pid=326184) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=326184) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=326184) $L__func_begin0:
(EngineCore_DP0 pid=326184) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=326184) 
(EngineCore_DP0 pid=326184) // %bb.0:
(EngineCore_DP0 pid=326184) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=326184) 	ld.param.b32 	%r28, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=326184) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=326184) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=326184) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=326184) $L__tmp0:
(EngineCore_DP0 pid=326184) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=326184) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=326184) 	ld.param.b32 	%r31, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=326184) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=326184) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=326184) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=326184) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=326184) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=326184) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=326184) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=326184) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=326184) 	mov.b32 	%r253, 0f2B8CBCCC;
(EngineCore_DP0 pid=326184) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=326184) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=326184) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=326184) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=326184) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=326184) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=326184) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=326184) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=326184) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=326184) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=326184) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=326184) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=326184) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=326184) 	mov.b32 	%r251, 0f00000000;
(EngineCore_DP0 pid=326184) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=326184) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=326184) 	mov.b32 	%r252, %r49;
(EngineCore_DP0 pid=326184) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=326184) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=326184) 	add.s32 	%r59, %r4, %r252;
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=326184) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=326184) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=326184) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=326184) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=326184) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=326184) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=326184) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=326184) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=326184) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=326184) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=326184) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=326184) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=326184) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=326184) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=326184) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=326184) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=326184) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=326184) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=326184) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=326184) $L__tmp1:
(EngineCore_DP0 pid=326184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	bar.sync 	0;
(EngineCore_DP0 pid=326184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=326184) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=326184) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=326184) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=326184) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=326184) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=326184) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=326184) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=326184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=326184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=326184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=326184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=326184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=326184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=326184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=326184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=326184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=326184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=326184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	bar.sync 	0;
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=326184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=326184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=326184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=326184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=326184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=326184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=326184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=326184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	bar.sync 	0;
(EngineCore_DP0 pid=326184) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=326184) $L__tmp2:
(EngineCore_DP0 pid=326184) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=326184) 	max.f32 	%r251, %r251, %r77;
(EngineCore_DP0 pid=326184) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=326184) 	add.s32 	%r252, %r252, 4096;
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p6, %r252, %r28;
(EngineCore_DP0 pid=326184) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=326184) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=326184) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=326184) 	max.f32 	%r253, %r251, 0f2B8CBCCC;
(EngineCore_DP0 pid=326184) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=326184) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=326184) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=326184) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=326184) 	div.full.f32 	%r80, %r253, %r79;
(EngineCore_DP0 pid=326184) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=326184) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=326184) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=326184) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=326184) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=326184) 	shl.b32 	%r15, %r29, 2;
(EngineCore_DP0 pid=326184) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=326184) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=326184) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=326184) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=326184) 	ld.param.b32 	%r33, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=326184) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=326184) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=326184) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=326184) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=326184) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=326184) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=326184) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=326184) 	div.full.f32 	%r14, %r79, %r253;
(EngineCore_DP0 pid=326184) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=326184) 	mov.b32 	%r254, 0;
(EngineCore_DP0 pid=326184) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=326184)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=326184) 	.loc	1 313 31                        // quant_slide_tuned_Llama3.2-1B.py:313:31
(EngineCore_DP0 pid=326184) 	add.s32 	%r86, %r16, %r254;
(EngineCore_DP0 pid=326184) 	or.b32 	%r87, %r254, 2;
(EngineCore_DP0 pid=326184) 	or.b32 	%r88, %r254, 3;
(EngineCore_DP0 pid=326184) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p25, %r86, %r15;
(EngineCore_DP0 pid=326184) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=326184) 	shr.s32 	%r89, %r86, 2;
(EngineCore_DP0 pid=326184) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=326184) 	add.s32 	%r90, %r254, 1;
(EngineCore_DP0 pid=326184) 	shr.s32 	%r91, %r90, 31;
(EngineCore_DP0 pid=326184) 	shr.u32 	%r92, %r91, 30;
(EngineCore_DP0 pid=326184) 	add.s32 	%r93, %r90, %r92;
(EngineCore_DP0 pid=326184) 	and.b32 	%r94, %r93, 2147483644;
(EngineCore_DP0 pid=326184) 	sub.s32 	%r95, %r90, %r94;
(EngineCore_DP0 pid=326184) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=326184) 	shl.b32 	%r96, %r95, 1;
(EngineCore_DP0 pid=326184) 	.loc	1 319 22                        // quant_slide_tuned_Llama3.2-1B.py:319:22
(EngineCore_DP0 pid=326184) 	mul.lo.s32 	%r97, %r89, 10;
(EngineCore_DP0 pid=326184) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=326184) 	add.s32 	%r98, %r97, %r96;
(EngineCore_DP0 pid=326184) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=326184) 	shr.s32 	%r99, %r254, 31;
(EngineCore_DP0 pid=326184) 	shr.u32 	%r100, %r99, 30;
(EngineCore_DP0 pid=326184) 	add.s32 	%r101, %r88, %r100;
(EngineCore_DP0 pid=326184) 	and.b32 	%r102, %r101, 2147483644;
(EngineCore_DP0 pid=326184) 	sub.s32 	%r103, %r88, %r102;
(EngineCore_DP0 pid=326184) 	add.s32 	%r104, %r87, %r100;
(EngineCore_DP0 pid=326184) 	and.b32 	%r105, %r104, 2147483644;
(EngineCore_DP0 pid=326184) 	sub.s32 	%r106, %r87, %r105;
(EngineCore_DP0 pid=326184) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=326184) 	shl.b32 	%r107, %r106, 1;
(EngineCore_DP0 pid=326184) 	shl.b32 	%r108, %r103, 1;
(EngineCore_DP0 pid=326184) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=326184) 	add.s32 	%r109, %r97, %r108;
(EngineCore_DP0 pid=326184) 	add.s32 	%r110, %r97, %r107;
(EngineCore_DP0 pid=326184) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p26, %r97, %r27;
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p27, %r98, %r27;
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p28, %r110, %r27;
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p29, %r109, %r27;
(EngineCore_DP0 pid=326184) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=326184) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=326184) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=326184) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=326184) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=326184) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=326184) 	mad.wide.s32 	%rd8, %r97, 2, %rd1;
(EngineCore_DP0 pid=326184) 	mad.wide.s32 	%rd9, %r98, 2, %rd1;
(EngineCore_DP0 pid=326184) 	mad.wide.s32 	%rd10, %r110, 2, %rd1;
(EngineCore_DP0 pid=326184) 	mad.wide.s32 	%rd11, %r109, 2, %rd1;
(EngineCore_DP0 pid=326184) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=326184) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=326184) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=326184) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=326184) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=326184) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=326184) 	cvt.f32.bf16 	%r111, %rs24;
(EngineCore_DP0 pid=326184) 	cvt.f32.bf16 	%r112, %rs26;
(EngineCore_DP0 pid=326184) 	cvt.f32.bf16 	%r113, %rs28;
(EngineCore_DP0 pid=326184) 	cvt.f32.bf16 	%r114, %rs30;
(EngineCore_DP0 pid=326184) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=326184) 	or.b32 	%r115, %r97, 1;
(EngineCore_DP0 pid=326184) 	or.b32 	%r116, %r98, 1;
(EngineCore_DP0 pid=326184) 	or.b32 	%r117, %r110, 1;
(EngineCore_DP0 pid=326184) 	or.b32 	%r118, %r109, 1;
(EngineCore_DP0 pid=326184) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p30, %r115, %r27;
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p31, %r116, %r27;
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p32, %r117, %r27;
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p33, %r118, %r27;
(EngineCore_DP0 pid=326184) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=326184) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=326184) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=326184) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=326184) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=326184) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=326184) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=326184) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=326184) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=326184) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=326184) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=326184) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=326184) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=326184) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=326184) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=326184) 	cvt.f32.bf16 	%r119, %rs32;
(EngineCore_DP0 pid=326184) 	cvt.f32.bf16 	%r120, %rs34;
(EngineCore_DP0 pid=326184) 	cvt.f32.bf16 	%r121, %rs36;
(EngineCore_DP0 pid=326184) 	cvt.f32.bf16 	%r122, %rs38;
(EngineCore_DP0 pid=326184) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=326184) 	add.s32 	%r123, %r98, 2;
(EngineCore_DP0 pid=326184) 	add.s32 	%r124, %r110, 2;
(EngineCore_DP0 pid=326184) 	add.s32 	%r125, %r109, 2;
(EngineCore_DP0 pid=326184) 	add.s32 	%r126, %r98, 3;
(EngineCore_DP0 pid=326184) 	add.s32 	%r127, %r110, 3;
(EngineCore_DP0 pid=326184) 	add.s32 	%r128, %r109, 3;
(EngineCore_DP0 pid=326184) 	add.s32 	%r129, %r97, 2;
(EngineCore_DP0 pid=326184) 	add.s32 	%r130, %r97, 3;
(EngineCore_DP0 pid=326184) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p34, %r128, %r27;
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p35, %r127, %r27;
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p36, %r126, %r27;
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p37, %r125, %r27;
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p38, %r124, %r27;
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p39, %r123, %r27;
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p40, %r130, %r27;
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p41, %r129, %r27;
(EngineCore_DP0 pid=326184) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=326184) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=326184) 	and.pred 	%p18, %p25, %p39;
(EngineCore_DP0 pid=326184) 	and.pred 	%p19, %p25, %p38;
(EngineCore_DP0 pid=326184) 	and.pred 	%p20, %p25, %p37;
(EngineCore_DP0 pid=326184) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=326184) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=326184) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=326184) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=326184) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=326184) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=326184) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=326184) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=326184) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=326184) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=326184) 	cvt.f32.bf16 	%r131, %rs40;
(EngineCore_DP0 pid=326184) 	cvt.f32.bf16 	%r132, %rs42;
(EngineCore_DP0 pid=326184) 	cvt.f32.bf16 	%r133, %rs44;
(EngineCore_DP0 pid=326184) 	cvt.f32.bf16 	%r134, %rs46;
(EngineCore_DP0 pid=326184) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=326184) 	and.pred 	%p21, %p25, %p40;
(EngineCore_DP0 pid=326184) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=326184) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=326184) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=326184) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=326184) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=326184) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=326184) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=326184) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=326184) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=326184) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=326184) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=326184) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=326184) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=326184) 	cvt.f32.bf16 	%r135, %rs48;
(EngineCore_DP0 pid=326184) 	cvt.f32.bf16 	%r136, %rs50;
(EngineCore_DP0 pid=326184) 	cvt.f32.bf16 	%r137, %rs52;
(EngineCore_DP0 pid=326184) 	cvt.f32.bf16 	%r138, %rs54;
(EngineCore_DP0 pid=326184) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=326184) 	mul.f32 	%r139, %r14, %r111;
(EngineCore_DP0 pid=326184) 	mul.f32 	%r140, %r14, %r112;
(EngineCore_DP0 pid=326184) 	mul.f32 	%r141, %r14, %r113;
(EngineCore_DP0 pid=326184) 	mul.f32 	%r142, %r14, %r114;
(EngineCore_DP0 pid=326184) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=326184) 	cvt.rni.f32.f32 	%r143, %r139;
(EngineCore_DP0 pid=326184) 	cvt.rni.f32.f32 	%r144, %r140;
(EngineCore_DP0 pid=326184) 	cvt.rni.f32.f32 	%r145, %r141;
(EngineCore_DP0 pid=326184) 	cvt.rni.f32.f32 	%r146, %r142;
(EngineCore_DP0 pid=326184) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=326184) 	max.f32 	%r147, %r143, 0fC3000000;
(EngineCore_DP0 pid=326184) 	min.f32 	%r148, %r147, 0f42FE0000;
(EngineCore_DP0 pid=326184) 	max.f32 	%r149, %r144, 0fC3000000;
(EngineCore_DP0 pid=326184) 	min.f32 	%r150, %r149, 0f42FE0000;
(EngineCore_DP0 pid=326184) 	max.f32 	%r151, %r145, 0fC3000000;
(EngineCore_DP0 pid=326184) 	min.f32 	%r152, %r151, 0f42FE0000;
(EngineCore_DP0 pid=326184) 	max.f32 	%r153, %r146, 0fC3000000;
(EngineCore_DP0 pid=326184) 	min.f32 	%r154, %r153, 0f42FE0000;
(EngineCore_DP0 pid=326184) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=326184) 	cvt.rzi.s32.f32 	%r155, %r148;
(EngineCore_DP0 pid=326184) 	cvt.rzi.s32.f32 	%r156, %r150;
(EngineCore_DP0 pid=326184) 	cvt.rzi.s32.f32 	%r157, %r152;
(EngineCore_DP0 pid=326184) 	cvt.rzi.s32.f32 	%r158, %r154;
(EngineCore_DP0 pid=326184) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=326184) 	and.b32 	%r159, %r155, 255;
(EngineCore_DP0 pid=326184) 	and.b32 	%r160, %r156, 255;
(EngineCore_DP0 pid=326184) 	and.b32 	%r161, %r157, 255;
(EngineCore_DP0 pid=326184) 	and.b32 	%r162, %r158, 255;
(EngineCore_DP0 pid=326184) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=326184) 	mul.f32 	%r163, %r14, %r119;
(EngineCore_DP0 pid=326184) 	mul.f32 	%r164, %r14, %r120;
(EngineCore_DP0 pid=326184) 	mul.f32 	%r165, %r14, %r121;
(EngineCore_DP0 pid=326184) 	mul.f32 	%r166, %r14, %r122;
(EngineCore_DP0 pid=326184) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=326184) 	cvt.rni.f32.f32 	%r167, %r163;
(EngineCore_DP0 pid=326184) 	cvt.rni.f32.f32 	%r168, %r164;
(EngineCore_DP0 pid=326184) 	cvt.rni.f32.f32 	%r169, %r165;
(EngineCore_DP0 pid=326184) 	cvt.rni.f32.f32 	%r170, %r166;
(EngineCore_DP0 pid=326184) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=326184) 	mul.f32 	%r171, %r14, %r131;
(EngineCore_DP0 pid=326184) 	mul.f32 	%r172, %r14, %r132;
(EngineCore_DP0 pid=326184) 	mul.f32 	%r173, %r14, %r133;
(EngineCore_DP0 pid=326184) 	mul.f32 	%r174, %r14, %r134;
(EngineCore_DP0 pid=326184) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=326184) 	cvt.rni.f32.f32 	%r175, %r171;
(EngineCore_DP0 pid=326184) 	cvt.rni.f32.f32 	%r176, %r172;
(EngineCore_DP0 pid=326184) 	cvt.rni.f32.f32 	%r177, %r173;
(EngineCore_DP0 pid=326184) 	cvt.rni.f32.f32 	%r178, %r174;
(EngineCore_DP0 pid=326184) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=326184) 	mul.f32 	%r179, %r14, %r135;
(EngineCore_DP0 pid=326184) 	mul.f32 	%r180, %r14, %r136;
(EngineCore_DP0 pid=326184) 	mul.f32 	%r181, %r14, %r137;
(EngineCore_DP0 pid=326184) 	mul.f32 	%r182, %r14, %r138;
(EngineCore_DP0 pid=326184) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=326184) 	cvt.rni.f32.f32 	%r183, %r179;
(EngineCore_DP0 pid=326184) 	cvt.rni.f32.f32 	%r184, %r180;
(EngineCore_DP0 pid=326184) 	cvt.rni.f32.f32 	%r185, %r181;
(EngineCore_DP0 pid=326184) 	cvt.rni.f32.f32 	%r186, %r182;
(EngineCore_DP0 pid=326184) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=326184) 	max.f32 	%r187, %r183, 0fC3000000;
(EngineCore_DP0 pid=326184) 	min.f32 	%r188, %r187, 0f42FE0000;
(EngineCore_DP0 pid=326184) 	max.f32 	%r189, %r184, 0fC3000000;
(EngineCore_DP0 pid=326184) 	min.f32 	%r190, %r189, 0f42FE0000;
(EngineCore_DP0 pid=326184) 	max.f32 	%r191, %r185, 0fC3000000;
(EngineCore_DP0 pid=326184) 	min.f32 	%r192, %r191, 0f42FE0000;
(EngineCore_DP0 pid=326184) 	max.f32 	%r193, %r186, 0fC3000000;
(EngineCore_DP0 pid=326184) 	min.f32 	%r194, %r193, 0f42FE0000;
(EngineCore_DP0 pid=326184) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=326184) 	cvt.rzi.s32.f32 	%r195, %r188;
(EngineCore_DP0 pid=326184) 	cvt.rzi.s32.f32 	%r196, %r190;
(EngineCore_DP0 pid=326184) 	cvt.rzi.s32.f32 	%r197, %r192;
(EngineCore_DP0 pid=326184) 	cvt.rzi.s32.f32 	%r198, %r194;
(EngineCore_DP0 pid=326184) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=326184) 	max.f32 	%r199, %r175, 0fC3000000;
(EngineCore_DP0 pid=326184) 	max.f32 	%r200, %r167, 0fC3000000;
(EngineCore_DP0 pid=326184) 	min.f32 	%r201, %r200, 0f42FE0000;
(EngineCore_DP0 pid=326184) 	min.f32 	%r202, %r199, 0f42FE0000;
(EngineCore_DP0 pid=326184) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=326184) 	cvt.rzi.s32.f32 	%r203, %r202;
(EngineCore_DP0 pid=326184) 	cvt.rzi.s32.f32 	%r204, %r201;
(EngineCore_DP0 pid=326184) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=326184) 	shl.b32 	%r205, %r204, 8;
(EngineCore_DP0 pid=326184) 	shl.b32 	%r206, %r203, 16;
(EngineCore_DP0 pid=326184) 	and.b32 	%r207, %r206, 16711680;
(EngineCore_DP0 pid=326184) 	and.b32 	%r208, %r205, 65280;
(EngineCore_DP0 pid=326184) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=326184) 	or.b32 	%r209, %r208, %r159;
(EngineCore_DP0 pid=326184) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=326184) 	max.f32 	%r210, %r176, 0fC3000000;
(EngineCore_DP0 pid=326184) 	max.f32 	%r211, %r168, 0fC3000000;
(EngineCore_DP0 pid=326184) 	min.f32 	%r212, %r211, 0f42FE0000;
(EngineCore_DP0 pid=326184) 	min.f32 	%r213, %r210, 0f42FE0000;
(EngineCore_DP0 pid=326184) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=326184) 	cvt.rzi.s32.f32 	%r214, %r213;
(EngineCore_DP0 pid=326184) 	cvt.rzi.s32.f32 	%r215, %r212;
(EngineCore_DP0 pid=326184) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=326184) 	shl.b32 	%r216, %r215, 8;
(EngineCore_DP0 pid=326184) 	shl.b32 	%r217, %r214, 16;
(EngineCore_DP0 pid=326184) 	and.b32 	%r218, %r217, 16711680;
(EngineCore_DP0 pid=326184) 	and.b32 	%r219, %r216, 65280;
(EngineCore_DP0 pid=326184) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=326184) 	or.b32 	%r220, %r219, %r160;
(EngineCore_DP0 pid=326184) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=326184) 	max.f32 	%r221, %r177, 0fC3000000;
(EngineCore_DP0 pid=326184) 	max.f32 	%r222, %r169, 0fC3000000;
(EngineCore_DP0 pid=326184) 	min.f32 	%r223, %r222, 0f42FE0000;
(EngineCore_DP0 pid=326184) 	min.f32 	%r224, %r221, 0f42FE0000;
(EngineCore_DP0 pid=326184) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=326184) 	cvt.rzi.s32.f32 	%r225, %r224;
(EngineCore_DP0 pid=326184) 	cvt.rzi.s32.f32 	%r226, %r223;
(EngineCore_DP0 pid=326184) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=326184) 	shl.b32 	%r227, %r226, 8;
(EngineCore_DP0 pid=326184) 	shl.b32 	%r228, %r225, 16;
(EngineCore_DP0 pid=326184) 	and.b32 	%r229, %r228, 16711680;
(EngineCore_DP0 pid=326184) 	and.b32 	%r230, %r227, 65280;
(EngineCore_DP0 pid=326184) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=326184) 	or.b32 	%r231, %r230, %r161;
(EngineCore_DP0 pid=326184) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=326184) 	max.f32 	%r232, %r178, 0fC3000000;
(EngineCore_DP0 pid=326184) 	max.f32 	%r233, %r170, 0fC3000000;
(EngineCore_DP0 pid=326184) 	min.f32 	%r234, %r233, 0f42FE0000;
(EngineCore_DP0 pid=326184) 	min.f32 	%r235, %r232, 0f42FE0000;
(EngineCore_DP0 pid=326184) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=326184) 	cvt.rzi.s32.f32 	%r236, %r235;
(EngineCore_DP0 pid=326184) 	cvt.rzi.s32.f32 	%r237, %r234;
(EngineCore_DP0 pid=326184) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=326184) 	shl.b32 	%r238, %r237, 8;
(EngineCore_DP0 pid=326184) 	shl.b32 	%r239, %r236, 16;
(EngineCore_DP0 pid=326184) 	and.b32 	%r240, %r239, 16711680;
(EngineCore_DP0 pid=326184) 	and.b32 	%r241, %r238, 65280;
(EngineCore_DP0 pid=326184) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=326184) 	or.b32 	%r242, %r241, %r162;
(EngineCore_DP0 pid=326184) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=326184) 	or.b32 	%r243, %r209, %r207;
(EngineCore_DP0 pid=326184) 	or.b32 	%r244, %r220, %r218;
(EngineCore_DP0 pid=326184) 	or.b32 	%r245, %r231, %r229;
(EngineCore_DP0 pid=326184) 	or.b32 	%r246, %r242, %r240;
(EngineCore_DP0 pid=326184) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=326184) 	shl.b32 	%r247, %r195, 24;
(EngineCore_DP0 pid=326184) 	shl.b32 	%r248, %r196, 24;
(EngineCore_DP0 pid=326184) 	shl.b32 	%r249, %r197, 24;
(EngineCore_DP0 pid=326184) 	shl.b32 	%r250, %r198, 24;
(EngineCore_DP0 pid=326184) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=326184) 	or.b32 	%r82, %r243, %r247;
(EngineCore_DP0 pid=326184) 	or.b32 	%r83, %r244, %r248;
(EngineCore_DP0 pid=326184) 	or.b32 	%r84, %r245, %r249;
(EngineCore_DP0 pid=326184) 	or.b32 	%r85, %r246, %r250;
(EngineCore_DP0 pid=326184) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=326184) 	mad.wide.s32 	%rd24, %r86, 4, %rd2;
(EngineCore_DP0 pid=326184) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=326184) 	// begin inline asm
(EngineCore_DP0 pid=326184) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r82, %r83, %r84, %r85 };
(EngineCore_DP0 pid=326184) 	// end inline asm
(EngineCore_DP0 pid=326184) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=326184) 	add.s32 	%r254, %r254, 2048;
(EngineCore_DP0 pid=326184) 	setp.lt.s32 	%p42, %r254, %r15;
(EngineCore_DP0 pid=326184) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=326184) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=326184) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=326184) 	ret;
(EngineCore_DP0 pid=326184) $L__tmp3:
(EngineCore_DP0 pid=326184) $L__func_end0:
(EngineCore_DP0 pid=326184)                                         // -- End function
(EngineCore_DP0 pid=326184) }
(EngineCore_DP0 pid=326184) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=326184) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=326184) 	.section	.debug_abbrev
(EngineCore_DP0 pid=326184) 	{
(EngineCore_DP0 pid=326184) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=326184) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=326184) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=326184) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=326184) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=326184) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=326184) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=326184) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=326184) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=326184) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=326184) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=326184) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=326184) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=326184) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=326184) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=326184) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=326184) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=326184) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=326184) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=326184) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=326184) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=326184) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=326184) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=326184) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=326184) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=326184) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=326184) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=326184) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=326184) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=326184) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=326184) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=326184) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=326184) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=326184) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=326184) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=326184) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=326184) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=326184) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=326184) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=326184) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=326184) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=326184) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=326184) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=326184) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=326184) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=326184) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=326184) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=326184) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=326184) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=326184) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=326184) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=326184) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=326184) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=326184) 	}
(EngineCore_DP0 pid=326184) 	.section	.debug_info
(EngineCore_DP0 pid=326184) 	{
(EngineCore_DP0 pid=326184) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=326184) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=326184) .b8 0
(EngineCore_DP0 pid=326184) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=326184) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=326184) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=326184) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=326184) .b8 114
(EngineCore_DP0 pid=326184) .b8 105
(EngineCore_DP0 pid=326184) .b8 116
(EngineCore_DP0 pid=326184) .b8 111
(EngineCore_DP0 pid=326184) .b8 110
(EngineCore_DP0 pid=326184) .b8 0
(EngineCore_DP0 pid=326184) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=326184) .b8 0
(EngineCore_DP0 pid=326184) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=326184) .b8 117
(EngineCore_DP0 pid=326184) .b8 97
(EngineCore_DP0 pid=326184) .b8 110
(EngineCore_DP0 pid=326184) .b8 116
(EngineCore_DP0 pid=326184) .b8 95
(EngineCore_DP0 pid=326184) .b8 115
(EngineCore_DP0 pid=326184) .b8 108
(EngineCore_DP0 pid=326184) .b8 105
(EngineCore_DP0 pid=326184) .b8 100
(EngineCore_DP0 pid=326184) .b8 101
(EngineCore_DP0 pid=326184) .b8 95
(EngineCore_DP0 pid=326184) .b8 116
(EngineCore_DP0 pid=326184) .b8 117
(EngineCore_DP0 pid=326184) .b8 110
(EngineCore_DP0 pid=326184) .b8 101
(EngineCore_DP0 pid=326184) .b8 100
(EngineCore_DP0 pid=326184) .b8 95
(EngineCore_DP0 pid=326184) .b8 76
(EngineCore_DP0 pid=326184) .b8 108
(EngineCore_DP0 pid=326184) .b8 97
(EngineCore_DP0 pid=326184) .b8 109
(EngineCore_DP0 pid=326184) .b8 97
(EngineCore_DP0 pid=326184) .b8 51
(EngineCore_DP0 pid=326184) .b8 46
(EngineCore_DP0 pid=326184) .b8 50
(EngineCore_DP0 pid=326184) .b8 45
(EngineCore_DP0 pid=326184) .b8 49
(EngineCore_DP0 pid=326184) .b8 66
(EngineCore_DP0 pid=326184) .b8 46
(EngineCore_DP0 pid=326184) .b8 112
(EngineCore_DP0 pid=326184) .b8 121
(EngineCore_DP0 pid=326184) .b8 0
(EngineCore_DP0 pid=326184) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=326184) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=326184) .b8 114
(EngineCore_DP0 pid=326184) .b8 111
(EngineCore_DP0 pid=326184) .b8 111
(EngineCore_DP0 pid=326184) .b8 116
(EngineCore_DP0 pid=326184) .b8 47
(EngineCore_DP0 pid=326184) .b8 118
(EngineCore_DP0 pid=326184) .b8 108
(EngineCore_DP0 pid=326184) .b8 108
(EngineCore_DP0 pid=326184) .b8 109
(EngineCore_DP0 pid=326184) .b8 98
(EngineCore_DP0 pid=326184) .b8 101
(EngineCore_DP0 pid=326184) .b8 110
(EngineCore_DP0 pid=326184) .b8 99
(EngineCore_DP0 pid=326184) .b8 104
(EngineCore_DP0 pid=326184) .b8 47
(EngineCore_DP0 pid=326184) .b8 115
(EngineCore_DP0 pid=326184) .b8 108
(EngineCore_DP0 pid=326184) .b8 105
(EngineCore_DP0 pid=326184) .b8 100
(EngineCore_DP0 pid=326184) .b8 101
(EngineCore_DP0 pid=326184) .b8 115
(EngineCore_DP0 pid=326184) .b8 112
(EngineCore_DP0 pid=326184) .b8 97
(EngineCore_DP0 pid=326184) .b8 114
(EngineCore_DP0 pid=326184) .b8 115
(EngineCore_DP0 pid=326184) .b8 101
(EngineCore_DP0 pid=326184) .b8 47
(EngineCore_DP0 pid=326184) .b8 99
(EngineCore_DP0 pid=326184) .b8 115
(EngineCore_DP0 pid=326184) .b8 114
(EngineCore_DP0 pid=326184) .b8 99
(EngineCore_DP0 pid=326184) .b8 47
(EngineCore_DP0 pid=326184) .b8 102
(EngineCore_DP0 pid=326184) .b8 117
(EngineCore_DP0 pid=326184) .b8 115
(EngineCore_DP0 pid=326184) .b8 101
(EngineCore_DP0 pid=326184) .b8 100
(EngineCore_DP0 pid=326184) .b8 95
(EngineCore_DP0 pid=326184) .b8 113
(EngineCore_DP0 pid=326184) .b8 117
(EngineCore_DP0 pid=326184) .b8 97
(EngineCore_DP0 pid=326184) .b8 110
(EngineCore_DP0 pid=326184) .b8 116
(EngineCore_DP0 pid=326184) .b8 95
(EngineCore_DP0 pid=326184) .b8 115
(EngineCore_DP0 pid=326184) .b8 108
(EngineCore_DP0 pid=326184) .b8 105
(EngineCore_DP0 pid=326184) .b8 100
(EngineCore_DP0 pid=326184) .b8 101
(EngineCore_DP0 pid=326184) .b8 95
(EngineCore_DP0 pid=326184) .b8 116
(EngineCore_DP0 pid=326184) .b8 114
(EngineCore_DP0 pid=326184) .b8 105
(EngineCore_DP0 pid=326184) .b8 116
(EngineCore_DP0 pid=326184) .b8 111
(EngineCore_DP0 pid=326184) .b8 110
(EngineCore_DP0 pid=326184) .b8 47
(EngineCore_DP0 pid=326184) .b8 98
(EngineCore_DP0 pid=326184) .b8 117
(EngineCore_DP0 pid=326184) .b8 105
(EngineCore_DP0 pid=326184) .b8 108
(EngineCore_DP0 pid=326184) .b8 100
(EngineCore_DP0 pid=326184) .b8 47
(EngineCore_DP0 pid=326184) .b8 71
(EngineCore_DP0 pid=326184) .b8 66
(EngineCore_DP0 pid=326184) .b8 49
(EngineCore_DP0 pid=326184) .b8 48
(EngineCore_DP0 pid=326184) .b8 95
(EngineCore_DP0 pid=326184) .b8 99
(EngineCore_DP0 pid=326184) .b8 99
(EngineCore_DP0 pid=326184) .b8 49
(EngineCore_DP0 pid=326184) .b8 50
(EngineCore_DP0 pid=326184) .b8 49
(EngineCore_DP0 pid=326184) .b8 95
(EngineCore_DP0 pid=326184) .b8 112
(EngineCore_DP0 pid=326184) .b8 121
(EngineCore_DP0 pid=326184) .b8 51
(EngineCore_DP0 pid=326184) .b8 49
(EngineCore_DP0 pid=326184) .b8 50
(EngineCore_DP0 pid=326184) .b8 95
(EngineCore_DP0 pid=326184) .b8 99
(EngineCore_DP0 pid=326184) .b8 117
(EngineCore_DP0 pid=326184) .b8 49
(EngineCore_DP0 pid=326184) .b8 50
(EngineCore_DP0 pid=326184) .b8 57
(EngineCore_DP0 pid=326184) .b8 95
(EngineCore_DP0 pid=326184) .b8 97
(EngineCore_DP0 pid=326184) .b8 97
(EngineCore_DP0 pid=326184) .b8 114
(EngineCore_DP0 pid=326184) .b8 99
(EngineCore_DP0 pid=326184) .b8 104
(EngineCore_DP0 pid=326184) .b8 54
(EngineCore_DP0 pid=326184) .b8 52
(EngineCore_DP0 pid=326184) .b8 0
(EngineCore_DP0 pid=326184) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=326184) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=326184) .b8 113
(EngineCore_DP0 pid=326184) .b8 117
(EngineCore_DP0 pid=326184) .b8 97
(EngineCore_DP0 pid=326184) .b8 110
(EngineCore_DP0 pid=326184) .b8 116
(EngineCore_DP0 pid=326184) .b8 95
(EngineCore_DP0 pid=326184) .b8 115
(EngineCore_DP0 pid=326184) .b8 108
(EngineCore_DP0 pid=326184) .b8 105
(EngineCore_DP0 pid=326184) .b8 100
(EngineCore_DP0 pid=326184) .b8 101
(EngineCore_DP0 pid=326184) .b8 95
(EngineCore_DP0 pid=326184) .b8 105
(EngineCore_DP0 pid=326184) .b8 110
(EngineCore_DP0 pid=326184) .b8 116
(EngineCore_DP0 pid=326184) .b8 56
(EngineCore_DP0 pid=326184) .b8 95
(EngineCore_DP0 pid=326184) .b8 107
(EngineCore_DP0 pid=326184) .b8 101
(EngineCore_DP0 pid=326184) .b8 114
(EngineCore_DP0 pid=326184) .b8 110
(EngineCore_DP0 pid=326184) .b8 101
(EngineCore_DP0 pid=326184) .b8 108
(EngineCore_DP0 pid=326184) .b8 0
(EngineCore_DP0 pid=326184) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=326184) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=326184) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=326184) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=326184) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=326184) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=326184) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=326184) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=326184) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=326184) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=326184) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=326184) .b8 1
(EngineCore_DP0 pid=326184) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=326184) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=326184) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=326184) 	}
(EngineCore_DP0 pid=326184) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=326184) 
(EngineCore_DP0 pid=326184) ================================================================
(EngineCore_DP0 pid=326184) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=326184) 
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp1jaf4nt4.ptx', '-o', '/tmp/tmp1jaf4nt4.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866] 
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866] 
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866] 
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp1jaf4nt4.ptx -o /tmp/tmp1jaf4nt4.ptx.o
(EngineCore_DP0 pid=326184) ERROR 01-25 19:07:58 [core.py:866] 

STDERR:
[2026-01-25 19:07:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:07:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:07:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:07:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:07:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:07:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:07:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:07:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:07:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:07:45] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:07:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:07:45] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:07:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:07:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:07:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:07:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:07:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:07:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:07:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=326184) [2026-01-25 19:07:46] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=326184) [2026-01-25 19:07:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=326184) [2026-01-25 19:07:46] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=326184) [2026-01-25 19:07:46] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=326184) [2026-01-25 19:07:46] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=326184) [2026-01-25 19:07:46] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=326184) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=326184) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.98s/it]
(EngineCore_DP0 pid=326184) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.98s/it]
(EngineCore_DP0 pid=326184) 
(EngineCore_DP0 pid=326184) [2026-01-25 19:07:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=326184) [2026-01-25 19:07:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=326184) [2026-01-25 19:07:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=326184) [2026-01-25 19:07:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=326184) [2026-01-25 19:07:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=326184) [2026-01-25 19:07:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=326184) [2026-01-25 19:07:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=326184) [2026-01-25 19:07:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=326184) Process EngineCore_DP0:
(EngineCore_DP0 pid=326184) Traceback (most recent call last):
(EngineCore_DP0 pid=326184)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=326184)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=326184)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=326184)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=326184) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp1jaf4nt4.ptx', '-o', '/tmp/tmp1jaf4nt4.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=326184) 
(EngineCore_DP0 pid=326184) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=326184) 
(EngineCore_DP0 pid=326184) Traceback (most recent call last):
(EngineCore_DP0 pid=326184)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=326184)     self.run()
(EngineCore_DP0 pid=326184)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=326184)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=326184)     raise e
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=326184)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=326184)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=326184)     super().__init__(
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=326184)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=326184)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=326184)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=326184)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=326184)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=326184)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=326184)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=326184)     return func(*args, **kwargs)
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=326184)     return func(*args, **kwargs)
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=326184)     self.model_runner.profile_run()
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=326184)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=326184)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=326184)     return func(*args, **kwargs)
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=326184)     outputs = self.model(
(EngineCore_DP0 pid=326184)               ^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=326184)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=326184)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=326184)     model_output = self.model(
(EngineCore_DP0 pid=326184)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=326184)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=326184)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=326184)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=326184)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=326184)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=326184)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=326184)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=326184)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=326184)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=326184)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=326184)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=326184)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=326184)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=326184)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=326184)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=326184)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=326184)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=326184)     return self._linear_fn(
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=326184)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=326184)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=326184)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=326184)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=326184)     return fn(input, L)
(EngineCore_DP0 pid=326184)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=326184)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=326184)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=326184)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=326184)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=326184)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=326184)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=326184)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=326184)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=326184)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=326184)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=326184)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=326184)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326184)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=326184)     raise PTXASError(error)
(EngineCore_DP0 pid=326184) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=326184) `ptxas` stderr:
(EngineCore_DP0 pid=326184) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=326184) 
(EngineCore_DP0 pid=326184) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp1jaf4nt4.ptx -o /tmp/tmp1jaf4nt4.ptx.o
(EngineCore_DP0 pid=326184) 
[rank0]:[W125 19:07:59.333653911 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 19:08:00
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:08:09 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:08:09 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=326741) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=326741) 
(EngineCore_DP0 pid=326741) 
(EngineCore_DP0 pid=326741) ================================================================
(EngineCore_DP0 pid=326741) Internal Triton PTX codegen error
(EngineCore_DP0 pid=326741) `ptxas` stderr:
(EngineCore_DP0 pid=326741) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=326741) 
(EngineCore_DP0 pid=326741) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpvskq4smh.ptx -o /tmp/tmpvskq4smh.ptx.o
(EngineCore_DP0 pid=326741) 
(EngineCore_DP0 pid=326741) 
(EngineCore_DP0 pid=326741) //
(EngineCore_DP0 pid=326741) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=326741) //
(EngineCore_DP0 pid=326741) 
(EngineCore_DP0 pid=326741) .version 8.7
(EngineCore_DP0 pid=326741) .target sm_121a
(EngineCore_DP0 pid=326741) .address_size 64
(EngineCore_DP0 pid=326741) 
(EngineCore_DP0 pid=326741) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=326741) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=326741)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=326741) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=326741) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=326741) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=326741) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=326741) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=326741) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=326741) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=326741) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=326741) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=326741) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=326741) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=326741) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=326741) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=326741) )
(EngineCore_DP0 pid=326741) .reqntid 512
(EngineCore_DP0 pid=326741) {
(EngineCore_DP0 pid=326741) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=326741) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=326741) 	.reg .b32 	%r<255>;
(EngineCore_DP0 pid=326741) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=326741) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=326741) $L__func_begin0:
(EngineCore_DP0 pid=326741) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=326741) 
(EngineCore_DP0 pid=326741) // %bb.0:
(EngineCore_DP0 pid=326741) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=326741) 	ld.param.b32 	%r28, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=326741) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=326741) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=326741) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=326741) $L__tmp0:
(EngineCore_DP0 pid=326741) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=326741) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=326741) 	ld.param.b32 	%r31, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=326741) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=326741) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=326741) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=326741) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=326741) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=326741) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=326741) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=326741) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=326741) 	mov.b32 	%r253, 0f2B8CBCCC;
(EngineCore_DP0 pid=326741) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=326741) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=326741) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=326741) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=326741) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=326741) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=326741) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=326741) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=326741) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=326741) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=326741) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=326741) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=326741) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=326741) 	mov.b32 	%r251, 0f00000000;
(EngineCore_DP0 pid=326741) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=326741) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=326741) 	mov.b32 	%r252, %r49;
(EngineCore_DP0 pid=326741) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=326741) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=326741) 	add.s32 	%r59, %r4, %r252;
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=326741) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=326741) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=326741) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=326741) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=326741) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=326741) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=326741) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=326741) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=326741) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=326741) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=326741) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=326741) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=326741) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=326741) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=326741) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=326741) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=326741) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=326741) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=326741) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=326741) $L__tmp1:
(EngineCore_DP0 pid=326741) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	bar.sync 	0;
(EngineCore_DP0 pid=326741) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=326741) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=326741) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=326741) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=326741) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=326741) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=326741) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=326741) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=326741) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=326741) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=326741) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=326741) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=326741) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=326741) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=326741) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=326741) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=326741) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=326741) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=326741) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	bar.sync 	0;
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=326741) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=326741) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=326741) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=326741) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=326741) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=326741) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=326741) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=326741) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	bar.sync 	0;
(EngineCore_DP0 pid=326741) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=326741) $L__tmp2:
(EngineCore_DP0 pid=326741) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=326741) 	max.f32 	%r251, %r251, %r77;
(EngineCore_DP0 pid=326741) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=326741) 	add.s32 	%r252, %r252, 4096;
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p6, %r252, %r28;
(EngineCore_DP0 pid=326741) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=326741) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=326741) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=326741) 	max.f32 	%r253, %r251, 0f2B8CBCCC;
(EngineCore_DP0 pid=326741) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=326741) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=326741) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=326741) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=326741) 	div.full.f32 	%r80, %r253, %r79;
(EngineCore_DP0 pid=326741) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=326741) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=326741) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=326741) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=326741) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=326741) 	shl.b32 	%r15, %r29, 2;
(EngineCore_DP0 pid=326741) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=326741) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=326741) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=326741) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=326741) 	ld.param.b32 	%r33, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=326741) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=326741) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=326741) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=326741) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=326741) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=326741) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=326741) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=326741) 	div.full.f32 	%r14, %r79, %r253;
(EngineCore_DP0 pid=326741) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=326741) 	mov.b32 	%r254, 0;
(EngineCore_DP0 pid=326741) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=326741)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=326741) 	.loc	1 313 31                        // quant_slide_tuned_Llama3.2-1B.py:313:31
(EngineCore_DP0 pid=326741) 	add.s32 	%r86, %r16, %r254;
(EngineCore_DP0 pid=326741) 	or.b32 	%r87, %r254, 2;
(EngineCore_DP0 pid=326741) 	or.b32 	%r88, %r254, 3;
(EngineCore_DP0 pid=326741) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p25, %r86, %r15;
(EngineCore_DP0 pid=326741) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=326741) 	shr.s32 	%r89, %r86, 2;
(EngineCore_DP0 pid=326741) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=326741) 	add.s32 	%r90, %r254, 1;
(EngineCore_DP0 pid=326741) 	shr.s32 	%r91, %r90, 31;
(EngineCore_DP0 pid=326741) 	shr.u32 	%r92, %r91, 30;
(EngineCore_DP0 pid=326741) 	add.s32 	%r93, %r90, %r92;
(EngineCore_DP0 pid=326741) 	and.b32 	%r94, %r93, 2147483644;
(EngineCore_DP0 pid=326741) 	sub.s32 	%r95, %r90, %r94;
(EngineCore_DP0 pid=326741) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=326741) 	shl.b32 	%r96, %r95, 1;
(EngineCore_DP0 pid=326741) 	.loc	1 319 22                        // quant_slide_tuned_Llama3.2-1B.py:319:22
(EngineCore_DP0 pid=326741) 	mul.lo.s32 	%r97, %r89, 10;
(EngineCore_DP0 pid=326741) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=326741) 	add.s32 	%r98, %r97, %r96;
(EngineCore_DP0 pid=326741) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=326741) 	shr.s32 	%r99, %r254, 31;
(EngineCore_DP0 pid=326741) 	shr.u32 	%r100, %r99, 30;
(EngineCore_DP0 pid=326741) 	add.s32 	%r101, %r88, %r100;
(EngineCore_DP0 pid=326741) 	and.b32 	%r102, %r101, 2147483644;
(EngineCore_DP0 pid=326741) 	sub.s32 	%r103, %r88, %r102;
(EngineCore_DP0 pid=326741) 	add.s32 	%r104, %r87, %r100;
(EngineCore_DP0 pid=326741) 	and.b32 	%r105, %r104, 2147483644;
(EngineCore_DP0 pid=326741) 	sub.s32 	%r106, %r87, %r105;
(EngineCore_DP0 pid=326741) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=326741) 	shl.b32 	%r107, %r106, 1;
(EngineCore_DP0 pid=326741) 	shl.b32 	%r108, %r103, 1;
(EngineCore_DP0 pid=326741) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=326741) 	add.s32 	%r109, %r97, %r108;
(EngineCore_DP0 pid=326741) 	add.s32 	%r110, %r97, %r107;
(EngineCore_DP0 pid=326741) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p26, %r97, %r27;
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p27, %r98, %r27;
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p28, %r110, %r27;
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p29, %r109, %r27;
(EngineCore_DP0 pid=326741) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=326741) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=326741) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=326741) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=326741) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=326741) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=326741) 	mad.wide.s32 	%rd8, %r97, 2, %rd1;
(EngineCore_DP0 pid=326741) 	mad.wide.s32 	%rd9, %r98, 2, %rd1;
(EngineCore_DP0 pid=326741) 	mad.wide.s32 	%rd10, %r110, 2, %rd1;
(EngineCore_DP0 pid=326741) 	mad.wide.s32 	%rd11, %r109, 2, %rd1;
(EngineCore_DP0 pid=326741) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=326741) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=326741) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=326741) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=326741) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=326741) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=326741) 	cvt.f32.bf16 	%r111, %rs24;
(EngineCore_DP0 pid=326741) 	cvt.f32.bf16 	%r112, %rs26;
(EngineCore_DP0 pid=326741) 	cvt.f32.bf16 	%r113, %rs28;
(EngineCore_DP0 pid=326741) 	cvt.f32.bf16 	%r114, %rs30;
(EngineCore_DP0 pid=326741) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=326741) 	or.b32 	%r115, %r97, 1;
(EngineCore_DP0 pid=326741) 	or.b32 	%r116, %r98, 1;
(EngineCore_DP0 pid=326741) 	or.b32 	%r117, %r110, 1;
(EngineCore_DP0 pid=326741) 	or.b32 	%r118, %r109, 1;
(EngineCore_DP0 pid=326741) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p30, %r115, %r27;
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p31, %r116, %r27;
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p32, %r117, %r27;
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p33, %r118, %r27;
(EngineCore_DP0 pid=326741) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=326741) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=326741) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=326741) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=326741) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=326741) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=326741) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=326741) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=326741) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=326741) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=326741) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=326741) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=326741) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=326741) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=326741) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=326741) 	cvt.f32.bf16 	%r119, %rs32;
(EngineCore_DP0 pid=326741) 	cvt.f32.bf16 	%r120, %rs34;
(EngineCore_DP0 pid=326741) 	cvt.f32.bf16 	%r121, %rs36;
(EngineCore_DP0 pid=326741) 	cvt.f32.bf16 	%r122, %rs38;
(EngineCore_DP0 pid=326741) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=326741) 	add.s32 	%r123, %r98, 2;
(EngineCore_DP0 pid=326741) 	add.s32 	%r124, %r110, 2;
(EngineCore_DP0 pid=326741) 	add.s32 	%r125, %r109, 2;
(EngineCore_DP0 pid=326741) 	add.s32 	%r126, %r98, 3;
(EngineCore_DP0 pid=326741) 	add.s32 	%r127, %r110, 3;
(EngineCore_DP0 pid=326741) 	add.s32 	%r128, %r109, 3;
(EngineCore_DP0 pid=326741) 	add.s32 	%r129, %r97, 2;
(EngineCore_DP0 pid=326741) 	add.s32 	%r130, %r97, 3;
(EngineCore_DP0 pid=326741) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p34, %r128, %r27;
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p35, %r127, %r27;
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p36, %r126, %r27;
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p37, %r125, %r27;
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p38, %r124, %r27;
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p39, %r123, %r27;
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p40, %r130, %r27;
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p41, %r129, %r27;
(EngineCore_DP0 pid=326741) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=326741) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=326741) 	and.pred 	%p18, %p25, %p39;
(EngineCore_DP0 pid=326741) 	and.pred 	%p19, %p25, %p38;
(EngineCore_DP0 pid=326741) 	and.pred 	%p20, %p25, %p37;
(EngineCore_DP0 pid=326741) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=326741) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=326741) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=326741) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=326741) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=326741) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=326741) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=326741) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=326741) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=326741) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=326741) 	cvt.f32.bf16 	%r131, %rs40;
(EngineCore_DP0 pid=326741) 	cvt.f32.bf16 	%r132, %rs42;
(EngineCore_DP0 pid=326741) 	cvt.f32.bf16 	%r133, %rs44;
(EngineCore_DP0 pid=326741) 	cvt.f32.bf16 	%r134, %rs46;
(EngineCore_DP0 pid=326741) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=326741) 	and.pred 	%p21, %p25, %p40;
(EngineCore_DP0 pid=326741) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=326741) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=326741) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=326741) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=326741) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=326741) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=326741) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=326741) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=326741) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=326741) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=326741) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=326741) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=326741) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=326741) 	cvt.f32.bf16 	%r135, %rs48;
(EngineCore_DP0 pid=326741) 	cvt.f32.bf16 	%r136, %rs50;
(EngineCore_DP0 pid=326741) 	cvt.f32.bf16 	%r137, %rs52;
(EngineCore_DP0 pid=326741) 	cvt.f32.bf16 	%r138, %rs54;
(EngineCore_DP0 pid=326741) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=326741) 	mul.f32 	%r139, %r14, %r111;
(EngineCore_DP0 pid=326741) 	mul.f32 	%r140, %r14, %r112;
(EngineCore_DP0 pid=326741) 	mul.f32 	%r141, %r14, %r113;
(EngineCore_DP0 pid=326741) 	mul.f32 	%r142, %r14, %r114;
(EngineCore_DP0 pid=326741) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=326741) 	cvt.rni.f32.f32 	%r143, %r139;
(EngineCore_DP0 pid=326741) 	cvt.rni.f32.f32 	%r144, %r140;
(EngineCore_DP0 pid=326741) 	cvt.rni.f32.f32 	%r145, %r141;
(EngineCore_DP0 pid=326741) 	cvt.rni.f32.f32 	%r146, %r142;
(EngineCore_DP0 pid=326741) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=326741) 	max.f32 	%r147, %r143, 0fC3000000;
(EngineCore_DP0 pid=326741) 	min.f32 	%r148, %r147, 0f42FE0000;
(EngineCore_DP0 pid=326741) 	max.f32 	%r149, %r144, 0fC3000000;
(EngineCore_DP0 pid=326741) 	min.f32 	%r150, %r149, 0f42FE0000;
(EngineCore_DP0 pid=326741) 	max.f32 	%r151, %r145, 0fC3000000;
(EngineCore_DP0 pid=326741) 	min.f32 	%r152, %r151, 0f42FE0000;
(EngineCore_DP0 pid=326741) 	max.f32 	%r153, %r146, 0fC3000000;
(EngineCore_DP0 pid=326741) 	min.f32 	%r154, %r153, 0f42FE0000;
(EngineCore_DP0 pid=326741) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=326741) 	cvt.rzi.s32.f32 	%r155, %r148;
(EngineCore_DP0 pid=326741) 	cvt.rzi.s32.f32 	%r156, %r150;
(EngineCore_DP0 pid=326741) 	cvt.rzi.s32.f32 	%r157, %r152;
(EngineCore_DP0 pid=326741) 	cvt.rzi.s32.f32 	%r158, %r154;
(EngineCore_DP0 pid=326741) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=326741) 	and.b32 	%r159, %r155, 255;
(EngineCore_DP0 pid=326741) 	and.b32 	%r160, %r156, 255;
(EngineCore_DP0 pid=326741) 	and.b32 	%r161, %r157, 255;
(EngineCore_DP0 pid=326741) 	and.b32 	%r162, %r158, 255;
(EngineCore_DP0 pid=326741) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=326741) 	mul.f32 	%r163, %r14, %r119;
(EngineCore_DP0 pid=326741) 	mul.f32 	%r164, %r14, %r120;
(EngineCore_DP0 pid=326741) 	mul.f32 	%r165, %r14, %r121;
(EngineCore_DP0 pid=326741) 	mul.f32 	%r166, %r14, %r122;
(EngineCore_DP0 pid=326741) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=326741) 	cvt.rni.f32.f32 	%r167, %r163;
(EngineCore_DP0 pid=326741) 	cvt.rni.f32.f32 	%r168, %r164;
(EngineCore_DP0 pid=326741) 	cvt.rni.f32.f32 	%r169, %r165;
(EngineCore_DP0 pid=326741) 	cvt.rni.f32.f32 	%r170, %r166;
(EngineCore_DP0 pid=326741) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=326741) 	mul.f32 	%r171, %r14, %r131;
(EngineCore_DP0 pid=326741) 	mul.f32 	%r172, %r14, %r132;
(EngineCore_DP0 pid=326741) 	mul.f32 	%r173, %r14, %r133;
(EngineCore_DP0 pid=326741) 	mul.f32 	%r174, %r14, %r134;
(EngineCore_DP0 pid=326741) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=326741) 	cvt.rni.f32.f32 	%r175, %r171;
(EngineCore_DP0 pid=326741) 	cvt.rni.f32.f32 	%r176, %r172;
(EngineCore_DP0 pid=326741) 	cvt.rni.f32.f32 	%r177, %r173;
(EngineCore_DP0 pid=326741) 	cvt.rni.f32.f32 	%r178, %r174;
(EngineCore_DP0 pid=326741) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=326741) 	mul.f32 	%r179, %r14, %r135;
(EngineCore_DP0 pid=326741) 	mul.f32 	%r180, %r14, %r136;
(EngineCore_DP0 pid=326741) 	mul.f32 	%r181, %r14, %r137;
(EngineCore_DP0 pid=326741) 	mul.f32 	%r182, %r14, %r138;
(EngineCore_DP0 pid=326741) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=326741) 	cvt.rni.f32.f32 	%r183, %r179;
(EngineCore_DP0 pid=326741) 	cvt.rni.f32.f32 	%r184, %r180;
(EngineCore_DP0 pid=326741) 	cvt.rni.f32.f32 	%r185, %r181;
(EngineCore_DP0 pid=326741) 	cvt.rni.f32.f32 	%r186, %r182;
(EngineCore_DP0 pid=326741) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=326741) 	max.f32 	%r187, %r183, 0fC3000000;
(EngineCore_DP0 pid=326741) 	min.f32 	%r188, %r187, 0f42FE0000;
(EngineCore_DP0 pid=326741) 	max.f32 	%r189, %r184, 0fC3000000;
(EngineCore_DP0 pid=326741) 	min.f32 	%r190, %r189, 0f42FE0000;
(EngineCore_DP0 pid=326741) 	max.f32 	%r191, %r185, 0fC3000000;
(EngineCore_DP0 pid=326741) 	min.f32 	%r192, %r191, 0f42FE0000;
(EngineCore_DP0 pid=326741) 	max.f32 	%r193, %r186, 0fC3000000;
(EngineCore_DP0 pid=326741) 	min.f32 	%r194, %r193, 0f42FE0000;
(EngineCore_DP0 pid=326741) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=326741) 	cvt.rzi.s32.f32 	%r195, %r188;
(EngineCore_DP0 pid=326741) 	cvt.rzi.s32.f32 	%r196, %r190;
(EngineCore_DP0 pid=326741) 	cvt.rzi.s32.f32 	%r197, %r192;
(EngineCore_DP0 pid=326741) 	cvt.rzi.s32.f32 	%r198, %r194;
(EngineCore_DP0 pid=326741) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=326741) 	max.f32 	%r199, %r175, 0fC3000000;
(EngineCore_DP0 pid=326741) 	max.f32 	%r200, %r167, 0fC3000000;
(EngineCore_DP0 pid=326741) 	min.f32 	%r201, %r200, 0f42FE0000;
(EngineCore_DP0 pid=326741) 	min.f32 	%r202, %r199, 0f42FE0000;
(EngineCore_DP0 pid=326741) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=326741) 	cvt.rzi.s32.f32 	%r203, %r202;
(EngineCore_DP0 pid=326741) 	cvt.rzi.s32.f32 	%r204, %r201;
(EngineCore_DP0 pid=326741) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=326741) 	shl.b32 	%r205, %r204, 8;
(EngineCore_DP0 pid=326741) 	shl.b32 	%r206, %r203, 16;
(EngineCore_DP0 pid=326741) 	and.b32 	%r207, %r206, 16711680;
(EngineCore_DP0 pid=326741) 	and.b32 	%r208, %r205, 65280;
(EngineCore_DP0 pid=326741) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=326741) 	or.b32 	%r209, %r208, %r159;
(EngineCore_DP0 pid=326741) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=326741) 	max.f32 	%r210, %r176, 0fC3000000;
(EngineCore_DP0 pid=326741) 	max.f32 	%r211, %r168, 0fC3000000;
(EngineCore_DP0 pid=326741) 	min.f32 	%r212, %r211, 0f42FE0000;
(EngineCore_DP0 pid=326741) 	min.f32 	%r213, %r210, 0f42FE0000;
(EngineCore_DP0 pid=326741) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=326741) 	cvt.rzi.s32.f32 	%r214, %r213;
(EngineCore_DP0 pid=326741) 	cvt.rzi.s32.f32 	%r215, %r212;
(EngineCore_DP0 pid=326741) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=326741) 	shl.b32 	%r216, %r215, 8;
(EngineCore_DP0 pid=326741) 	shl.b32 	%r217, %r214, 16;
(EngineCore_DP0 pid=326741) 	and.b32 	%r218, %r217, 16711680;
(EngineCore_DP0 pid=326741) 	and.b32 	%r219, %r216, 65280;
(EngineCore_DP0 pid=326741) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=326741) 	or.b32 	%r220, %r219, %r160;
(EngineCore_DP0 pid=326741) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=326741) 	max.f32 	%r221, %r177, 0fC3000000;
(EngineCore_DP0 pid=326741) 	max.f32 	%r222, %r169, 0fC3000000;
(EngineCore_DP0 pid=326741) 	min.f32 	%r223, %r222, 0f42FE0000;
(EngineCore_DP0 pid=326741) 	min.f32 	%r224, %r221, 0f42FE0000;
(EngineCore_DP0 pid=326741) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=326741) 	cvt.rzi.s32.f32 	%r225, %r224;
(EngineCore_DP0 pid=326741) 	cvt.rzi.s32.f32 	%r226, %r223;
(EngineCore_DP0 pid=326741) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=326741) 	shl.b32 	%r227, %r226, 8;
(EngineCore_DP0 pid=326741) 	shl.b32 	%r228, %r225, 16;
(EngineCore_DP0 pid=326741) 	and.b32 	%r229, %r228, 16711680;
(EngineCore_DP0 pid=326741) 	and.b32 	%r230, %r227, 65280;
(EngineCore_DP0 pid=326741) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=326741) 	or.b32 	%r231, %r230, %r161;
(EngineCore_DP0 pid=326741) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=326741) 	max.f32 	%r232, %r178, 0fC3000000;
(EngineCore_DP0 pid=326741) 	max.f32 	%r233, %r170, 0fC3000000;
(EngineCore_DP0 pid=326741) 	min.f32 	%r234, %r233, 0f42FE0000;
(EngineCore_DP0 pid=326741) 	min.f32 	%r235, %r232, 0f42FE0000;
(EngineCore_DP0 pid=326741) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=326741) 	cvt.rzi.s32.f32 	%r236, %r235;
(EngineCore_DP0 pid=326741) 	cvt.rzi.s32.f32 	%r237, %r234;
(EngineCore_DP0 pid=326741) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=326741) 	shl.b32 	%r238, %r237, 8;
(EngineCore_DP0 pid=326741) 	shl.b32 	%r239, %r236, 16;
(EngineCore_DP0 pid=326741) 	and.b32 	%r240, %r239, 16711680;
(EngineCore_DP0 pid=326741) 	and.b32 	%r241, %r238, 65280;
(EngineCore_DP0 pid=326741) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=326741) 	or.b32 	%r242, %r241, %r162;
(EngineCore_DP0 pid=326741) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=326741) 	or.b32 	%r243, %r209, %r207;
(EngineCore_DP0 pid=326741) 	or.b32 	%r244, %r220, %r218;
(EngineCore_DP0 pid=326741) 	or.b32 	%r245, %r231, %r229;
(EngineCore_DP0 pid=326741) 	or.b32 	%r246, %r242, %r240;
(EngineCore_DP0 pid=326741) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=326741) 	shl.b32 	%r247, %r195, 24;
(EngineCore_DP0 pid=326741) 	shl.b32 	%r248, %r196, 24;
(EngineCore_DP0 pid=326741) 	shl.b32 	%r249, %r197, 24;
(EngineCore_DP0 pid=326741) 	shl.b32 	%r250, %r198, 24;
(EngineCore_DP0 pid=326741) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=326741) 	or.b32 	%r82, %r243, %r247;
(EngineCore_DP0 pid=326741) 	or.b32 	%r83, %r244, %r248;
(EngineCore_DP0 pid=326741) 	or.b32 	%r84, %r245, %r249;
(EngineCore_DP0 pid=326741) 	or.b32 	%r85, %r246, %r250;
(EngineCore_DP0 pid=326741) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=326741) 	mad.wide.s32 	%rd24, %r86, 4, %rd2;
(EngineCore_DP0 pid=326741) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=326741) 	// begin inline asm
(EngineCore_DP0 pid=326741) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r82, %r83, %r84, %r85 };
(EngineCore_DP0 pid=326741) 	// end inline asm
(EngineCore_DP0 pid=326741) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=326741) 	add.s32 	%r254, %r254, 2048;
(EngineCore_DP0 pid=326741) 	setp.lt.s32 	%p42, %r254, %r15;
(EngineCore_DP0 pid=326741) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=326741) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=326741) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=326741) 	ret;
(EngineCore_DP0 pid=326741) $L__tmp3:
(EngineCore_DP0 pid=326741) $L__func_end0:
(EngineCore_DP0 pid=326741)                                         // -- End function
(EngineCore_DP0 pid=326741) }
(EngineCore_DP0 pid=326741) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=326741) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=326741) 	.section	.debug_abbrev
(EngineCore_DP0 pid=326741) 	{
(EngineCore_DP0 pid=326741) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=326741) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=326741) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=326741) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=326741) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=326741) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=326741) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=326741) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=326741) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=326741) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=326741) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=326741) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=326741) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=326741) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=326741) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=326741) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=326741) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=326741) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=326741) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=326741) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=326741) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=326741) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=326741) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=326741) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=326741) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=326741) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=326741) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=326741) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=326741) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=326741) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=326741) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=326741) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=326741) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=326741) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=326741) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=326741) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=326741) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=326741) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=326741) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=326741) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=326741) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=326741) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=326741) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=326741) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=326741) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=326741) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=326741) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=326741) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=326741) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=326741) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=326741) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=326741) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=326741) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=326741) 	}
(EngineCore_DP0 pid=326741) 	.section	.debug_info
(EngineCore_DP0 pid=326741) 	{
(EngineCore_DP0 pid=326741) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=326741) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=326741) .b8 0
(EngineCore_DP0 pid=326741) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=326741) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=326741) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=326741) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=326741) .b8 114
(EngineCore_DP0 pid=326741) .b8 105
(EngineCore_DP0 pid=326741) .b8 116
(EngineCore_DP0 pid=326741) .b8 111
(EngineCore_DP0 pid=326741) .b8 110
(EngineCore_DP0 pid=326741) .b8 0
(EngineCore_DP0 pid=326741) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=326741) .b8 0
(EngineCore_DP0 pid=326741) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=326741) .b8 117
(EngineCore_DP0 pid=326741) .b8 97
(EngineCore_DP0 pid=326741) .b8 110
(EngineCore_DP0 pid=326741) .b8 116
(EngineCore_DP0 pid=326741) .b8 95
(EngineCore_DP0 pid=326741) .b8 115
(EngineCore_DP0 pid=326741) .b8 108
(EngineCore_DP0 pid=326741) .b8 105
(EngineCore_DP0 pid=326741) .b8 100
(EngineCore_DP0 pid=326741) .b8 101
(EngineCore_DP0 pid=326741) .b8 95
(EngineCore_DP0 pid=326741) .b8 116
(EngineCore_DP0 pid=326741) .b8 117
(EngineCore_DP0 pid=326741) .b8 110
(EngineCore_DP0 pid=326741) .b8 101
(EngineCore_DP0 pid=326741) .b8 100
(EngineCore_DP0 pid=326741) .b8 95
(EngineCore_DP0 pid=326741) .b8 76
(EngineCore_DP0 pid=326741) .b8 108
(EngineCore_DP0 pid=326741) .b8 97
(EngineCore_DP0 pid=326741) .b8 109
(EngineCore_DP0 pid=326741) .b8 97
(EngineCore_DP0 pid=326741) .b8 51
(EngineCore_DP0 pid=326741) .b8 46
(EngineCore_DP0 pid=326741) .b8 50
(EngineCore_DP0 pid=326741) .b8 45
(EngineCore_DP0 pid=326741) .b8 49
(EngineCore_DP0 pid=326741) .b8 66
(EngineCore_DP0 pid=326741) .b8 46
(EngineCore_DP0 pid=326741) .b8 112
(EngineCore_DP0 pid=326741) .b8 121
(EngineCore_DP0 pid=326741) .b8 0
(EngineCore_DP0 pid=326741) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=326741) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=326741) .b8 114
(EngineCore_DP0 pid=326741) .b8 111
(EngineCore_DP0 pid=326741) .b8 111
(EngineCore_DP0 pid=326741) .b8 116
(EngineCore_DP0 pid=326741) .b8 47
(EngineCore_DP0 pid=326741) .b8 118
(EngineCore_DP0 pid=326741) .b8 108
(EngineCore_DP0 pid=326741) .b8 108
(EngineCore_DP0 pid=326741) .b8 109
(EngineCore_DP0 pid=326741) .b8 98
(EngineCore_DP0 pid=326741) .b8 101
(EngineCore_DP0 pid=326741) .b8 110
(EngineCore_DP0 pid=326741) .b8 99
(EngineCore_DP0 pid=326741) .b8 104
(EngineCore_DP0 pid=326741) .b8 47
(EngineCore_DP0 pid=326741) .b8 115
(EngineCore_DP0 pid=326741) .b8 108
(EngineCore_DP0 pid=326741) .b8 105
(EngineCore_DP0 pid=326741) .b8 100
(EngineCore_DP0 pid=326741) .b8 101
(EngineCore_DP0 pid=326741) .b8 115
(EngineCore_DP0 pid=326741) .b8 112
(EngineCore_DP0 pid=326741) .b8 97
(EngineCore_DP0 pid=326741) .b8 114
(EngineCore_DP0 pid=326741) .b8 115
(EngineCore_DP0 pid=326741) .b8 101
(EngineCore_DP0 pid=326741) .b8 47
(EngineCore_DP0 pid=326741) .b8 99
(EngineCore_DP0 pid=326741) .b8 115
(EngineCore_DP0 pid=326741) .b8 114
(EngineCore_DP0 pid=326741) .b8 99
(EngineCore_DP0 pid=326741) .b8 47
(EngineCore_DP0 pid=326741) .b8 102
(EngineCore_DP0 pid=326741) .b8 117
(EngineCore_DP0 pid=326741) .b8 115
(EngineCore_DP0 pid=326741) .b8 101
(EngineCore_DP0 pid=326741) .b8 100
(EngineCore_DP0 pid=326741) .b8 95
(EngineCore_DP0 pid=326741) .b8 113
(EngineCore_DP0 pid=326741) .b8 117
(EngineCore_DP0 pid=326741) .b8 97
(EngineCore_DP0 pid=326741) .b8 110
(EngineCore_DP0 pid=326741) .b8 116
(EngineCore_DP0 pid=326741) .b8 95
(EngineCore_DP0 pid=326741) .b8 115
(EngineCore_DP0 pid=326741) .b8 108
(EngineCore_DP0 pid=326741) .b8 105
(EngineCore_DP0 pid=326741) .b8 100
(EngineCore_DP0 pid=326741) .b8 101
(EngineCore_DP0 pid=326741) .b8 95
(EngineCore_DP0 pid=326741) .b8 116
(EngineCore_DP0 pid=326741) .b8 114
(EngineCore_DP0 pid=326741) .b8 105
(EngineCore_DP0 pid=326741) .b8 116
(EngineCore_DP0 pid=326741) .b8 111
(EngineCore_DP0 pid=326741) .b8 110
(EngineCore_DP0 pid=326741) .b8 47
(EngineCore_DP0 pid=326741) .b8 98
(EngineCore_DP0 pid=326741) .b8 117
(EngineCore_DP0 pid=326741) .b8 105
(EngineCore_DP0 pid=326741) .b8 108
(EngineCore_DP0 pid=326741) .b8 100
(EngineCore_DP0 pid=326741) .b8 47
(EngineCore_DP0 pid=326741) .b8 71
(EngineCore_DP0 pid=326741) .b8 66
(EngineCore_DP0 pid=326741) .b8 49
(EngineCore_DP0 pid=326741) .b8 48
(EngineCore_DP0 pid=326741) .b8 95
(EngineCore_DP0 pid=326741) .b8 99
(EngineCore_DP0 pid=326741) .b8 99
(EngineCore_DP0 pid=326741) .b8 49
(EngineCore_DP0 pid=326741) .b8 50
(EngineCore_DP0 pid=326741) .b8 49
(EngineCore_DP0 pid=326741) .b8 95
(EngineCore_DP0 pid=326741) .b8 112
(EngineCore_DP0 pid=326741) .b8 121
(EngineCore_DP0 pid=326741) .b8 51
(EngineCore_DP0 pid=326741) .b8 49
(EngineCore_DP0 pid=326741) .b8 50
(EngineCore_DP0 pid=326741) .b8 95
(EngineCore_DP0 pid=326741) .b8 99
(EngineCore_DP0 pid=326741) .b8 117
(EngineCore_DP0 pid=326741) .b8 49
(EngineCore_DP0 pid=326741) .b8 50
(EngineCore_DP0 pid=326741) .b8 57
(EngineCore_DP0 pid=326741) .b8 95
(EngineCore_DP0 pid=326741) .b8 97
(EngineCore_DP0 pid=326741) .b8 97
(EngineCore_DP0 pid=326741) .b8 114
(EngineCore_DP0 pid=326741) .b8 99
(EngineCore_DP0 pid=326741) .b8 104
(EngineCore_DP0 pid=326741) .b8 54
(EngineCore_DP0 pid=326741) .b8 52
(EngineCore_DP0 pid=326741) .b8 0
(EngineCore_DP0 pid=326741) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=326741) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=326741) .b8 113
(EngineCore_DP0 pid=326741) .b8 117
(EngineCore_DP0 pid=326741) .b8 97
(EngineCore_DP0 pid=326741) .b8 110
(EngineCore_DP0 pid=326741) .b8 116
(EngineCore_DP0 pid=326741) .b8 95
(EngineCore_DP0 pid=326741) .b8 115
(EngineCore_DP0 pid=326741) .b8 108
(EngineCore_DP0 pid=326741) .b8 105
(EngineCore_DP0 pid=326741) .b8 100
(EngineCore_DP0 pid=326741) .b8 101
(EngineCore_DP0 pid=326741) .b8 95
(EngineCore_DP0 pid=326741) .b8 105
(EngineCore_DP0 pid=326741) .b8 110
(EngineCore_DP0 pid=326741) .b8 116
(EngineCore_DP0 pid=326741) .b8 56
(EngineCore_DP0 pid=326741) .b8 95
(EngineCore_DP0 pid=326741) .b8 107
(EngineCore_DP0 pid=326741) .b8 101
(EngineCore_DP0 pid=326741) .b8 114
(EngineCore_DP0 pid=326741) .b8 110
(EngineCore_DP0 pid=326741) .b8 101
(EngineCore_DP0 pid=326741) .b8 108
(EngineCore_DP0 pid=326741) .b8 0
(EngineCore_DP0 pid=326741) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=326741) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=326741) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=326741) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=326741) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=326741) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=326741) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=326741) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=326741) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=326741) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=326741) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=326741) .b8 1
(EngineCore_DP0 pid=326741) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=326741) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=326741) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=326741) 	}
(EngineCore_DP0 pid=326741) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=326741) 
(EngineCore_DP0 pid=326741) ================================================================
(EngineCore_DP0 pid=326741) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=326741) 
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpvskq4smh.ptx', '-o', '/tmp/tmpvskq4smh.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866] 
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866] 
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866] 
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpvskq4smh.ptx -o /tmp/tmpvskq4smh.ptx.o
(EngineCore_DP0 pid=326741) ERROR 01-25 19:08:26 [core.py:866] 

STDERR:
[2026-01-25 19:08:09] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:08:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:08:09] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:08:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:08:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:08:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:08:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:08:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:08:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:08:13] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:08:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:08:13] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:08:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:08:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:08:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:08:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:08:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:08:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=326741) [2026-01-25 19:08:14] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=326741) [2026-01-25 19:08:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=326741) [2026-01-25 19:08:14] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=326741) [2026-01-25 19:08:14] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=326741) [2026-01-25 19:08:14] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=326741) [2026-01-25 19:08:14] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=326741) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=326741) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.81s/it]
(EngineCore_DP0 pid=326741) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.81s/it]
(EngineCore_DP0 pid=326741) 
(EngineCore_DP0 pid=326741) [2026-01-25 19:08:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=326741) [2026-01-25 19:08:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=326741) [2026-01-25 19:08:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=326741) [2026-01-25 19:08:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=326741) [2026-01-25 19:08:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=326741) [2026-01-25 19:08:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=326741) [2026-01-25 19:08:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=326741) [2026-01-25 19:08:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=326741) Process EngineCore_DP0:
(EngineCore_DP0 pid=326741) Traceback (most recent call last):
(EngineCore_DP0 pid=326741)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=326741)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=326741)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=326741)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=326741) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpvskq4smh.ptx', '-o', '/tmp/tmpvskq4smh.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=326741) 
(EngineCore_DP0 pid=326741) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=326741) 
(EngineCore_DP0 pid=326741) Traceback (most recent call last):
(EngineCore_DP0 pid=326741)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=326741)     self.run()
(EngineCore_DP0 pid=326741)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=326741)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=326741)     raise e
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=326741)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=326741)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=326741)     super().__init__(
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=326741)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=326741)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=326741)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=326741)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=326741)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=326741)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=326741)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=326741)     return func(*args, **kwargs)
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=326741)     return func(*args, **kwargs)
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=326741)     self.model_runner.profile_run()
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=326741)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=326741)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=326741)     return func(*args, **kwargs)
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=326741)     outputs = self.model(
(EngineCore_DP0 pid=326741)               ^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=326741)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=326741)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=326741)     model_output = self.model(
(EngineCore_DP0 pid=326741)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=326741)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=326741)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=326741)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=326741)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=326741)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=326741)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=326741)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=326741)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=326741)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=326741)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=326741)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=326741)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=326741)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=326741)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=326741)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=326741)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=326741)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=326741)     return self._linear_fn(
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=326741)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=326741)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=326741)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=326741)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=326741)     return fn(input, L)
(EngineCore_DP0 pid=326741)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=326741)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=326741)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=326741)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=326741)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=326741)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=326741)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=326741)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=326741)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=326741)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=326741)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=326741)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=326741)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=326741)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=326741)     raise PTXASError(error)
(EngineCore_DP0 pid=326741) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=326741) `ptxas` stderr:
(EngineCore_DP0 pid=326741) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=326741) 
(EngineCore_DP0 pid=326741) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpvskq4smh.ptx -o /tmp/tmpvskq4smh.ptx.o
(EngineCore_DP0 pid=326741) 
[rank0]:[W125 19:08:26.032478723 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 19:08:28
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:08:43 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:08:43 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=327402) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=327402) 
(EngineCore_DP0 pid=327402) 
(EngineCore_DP0 pid=327402) ================================================================
(EngineCore_DP0 pid=327402) Internal Triton PTX codegen error
(EngineCore_DP0 pid=327402) `ptxas` stderr:
(EngineCore_DP0 pid=327402) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=327402) 
(EngineCore_DP0 pid=327402) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp_k2esk53.ptx -o /tmp/tmp_k2esk53.ptx.o
(EngineCore_DP0 pid=327402) 
(EngineCore_DP0 pid=327402) 
(EngineCore_DP0 pid=327402) //
(EngineCore_DP0 pid=327402) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=327402) //
(EngineCore_DP0 pid=327402) 
(EngineCore_DP0 pid=327402) .version 8.7
(EngineCore_DP0 pid=327402) .target sm_121a
(EngineCore_DP0 pid=327402) .address_size 64
(EngineCore_DP0 pid=327402) 
(EngineCore_DP0 pid=327402) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=327402) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=327402)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=327402) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=327402) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=327402) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=327402) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=327402) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=327402) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=327402) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=327402) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=327402) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=327402) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=327402) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=327402) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=327402) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=327402) )
(EngineCore_DP0 pid=327402) .reqntid 512
(EngineCore_DP0 pid=327402) {
(EngineCore_DP0 pid=327402) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=327402) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=327402) 	.reg .b32 	%r<255>;
(EngineCore_DP0 pid=327402) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=327402) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=327402) $L__func_begin0:
(EngineCore_DP0 pid=327402) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=327402) 
(EngineCore_DP0 pid=327402) // %bb.0:
(EngineCore_DP0 pid=327402) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=327402) 	ld.param.b32 	%r28, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=327402) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=327402) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=327402) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=327402) $L__tmp0:
(EngineCore_DP0 pid=327402) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=327402) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=327402) 	ld.param.b32 	%r31, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=327402) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=327402) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=327402) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=327402) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=327402) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=327402) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=327402) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=327402) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=327402) 	mov.b32 	%r253, 0f2B8CBCCC;
(EngineCore_DP0 pid=327402) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=327402) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=327402) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=327402) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=327402) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=327402) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=327402) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=327402) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=327402) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=327402) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=327402) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=327402) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=327402) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=327402) 	mov.b32 	%r251, 0f00000000;
(EngineCore_DP0 pid=327402) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=327402) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=327402) 	mov.b32 	%r252, %r49;
(EngineCore_DP0 pid=327402) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=327402) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=327402) 	add.s32 	%r59, %r4, %r252;
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=327402) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=327402) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=327402) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=327402) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=327402) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=327402) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=327402) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=327402) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=327402) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=327402) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=327402) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=327402) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=327402) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=327402) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=327402) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=327402) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=327402) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=327402) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=327402) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=327402) $L__tmp1:
(EngineCore_DP0 pid=327402) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	bar.sync 	0;
(EngineCore_DP0 pid=327402) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=327402) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=327402) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=327402) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=327402) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=327402) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=327402) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=327402) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=327402) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=327402) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=327402) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=327402) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=327402) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=327402) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=327402) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=327402) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=327402) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=327402) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=327402) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	bar.sync 	0;
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=327402) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=327402) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=327402) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=327402) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=327402) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=327402) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=327402) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=327402) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	bar.sync 	0;
(EngineCore_DP0 pid=327402) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=327402) $L__tmp2:
(EngineCore_DP0 pid=327402) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=327402) 	max.f32 	%r251, %r251, %r77;
(EngineCore_DP0 pid=327402) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=327402) 	add.s32 	%r252, %r252, 4096;
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p6, %r252, %r28;
(EngineCore_DP0 pid=327402) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=327402) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=327402) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=327402) 	max.f32 	%r253, %r251, 0f2B8CBCCC;
(EngineCore_DP0 pid=327402) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=327402) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=327402) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=327402) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=327402) 	div.full.f32 	%r80, %r253, %r79;
(EngineCore_DP0 pid=327402) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=327402) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=327402) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=327402) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=327402) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=327402) 	shl.b32 	%r15, %r29, 2;
(EngineCore_DP0 pid=327402) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=327402) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=327402) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=327402) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=327402) 	ld.param.b32 	%r33, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=327402) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=327402) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=327402) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=327402) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=327402) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=327402) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=327402) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=327402) 	div.full.f32 	%r14, %r79, %r253;
(EngineCore_DP0 pid=327402) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=327402) 	mov.b32 	%r254, 0;
(EngineCore_DP0 pid=327402) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=327402)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=327402) 	.loc	1 313 31                        // quant_slide_tuned_Llama3.2-1B.py:313:31
(EngineCore_DP0 pid=327402) 	add.s32 	%r86, %r16, %r254;
(EngineCore_DP0 pid=327402) 	or.b32 	%r87, %r254, 2;
(EngineCore_DP0 pid=327402) 	or.b32 	%r88, %r254, 3;
(EngineCore_DP0 pid=327402) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p25, %r86, %r15;
(EngineCore_DP0 pid=327402) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=327402) 	shr.s32 	%r89, %r86, 2;
(EngineCore_DP0 pid=327402) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=327402) 	add.s32 	%r90, %r254, 1;
(EngineCore_DP0 pid=327402) 	shr.s32 	%r91, %r90, 31;
(EngineCore_DP0 pid=327402) 	shr.u32 	%r92, %r91, 30;
(EngineCore_DP0 pid=327402) 	add.s32 	%r93, %r90, %r92;
(EngineCore_DP0 pid=327402) 	and.b32 	%r94, %r93, 2147483644;
(EngineCore_DP0 pid=327402) 	sub.s32 	%r95, %r90, %r94;
(EngineCore_DP0 pid=327402) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=327402) 	shl.b32 	%r96, %r95, 1;
(EngineCore_DP0 pid=327402) 	.loc	1 319 22                        // quant_slide_tuned_Llama3.2-1B.py:319:22
(EngineCore_DP0 pid=327402) 	mul.lo.s32 	%r97, %r89, 10;
(EngineCore_DP0 pid=327402) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=327402) 	add.s32 	%r98, %r97, %r96;
(EngineCore_DP0 pid=327402) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=327402) 	shr.s32 	%r99, %r254, 31;
(EngineCore_DP0 pid=327402) 	shr.u32 	%r100, %r99, 30;
(EngineCore_DP0 pid=327402) 	add.s32 	%r101, %r88, %r100;
(EngineCore_DP0 pid=327402) 	and.b32 	%r102, %r101, 2147483644;
(EngineCore_DP0 pid=327402) 	sub.s32 	%r103, %r88, %r102;
(EngineCore_DP0 pid=327402) 	add.s32 	%r104, %r87, %r100;
(EngineCore_DP0 pid=327402) 	and.b32 	%r105, %r104, 2147483644;
(EngineCore_DP0 pid=327402) 	sub.s32 	%r106, %r87, %r105;
(EngineCore_DP0 pid=327402) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=327402) 	shl.b32 	%r107, %r106, 1;
(EngineCore_DP0 pid=327402) 	shl.b32 	%r108, %r103, 1;
(EngineCore_DP0 pid=327402) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=327402) 	add.s32 	%r109, %r97, %r108;
(EngineCore_DP0 pid=327402) 	add.s32 	%r110, %r97, %r107;
(EngineCore_DP0 pid=327402) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p26, %r97, %r27;
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p27, %r98, %r27;
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p28, %r110, %r27;
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p29, %r109, %r27;
(EngineCore_DP0 pid=327402) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=327402) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=327402) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=327402) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=327402) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=327402) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=327402) 	mad.wide.s32 	%rd8, %r97, 2, %rd1;
(EngineCore_DP0 pid=327402) 	mad.wide.s32 	%rd9, %r98, 2, %rd1;
(EngineCore_DP0 pid=327402) 	mad.wide.s32 	%rd10, %r110, 2, %rd1;
(EngineCore_DP0 pid=327402) 	mad.wide.s32 	%rd11, %r109, 2, %rd1;
(EngineCore_DP0 pid=327402) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=327402) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=327402) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=327402) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=327402) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=327402) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=327402) 	cvt.f32.bf16 	%r111, %rs24;
(EngineCore_DP0 pid=327402) 	cvt.f32.bf16 	%r112, %rs26;
(EngineCore_DP0 pid=327402) 	cvt.f32.bf16 	%r113, %rs28;
(EngineCore_DP0 pid=327402) 	cvt.f32.bf16 	%r114, %rs30;
(EngineCore_DP0 pid=327402) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=327402) 	or.b32 	%r115, %r97, 1;
(EngineCore_DP0 pid=327402) 	or.b32 	%r116, %r98, 1;
(EngineCore_DP0 pid=327402) 	or.b32 	%r117, %r110, 1;
(EngineCore_DP0 pid=327402) 	or.b32 	%r118, %r109, 1;
(EngineCore_DP0 pid=327402) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p30, %r115, %r27;
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p31, %r116, %r27;
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p32, %r117, %r27;
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p33, %r118, %r27;
(EngineCore_DP0 pid=327402) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=327402) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=327402) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=327402) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=327402) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=327402) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=327402) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=327402) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=327402) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=327402) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=327402) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=327402) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=327402) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=327402) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=327402) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=327402) 	cvt.f32.bf16 	%r119, %rs32;
(EngineCore_DP0 pid=327402) 	cvt.f32.bf16 	%r120, %rs34;
(EngineCore_DP0 pid=327402) 	cvt.f32.bf16 	%r121, %rs36;
(EngineCore_DP0 pid=327402) 	cvt.f32.bf16 	%r122, %rs38;
(EngineCore_DP0 pid=327402) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=327402) 	add.s32 	%r123, %r98, 2;
(EngineCore_DP0 pid=327402) 	add.s32 	%r124, %r110, 2;
(EngineCore_DP0 pid=327402) 	add.s32 	%r125, %r109, 2;
(EngineCore_DP0 pid=327402) 	add.s32 	%r126, %r98, 3;
(EngineCore_DP0 pid=327402) 	add.s32 	%r127, %r110, 3;
(EngineCore_DP0 pid=327402) 	add.s32 	%r128, %r109, 3;
(EngineCore_DP0 pid=327402) 	add.s32 	%r129, %r97, 2;
(EngineCore_DP0 pid=327402) 	add.s32 	%r130, %r97, 3;
(EngineCore_DP0 pid=327402) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p34, %r128, %r27;
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p35, %r127, %r27;
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p36, %r126, %r27;
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p37, %r125, %r27;
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p38, %r124, %r27;
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p39, %r123, %r27;
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p40, %r130, %r27;
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p41, %r129, %r27;
(EngineCore_DP0 pid=327402) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=327402) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=327402) 	and.pred 	%p18, %p25, %p39;
(EngineCore_DP0 pid=327402) 	and.pred 	%p19, %p25, %p38;
(EngineCore_DP0 pid=327402) 	and.pred 	%p20, %p25, %p37;
(EngineCore_DP0 pid=327402) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=327402) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=327402) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=327402) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=327402) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=327402) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=327402) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=327402) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=327402) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=327402) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=327402) 	cvt.f32.bf16 	%r131, %rs40;
(EngineCore_DP0 pid=327402) 	cvt.f32.bf16 	%r132, %rs42;
(EngineCore_DP0 pid=327402) 	cvt.f32.bf16 	%r133, %rs44;
(EngineCore_DP0 pid=327402) 	cvt.f32.bf16 	%r134, %rs46;
(EngineCore_DP0 pid=327402) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=327402) 	and.pred 	%p21, %p25, %p40;
(EngineCore_DP0 pid=327402) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=327402) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=327402) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=327402) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=327402) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=327402) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=327402) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=327402) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=327402) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=327402) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=327402) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=327402) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=327402) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=327402) 	cvt.f32.bf16 	%r135, %rs48;
(EngineCore_DP0 pid=327402) 	cvt.f32.bf16 	%r136, %rs50;
(EngineCore_DP0 pid=327402) 	cvt.f32.bf16 	%r137, %rs52;
(EngineCore_DP0 pid=327402) 	cvt.f32.bf16 	%r138, %rs54;
(EngineCore_DP0 pid=327402) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=327402) 	mul.f32 	%r139, %r14, %r111;
(EngineCore_DP0 pid=327402) 	mul.f32 	%r140, %r14, %r112;
(EngineCore_DP0 pid=327402) 	mul.f32 	%r141, %r14, %r113;
(EngineCore_DP0 pid=327402) 	mul.f32 	%r142, %r14, %r114;
(EngineCore_DP0 pid=327402) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=327402) 	cvt.rni.f32.f32 	%r143, %r139;
(EngineCore_DP0 pid=327402) 	cvt.rni.f32.f32 	%r144, %r140;
(EngineCore_DP0 pid=327402) 	cvt.rni.f32.f32 	%r145, %r141;
(EngineCore_DP0 pid=327402) 	cvt.rni.f32.f32 	%r146, %r142;
(EngineCore_DP0 pid=327402) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=327402) 	max.f32 	%r147, %r143, 0fC3000000;
(EngineCore_DP0 pid=327402) 	min.f32 	%r148, %r147, 0f42FE0000;
(EngineCore_DP0 pid=327402) 	max.f32 	%r149, %r144, 0fC3000000;
(EngineCore_DP0 pid=327402) 	min.f32 	%r150, %r149, 0f42FE0000;
(EngineCore_DP0 pid=327402) 	max.f32 	%r151, %r145, 0fC3000000;
(EngineCore_DP0 pid=327402) 	min.f32 	%r152, %r151, 0f42FE0000;
(EngineCore_DP0 pid=327402) 	max.f32 	%r153, %r146, 0fC3000000;
(EngineCore_DP0 pid=327402) 	min.f32 	%r154, %r153, 0f42FE0000;
(EngineCore_DP0 pid=327402) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=327402) 	cvt.rzi.s32.f32 	%r155, %r148;
(EngineCore_DP0 pid=327402) 	cvt.rzi.s32.f32 	%r156, %r150;
(EngineCore_DP0 pid=327402) 	cvt.rzi.s32.f32 	%r157, %r152;
(EngineCore_DP0 pid=327402) 	cvt.rzi.s32.f32 	%r158, %r154;
(EngineCore_DP0 pid=327402) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=327402) 	and.b32 	%r159, %r155, 255;
(EngineCore_DP0 pid=327402) 	and.b32 	%r160, %r156, 255;
(EngineCore_DP0 pid=327402) 	and.b32 	%r161, %r157, 255;
(EngineCore_DP0 pid=327402) 	and.b32 	%r162, %r158, 255;
(EngineCore_DP0 pid=327402) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=327402) 	mul.f32 	%r163, %r14, %r119;
(EngineCore_DP0 pid=327402) 	mul.f32 	%r164, %r14, %r120;
(EngineCore_DP0 pid=327402) 	mul.f32 	%r165, %r14, %r121;
(EngineCore_DP0 pid=327402) 	mul.f32 	%r166, %r14, %r122;
(EngineCore_DP0 pid=327402) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=327402) 	cvt.rni.f32.f32 	%r167, %r163;
(EngineCore_DP0 pid=327402) 	cvt.rni.f32.f32 	%r168, %r164;
(EngineCore_DP0 pid=327402) 	cvt.rni.f32.f32 	%r169, %r165;
(EngineCore_DP0 pid=327402) 	cvt.rni.f32.f32 	%r170, %r166;
(EngineCore_DP0 pid=327402) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=327402) 	mul.f32 	%r171, %r14, %r131;
(EngineCore_DP0 pid=327402) 	mul.f32 	%r172, %r14, %r132;
(EngineCore_DP0 pid=327402) 	mul.f32 	%r173, %r14, %r133;
(EngineCore_DP0 pid=327402) 	mul.f32 	%r174, %r14, %r134;
(EngineCore_DP0 pid=327402) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=327402) 	cvt.rni.f32.f32 	%r175, %r171;
(EngineCore_DP0 pid=327402) 	cvt.rni.f32.f32 	%r176, %r172;
(EngineCore_DP0 pid=327402) 	cvt.rni.f32.f32 	%r177, %r173;
(EngineCore_DP0 pid=327402) 	cvt.rni.f32.f32 	%r178, %r174;
(EngineCore_DP0 pid=327402) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=327402) 	mul.f32 	%r179, %r14, %r135;
(EngineCore_DP0 pid=327402) 	mul.f32 	%r180, %r14, %r136;
(EngineCore_DP0 pid=327402) 	mul.f32 	%r181, %r14, %r137;
(EngineCore_DP0 pid=327402) 	mul.f32 	%r182, %r14, %r138;
(EngineCore_DP0 pid=327402) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=327402) 	cvt.rni.f32.f32 	%r183, %r179;
(EngineCore_DP0 pid=327402) 	cvt.rni.f32.f32 	%r184, %r180;
(EngineCore_DP0 pid=327402) 	cvt.rni.f32.f32 	%r185, %r181;
(EngineCore_DP0 pid=327402) 	cvt.rni.f32.f32 	%r186, %r182;
(EngineCore_DP0 pid=327402) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=327402) 	max.f32 	%r187, %r183, 0fC3000000;
(EngineCore_DP0 pid=327402) 	min.f32 	%r188, %r187, 0f42FE0000;
(EngineCore_DP0 pid=327402) 	max.f32 	%r189, %r184, 0fC3000000;
(EngineCore_DP0 pid=327402) 	min.f32 	%r190, %r189, 0f42FE0000;
(EngineCore_DP0 pid=327402) 	max.f32 	%r191, %r185, 0fC3000000;
(EngineCore_DP0 pid=327402) 	min.f32 	%r192, %r191, 0f42FE0000;
(EngineCore_DP0 pid=327402) 	max.f32 	%r193, %r186, 0fC3000000;
(EngineCore_DP0 pid=327402) 	min.f32 	%r194, %r193, 0f42FE0000;
(EngineCore_DP0 pid=327402) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=327402) 	cvt.rzi.s32.f32 	%r195, %r188;
(EngineCore_DP0 pid=327402) 	cvt.rzi.s32.f32 	%r196, %r190;
(EngineCore_DP0 pid=327402) 	cvt.rzi.s32.f32 	%r197, %r192;
(EngineCore_DP0 pid=327402) 	cvt.rzi.s32.f32 	%r198, %r194;
(EngineCore_DP0 pid=327402) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=327402) 	max.f32 	%r199, %r175, 0fC3000000;
(EngineCore_DP0 pid=327402) 	max.f32 	%r200, %r167, 0fC3000000;
(EngineCore_DP0 pid=327402) 	min.f32 	%r201, %r200, 0f42FE0000;
(EngineCore_DP0 pid=327402) 	min.f32 	%r202, %r199, 0f42FE0000;
(EngineCore_DP0 pid=327402) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=327402) 	cvt.rzi.s32.f32 	%r203, %r202;
(EngineCore_DP0 pid=327402) 	cvt.rzi.s32.f32 	%r204, %r201;
(EngineCore_DP0 pid=327402) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=327402) 	shl.b32 	%r205, %r204, 8;
(EngineCore_DP0 pid=327402) 	shl.b32 	%r206, %r203, 16;
(EngineCore_DP0 pid=327402) 	and.b32 	%r207, %r206, 16711680;
(EngineCore_DP0 pid=327402) 	and.b32 	%r208, %r205, 65280;
(EngineCore_DP0 pid=327402) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=327402) 	or.b32 	%r209, %r208, %r159;
(EngineCore_DP0 pid=327402) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=327402) 	max.f32 	%r210, %r176, 0fC3000000;
(EngineCore_DP0 pid=327402) 	max.f32 	%r211, %r168, 0fC3000000;
(EngineCore_DP0 pid=327402) 	min.f32 	%r212, %r211, 0f42FE0000;
(EngineCore_DP0 pid=327402) 	min.f32 	%r213, %r210, 0f42FE0000;
(EngineCore_DP0 pid=327402) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=327402) 	cvt.rzi.s32.f32 	%r214, %r213;
(EngineCore_DP0 pid=327402) 	cvt.rzi.s32.f32 	%r215, %r212;
(EngineCore_DP0 pid=327402) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=327402) 	shl.b32 	%r216, %r215, 8;
(EngineCore_DP0 pid=327402) 	shl.b32 	%r217, %r214, 16;
(EngineCore_DP0 pid=327402) 	and.b32 	%r218, %r217, 16711680;
(EngineCore_DP0 pid=327402) 	and.b32 	%r219, %r216, 65280;
(EngineCore_DP0 pid=327402) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=327402) 	or.b32 	%r220, %r219, %r160;
(EngineCore_DP0 pid=327402) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=327402) 	max.f32 	%r221, %r177, 0fC3000000;
(EngineCore_DP0 pid=327402) 	max.f32 	%r222, %r169, 0fC3000000;
(EngineCore_DP0 pid=327402) 	min.f32 	%r223, %r222, 0f42FE0000;
(EngineCore_DP0 pid=327402) 	min.f32 	%r224, %r221, 0f42FE0000;
(EngineCore_DP0 pid=327402) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=327402) 	cvt.rzi.s32.f32 	%r225, %r224;
(EngineCore_DP0 pid=327402) 	cvt.rzi.s32.f32 	%r226, %r223;
(EngineCore_DP0 pid=327402) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=327402) 	shl.b32 	%r227, %r226, 8;
(EngineCore_DP0 pid=327402) 	shl.b32 	%r228, %r225, 16;
(EngineCore_DP0 pid=327402) 	and.b32 	%r229, %r228, 16711680;
(EngineCore_DP0 pid=327402) 	and.b32 	%r230, %r227, 65280;
(EngineCore_DP0 pid=327402) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=327402) 	or.b32 	%r231, %r230, %r161;
(EngineCore_DP0 pid=327402) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=327402) 	max.f32 	%r232, %r178, 0fC3000000;
(EngineCore_DP0 pid=327402) 	max.f32 	%r233, %r170, 0fC3000000;
(EngineCore_DP0 pid=327402) 	min.f32 	%r234, %r233, 0f42FE0000;
(EngineCore_DP0 pid=327402) 	min.f32 	%r235, %r232, 0f42FE0000;
(EngineCore_DP0 pid=327402) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=327402) 	cvt.rzi.s32.f32 	%r236, %r235;
(EngineCore_DP0 pid=327402) 	cvt.rzi.s32.f32 	%r237, %r234;
(EngineCore_DP0 pid=327402) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=327402) 	shl.b32 	%r238, %r237, 8;
(EngineCore_DP0 pid=327402) 	shl.b32 	%r239, %r236, 16;
(EngineCore_DP0 pid=327402) 	and.b32 	%r240, %r239, 16711680;
(EngineCore_DP0 pid=327402) 	and.b32 	%r241, %r238, 65280;
(EngineCore_DP0 pid=327402) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=327402) 	or.b32 	%r242, %r241, %r162;
(EngineCore_DP0 pid=327402) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=327402) 	or.b32 	%r243, %r209, %r207;
(EngineCore_DP0 pid=327402) 	or.b32 	%r244, %r220, %r218;
(EngineCore_DP0 pid=327402) 	or.b32 	%r245, %r231, %r229;
(EngineCore_DP0 pid=327402) 	or.b32 	%r246, %r242, %r240;
(EngineCore_DP0 pid=327402) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=327402) 	shl.b32 	%r247, %r195, 24;
(EngineCore_DP0 pid=327402) 	shl.b32 	%r248, %r196, 24;
(EngineCore_DP0 pid=327402) 	shl.b32 	%r249, %r197, 24;
(EngineCore_DP0 pid=327402) 	shl.b32 	%r250, %r198, 24;
(EngineCore_DP0 pid=327402) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=327402) 	or.b32 	%r82, %r243, %r247;
(EngineCore_DP0 pid=327402) 	or.b32 	%r83, %r244, %r248;
(EngineCore_DP0 pid=327402) 	or.b32 	%r84, %r245, %r249;
(EngineCore_DP0 pid=327402) 	or.b32 	%r85, %r246, %r250;
(EngineCore_DP0 pid=327402) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=327402) 	mad.wide.s32 	%rd24, %r86, 4, %rd2;
(EngineCore_DP0 pid=327402) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=327402) 	// begin inline asm
(EngineCore_DP0 pid=327402) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r82, %r83, %r84, %r85 };
(EngineCore_DP0 pid=327402) 	// end inline asm
(EngineCore_DP0 pid=327402) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=327402) 	add.s32 	%r254, %r254, 2048;
(EngineCore_DP0 pid=327402) 	setp.lt.s32 	%p42, %r254, %r15;
(EngineCore_DP0 pid=327402) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=327402) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=327402) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=327402) 	ret;
(EngineCore_DP0 pid=327402) $L__tmp3:
(EngineCore_DP0 pid=327402) $L__func_end0:
(EngineCore_DP0 pid=327402)                                         // -- End function
(EngineCore_DP0 pid=327402) }
(EngineCore_DP0 pid=327402) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=327402) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=327402) 	.section	.debug_abbrev
(EngineCore_DP0 pid=327402) 	{
(EngineCore_DP0 pid=327402) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=327402) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=327402) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=327402) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=327402) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=327402) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=327402) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=327402) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=327402) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=327402) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=327402) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=327402) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=327402) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=327402) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=327402) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=327402) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=327402) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=327402) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=327402) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=327402) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=327402) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=327402) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=327402) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=327402) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=327402) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=327402) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=327402) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=327402) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=327402) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=327402) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=327402) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=327402) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=327402) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=327402) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=327402) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=327402) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=327402) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=327402) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=327402) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=327402) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=327402) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=327402) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=327402) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=327402) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=327402) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=327402) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=327402) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=327402) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=327402) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=327402) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=327402) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=327402) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=327402) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=327402) 	}
(EngineCore_DP0 pid=327402) 	.section	.debug_info
(EngineCore_DP0 pid=327402) 	{
(EngineCore_DP0 pid=327402) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=327402) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=327402) .b8 0
(EngineCore_DP0 pid=327402) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=327402) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=327402) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=327402) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=327402) .b8 114
(EngineCore_DP0 pid=327402) .b8 105
(EngineCore_DP0 pid=327402) .b8 116
(EngineCore_DP0 pid=327402) .b8 111
(EngineCore_DP0 pid=327402) .b8 110
(EngineCore_DP0 pid=327402) .b8 0
(EngineCore_DP0 pid=327402) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=327402) .b8 0
(EngineCore_DP0 pid=327402) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=327402) .b8 117
(EngineCore_DP0 pid=327402) .b8 97
(EngineCore_DP0 pid=327402) .b8 110
(EngineCore_DP0 pid=327402) .b8 116
(EngineCore_DP0 pid=327402) .b8 95
(EngineCore_DP0 pid=327402) .b8 115
(EngineCore_DP0 pid=327402) .b8 108
(EngineCore_DP0 pid=327402) .b8 105
(EngineCore_DP0 pid=327402) .b8 100
(EngineCore_DP0 pid=327402) .b8 101
(EngineCore_DP0 pid=327402) .b8 95
(EngineCore_DP0 pid=327402) .b8 116
(EngineCore_DP0 pid=327402) .b8 117
(EngineCore_DP0 pid=327402) .b8 110
(EngineCore_DP0 pid=327402) .b8 101
(EngineCore_DP0 pid=327402) .b8 100
(EngineCore_DP0 pid=327402) .b8 95
(EngineCore_DP0 pid=327402) .b8 76
(EngineCore_DP0 pid=327402) .b8 108
(EngineCore_DP0 pid=327402) .b8 97
(EngineCore_DP0 pid=327402) .b8 109
(EngineCore_DP0 pid=327402) .b8 97
(EngineCore_DP0 pid=327402) .b8 51
(EngineCore_DP0 pid=327402) .b8 46
(EngineCore_DP0 pid=327402) .b8 50
(EngineCore_DP0 pid=327402) .b8 45
(EngineCore_DP0 pid=327402) .b8 49
(EngineCore_DP0 pid=327402) .b8 66
(EngineCore_DP0 pid=327402) .b8 46
(EngineCore_DP0 pid=327402) .b8 112
(EngineCore_DP0 pid=327402) .b8 121
(EngineCore_DP0 pid=327402) .b8 0
(EngineCore_DP0 pid=327402) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=327402) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=327402) .b8 114
(EngineCore_DP0 pid=327402) .b8 111
(EngineCore_DP0 pid=327402) .b8 111
(EngineCore_DP0 pid=327402) .b8 116
(EngineCore_DP0 pid=327402) .b8 47
(EngineCore_DP0 pid=327402) .b8 118
(EngineCore_DP0 pid=327402) .b8 108
(EngineCore_DP0 pid=327402) .b8 108
(EngineCore_DP0 pid=327402) .b8 109
(EngineCore_DP0 pid=327402) .b8 98
(EngineCore_DP0 pid=327402) .b8 101
(EngineCore_DP0 pid=327402) .b8 110
(EngineCore_DP0 pid=327402) .b8 99
(EngineCore_DP0 pid=327402) .b8 104
(EngineCore_DP0 pid=327402) .b8 47
(EngineCore_DP0 pid=327402) .b8 115
(EngineCore_DP0 pid=327402) .b8 108
(EngineCore_DP0 pid=327402) .b8 105
(EngineCore_DP0 pid=327402) .b8 100
(EngineCore_DP0 pid=327402) .b8 101
(EngineCore_DP0 pid=327402) .b8 115
(EngineCore_DP0 pid=327402) .b8 112
(EngineCore_DP0 pid=327402) .b8 97
(EngineCore_DP0 pid=327402) .b8 114
(EngineCore_DP0 pid=327402) .b8 115
(EngineCore_DP0 pid=327402) .b8 101
(EngineCore_DP0 pid=327402) .b8 47
(EngineCore_DP0 pid=327402) .b8 99
(EngineCore_DP0 pid=327402) .b8 115
(EngineCore_DP0 pid=327402) .b8 114
(EngineCore_DP0 pid=327402) .b8 99
(EngineCore_DP0 pid=327402) .b8 47
(EngineCore_DP0 pid=327402) .b8 102
(EngineCore_DP0 pid=327402) .b8 117
(EngineCore_DP0 pid=327402) .b8 115
(EngineCore_DP0 pid=327402) .b8 101
(EngineCore_DP0 pid=327402) .b8 100
(EngineCore_DP0 pid=327402) .b8 95
(EngineCore_DP0 pid=327402) .b8 113
(EngineCore_DP0 pid=327402) .b8 117
(EngineCore_DP0 pid=327402) .b8 97
(EngineCore_DP0 pid=327402) .b8 110
(EngineCore_DP0 pid=327402) .b8 116
(EngineCore_DP0 pid=327402) .b8 95
(EngineCore_DP0 pid=327402) .b8 115
(EngineCore_DP0 pid=327402) .b8 108
(EngineCore_DP0 pid=327402) .b8 105
(EngineCore_DP0 pid=327402) .b8 100
(EngineCore_DP0 pid=327402) .b8 101
(EngineCore_DP0 pid=327402) .b8 95
(EngineCore_DP0 pid=327402) .b8 116
(EngineCore_DP0 pid=327402) .b8 114
(EngineCore_DP0 pid=327402) .b8 105
(EngineCore_DP0 pid=327402) .b8 116
(EngineCore_DP0 pid=327402) .b8 111
(EngineCore_DP0 pid=327402) .b8 110
(EngineCore_DP0 pid=327402) .b8 47
(EngineCore_DP0 pid=327402) .b8 98
(EngineCore_DP0 pid=327402) .b8 117
(EngineCore_DP0 pid=327402) .b8 105
(EngineCore_DP0 pid=327402) .b8 108
(EngineCore_DP0 pid=327402) .b8 100
(EngineCore_DP0 pid=327402) .b8 47
(EngineCore_DP0 pid=327402) .b8 71
(EngineCore_DP0 pid=327402) .b8 66
(EngineCore_DP0 pid=327402) .b8 49
(EngineCore_DP0 pid=327402) .b8 48
(EngineCore_DP0 pid=327402) .b8 95
(EngineCore_DP0 pid=327402) .b8 99
(EngineCore_DP0 pid=327402) .b8 99
(EngineCore_DP0 pid=327402) .b8 49
(EngineCore_DP0 pid=327402) .b8 50
(EngineCore_DP0 pid=327402) .b8 49
(EngineCore_DP0 pid=327402) .b8 95
(EngineCore_DP0 pid=327402) .b8 112
(EngineCore_DP0 pid=327402) .b8 121
(EngineCore_DP0 pid=327402) .b8 51
(EngineCore_DP0 pid=327402) .b8 49
(EngineCore_DP0 pid=327402) .b8 50
(EngineCore_DP0 pid=327402) .b8 95
(EngineCore_DP0 pid=327402) .b8 99
(EngineCore_DP0 pid=327402) .b8 117
(EngineCore_DP0 pid=327402) .b8 49
(EngineCore_DP0 pid=327402) .b8 50
(EngineCore_DP0 pid=327402) .b8 57
(EngineCore_DP0 pid=327402) .b8 95
(EngineCore_DP0 pid=327402) .b8 97
(EngineCore_DP0 pid=327402) .b8 97
(EngineCore_DP0 pid=327402) .b8 114
(EngineCore_DP0 pid=327402) .b8 99
(EngineCore_DP0 pid=327402) .b8 104
(EngineCore_DP0 pid=327402) .b8 54
(EngineCore_DP0 pid=327402) .b8 52
(EngineCore_DP0 pid=327402) .b8 0
(EngineCore_DP0 pid=327402) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=327402) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=327402) .b8 113
(EngineCore_DP0 pid=327402) .b8 117
(EngineCore_DP0 pid=327402) .b8 97
(EngineCore_DP0 pid=327402) .b8 110
(EngineCore_DP0 pid=327402) .b8 116
(EngineCore_DP0 pid=327402) .b8 95
(EngineCore_DP0 pid=327402) .b8 115
(EngineCore_DP0 pid=327402) .b8 108
(EngineCore_DP0 pid=327402) .b8 105
(EngineCore_DP0 pid=327402) .b8 100
(EngineCore_DP0 pid=327402) .b8 101
(EngineCore_DP0 pid=327402) .b8 95
(EngineCore_DP0 pid=327402) .b8 105
(EngineCore_DP0 pid=327402) .b8 110
(EngineCore_DP0 pid=327402) .b8 116
(EngineCore_DP0 pid=327402) .b8 56
(EngineCore_DP0 pid=327402) .b8 95
(EngineCore_DP0 pid=327402) .b8 107
(EngineCore_DP0 pid=327402) .b8 101
(EngineCore_DP0 pid=327402) .b8 114
(EngineCore_DP0 pid=327402) .b8 110
(EngineCore_DP0 pid=327402) .b8 101
(EngineCore_DP0 pid=327402) .b8 108
(EngineCore_DP0 pid=327402) .b8 0
(EngineCore_DP0 pid=327402) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=327402) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=327402) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=327402) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=327402) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=327402) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=327402) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=327402) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=327402) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=327402) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=327402) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=327402) .b8 1
(EngineCore_DP0 pid=327402) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=327402) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=327402) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=327402) 	}
(EngineCore_DP0 pid=327402) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=327402) 
(EngineCore_DP0 pid=327402) ================================================================
(EngineCore_DP0 pid=327402) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=327402) 
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp_k2esk53.ptx', '-o', '/tmp/tmp_k2esk53.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866] 
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866] 
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866] 
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp_k2esk53.ptx -o /tmp/tmp_k2esk53.ptx.o
(EngineCore_DP0 pid=327402) ERROR 01-25 19:09:00 [core.py:866] 

STDERR:
[2026-01-25 19:08:43] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:08:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:08:43] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:08:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:08:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:08:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:08:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:08:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:08:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:08:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:08:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:08:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:08:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:08:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:08:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:08:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:08:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:08:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:08:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=327402) [2026-01-25 19:08:47] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=327402) [2026-01-25 19:08:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=327402) [2026-01-25 19:08:47] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=327402) [2026-01-25 19:08:47] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=327402) [2026-01-25 19:08:47] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=327402) [2026-01-25 19:08:47] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=327402) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=327402) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.92s/it]
(EngineCore_DP0 pid=327402) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.92s/it]
(EngineCore_DP0 pid=327402) 
(EngineCore_DP0 pid=327402) [2026-01-25 19:08:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=327402) [2026-01-25 19:08:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=327402) [2026-01-25 19:08:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=327402) [2026-01-25 19:08:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=327402) [2026-01-25 19:08:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=327402) [2026-01-25 19:08:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=327402) [2026-01-25 19:08:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=327402) [2026-01-25 19:08:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=327402) Process EngineCore_DP0:
(EngineCore_DP0 pid=327402) Traceback (most recent call last):
(EngineCore_DP0 pid=327402)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=327402)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=327402)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=327402)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=327402) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp_k2esk53.ptx', '-o', '/tmp/tmp_k2esk53.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=327402) 
(EngineCore_DP0 pid=327402) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=327402) 
(EngineCore_DP0 pid=327402) Traceback (most recent call last):
(EngineCore_DP0 pid=327402)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=327402)     self.run()
(EngineCore_DP0 pid=327402)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=327402)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=327402)     raise e
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=327402)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=327402)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=327402)     super().__init__(
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=327402)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=327402)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=327402)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=327402)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=327402)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=327402)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=327402)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=327402)     return func(*args, **kwargs)
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=327402)     return func(*args, **kwargs)
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=327402)     self.model_runner.profile_run()
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=327402)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=327402)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=327402)     return func(*args, **kwargs)
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=327402)     outputs = self.model(
(EngineCore_DP0 pid=327402)               ^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=327402)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=327402)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=327402)     model_output = self.model(
(EngineCore_DP0 pid=327402)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=327402)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=327402)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=327402)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=327402)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=327402)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=327402)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=327402)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=327402)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=327402)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=327402)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=327402)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=327402)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=327402)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=327402)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=327402)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=327402)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=327402)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=327402)     return self._linear_fn(
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=327402)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=327402)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=327402)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=327402)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=327402)     return fn(input, L)
(EngineCore_DP0 pid=327402)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=327402)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=327402)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=327402)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=327402)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=327402)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=327402)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=327402)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=327402)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=327402)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=327402)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=327402)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=327402)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=327402)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=327402)     raise PTXASError(error)
(EngineCore_DP0 pid=327402) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=327402) `ptxas` stderr:
(EngineCore_DP0 pid=327402) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=327402) 
(EngineCore_DP0 pid=327402) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp_k2esk53.ptx -o /tmp/tmp_k2esk53.ptx.o
(EngineCore_DP0 pid=327402) 
[rank0]:[W125 19:09:00.596987696 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 19:09:02
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:09:28 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:09:28 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=328222) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=328222) 
(EngineCore_DP0 pid=328222) 
(EngineCore_DP0 pid=328222) ================================================================
(EngineCore_DP0 pid=328222) Internal Triton PTX codegen error
(EngineCore_DP0 pid=328222) `ptxas` stderr:
(EngineCore_DP0 pid=328222) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=328222) 
(EngineCore_DP0 pid=328222) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpwpflavt9.ptx -o /tmp/tmpwpflavt9.ptx.o
(EngineCore_DP0 pid=328222) 
(EngineCore_DP0 pid=328222) 
(EngineCore_DP0 pid=328222) //
(EngineCore_DP0 pid=328222) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=328222) //
(EngineCore_DP0 pid=328222) 
(EngineCore_DP0 pid=328222) .version 8.7
(EngineCore_DP0 pid=328222) .target sm_121a
(EngineCore_DP0 pid=328222) .address_size 64
(EngineCore_DP0 pid=328222) 
(EngineCore_DP0 pid=328222) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=328222) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=328222)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=328222) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=328222) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=328222) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=328222) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=328222) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=328222) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=328222) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=328222) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=328222) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=328222) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=328222) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=328222) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=328222) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=328222) )
(EngineCore_DP0 pid=328222) .reqntid 512
(EngineCore_DP0 pid=328222) {
(EngineCore_DP0 pid=328222) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=328222) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=328222) 	.reg .b32 	%r<255>;
(EngineCore_DP0 pid=328222) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=328222) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=328222) $L__func_begin0:
(EngineCore_DP0 pid=328222) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=328222) 
(EngineCore_DP0 pid=328222) // %bb.0:
(EngineCore_DP0 pid=328222) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=328222) 	ld.param.b32 	%r28, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=328222) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=328222) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=328222) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=328222) $L__tmp0:
(EngineCore_DP0 pid=328222) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=328222) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=328222) 	ld.param.b32 	%r31, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=328222) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=328222) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=328222) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=328222) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=328222) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=328222) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=328222) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=328222) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=328222) 	mov.b32 	%r253, 0f2B8CBCCC;
(EngineCore_DP0 pid=328222) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=328222) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=328222) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=328222) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=328222) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=328222) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=328222) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=328222) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=328222) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=328222) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=328222) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=328222) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=328222) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=328222) 	mov.b32 	%r251, 0f00000000;
(EngineCore_DP0 pid=328222) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=328222) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=328222) 	mov.b32 	%r252, %r49;
(EngineCore_DP0 pid=328222) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=328222) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=328222) 	add.s32 	%r59, %r4, %r252;
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=328222) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=328222) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=328222) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=328222) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=328222) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=328222) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=328222) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=328222) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=328222) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=328222) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=328222) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=328222) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=328222) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=328222) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=328222) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=328222) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=328222) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=328222) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=328222) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=328222) $L__tmp1:
(EngineCore_DP0 pid=328222) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	bar.sync 	0;
(EngineCore_DP0 pid=328222) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=328222) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=328222) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=328222) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=328222) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=328222) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=328222) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=328222) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=328222) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=328222) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=328222) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=328222) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=328222) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=328222) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=328222) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=328222) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=328222) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=328222) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=328222) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	bar.sync 	0;
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=328222) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=328222) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=328222) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=328222) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=328222) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=328222) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=328222) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=328222) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	bar.sync 	0;
(EngineCore_DP0 pid=328222) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=328222) $L__tmp2:
(EngineCore_DP0 pid=328222) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=328222) 	max.f32 	%r251, %r251, %r77;
(EngineCore_DP0 pid=328222) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=328222) 	add.s32 	%r252, %r252, 4096;
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p6, %r252, %r28;
(EngineCore_DP0 pid=328222) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=328222) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=328222) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=328222) 	max.f32 	%r253, %r251, 0f2B8CBCCC;
(EngineCore_DP0 pid=328222) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=328222) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=328222) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=328222) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=328222) 	div.full.f32 	%r80, %r253, %r79;
(EngineCore_DP0 pid=328222) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=328222) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=328222) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=328222) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=328222) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=328222) 	shl.b32 	%r15, %r29, 2;
(EngineCore_DP0 pid=328222) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=328222) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=328222) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=328222) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=328222) 	ld.param.b32 	%r33, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=328222) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=328222) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=328222) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=328222) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=328222) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=328222) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=328222) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=328222) 	div.full.f32 	%r14, %r79, %r253;
(EngineCore_DP0 pid=328222) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=328222) 	mov.b32 	%r254, 0;
(EngineCore_DP0 pid=328222) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=328222)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=328222) 	.loc	1 313 31                        // quant_slide_tuned_Llama3.2-1B.py:313:31
(EngineCore_DP0 pid=328222) 	add.s32 	%r86, %r16, %r254;
(EngineCore_DP0 pid=328222) 	or.b32 	%r87, %r254, 2;
(EngineCore_DP0 pid=328222) 	or.b32 	%r88, %r254, 3;
(EngineCore_DP0 pid=328222) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p25, %r86, %r15;
(EngineCore_DP0 pid=328222) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=328222) 	shr.s32 	%r89, %r86, 2;
(EngineCore_DP0 pid=328222) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=328222) 	add.s32 	%r90, %r254, 1;
(EngineCore_DP0 pid=328222) 	shr.s32 	%r91, %r90, 31;
(EngineCore_DP0 pid=328222) 	shr.u32 	%r92, %r91, 30;
(EngineCore_DP0 pid=328222) 	add.s32 	%r93, %r90, %r92;
(EngineCore_DP0 pid=328222) 	and.b32 	%r94, %r93, 2147483644;
(EngineCore_DP0 pid=328222) 	sub.s32 	%r95, %r90, %r94;
(EngineCore_DP0 pid=328222) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=328222) 	shl.b32 	%r96, %r95, 1;
(EngineCore_DP0 pid=328222) 	.loc	1 319 22                        // quant_slide_tuned_Llama3.2-1B.py:319:22
(EngineCore_DP0 pid=328222) 	mul.lo.s32 	%r97, %r89, 10;
(EngineCore_DP0 pid=328222) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=328222) 	add.s32 	%r98, %r97, %r96;
(EngineCore_DP0 pid=328222) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=328222) 	shr.s32 	%r99, %r254, 31;
(EngineCore_DP0 pid=328222) 	shr.u32 	%r100, %r99, 30;
(EngineCore_DP0 pid=328222) 	add.s32 	%r101, %r88, %r100;
(EngineCore_DP0 pid=328222) 	and.b32 	%r102, %r101, 2147483644;
(EngineCore_DP0 pid=328222) 	sub.s32 	%r103, %r88, %r102;
(EngineCore_DP0 pid=328222) 	add.s32 	%r104, %r87, %r100;
(EngineCore_DP0 pid=328222) 	and.b32 	%r105, %r104, 2147483644;
(EngineCore_DP0 pid=328222) 	sub.s32 	%r106, %r87, %r105;
(EngineCore_DP0 pid=328222) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=328222) 	shl.b32 	%r107, %r106, 1;
(EngineCore_DP0 pid=328222) 	shl.b32 	%r108, %r103, 1;
(EngineCore_DP0 pid=328222) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=328222) 	add.s32 	%r109, %r97, %r108;
(EngineCore_DP0 pid=328222) 	add.s32 	%r110, %r97, %r107;
(EngineCore_DP0 pid=328222) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p26, %r97, %r27;
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p27, %r98, %r27;
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p28, %r110, %r27;
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p29, %r109, %r27;
(EngineCore_DP0 pid=328222) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=328222) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=328222) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=328222) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=328222) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=328222) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=328222) 	mad.wide.s32 	%rd8, %r97, 2, %rd1;
(EngineCore_DP0 pid=328222) 	mad.wide.s32 	%rd9, %r98, 2, %rd1;
(EngineCore_DP0 pid=328222) 	mad.wide.s32 	%rd10, %r110, 2, %rd1;
(EngineCore_DP0 pid=328222) 	mad.wide.s32 	%rd11, %r109, 2, %rd1;
(EngineCore_DP0 pid=328222) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=328222) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=328222) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=328222) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=328222) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=328222) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=328222) 	cvt.f32.bf16 	%r111, %rs24;
(EngineCore_DP0 pid=328222) 	cvt.f32.bf16 	%r112, %rs26;
(EngineCore_DP0 pid=328222) 	cvt.f32.bf16 	%r113, %rs28;
(EngineCore_DP0 pid=328222) 	cvt.f32.bf16 	%r114, %rs30;
(EngineCore_DP0 pid=328222) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=328222) 	or.b32 	%r115, %r97, 1;
(EngineCore_DP0 pid=328222) 	or.b32 	%r116, %r98, 1;
(EngineCore_DP0 pid=328222) 	or.b32 	%r117, %r110, 1;
(EngineCore_DP0 pid=328222) 	or.b32 	%r118, %r109, 1;
(EngineCore_DP0 pid=328222) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p30, %r115, %r27;
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p31, %r116, %r27;
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p32, %r117, %r27;
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p33, %r118, %r27;
(EngineCore_DP0 pid=328222) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=328222) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=328222) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=328222) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=328222) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=328222) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=328222) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=328222) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=328222) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=328222) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=328222) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=328222) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=328222) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=328222) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=328222) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=328222) 	cvt.f32.bf16 	%r119, %rs32;
(EngineCore_DP0 pid=328222) 	cvt.f32.bf16 	%r120, %rs34;
(EngineCore_DP0 pid=328222) 	cvt.f32.bf16 	%r121, %rs36;
(EngineCore_DP0 pid=328222) 	cvt.f32.bf16 	%r122, %rs38;
(EngineCore_DP0 pid=328222) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=328222) 	add.s32 	%r123, %r98, 2;
(EngineCore_DP0 pid=328222) 	add.s32 	%r124, %r110, 2;
(EngineCore_DP0 pid=328222) 	add.s32 	%r125, %r109, 2;
(EngineCore_DP0 pid=328222) 	add.s32 	%r126, %r98, 3;
(EngineCore_DP0 pid=328222) 	add.s32 	%r127, %r110, 3;
(EngineCore_DP0 pid=328222) 	add.s32 	%r128, %r109, 3;
(EngineCore_DP0 pid=328222) 	add.s32 	%r129, %r97, 2;
(EngineCore_DP0 pid=328222) 	add.s32 	%r130, %r97, 3;
(EngineCore_DP0 pid=328222) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p34, %r128, %r27;
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p35, %r127, %r27;
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p36, %r126, %r27;
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p37, %r125, %r27;
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p38, %r124, %r27;
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p39, %r123, %r27;
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p40, %r130, %r27;
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p41, %r129, %r27;
(EngineCore_DP0 pid=328222) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=328222) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=328222) 	and.pred 	%p18, %p25, %p39;
(EngineCore_DP0 pid=328222) 	and.pred 	%p19, %p25, %p38;
(EngineCore_DP0 pid=328222) 	and.pred 	%p20, %p25, %p37;
(EngineCore_DP0 pid=328222) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=328222) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=328222) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=328222) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=328222) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=328222) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=328222) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=328222) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=328222) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=328222) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=328222) 	cvt.f32.bf16 	%r131, %rs40;
(EngineCore_DP0 pid=328222) 	cvt.f32.bf16 	%r132, %rs42;
(EngineCore_DP0 pid=328222) 	cvt.f32.bf16 	%r133, %rs44;
(EngineCore_DP0 pid=328222) 	cvt.f32.bf16 	%r134, %rs46;
(EngineCore_DP0 pid=328222) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=328222) 	and.pred 	%p21, %p25, %p40;
(EngineCore_DP0 pid=328222) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=328222) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=328222) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=328222) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=328222) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=328222) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=328222) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=328222) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=328222) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=328222) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=328222) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=328222) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=328222) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=328222) 	cvt.f32.bf16 	%r135, %rs48;
(EngineCore_DP0 pid=328222) 	cvt.f32.bf16 	%r136, %rs50;
(EngineCore_DP0 pid=328222) 	cvt.f32.bf16 	%r137, %rs52;
(EngineCore_DP0 pid=328222) 	cvt.f32.bf16 	%r138, %rs54;
(EngineCore_DP0 pid=328222) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=328222) 	mul.f32 	%r139, %r14, %r111;
(EngineCore_DP0 pid=328222) 	mul.f32 	%r140, %r14, %r112;
(EngineCore_DP0 pid=328222) 	mul.f32 	%r141, %r14, %r113;
(EngineCore_DP0 pid=328222) 	mul.f32 	%r142, %r14, %r114;
(EngineCore_DP0 pid=328222) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=328222) 	cvt.rni.f32.f32 	%r143, %r139;
(EngineCore_DP0 pid=328222) 	cvt.rni.f32.f32 	%r144, %r140;
(EngineCore_DP0 pid=328222) 	cvt.rni.f32.f32 	%r145, %r141;
(EngineCore_DP0 pid=328222) 	cvt.rni.f32.f32 	%r146, %r142;
(EngineCore_DP0 pid=328222) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=328222) 	max.f32 	%r147, %r143, 0fC3000000;
(EngineCore_DP0 pid=328222) 	min.f32 	%r148, %r147, 0f42FE0000;
(EngineCore_DP0 pid=328222) 	max.f32 	%r149, %r144, 0fC3000000;
(EngineCore_DP0 pid=328222) 	min.f32 	%r150, %r149, 0f42FE0000;
(EngineCore_DP0 pid=328222) 	max.f32 	%r151, %r145, 0fC3000000;
(EngineCore_DP0 pid=328222) 	min.f32 	%r152, %r151, 0f42FE0000;
(EngineCore_DP0 pid=328222) 	max.f32 	%r153, %r146, 0fC3000000;
(EngineCore_DP0 pid=328222) 	min.f32 	%r154, %r153, 0f42FE0000;
(EngineCore_DP0 pid=328222) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=328222) 	cvt.rzi.s32.f32 	%r155, %r148;
(EngineCore_DP0 pid=328222) 	cvt.rzi.s32.f32 	%r156, %r150;
(EngineCore_DP0 pid=328222) 	cvt.rzi.s32.f32 	%r157, %r152;
(EngineCore_DP0 pid=328222) 	cvt.rzi.s32.f32 	%r158, %r154;
(EngineCore_DP0 pid=328222) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=328222) 	and.b32 	%r159, %r155, 255;
(EngineCore_DP0 pid=328222) 	and.b32 	%r160, %r156, 255;
(EngineCore_DP0 pid=328222) 	and.b32 	%r161, %r157, 255;
(EngineCore_DP0 pid=328222) 	and.b32 	%r162, %r158, 255;
(EngineCore_DP0 pid=328222) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=328222) 	mul.f32 	%r163, %r14, %r119;
(EngineCore_DP0 pid=328222) 	mul.f32 	%r164, %r14, %r120;
(EngineCore_DP0 pid=328222) 	mul.f32 	%r165, %r14, %r121;
(EngineCore_DP0 pid=328222) 	mul.f32 	%r166, %r14, %r122;
(EngineCore_DP0 pid=328222) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=328222) 	cvt.rni.f32.f32 	%r167, %r163;
(EngineCore_DP0 pid=328222) 	cvt.rni.f32.f32 	%r168, %r164;
(EngineCore_DP0 pid=328222) 	cvt.rni.f32.f32 	%r169, %r165;
(EngineCore_DP0 pid=328222) 	cvt.rni.f32.f32 	%r170, %r166;
(EngineCore_DP0 pid=328222) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=328222) 	mul.f32 	%r171, %r14, %r131;
(EngineCore_DP0 pid=328222) 	mul.f32 	%r172, %r14, %r132;
(EngineCore_DP0 pid=328222) 	mul.f32 	%r173, %r14, %r133;
(EngineCore_DP0 pid=328222) 	mul.f32 	%r174, %r14, %r134;
(EngineCore_DP0 pid=328222) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=328222) 	cvt.rni.f32.f32 	%r175, %r171;
(EngineCore_DP0 pid=328222) 	cvt.rni.f32.f32 	%r176, %r172;
(EngineCore_DP0 pid=328222) 	cvt.rni.f32.f32 	%r177, %r173;
(EngineCore_DP0 pid=328222) 	cvt.rni.f32.f32 	%r178, %r174;
(EngineCore_DP0 pid=328222) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=328222) 	mul.f32 	%r179, %r14, %r135;
(EngineCore_DP0 pid=328222) 	mul.f32 	%r180, %r14, %r136;
(EngineCore_DP0 pid=328222) 	mul.f32 	%r181, %r14, %r137;
(EngineCore_DP0 pid=328222) 	mul.f32 	%r182, %r14, %r138;
(EngineCore_DP0 pid=328222) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=328222) 	cvt.rni.f32.f32 	%r183, %r179;
(EngineCore_DP0 pid=328222) 	cvt.rni.f32.f32 	%r184, %r180;
(EngineCore_DP0 pid=328222) 	cvt.rni.f32.f32 	%r185, %r181;
(EngineCore_DP0 pid=328222) 	cvt.rni.f32.f32 	%r186, %r182;
(EngineCore_DP0 pid=328222) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=328222) 	max.f32 	%r187, %r183, 0fC3000000;
(EngineCore_DP0 pid=328222) 	min.f32 	%r188, %r187, 0f42FE0000;
(EngineCore_DP0 pid=328222) 	max.f32 	%r189, %r184, 0fC3000000;
(EngineCore_DP0 pid=328222) 	min.f32 	%r190, %r189, 0f42FE0000;
(EngineCore_DP0 pid=328222) 	max.f32 	%r191, %r185, 0fC3000000;
(EngineCore_DP0 pid=328222) 	min.f32 	%r192, %r191, 0f42FE0000;
(EngineCore_DP0 pid=328222) 	max.f32 	%r193, %r186, 0fC3000000;
(EngineCore_DP0 pid=328222) 	min.f32 	%r194, %r193, 0f42FE0000;
(EngineCore_DP0 pid=328222) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=328222) 	cvt.rzi.s32.f32 	%r195, %r188;
(EngineCore_DP0 pid=328222) 	cvt.rzi.s32.f32 	%r196, %r190;
(EngineCore_DP0 pid=328222) 	cvt.rzi.s32.f32 	%r197, %r192;
(EngineCore_DP0 pid=328222) 	cvt.rzi.s32.f32 	%r198, %r194;
(EngineCore_DP0 pid=328222) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=328222) 	max.f32 	%r199, %r175, 0fC3000000;
(EngineCore_DP0 pid=328222) 	max.f32 	%r200, %r167, 0fC3000000;
(EngineCore_DP0 pid=328222) 	min.f32 	%r201, %r200, 0f42FE0000;
(EngineCore_DP0 pid=328222) 	min.f32 	%r202, %r199, 0f42FE0000;
(EngineCore_DP0 pid=328222) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=328222) 	cvt.rzi.s32.f32 	%r203, %r202;
(EngineCore_DP0 pid=328222) 	cvt.rzi.s32.f32 	%r204, %r201;
(EngineCore_DP0 pid=328222) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=328222) 	shl.b32 	%r205, %r204, 8;
(EngineCore_DP0 pid=328222) 	shl.b32 	%r206, %r203, 16;
(EngineCore_DP0 pid=328222) 	and.b32 	%r207, %r206, 16711680;
(EngineCore_DP0 pid=328222) 	and.b32 	%r208, %r205, 65280;
(EngineCore_DP0 pid=328222) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=328222) 	or.b32 	%r209, %r208, %r159;
(EngineCore_DP0 pid=328222) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=328222) 	max.f32 	%r210, %r176, 0fC3000000;
(EngineCore_DP0 pid=328222) 	max.f32 	%r211, %r168, 0fC3000000;
(EngineCore_DP0 pid=328222) 	min.f32 	%r212, %r211, 0f42FE0000;
(EngineCore_DP0 pid=328222) 	min.f32 	%r213, %r210, 0f42FE0000;
(EngineCore_DP0 pid=328222) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=328222) 	cvt.rzi.s32.f32 	%r214, %r213;
(EngineCore_DP0 pid=328222) 	cvt.rzi.s32.f32 	%r215, %r212;
(EngineCore_DP0 pid=328222) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=328222) 	shl.b32 	%r216, %r215, 8;
(EngineCore_DP0 pid=328222) 	shl.b32 	%r217, %r214, 16;
(EngineCore_DP0 pid=328222) 	and.b32 	%r218, %r217, 16711680;
(EngineCore_DP0 pid=328222) 	and.b32 	%r219, %r216, 65280;
(EngineCore_DP0 pid=328222) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=328222) 	or.b32 	%r220, %r219, %r160;
(EngineCore_DP0 pid=328222) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=328222) 	max.f32 	%r221, %r177, 0fC3000000;
(EngineCore_DP0 pid=328222) 	max.f32 	%r222, %r169, 0fC3000000;
(EngineCore_DP0 pid=328222) 	min.f32 	%r223, %r222, 0f42FE0000;
(EngineCore_DP0 pid=328222) 	min.f32 	%r224, %r221, 0f42FE0000;
(EngineCore_DP0 pid=328222) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=328222) 	cvt.rzi.s32.f32 	%r225, %r224;
(EngineCore_DP0 pid=328222) 	cvt.rzi.s32.f32 	%r226, %r223;
(EngineCore_DP0 pid=328222) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=328222) 	shl.b32 	%r227, %r226, 8;
(EngineCore_DP0 pid=328222) 	shl.b32 	%r228, %r225, 16;
(EngineCore_DP0 pid=328222) 	and.b32 	%r229, %r228, 16711680;
(EngineCore_DP0 pid=328222) 	and.b32 	%r230, %r227, 65280;
(EngineCore_DP0 pid=328222) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=328222) 	or.b32 	%r231, %r230, %r161;
(EngineCore_DP0 pid=328222) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=328222) 	max.f32 	%r232, %r178, 0fC3000000;
(EngineCore_DP0 pid=328222) 	max.f32 	%r233, %r170, 0fC3000000;
(EngineCore_DP0 pid=328222) 	min.f32 	%r234, %r233, 0f42FE0000;
(EngineCore_DP0 pid=328222) 	min.f32 	%r235, %r232, 0f42FE0000;
(EngineCore_DP0 pid=328222) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=328222) 	cvt.rzi.s32.f32 	%r236, %r235;
(EngineCore_DP0 pid=328222) 	cvt.rzi.s32.f32 	%r237, %r234;
(EngineCore_DP0 pid=328222) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=328222) 	shl.b32 	%r238, %r237, 8;
(EngineCore_DP0 pid=328222) 	shl.b32 	%r239, %r236, 16;
(EngineCore_DP0 pid=328222) 	and.b32 	%r240, %r239, 16711680;
(EngineCore_DP0 pid=328222) 	and.b32 	%r241, %r238, 65280;
(EngineCore_DP0 pid=328222) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=328222) 	or.b32 	%r242, %r241, %r162;
(EngineCore_DP0 pid=328222) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=328222) 	or.b32 	%r243, %r209, %r207;
(EngineCore_DP0 pid=328222) 	or.b32 	%r244, %r220, %r218;
(EngineCore_DP0 pid=328222) 	or.b32 	%r245, %r231, %r229;
(EngineCore_DP0 pid=328222) 	or.b32 	%r246, %r242, %r240;
(EngineCore_DP0 pid=328222) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=328222) 	shl.b32 	%r247, %r195, 24;
(EngineCore_DP0 pid=328222) 	shl.b32 	%r248, %r196, 24;
(EngineCore_DP0 pid=328222) 	shl.b32 	%r249, %r197, 24;
(EngineCore_DP0 pid=328222) 	shl.b32 	%r250, %r198, 24;
(EngineCore_DP0 pid=328222) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=328222) 	or.b32 	%r82, %r243, %r247;
(EngineCore_DP0 pid=328222) 	or.b32 	%r83, %r244, %r248;
(EngineCore_DP0 pid=328222) 	or.b32 	%r84, %r245, %r249;
(EngineCore_DP0 pid=328222) 	or.b32 	%r85, %r246, %r250;
(EngineCore_DP0 pid=328222) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=328222) 	mad.wide.s32 	%rd24, %r86, 4, %rd2;
(EngineCore_DP0 pid=328222) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=328222) 	// begin inline asm
(EngineCore_DP0 pid=328222) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r82, %r83, %r84, %r85 };
(EngineCore_DP0 pid=328222) 	// end inline asm
(EngineCore_DP0 pid=328222) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=328222) 	add.s32 	%r254, %r254, 2048;
(EngineCore_DP0 pid=328222) 	setp.lt.s32 	%p42, %r254, %r15;
(EngineCore_DP0 pid=328222) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=328222) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=328222) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=328222) 	ret;
(EngineCore_DP0 pid=328222) $L__tmp3:
(EngineCore_DP0 pid=328222) $L__func_end0:
(EngineCore_DP0 pid=328222)                                         // -- End function
(EngineCore_DP0 pid=328222) }
(EngineCore_DP0 pid=328222) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=328222) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=328222) 	.section	.debug_abbrev
(EngineCore_DP0 pid=328222) 	{
(EngineCore_DP0 pid=328222) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=328222) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=328222) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=328222) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=328222) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=328222) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=328222) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=328222) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=328222) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=328222) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=328222) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=328222) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=328222) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=328222) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=328222) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=328222) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=328222) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=328222) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=328222) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=328222) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=328222) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=328222) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=328222) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=328222) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=328222) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=328222) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=328222) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=328222) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=328222) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=328222) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=328222) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=328222) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=328222) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=328222) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=328222) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=328222) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=328222) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=328222) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=328222) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=328222) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=328222) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=328222) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=328222) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=328222) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=328222) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=328222) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=328222) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=328222) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=328222) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=328222) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=328222) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=328222) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=328222) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=328222) 	}
(EngineCore_DP0 pid=328222) 	.section	.debug_info
(EngineCore_DP0 pid=328222) 	{
(EngineCore_DP0 pid=328222) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=328222) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=328222) .b8 0
(EngineCore_DP0 pid=328222) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=328222) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=328222) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=328222) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=328222) .b8 114
(EngineCore_DP0 pid=328222) .b8 105
(EngineCore_DP0 pid=328222) .b8 116
(EngineCore_DP0 pid=328222) .b8 111
(EngineCore_DP0 pid=328222) .b8 110
(EngineCore_DP0 pid=328222) .b8 0
(EngineCore_DP0 pid=328222) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=328222) .b8 0
(EngineCore_DP0 pid=328222) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=328222) .b8 117
(EngineCore_DP0 pid=328222) .b8 97
(EngineCore_DP0 pid=328222) .b8 110
(EngineCore_DP0 pid=328222) .b8 116
(EngineCore_DP0 pid=328222) .b8 95
(EngineCore_DP0 pid=328222) .b8 115
(EngineCore_DP0 pid=328222) .b8 108
(EngineCore_DP0 pid=328222) .b8 105
(EngineCore_DP0 pid=328222) .b8 100
(EngineCore_DP0 pid=328222) .b8 101
(EngineCore_DP0 pid=328222) .b8 95
(EngineCore_DP0 pid=328222) .b8 116
(EngineCore_DP0 pid=328222) .b8 117
(EngineCore_DP0 pid=328222) .b8 110
(EngineCore_DP0 pid=328222) .b8 101
(EngineCore_DP0 pid=328222) .b8 100
(EngineCore_DP0 pid=328222) .b8 95
(EngineCore_DP0 pid=328222) .b8 76
(EngineCore_DP0 pid=328222) .b8 108
(EngineCore_DP0 pid=328222) .b8 97
(EngineCore_DP0 pid=328222) .b8 109
(EngineCore_DP0 pid=328222) .b8 97
(EngineCore_DP0 pid=328222) .b8 51
(EngineCore_DP0 pid=328222) .b8 46
(EngineCore_DP0 pid=328222) .b8 50
(EngineCore_DP0 pid=328222) .b8 45
(EngineCore_DP0 pid=328222) .b8 49
(EngineCore_DP0 pid=328222) .b8 66
(EngineCore_DP0 pid=328222) .b8 46
(EngineCore_DP0 pid=328222) .b8 112
(EngineCore_DP0 pid=328222) .b8 121
(EngineCore_DP0 pid=328222) .b8 0
(EngineCore_DP0 pid=328222) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=328222) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=328222) .b8 114
(EngineCore_DP0 pid=328222) .b8 111
(EngineCore_DP0 pid=328222) .b8 111
(EngineCore_DP0 pid=328222) .b8 116
(EngineCore_DP0 pid=328222) .b8 47
(EngineCore_DP0 pid=328222) .b8 118
(EngineCore_DP0 pid=328222) .b8 108
(EngineCore_DP0 pid=328222) .b8 108
(EngineCore_DP0 pid=328222) .b8 109
(EngineCore_DP0 pid=328222) .b8 98
(EngineCore_DP0 pid=328222) .b8 101
(EngineCore_DP0 pid=328222) .b8 110
(EngineCore_DP0 pid=328222) .b8 99
(EngineCore_DP0 pid=328222) .b8 104
(EngineCore_DP0 pid=328222) .b8 47
(EngineCore_DP0 pid=328222) .b8 115
(EngineCore_DP0 pid=328222) .b8 108
(EngineCore_DP0 pid=328222) .b8 105
(EngineCore_DP0 pid=328222) .b8 100
(EngineCore_DP0 pid=328222) .b8 101
(EngineCore_DP0 pid=328222) .b8 115
(EngineCore_DP0 pid=328222) .b8 112
(EngineCore_DP0 pid=328222) .b8 97
(EngineCore_DP0 pid=328222) .b8 114
(EngineCore_DP0 pid=328222) .b8 115
(EngineCore_DP0 pid=328222) .b8 101
(EngineCore_DP0 pid=328222) .b8 47
(EngineCore_DP0 pid=328222) .b8 99
(EngineCore_DP0 pid=328222) .b8 115
(EngineCore_DP0 pid=328222) .b8 114
(EngineCore_DP0 pid=328222) .b8 99
(EngineCore_DP0 pid=328222) .b8 47
(EngineCore_DP0 pid=328222) .b8 102
(EngineCore_DP0 pid=328222) .b8 117
(EngineCore_DP0 pid=328222) .b8 115
(EngineCore_DP0 pid=328222) .b8 101
(EngineCore_DP0 pid=328222) .b8 100
(EngineCore_DP0 pid=328222) .b8 95
(EngineCore_DP0 pid=328222) .b8 113
(EngineCore_DP0 pid=328222) .b8 117
(EngineCore_DP0 pid=328222) .b8 97
(EngineCore_DP0 pid=328222) .b8 110
(EngineCore_DP0 pid=328222) .b8 116
(EngineCore_DP0 pid=328222) .b8 95
(EngineCore_DP0 pid=328222) .b8 115
(EngineCore_DP0 pid=328222) .b8 108
(EngineCore_DP0 pid=328222) .b8 105
(EngineCore_DP0 pid=328222) .b8 100
(EngineCore_DP0 pid=328222) .b8 101
(EngineCore_DP0 pid=328222) .b8 95
(EngineCore_DP0 pid=328222) .b8 116
(EngineCore_DP0 pid=328222) .b8 114
(EngineCore_DP0 pid=328222) .b8 105
(EngineCore_DP0 pid=328222) .b8 116
(EngineCore_DP0 pid=328222) .b8 111
(EngineCore_DP0 pid=328222) .b8 110
(EngineCore_DP0 pid=328222) .b8 47
(EngineCore_DP0 pid=328222) .b8 98
(EngineCore_DP0 pid=328222) .b8 117
(EngineCore_DP0 pid=328222) .b8 105
(EngineCore_DP0 pid=328222) .b8 108
(EngineCore_DP0 pid=328222) .b8 100
(EngineCore_DP0 pid=328222) .b8 47
(EngineCore_DP0 pid=328222) .b8 71
(EngineCore_DP0 pid=328222) .b8 66
(EngineCore_DP0 pid=328222) .b8 49
(EngineCore_DP0 pid=328222) .b8 48
(EngineCore_DP0 pid=328222) .b8 95
(EngineCore_DP0 pid=328222) .b8 99
(EngineCore_DP0 pid=328222) .b8 99
(EngineCore_DP0 pid=328222) .b8 49
(EngineCore_DP0 pid=328222) .b8 50
(EngineCore_DP0 pid=328222) .b8 49
(EngineCore_DP0 pid=328222) .b8 95
(EngineCore_DP0 pid=328222) .b8 112
(EngineCore_DP0 pid=328222) .b8 121
(EngineCore_DP0 pid=328222) .b8 51
(EngineCore_DP0 pid=328222) .b8 49
(EngineCore_DP0 pid=328222) .b8 50
(EngineCore_DP0 pid=328222) .b8 95
(EngineCore_DP0 pid=328222) .b8 99
(EngineCore_DP0 pid=328222) .b8 117
(EngineCore_DP0 pid=328222) .b8 49
(EngineCore_DP0 pid=328222) .b8 50
(EngineCore_DP0 pid=328222) .b8 57
(EngineCore_DP0 pid=328222) .b8 95
(EngineCore_DP0 pid=328222) .b8 97
(EngineCore_DP0 pid=328222) .b8 97
(EngineCore_DP0 pid=328222) .b8 114
(EngineCore_DP0 pid=328222) .b8 99
(EngineCore_DP0 pid=328222) .b8 104
(EngineCore_DP0 pid=328222) .b8 54
(EngineCore_DP0 pid=328222) .b8 52
(EngineCore_DP0 pid=328222) .b8 0
(EngineCore_DP0 pid=328222) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=328222) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=328222) .b8 113
(EngineCore_DP0 pid=328222) .b8 117
(EngineCore_DP0 pid=328222) .b8 97
(EngineCore_DP0 pid=328222) .b8 110
(EngineCore_DP0 pid=328222) .b8 116
(EngineCore_DP0 pid=328222) .b8 95
(EngineCore_DP0 pid=328222) .b8 115
(EngineCore_DP0 pid=328222) .b8 108
(EngineCore_DP0 pid=328222) .b8 105
(EngineCore_DP0 pid=328222) .b8 100
(EngineCore_DP0 pid=328222) .b8 101
(EngineCore_DP0 pid=328222) .b8 95
(EngineCore_DP0 pid=328222) .b8 105
(EngineCore_DP0 pid=328222) .b8 110
(EngineCore_DP0 pid=328222) .b8 116
(EngineCore_DP0 pid=328222) .b8 56
(EngineCore_DP0 pid=328222) .b8 95
(EngineCore_DP0 pid=328222) .b8 107
(EngineCore_DP0 pid=328222) .b8 101
(EngineCore_DP0 pid=328222) .b8 114
(EngineCore_DP0 pid=328222) .b8 110
(EngineCore_DP0 pid=328222) .b8 101
(EngineCore_DP0 pid=328222) .b8 108
(EngineCore_DP0 pid=328222) .b8 0
(EngineCore_DP0 pid=328222) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=328222) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=328222) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=328222) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=328222) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=328222) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=328222) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=328222) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=328222) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=328222) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=328222) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=328222) .b8 1
(EngineCore_DP0 pid=328222) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=328222) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=328222) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=328222) 	}
(EngineCore_DP0 pid=328222) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=328222) 
(EngineCore_DP0 pid=328222) ================================================================
(EngineCore_DP0 pid=328222) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=328222) 
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpwpflavt9.ptx', '-o', '/tmp/tmpwpflavt9.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866] 
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866] 
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866] 
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpwpflavt9.ptx -o /tmp/tmpwpflavt9.ptx.o
(EngineCore_DP0 pid=328222) ERROR 01-25 19:09:45 [core.py:866] 

STDERR:
[2026-01-25 19:09:28] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:09:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:09:28] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:09:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:09:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:09:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:09:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:09:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:09:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:09:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:09:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:09:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:09:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:09:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:09:31] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:09:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:09:31] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:09:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:09:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:09:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:09:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:09:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:09:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:09:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:09:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:09:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:09:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:09:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=328222) [2026-01-25 19:09:32] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=328222) [2026-01-25 19:09:32] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=328222) [2026-01-25 19:09:32] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=328222) [2026-01-25 19:09:32] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=328222) [2026-01-25 19:09:32] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=328222) [2026-01-25 19:09:32] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=328222) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=328222) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.84s/it]
(EngineCore_DP0 pid=328222) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.84s/it]
(EngineCore_DP0 pid=328222) 
(EngineCore_DP0 pid=328222) [2026-01-25 19:09:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=328222) [2026-01-25 19:09:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=328222) [2026-01-25 19:09:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=328222) [2026-01-25 19:09:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=328222) [2026-01-25 19:09:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=328222) [2026-01-25 19:09:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=328222) [2026-01-25 19:09:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=328222) [2026-01-25 19:09:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=328222) Process EngineCore_DP0:
(EngineCore_DP0 pid=328222) Traceback (most recent call last):
(EngineCore_DP0 pid=328222)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=328222)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=328222)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=328222)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=328222) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpwpflavt9.ptx', '-o', '/tmp/tmpwpflavt9.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=328222) 
(EngineCore_DP0 pid=328222) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=328222) 
(EngineCore_DP0 pid=328222) Traceback (most recent call last):
(EngineCore_DP0 pid=328222)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=328222)     self.run()
(EngineCore_DP0 pid=328222)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=328222)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=328222)     raise e
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=328222)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=328222)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=328222)     super().__init__(
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=328222)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=328222)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=328222)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=328222)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=328222)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=328222)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=328222)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=328222)     return func(*args, **kwargs)
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=328222)     return func(*args, **kwargs)
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=328222)     self.model_runner.profile_run()
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=328222)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=328222)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=328222)     return func(*args, **kwargs)
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=328222)     outputs = self.model(
(EngineCore_DP0 pid=328222)               ^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=328222)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=328222)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=328222)     model_output = self.model(
(EngineCore_DP0 pid=328222)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=328222)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=328222)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=328222)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=328222)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=328222)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=328222)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=328222)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=328222)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=328222)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=328222)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=328222)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=328222)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=328222)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=328222)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=328222)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=328222)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=328222)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=328222)     return self._linear_fn(
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=328222)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=328222)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=328222)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=328222)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=328222)     return fn(input, L)
(EngineCore_DP0 pid=328222)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=328222)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=328222)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=328222)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=328222)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=328222)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=328222)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=328222)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=328222)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=328222)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=328222)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=328222)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=328222)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=328222)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=328222)     raise PTXASError(error)
(EngineCore_DP0 pid=328222) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=328222) `ptxas` stderr:
(EngineCore_DP0 pid=328222) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=328222) 
(EngineCore_DP0 pid=328222) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpwpflavt9.ptx -o /tmp/tmpwpflavt9.ptx.o
(EngineCore_DP0 pid=328222) 
[rank0]:[W125 19:09:45.540265422 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-25 19:49:08
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:49:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:49:12 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=375213) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=375213) 
(EngineCore_DP0 pid=375213) 
(EngineCore_DP0 pid=375213) ================================================================
(EngineCore_DP0 pid=375213) Internal Triton PTX codegen error
(EngineCore_DP0 pid=375213) `ptxas` stderr:
(EngineCore_DP0 pid=375213) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=375213) 
(EngineCore_DP0 pid=375213) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmprad6xu1n.ptx -o /tmp/tmprad6xu1n.ptx.o
(EngineCore_DP0 pid=375213) 
(EngineCore_DP0 pid=375213) 
(EngineCore_DP0 pid=375213) //
(EngineCore_DP0 pid=375213) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=375213) //
(EngineCore_DP0 pid=375213) 
(EngineCore_DP0 pid=375213) .version 8.7
(EngineCore_DP0 pid=375213) .target sm_121a
(EngineCore_DP0 pid=375213) .address_size 64
(EngineCore_DP0 pid=375213) 
(EngineCore_DP0 pid=375213) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=375213) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=375213)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=375213) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=375213) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=375213) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=375213) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=375213) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=375213) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=375213) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=375213) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=375213) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=375213) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=375213) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=375213) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=375213) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=375213) )
(EngineCore_DP0 pid=375213) .reqntid 1024
(EngineCore_DP0 pid=375213) {
(EngineCore_DP0 pid=375213) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=375213) 	.reg .b16 	%rs<20>;
(EngineCore_DP0 pid=375213) 	.reg .b32 	%r<120>;
(EngineCore_DP0 pid=375213) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=375213) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=375213) $L__func_begin0:
(EngineCore_DP0 pid=375213) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=375213) 
(EngineCore_DP0 pid=375213) // %bb.0:
(EngineCore_DP0 pid=375213) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=375213) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=375213) 	ld.param.b32 	%r17, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=375213) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=375213) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=375213) $L__tmp0:
(EngineCore_DP0 pid=375213) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=375213) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=375213) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=375213) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=375213) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=375213) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=375213) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=375213) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=375213) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=375213) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=375213) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=375213) 	mov.b32 	%r118, 0f2B8CBCCC;
(EngineCore_DP0 pid=375213) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=375213) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=375213) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=375213) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=375213) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=375213) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=375213) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=375213) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=375213) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=375213) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=375213) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=375213) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=375213) 	mov.b32 	%r116, 0f00000000;
(EngineCore_DP0 pid=375213) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=375213) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=375213) 	mov.b32 	%r117, %r37;
(EngineCore_DP0 pid=375213) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=375213) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=375213) 	add.s32 	%r45, %r3, %r117;
(EngineCore_DP0 pid=375213) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=375213) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=375213) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=375213) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=375213) 	// begin inline asm
(EngineCore_DP0 pid=375213) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=375213) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=375213) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=375213) 	// end inline asm
(EngineCore_DP0 pid=375213) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=375213) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=375213) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=375213) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=375213) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=375213) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=375213) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=375213) $L__tmp1:
(EngineCore_DP0 pid=375213) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	bar.sync 	0;
(EngineCore_DP0 pid=375213) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=375213) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=375213) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=375213) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=375213) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=375213) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=375213) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=375213) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=375213) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=375213) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=375213) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=375213) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=375213) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=375213) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=375213) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	// begin inline asm
(EngineCore_DP0 pid=375213) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=375213) 	// end inline asm
(EngineCore_DP0 pid=375213) 	bar.sync 	0;
(EngineCore_DP0 pid=375213) 	// begin inline asm
(EngineCore_DP0 pid=375213) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=375213) 	// end inline asm
(EngineCore_DP0 pid=375213) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=375213) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=375213) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=375213) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=375213) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=375213) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=375213) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=375213) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=375213) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=375213) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=375213) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375213) 	// begin inline asm
(EngineCore_DP0 pid=375213) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=375213) 	// end inline asm
(EngineCore_DP0 pid=375213) 	bar.sync 	0;
(EngineCore_DP0 pid=375213) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=375213) $L__tmp2:
(EngineCore_DP0 pid=375213) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=375213) 	max.f32 	%r116, %r116, %r65;
(EngineCore_DP0 pid=375213) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=375213) 	add.s32 	%r117, %r117, 4096;
(EngineCore_DP0 pid=375213) 	setp.lt.s32 	%p6, %r117, %r18;
(EngineCore_DP0 pid=375213) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=375213) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=375213) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=375213) 	max.f32 	%r118, %r116, 0f2B8CBCCC;
(EngineCore_DP0 pid=375213) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=375213) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=375213) 	mov.b32 	%r67, 0f42FE0000;
(EngineCore_DP0 pid=375213) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=375213) 	div.full.f32 	%r68, %r118, %r67;
(EngineCore_DP0 pid=375213) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=375213) 	max.f32 	%r66, %r68, 0f37810204;
(EngineCore_DP0 pid=375213) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=375213) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=375213) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=375213) 	// begin inline asm
(EngineCore_DP0 pid=375213) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=375213) 	// end inline asm
(EngineCore_DP0 pid=375213) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=375213) 	shl.b32 	%r14, %r19, 2;
(EngineCore_DP0 pid=375213) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=375213) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=375213) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=375213) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=375213) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=375213) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=375213) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=375213) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=375213) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=375213) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=375213) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=375213) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=375213) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=375213) 	div.full.f32 	%r13, %r67, %r118;
(EngineCore_DP0 pid=375213) 	mov.b32 	%r119, 0;
(EngineCore_DP0 pid=375213) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=375213)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=375213) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=375213) 	add.s32 	%r72, %r2, %r119;
(EngineCore_DP0 pid=375213) 	setp.lt.s32 	%p13, %r72, %r14;
(EngineCore_DP0 pid=375213) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=375213) 	shr.s32 	%r73, %r72, 31;
(EngineCore_DP0 pid=375213) 	shr.u32 	%r74, %r73, 30;
(EngineCore_DP0 pid=375213) 	add.s32 	%r75, %r72, %r74;
(EngineCore_DP0 pid=375213) 	shr.s32 	%r76, %r75, 2;
(EngineCore_DP0 pid=375213) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=375213) 	and.b32 	%r77, %r75, 2147483644;
(EngineCore_DP0 pid=375213) 	sub.s32 	%r78, %r72, %r77;
(EngineCore_DP0 pid=375213) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=375213) 	shl.b32 	%r79, %r78, 1;
(EngineCore_DP0 pid=375213) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=375213) 	mad.lo.s32 	%r80, %r76, 10, %r79;
(EngineCore_DP0 pid=375213) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=375213) 	setp.lt.s32 	%p14, %r80, %r17;
(EngineCore_DP0 pid=375213) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=375213) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=375213) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=375213) 	mad.wide.s32 	%rd8, %r80, 2, %rd1;
(EngineCore_DP0 pid=375213) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=375213) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=375213) 	// begin inline asm
(EngineCore_DP0 pid=375213) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=375213) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=375213) 	// end inline asm
(EngineCore_DP0 pid=375213) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=375213) 	cvt.f32.bf16 	%r81, %rs12;
(EngineCore_DP0 pid=375213) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=375213) 	or.b32 	%r82, %r80, 1;
(EngineCore_DP0 pid=375213) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=375213) 	setp.lt.s32 	%p15, %r82, %r17;
(EngineCore_DP0 pid=375213) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=375213) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=375213) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=375213) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=375213) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=375213) 	// begin inline asm
(EngineCore_DP0 pid=375213) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=375213) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=375213) 	// end inline asm
(EngineCore_DP0 pid=375213) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=375213) 	cvt.f32.bf16 	%r83, %rs14;
(EngineCore_DP0 pid=375213) 	.loc	1 340 48                        // quant_slide_tuned_Llama3.2-3B.py:340:48
(EngineCore_DP0 pid=375213) 	add.s32 	%r84, %r80, 2;
(EngineCore_DP0 pid=375213) 	.loc	1 340 53                        // quant_slide_tuned_Llama3.2-3B.py:340:53
(EngineCore_DP0 pid=375213) 	setp.lt.s32 	%p16, %r84, %r17;
(EngineCore_DP0 pid=375213) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=375213) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=375213) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=375213) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=375213) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=375213) 	// begin inline asm
(EngineCore_DP0 pid=375213) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=375213) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=375213) 	// end inline asm
(EngineCore_DP0 pid=375213) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=375213) 	cvt.f32.bf16 	%r85, %rs16;
(EngineCore_DP0 pid=375213) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=375213) 	add.s32 	%r86, %r80, 3;
(EngineCore_DP0 pid=375213) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=375213) 	setp.lt.s32 	%p17, %r86, %r17;
(EngineCore_DP0 pid=375213) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=375213) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=375213) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=375213) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=375213) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=375213) 	// begin inline asm
(EngineCore_DP0 pid=375213) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=375213) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=375213) 	// end inline asm
(EngineCore_DP0 pid=375213) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=375213) 	cvt.f32.bf16 	%r87, %rs18;
(EngineCore_DP0 pid=375213) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=375213) 	mul.f32 	%r88, %r13, %r81;
(EngineCore_DP0 pid=375213) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=375213) 	cvt.rni.f32.f32 	%r89, %r88;
(EngineCore_DP0 pid=375213) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=375213) 	max.f32 	%r90, %r89, 0fC3000000;
(EngineCore_DP0 pid=375213) 	min.f32 	%r91, %r90, 0f42FE0000;
(EngineCore_DP0 pid=375213) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=375213) 	cvt.rzi.s32.f32 	%r92, %r91;
(EngineCore_DP0 pid=375213) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=375213) 	and.b32 	%r93, %r92, 255;
(EngineCore_DP0 pid=375213) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=375213) 	mul.f32 	%r94, %r13, %r83;
(EngineCore_DP0 pid=375213) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=375213) 	cvt.rni.f32.f32 	%r95, %r94;
(EngineCore_DP0 pid=375213) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=375213) 	mul.f32 	%r96, %r13, %r85;
(EngineCore_DP0 pid=375213) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=375213) 	cvt.rni.f32.f32 	%r97, %r96;
(EngineCore_DP0 pid=375213) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=375213) 	mul.f32 	%r98, %r13, %r87;
(EngineCore_DP0 pid=375213) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=375213) 	cvt.rni.f32.f32 	%r99, %r98;
(EngineCore_DP0 pid=375213) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=375213) 	max.f32 	%r100, %r99, 0fC3000000;
(EngineCore_DP0 pid=375213) 	min.f32 	%r101, %r100, 0f42FE0000;
(EngineCore_DP0 pid=375213) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=375213) 	cvt.rzi.s32.f32 	%r102, %r101;
(EngineCore_DP0 pid=375213) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=375213) 	max.f32 	%r103, %r97, 0fC3000000;
(EngineCore_DP0 pid=375213) 	max.f32 	%r104, %r95, 0fC3000000;
(EngineCore_DP0 pid=375213) 	min.f32 	%r105, %r104, 0f42FE0000;
(EngineCore_DP0 pid=375213) 	min.f32 	%r106, %r103, 0f42FE0000;
(EngineCore_DP0 pid=375213) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=375213) 	cvt.rzi.s32.f32 	%r107, %r106;
(EngineCore_DP0 pid=375213) 	cvt.rzi.s32.f32 	%r108, %r105;
(EngineCore_DP0 pid=375213) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=375213) 	shl.b32 	%r109, %r108, 8;
(EngineCore_DP0 pid=375213) 	shl.b32 	%r110, %r107, 16;
(EngineCore_DP0 pid=375213) 	and.b32 	%r111, %r110, 16711680;
(EngineCore_DP0 pid=375213) 	and.b32 	%r112, %r109, 65280;
(EngineCore_DP0 pid=375213) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=375213) 	or.b32 	%r113, %r112, %r93;
(EngineCore_DP0 pid=375213) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=375213) 	or.b32 	%r114, %r113, %r111;
(EngineCore_DP0 pid=375213) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=375213) 	shl.b32 	%r115, %r102, 24;
(EngineCore_DP0 pid=375213) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=375213) 	or.b32 	%r70, %r114, %r115;
(EngineCore_DP0 pid=375213) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=375213) 	mad.wide.s32 	%rd12, %r72, 4, %rd2;
(EngineCore_DP0 pid=375213) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=375213) 	// begin inline asm
(EngineCore_DP0 pid=375213) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r70 };
(EngineCore_DP0 pid=375213) 	// end inline asm
(EngineCore_DP0 pid=375213) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=375213) 	add.s32 	%r119, %r119, 1024;
(EngineCore_DP0 pid=375213) 	setp.lt.s32 	%p18, %r119, %r14;
(EngineCore_DP0 pid=375213) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=375213) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=375213) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=375213) 	ret;
(EngineCore_DP0 pid=375213) $L__tmp3:
(EngineCore_DP0 pid=375213) $L__func_end0:
(EngineCore_DP0 pid=375213)                                         // -- End function
(EngineCore_DP0 pid=375213) }
(EngineCore_DP0 pid=375213) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=375213) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=375213) 	.section	.debug_abbrev
(EngineCore_DP0 pid=375213) 	{
(EngineCore_DP0 pid=375213) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=375213) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=375213) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=375213) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=375213) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=375213) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=375213) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=375213) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=375213) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=375213) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=375213) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=375213) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=375213) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=375213) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=375213) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=375213) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=375213) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=375213) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=375213) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=375213) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=375213) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=375213) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=375213) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=375213) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=375213) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=375213) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=375213) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=375213) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=375213) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=375213) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=375213) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=375213) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=375213) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=375213) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=375213) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=375213) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=375213) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=375213) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=375213) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=375213) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=375213) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=375213) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=375213) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=375213) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=375213) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=375213) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=375213) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=375213) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=375213) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=375213) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=375213) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=375213) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=375213) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=375213) 	}
(EngineCore_DP0 pid=375213) 	.section	.debug_info
(EngineCore_DP0 pid=375213) 	{
(EngineCore_DP0 pid=375213) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=375213) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=375213) .b8 0
(EngineCore_DP0 pid=375213) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=375213) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=375213) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=375213) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=375213) .b8 114
(EngineCore_DP0 pid=375213) .b8 105
(EngineCore_DP0 pid=375213) .b8 116
(EngineCore_DP0 pid=375213) .b8 111
(EngineCore_DP0 pid=375213) .b8 110
(EngineCore_DP0 pid=375213) .b8 0
(EngineCore_DP0 pid=375213) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=375213) .b8 0
(EngineCore_DP0 pid=375213) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=375213) .b8 117
(EngineCore_DP0 pid=375213) .b8 97
(EngineCore_DP0 pid=375213) .b8 110
(EngineCore_DP0 pid=375213) .b8 116
(EngineCore_DP0 pid=375213) .b8 95
(EngineCore_DP0 pid=375213) .b8 115
(EngineCore_DP0 pid=375213) .b8 108
(EngineCore_DP0 pid=375213) .b8 105
(EngineCore_DP0 pid=375213) .b8 100
(EngineCore_DP0 pid=375213) .b8 101
(EngineCore_DP0 pid=375213) .b8 95
(EngineCore_DP0 pid=375213) .b8 116
(EngineCore_DP0 pid=375213) .b8 117
(EngineCore_DP0 pid=375213) .b8 110
(EngineCore_DP0 pid=375213) .b8 101
(EngineCore_DP0 pid=375213) .b8 100
(EngineCore_DP0 pid=375213) .b8 95
(EngineCore_DP0 pid=375213) .b8 76
(EngineCore_DP0 pid=375213) .b8 108
(EngineCore_DP0 pid=375213) .b8 97
(EngineCore_DP0 pid=375213) .b8 109
(EngineCore_DP0 pid=375213) .b8 97
(EngineCore_DP0 pid=375213) .b8 51
(EngineCore_DP0 pid=375213) .b8 46
(EngineCore_DP0 pid=375213) .b8 50
(EngineCore_DP0 pid=375213) .b8 45
(EngineCore_DP0 pid=375213) .b8 51
(EngineCore_DP0 pid=375213) .b8 66
(EngineCore_DP0 pid=375213) .b8 46
(EngineCore_DP0 pid=375213) .b8 112
(EngineCore_DP0 pid=375213) .b8 121
(EngineCore_DP0 pid=375213) .b8 0
(EngineCore_DP0 pid=375213) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=375213) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=375213) .b8 114
(EngineCore_DP0 pid=375213) .b8 111
(EngineCore_DP0 pid=375213) .b8 111
(EngineCore_DP0 pid=375213) .b8 116
(EngineCore_DP0 pid=375213) .b8 47
(EngineCore_DP0 pid=375213) .b8 118
(EngineCore_DP0 pid=375213) .b8 108
(EngineCore_DP0 pid=375213) .b8 108
(EngineCore_DP0 pid=375213) .b8 109
(EngineCore_DP0 pid=375213) .b8 98
(EngineCore_DP0 pid=375213) .b8 101
(EngineCore_DP0 pid=375213) .b8 110
(EngineCore_DP0 pid=375213) .b8 99
(EngineCore_DP0 pid=375213) .b8 104
(EngineCore_DP0 pid=375213) .b8 47
(EngineCore_DP0 pid=375213) .b8 115
(EngineCore_DP0 pid=375213) .b8 108
(EngineCore_DP0 pid=375213) .b8 105
(EngineCore_DP0 pid=375213) .b8 100
(EngineCore_DP0 pid=375213) .b8 101
(EngineCore_DP0 pid=375213) .b8 115
(EngineCore_DP0 pid=375213) .b8 112
(EngineCore_DP0 pid=375213) .b8 97
(EngineCore_DP0 pid=375213) .b8 114
(EngineCore_DP0 pid=375213) .b8 115
(EngineCore_DP0 pid=375213) .b8 101
(EngineCore_DP0 pid=375213) .b8 47
(EngineCore_DP0 pid=375213) .b8 99
(EngineCore_DP0 pid=375213) .b8 115
(EngineCore_DP0 pid=375213) .b8 114
(EngineCore_DP0 pid=375213) .b8 99
(EngineCore_DP0 pid=375213) .b8 47
(EngineCore_DP0 pid=375213) .b8 102
(EngineCore_DP0 pid=375213) .b8 117
(EngineCore_DP0 pid=375213) .b8 115
(EngineCore_DP0 pid=375213) .b8 101
(EngineCore_DP0 pid=375213) .b8 100
(EngineCore_DP0 pid=375213) .b8 95
(EngineCore_DP0 pid=375213) .b8 113
(EngineCore_DP0 pid=375213) .b8 117
(EngineCore_DP0 pid=375213) .b8 97
(EngineCore_DP0 pid=375213) .b8 110
(EngineCore_DP0 pid=375213) .b8 116
(EngineCore_DP0 pid=375213) .b8 95
(EngineCore_DP0 pid=375213) .b8 115
(EngineCore_DP0 pid=375213) .b8 108
(EngineCore_DP0 pid=375213) .b8 105
(EngineCore_DP0 pid=375213) .b8 100
(EngineCore_DP0 pid=375213) .b8 101
(EngineCore_DP0 pid=375213) .b8 95
(EngineCore_DP0 pid=375213) .b8 116
(EngineCore_DP0 pid=375213) .b8 114
(EngineCore_DP0 pid=375213) .b8 105
(EngineCore_DP0 pid=375213) .b8 116
(EngineCore_DP0 pid=375213) .b8 111
(EngineCore_DP0 pid=375213) .b8 110
(EngineCore_DP0 pid=375213) .b8 47
(EngineCore_DP0 pid=375213) .b8 98
(EngineCore_DP0 pid=375213) .b8 117
(EngineCore_DP0 pid=375213) .b8 105
(EngineCore_DP0 pid=375213) .b8 108
(EngineCore_DP0 pid=375213) .b8 100
(EngineCore_DP0 pid=375213) .b8 47
(EngineCore_DP0 pid=375213) .b8 71
(EngineCore_DP0 pid=375213) .b8 66
(EngineCore_DP0 pid=375213) .b8 49
(EngineCore_DP0 pid=375213) .b8 48
(EngineCore_DP0 pid=375213) .b8 95
(EngineCore_DP0 pid=375213) .b8 99
(EngineCore_DP0 pid=375213) .b8 99
(EngineCore_DP0 pid=375213) .b8 49
(EngineCore_DP0 pid=375213) .b8 50
(EngineCore_DP0 pid=375213) .b8 49
(EngineCore_DP0 pid=375213) .b8 95
(EngineCore_DP0 pid=375213) .b8 112
(EngineCore_DP0 pid=375213) .b8 121
(EngineCore_DP0 pid=375213) .b8 51
(EngineCore_DP0 pid=375213) .b8 49
(EngineCore_DP0 pid=375213) .b8 50
(EngineCore_DP0 pid=375213) .b8 95
(EngineCore_DP0 pid=375213) .b8 99
(EngineCore_DP0 pid=375213) .b8 117
(EngineCore_DP0 pid=375213) .b8 49
(EngineCore_DP0 pid=375213) .b8 50
(EngineCore_DP0 pid=375213) .b8 57
(EngineCore_DP0 pid=375213) .b8 95
(EngineCore_DP0 pid=375213) .b8 97
(EngineCore_DP0 pid=375213) .b8 97
(EngineCore_DP0 pid=375213) .b8 114
(EngineCore_DP0 pid=375213) .b8 99
(EngineCore_DP0 pid=375213) .b8 104
(EngineCore_DP0 pid=375213) .b8 54
(EngineCore_DP0 pid=375213) .b8 52
(EngineCore_DP0 pid=375213) .b8 0
(EngineCore_DP0 pid=375213) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=375213) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=375213) .b8 113
(EngineCore_DP0 pid=375213) .b8 117
(EngineCore_DP0 pid=375213) .b8 97
(EngineCore_DP0 pid=375213) .b8 110
(EngineCore_DP0 pid=375213) .b8 116
(EngineCore_DP0 pid=375213) .b8 95
(EngineCore_DP0 pid=375213) .b8 115
(EngineCore_DP0 pid=375213) .b8 108
(EngineCore_DP0 pid=375213) .b8 105
(EngineCore_DP0 pid=375213) .b8 100
(EngineCore_DP0 pid=375213) .b8 101
(EngineCore_DP0 pid=375213) .b8 95
(EngineCore_DP0 pid=375213) .b8 105
(EngineCore_DP0 pid=375213) .b8 110
(EngineCore_DP0 pid=375213) .b8 116
(EngineCore_DP0 pid=375213) .b8 56
(EngineCore_DP0 pid=375213) .b8 95
(EngineCore_DP0 pid=375213) .b8 107
(EngineCore_DP0 pid=375213) .b8 101
(EngineCore_DP0 pid=375213) .b8 114
(EngineCore_DP0 pid=375213) .b8 110
(EngineCore_DP0 pid=375213) .b8 101
(EngineCore_DP0 pid=375213) .b8 108
(EngineCore_DP0 pid=375213) .b8 0
(EngineCore_DP0 pid=375213) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=375213) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=375213) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=375213) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=375213) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=375213) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=375213) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=375213) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=375213) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=375213) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=375213) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=375213) .b8 1
(EngineCore_DP0 pid=375213) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=375213) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=375213) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=375213) 	}
(EngineCore_DP0 pid=375213) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=375213) 
(EngineCore_DP0 pid=375213) ================================================================
(EngineCore_DP0 pid=375213) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=375213) 
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmprad6xu1n.ptx', '-o', '/tmp/tmprad6xu1n.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866] 
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866] 
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866] 
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmprad6xu1n.ptx -o /tmp/tmprad6xu1n.ptx.o
(EngineCore_DP0 pid=375213) ERROR 01-25 19:49:49 [core.py:866] 

STDERR:
[2026-01-25 19:49:12] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:49:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:49:12] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:49:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:49:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:49:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:49:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:49:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:49:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:49:15] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:49:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:49:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:49:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:49:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:49:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:49:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:49:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:49:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=375213) [2026-01-25 19:49:16] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=375213) [2026-01-25 19:49:16] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=375213) [2026-01-25 19:49:16] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=375213) [2026-01-25 19:49:16] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=375213) [2026-01-25 19:49:16] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=375213) [2026-01-25 19:49:16] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=375213) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=375213) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29<00:00, 29.72s/it]
(EngineCore_DP0 pid=375213) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29<00:00, 29.72s/it]
(EngineCore_DP0 pid=375213) 
(EngineCore_DP0 pid=375213) [2026-01-25 19:49:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=375213) [2026-01-25 19:49:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=375213) [2026-01-25 19:49:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=375213) [2026-01-25 19:49:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=375213) [2026-01-25 19:49:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=375213) [2026-01-25 19:49:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=375213) [2026-01-25 19:49:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=375213) [2026-01-25 19:49:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=375213) Process EngineCore_DP0:
(EngineCore_DP0 pid=375213) Traceback (most recent call last):
(EngineCore_DP0 pid=375213)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=375213)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=375213)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=375213)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=375213) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmprad6xu1n.ptx', '-o', '/tmp/tmprad6xu1n.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=375213) 
(EngineCore_DP0 pid=375213) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=375213) 
(EngineCore_DP0 pid=375213) Traceback (most recent call last):
(EngineCore_DP0 pid=375213)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=375213)     self.run()
(EngineCore_DP0 pid=375213)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=375213)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=375213)     raise e
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=375213)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=375213)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=375213)     super().__init__(
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=375213)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=375213)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=375213)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=375213)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=375213)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=375213)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=375213)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=375213)     return func(*args, **kwargs)
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=375213)     return func(*args, **kwargs)
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=375213)     self.model_runner.profile_run()
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=375213)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=375213)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=375213)     return func(*args, **kwargs)
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=375213)     outputs = self.model(
(EngineCore_DP0 pid=375213)               ^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=375213)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=375213)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=375213)     model_output = self.model(
(EngineCore_DP0 pid=375213)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=375213)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=375213)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=375213)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=375213)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=375213)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=375213)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=375213)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=375213)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=375213)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=375213)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=375213)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=375213)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=375213)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=375213)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=375213)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=375213)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=375213)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=375213)     return self._linear_fn(
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=375213)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=375213)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=375213)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=375213)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=375213)     return fn(input, L)
(EngineCore_DP0 pid=375213)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=375213)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=375213)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=375213)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=375213)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=375213)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=375213)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=375213)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=375213)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=375213)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=375213)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=375213)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=375213)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375213)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=375213)     raise PTXASError(error)
(EngineCore_DP0 pid=375213) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=375213) `ptxas` stderr:
(EngineCore_DP0 pid=375213) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=375213) 
(EngineCore_DP0 pid=375213) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmprad6xu1n.ptx -o /tmp/tmprad6xu1n.ptx.o
(EngineCore_DP0 pid=375213) 
[rank0]:[W125 19:49:49.578573690 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 19:49:51
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:49:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:49:55 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=375983) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=375983) 
(EngineCore_DP0 pid=375983) 
(EngineCore_DP0 pid=375983) ================================================================
(EngineCore_DP0 pid=375983) Internal Triton PTX codegen error
(EngineCore_DP0 pid=375983) `ptxas` stderr:
(EngineCore_DP0 pid=375983) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=375983) 
(EngineCore_DP0 pid=375983) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpds2audsm.ptx -o /tmp/tmpds2audsm.ptx.o
(EngineCore_DP0 pid=375983) 
(EngineCore_DP0 pid=375983) 
(EngineCore_DP0 pid=375983) //
(EngineCore_DP0 pid=375983) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=375983) //
(EngineCore_DP0 pid=375983) 
(EngineCore_DP0 pid=375983) .version 8.7
(EngineCore_DP0 pid=375983) .target sm_121a
(EngineCore_DP0 pid=375983) .address_size 64
(EngineCore_DP0 pid=375983) 
(EngineCore_DP0 pid=375983) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=375983) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=375983)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=375983) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=375983) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=375983) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=375983) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=375983) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=375983) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=375983) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=375983) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=375983) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=375983) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=375983) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=375983) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=375983) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=375983) )
(EngineCore_DP0 pid=375983) .reqntid 512
(EngineCore_DP0 pid=375983) {
(EngineCore_DP0 pid=375983) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=375983) 	.reg .b16 	%rs<32>;
(EngineCore_DP0 pid=375983) 	.reg .b32 	%r<123>;
(EngineCore_DP0 pid=375983) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=375983) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=375983) $L__func_begin0:
(EngineCore_DP0 pid=375983) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=375983) 
(EngineCore_DP0 pid=375983) // %bb.0:
(EngineCore_DP0 pid=375983) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=375983) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=375983) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=375983) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=375983) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=375983) $L__tmp0:
(EngineCore_DP0 pid=375983) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=375983) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=375983) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=375983) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=375983) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=375983) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=375983) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=375983) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=375983) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=375983) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=375983) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=375983) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=375983) 	mov.b32 	%r121, 0f2B8CBCCC;
(EngineCore_DP0 pid=375983) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=375983) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=375983) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=375983) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=375983) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=375983) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=375983) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=375983) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=375983) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=375983) 	add.s32 	%r44, %r34, %r33;
(EngineCore_DP0 pid=375983) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=375983) 	add.s32 	%r47, %r34, %r35;
(EngineCore_DP0 pid=375983) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=375983) 	mov.b32 	%r119, 0f00000000;
(EngineCore_DP0 pid=375983) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=375983) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=375983) 	mov.b32 	%r120, %r40;
(EngineCore_DP0 pid=375983) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=375983) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=375983) 	add.s32 	%r50, %r4, %r120;
(EngineCore_DP0 pid=375983) 	setp.lt.s32 	%p2, %r50, %r18;
(EngineCore_DP0 pid=375983) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=375983) 	mad.wide.s32 	%rd6, %r50, 2, %rd1;
(EngineCore_DP0 pid=375983) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=375983) 	// begin inline asm
(EngineCore_DP0 pid=375983) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=375983) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=375983) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=375983) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=375983) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=375983) 	// end inline asm
(EngineCore_DP0 pid=375983) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=375983) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=375983) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=375983) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=375983) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=375983) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=375983) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=375983) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=375983) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=375983) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=375983) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=375983) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=375983) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=375983) $L__tmp1:
(EngineCore_DP0 pid=375983) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	bar.sync 	0;
(EngineCore_DP0 pid=375983) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=375983) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=375983) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=375983) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=375983) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=375983) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=375983) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=375983) 	cvt.f32.bf16 	%r51, %rs23;
(EngineCore_DP0 pid=375983) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	shfl.sync.bfly.b32 	%r52, %r51, 16, 31, -1;
(EngineCore_DP0 pid=375983) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=375983) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	shfl.sync.bfly.b32 	%r54, %r53, 8, 31, -1;
(EngineCore_DP0 pid=375983) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=375983) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	shfl.sync.bfly.b32 	%r56, %r55, 4, 31, -1;
(EngineCore_DP0 pid=375983) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=375983) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	shfl.sync.bfly.b32 	%r58, %r57, 2, 31, -1;
(EngineCore_DP0 pid=375983) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=375983) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	shfl.sync.bfly.b32 	%r60, %r59, 1, 31, -1;
(EngineCore_DP0 pid=375983) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	max.f32 	%r45, %r59, %r60;
(EngineCore_DP0 pid=375983) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	// begin inline asm
(EngineCore_DP0 pid=375983) 	@%p3 st.shared.b32 [ %r44 + 0 ], %r45;
(EngineCore_DP0 pid=375983) 	// end inline asm
(EngineCore_DP0 pid=375983) 	bar.sync 	0;
(EngineCore_DP0 pid=375983) 	// begin inline asm
(EngineCore_DP0 pid=375983) 	@%p4 ld.shared.b32 %r46, [ %r47 + 0 ];
(EngineCore_DP0 pid=375983) 	// end inline asm
(EngineCore_DP0 pid=375983) 	shfl.sync.bfly.b32 	%r61, %r46, 8, 31, -1;
(EngineCore_DP0 pid=375983) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	max.f32 	%r62, %r46, %r61;
(EngineCore_DP0 pid=375983) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	shfl.sync.bfly.b32 	%r63, %r62, 4, 31, -1;
(EngineCore_DP0 pid=375983) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=375983) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	shfl.sync.bfly.b32 	%r65, %r64, 2, 31, -1;
(EngineCore_DP0 pid=375983) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=375983) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	shfl.sync.bfly.b32 	%r67, %r66, 1, 31, -1;
(EngineCore_DP0 pid=375983) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	max.f32 	%r49, %r66, %r67;
(EngineCore_DP0 pid=375983) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=375983) 	// begin inline asm
(EngineCore_DP0 pid=375983) 	@%p19 st.shared.b32 [ %r47 + 0 ], %r49;
(EngineCore_DP0 pid=375983) 	// end inline asm
(EngineCore_DP0 pid=375983) 	bar.sync 	0;
(EngineCore_DP0 pid=375983) 	ld.shared.b32 	%r68, [global_smem];
(EngineCore_DP0 pid=375983) $L__tmp2:
(EngineCore_DP0 pid=375983) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=375983) 	max.f32 	%r119, %r119, %r68;
(EngineCore_DP0 pid=375983) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=375983) 	add.s32 	%r120, %r120, 4096;
(EngineCore_DP0 pid=375983) 	setp.lt.s32 	%p6, %r120, %r19;
(EngineCore_DP0 pid=375983) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=375983) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=375983) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=375983) 	max.f32 	%r121, %r119, 0f2B8CBCCC;
(EngineCore_DP0 pid=375983) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=375983) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=375983) 	mov.b32 	%r70, 0f42FE0000;
(EngineCore_DP0 pid=375983) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=375983) 	div.full.f32 	%r71, %r121, %r70;
(EngineCore_DP0 pid=375983) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=375983) 	max.f32 	%r69, %r71, 0f37810204;
(EngineCore_DP0 pid=375983) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=375983) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=375983) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=375983) 	// begin inline asm
(EngineCore_DP0 pid=375983) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r69 };
(EngineCore_DP0 pid=375983) 	// end inline asm
(EngineCore_DP0 pid=375983) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=375983) 	shl.b32 	%r15, %r20, 2;
(EngineCore_DP0 pid=375983) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=375983) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=375983) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=375983) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=375983) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=375983) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=375983) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=375983) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=375983) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=375983) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=375983) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=375983) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=375983) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=375983) 	div.full.f32 	%r14, %r70, %r121;
(EngineCore_DP0 pid=375983) 	mov.b32 	%r122, 0;
(EngineCore_DP0 pid=375983) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=375983)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=375983) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=375983) 	add.s32 	%r75, %r3, %r122;
(EngineCore_DP0 pid=375983) 	setp.lt.s32 	%p13, %r75, %r15;
(EngineCore_DP0 pid=375983) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=375983) 	shr.s32 	%r76, %r75, 31;
(EngineCore_DP0 pid=375983) 	shr.u32 	%r77, %r76, 30;
(EngineCore_DP0 pid=375983) 	add.s32 	%r78, %r75, %r77;
(EngineCore_DP0 pid=375983) 	shr.s32 	%r79, %r78, 2;
(EngineCore_DP0 pid=375983) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=375983) 	and.b32 	%r80, %r78, 2147483644;
(EngineCore_DP0 pid=375983) 	sub.s32 	%r81, %r75, %r80;
(EngineCore_DP0 pid=375983) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=375983) 	shl.b32 	%r82, %r81, 1;
(EngineCore_DP0 pid=375983) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=375983) 	mad.lo.s32 	%r83, %r79, 10, %r82;
(EngineCore_DP0 pid=375983) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=375983) 	setp.lt.s32 	%p14, %r83, %r18;
(EngineCore_DP0 pid=375983) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=375983) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=375983) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=375983) 	mad.wide.s32 	%rd8, %r83, 2, %rd1;
(EngineCore_DP0 pid=375983) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=375983) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=375983) 	// begin inline asm
(EngineCore_DP0 pid=375983) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=375983) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=375983) 	// end inline asm
(EngineCore_DP0 pid=375983) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=375983) 	cvt.f32.bf16 	%r84, %rs24;
(EngineCore_DP0 pid=375983) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=375983) 	or.b32 	%r85, %r83, 1;
(EngineCore_DP0 pid=375983) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=375983) 	setp.lt.s32 	%p15, %r85, %r18;
(EngineCore_DP0 pid=375983) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=375983) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=375983) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=375983) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=375983) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=375983) 	// begin inline asm
(EngineCore_DP0 pid=375983) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=375983) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=375983) 	// end inline asm
(EngineCore_DP0 pid=375983) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=375983) 	cvt.f32.bf16 	%r86, %rs26;
(EngineCore_DP0 pid=375983) 	.loc	1 340 48                        // quant_slide_tuned_Llama3.2-3B.py:340:48
(EngineCore_DP0 pid=375983) 	add.s32 	%r87, %r83, 2;
(EngineCore_DP0 pid=375983) 	.loc	1 340 53                        // quant_slide_tuned_Llama3.2-3B.py:340:53
(EngineCore_DP0 pid=375983) 	setp.lt.s32 	%p16, %r87, %r18;
(EngineCore_DP0 pid=375983) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=375983) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=375983) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=375983) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=375983) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=375983) 	// begin inline asm
(EngineCore_DP0 pid=375983) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=375983) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=375983) 	// end inline asm
(EngineCore_DP0 pid=375983) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=375983) 	cvt.f32.bf16 	%r88, %rs28;
(EngineCore_DP0 pid=375983) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=375983) 	add.s32 	%r89, %r83, 3;
(EngineCore_DP0 pid=375983) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=375983) 	setp.lt.s32 	%p17, %r89, %r18;
(EngineCore_DP0 pid=375983) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=375983) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=375983) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=375983) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=375983) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=375983) 	// begin inline asm
(EngineCore_DP0 pid=375983) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=375983) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=375983) 	// end inline asm
(EngineCore_DP0 pid=375983) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=375983) 	cvt.f32.bf16 	%r90, %rs30;
(EngineCore_DP0 pid=375983) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=375983) 	mul.f32 	%r91, %r14, %r84;
(EngineCore_DP0 pid=375983) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=375983) 	cvt.rni.f32.f32 	%r92, %r91;
(EngineCore_DP0 pid=375983) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=375983) 	max.f32 	%r93, %r92, 0fC3000000;
(EngineCore_DP0 pid=375983) 	min.f32 	%r94, %r93, 0f42FE0000;
(EngineCore_DP0 pid=375983) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=375983) 	cvt.rzi.s32.f32 	%r95, %r94;
(EngineCore_DP0 pid=375983) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=375983) 	and.b32 	%r96, %r95, 255;
(EngineCore_DP0 pid=375983) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=375983) 	mul.f32 	%r97, %r14, %r86;
(EngineCore_DP0 pid=375983) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=375983) 	cvt.rni.f32.f32 	%r98, %r97;
(EngineCore_DP0 pid=375983) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=375983) 	mul.f32 	%r99, %r14, %r88;
(EngineCore_DP0 pid=375983) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=375983) 	cvt.rni.f32.f32 	%r100, %r99;
(EngineCore_DP0 pid=375983) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=375983) 	mul.f32 	%r101, %r14, %r90;
(EngineCore_DP0 pid=375983) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=375983) 	cvt.rni.f32.f32 	%r102, %r101;
(EngineCore_DP0 pid=375983) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=375983) 	max.f32 	%r103, %r102, 0fC3000000;
(EngineCore_DP0 pid=375983) 	min.f32 	%r104, %r103, 0f42FE0000;
(EngineCore_DP0 pid=375983) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=375983) 	cvt.rzi.s32.f32 	%r105, %r104;
(EngineCore_DP0 pid=375983) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=375983) 	max.f32 	%r106, %r100, 0fC3000000;
(EngineCore_DP0 pid=375983) 	max.f32 	%r107, %r98, 0fC3000000;
(EngineCore_DP0 pid=375983) 	min.f32 	%r108, %r107, 0f42FE0000;
(EngineCore_DP0 pid=375983) 	min.f32 	%r109, %r106, 0f42FE0000;
(EngineCore_DP0 pid=375983) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=375983) 	cvt.rzi.s32.f32 	%r110, %r109;
(EngineCore_DP0 pid=375983) 	cvt.rzi.s32.f32 	%r111, %r108;
(EngineCore_DP0 pid=375983) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=375983) 	shl.b32 	%r112, %r111, 8;
(EngineCore_DP0 pid=375983) 	shl.b32 	%r113, %r110, 16;
(EngineCore_DP0 pid=375983) 	and.b32 	%r114, %r113, 16711680;
(EngineCore_DP0 pid=375983) 	and.b32 	%r115, %r112, 65280;
(EngineCore_DP0 pid=375983) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=375983) 	or.b32 	%r116, %r115, %r96;
(EngineCore_DP0 pid=375983) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=375983) 	or.b32 	%r117, %r116, %r114;
(EngineCore_DP0 pid=375983) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=375983) 	shl.b32 	%r118, %r105, 24;
(EngineCore_DP0 pid=375983) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=375983) 	or.b32 	%r73, %r117, %r118;
(EngineCore_DP0 pid=375983) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=375983) 	mad.wide.s32 	%rd12, %r75, 4, %rd2;
(EngineCore_DP0 pid=375983) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=375983) 	// begin inline asm
(EngineCore_DP0 pid=375983) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r73 };
(EngineCore_DP0 pid=375983) 	// end inline asm
(EngineCore_DP0 pid=375983) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=375983) 	add.s32 	%r122, %r122, 512;
(EngineCore_DP0 pid=375983) 	setp.lt.s32 	%p18, %r122, %r15;
(EngineCore_DP0 pid=375983) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=375983) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=375983) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=375983) 	ret;
(EngineCore_DP0 pid=375983) $L__tmp3:
(EngineCore_DP0 pid=375983) $L__func_end0:
(EngineCore_DP0 pid=375983)                                         // -- End function
(EngineCore_DP0 pid=375983) }
(EngineCore_DP0 pid=375983) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=375983) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=375983) 	.section	.debug_abbrev
(EngineCore_DP0 pid=375983) 	{
(EngineCore_DP0 pid=375983) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=375983) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=375983) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=375983) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=375983) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=375983) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=375983) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=375983) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=375983) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=375983) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=375983) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=375983) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=375983) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=375983) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=375983) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=375983) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=375983) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=375983) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=375983) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=375983) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=375983) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=375983) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=375983) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=375983) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=375983) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=375983) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=375983) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=375983) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=375983) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=375983) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=375983) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=375983) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=375983) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=375983) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=375983) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=375983) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=375983) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=375983) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=375983) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=375983) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=375983) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=375983) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=375983) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=375983) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=375983) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=375983) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=375983) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=375983) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=375983) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=375983) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=375983) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=375983) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=375983) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=375983) 	}
(EngineCore_DP0 pid=375983) 	.section	.debug_info
(EngineCore_DP0 pid=375983) 	{
(EngineCore_DP0 pid=375983) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=375983) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=375983) .b8 0
(EngineCore_DP0 pid=375983) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=375983) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=375983) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=375983) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=375983) .b8 114
(EngineCore_DP0 pid=375983) .b8 105
(EngineCore_DP0 pid=375983) .b8 116
(EngineCore_DP0 pid=375983) .b8 111
(EngineCore_DP0 pid=375983) .b8 110
(EngineCore_DP0 pid=375983) .b8 0
(EngineCore_DP0 pid=375983) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=375983) .b8 0
(EngineCore_DP0 pid=375983) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=375983) .b8 117
(EngineCore_DP0 pid=375983) .b8 97
(EngineCore_DP0 pid=375983) .b8 110
(EngineCore_DP0 pid=375983) .b8 116
(EngineCore_DP0 pid=375983) .b8 95
(EngineCore_DP0 pid=375983) .b8 115
(EngineCore_DP0 pid=375983) .b8 108
(EngineCore_DP0 pid=375983) .b8 105
(EngineCore_DP0 pid=375983) .b8 100
(EngineCore_DP0 pid=375983) .b8 101
(EngineCore_DP0 pid=375983) .b8 95
(EngineCore_DP0 pid=375983) .b8 116
(EngineCore_DP0 pid=375983) .b8 117
(EngineCore_DP0 pid=375983) .b8 110
(EngineCore_DP0 pid=375983) .b8 101
(EngineCore_DP0 pid=375983) .b8 100
(EngineCore_DP0 pid=375983) .b8 95
(EngineCore_DP0 pid=375983) .b8 76
(EngineCore_DP0 pid=375983) .b8 108
(EngineCore_DP0 pid=375983) .b8 97
(EngineCore_DP0 pid=375983) .b8 109
(EngineCore_DP0 pid=375983) .b8 97
(EngineCore_DP0 pid=375983) .b8 51
(EngineCore_DP0 pid=375983) .b8 46
(EngineCore_DP0 pid=375983) .b8 50
(EngineCore_DP0 pid=375983) .b8 45
(EngineCore_DP0 pid=375983) .b8 51
(EngineCore_DP0 pid=375983) .b8 66
(EngineCore_DP0 pid=375983) .b8 46
(EngineCore_DP0 pid=375983) .b8 112
(EngineCore_DP0 pid=375983) .b8 121
(EngineCore_DP0 pid=375983) .b8 0
(EngineCore_DP0 pid=375983) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=375983) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=375983) .b8 114
(EngineCore_DP0 pid=375983) .b8 111
(EngineCore_DP0 pid=375983) .b8 111
(EngineCore_DP0 pid=375983) .b8 116
(EngineCore_DP0 pid=375983) .b8 47
(EngineCore_DP0 pid=375983) .b8 118
(EngineCore_DP0 pid=375983) .b8 108
(EngineCore_DP0 pid=375983) .b8 108
(EngineCore_DP0 pid=375983) .b8 109
(EngineCore_DP0 pid=375983) .b8 98
(EngineCore_DP0 pid=375983) .b8 101
(EngineCore_DP0 pid=375983) .b8 110
(EngineCore_DP0 pid=375983) .b8 99
(EngineCore_DP0 pid=375983) .b8 104
(EngineCore_DP0 pid=375983) .b8 47
(EngineCore_DP0 pid=375983) .b8 115
(EngineCore_DP0 pid=375983) .b8 108
(EngineCore_DP0 pid=375983) .b8 105
(EngineCore_DP0 pid=375983) .b8 100
(EngineCore_DP0 pid=375983) .b8 101
(EngineCore_DP0 pid=375983) .b8 115
(EngineCore_DP0 pid=375983) .b8 112
(EngineCore_DP0 pid=375983) .b8 97
(EngineCore_DP0 pid=375983) .b8 114
(EngineCore_DP0 pid=375983) .b8 115
(EngineCore_DP0 pid=375983) .b8 101
(EngineCore_DP0 pid=375983) .b8 47
(EngineCore_DP0 pid=375983) .b8 99
(EngineCore_DP0 pid=375983) .b8 115
(EngineCore_DP0 pid=375983) .b8 114
(EngineCore_DP0 pid=375983) .b8 99
(EngineCore_DP0 pid=375983) .b8 47
(EngineCore_DP0 pid=375983) .b8 102
(EngineCore_DP0 pid=375983) .b8 117
(EngineCore_DP0 pid=375983) .b8 115
(EngineCore_DP0 pid=375983) .b8 101
(EngineCore_DP0 pid=375983) .b8 100
(EngineCore_DP0 pid=375983) .b8 95
(EngineCore_DP0 pid=375983) .b8 113
(EngineCore_DP0 pid=375983) .b8 117
(EngineCore_DP0 pid=375983) .b8 97
(EngineCore_DP0 pid=375983) .b8 110
(EngineCore_DP0 pid=375983) .b8 116
(EngineCore_DP0 pid=375983) .b8 95
(EngineCore_DP0 pid=375983) .b8 115
(EngineCore_DP0 pid=375983) .b8 108
(EngineCore_DP0 pid=375983) .b8 105
(EngineCore_DP0 pid=375983) .b8 100
(EngineCore_DP0 pid=375983) .b8 101
(EngineCore_DP0 pid=375983) .b8 95
(EngineCore_DP0 pid=375983) .b8 116
(EngineCore_DP0 pid=375983) .b8 114
(EngineCore_DP0 pid=375983) .b8 105
(EngineCore_DP0 pid=375983) .b8 116
(EngineCore_DP0 pid=375983) .b8 111
(EngineCore_DP0 pid=375983) .b8 110
(EngineCore_DP0 pid=375983) .b8 47
(EngineCore_DP0 pid=375983) .b8 98
(EngineCore_DP0 pid=375983) .b8 117
(EngineCore_DP0 pid=375983) .b8 105
(EngineCore_DP0 pid=375983) .b8 108
(EngineCore_DP0 pid=375983) .b8 100
(EngineCore_DP0 pid=375983) .b8 47
(EngineCore_DP0 pid=375983) .b8 71
(EngineCore_DP0 pid=375983) .b8 66
(EngineCore_DP0 pid=375983) .b8 49
(EngineCore_DP0 pid=375983) .b8 48
(EngineCore_DP0 pid=375983) .b8 95
(EngineCore_DP0 pid=375983) .b8 99
(EngineCore_DP0 pid=375983) .b8 99
(EngineCore_DP0 pid=375983) .b8 49
(EngineCore_DP0 pid=375983) .b8 50
(EngineCore_DP0 pid=375983) .b8 49
(EngineCore_DP0 pid=375983) .b8 95
(EngineCore_DP0 pid=375983) .b8 112
(EngineCore_DP0 pid=375983) .b8 121
(EngineCore_DP0 pid=375983) .b8 51
(EngineCore_DP0 pid=375983) .b8 49
(EngineCore_DP0 pid=375983) .b8 50
(EngineCore_DP0 pid=375983) .b8 95
(EngineCore_DP0 pid=375983) .b8 99
(EngineCore_DP0 pid=375983) .b8 117
(EngineCore_DP0 pid=375983) .b8 49
(EngineCore_DP0 pid=375983) .b8 50
(EngineCore_DP0 pid=375983) .b8 57
(EngineCore_DP0 pid=375983) .b8 95
(EngineCore_DP0 pid=375983) .b8 97
(EngineCore_DP0 pid=375983) .b8 97
(EngineCore_DP0 pid=375983) .b8 114
(EngineCore_DP0 pid=375983) .b8 99
(EngineCore_DP0 pid=375983) .b8 104
(EngineCore_DP0 pid=375983) .b8 54
(EngineCore_DP0 pid=375983) .b8 52
(EngineCore_DP0 pid=375983) .b8 0
(EngineCore_DP0 pid=375983) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=375983) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=375983) .b8 113
(EngineCore_DP0 pid=375983) .b8 117
(EngineCore_DP0 pid=375983) .b8 97
(EngineCore_DP0 pid=375983) .b8 110
(EngineCore_DP0 pid=375983) .b8 116
(EngineCore_DP0 pid=375983) .b8 95
(EngineCore_DP0 pid=375983) .b8 115
(EngineCore_DP0 pid=375983) .b8 108
(EngineCore_DP0 pid=375983) .b8 105
(EngineCore_DP0 pid=375983) .b8 100
(EngineCore_DP0 pid=375983) .b8 101
(EngineCore_DP0 pid=375983) .b8 95
(EngineCore_DP0 pid=375983) .b8 105
(EngineCore_DP0 pid=375983) .b8 110
(EngineCore_DP0 pid=375983) .b8 116
(EngineCore_DP0 pid=375983) .b8 56
(EngineCore_DP0 pid=375983) .b8 95
(EngineCore_DP0 pid=375983) .b8 107
(EngineCore_DP0 pid=375983) .b8 101
(EngineCore_DP0 pid=375983) .b8 114
(EngineCore_DP0 pid=375983) .b8 110
(EngineCore_DP0 pid=375983) .b8 101
(EngineCore_DP0 pid=375983) .b8 108
(EngineCore_DP0 pid=375983) .b8 0
(EngineCore_DP0 pid=375983) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=375983) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=375983) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=375983) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=375983) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=375983) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=375983) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=375983) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=375983) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=375983) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=375983) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=375983) .b8 1
(EngineCore_DP0 pid=375983) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=375983) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=375983) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=375983) 	}
(EngineCore_DP0 pid=375983) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=375983) 
(EngineCore_DP0 pid=375983) ================================================================
(EngineCore_DP0 pid=375983) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=375983) 
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpds2audsm.ptx', '-o', '/tmp/tmpds2audsm.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866] 
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866] 
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866] 
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpds2audsm.ptx -o /tmp/tmpds2audsm.ptx.o
(EngineCore_DP0 pid=375983) ERROR 01-25 19:50:31 [core.py:866] 

STDERR:
[2026-01-25 19:49:55] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:49:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:49:55] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:49:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:49:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:49:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:49:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:49:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:49:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:49:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:49:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:49:58] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:49:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:49:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:49:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:49:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:49:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:49:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:49:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=375983) [2026-01-25 19:49:59] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=375983) [2026-01-25 19:49:59] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=375983) [2026-01-25 19:49:59] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=375983) [2026-01-25 19:49:59] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=375983) [2026-01-25 19:49:59] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=375983) [2026-01-25 19:49:59] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=375983) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=375983) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29<00:00, 29.22s/it]
(EngineCore_DP0 pid=375983) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29<00:00, 29.22s/it]
(EngineCore_DP0 pid=375983) 
(EngineCore_DP0 pid=375983) [2026-01-25 19:50:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=375983) [2026-01-25 19:50:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=375983) [2026-01-25 19:50:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=375983) [2026-01-25 19:50:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=375983) [2026-01-25 19:50:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=375983) [2026-01-25 19:50:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=375983) [2026-01-25 19:50:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=375983) [2026-01-25 19:50:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=375983) Process EngineCore_DP0:
(EngineCore_DP0 pid=375983) Traceback (most recent call last):
(EngineCore_DP0 pid=375983)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=375983)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=375983)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=375983)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=375983) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpds2audsm.ptx', '-o', '/tmp/tmpds2audsm.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=375983) 
(EngineCore_DP0 pid=375983) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=375983) 
(EngineCore_DP0 pid=375983) Traceback (most recent call last):
(EngineCore_DP0 pid=375983)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=375983)     self.run()
(EngineCore_DP0 pid=375983)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=375983)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=375983)     raise e
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=375983)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=375983)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=375983)     super().__init__(
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=375983)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=375983)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=375983)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=375983)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=375983)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=375983)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=375983)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=375983)     return func(*args, **kwargs)
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=375983)     return func(*args, **kwargs)
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=375983)     self.model_runner.profile_run()
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=375983)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=375983)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=375983)     return func(*args, **kwargs)
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=375983)     outputs = self.model(
(EngineCore_DP0 pid=375983)               ^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=375983)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=375983)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=375983)     model_output = self.model(
(EngineCore_DP0 pid=375983)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=375983)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=375983)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=375983)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=375983)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=375983)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=375983)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=375983)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=375983)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=375983)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=375983)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=375983)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=375983)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=375983)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=375983)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=375983)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=375983)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=375983)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=375983)     return self._linear_fn(
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=375983)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=375983)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=375983)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=375983)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=375983)     return fn(input, L)
(EngineCore_DP0 pid=375983)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=375983)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=375983)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=375983)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=375983)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=375983)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=375983)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=375983)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=375983)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=375983)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=375983)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=375983)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=375983)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=375983)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=375983)     raise PTXASError(error)
(EngineCore_DP0 pid=375983) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=375983) `ptxas` stderr:
(EngineCore_DP0 pid=375983) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=375983) 
(EngineCore_DP0 pid=375983) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpds2audsm.ptx -o /tmp/tmpds2audsm.ptx.o
(EngineCore_DP0 pid=375983) 
[rank0]:[W125 19:50:31.902187917 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 19:50:33
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:50:37 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:50:37 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=376768) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=376768) 
(EngineCore_DP0 pid=376768) 
(EngineCore_DP0 pid=376768) ================================================================
(EngineCore_DP0 pid=376768) Internal Triton PTX codegen error
(EngineCore_DP0 pid=376768) `ptxas` stderr:
(EngineCore_DP0 pid=376768) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=376768) 
(EngineCore_DP0 pid=376768) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpytkjzww5.ptx -o /tmp/tmpytkjzww5.ptx.o
(EngineCore_DP0 pid=376768) 
(EngineCore_DP0 pid=376768) 
(EngineCore_DP0 pid=376768) //
(EngineCore_DP0 pid=376768) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=376768) //
(EngineCore_DP0 pid=376768) 
(EngineCore_DP0 pid=376768) .version 8.7
(EngineCore_DP0 pid=376768) .target sm_121a
(EngineCore_DP0 pid=376768) .address_size 64
(EngineCore_DP0 pid=376768) 
(EngineCore_DP0 pid=376768) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=376768) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=376768)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=376768) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=376768) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=376768) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=376768) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=376768) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=376768) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=376768) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=376768) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=376768) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=376768) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=376768) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=376768) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=376768) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=376768) )
(EngineCore_DP0 pid=376768) .reqntid 512
(EngineCore_DP0 pid=376768) {
(EngineCore_DP0 pid=376768) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=376768) 	.reg .b16 	%rs<32>;
(EngineCore_DP0 pid=376768) 	.reg .b32 	%r<123>;
(EngineCore_DP0 pid=376768) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=376768) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=376768) $L__func_begin0:
(EngineCore_DP0 pid=376768) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=376768) 
(EngineCore_DP0 pid=376768) // %bb.0:
(EngineCore_DP0 pid=376768) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=376768) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=376768) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=376768) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=376768) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=376768) $L__tmp0:
(EngineCore_DP0 pid=376768) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=376768) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=376768) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=376768) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=376768) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=376768) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=376768) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=376768) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=376768) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=376768) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=376768) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=376768) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=376768) 	mov.b32 	%r121, 0f2B8CBCCC;
(EngineCore_DP0 pid=376768) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=376768) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=376768) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=376768) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=376768) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=376768) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=376768) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=376768) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=376768) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=376768) 	add.s32 	%r44, %r34, %r33;
(EngineCore_DP0 pid=376768) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=376768) 	add.s32 	%r47, %r34, %r35;
(EngineCore_DP0 pid=376768) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=376768) 	mov.b32 	%r119, 0f00000000;
(EngineCore_DP0 pid=376768) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=376768) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=376768) 	mov.b32 	%r120, %r40;
(EngineCore_DP0 pid=376768) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=376768) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=376768) 	add.s32 	%r50, %r4, %r120;
(EngineCore_DP0 pid=376768) 	setp.lt.s32 	%p2, %r50, %r18;
(EngineCore_DP0 pid=376768) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=376768) 	mad.wide.s32 	%rd6, %r50, 2, %rd1;
(EngineCore_DP0 pid=376768) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=376768) 	// begin inline asm
(EngineCore_DP0 pid=376768) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=376768) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=376768) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=376768) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=376768) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=376768) 	// end inline asm
(EngineCore_DP0 pid=376768) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=376768) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=376768) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=376768) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=376768) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=376768) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=376768) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=376768) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=376768) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=376768) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=376768) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=376768) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=376768) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=376768) $L__tmp1:
(EngineCore_DP0 pid=376768) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	bar.sync 	0;
(EngineCore_DP0 pid=376768) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=376768) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=376768) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=376768) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=376768) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=376768) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=376768) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=376768) 	cvt.f32.bf16 	%r51, %rs23;
(EngineCore_DP0 pid=376768) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	shfl.sync.bfly.b32 	%r52, %r51, 16, 31, -1;
(EngineCore_DP0 pid=376768) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=376768) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	shfl.sync.bfly.b32 	%r54, %r53, 8, 31, -1;
(EngineCore_DP0 pid=376768) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=376768) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	shfl.sync.bfly.b32 	%r56, %r55, 4, 31, -1;
(EngineCore_DP0 pid=376768) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=376768) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	shfl.sync.bfly.b32 	%r58, %r57, 2, 31, -1;
(EngineCore_DP0 pid=376768) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=376768) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	shfl.sync.bfly.b32 	%r60, %r59, 1, 31, -1;
(EngineCore_DP0 pid=376768) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	max.f32 	%r45, %r59, %r60;
(EngineCore_DP0 pid=376768) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	// begin inline asm
(EngineCore_DP0 pid=376768) 	@%p3 st.shared.b32 [ %r44 + 0 ], %r45;
(EngineCore_DP0 pid=376768) 	// end inline asm
(EngineCore_DP0 pid=376768) 	bar.sync 	0;
(EngineCore_DP0 pid=376768) 	// begin inline asm
(EngineCore_DP0 pid=376768) 	@%p4 ld.shared.b32 %r46, [ %r47 + 0 ];
(EngineCore_DP0 pid=376768) 	// end inline asm
(EngineCore_DP0 pid=376768) 	shfl.sync.bfly.b32 	%r61, %r46, 8, 31, -1;
(EngineCore_DP0 pid=376768) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	max.f32 	%r62, %r46, %r61;
(EngineCore_DP0 pid=376768) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	shfl.sync.bfly.b32 	%r63, %r62, 4, 31, -1;
(EngineCore_DP0 pid=376768) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=376768) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	shfl.sync.bfly.b32 	%r65, %r64, 2, 31, -1;
(EngineCore_DP0 pid=376768) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=376768) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	shfl.sync.bfly.b32 	%r67, %r66, 1, 31, -1;
(EngineCore_DP0 pid=376768) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	max.f32 	%r49, %r66, %r67;
(EngineCore_DP0 pid=376768) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=376768) 	// begin inline asm
(EngineCore_DP0 pid=376768) 	@%p19 st.shared.b32 [ %r47 + 0 ], %r49;
(EngineCore_DP0 pid=376768) 	// end inline asm
(EngineCore_DP0 pid=376768) 	bar.sync 	0;
(EngineCore_DP0 pid=376768) 	ld.shared.b32 	%r68, [global_smem];
(EngineCore_DP0 pid=376768) $L__tmp2:
(EngineCore_DP0 pid=376768) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=376768) 	max.f32 	%r119, %r119, %r68;
(EngineCore_DP0 pid=376768) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=376768) 	add.s32 	%r120, %r120, 4096;
(EngineCore_DP0 pid=376768) 	setp.lt.s32 	%p6, %r120, %r19;
(EngineCore_DP0 pid=376768) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=376768) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=376768) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=376768) 	max.f32 	%r121, %r119, 0f2B8CBCCC;
(EngineCore_DP0 pid=376768) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=376768) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=376768) 	mov.b32 	%r70, 0f42FE0000;
(EngineCore_DP0 pid=376768) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=376768) 	div.full.f32 	%r71, %r121, %r70;
(EngineCore_DP0 pid=376768) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=376768) 	max.f32 	%r69, %r71, 0f37810204;
(EngineCore_DP0 pid=376768) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=376768) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=376768) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=376768) 	// begin inline asm
(EngineCore_DP0 pid=376768) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r69 };
(EngineCore_DP0 pid=376768) 	// end inline asm
(EngineCore_DP0 pid=376768) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=376768) 	shl.b32 	%r15, %r20, 2;
(EngineCore_DP0 pid=376768) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=376768) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=376768) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=376768) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=376768) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=376768) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=376768) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=376768) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=376768) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=376768) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=376768) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=376768) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=376768) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=376768) 	div.full.f32 	%r14, %r70, %r121;
(EngineCore_DP0 pid=376768) 	mov.b32 	%r122, 0;
(EngineCore_DP0 pid=376768) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=376768)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=376768) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=376768) 	add.s32 	%r75, %r3, %r122;
(EngineCore_DP0 pid=376768) 	setp.lt.s32 	%p13, %r75, %r15;
(EngineCore_DP0 pid=376768) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=376768) 	shr.s32 	%r76, %r75, 31;
(EngineCore_DP0 pid=376768) 	shr.u32 	%r77, %r76, 30;
(EngineCore_DP0 pid=376768) 	add.s32 	%r78, %r75, %r77;
(EngineCore_DP0 pid=376768) 	shr.s32 	%r79, %r78, 2;
(EngineCore_DP0 pid=376768) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=376768) 	and.b32 	%r80, %r78, 2147483644;
(EngineCore_DP0 pid=376768) 	sub.s32 	%r81, %r75, %r80;
(EngineCore_DP0 pid=376768) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=376768) 	shl.b32 	%r82, %r81, 1;
(EngineCore_DP0 pid=376768) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=376768) 	mad.lo.s32 	%r83, %r79, 10, %r82;
(EngineCore_DP0 pid=376768) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=376768) 	setp.lt.s32 	%p14, %r83, %r18;
(EngineCore_DP0 pid=376768) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=376768) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=376768) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=376768) 	mad.wide.s32 	%rd8, %r83, 2, %rd1;
(EngineCore_DP0 pid=376768) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=376768) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=376768) 	// begin inline asm
(EngineCore_DP0 pid=376768) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=376768) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=376768) 	// end inline asm
(EngineCore_DP0 pid=376768) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=376768) 	cvt.f32.bf16 	%r84, %rs24;
(EngineCore_DP0 pid=376768) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=376768) 	or.b32 	%r85, %r83, 1;
(EngineCore_DP0 pid=376768) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=376768) 	setp.lt.s32 	%p15, %r85, %r18;
(EngineCore_DP0 pid=376768) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=376768) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=376768) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=376768) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=376768) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=376768) 	// begin inline asm
(EngineCore_DP0 pid=376768) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=376768) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=376768) 	// end inline asm
(EngineCore_DP0 pid=376768) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=376768) 	cvt.f32.bf16 	%r86, %rs26;
(EngineCore_DP0 pid=376768) 	.loc	1 340 48                        // quant_slide_tuned_Llama3.2-3B.py:340:48
(EngineCore_DP0 pid=376768) 	add.s32 	%r87, %r83, 2;
(EngineCore_DP0 pid=376768) 	.loc	1 340 53                        // quant_slide_tuned_Llama3.2-3B.py:340:53
(EngineCore_DP0 pid=376768) 	setp.lt.s32 	%p16, %r87, %r18;
(EngineCore_DP0 pid=376768) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=376768) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=376768) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=376768) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=376768) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=376768) 	// begin inline asm
(EngineCore_DP0 pid=376768) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=376768) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=376768) 	// end inline asm
(EngineCore_DP0 pid=376768) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=376768) 	cvt.f32.bf16 	%r88, %rs28;
(EngineCore_DP0 pid=376768) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=376768) 	add.s32 	%r89, %r83, 3;
(EngineCore_DP0 pid=376768) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=376768) 	setp.lt.s32 	%p17, %r89, %r18;
(EngineCore_DP0 pid=376768) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=376768) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=376768) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=376768) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=376768) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=376768) 	// begin inline asm
(EngineCore_DP0 pid=376768) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=376768) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=376768) 	// end inline asm
(EngineCore_DP0 pid=376768) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=376768) 	cvt.f32.bf16 	%r90, %rs30;
(EngineCore_DP0 pid=376768) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=376768) 	mul.f32 	%r91, %r14, %r84;
(EngineCore_DP0 pid=376768) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=376768) 	cvt.rni.f32.f32 	%r92, %r91;
(EngineCore_DP0 pid=376768) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=376768) 	max.f32 	%r93, %r92, 0fC3000000;
(EngineCore_DP0 pid=376768) 	min.f32 	%r94, %r93, 0f42FE0000;
(EngineCore_DP0 pid=376768) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=376768) 	cvt.rzi.s32.f32 	%r95, %r94;
(EngineCore_DP0 pid=376768) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=376768) 	and.b32 	%r96, %r95, 255;
(EngineCore_DP0 pid=376768) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=376768) 	mul.f32 	%r97, %r14, %r86;
(EngineCore_DP0 pid=376768) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=376768) 	cvt.rni.f32.f32 	%r98, %r97;
(EngineCore_DP0 pid=376768) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=376768) 	mul.f32 	%r99, %r14, %r88;
(EngineCore_DP0 pid=376768) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=376768) 	cvt.rni.f32.f32 	%r100, %r99;
(EngineCore_DP0 pid=376768) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=376768) 	mul.f32 	%r101, %r14, %r90;
(EngineCore_DP0 pid=376768) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=376768) 	cvt.rni.f32.f32 	%r102, %r101;
(EngineCore_DP0 pid=376768) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=376768) 	max.f32 	%r103, %r102, 0fC3000000;
(EngineCore_DP0 pid=376768) 	min.f32 	%r104, %r103, 0f42FE0000;
(EngineCore_DP0 pid=376768) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=376768) 	cvt.rzi.s32.f32 	%r105, %r104;
(EngineCore_DP0 pid=376768) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=376768) 	max.f32 	%r106, %r100, 0fC3000000;
(EngineCore_DP0 pid=376768) 	max.f32 	%r107, %r98, 0fC3000000;
(EngineCore_DP0 pid=376768) 	min.f32 	%r108, %r107, 0f42FE0000;
(EngineCore_DP0 pid=376768) 	min.f32 	%r109, %r106, 0f42FE0000;
(EngineCore_DP0 pid=376768) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=376768) 	cvt.rzi.s32.f32 	%r110, %r109;
(EngineCore_DP0 pid=376768) 	cvt.rzi.s32.f32 	%r111, %r108;
(EngineCore_DP0 pid=376768) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=376768) 	shl.b32 	%r112, %r111, 8;
(EngineCore_DP0 pid=376768) 	shl.b32 	%r113, %r110, 16;
(EngineCore_DP0 pid=376768) 	and.b32 	%r114, %r113, 16711680;
(EngineCore_DP0 pid=376768) 	and.b32 	%r115, %r112, 65280;
(EngineCore_DP0 pid=376768) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=376768) 	or.b32 	%r116, %r115, %r96;
(EngineCore_DP0 pid=376768) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=376768) 	or.b32 	%r117, %r116, %r114;
(EngineCore_DP0 pid=376768) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=376768) 	shl.b32 	%r118, %r105, 24;
(EngineCore_DP0 pid=376768) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=376768) 	or.b32 	%r73, %r117, %r118;
(EngineCore_DP0 pid=376768) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=376768) 	mad.wide.s32 	%rd12, %r75, 4, %rd2;
(EngineCore_DP0 pid=376768) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=376768) 	// begin inline asm
(EngineCore_DP0 pid=376768) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r73 };
(EngineCore_DP0 pid=376768) 	// end inline asm
(EngineCore_DP0 pid=376768) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=376768) 	add.s32 	%r122, %r122, 512;
(EngineCore_DP0 pid=376768) 	setp.lt.s32 	%p18, %r122, %r15;
(EngineCore_DP0 pid=376768) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=376768) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=376768) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=376768) 	ret;
(EngineCore_DP0 pid=376768) $L__tmp3:
(EngineCore_DP0 pid=376768) $L__func_end0:
(EngineCore_DP0 pid=376768)                                         // -- End function
(EngineCore_DP0 pid=376768) }
(EngineCore_DP0 pid=376768) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=376768) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=376768) 	.section	.debug_abbrev
(EngineCore_DP0 pid=376768) 	{
(EngineCore_DP0 pid=376768) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=376768) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=376768) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=376768) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=376768) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=376768) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=376768) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=376768) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=376768) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=376768) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=376768) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=376768) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=376768) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=376768) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=376768) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=376768) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=376768) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=376768) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=376768) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=376768) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=376768) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=376768) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=376768) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=376768) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=376768) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=376768) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=376768) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=376768) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=376768) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=376768) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=376768) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=376768) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=376768) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=376768) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=376768) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=376768) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=376768) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=376768) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=376768) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=376768) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=376768) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=376768) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=376768) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=376768) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=376768) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=376768) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=376768) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=376768) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=376768) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=376768) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=376768) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=376768) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=376768) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=376768) 	}
(EngineCore_DP0 pid=376768) 	.section	.debug_info
(EngineCore_DP0 pid=376768) 	{
(EngineCore_DP0 pid=376768) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=376768) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=376768) .b8 0
(EngineCore_DP0 pid=376768) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=376768) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=376768) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=376768) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=376768) .b8 114
(EngineCore_DP0 pid=376768) .b8 105
(EngineCore_DP0 pid=376768) .b8 116
(EngineCore_DP0 pid=376768) .b8 111
(EngineCore_DP0 pid=376768) .b8 110
(EngineCore_DP0 pid=376768) .b8 0
(EngineCore_DP0 pid=376768) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=376768) .b8 0
(EngineCore_DP0 pid=376768) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=376768) .b8 117
(EngineCore_DP0 pid=376768) .b8 97
(EngineCore_DP0 pid=376768) .b8 110
(EngineCore_DP0 pid=376768) .b8 116
(EngineCore_DP0 pid=376768) .b8 95
(EngineCore_DP0 pid=376768) .b8 115
(EngineCore_DP0 pid=376768) .b8 108
(EngineCore_DP0 pid=376768) .b8 105
(EngineCore_DP0 pid=376768) .b8 100
(EngineCore_DP0 pid=376768) .b8 101
(EngineCore_DP0 pid=376768) .b8 95
(EngineCore_DP0 pid=376768) .b8 116
(EngineCore_DP0 pid=376768) .b8 117
(EngineCore_DP0 pid=376768) .b8 110
(EngineCore_DP0 pid=376768) .b8 101
(EngineCore_DP0 pid=376768) .b8 100
(EngineCore_DP0 pid=376768) .b8 95
(EngineCore_DP0 pid=376768) .b8 76
(EngineCore_DP0 pid=376768) .b8 108
(EngineCore_DP0 pid=376768) .b8 97
(EngineCore_DP0 pid=376768) .b8 109
(EngineCore_DP0 pid=376768) .b8 97
(EngineCore_DP0 pid=376768) .b8 51
(EngineCore_DP0 pid=376768) .b8 46
(EngineCore_DP0 pid=376768) .b8 50
(EngineCore_DP0 pid=376768) .b8 45
(EngineCore_DP0 pid=376768) .b8 51
(EngineCore_DP0 pid=376768) .b8 66
(EngineCore_DP0 pid=376768) .b8 46
(EngineCore_DP0 pid=376768) .b8 112
(EngineCore_DP0 pid=376768) .b8 121
(EngineCore_DP0 pid=376768) .b8 0
(EngineCore_DP0 pid=376768) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=376768) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=376768) .b8 114
(EngineCore_DP0 pid=376768) .b8 111
(EngineCore_DP0 pid=376768) .b8 111
(EngineCore_DP0 pid=376768) .b8 116
(EngineCore_DP0 pid=376768) .b8 47
(EngineCore_DP0 pid=376768) .b8 118
(EngineCore_DP0 pid=376768) .b8 108
(EngineCore_DP0 pid=376768) .b8 108
(EngineCore_DP0 pid=376768) .b8 109
(EngineCore_DP0 pid=376768) .b8 98
(EngineCore_DP0 pid=376768) .b8 101
(EngineCore_DP0 pid=376768) .b8 110
(EngineCore_DP0 pid=376768) .b8 99
(EngineCore_DP0 pid=376768) .b8 104
(EngineCore_DP0 pid=376768) .b8 47
(EngineCore_DP0 pid=376768) .b8 115
(EngineCore_DP0 pid=376768) .b8 108
(EngineCore_DP0 pid=376768) .b8 105
(EngineCore_DP0 pid=376768) .b8 100
(EngineCore_DP0 pid=376768) .b8 101
(EngineCore_DP0 pid=376768) .b8 115
(EngineCore_DP0 pid=376768) .b8 112
(EngineCore_DP0 pid=376768) .b8 97
(EngineCore_DP0 pid=376768) .b8 114
(EngineCore_DP0 pid=376768) .b8 115
(EngineCore_DP0 pid=376768) .b8 101
(EngineCore_DP0 pid=376768) .b8 47
(EngineCore_DP0 pid=376768) .b8 99
(EngineCore_DP0 pid=376768) .b8 115
(EngineCore_DP0 pid=376768) .b8 114
(EngineCore_DP0 pid=376768) .b8 99
(EngineCore_DP0 pid=376768) .b8 47
(EngineCore_DP0 pid=376768) .b8 102
(EngineCore_DP0 pid=376768) .b8 117
(EngineCore_DP0 pid=376768) .b8 115
(EngineCore_DP0 pid=376768) .b8 101
(EngineCore_DP0 pid=376768) .b8 100
(EngineCore_DP0 pid=376768) .b8 95
(EngineCore_DP0 pid=376768) .b8 113
(EngineCore_DP0 pid=376768) .b8 117
(EngineCore_DP0 pid=376768) .b8 97
(EngineCore_DP0 pid=376768) .b8 110
(EngineCore_DP0 pid=376768) .b8 116
(EngineCore_DP0 pid=376768) .b8 95
(EngineCore_DP0 pid=376768) .b8 115
(EngineCore_DP0 pid=376768) .b8 108
(EngineCore_DP0 pid=376768) .b8 105
(EngineCore_DP0 pid=376768) .b8 100
(EngineCore_DP0 pid=376768) .b8 101
(EngineCore_DP0 pid=376768) .b8 95
(EngineCore_DP0 pid=376768) .b8 116
(EngineCore_DP0 pid=376768) .b8 114
(EngineCore_DP0 pid=376768) .b8 105
(EngineCore_DP0 pid=376768) .b8 116
(EngineCore_DP0 pid=376768) .b8 111
(EngineCore_DP0 pid=376768) .b8 110
(EngineCore_DP0 pid=376768) .b8 47
(EngineCore_DP0 pid=376768) .b8 98
(EngineCore_DP0 pid=376768) .b8 117
(EngineCore_DP0 pid=376768) .b8 105
(EngineCore_DP0 pid=376768) .b8 108
(EngineCore_DP0 pid=376768) .b8 100
(EngineCore_DP0 pid=376768) .b8 47
(EngineCore_DP0 pid=376768) .b8 71
(EngineCore_DP0 pid=376768) .b8 66
(EngineCore_DP0 pid=376768) .b8 49
(EngineCore_DP0 pid=376768) .b8 48
(EngineCore_DP0 pid=376768) .b8 95
(EngineCore_DP0 pid=376768) .b8 99
(EngineCore_DP0 pid=376768) .b8 99
(EngineCore_DP0 pid=376768) .b8 49
(EngineCore_DP0 pid=376768) .b8 50
(EngineCore_DP0 pid=376768) .b8 49
(EngineCore_DP0 pid=376768) .b8 95
(EngineCore_DP0 pid=376768) .b8 112
(EngineCore_DP0 pid=376768) .b8 121
(EngineCore_DP0 pid=376768) .b8 51
(EngineCore_DP0 pid=376768) .b8 49
(EngineCore_DP0 pid=376768) .b8 50
(EngineCore_DP0 pid=376768) .b8 95
(EngineCore_DP0 pid=376768) .b8 99
(EngineCore_DP0 pid=376768) .b8 117
(EngineCore_DP0 pid=376768) .b8 49
(EngineCore_DP0 pid=376768) .b8 50
(EngineCore_DP0 pid=376768) .b8 57
(EngineCore_DP0 pid=376768) .b8 95
(EngineCore_DP0 pid=376768) .b8 97
(EngineCore_DP0 pid=376768) .b8 97
(EngineCore_DP0 pid=376768) .b8 114
(EngineCore_DP0 pid=376768) .b8 99
(EngineCore_DP0 pid=376768) .b8 104
(EngineCore_DP0 pid=376768) .b8 54
(EngineCore_DP0 pid=376768) .b8 52
(EngineCore_DP0 pid=376768) .b8 0
(EngineCore_DP0 pid=376768) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=376768) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=376768) .b8 113
(EngineCore_DP0 pid=376768) .b8 117
(EngineCore_DP0 pid=376768) .b8 97
(EngineCore_DP0 pid=376768) .b8 110
(EngineCore_DP0 pid=376768) .b8 116
(EngineCore_DP0 pid=376768) .b8 95
(EngineCore_DP0 pid=376768) .b8 115
(EngineCore_DP0 pid=376768) .b8 108
(EngineCore_DP0 pid=376768) .b8 105
(EngineCore_DP0 pid=376768) .b8 100
(EngineCore_DP0 pid=376768) .b8 101
(EngineCore_DP0 pid=376768) .b8 95
(EngineCore_DP0 pid=376768) .b8 105
(EngineCore_DP0 pid=376768) .b8 110
(EngineCore_DP0 pid=376768) .b8 116
(EngineCore_DP0 pid=376768) .b8 56
(EngineCore_DP0 pid=376768) .b8 95
(EngineCore_DP0 pid=376768) .b8 107
(EngineCore_DP0 pid=376768) .b8 101
(EngineCore_DP0 pid=376768) .b8 114
(EngineCore_DP0 pid=376768) .b8 110
(EngineCore_DP0 pid=376768) .b8 101
(EngineCore_DP0 pid=376768) .b8 108
(EngineCore_DP0 pid=376768) .b8 0
(EngineCore_DP0 pid=376768) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=376768) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=376768) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=376768) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=376768) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=376768) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=376768) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=376768) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=376768) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=376768) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=376768) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=376768) .b8 1
(EngineCore_DP0 pid=376768) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=376768) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=376768) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=376768) 	}
(EngineCore_DP0 pid=376768) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=376768) 
(EngineCore_DP0 pid=376768) ================================================================
(EngineCore_DP0 pid=376768) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=376768) 
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpytkjzww5.ptx', '-o', '/tmp/tmpytkjzww5.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866] 
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866] 
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866] 
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpytkjzww5.ptx -o /tmp/tmpytkjzww5.ptx.o
(EngineCore_DP0 pid=376768) ERROR 01-25 19:51:13 [core.py:866] 

STDERR:
[2026-01-25 19:50:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:50:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:50:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:50:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:50:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:50:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:50:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:50:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:50:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:50:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:50:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:50:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:50:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:50:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:50:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:50:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:50:40] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:50:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:50:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:50:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:50:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:50:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:50:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:50:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:50:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:50:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:50:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:50:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=376768) [2026-01-25 19:50:41] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=376768) [2026-01-25 19:50:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=376768) [2026-01-25 19:50:41] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=376768) [2026-01-25 19:50:41] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=376768) [2026-01-25 19:50:41] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=376768) [2026-01-25 19:50:41] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=376768) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=376768) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:28<00:00, 28.91s/it]
(EngineCore_DP0 pid=376768) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:28<00:00, 28.91s/it]
(EngineCore_DP0 pid=376768) 
(EngineCore_DP0 pid=376768) [2026-01-25 19:51:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=376768) [2026-01-25 19:51:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=376768) [2026-01-25 19:51:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=376768) [2026-01-25 19:51:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=376768) [2026-01-25 19:51:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=376768) [2026-01-25 19:51:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=376768) [2026-01-25 19:51:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=376768) [2026-01-25 19:51:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=376768) Process EngineCore_DP0:
(EngineCore_DP0 pid=376768) Traceback (most recent call last):
(EngineCore_DP0 pid=376768)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=376768)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=376768)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=376768)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=376768) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpytkjzww5.ptx', '-o', '/tmp/tmpytkjzww5.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=376768) 
(EngineCore_DP0 pid=376768) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=376768) 
(EngineCore_DP0 pid=376768) Traceback (most recent call last):
(EngineCore_DP0 pid=376768)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=376768)     self.run()
(EngineCore_DP0 pid=376768)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=376768)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=376768)     raise e
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=376768)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=376768)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=376768)     super().__init__(
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=376768)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=376768)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=376768)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=376768)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=376768)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=376768)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=376768)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=376768)     return func(*args, **kwargs)
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=376768)     return func(*args, **kwargs)
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=376768)     self.model_runner.profile_run()
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=376768)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=376768)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=376768)     return func(*args, **kwargs)
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=376768)     outputs = self.model(
(EngineCore_DP0 pid=376768)               ^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=376768)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=376768)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=376768)     model_output = self.model(
(EngineCore_DP0 pid=376768)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=376768)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=376768)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=376768)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=376768)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=376768)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=376768)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=376768)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=376768)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=376768)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=376768)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=376768)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=376768)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=376768)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=376768)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=376768)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=376768)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=376768)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=376768)     return self._linear_fn(
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=376768)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=376768)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=376768)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=376768)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=376768)     return fn(input, L)
(EngineCore_DP0 pid=376768)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=376768)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=376768)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=376768)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=376768)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=376768)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=376768)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=376768)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=376768)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=376768)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=376768)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=376768)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=376768)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=376768)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=376768)     raise PTXASError(error)
(EngineCore_DP0 pid=376768) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=376768) `ptxas` stderr:
(EngineCore_DP0 pid=376768) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=376768) 
(EngineCore_DP0 pid=376768) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpytkjzww5.ptx -o /tmp/tmpytkjzww5.ptx.o
(EngineCore_DP0 pid=376768) 
[rank0]:[W125 19:51:13.740885571 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 19:51:15
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:51:20 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:51:20 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=377528) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=377528) 
(EngineCore_DP0 pid=377528) 
(EngineCore_DP0 pid=377528) ================================================================
(EngineCore_DP0 pid=377528) Internal Triton PTX codegen error
(EngineCore_DP0 pid=377528) `ptxas` stderr:
(EngineCore_DP0 pid=377528) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=377528) 
(EngineCore_DP0 pid=377528) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp903ii00z.ptx -o /tmp/tmp903ii00z.ptx.o
(EngineCore_DP0 pid=377528) 
(EngineCore_DP0 pid=377528) 
(EngineCore_DP0 pid=377528) //
(EngineCore_DP0 pid=377528) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=377528) //
(EngineCore_DP0 pid=377528) 
(EngineCore_DP0 pid=377528) .version 8.7
(EngineCore_DP0 pid=377528) .target sm_121a
(EngineCore_DP0 pid=377528) .address_size 64
(EngineCore_DP0 pid=377528) 
(EngineCore_DP0 pid=377528) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=377528) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=377528)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=377528) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=377528) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=377528) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=377528) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=377528) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=377528) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=377528) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=377528) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=377528) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=377528) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=377528) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=377528) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=377528) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=377528) )
(EngineCore_DP0 pid=377528) .reqntid 512
(EngineCore_DP0 pid=377528) {
(EngineCore_DP0 pid=377528) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=377528) 	.reg .b16 	%rs<40>;
(EngineCore_DP0 pid=377528) 	.reg .b32 	%r<172>;
(EngineCore_DP0 pid=377528) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=377528) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=377528) $L__func_begin0:
(EngineCore_DP0 pid=377528) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=377528) 
(EngineCore_DP0 pid=377528) // %bb.0:
(EngineCore_DP0 pid=377528) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=377528) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=377528) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=377528) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=377528) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=377528) $L__tmp0:
(EngineCore_DP0 pid=377528) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=377528) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=377528) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=377528) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=377528) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=377528) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=377528) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=377528) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=377528) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=377528) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=377528) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=377528) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=377528) 	mov.b32 	%r170, 0f2B8CBCCC;
(EngineCore_DP0 pid=377528) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=377528) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=377528) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=377528) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=377528) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=377528) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=377528) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=377528) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=377528) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=377528) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=377528) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=377528) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=377528) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=377528) 	mov.b32 	%r168, 0f00000000;
(EngineCore_DP0 pid=377528) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=377528) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=377528) 	mov.b32 	%r169, %r45;
(EngineCore_DP0 pid=377528) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=377528) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=377528) 	add.s32 	%r55, %r4, %r169;
(EngineCore_DP0 pid=377528) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=377528) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=377528) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=377528) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=377528) 	// begin inline asm
(EngineCore_DP0 pid=377528) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=377528) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=377528) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=377528) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=377528) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=377528) 	// end inline asm
(EngineCore_DP0 pid=377528) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=377528) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=377528) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=377528) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=377528) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=377528) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=377528) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=377528) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=377528) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=377528) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=377528) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=377528) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=377528) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=377528) $L__tmp1:
(EngineCore_DP0 pid=377528) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	bar.sync 	0;
(EngineCore_DP0 pid=377528) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=377528) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=377528) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=377528) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=377528) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=377528) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=377528) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=377528) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=377528) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=377528) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=377528) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=377528) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=377528) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=377528) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=377528) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=377528) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=377528) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=377528) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=377528) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	// begin inline asm
(EngineCore_DP0 pid=377528) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=377528) 	// end inline asm
(EngineCore_DP0 pid=377528) 	bar.sync 	0;
(EngineCore_DP0 pid=377528) 	// begin inline asm
(EngineCore_DP0 pid=377528) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=377528) 	// end inline asm
(EngineCore_DP0 pid=377528) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=377528) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=377528) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=377528) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=377528) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=377528) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=377528) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=377528) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=377528) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=377528) 	// begin inline asm
(EngineCore_DP0 pid=377528) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=377528) 	// end inline asm
(EngineCore_DP0 pid=377528) 	bar.sync 	0;
(EngineCore_DP0 pid=377528) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=377528) $L__tmp2:
(EngineCore_DP0 pid=377528) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=377528) 	max.f32 	%r168, %r168, %r73;
(EngineCore_DP0 pid=377528) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=377528) 	add.s32 	%r169, %r169, 4096;
(EngineCore_DP0 pid=377528) 	setp.lt.s32 	%p6, %r169, %r24;
(EngineCore_DP0 pid=377528) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=377528) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=377528) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=377528) 	max.f32 	%r170, %r168, 0f2B8CBCCC;
(EngineCore_DP0 pid=377528) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=377528) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=377528) 	mov.b32 	%r75, 0f42FE0000;
(EngineCore_DP0 pid=377528) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=377528) 	div.full.f32 	%r76, %r170, %r75;
(EngineCore_DP0 pid=377528) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=377528) 	max.f32 	%r74, %r76, 0f37810204;
(EngineCore_DP0 pid=377528) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=377528) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=377528) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=377528) 	// begin inline asm
(EngineCore_DP0 pid=377528) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=377528) 	// end inline asm
(EngineCore_DP0 pid=377528) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=377528) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=377528) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=377528) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=377528) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=377528) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=377528) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=377528) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=377528) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=377528) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=377528) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=377528) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=377528) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=377528) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=377528) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=377528) 	div.full.f32 	%r14, %r75, %r170;
(EngineCore_DP0 pid=377528) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=377528) 	mov.b32 	%r171, 0;
(EngineCore_DP0 pid=377528) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=377528)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=377528) 	.loc	1 327 31                        // quant_slide_tuned_Llama3.2-3B.py:327:31
(EngineCore_DP0 pid=377528) 	add.s32 	%r80, %r16, %r171;
(EngineCore_DP0 pid=377528) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=377528) 	add.s32 	%r81, %r80, 1;
(EngineCore_DP0 pid=377528) 	setp.lt.s32 	%p17, %r80, %r15;
(EngineCore_DP0 pid=377528) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=377528) 	shr.s32 	%r82, %r80, 31;
(EngineCore_DP0 pid=377528) 	shr.u32 	%r83, %r82, 30;
(EngineCore_DP0 pid=377528) 	add.s32 	%r84, %r80, %r83;
(EngineCore_DP0 pid=377528) 	shr.s32 	%r85, %r84, 2;
(EngineCore_DP0 pid=377528) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=377528) 	shr.s32 	%r86, %r81, 31;
(EngineCore_DP0 pid=377528) 	shr.u32 	%r87, %r86, 30;
(EngineCore_DP0 pid=377528) 	add.s32 	%r88, %r81, %r87;
(EngineCore_DP0 pid=377528) 	and.b32 	%r89, %r88, 2147483644;
(EngineCore_DP0 pid=377528) 	sub.s32 	%r90, %r81, %r89;
(EngineCore_DP0 pid=377528) 	and.b32 	%r91, %r84, 2147483644;
(EngineCore_DP0 pid=377528) 	sub.s32 	%r92, %r80, %r91;
(EngineCore_DP0 pid=377528) 	.loc	1 333 22                        // quant_slide_tuned_Llama3.2-3B.py:333:22
(EngineCore_DP0 pid=377528) 	mul.lo.s32 	%r93, %r85, 10;
(EngineCore_DP0 pid=377528) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=377528) 	shl.b32 	%r94, %r92, 1;
(EngineCore_DP0 pid=377528) 	shl.b32 	%r95, %r90, 1;
(EngineCore_DP0 pid=377528) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=377528) 	add.s32 	%r96, %r93, %r95;
(EngineCore_DP0 pid=377528) 	add.s32 	%r97, %r93, %r94;
(EngineCore_DP0 pid=377528) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=377528) 	setp.lt.s32 	%p18, %r97, %r23;
(EngineCore_DP0 pid=377528) 	setp.lt.s32 	%p19, %r96, %r23;
(EngineCore_DP0 pid=377528) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=377528) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=377528) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=377528) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=377528) 	mad.wide.s32 	%rd8, %r97, 2, %rd1;
(EngineCore_DP0 pid=377528) 	mad.wide.s32 	%rd9, %r96, 2, %rd1;
(EngineCore_DP0 pid=377528) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=377528) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=377528) 	// begin inline asm
(EngineCore_DP0 pid=377528) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=377528) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=377528) 	// end inline asm
(EngineCore_DP0 pid=377528) 	// begin inline asm
(EngineCore_DP0 pid=377528) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=377528) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=377528) 	// end inline asm
(EngineCore_DP0 pid=377528) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=377528) 	cvt.f32.bf16 	%r98, %rs24;
(EngineCore_DP0 pid=377528) 	cvt.f32.bf16 	%r99, %rs26;
(EngineCore_DP0 pid=377528) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=377528) 	or.b32 	%r100, %r97, 1;
(EngineCore_DP0 pid=377528) 	or.b32 	%r101, %r96, 1;
(EngineCore_DP0 pid=377528) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=377528) 	setp.lt.s32 	%p20, %r100, %r23;
(EngineCore_DP0 pid=377528) 	setp.lt.s32 	%p21, %r101, %r23;
(EngineCore_DP0 pid=377528) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=377528) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=377528) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=377528) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=377528) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=377528) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=377528) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=377528) 	// begin inline asm
(EngineCore_DP0 pid=377528) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=377528) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=377528) 	// end inline asm
(EngineCore_DP0 pid=377528) 	// begin inline asm
(EngineCore_DP0 pid=377528) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=377528) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=377528) 	// end inline asm
(EngineCore_DP0 pid=377528) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=377528) 	cvt.f32.bf16 	%r102, %rs28;
(EngineCore_DP0 pid=377528) 	cvt.f32.bf16 	%r103, %rs30;
(EngineCore_DP0 pid=377528) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=377528) 	add.s32 	%r104, %r97, 2;
(EngineCore_DP0 pid=377528) 	add.s32 	%r105, %r96, 2;
(EngineCore_DP0 pid=377528) 	add.s32 	%r106, %r97, 3;
(EngineCore_DP0 pid=377528) 	add.s32 	%r107, %r96, 3;
(EngineCore_DP0 pid=377528) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=377528) 	setp.lt.s32 	%p22, %r107, %r23;
(EngineCore_DP0 pid=377528) 	setp.lt.s32 	%p23, %r106, %r23;
(EngineCore_DP0 pid=377528) 	setp.lt.s32 	%p24, %r105, %r23;
(EngineCore_DP0 pid=377528) 	setp.lt.s32 	%p25, %r104, %r23;
(EngineCore_DP0 pid=377528) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=377528) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=377528) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=377528) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=377528) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=377528) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=377528) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=377528) 	// begin inline asm
(EngineCore_DP0 pid=377528) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=377528) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=377528) 	// end inline asm
(EngineCore_DP0 pid=377528) 	// begin inline asm
(EngineCore_DP0 pid=377528) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=377528) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=377528) 	// end inline asm
(EngineCore_DP0 pid=377528) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=377528) 	cvt.f32.bf16 	%r108, %rs32;
(EngineCore_DP0 pid=377528) 	cvt.f32.bf16 	%r109, %rs34;
(EngineCore_DP0 pid=377528) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=377528) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=377528) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=377528) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=377528) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=377528) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=377528) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=377528) 	// begin inline asm
(EngineCore_DP0 pid=377528) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=377528) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=377528) 	// end inline asm
(EngineCore_DP0 pid=377528) 	// begin inline asm
(EngineCore_DP0 pid=377528) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=377528) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=377528) 	// end inline asm
(EngineCore_DP0 pid=377528) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=377528) 	cvt.f32.bf16 	%r110, %rs36;
(EngineCore_DP0 pid=377528) 	cvt.f32.bf16 	%r111, %rs38;
(EngineCore_DP0 pid=377528) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=377528) 	mul.f32 	%r112, %r14, %r98;
(EngineCore_DP0 pid=377528) 	mul.f32 	%r113, %r14, %r99;
(EngineCore_DP0 pid=377528) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=377528) 	cvt.rni.f32.f32 	%r114, %r112;
(EngineCore_DP0 pid=377528) 	cvt.rni.f32.f32 	%r115, %r113;
(EngineCore_DP0 pid=377528) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=377528) 	max.f32 	%r116, %r114, 0fC3000000;
(EngineCore_DP0 pid=377528) 	min.f32 	%r117, %r116, 0f42FE0000;
(EngineCore_DP0 pid=377528) 	max.f32 	%r118, %r115, 0fC3000000;
(EngineCore_DP0 pid=377528) 	min.f32 	%r119, %r118, 0f42FE0000;
(EngineCore_DP0 pid=377528) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=377528) 	cvt.rzi.s32.f32 	%r120, %r117;
(EngineCore_DP0 pid=377528) 	cvt.rzi.s32.f32 	%r121, %r119;
(EngineCore_DP0 pid=377528) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=377528) 	and.b32 	%r122, %r120, 255;
(EngineCore_DP0 pid=377528) 	and.b32 	%r123, %r121, 255;
(EngineCore_DP0 pid=377528) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=377528) 	mul.f32 	%r124, %r14, %r102;
(EngineCore_DP0 pid=377528) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=377528) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=377528) 	cvt.rni.f32.f32 	%r126, %r124;
(EngineCore_DP0 pid=377528) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=377528) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=377528) 	mul.f32 	%r128, %r14, %r108;
(EngineCore_DP0 pid=377528) 	mul.f32 	%r129, %r14, %r109;
(EngineCore_DP0 pid=377528) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=377528) 	cvt.rni.f32.f32 	%r130, %r128;
(EngineCore_DP0 pid=377528) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=377528) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=377528) 	mul.f32 	%r132, %r14, %r110;
(EngineCore_DP0 pid=377528) 	mul.f32 	%r133, %r14, %r111;
(EngineCore_DP0 pid=377528) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=377528) 	cvt.rni.f32.f32 	%r134, %r132;
(EngineCore_DP0 pid=377528) 	cvt.rni.f32.f32 	%r135, %r133;
(EngineCore_DP0 pid=377528) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=377528) 	max.f32 	%r136, %r134, 0fC3000000;
(EngineCore_DP0 pid=377528) 	min.f32 	%r137, %r136, 0f42FE0000;
(EngineCore_DP0 pid=377528) 	max.f32 	%r138, %r135, 0fC3000000;
(EngineCore_DP0 pid=377528) 	min.f32 	%r139, %r138, 0f42FE0000;
(EngineCore_DP0 pid=377528) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=377528) 	cvt.rzi.s32.f32 	%r140, %r137;
(EngineCore_DP0 pid=377528) 	cvt.rzi.s32.f32 	%r141, %r139;
(EngineCore_DP0 pid=377528) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=377528) 	max.f32 	%r142, %r130, 0fC3000000;
(EngineCore_DP0 pid=377528) 	max.f32 	%r143, %r126, 0fC3000000;
(EngineCore_DP0 pid=377528) 	min.f32 	%r144, %r143, 0f42FE0000;
(EngineCore_DP0 pid=377528) 	min.f32 	%r145, %r142, 0f42FE0000;
(EngineCore_DP0 pid=377528) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=377528) 	cvt.rzi.s32.f32 	%r146, %r145;
(EngineCore_DP0 pid=377528) 	cvt.rzi.s32.f32 	%r147, %r144;
(EngineCore_DP0 pid=377528) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=377528) 	shl.b32 	%r148, %r147, 8;
(EngineCore_DP0 pid=377528) 	shl.b32 	%r149, %r146, 16;
(EngineCore_DP0 pid=377528) 	and.b32 	%r150, %r149, 16711680;
(EngineCore_DP0 pid=377528) 	and.b32 	%r151, %r148, 65280;
(EngineCore_DP0 pid=377528) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=377528) 	or.b32 	%r152, %r151, %r122;
(EngineCore_DP0 pid=377528) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=377528) 	max.f32 	%r153, %r131, 0fC3000000;
(EngineCore_DP0 pid=377528) 	max.f32 	%r154, %r127, 0fC3000000;
(EngineCore_DP0 pid=377528) 	min.f32 	%r155, %r154, 0f42FE0000;
(EngineCore_DP0 pid=377528) 	min.f32 	%r156, %r153, 0f42FE0000;
(EngineCore_DP0 pid=377528) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=377528) 	cvt.rzi.s32.f32 	%r157, %r156;
(EngineCore_DP0 pid=377528) 	cvt.rzi.s32.f32 	%r158, %r155;
(EngineCore_DP0 pid=377528) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=377528) 	shl.b32 	%r159, %r158, 8;
(EngineCore_DP0 pid=377528) 	shl.b32 	%r160, %r157, 16;
(EngineCore_DP0 pid=377528) 	and.b32 	%r161, %r160, 16711680;
(EngineCore_DP0 pid=377528) 	and.b32 	%r162, %r159, 65280;
(EngineCore_DP0 pid=377528) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=377528) 	or.b32 	%r163, %r162, %r123;
(EngineCore_DP0 pid=377528) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=377528) 	or.b32 	%r164, %r152, %r150;
(EngineCore_DP0 pid=377528) 	or.b32 	%r165, %r163, %r161;
(EngineCore_DP0 pid=377528) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=377528) 	shl.b32 	%r166, %r140, 24;
(EngineCore_DP0 pid=377528) 	shl.b32 	%r167, %r141, 24;
(EngineCore_DP0 pid=377528) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=377528) 	or.b32 	%r78, %r164, %r166;
(EngineCore_DP0 pid=377528) 	or.b32 	%r79, %r165, %r167;
(EngineCore_DP0 pid=377528) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=377528) 	mad.wide.s32 	%rd16, %r80, 4, %rd2;
(EngineCore_DP0 pid=377528) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=377528) 	// begin inline asm
(EngineCore_DP0 pid=377528) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r78, %r79 };
(EngineCore_DP0 pid=377528) 	// end inline asm
(EngineCore_DP0 pid=377528) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=377528) 	add.s32 	%r171, %r171, 1024;
(EngineCore_DP0 pid=377528) 	setp.lt.s32 	%p26, %r171, %r15;
(EngineCore_DP0 pid=377528) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=377528) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=377528) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=377528) 	ret;
(EngineCore_DP0 pid=377528) $L__tmp3:
(EngineCore_DP0 pid=377528) $L__func_end0:
(EngineCore_DP0 pid=377528)                                         // -- End function
(EngineCore_DP0 pid=377528) }
(EngineCore_DP0 pid=377528) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=377528) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=377528) 	.section	.debug_abbrev
(EngineCore_DP0 pid=377528) 	{
(EngineCore_DP0 pid=377528) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=377528) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=377528) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=377528) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=377528) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=377528) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=377528) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=377528) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=377528) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=377528) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=377528) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=377528) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=377528) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=377528) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=377528) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=377528) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=377528) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=377528) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=377528) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=377528) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=377528) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=377528) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=377528) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=377528) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=377528) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=377528) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=377528) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=377528) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=377528) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=377528) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=377528) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=377528) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=377528) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=377528) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=377528) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=377528) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=377528) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=377528) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=377528) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=377528) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=377528) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=377528) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=377528) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=377528) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=377528) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=377528) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=377528) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=377528) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=377528) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=377528) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=377528) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=377528) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=377528) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=377528) 	}
(EngineCore_DP0 pid=377528) 	.section	.debug_info
(EngineCore_DP0 pid=377528) 	{
(EngineCore_DP0 pid=377528) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=377528) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=377528) .b8 0
(EngineCore_DP0 pid=377528) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=377528) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=377528) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=377528) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=377528) .b8 114
(EngineCore_DP0 pid=377528) .b8 105
(EngineCore_DP0 pid=377528) .b8 116
(EngineCore_DP0 pid=377528) .b8 111
(EngineCore_DP0 pid=377528) .b8 110
(EngineCore_DP0 pid=377528) .b8 0
(EngineCore_DP0 pid=377528) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=377528) .b8 0
(EngineCore_DP0 pid=377528) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=377528) .b8 117
(EngineCore_DP0 pid=377528) .b8 97
(EngineCore_DP0 pid=377528) .b8 110
(EngineCore_DP0 pid=377528) .b8 116
(EngineCore_DP0 pid=377528) .b8 95
(EngineCore_DP0 pid=377528) .b8 115
(EngineCore_DP0 pid=377528) .b8 108
(EngineCore_DP0 pid=377528) .b8 105
(EngineCore_DP0 pid=377528) .b8 100
(EngineCore_DP0 pid=377528) .b8 101
(EngineCore_DP0 pid=377528) .b8 95
(EngineCore_DP0 pid=377528) .b8 116
(EngineCore_DP0 pid=377528) .b8 117
(EngineCore_DP0 pid=377528) .b8 110
(EngineCore_DP0 pid=377528) .b8 101
(EngineCore_DP0 pid=377528) .b8 100
(EngineCore_DP0 pid=377528) .b8 95
(EngineCore_DP0 pid=377528) .b8 76
(EngineCore_DP0 pid=377528) .b8 108
(EngineCore_DP0 pid=377528) .b8 97
(EngineCore_DP0 pid=377528) .b8 109
(EngineCore_DP0 pid=377528) .b8 97
(EngineCore_DP0 pid=377528) .b8 51
(EngineCore_DP0 pid=377528) .b8 46
(EngineCore_DP0 pid=377528) .b8 50
(EngineCore_DP0 pid=377528) .b8 45
(EngineCore_DP0 pid=377528) .b8 51
(EngineCore_DP0 pid=377528) .b8 66
(EngineCore_DP0 pid=377528) .b8 46
(EngineCore_DP0 pid=377528) .b8 112
(EngineCore_DP0 pid=377528) .b8 121
(EngineCore_DP0 pid=377528) .b8 0
(EngineCore_DP0 pid=377528) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=377528) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=377528) .b8 114
(EngineCore_DP0 pid=377528) .b8 111
(EngineCore_DP0 pid=377528) .b8 111
(EngineCore_DP0 pid=377528) .b8 116
(EngineCore_DP0 pid=377528) .b8 47
(EngineCore_DP0 pid=377528) .b8 118
(EngineCore_DP0 pid=377528) .b8 108
(EngineCore_DP0 pid=377528) .b8 108
(EngineCore_DP0 pid=377528) .b8 109
(EngineCore_DP0 pid=377528) .b8 98
(EngineCore_DP0 pid=377528) .b8 101
(EngineCore_DP0 pid=377528) .b8 110
(EngineCore_DP0 pid=377528) .b8 99
(EngineCore_DP0 pid=377528) .b8 104
(EngineCore_DP0 pid=377528) .b8 47
(EngineCore_DP0 pid=377528) .b8 115
(EngineCore_DP0 pid=377528) .b8 108
(EngineCore_DP0 pid=377528) .b8 105
(EngineCore_DP0 pid=377528) .b8 100
(EngineCore_DP0 pid=377528) .b8 101
(EngineCore_DP0 pid=377528) .b8 115
(EngineCore_DP0 pid=377528) .b8 112
(EngineCore_DP0 pid=377528) .b8 97
(EngineCore_DP0 pid=377528) .b8 114
(EngineCore_DP0 pid=377528) .b8 115
(EngineCore_DP0 pid=377528) .b8 101
(EngineCore_DP0 pid=377528) .b8 47
(EngineCore_DP0 pid=377528) .b8 99
(EngineCore_DP0 pid=377528) .b8 115
(EngineCore_DP0 pid=377528) .b8 114
(EngineCore_DP0 pid=377528) .b8 99
(EngineCore_DP0 pid=377528) .b8 47
(EngineCore_DP0 pid=377528) .b8 102
(EngineCore_DP0 pid=377528) .b8 117
(EngineCore_DP0 pid=377528) .b8 115
(EngineCore_DP0 pid=377528) .b8 101
(EngineCore_DP0 pid=377528) .b8 100
(EngineCore_DP0 pid=377528) .b8 95
(EngineCore_DP0 pid=377528) .b8 113
(EngineCore_DP0 pid=377528) .b8 117
(EngineCore_DP0 pid=377528) .b8 97
(EngineCore_DP0 pid=377528) .b8 110
(EngineCore_DP0 pid=377528) .b8 116
(EngineCore_DP0 pid=377528) .b8 95
(EngineCore_DP0 pid=377528) .b8 115
(EngineCore_DP0 pid=377528) .b8 108
(EngineCore_DP0 pid=377528) .b8 105
(EngineCore_DP0 pid=377528) .b8 100
(EngineCore_DP0 pid=377528) .b8 101
(EngineCore_DP0 pid=377528) .b8 95
(EngineCore_DP0 pid=377528) .b8 116
(EngineCore_DP0 pid=377528) .b8 114
(EngineCore_DP0 pid=377528) .b8 105
(EngineCore_DP0 pid=377528) .b8 116
(EngineCore_DP0 pid=377528) .b8 111
(EngineCore_DP0 pid=377528) .b8 110
(EngineCore_DP0 pid=377528) .b8 47
(EngineCore_DP0 pid=377528) .b8 98
(EngineCore_DP0 pid=377528) .b8 117
(EngineCore_DP0 pid=377528) .b8 105
(EngineCore_DP0 pid=377528) .b8 108
(EngineCore_DP0 pid=377528) .b8 100
(EngineCore_DP0 pid=377528) .b8 47
(EngineCore_DP0 pid=377528) .b8 71
(EngineCore_DP0 pid=377528) .b8 66
(EngineCore_DP0 pid=377528) .b8 49
(EngineCore_DP0 pid=377528) .b8 48
(EngineCore_DP0 pid=377528) .b8 95
(EngineCore_DP0 pid=377528) .b8 99
(EngineCore_DP0 pid=377528) .b8 99
(EngineCore_DP0 pid=377528) .b8 49
(EngineCore_DP0 pid=377528) .b8 50
(EngineCore_DP0 pid=377528) .b8 49
(EngineCore_DP0 pid=377528) .b8 95
(EngineCore_DP0 pid=377528) .b8 112
(EngineCore_DP0 pid=377528) .b8 121
(EngineCore_DP0 pid=377528) .b8 51
(EngineCore_DP0 pid=377528) .b8 49
(EngineCore_DP0 pid=377528) .b8 50
(EngineCore_DP0 pid=377528) .b8 95
(EngineCore_DP0 pid=377528) .b8 99
(EngineCore_DP0 pid=377528) .b8 117
(EngineCore_DP0 pid=377528) .b8 49
(EngineCore_DP0 pid=377528) .b8 50
(EngineCore_DP0 pid=377528) .b8 57
(EngineCore_DP0 pid=377528) .b8 95
(EngineCore_DP0 pid=377528) .b8 97
(EngineCore_DP0 pid=377528) .b8 97
(EngineCore_DP0 pid=377528) .b8 114
(EngineCore_DP0 pid=377528) .b8 99
(EngineCore_DP0 pid=377528) .b8 104
(EngineCore_DP0 pid=377528) .b8 54
(EngineCore_DP0 pid=377528) .b8 52
(EngineCore_DP0 pid=377528) .b8 0
(EngineCore_DP0 pid=377528) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=377528) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=377528) .b8 113
(EngineCore_DP0 pid=377528) .b8 117
(EngineCore_DP0 pid=377528) .b8 97
(EngineCore_DP0 pid=377528) .b8 110
(EngineCore_DP0 pid=377528) .b8 116
(EngineCore_DP0 pid=377528) .b8 95
(EngineCore_DP0 pid=377528) .b8 115
(EngineCore_DP0 pid=377528) .b8 108
(EngineCore_DP0 pid=377528) .b8 105
(EngineCore_DP0 pid=377528) .b8 100
(EngineCore_DP0 pid=377528) .b8 101
(EngineCore_DP0 pid=377528) .b8 95
(EngineCore_DP0 pid=377528) .b8 105
(EngineCore_DP0 pid=377528) .b8 110
(EngineCore_DP0 pid=377528) .b8 116
(EngineCore_DP0 pid=377528) .b8 56
(EngineCore_DP0 pid=377528) .b8 95
(EngineCore_DP0 pid=377528) .b8 107
(EngineCore_DP0 pid=377528) .b8 101
(EngineCore_DP0 pid=377528) .b8 114
(EngineCore_DP0 pid=377528) .b8 110
(EngineCore_DP0 pid=377528) .b8 101
(EngineCore_DP0 pid=377528) .b8 108
(EngineCore_DP0 pid=377528) .b8 0
(EngineCore_DP0 pid=377528) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=377528) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=377528) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=377528) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=377528) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=377528) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=377528) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=377528) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=377528) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=377528) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=377528) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=377528) .b8 1
(EngineCore_DP0 pid=377528) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=377528) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=377528) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=377528) 	}
(EngineCore_DP0 pid=377528) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=377528) 
(EngineCore_DP0 pid=377528) ================================================================
(EngineCore_DP0 pid=377528) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=377528) 
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp903ii00z.ptx', '-o', '/tmp/tmp903ii00z.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866] 
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866] 
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866] 
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp903ii00z.ptx -o /tmp/tmp903ii00z.ptx.o
(EngineCore_DP0 pid=377528) ERROR 01-25 19:51:55 [core.py:866] 

STDERR:
[2026-01-25 19:51:19] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:51:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:51:19] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:51:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:51:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:51:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:51:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:51:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:51:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:51:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:51:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:51:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:51:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:51:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:51:23] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:51:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:51:23] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:51:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:51:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:51:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:51:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:51:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:51:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:51:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:51:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:51:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:51:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:51:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=377528) [2026-01-25 19:51:24] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=377528) [2026-01-25 19:51:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=377528) [2026-01-25 19:51:24] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=377528) [2026-01-25 19:51:24] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=377528) [2026-01-25 19:51:24] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=377528) [2026-01-25 19:51:24] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=377528) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=377528) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29<00:00, 29.06s/it]
(EngineCore_DP0 pid=377528) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29<00:00, 29.06s/it]
(EngineCore_DP0 pid=377528) 
(EngineCore_DP0 pid=377528) [2026-01-25 19:51:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=377528) [2026-01-25 19:51:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=377528) [2026-01-25 19:51:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=377528) [2026-01-25 19:51:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=377528) [2026-01-25 19:51:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=377528) [2026-01-25 19:51:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=377528) [2026-01-25 19:51:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=377528) [2026-01-25 19:51:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=377528) Process EngineCore_DP0:
(EngineCore_DP0 pid=377528) Traceback (most recent call last):
(EngineCore_DP0 pid=377528)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=377528)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=377528)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=377528)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=377528) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp903ii00z.ptx', '-o', '/tmp/tmp903ii00z.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=377528) 
(EngineCore_DP0 pid=377528) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=377528) 
(EngineCore_DP0 pid=377528) Traceback (most recent call last):
(EngineCore_DP0 pid=377528)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=377528)     self.run()
(EngineCore_DP0 pid=377528)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=377528)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=377528)     raise e
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=377528)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=377528)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=377528)     super().__init__(
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=377528)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=377528)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=377528)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=377528)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=377528)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=377528)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=377528)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=377528)     return func(*args, **kwargs)
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=377528)     return func(*args, **kwargs)
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=377528)     self.model_runner.profile_run()
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=377528)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=377528)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=377528)     return func(*args, **kwargs)
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=377528)     outputs = self.model(
(EngineCore_DP0 pid=377528)               ^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=377528)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=377528)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=377528)     model_output = self.model(
(EngineCore_DP0 pid=377528)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=377528)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=377528)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=377528)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=377528)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=377528)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=377528)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=377528)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=377528)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=377528)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=377528)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=377528)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=377528)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=377528)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=377528)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=377528)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=377528)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=377528)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=377528)     return self._linear_fn(
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=377528)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=377528)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=377528)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=377528)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=377528)     return fn(input, L)
(EngineCore_DP0 pid=377528)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=377528)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=377528)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=377528)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=377528)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=377528)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=377528)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=377528)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=377528)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=377528)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=377528)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=377528)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=377528)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=377528)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=377528)     raise PTXASError(error)
(EngineCore_DP0 pid=377528) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=377528) `ptxas` stderr:
(EngineCore_DP0 pid=377528) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=377528) 
(EngineCore_DP0 pid=377528) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp903ii00z.ptx -o /tmp/tmp903ii00z.ptx.o
(EngineCore_DP0 pid=377528) 
[rank0]:[W125 19:51:56.388675770 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 19:51:57
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:52:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:52:04 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=378339) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=378339) 
(EngineCore_DP0 pid=378339) 
(EngineCore_DP0 pid=378339) ================================================================
(EngineCore_DP0 pid=378339) Internal Triton PTX codegen error
(EngineCore_DP0 pid=378339) `ptxas` stderr:
(EngineCore_DP0 pid=378339) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=378339) 
(EngineCore_DP0 pid=378339) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp7o9mi6zf.ptx -o /tmp/tmp7o9mi6zf.ptx.o
(EngineCore_DP0 pid=378339) 
(EngineCore_DP0 pid=378339) 
(EngineCore_DP0 pid=378339) //
(EngineCore_DP0 pid=378339) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=378339) //
(EngineCore_DP0 pid=378339) 
(EngineCore_DP0 pid=378339) .version 8.7
(EngineCore_DP0 pid=378339) .target sm_121a
(EngineCore_DP0 pid=378339) .address_size 64
(EngineCore_DP0 pid=378339) 
(EngineCore_DP0 pid=378339) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=378339) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=378339)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=378339) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=378339) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=378339) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=378339) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=378339) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=378339) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=378339) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=378339) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=378339) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=378339) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=378339) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=378339) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=378339) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=378339) )
(EngineCore_DP0 pid=378339) .reqntid 512
(EngineCore_DP0 pid=378339) {
(EngineCore_DP0 pid=378339) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=378339) 	.reg .b16 	%rs<64>;
(EngineCore_DP0 pid=378339) 	.reg .b32 	%r<181>;
(EngineCore_DP0 pid=378339) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=378339) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=378339) $L__func_begin0:
(EngineCore_DP0 pid=378339) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=378339) 
(EngineCore_DP0 pid=378339) // %bb.0:
(EngineCore_DP0 pid=378339) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=378339) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=378339) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=378339) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=378339) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=378339) $L__tmp0:
(EngineCore_DP0 pid=378339) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=378339) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=378339) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=378339) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=378339) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=378339) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=378339) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=378339) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=378339) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=378339) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=378339) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=378339) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=378339) 	mov.b32 	%r179, 0f2B8CBCCC;
(EngineCore_DP0 pid=378339) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=378339) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=378339) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=378339) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=378339) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=378339) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=378339) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=378339) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=378339) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=378339) 	add.s32 	%r57, %r39, %r38;
(EngineCore_DP0 pid=378339) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=378339) 	add.s32 	%r60, %r39, %r40;
(EngineCore_DP0 pid=378339) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=378339) 	mov.b32 	%r177, 0f00000000;
(EngineCore_DP0 pid=378339) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=378339) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=378339) 	mov.b32 	%r178, %r45;
(EngineCore_DP0 pid=378339) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=378339) 	.loc	1 313 19                        // quant_slide_tuned_Llama3.2-3B.py:313:19
(EngineCore_DP0 pid=378339) 	add.s32 	%r63, %r4, %r178;
(EngineCore_DP0 pid=378339) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=378339) 	add.s32 	%r64, %r63, 4096;
(EngineCore_DP0 pid=378339) 	setp.lt.s32 	%p2, %r63, %r23;
(EngineCore_DP0 pid=378339) 	setp.lt.s32 	%p3, %r64, %r23;
(EngineCore_DP0 pid=378339) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=378339) 	mad.wide.s32 	%rd6, %r63, 2, %rd1;
(EngineCore_DP0 pid=378339) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=378339) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=378339) 	// begin inline asm
(EngineCore_DP0 pid=378339) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=378339) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=378339) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=378339) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=378339) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=378339) 	// end inline asm
(EngineCore_DP0 pid=378339) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=378339) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=378339) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=378339) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=378339) 	// begin inline asm
(EngineCore_DP0 pid=378339) 	mov.u32 %r49, %r45;
(EngineCore_DP0 pid=378339) 	mov.u32 %r50, %r45;
(EngineCore_DP0 pid=378339) 	mov.u32 %r51, %r45;
(EngineCore_DP0 pid=378339) 	mov.u32 %r52, %r45;
(EngineCore_DP0 pid=378339) 	@%p3 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=378339) 	// end inline asm
(EngineCore_DP0 pid=378339) 	mov.b32 	{%rs9, %rs10}, %r49;
(EngineCore_DP0 pid=378339) 	mov.b32 	{%rs11, %rs12}, %r50;
(EngineCore_DP0 pid=378339) 	mov.b32 	{%rs13, %rs14}, %r51;
(EngineCore_DP0 pid=378339) 	mov.b32 	{%rs15, %rs16}, %r52;
(EngineCore_DP0 pid=378339) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=378339) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=378339) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=378339) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=378339) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=378339) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=378339) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=378339) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=378339) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=378339) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=378339) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=378339) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=378339) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=378339) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=378339) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=378339) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=378339) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=378339) $L__tmp1:
(EngineCore_DP0 pid=378339) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	bar.sync 	0;
(EngineCore_DP0 pid=378339) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=378339) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=378339) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=378339) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=378339) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=378339) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=378339) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=378339) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=378339) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=378339) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=378339) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=378339) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=378339) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=378339) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=378339) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=378339) 	cvt.f32.bf16 	%r65, %rs47;
(EngineCore_DP0 pid=378339) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	shfl.sync.bfly.b32 	%r66, %r65, 16, 31, -1;
(EngineCore_DP0 pid=378339) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=378339) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	shfl.sync.bfly.b32 	%r68, %r67, 8, 31, -1;
(EngineCore_DP0 pid=378339) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=378339) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	shfl.sync.bfly.b32 	%r70, %r69, 4, 31, -1;
(EngineCore_DP0 pid=378339) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=378339) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	shfl.sync.bfly.b32 	%r72, %r71, 2, 31, -1;
(EngineCore_DP0 pid=378339) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=378339) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	shfl.sync.bfly.b32 	%r74, %r73, 1, 31, -1;
(EngineCore_DP0 pid=378339) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	max.f32 	%r58, %r73, %r74;
(EngineCore_DP0 pid=378339) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	// begin inline asm
(EngineCore_DP0 pid=378339) 	@%p4 st.shared.b32 [ %r57 + 0 ], %r58;
(EngineCore_DP0 pid=378339) 	// end inline asm
(EngineCore_DP0 pid=378339) 	bar.sync 	0;
(EngineCore_DP0 pid=378339) 	// begin inline asm
(EngineCore_DP0 pid=378339) 	@%p5 ld.shared.b32 %r59, [ %r60 + 0 ];
(EngineCore_DP0 pid=378339) 	// end inline asm
(EngineCore_DP0 pid=378339) 	shfl.sync.bfly.b32 	%r75, %r59, 8, 31, -1;
(EngineCore_DP0 pid=378339) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	max.f32 	%r76, %r59, %r75;
(EngineCore_DP0 pid=378339) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	shfl.sync.bfly.b32 	%r77, %r76, 4, 31, -1;
(EngineCore_DP0 pid=378339) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=378339) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	shfl.sync.bfly.b32 	%r79, %r78, 2, 31, -1;
(EngineCore_DP0 pid=378339) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	max.f32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=378339) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	shfl.sync.bfly.b32 	%r81, %r80, 1, 31, -1;
(EngineCore_DP0 pid=378339) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	max.f32 	%r62, %r80, %r81;
(EngineCore_DP0 pid=378339) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=378339) 	// begin inline asm
(EngineCore_DP0 pid=378339) 	@%p28 st.shared.b32 [ %r60 + 0 ], %r62;
(EngineCore_DP0 pid=378339) 	// end inline asm
(EngineCore_DP0 pid=378339) 	bar.sync 	0;
(EngineCore_DP0 pid=378339) 	ld.shared.b32 	%r82, [global_smem];
(EngineCore_DP0 pid=378339) $L__tmp2:
(EngineCore_DP0 pid=378339) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=378339) 	max.f32 	%r177, %r177, %r82;
(EngineCore_DP0 pid=378339) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=378339) 	add.s32 	%r178, %r178, 8192;
(EngineCore_DP0 pid=378339) 	setp.lt.s32 	%p7, %r178, %r24;
(EngineCore_DP0 pid=378339) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=378339) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=378339) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=378339) 	max.f32 	%r179, %r177, 0f2B8CBCCC;
(EngineCore_DP0 pid=378339) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=378339) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=378339) 	mov.b32 	%r84, 0f42FE0000;
(EngineCore_DP0 pid=378339) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=378339) 	div.full.f32 	%r85, %r179, %r84;
(EngineCore_DP0 pid=378339) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=378339) 	max.f32 	%r83, %r85, 0f37810204;
(EngineCore_DP0 pid=378339) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=378339) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=378339) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=378339) 	// begin inline asm
(EngineCore_DP0 pid=378339) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r83 };
(EngineCore_DP0 pid=378339) 	// end inline asm
(EngineCore_DP0 pid=378339) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=378339) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=378339) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=378339) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=378339) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=378339) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=378339) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=378339) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=378339) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=378339) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=378339) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=378339) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=378339) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=378339) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=378339) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=378339) 	div.full.f32 	%r14, %r84, %r179;
(EngineCore_DP0 pid=378339) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=378339) 	mov.b32 	%r180, 0;
(EngineCore_DP0 pid=378339) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=378339)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=378339) 	.loc	1 327 31                        // quant_slide_tuned_Llama3.2-3B.py:327:31
(EngineCore_DP0 pid=378339) 	add.s32 	%r89, %r16, %r180;
(EngineCore_DP0 pid=378339) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=378339) 	add.s32 	%r90, %r89, 1;
(EngineCore_DP0 pid=378339) 	setp.lt.s32 	%p18, %r89, %r15;
(EngineCore_DP0 pid=378339) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=378339) 	shr.s32 	%r91, %r89, 31;
(EngineCore_DP0 pid=378339) 	shr.u32 	%r92, %r91, 30;
(EngineCore_DP0 pid=378339) 	add.s32 	%r93, %r89, %r92;
(EngineCore_DP0 pid=378339) 	shr.s32 	%r94, %r93, 2;
(EngineCore_DP0 pid=378339) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=378339) 	shr.s32 	%r95, %r90, 31;
(EngineCore_DP0 pid=378339) 	shr.u32 	%r96, %r95, 30;
(EngineCore_DP0 pid=378339) 	add.s32 	%r97, %r90, %r96;
(EngineCore_DP0 pid=378339) 	and.b32 	%r98, %r97, 2147483644;
(EngineCore_DP0 pid=378339) 	sub.s32 	%r99, %r90, %r98;
(EngineCore_DP0 pid=378339) 	and.b32 	%r100, %r93, 2147483644;
(EngineCore_DP0 pid=378339) 	sub.s32 	%r101, %r89, %r100;
(EngineCore_DP0 pid=378339) 	.loc	1 333 22                        // quant_slide_tuned_Llama3.2-3B.py:333:22
(EngineCore_DP0 pid=378339) 	mul.lo.s32 	%r102, %r94, 10;
(EngineCore_DP0 pid=378339) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=378339) 	shl.b32 	%r103, %r101, 1;
(EngineCore_DP0 pid=378339) 	shl.b32 	%r104, %r99, 1;
(EngineCore_DP0 pid=378339) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=378339) 	add.s32 	%r105, %r102, %r104;
(EngineCore_DP0 pid=378339) 	add.s32 	%r106, %r102, %r103;
(EngineCore_DP0 pid=378339) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=378339) 	setp.lt.s32 	%p19, %r106, %r23;
(EngineCore_DP0 pid=378339) 	setp.lt.s32 	%p20, %r105, %r23;
(EngineCore_DP0 pid=378339) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=378339) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=378339) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=378339) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=378339) 	mad.wide.s32 	%rd9, %r106, 2, %rd1;
(EngineCore_DP0 pid=378339) 	mad.wide.s32 	%rd10, %r105, 2, %rd1;
(EngineCore_DP0 pid=378339) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=378339) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=378339) 	// begin inline asm
(EngineCore_DP0 pid=378339) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=378339) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=378339) 	// end inline asm
(EngineCore_DP0 pid=378339) 	// begin inline asm
(EngineCore_DP0 pid=378339) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=378339) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=378339) 	// end inline asm
(EngineCore_DP0 pid=378339) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=378339) 	cvt.f32.bf16 	%r107, %rs48;
(EngineCore_DP0 pid=378339) 	cvt.f32.bf16 	%r108, %rs50;
(EngineCore_DP0 pid=378339) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=378339) 	or.b32 	%r109, %r106, 1;
(EngineCore_DP0 pid=378339) 	or.b32 	%r110, %r105, 1;
(EngineCore_DP0 pid=378339) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=378339) 	setp.lt.s32 	%p21, %r109, %r23;
(EngineCore_DP0 pid=378339) 	setp.lt.s32 	%p22, %r110, %r23;
(EngineCore_DP0 pid=378339) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=378339) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=378339) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=378339) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=378339) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=378339) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=378339) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=378339) 	// begin inline asm
(EngineCore_DP0 pid=378339) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=378339) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=378339) 	// end inline asm
(EngineCore_DP0 pid=378339) 	// begin inline asm
(EngineCore_DP0 pid=378339) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=378339) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=378339) 	// end inline asm
(EngineCore_DP0 pid=378339) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=378339) 	cvt.f32.bf16 	%r111, %rs52;
(EngineCore_DP0 pid=378339) 	cvt.f32.bf16 	%r112, %rs54;
(EngineCore_DP0 pid=378339) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=378339) 	add.s32 	%r113, %r106, 2;
(EngineCore_DP0 pid=378339) 	add.s32 	%r114, %r105, 2;
(EngineCore_DP0 pid=378339) 	add.s32 	%r115, %r106, 3;
(EngineCore_DP0 pid=378339) 	add.s32 	%r116, %r105, 3;
(EngineCore_DP0 pid=378339) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=378339) 	setp.lt.s32 	%p23, %r116, %r23;
(EngineCore_DP0 pid=378339) 	setp.lt.s32 	%p24, %r115, %r23;
(EngineCore_DP0 pid=378339) 	setp.lt.s32 	%p25, %r114, %r23;
(EngineCore_DP0 pid=378339) 	setp.lt.s32 	%p26, %r113, %r23;
(EngineCore_DP0 pid=378339) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=378339) 	and.pred 	%p14, %p18, %p26;
(EngineCore_DP0 pid=378339) 	and.pred 	%p15, %p18, %p25;
(EngineCore_DP0 pid=378339) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=378339) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=378339) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=378339) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=378339) 	// begin inline asm
(EngineCore_DP0 pid=378339) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=378339) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=378339) 	// end inline asm
(EngineCore_DP0 pid=378339) 	// begin inline asm
(EngineCore_DP0 pid=378339) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=378339) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=378339) 	// end inline asm
(EngineCore_DP0 pid=378339) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=378339) 	cvt.f32.bf16 	%r117, %rs56;
(EngineCore_DP0 pid=378339) 	cvt.f32.bf16 	%r118, %rs58;
(EngineCore_DP0 pid=378339) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=378339) 	and.pred 	%p16, %p18, %p24;
(EngineCore_DP0 pid=378339) 	and.pred 	%p17, %p18, %p23;
(EngineCore_DP0 pid=378339) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=378339) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=378339) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=378339) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=378339) 	// begin inline asm
(EngineCore_DP0 pid=378339) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=378339) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=378339) 	// end inline asm
(EngineCore_DP0 pid=378339) 	// begin inline asm
(EngineCore_DP0 pid=378339) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=378339) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=378339) 	// end inline asm
(EngineCore_DP0 pid=378339) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=378339) 	cvt.f32.bf16 	%r119, %rs60;
(EngineCore_DP0 pid=378339) 	cvt.f32.bf16 	%r120, %rs62;
(EngineCore_DP0 pid=378339) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=378339) 	mul.f32 	%r121, %r14, %r107;
(EngineCore_DP0 pid=378339) 	mul.f32 	%r122, %r14, %r108;
(EngineCore_DP0 pid=378339) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=378339) 	cvt.rni.f32.f32 	%r123, %r121;
(EngineCore_DP0 pid=378339) 	cvt.rni.f32.f32 	%r124, %r122;
(EngineCore_DP0 pid=378339) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=378339) 	max.f32 	%r125, %r123, 0fC3000000;
(EngineCore_DP0 pid=378339) 	min.f32 	%r126, %r125, 0f42FE0000;
(EngineCore_DP0 pid=378339) 	max.f32 	%r127, %r124, 0fC3000000;
(EngineCore_DP0 pid=378339) 	min.f32 	%r128, %r127, 0f42FE0000;
(EngineCore_DP0 pid=378339) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=378339) 	cvt.rzi.s32.f32 	%r129, %r126;
(EngineCore_DP0 pid=378339) 	cvt.rzi.s32.f32 	%r130, %r128;
(EngineCore_DP0 pid=378339) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=378339) 	and.b32 	%r131, %r129, 255;
(EngineCore_DP0 pid=378339) 	and.b32 	%r132, %r130, 255;
(EngineCore_DP0 pid=378339) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=378339) 	mul.f32 	%r133, %r14, %r111;
(EngineCore_DP0 pid=378339) 	mul.f32 	%r134, %r14, %r112;
(EngineCore_DP0 pid=378339) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=378339) 	cvt.rni.f32.f32 	%r135, %r133;
(EngineCore_DP0 pid=378339) 	cvt.rni.f32.f32 	%r136, %r134;
(EngineCore_DP0 pid=378339) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=378339) 	mul.f32 	%r137, %r14, %r117;
(EngineCore_DP0 pid=378339) 	mul.f32 	%r138, %r14, %r118;
(EngineCore_DP0 pid=378339) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=378339) 	cvt.rni.f32.f32 	%r139, %r137;
(EngineCore_DP0 pid=378339) 	cvt.rni.f32.f32 	%r140, %r138;
(EngineCore_DP0 pid=378339) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=378339) 	mul.f32 	%r141, %r14, %r119;
(EngineCore_DP0 pid=378339) 	mul.f32 	%r142, %r14, %r120;
(EngineCore_DP0 pid=378339) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=378339) 	cvt.rni.f32.f32 	%r143, %r141;
(EngineCore_DP0 pid=378339) 	cvt.rni.f32.f32 	%r144, %r142;
(EngineCore_DP0 pid=378339) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=378339) 	max.f32 	%r145, %r143, 0fC3000000;
(EngineCore_DP0 pid=378339) 	min.f32 	%r146, %r145, 0f42FE0000;
(EngineCore_DP0 pid=378339) 	max.f32 	%r147, %r144, 0fC3000000;
(EngineCore_DP0 pid=378339) 	min.f32 	%r148, %r147, 0f42FE0000;
(EngineCore_DP0 pid=378339) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=378339) 	cvt.rzi.s32.f32 	%r149, %r146;
(EngineCore_DP0 pid=378339) 	cvt.rzi.s32.f32 	%r150, %r148;
(EngineCore_DP0 pid=378339) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=378339) 	max.f32 	%r151, %r139, 0fC3000000;
(EngineCore_DP0 pid=378339) 	max.f32 	%r152, %r135, 0fC3000000;
(EngineCore_DP0 pid=378339) 	min.f32 	%r153, %r152, 0f42FE0000;
(EngineCore_DP0 pid=378339) 	min.f32 	%r154, %r151, 0f42FE0000;
(EngineCore_DP0 pid=378339) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=378339) 	cvt.rzi.s32.f32 	%r155, %r154;
(EngineCore_DP0 pid=378339) 	cvt.rzi.s32.f32 	%r156, %r153;
(EngineCore_DP0 pid=378339) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=378339) 	shl.b32 	%r157, %r156, 8;
(EngineCore_DP0 pid=378339) 	shl.b32 	%r158, %r155, 16;
(EngineCore_DP0 pid=378339) 	and.b32 	%r159, %r158, 16711680;
(EngineCore_DP0 pid=378339) 	and.b32 	%r160, %r157, 65280;
(EngineCore_DP0 pid=378339) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=378339) 	or.b32 	%r161, %r160, %r131;
(EngineCore_DP0 pid=378339) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=378339) 	max.f32 	%r162, %r140, 0fC3000000;
(EngineCore_DP0 pid=378339) 	max.f32 	%r163, %r136, 0fC3000000;
(EngineCore_DP0 pid=378339) 	min.f32 	%r164, %r163, 0f42FE0000;
(EngineCore_DP0 pid=378339) 	min.f32 	%r165, %r162, 0f42FE0000;
(EngineCore_DP0 pid=378339) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=378339) 	cvt.rzi.s32.f32 	%r166, %r165;
(EngineCore_DP0 pid=378339) 	cvt.rzi.s32.f32 	%r167, %r164;
(EngineCore_DP0 pid=378339) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=378339) 	shl.b32 	%r168, %r167, 8;
(EngineCore_DP0 pid=378339) 	shl.b32 	%r169, %r166, 16;
(EngineCore_DP0 pid=378339) 	and.b32 	%r170, %r169, 16711680;
(EngineCore_DP0 pid=378339) 	and.b32 	%r171, %r168, 65280;
(EngineCore_DP0 pid=378339) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=378339) 	or.b32 	%r172, %r171, %r132;
(EngineCore_DP0 pid=378339) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=378339) 	or.b32 	%r173, %r161, %r159;
(EngineCore_DP0 pid=378339) 	or.b32 	%r174, %r172, %r170;
(EngineCore_DP0 pid=378339) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=378339) 	shl.b32 	%r175, %r149, 24;
(EngineCore_DP0 pid=378339) 	shl.b32 	%r176, %r150, 24;
(EngineCore_DP0 pid=378339) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=378339) 	or.b32 	%r87, %r173, %r175;
(EngineCore_DP0 pid=378339) 	or.b32 	%r88, %r174, %r176;
(EngineCore_DP0 pid=378339) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=378339) 	mad.wide.s32 	%rd17, %r89, 4, %rd2;
(EngineCore_DP0 pid=378339) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=378339) 	// begin inline asm
(EngineCore_DP0 pid=378339) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r87, %r88 };
(EngineCore_DP0 pid=378339) 	// end inline asm
(EngineCore_DP0 pid=378339) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=378339) 	add.s32 	%r180, %r180, 1024;
(EngineCore_DP0 pid=378339) 	setp.lt.s32 	%p27, %r180, %r15;
(EngineCore_DP0 pid=378339) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=378339) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=378339) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=378339) 	ret;
(EngineCore_DP0 pid=378339) $L__tmp3:
(EngineCore_DP0 pid=378339) $L__func_end0:
(EngineCore_DP0 pid=378339)                                         // -- End function
(EngineCore_DP0 pid=378339) }
(EngineCore_DP0 pid=378339) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=378339) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=378339) 	.section	.debug_abbrev
(EngineCore_DP0 pid=378339) 	{
(EngineCore_DP0 pid=378339) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=378339) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=378339) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=378339) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=378339) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=378339) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=378339) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=378339) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=378339) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=378339) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=378339) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=378339) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=378339) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=378339) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=378339) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=378339) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=378339) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=378339) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=378339) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=378339) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=378339) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=378339) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=378339) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=378339) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=378339) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=378339) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=378339) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=378339) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=378339) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=378339) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=378339) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=378339) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=378339) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=378339) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=378339) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=378339) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=378339) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=378339) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=378339) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=378339) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=378339) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=378339) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=378339) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=378339) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=378339) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=378339) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=378339) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=378339) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=378339) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=378339) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=378339) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=378339) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=378339) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=378339) 	}
(EngineCore_DP0 pid=378339) 	.section	.debug_info
(EngineCore_DP0 pid=378339) 	{
(EngineCore_DP0 pid=378339) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=378339) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=378339) .b8 0
(EngineCore_DP0 pid=378339) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=378339) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=378339) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=378339) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=378339) .b8 114
(EngineCore_DP0 pid=378339) .b8 105
(EngineCore_DP0 pid=378339) .b8 116
(EngineCore_DP0 pid=378339) .b8 111
(EngineCore_DP0 pid=378339) .b8 110
(EngineCore_DP0 pid=378339) .b8 0
(EngineCore_DP0 pid=378339) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=378339) .b8 0
(EngineCore_DP0 pid=378339) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=378339) .b8 117
(EngineCore_DP0 pid=378339) .b8 97
(EngineCore_DP0 pid=378339) .b8 110
(EngineCore_DP0 pid=378339) .b8 116
(EngineCore_DP0 pid=378339) .b8 95
(EngineCore_DP0 pid=378339) .b8 115
(EngineCore_DP0 pid=378339) .b8 108
(EngineCore_DP0 pid=378339) .b8 105
(EngineCore_DP0 pid=378339) .b8 100
(EngineCore_DP0 pid=378339) .b8 101
(EngineCore_DP0 pid=378339) .b8 95
(EngineCore_DP0 pid=378339) .b8 116
(EngineCore_DP0 pid=378339) .b8 117
(EngineCore_DP0 pid=378339) .b8 110
(EngineCore_DP0 pid=378339) .b8 101
(EngineCore_DP0 pid=378339) .b8 100
(EngineCore_DP0 pid=378339) .b8 95
(EngineCore_DP0 pid=378339) .b8 76
(EngineCore_DP0 pid=378339) .b8 108
(EngineCore_DP0 pid=378339) .b8 97
(EngineCore_DP0 pid=378339) .b8 109
(EngineCore_DP0 pid=378339) .b8 97
(EngineCore_DP0 pid=378339) .b8 51
(EngineCore_DP0 pid=378339) .b8 46
(EngineCore_DP0 pid=378339) .b8 50
(EngineCore_DP0 pid=378339) .b8 45
(EngineCore_DP0 pid=378339) .b8 51
(EngineCore_DP0 pid=378339) .b8 66
(EngineCore_DP0 pid=378339) .b8 46
(EngineCore_DP0 pid=378339) .b8 112
(EngineCore_DP0 pid=378339) .b8 121
(EngineCore_DP0 pid=378339) .b8 0
(EngineCore_DP0 pid=378339) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=378339) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=378339) .b8 114
(EngineCore_DP0 pid=378339) .b8 111
(EngineCore_DP0 pid=378339) .b8 111
(EngineCore_DP0 pid=378339) .b8 116
(EngineCore_DP0 pid=378339) .b8 47
(EngineCore_DP0 pid=378339) .b8 118
(EngineCore_DP0 pid=378339) .b8 108
(EngineCore_DP0 pid=378339) .b8 108
(EngineCore_DP0 pid=378339) .b8 109
(EngineCore_DP0 pid=378339) .b8 98
(EngineCore_DP0 pid=378339) .b8 101
(EngineCore_DP0 pid=378339) .b8 110
(EngineCore_DP0 pid=378339) .b8 99
(EngineCore_DP0 pid=378339) .b8 104
(EngineCore_DP0 pid=378339) .b8 47
(EngineCore_DP0 pid=378339) .b8 115
(EngineCore_DP0 pid=378339) .b8 108
(EngineCore_DP0 pid=378339) .b8 105
(EngineCore_DP0 pid=378339) .b8 100
(EngineCore_DP0 pid=378339) .b8 101
(EngineCore_DP0 pid=378339) .b8 115
(EngineCore_DP0 pid=378339) .b8 112
(EngineCore_DP0 pid=378339) .b8 97
(EngineCore_DP0 pid=378339) .b8 114
(EngineCore_DP0 pid=378339) .b8 115
(EngineCore_DP0 pid=378339) .b8 101
(EngineCore_DP0 pid=378339) .b8 47
(EngineCore_DP0 pid=378339) .b8 99
(EngineCore_DP0 pid=378339) .b8 115
(EngineCore_DP0 pid=378339) .b8 114
(EngineCore_DP0 pid=378339) .b8 99
(EngineCore_DP0 pid=378339) .b8 47
(EngineCore_DP0 pid=378339) .b8 102
(EngineCore_DP0 pid=378339) .b8 117
(EngineCore_DP0 pid=378339) .b8 115
(EngineCore_DP0 pid=378339) .b8 101
(EngineCore_DP0 pid=378339) .b8 100
(EngineCore_DP0 pid=378339) .b8 95
(EngineCore_DP0 pid=378339) .b8 113
(EngineCore_DP0 pid=378339) .b8 117
(EngineCore_DP0 pid=378339) .b8 97
(EngineCore_DP0 pid=378339) .b8 110
(EngineCore_DP0 pid=378339) .b8 116
(EngineCore_DP0 pid=378339) .b8 95
(EngineCore_DP0 pid=378339) .b8 115
(EngineCore_DP0 pid=378339) .b8 108
(EngineCore_DP0 pid=378339) .b8 105
(EngineCore_DP0 pid=378339) .b8 100
(EngineCore_DP0 pid=378339) .b8 101
(EngineCore_DP0 pid=378339) .b8 95
(EngineCore_DP0 pid=378339) .b8 116
(EngineCore_DP0 pid=378339) .b8 114
(EngineCore_DP0 pid=378339) .b8 105
(EngineCore_DP0 pid=378339) .b8 116
(EngineCore_DP0 pid=378339) .b8 111
(EngineCore_DP0 pid=378339) .b8 110
(EngineCore_DP0 pid=378339) .b8 47
(EngineCore_DP0 pid=378339) .b8 98
(EngineCore_DP0 pid=378339) .b8 117
(EngineCore_DP0 pid=378339) .b8 105
(EngineCore_DP0 pid=378339) .b8 108
(EngineCore_DP0 pid=378339) .b8 100
(EngineCore_DP0 pid=378339) .b8 47
(EngineCore_DP0 pid=378339) .b8 71
(EngineCore_DP0 pid=378339) .b8 66
(EngineCore_DP0 pid=378339) .b8 49
(EngineCore_DP0 pid=378339) .b8 48
(EngineCore_DP0 pid=378339) .b8 95
(EngineCore_DP0 pid=378339) .b8 99
(EngineCore_DP0 pid=378339) .b8 99
(EngineCore_DP0 pid=378339) .b8 49
(EngineCore_DP0 pid=378339) .b8 50
(EngineCore_DP0 pid=378339) .b8 49
(EngineCore_DP0 pid=378339) .b8 95
(EngineCore_DP0 pid=378339) .b8 112
(EngineCore_DP0 pid=378339) .b8 121
(EngineCore_DP0 pid=378339) .b8 51
(EngineCore_DP0 pid=378339) .b8 49
(EngineCore_DP0 pid=378339) .b8 50
(EngineCore_DP0 pid=378339) .b8 95
(EngineCore_DP0 pid=378339) .b8 99
(EngineCore_DP0 pid=378339) .b8 117
(EngineCore_DP0 pid=378339) .b8 49
(EngineCore_DP0 pid=378339) .b8 50
(EngineCore_DP0 pid=378339) .b8 57
(EngineCore_DP0 pid=378339) .b8 95
(EngineCore_DP0 pid=378339) .b8 97
(EngineCore_DP0 pid=378339) .b8 97
(EngineCore_DP0 pid=378339) .b8 114
(EngineCore_DP0 pid=378339) .b8 99
(EngineCore_DP0 pid=378339) .b8 104
(EngineCore_DP0 pid=378339) .b8 54
(EngineCore_DP0 pid=378339) .b8 52
(EngineCore_DP0 pid=378339) .b8 0
(EngineCore_DP0 pid=378339) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=378339) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=378339) .b8 113
(EngineCore_DP0 pid=378339) .b8 117
(EngineCore_DP0 pid=378339) .b8 97
(EngineCore_DP0 pid=378339) .b8 110
(EngineCore_DP0 pid=378339) .b8 116
(EngineCore_DP0 pid=378339) .b8 95
(EngineCore_DP0 pid=378339) .b8 115
(EngineCore_DP0 pid=378339) .b8 108
(EngineCore_DP0 pid=378339) .b8 105
(EngineCore_DP0 pid=378339) .b8 100
(EngineCore_DP0 pid=378339) .b8 101
(EngineCore_DP0 pid=378339) .b8 95
(EngineCore_DP0 pid=378339) .b8 105
(EngineCore_DP0 pid=378339) .b8 110
(EngineCore_DP0 pid=378339) .b8 116
(EngineCore_DP0 pid=378339) .b8 56
(EngineCore_DP0 pid=378339) .b8 95
(EngineCore_DP0 pid=378339) .b8 107
(EngineCore_DP0 pid=378339) .b8 101
(EngineCore_DP0 pid=378339) .b8 114
(EngineCore_DP0 pid=378339) .b8 110
(EngineCore_DP0 pid=378339) .b8 101
(EngineCore_DP0 pid=378339) .b8 108
(EngineCore_DP0 pid=378339) .b8 0
(EngineCore_DP0 pid=378339) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=378339) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=378339) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=378339) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=378339) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=378339) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=378339) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=378339) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=378339) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=378339) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=378339) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=378339) .b8 1
(EngineCore_DP0 pid=378339) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=378339) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=378339) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=378339) 	}
(EngineCore_DP0 pid=378339) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=378339) 
(EngineCore_DP0 pid=378339) ================================================================
(EngineCore_DP0 pid=378339) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=378339) 
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp7o9mi6zf.ptx', '-o', '/tmp/tmp7o9mi6zf.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866] 
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866] 
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866] 
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp7o9mi6zf.ptx -o /tmp/tmp7o9mi6zf.ptx.o
(EngineCore_DP0 pid=378339) ERROR 01-25 19:52:40 [core.py:866] 

STDERR:
[2026-01-25 19:52:04] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:52:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:52:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:52:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:52:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:52:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:52:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:52:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:52:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:52:07] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:52:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:52:07] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:52:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:52:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:52:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:52:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:52:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:52:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=378339) [2026-01-25 19:52:08] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=378339) [2026-01-25 19:52:08] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=378339) [2026-01-25 19:52:08] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=378339) [2026-01-25 19:52:08] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=378339) [2026-01-25 19:52:08] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=378339) [2026-01-25 19:52:08] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=378339) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=378339) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29<00:00, 29.38s/it]
(EngineCore_DP0 pid=378339) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29<00:00, 29.38s/it]
(EngineCore_DP0 pid=378339) 
(EngineCore_DP0 pid=378339) [2026-01-25 19:52:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=378339) [2026-01-25 19:52:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=378339) [2026-01-25 19:52:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=378339) [2026-01-25 19:52:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=378339) [2026-01-25 19:52:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=378339) [2026-01-25 19:52:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=378339) [2026-01-25 19:52:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=378339) [2026-01-25 19:52:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=378339) Process EngineCore_DP0:
(EngineCore_DP0 pid=378339) Traceback (most recent call last):
(EngineCore_DP0 pid=378339)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=378339)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=378339)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=378339)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=378339) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp7o9mi6zf.ptx', '-o', '/tmp/tmp7o9mi6zf.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=378339) 
(EngineCore_DP0 pid=378339) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=378339) 
(EngineCore_DP0 pid=378339) Traceback (most recent call last):
(EngineCore_DP0 pid=378339)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=378339)     self.run()
(EngineCore_DP0 pid=378339)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=378339)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=378339)     raise e
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=378339)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=378339)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=378339)     super().__init__(
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=378339)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=378339)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=378339)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=378339)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=378339)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=378339)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=378339)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=378339)     return func(*args, **kwargs)
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=378339)     return func(*args, **kwargs)
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=378339)     self.model_runner.profile_run()
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=378339)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=378339)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=378339)     return func(*args, **kwargs)
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=378339)     outputs = self.model(
(EngineCore_DP0 pid=378339)               ^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=378339)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=378339)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=378339)     model_output = self.model(
(EngineCore_DP0 pid=378339)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=378339)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=378339)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=378339)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=378339)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=378339)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=378339)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=378339)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=378339)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=378339)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=378339)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=378339)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=378339)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=378339)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=378339)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=378339)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=378339)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=378339)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=378339)     return self._linear_fn(
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=378339)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=378339)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=378339)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=378339)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=378339)     return fn(input, L)
(EngineCore_DP0 pid=378339)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=378339)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=378339)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=378339)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=378339)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=378339)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=378339)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=378339)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=378339)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=378339)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=378339)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=378339)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=378339)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=378339)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=378339)     raise PTXASError(error)
(EngineCore_DP0 pid=378339) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=378339) `ptxas` stderr:
(EngineCore_DP0 pid=378339) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=378339) 
(EngineCore_DP0 pid=378339) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp7o9mi6zf.ptx -o /tmp/tmp7o9mi6zf.ptx.o
(EngineCore_DP0 pid=378339) 
[rank0]:[W125 19:52:40.831371644 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 19:52:42
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:52:51 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:52:51 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=379187) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=379187) 
(EngineCore_DP0 pid=379187) 
(EngineCore_DP0 pid=379187) ================================================================
(EngineCore_DP0 pid=379187) Internal Triton PTX codegen error
(EngineCore_DP0 pid=379187) `ptxas` stderr:
(EngineCore_DP0 pid=379187) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=379187) 
(EngineCore_DP0 pid=379187) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpn82m9hzg.ptx -o /tmp/tmpn82m9hzg.ptx.o
(EngineCore_DP0 pid=379187) 
(EngineCore_DP0 pid=379187) 
(EngineCore_DP0 pid=379187) //
(EngineCore_DP0 pid=379187) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=379187) //
(EngineCore_DP0 pid=379187) 
(EngineCore_DP0 pid=379187) .version 8.7
(EngineCore_DP0 pid=379187) .target sm_121a
(EngineCore_DP0 pid=379187) .address_size 64
(EngineCore_DP0 pid=379187) 
(EngineCore_DP0 pid=379187) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=379187) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=379187)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=379187) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=379187) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=379187) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=379187) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=379187) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=379187) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=379187) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=379187) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=379187) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=379187) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=379187) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=379187) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=379187) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=379187) )
(EngineCore_DP0 pid=379187) .reqntid 512
(EngineCore_DP0 pid=379187) {
(EngineCore_DP0 pid=379187) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=379187) 	.reg .b16 	%rs<64>;
(EngineCore_DP0 pid=379187) 	.reg .b32 	%r<181>;
(EngineCore_DP0 pid=379187) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=379187) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=379187) $L__func_begin0:
(EngineCore_DP0 pid=379187) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=379187) 
(EngineCore_DP0 pid=379187) // %bb.0:
(EngineCore_DP0 pid=379187) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=379187) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=379187) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=379187) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=379187) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=379187) $L__tmp0:
(EngineCore_DP0 pid=379187) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=379187) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=379187) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=379187) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=379187) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=379187) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=379187) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=379187) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=379187) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=379187) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=379187) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=379187) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=379187) 	mov.b32 	%r179, 0f2B8CBCCC;
(EngineCore_DP0 pid=379187) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=379187) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=379187) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=379187) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=379187) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=379187) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=379187) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=379187) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=379187) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=379187) 	add.s32 	%r57, %r39, %r38;
(EngineCore_DP0 pid=379187) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=379187) 	add.s32 	%r60, %r39, %r40;
(EngineCore_DP0 pid=379187) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=379187) 	mov.b32 	%r177, 0f00000000;
(EngineCore_DP0 pid=379187) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=379187) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=379187) 	mov.b32 	%r178, %r45;
(EngineCore_DP0 pid=379187) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=379187) 	.loc	1 313 19                        // quant_slide_tuned_Llama3.2-3B.py:313:19
(EngineCore_DP0 pid=379187) 	add.s32 	%r63, %r4, %r178;
(EngineCore_DP0 pid=379187) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=379187) 	add.s32 	%r64, %r63, 4096;
(EngineCore_DP0 pid=379187) 	setp.lt.s32 	%p2, %r63, %r23;
(EngineCore_DP0 pid=379187) 	setp.lt.s32 	%p3, %r64, %r23;
(EngineCore_DP0 pid=379187) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=379187) 	mad.wide.s32 	%rd6, %r63, 2, %rd1;
(EngineCore_DP0 pid=379187) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=379187) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=379187) 	// begin inline asm
(EngineCore_DP0 pid=379187) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=379187) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=379187) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=379187) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=379187) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=379187) 	// end inline asm
(EngineCore_DP0 pid=379187) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=379187) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=379187) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=379187) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=379187) 	// begin inline asm
(EngineCore_DP0 pid=379187) 	mov.u32 %r49, %r45;
(EngineCore_DP0 pid=379187) 	mov.u32 %r50, %r45;
(EngineCore_DP0 pid=379187) 	mov.u32 %r51, %r45;
(EngineCore_DP0 pid=379187) 	mov.u32 %r52, %r45;
(EngineCore_DP0 pid=379187) 	@%p3 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=379187) 	// end inline asm
(EngineCore_DP0 pid=379187) 	mov.b32 	{%rs9, %rs10}, %r49;
(EngineCore_DP0 pid=379187) 	mov.b32 	{%rs11, %rs12}, %r50;
(EngineCore_DP0 pid=379187) 	mov.b32 	{%rs13, %rs14}, %r51;
(EngineCore_DP0 pid=379187) 	mov.b32 	{%rs15, %rs16}, %r52;
(EngineCore_DP0 pid=379187) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=379187) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=379187) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=379187) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=379187) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=379187) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=379187) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=379187) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=379187) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=379187) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=379187) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=379187) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=379187) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=379187) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=379187) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=379187) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=379187) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=379187) $L__tmp1:
(EngineCore_DP0 pid=379187) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	bar.sync 	0;
(EngineCore_DP0 pid=379187) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=379187) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=379187) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=379187) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=379187) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=379187) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=379187) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=379187) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=379187) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=379187) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=379187) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=379187) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=379187) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=379187) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=379187) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=379187) 	cvt.f32.bf16 	%r65, %rs47;
(EngineCore_DP0 pid=379187) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	shfl.sync.bfly.b32 	%r66, %r65, 16, 31, -1;
(EngineCore_DP0 pid=379187) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=379187) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	shfl.sync.bfly.b32 	%r68, %r67, 8, 31, -1;
(EngineCore_DP0 pid=379187) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=379187) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	shfl.sync.bfly.b32 	%r70, %r69, 4, 31, -1;
(EngineCore_DP0 pid=379187) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=379187) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	shfl.sync.bfly.b32 	%r72, %r71, 2, 31, -1;
(EngineCore_DP0 pid=379187) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=379187) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	shfl.sync.bfly.b32 	%r74, %r73, 1, 31, -1;
(EngineCore_DP0 pid=379187) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	max.f32 	%r58, %r73, %r74;
(EngineCore_DP0 pid=379187) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	// begin inline asm
(EngineCore_DP0 pid=379187) 	@%p4 st.shared.b32 [ %r57 + 0 ], %r58;
(EngineCore_DP0 pid=379187) 	// end inline asm
(EngineCore_DP0 pid=379187) 	bar.sync 	0;
(EngineCore_DP0 pid=379187) 	// begin inline asm
(EngineCore_DP0 pid=379187) 	@%p5 ld.shared.b32 %r59, [ %r60 + 0 ];
(EngineCore_DP0 pid=379187) 	// end inline asm
(EngineCore_DP0 pid=379187) 	shfl.sync.bfly.b32 	%r75, %r59, 8, 31, -1;
(EngineCore_DP0 pid=379187) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	max.f32 	%r76, %r59, %r75;
(EngineCore_DP0 pid=379187) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	shfl.sync.bfly.b32 	%r77, %r76, 4, 31, -1;
(EngineCore_DP0 pid=379187) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=379187) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	shfl.sync.bfly.b32 	%r79, %r78, 2, 31, -1;
(EngineCore_DP0 pid=379187) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	max.f32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=379187) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	shfl.sync.bfly.b32 	%r81, %r80, 1, 31, -1;
(EngineCore_DP0 pid=379187) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	max.f32 	%r62, %r80, %r81;
(EngineCore_DP0 pid=379187) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=379187) 	// begin inline asm
(EngineCore_DP0 pid=379187) 	@%p28 st.shared.b32 [ %r60 + 0 ], %r62;
(EngineCore_DP0 pid=379187) 	// end inline asm
(EngineCore_DP0 pid=379187) 	bar.sync 	0;
(EngineCore_DP0 pid=379187) 	ld.shared.b32 	%r82, [global_smem];
(EngineCore_DP0 pid=379187) $L__tmp2:
(EngineCore_DP0 pid=379187) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=379187) 	max.f32 	%r177, %r177, %r82;
(EngineCore_DP0 pid=379187) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=379187) 	add.s32 	%r178, %r178, 8192;
(EngineCore_DP0 pid=379187) 	setp.lt.s32 	%p7, %r178, %r24;
(EngineCore_DP0 pid=379187) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=379187) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=379187) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=379187) 	max.f32 	%r179, %r177, 0f2B8CBCCC;
(EngineCore_DP0 pid=379187) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=379187) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=379187) 	mov.b32 	%r84, 0f42FE0000;
(EngineCore_DP0 pid=379187) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=379187) 	div.full.f32 	%r85, %r179, %r84;
(EngineCore_DP0 pid=379187) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=379187) 	max.f32 	%r83, %r85, 0f37810204;
(EngineCore_DP0 pid=379187) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=379187) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=379187) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=379187) 	// begin inline asm
(EngineCore_DP0 pid=379187) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r83 };
(EngineCore_DP0 pid=379187) 	// end inline asm
(EngineCore_DP0 pid=379187) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=379187) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=379187) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=379187) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=379187) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=379187) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=379187) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=379187) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=379187) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=379187) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=379187) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=379187) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=379187) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=379187) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=379187) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=379187) 	div.full.f32 	%r14, %r84, %r179;
(EngineCore_DP0 pid=379187) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=379187) 	mov.b32 	%r180, 0;
(EngineCore_DP0 pid=379187) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=379187)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=379187) 	.loc	1 327 31                        // quant_slide_tuned_Llama3.2-3B.py:327:31
(EngineCore_DP0 pid=379187) 	add.s32 	%r89, %r16, %r180;
(EngineCore_DP0 pid=379187) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=379187) 	add.s32 	%r90, %r89, 1;
(EngineCore_DP0 pid=379187) 	setp.lt.s32 	%p18, %r89, %r15;
(EngineCore_DP0 pid=379187) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=379187) 	shr.s32 	%r91, %r89, 31;
(EngineCore_DP0 pid=379187) 	shr.u32 	%r92, %r91, 30;
(EngineCore_DP0 pid=379187) 	add.s32 	%r93, %r89, %r92;
(EngineCore_DP0 pid=379187) 	shr.s32 	%r94, %r93, 2;
(EngineCore_DP0 pid=379187) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=379187) 	shr.s32 	%r95, %r90, 31;
(EngineCore_DP0 pid=379187) 	shr.u32 	%r96, %r95, 30;
(EngineCore_DP0 pid=379187) 	add.s32 	%r97, %r90, %r96;
(EngineCore_DP0 pid=379187) 	and.b32 	%r98, %r97, 2147483644;
(EngineCore_DP0 pid=379187) 	sub.s32 	%r99, %r90, %r98;
(EngineCore_DP0 pid=379187) 	and.b32 	%r100, %r93, 2147483644;
(EngineCore_DP0 pid=379187) 	sub.s32 	%r101, %r89, %r100;
(EngineCore_DP0 pid=379187) 	.loc	1 333 22                        // quant_slide_tuned_Llama3.2-3B.py:333:22
(EngineCore_DP0 pid=379187) 	mul.lo.s32 	%r102, %r94, 10;
(EngineCore_DP0 pid=379187) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=379187) 	shl.b32 	%r103, %r101, 1;
(EngineCore_DP0 pid=379187) 	shl.b32 	%r104, %r99, 1;
(EngineCore_DP0 pid=379187) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=379187) 	add.s32 	%r105, %r102, %r104;
(EngineCore_DP0 pid=379187) 	add.s32 	%r106, %r102, %r103;
(EngineCore_DP0 pid=379187) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=379187) 	setp.lt.s32 	%p19, %r106, %r23;
(EngineCore_DP0 pid=379187) 	setp.lt.s32 	%p20, %r105, %r23;
(EngineCore_DP0 pid=379187) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=379187) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=379187) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=379187) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=379187) 	mad.wide.s32 	%rd9, %r106, 2, %rd1;
(EngineCore_DP0 pid=379187) 	mad.wide.s32 	%rd10, %r105, 2, %rd1;
(EngineCore_DP0 pid=379187) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=379187) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=379187) 	// begin inline asm
(EngineCore_DP0 pid=379187) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=379187) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=379187) 	// end inline asm
(EngineCore_DP0 pid=379187) 	// begin inline asm
(EngineCore_DP0 pid=379187) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=379187) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=379187) 	// end inline asm
(EngineCore_DP0 pid=379187) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=379187) 	cvt.f32.bf16 	%r107, %rs48;
(EngineCore_DP0 pid=379187) 	cvt.f32.bf16 	%r108, %rs50;
(EngineCore_DP0 pid=379187) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=379187) 	or.b32 	%r109, %r106, 1;
(EngineCore_DP0 pid=379187) 	or.b32 	%r110, %r105, 1;
(EngineCore_DP0 pid=379187) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=379187) 	setp.lt.s32 	%p21, %r109, %r23;
(EngineCore_DP0 pid=379187) 	setp.lt.s32 	%p22, %r110, %r23;
(EngineCore_DP0 pid=379187) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=379187) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=379187) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=379187) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=379187) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=379187) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=379187) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=379187) 	// begin inline asm
(EngineCore_DP0 pid=379187) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=379187) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=379187) 	// end inline asm
(EngineCore_DP0 pid=379187) 	// begin inline asm
(EngineCore_DP0 pid=379187) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=379187) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=379187) 	// end inline asm
(EngineCore_DP0 pid=379187) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=379187) 	cvt.f32.bf16 	%r111, %rs52;
(EngineCore_DP0 pid=379187) 	cvt.f32.bf16 	%r112, %rs54;
(EngineCore_DP0 pid=379187) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=379187) 	add.s32 	%r113, %r106, 2;
(EngineCore_DP0 pid=379187) 	add.s32 	%r114, %r105, 2;
(EngineCore_DP0 pid=379187) 	add.s32 	%r115, %r106, 3;
(EngineCore_DP0 pid=379187) 	add.s32 	%r116, %r105, 3;
(EngineCore_DP0 pid=379187) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=379187) 	setp.lt.s32 	%p23, %r116, %r23;
(EngineCore_DP0 pid=379187) 	setp.lt.s32 	%p24, %r115, %r23;
(EngineCore_DP0 pid=379187) 	setp.lt.s32 	%p25, %r114, %r23;
(EngineCore_DP0 pid=379187) 	setp.lt.s32 	%p26, %r113, %r23;
(EngineCore_DP0 pid=379187) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=379187) 	and.pred 	%p14, %p18, %p26;
(EngineCore_DP0 pid=379187) 	and.pred 	%p15, %p18, %p25;
(EngineCore_DP0 pid=379187) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=379187) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=379187) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=379187) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=379187) 	// begin inline asm
(EngineCore_DP0 pid=379187) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=379187) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=379187) 	// end inline asm
(EngineCore_DP0 pid=379187) 	// begin inline asm
(EngineCore_DP0 pid=379187) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=379187) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=379187) 	// end inline asm
(EngineCore_DP0 pid=379187) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=379187) 	cvt.f32.bf16 	%r117, %rs56;
(EngineCore_DP0 pid=379187) 	cvt.f32.bf16 	%r118, %rs58;
(EngineCore_DP0 pid=379187) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=379187) 	and.pred 	%p16, %p18, %p24;
(EngineCore_DP0 pid=379187) 	and.pred 	%p17, %p18, %p23;
(EngineCore_DP0 pid=379187) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=379187) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=379187) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=379187) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=379187) 	// begin inline asm
(EngineCore_DP0 pid=379187) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=379187) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=379187) 	// end inline asm
(EngineCore_DP0 pid=379187) 	// begin inline asm
(EngineCore_DP0 pid=379187) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=379187) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=379187) 	// end inline asm
(EngineCore_DP0 pid=379187) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=379187) 	cvt.f32.bf16 	%r119, %rs60;
(EngineCore_DP0 pid=379187) 	cvt.f32.bf16 	%r120, %rs62;
(EngineCore_DP0 pid=379187) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=379187) 	mul.f32 	%r121, %r14, %r107;
(EngineCore_DP0 pid=379187) 	mul.f32 	%r122, %r14, %r108;
(EngineCore_DP0 pid=379187) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=379187) 	cvt.rni.f32.f32 	%r123, %r121;
(EngineCore_DP0 pid=379187) 	cvt.rni.f32.f32 	%r124, %r122;
(EngineCore_DP0 pid=379187) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=379187) 	max.f32 	%r125, %r123, 0fC3000000;
(EngineCore_DP0 pid=379187) 	min.f32 	%r126, %r125, 0f42FE0000;
(EngineCore_DP0 pid=379187) 	max.f32 	%r127, %r124, 0fC3000000;
(EngineCore_DP0 pid=379187) 	min.f32 	%r128, %r127, 0f42FE0000;
(EngineCore_DP0 pid=379187) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=379187) 	cvt.rzi.s32.f32 	%r129, %r126;
(EngineCore_DP0 pid=379187) 	cvt.rzi.s32.f32 	%r130, %r128;
(EngineCore_DP0 pid=379187) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=379187) 	and.b32 	%r131, %r129, 255;
(EngineCore_DP0 pid=379187) 	and.b32 	%r132, %r130, 255;
(EngineCore_DP0 pid=379187) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=379187) 	mul.f32 	%r133, %r14, %r111;
(EngineCore_DP0 pid=379187) 	mul.f32 	%r134, %r14, %r112;
(EngineCore_DP0 pid=379187) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=379187) 	cvt.rni.f32.f32 	%r135, %r133;
(EngineCore_DP0 pid=379187) 	cvt.rni.f32.f32 	%r136, %r134;
(EngineCore_DP0 pid=379187) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=379187) 	mul.f32 	%r137, %r14, %r117;
(EngineCore_DP0 pid=379187) 	mul.f32 	%r138, %r14, %r118;
(EngineCore_DP0 pid=379187) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=379187) 	cvt.rni.f32.f32 	%r139, %r137;
(EngineCore_DP0 pid=379187) 	cvt.rni.f32.f32 	%r140, %r138;
(EngineCore_DP0 pid=379187) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=379187) 	mul.f32 	%r141, %r14, %r119;
(EngineCore_DP0 pid=379187) 	mul.f32 	%r142, %r14, %r120;
(EngineCore_DP0 pid=379187) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=379187) 	cvt.rni.f32.f32 	%r143, %r141;
(EngineCore_DP0 pid=379187) 	cvt.rni.f32.f32 	%r144, %r142;
(EngineCore_DP0 pid=379187) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=379187) 	max.f32 	%r145, %r143, 0fC3000000;
(EngineCore_DP0 pid=379187) 	min.f32 	%r146, %r145, 0f42FE0000;
(EngineCore_DP0 pid=379187) 	max.f32 	%r147, %r144, 0fC3000000;
(EngineCore_DP0 pid=379187) 	min.f32 	%r148, %r147, 0f42FE0000;
(EngineCore_DP0 pid=379187) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=379187) 	cvt.rzi.s32.f32 	%r149, %r146;
(EngineCore_DP0 pid=379187) 	cvt.rzi.s32.f32 	%r150, %r148;
(EngineCore_DP0 pid=379187) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=379187) 	max.f32 	%r151, %r139, 0fC3000000;
(EngineCore_DP0 pid=379187) 	max.f32 	%r152, %r135, 0fC3000000;
(EngineCore_DP0 pid=379187) 	min.f32 	%r153, %r152, 0f42FE0000;
(EngineCore_DP0 pid=379187) 	min.f32 	%r154, %r151, 0f42FE0000;
(EngineCore_DP0 pid=379187) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=379187) 	cvt.rzi.s32.f32 	%r155, %r154;
(EngineCore_DP0 pid=379187) 	cvt.rzi.s32.f32 	%r156, %r153;
(EngineCore_DP0 pid=379187) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=379187) 	shl.b32 	%r157, %r156, 8;
(EngineCore_DP0 pid=379187) 	shl.b32 	%r158, %r155, 16;
(EngineCore_DP0 pid=379187) 	and.b32 	%r159, %r158, 16711680;
(EngineCore_DP0 pid=379187) 	and.b32 	%r160, %r157, 65280;
(EngineCore_DP0 pid=379187) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=379187) 	or.b32 	%r161, %r160, %r131;
(EngineCore_DP0 pid=379187) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=379187) 	max.f32 	%r162, %r140, 0fC3000000;
(EngineCore_DP0 pid=379187) 	max.f32 	%r163, %r136, 0fC3000000;
(EngineCore_DP0 pid=379187) 	min.f32 	%r164, %r163, 0f42FE0000;
(EngineCore_DP0 pid=379187) 	min.f32 	%r165, %r162, 0f42FE0000;
(EngineCore_DP0 pid=379187) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=379187) 	cvt.rzi.s32.f32 	%r166, %r165;
(EngineCore_DP0 pid=379187) 	cvt.rzi.s32.f32 	%r167, %r164;
(EngineCore_DP0 pid=379187) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=379187) 	shl.b32 	%r168, %r167, 8;
(EngineCore_DP0 pid=379187) 	shl.b32 	%r169, %r166, 16;
(EngineCore_DP0 pid=379187) 	and.b32 	%r170, %r169, 16711680;
(EngineCore_DP0 pid=379187) 	and.b32 	%r171, %r168, 65280;
(EngineCore_DP0 pid=379187) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=379187) 	or.b32 	%r172, %r171, %r132;
(EngineCore_DP0 pid=379187) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=379187) 	or.b32 	%r173, %r161, %r159;
(EngineCore_DP0 pid=379187) 	or.b32 	%r174, %r172, %r170;
(EngineCore_DP0 pid=379187) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=379187) 	shl.b32 	%r175, %r149, 24;
(EngineCore_DP0 pid=379187) 	shl.b32 	%r176, %r150, 24;
(EngineCore_DP0 pid=379187) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=379187) 	or.b32 	%r87, %r173, %r175;
(EngineCore_DP0 pid=379187) 	or.b32 	%r88, %r174, %r176;
(EngineCore_DP0 pid=379187) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=379187) 	mad.wide.s32 	%rd17, %r89, 4, %rd2;
(EngineCore_DP0 pid=379187) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=379187) 	// begin inline asm
(EngineCore_DP0 pid=379187) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r87, %r88 };
(EngineCore_DP0 pid=379187) 	// end inline asm
(EngineCore_DP0 pid=379187) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=379187) 	add.s32 	%r180, %r180, 1024;
(EngineCore_DP0 pid=379187) 	setp.lt.s32 	%p27, %r180, %r15;
(EngineCore_DP0 pid=379187) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=379187) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=379187) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=379187) 	ret;
(EngineCore_DP0 pid=379187) $L__tmp3:
(EngineCore_DP0 pid=379187) $L__func_end0:
(EngineCore_DP0 pid=379187)                                         // -- End function
(EngineCore_DP0 pid=379187) }
(EngineCore_DP0 pid=379187) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=379187) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=379187) 	.section	.debug_abbrev
(EngineCore_DP0 pid=379187) 	{
(EngineCore_DP0 pid=379187) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=379187) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=379187) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=379187) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=379187) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=379187) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=379187) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=379187) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=379187) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=379187) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=379187) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=379187) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=379187) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=379187) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=379187) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=379187) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=379187) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=379187) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=379187) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=379187) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=379187) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=379187) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=379187) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=379187) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=379187) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=379187) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=379187) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=379187) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=379187) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=379187) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=379187) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=379187) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=379187) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=379187) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=379187) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=379187) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=379187) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=379187) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=379187) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=379187) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=379187) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=379187) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=379187) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=379187) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=379187) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=379187) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=379187) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=379187) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=379187) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=379187) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=379187) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=379187) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=379187) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=379187) 	}
(EngineCore_DP0 pid=379187) 	.section	.debug_info
(EngineCore_DP0 pid=379187) 	{
(EngineCore_DP0 pid=379187) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=379187) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=379187) .b8 0
(EngineCore_DP0 pid=379187) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=379187) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=379187) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=379187) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=379187) .b8 114
(EngineCore_DP0 pid=379187) .b8 105
(EngineCore_DP0 pid=379187) .b8 116
(EngineCore_DP0 pid=379187) .b8 111
(EngineCore_DP0 pid=379187) .b8 110
(EngineCore_DP0 pid=379187) .b8 0
(EngineCore_DP0 pid=379187) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=379187) .b8 0
(EngineCore_DP0 pid=379187) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=379187) .b8 117
(EngineCore_DP0 pid=379187) .b8 97
(EngineCore_DP0 pid=379187) .b8 110
(EngineCore_DP0 pid=379187) .b8 116
(EngineCore_DP0 pid=379187) .b8 95
(EngineCore_DP0 pid=379187) .b8 115
(EngineCore_DP0 pid=379187) .b8 108
(EngineCore_DP0 pid=379187) .b8 105
(EngineCore_DP0 pid=379187) .b8 100
(EngineCore_DP0 pid=379187) .b8 101
(EngineCore_DP0 pid=379187) .b8 95
(EngineCore_DP0 pid=379187) .b8 116
(EngineCore_DP0 pid=379187) .b8 117
(EngineCore_DP0 pid=379187) .b8 110
(EngineCore_DP0 pid=379187) .b8 101
(EngineCore_DP0 pid=379187) .b8 100
(EngineCore_DP0 pid=379187) .b8 95
(EngineCore_DP0 pid=379187) .b8 76
(EngineCore_DP0 pid=379187) .b8 108
(EngineCore_DP0 pid=379187) .b8 97
(EngineCore_DP0 pid=379187) .b8 109
(EngineCore_DP0 pid=379187) .b8 97
(EngineCore_DP0 pid=379187) .b8 51
(EngineCore_DP0 pid=379187) .b8 46
(EngineCore_DP0 pid=379187) .b8 50
(EngineCore_DP0 pid=379187) .b8 45
(EngineCore_DP0 pid=379187) .b8 51
(EngineCore_DP0 pid=379187) .b8 66
(EngineCore_DP0 pid=379187) .b8 46
(EngineCore_DP0 pid=379187) .b8 112
(EngineCore_DP0 pid=379187) .b8 121
(EngineCore_DP0 pid=379187) .b8 0
(EngineCore_DP0 pid=379187) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=379187) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=379187) .b8 114
(EngineCore_DP0 pid=379187) .b8 111
(EngineCore_DP0 pid=379187) .b8 111
(EngineCore_DP0 pid=379187) .b8 116
(EngineCore_DP0 pid=379187) .b8 47
(EngineCore_DP0 pid=379187) .b8 118
(EngineCore_DP0 pid=379187) .b8 108
(EngineCore_DP0 pid=379187) .b8 108
(EngineCore_DP0 pid=379187) .b8 109
(EngineCore_DP0 pid=379187) .b8 98
(EngineCore_DP0 pid=379187) .b8 101
(EngineCore_DP0 pid=379187) .b8 110
(EngineCore_DP0 pid=379187) .b8 99
(EngineCore_DP0 pid=379187) .b8 104
(EngineCore_DP0 pid=379187) .b8 47
(EngineCore_DP0 pid=379187) .b8 115
(EngineCore_DP0 pid=379187) .b8 108
(EngineCore_DP0 pid=379187) .b8 105
(EngineCore_DP0 pid=379187) .b8 100
(EngineCore_DP0 pid=379187) .b8 101
(EngineCore_DP0 pid=379187) .b8 115
(EngineCore_DP0 pid=379187) .b8 112
(EngineCore_DP0 pid=379187) .b8 97
(EngineCore_DP0 pid=379187) .b8 114
(EngineCore_DP0 pid=379187) .b8 115
(EngineCore_DP0 pid=379187) .b8 101
(EngineCore_DP0 pid=379187) .b8 47
(EngineCore_DP0 pid=379187) .b8 99
(EngineCore_DP0 pid=379187) .b8 115
(EngineCore_DP0 pid=379187) .b8 114
(EngineCore_DP0 pid=379187) .b8 99
(EngineCore_DP0 pid=379187) .b8 47
(EngineCore_DP0 pid=379187) .b8 102
(EngineCore_DP0 pid=379187) .b8 117
(EngineCore_DP0 pid=379187) .b8 115
(EngineCore_DP0 pid=379187) .b8 101
(EngineCore_DP0 pid=379187) .b8 100
(EngineCore_DP0 pid=379187) .b8 95
(EngineCore_DP0 pid=379187) .b8 113
(EngineCore_DP0 pid=379187) .b8 117
(EngineCore_DP0 pid=379187) .b8 97
(EngineCore_DP0 pid=379187) .b8 110
(EngineCore_DP0 pid=379187) .b8 116
(EngineCore_DP0 pid=379187) .b8 95
(EngineCore_DP0 pid=379187) .b8 115
(EngineCore_DP0 pid=379187) .b8 108
(EngineCore_DP0 pid=379187) .b8 105
(EngineCore_DP0 pid=379187) .b8 100
(EngineCore_DP0 pid=379187) .b8 101
(EngineCore_DP0 pid=379187) .b8 95
(EngineCore_DP0 pid=379187) .b8 116
(EngineCore_DP0 pid=379187) .b8 114
(EngineCore_DP0 pid=379187) .b8 105
(EngineCore_DP0 pid=379187) .b8 116
(EngineCore_DP0 pid=379187) .b8 111
(EngineCore_DP0 pid=379187) .b8 110
(EngineCore_DP0 pid=379187) .b8 47
(EngineCore_DP0 pid=379187) .b8 98
(EngineCore_DP0 pid=379187) .b8 117
(EngineCore_DP0 pid=379187) .b8 105
(EngineCore_DP0 pid=379187) .b8 108
(EngineCore_DP0 pid=379187) .b8 100
(EngineCore_DP0 pid=379187) .b8 47
(EngineCore_DP0 pid=379187) .b8 71
(EngineCore_DP0 pid=379187) .b8 66
(EngineCore_DP0 pid=379187) .b8 49
(EngineCore_DP0 pid=379187) .b8 48
(EngineCore_DP0 pid=379187) .b8 95
(EngineCore_DP0 pid=379187) .b8 99
(EngineCore_DP0 pid=379187) .b8 99
(EngineCore_DP0 pid=379187) .b8 49
(EngineCore_DP0 pid=379187) .b8 50
(EngineCore_DP0 pid=379187) .b8 49
(EngineCore_DP0 pid=379187) .b8 95
(EngineCore_DP0 pid=379187) .b8 112
(EngineCore_DP0 pid=379187) .b8 121
(EngineCore_DP0 pid=379187) .b8 51
(EngineCore_DP0 pid=379187) .b8 49
(EngineCore_DP0 pid=379187) .b8 50
(EngineCore_DP0 pid=379187) .b8 95
(EngineCore_DP0 pid=379187) .b8 99
(EngineCore_DP0 pid=379187) .b8 117
(EngineCore_DP0 pid=379187) .b8 49
(EngineCore_DP0 pid=379187) .b8 50
(EngineCore_DP0 pid=379187) .b8 57
(EngineCore_DP0 pid=379187) .b8 95
(EngineCore_DP0 pid=379187) .b8 97
(EngineCore_DP0 pid=379187) .b8 97
(EngineCore_DP0 pid=379187) .b8 114
(EngineCore_DP0 pid=379187) .b8 99
(EngineCore_DP0 pid=379187) .b8 104
(EngineCore_DP0 pid=379187) .b8 54
(EngineCore_DP0 pid=379187) .b8 52
(EngineCore_DP0 pid=379187) .b8 0
(EngineCore_DP0 pid=379187) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=379187) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=379187) .b8 113
(EngineCore_DP0 pid=379187) .b8 117
(EngineCore_DP0 pid=379187) .b8 97
(EngineCore_DP0 pid=379187) .b8 110
(EngineCore_DP0 pid=379187) .b8 116
(EngineCore_DP0 pid=379187) .b8 95
(EngineCore_DP0 pid=379187) .b8 115
(EngineCore_DP0 pid=379187) .b8 108
(EngineCore_DP0 pid=379187) .b8 105
(EngineCore_DP0 pid=379187) .b8 100
(EngineCore_DP0 pid=379187) .b8 101
(EngineCore_DP0 pid=379187) .b8 95
(EngineCore_DP0 pid=379187) .b8 105
(EngineCore_DP0 pid=379187) .b8 110
(EngineCore_DP0 pid=379187) .b8 116
(EngineCore_DP0 pid=379187) .b8 56
(EngineCore_DP0 pid=379187) .b8 95
(EngineCore_DP0 pid=379187) .b8 107
(EngineCore_DP0 pid=379187) .b8 101
(EngineCore_DP0 pid=379187) .b8 114
(EngineCore_DP0 pid=379187) .b8 110
(EngineCore_DP0 pid=379187) .b8 101
(EngineCore_DP0 pid=379187) .b8 108
(EngineCore_DP0 pid=379187) .b8 0
(EngineCore_DP0 pid=379187) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=379187) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=379187) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=379187) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=379187) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=379187) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=379187) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=379187) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=379187) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=379187) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=379187) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=379187) .b8 1
(EngineCore_DP0 pid=379187) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=379187) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=379187) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=379187) 	}
(EngineCore_DP0 pid=379187) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=379187) 
(EngineCore_DP0 pid=379187) ================================================================
(EngineCore_DP0 pid=379187) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=379187) 
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpn82m9hzg.ptx', '-o', '/tmp/tmpn82m9hzg.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866] 
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866] 
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866] 
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpn82m9hzg.ptx -o /tmp/tmpn82m9hzg.ptx.o
(EngineCore_DP0 pid=379187) ERROR 01-25 19:53:27 [core.py:866] 

STDERR:
[2026-01-25 19:52:51] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:52:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:52:51] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:52:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:52:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:52:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:52:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:52:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:52:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:52:54] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:52:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:52:54] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:52:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:52:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:52:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:52:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:52:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:52:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:52:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=379187) [2026-01-25 19:52:55] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=379187) [2026-01-25 19:52:55] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=379187) [2026-01-25 19:52:55] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=379187) [2026-01-25 19:52:55] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=379187) [2026-01-25 19:52:55] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=379187) [2026-01-25 19:52:55] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=379187) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=379187) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29<00:00, 29.20s/it]
(EngineCore_DP0 pid=379187) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29<00:00, 29.20s/it]
(EngineCore_DP0 pid=379187) 
(EngineCore_DP0 pid=379187) [2026-01-25 19:53:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=379187) [2026-01-25 19:53:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=379187) [2026-01-25 19:53:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=379187) [2026-01-25 19:53:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=379187) [2026-01-25 19:53:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=379187) [2026-01-25 19:53:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=379187) [2026-01-25 19:53:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=379187) [2026-01-25 19:53:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=379187) Process EngineCore_DP0:
(EngineCore_DP0 pid=379187) Traceback (most recent call last):
(EngineCore_DP0 pid=379187)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=379187)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=379187)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=379187)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=379187) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpn82m9hzg.ptx', '-o', '/tmp/tmpn82m9hzg.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=379187) 
(EngineCore_DP0 pid=379187) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=379187) 
(EngineCore_DP0 pid=379187) Traceback (most recent call last):
(EngineCore_DP0 pid=379187)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=379187)     self.run()
(EngineCore_DP0 pid=379187)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=379187)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=379187)     raise e
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=379187)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=379187)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=379187)     super().__init__(
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=379187)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=379187)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=379187)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=379187)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=379187)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=379187)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=379187)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=379187)     return func(*args, **kwargs)
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=379187)     return func(*args, **kwargs)
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=379187)     self.model_runner.profile_run()
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=379187)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=379187)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=379187)     return func(*args, **kwargs)
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=379187)     outputs = self.model(
(EngineCore_DP0 pid=379187)               ^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=379187)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=379187)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=379187)     model_output = self.model(
(EngineCore_DP0 pid=379187)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=379187)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=379187)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=379187)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=379187)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=379187)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=379187)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=379187)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=379187)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=379187)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=379187)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=379187)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=379187)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=379187)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=379187)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=379187)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=379187)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=379187)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=379187)     return self._linear_fn(
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=379187)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=379187)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=379187)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=379187)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=379187)     return fn(input, L)
(EngineCore_DP0 pid=379187)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=379187)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=379187)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=379187)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=379187)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=379187)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=379187)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=379187)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=379187)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=379187)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=379187)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=379187)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=379187)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=379187)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=379187)     raise PTXASError(error)
(EngineCore_DP0 pid=379187) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=379187) `ptxas` stderr:
(EngineCore_DP0 pid=379187) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=379187) 
(EngineCore_DP0 pid=379187) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpn82m9hzg.ptx -o /tmp/tmpn82m9hzg.ptx.o
(EngineCore_DP0 pid=379187) 
[rank0]:[W125 19:53:27.176685577 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 19:53:29
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:53:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:53:44 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=380097) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=380097) 
(EngineCore_DP0 pid=380097) 
(EngineCore_DP0 pid=380097) ================================================================
(EngineCore_DP0 pid=380097) Internal Triton PTX codegen error
(EngineCore_DP0 pid=380097) `ptxas` stderr:
(EngineCore_DP0 pid=380097) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=380097) 
(EngineCore_DP0 pid=380097) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpbnjk4nbv.ptx -o /tmp/tmpbnjk4nbv.ptx.o
(EngineCore_DP0 pid=380097) 
(EngineCore_DP0 pid=380097) 
(EngineCore_DP0 pid=380097) //
(EngineCore_DP0 pid=380097) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=380097) //
(EngineCore_DP0 pid=380097) 
(EngineCore_DP0 pid=380097) .version 8.7
(EngineCore_DP0 pid=380097) .target sm_121a
(EngineCore_DP0 pid=380097) .address_size 64
(EngineCore_DP0 pid=380097) 
(EngineCore_DP0 pid=380097) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=380097) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=380097)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=380097) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=380097) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=380097) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=380097) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=380097) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=380097) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=380097) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=380097) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=380097) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=380097) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=380097) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=380097) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=380097) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=380097) )
(EngineCore_DP0 pid=380097) .reqntid 512
(EngineCore_DP0 pid=380097) {
(EngineCore_DP0 pid=380097) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=380097) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=380097) 	.reg .b32 	%r<255>;
(EngineCore_DP0 pid=380097) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=380097) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=380097) $L__func_begin0:
(EngineCore_DP0 pid=380097) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=380097) 
(EngineCore_DP0 pid=380097) // %bb.0:
(EngineCore_DP0 pid=380097) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=380097) 	ld.param.b32 	%r28, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=380097) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=380097) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=380097) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=380097) $L__tmp0:
(EngineCore_DP0 pid=380097) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=380097) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=380097) 	ld.param.b32 	%r31, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=380097) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=380097) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=380097) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=380097) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=380097) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=380097) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=380097) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=380097) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=380097) 	mov.b32 	%r253, 0f2B8CBCCC;
(EngineCore_DP0 pid=380097) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=380097) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=380097) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=380097) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=380097) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=380097) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=380097) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=380097) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=380097) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=380097) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=380097) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=380097) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=380097) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=380097) 	mov.b32 	%r251, 0f00000000;
(EngineCore_DP0 pid=380097) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=380097) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=380097) 	mov.b32 	%r252, %r49;
(EngineCore_DP0 pid=380097) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=380097) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=380097) 	add.s32 	%r59, %r4, %r252;
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=380097) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=380097) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=380097) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=380097) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=380097) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=380097) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=380097) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=380097) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=380097) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=380097) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=380097) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=380097) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=380097) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=380097) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=380097) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=380097) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=380097) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=380097) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=380097) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=380097) $L__tmp1:
(EngineCore_DP0 pid=380097) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	bar.sync 	0;
(EngineCore_DP0 pid=380097) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=380097) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=380097) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=380097) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=380097) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=380097) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=380097) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=380097) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=380097) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=380097) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=380097) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=380097) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=380097) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=380097) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=380097) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=380097) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=380097) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=380097) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=380097) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	bar.sync 	0;
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=380097) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=380097) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=380097) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=380097) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=380097) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=380097) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=380097) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=380097) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	bar.sync 	0;
(EngineCore_DP0 pid=380097) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=380097) $L__tmp2:
(EngineCore_DP0 pid=380097) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=380097) 	max.f32 	%r251, %r251, %r77;
(EngineCore_DP0 pid=380097) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=380097) 	add.s32 	%r252, %r252, 4096;
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p6, %r252, %r28;
(EngineCore_DP0 pid=380097) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=380097) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=380097) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=380097) 	max.f32 	%r253, %r251, 0f2B8CBCCC;
(EngineCore_DP0 pid=380097) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=380097) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=380097) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=380097) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=380097) 	div.full.f32 	%r80, %r253, %r79;
(EngineCore_DP0 pid=380097) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=380097) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=380097) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=380097) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=380097) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=380097) 	shl.b32 	%r15, %r29, 2;
(EngineCore_DP0 pid=380097) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=380097) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=380097) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=380097) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=380097) 	ld.param.b32 	%r33, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=380097) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=380097) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=380097) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=380097) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=380097) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=380097) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=380097) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=380097) 	div.full.f32 	%r14, %r79, %r253;
(EngineCore_DP0 pid=380097) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=380097) 	mov.b32 	%r254, 0;
(EngineCore_DP0 pid=380097) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=380097)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=380097) 	.loc	1 327 31                        // quant_slide_tuned_Llama3.2-3B.py:327:31
(EngineCore_DP0 pid=380097) 	add.s32 	%r86, %r16, %r254;
(EngineCore_DP0 pid=380097) 	or.b32 	%r87, %r254, 2;
(EngineCore_DP0 pid=380097) 	or.b32 	%r88, %r254, 3;
(EngineCore_DP0 pid=380097) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p25, %r86, %r15;
(EngineCore_DP0 pid=380097) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=380097) 	shr.s32 	%r89, %r86, 2;
(EngineCore_DP0 pid=380097) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=380097) 	add.s32 	%r90, %r254, 1;
(EngineCore_DP0 pid=380097) 	shr.s32 	%r91, %r90, 31;
(EngineCore_DP0 pid=380097) 	shr.u32 	%r92, %r91, 30;
(EngineCore_DP0 pid=380097) 	add.s32 	%r93, %r90, %r92;
(EngineCore_DP0 pid=380097) 	and.b32 	%r94, %r93, 2147483644;
(EngineCore_DP0 pid=380097) 	sub.s32 	%r95, %r90, %r94;
(EngineCore_DP0 pid=380097) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=380097) 	shl.b32 	%r96, %r95, 1;
(EngineCore_DP0 pid=380097) 	.loc	1 333 22                        // quant_slide_tuned_Llama3.2-3B.py:333:22
(EngineCore_DP0 pid=380097) 	mul.lo.s32 	%r97, %r89, 10;
(EngineCore_DP0 pid=380097) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=380097) 	add.s32 	%r98, %r97, %r96;
(EngineCore_DP0 pid=380097) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=380097) 	shr.s32 	%r99, %r254, 31;
(EngineCore_DP0 pid=380097) 	shr.u32 	%r100, %r99, 30;
(EngineCore_DP0 pid=380097) 	add.s32 	%r101, %r88, %r100;
(EngineCore_DP0 pid=380097) 	and.b32 	%r102, %r101, 2147483644;
(EngineCore_DP0 pid=380097) 	sub.s32 	%r103, %r88, %r102;
(EngineCore_DP0 pid=380097) 	add.s32 	%r104, %r87, %r100;
(EngineCore_DP0 pid=380097) 	and.b32 	%r105, %r104, 2147483644;
(EngineCore_DP0 pid=380097) 	sub.s32 	%r106, %r87, %r105;
(EngineCore_DP0 pid=380097) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=380097) 	shl.b32 	%r107, %r106, 1;
(EngineCore_DP0 pid=380097) 	shl.b32 	%r108, %r103, 1;
(EngineCore_DP0 pid=380097) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=380097) 	add.s32 	%r109, %r97, %r108;
(EngineCore_DP0 pid=380097) 	add.s32 	%r110, %r97, %r107;
(EngineCore_DP0 pid=380097) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p26, %r97, %r27;
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p27, %r98, %r27;
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p28, %r110, %r27;
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p29, %r109, %r27;
(EngineCore_DP0 pid=380097) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=380097) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=380097) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=380097) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=380097) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=380097) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=380097) 	mad.wide.s32 	%rd8, %r97, 2, %rd1;
(EngineCore_DP0 pid=380097) 	mad.wide.s32 	%rd9, %r98, 2, %rd1;
(EngineCore_DP0 pid=380097) 	mad.wide.s32 	%rd10, %r110, 2, %rd1;
(EngineCore_DP0 pid=380097) 	mad.wide.s32 	%rd11, %r109, 2, %rd1;
(EngineCore_DP0 pid=380097) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=380097) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=380097) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=380097) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=380097) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=380097) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=380097) 	cvt.f32.bf16 	%r111, %rs24;
(EngineCore_DP0 pid=380097) 	cvt.f32.bf16 	%r112, %rs26;
(EngineCore_DP0 pid=380097) 	cvt.f32.bf16 	%r113, %rs28;
(EngineCore_DP0 pid=380097) 	cvt.f32.bf16 	%r114, %rs30;
(EngineCore_DP0 pid=380097) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=380097) 	or.b32 	%r115, %r97, 1;
(EngineCore_DP0 pid=380097) 	or.b32 	%r116, %r98, 1;
(EngineCore_DP0 pid=380097) 	or.b32 	%r117, %r110, 1;
(EngineCore_DP0 pid=380097) 	or.b32 	%r118, %r109, 1;
(EngineCore_DP0 pid=380097) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p30, %r115, %r27;
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p31, %r116, %r27;
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p32, %r117, %r27;
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p33, %r118, %r27;
(EngineCore_DP0 pid=380097) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=380097) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=380097) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=380097) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=380097) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=380097) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=380097) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=380097) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=380097) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=380097) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=380097) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=380097) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=380097) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=380097) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=380097) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=380097) 	cvt.f32.bf16 	%r119, %rs32;
(EngineCore_DP0 pid=380097) 	cvt.f32.bf16 	%r120, %rs34;
(EngineCore_DP0 pid=380097) 	cvt.f32.bf16 	%r121, %rs36;
(EngineCore_DP0 pid=380097) 	cvt.f32.bf16 	%r122, %rs38;
(EngineCore_DP0 pid=380097) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=380097) 	add.s32 	%r123, %r98, 2;
(EngineCore_DP0 pid=380097) 	add.s32 	%r124, %r110, 2;
(EngineCore_DP0 pid=380097) 	add.s32 	%r125, %r109, 2;
(EngineCore_DP0 pid=380097) 	add.s32 	%r126, %r98, 3;
(EngineCore_DP0 pid=380097) 	add.s32 	%r127, %r110, 3;
(EngineCore_DP0 pid=380097) 	add.s32 	%r128, %r109, 3;
(EngineCore_DP0 pid=380097) 	add.s32 	%r129, %r97, 2;
(EngineCore_DP0 pid=380097) 	add.s32 	%r130, %r97, 3;
(EngineCore_DP0 pid=380097) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p34, %r128, %r27;
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p35, %r127, %r27;
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p36, %r126, %r27;
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p37, %r125, %r27;
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p38, %r124, %r27;
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p39, %r123, %r27;
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p40, %r130, %r27;
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p41, %r129, %r27;
(EngineCore_DP0 pid=380097) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=380097) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=380097) 	and.pred 	%p18, %p25, %p39;
(EngineCore_DP0 pid=380097) 	and.pred 	%p19, %p25, %p38;
(EngineCore_DP0 pid=380097) 	and.pred 	%p20, %p25, %p37;
(EngineCore_DP0 pid=380097) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=380097) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=380097) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=380097) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=380097) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=380097) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=380097) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=380097) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=380097) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=380097) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=380097) 	cvt.f32.bf16 	%r131, %rs40;
(EngineCore_DP0 pid=380097) 	cvt.f32.bf16 	%r132, %rs42;
(EngineCore_DP0 pid=380097) 	cvt.f32.bf16 	%r133, %rs44;
(EngineCore_DP0 pid=380097) 	cvt.f32.bf16 	%r134, %rs46;
(EngineCore_DP0 pid=380097) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=380097) 	and.pred 	%p21, %p25, %p40;
(EngineCore_DP0 pid=380097) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=380097) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=380097) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=380097) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=380097) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=380097) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=380097) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=380097) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=380097) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=380097) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=380097) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=380097) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=380097) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=380097) 	cvt.f32.bf16 	%r135, %rs48;
(EngineCore_DP0 pid=380097) 	cvt.f32.bf16 	%r136, %rs50;
(EngineCore_DP0 pid=380097) 	cvt.f32.bf16 	%r137, %rs52;
(EngineCore_DP0 pid=380097) 	cvt.f32.bf16 	%r138, %rs54;
(EngineCore_DP0 pid=380097) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=380097) 	mul.f32 	%r139, %r14, %r111;
(EngineCore_DP0 pid=380097) 	mul.f32 	%r140, %r14, %r112;
(EngineCore_DP0 pid=380097) 	mul.f32 	%r141, %r14, %r113;
(EngineCore_DP0 pid=380097) 	mul.f32 	%r142, %r14, %r114;
(EngineCore_DP0 pid=380097) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=380097) 	cvt.rni.f32.f32 	%r143, %r139;
(EngineCore_DP0 pid=380097) 	cvt.rni.f32.f32 	%r144, %r140;
(EngineCore_DP0 pid=380097) 	cvt.rni.f32.f32 	%r145, %r141;
(EngineCore_DP0 pid=380097) 	cvt.rni.f32.f32 	%r146, %r142;
(EngineCore_DP0 pid=380097) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=380097) 	max.f32 	%r147, %r143, 0fC3000000;
(EngineCore_DP0 pid=380097) 	min.f32 	%r148, %r147, 0f42FE0000;
(EngineCore_DP0 pid=380097) 	max.f32 	%r149, %r144, 0fC3000000;
(EngineCore_DP0 pid=380097) 	min.f32 	%r150, %r149, 0f42FE0000;
(EngineCore_DP0 pid=380097) 	max.f32 	%r151, %r145, 0fC3000000;
(EngineCore_DP0 pid=380097) 	min.f32 	%r152, %r151, 0f42FE0000;
(EngineCore_DP0 pid=380097) 	max.f32 	%r153, %r146, 0fC3000000;
(EngineCore_DP0 pid=380097) 	min.f32 	%r154, %r153, 0f42FE0000;
(EngineCore_DP0 pid=380097) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=380097) 	cvt.rzi.s32.f32 	%r155, %r148;
(EngineCore_DP0 pid=380097) 	cvt.rzi.s32.f32 	%r156, %r150;
(EngineCore_DP0 pid=380097) 	cvt.rzi.s32.f32 	%r157, %r152;
(EngineCore_DP0 pid=380097) 	cvt.rzi.s32.f32 	%r158, %r154;
(EngineCore_DP0 pid=380097) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=380097) 	and.b32 	%r159, %r155, 255;
(EngineCore_DP0 pid=380097) 	and.b32 	%r160, %r156, 255;
(EngineCore_DP0 pid=380097) 	and.b32 	%r161, %r157, 255;
(EngineCore_DP0 pid=380097) 	and.b32 	%r162, %r158, 255;
(EngineCore_DP0 pid=380097) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=380097) 	mul.f32 	%r163, %r14, %r119;
(EngineCore_DP0 pid=380097) 	mul.f32 	%r164, %r14, %r120;
(EngineCore_DP0 pid=380097) 	mul.f32 	%r165, %r14, %r121;
(EngineCore_DP0 pid=380097) 	mul.f32 	%r166, %r14, %r122;
(EngineCore_DP0 pid=380097) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=380097) 	cvt.rni.f32.f32 	%r167, %r163;
(EngineCore_DP0 pid=380097) 	cvt.rni.f32.f32 	%r168, %r164;
(EngineCore_DP0 pid=380097) 	cvt.rni.f32.f32 	%r169, %r165;
(EngineCore_DP0 pid=380097) 	cvt.rni.f32.f32 	%r170, %r166;
(EngineCore_DP0 pid=380097) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=380097) 	mul.f32 	%r171, %r14, %r131;
(EngineCore_DP0 pid=380097) 	mul.f32 	%r172, %r14, %r132;
(EngineCore_DP0 pid=380097) 	mul.f32 	%r173, %r14, %r133;
(EngineCore_DP0 pid=380097) 	mul.f32 	%r174, %r14, %r134;
(EngineCore_DP0 pid=380097) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=380097) 	cvt.rni.f32.f32 	%r175, %r171;
(EngineCore_DP0 pid=380097) 	cvt.rni.f32.f32 	%r176, %r172;
(EngineCore_DP0 pid=380097) 	cvt.rni.f32.f32 	%r177, %r173;
(EngineCore_DP0 pid=380097) 	cvt.rni.f32.f32 	%r178, %r174;
(EngineCore_DP0 pid=380097) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=380097) 	mul.f32 	%r179, %r14, %r135;
(EngineCore_DP0 pid=380097) 	mul.f32 	%r180, %r14, %r136;
(EngineCore_DP0 pid=380097) 	mul.f32 	%r181, %r14, %r137;
(EngineCore_DP0 pid=380097) 	mul.f32 	%r182, %r14, %r138;
(EngineCore_DP0 pid=380097) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=380097) 	cvt.rni.f32.f32 	%r183, %r179;
(EngineCore_DP0 pid=380097) 	cvt.rni.f32.f32 	%r184, %r180;
(EngineCore_DP0 pid=380097) 	cvt.rni.f32.f32 	%r185, %r181;
(EngineCore_DP0 pid=380097) 	cvt.rni.f32.f32 	%r186, %r182;
(EngineCore_DP0 pid=380097) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=380097) 	max.f32 	%r187, %r183, 0fC3000000;
(EngineCore_DP0 pid=380097) 	min.f32 	%r188, %r187, 0f42FE0000;
(EngineCore_DP0 pid=380097) 	max.f32 	%r189, %r184, 0fC3000000;
(EngineCore_DP0 pid=380097) 	min.f32 	%r190, %r189, 0f42FE0000;
(EngineCore_DP0 pid=380097) 	max.f32 	%r191, %r185, 0fC3000000;
(EngineCore_DP0 pid=380097) 	min.f32 	%r192, %r191, 0f42FE0000;
(EngineCore_DP0 pid=380097) 	max.f32 	%r193, %r186, 0fC3000000;
(EngineCore_DP0 pid=380097) 	min.f32 	%r194, %r193, 0f42FE0000;
(EngineCore_DP0 pid=380097) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=380097) 	cvt.rzi.s32.f32 	%r195, %r188;
(EngineCore_DP0 pid=380097) 	cvt.rzi.s32.f32 	%r196, %r190;
(EngineCore_DP0 pid=380097) 	cvt.rzi.s32.f32 	%r197, %r192;
(EngineCore_DP0 pid=380097) 	cvt.rzi.s32.f32 	%r198, %r194;
(EngineCore_DP0 pid=380097) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=380097) 	max.f32 	%r199, %r175, 0fC3000000;
(EngineCore_DP0 pid=380097) 	max.f32 	%r200, %r167, 0fC3000000;
(EngineCore_DP0 pid=380097) 	min.f32 	%r201, %r200, 0f42FE0000;
(EngineCore_DP0 pid=380097) 	min.f32 	%r202, %r199, 0f42FE0000;
(EngineCore_DP0 pid=380097) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=380097) 	cvt.rzi.s32.f32 	%r203, %r202;
(EngineCore_DP0 pid=380097) 	cvt.rzi.s32.f32 	%r204, %r201;
(EngineCore_DP0 pid=380097) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=380097) 	shl.b32 	%r205, %r204, 8;
(EngineCore_DP0 pid=380097) 	shl.b32 	%r206, %r203, 16;
(EngineCore_DP0 pid=380097) 	and.b32 	%r207, %r206, 16711680;
(EngineCore_DP0 pid=380097) 	and.b32 	%r208, %r205, 65280;
(EngineCore_DP0 pid=380097) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=380097) 	or.b32 	%r209, %r208, %r159;
(EngineCore_DP0 pid=380097) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=380097) 	max.f32 	%r210, %r176, 0fC3000000;
(EngineCore_DP0 pid=380097) 	max.f32 	%r211, %r168, 0fC3000000;
(EngineCore_DP0 pid=380097) 	min.f32 	%r212, %r211, 0f42FE0000;
(EngineCore_DP0 pid=380097) 	min.f32 	%r213, %r210, 0f42FE0000;
(EngineCore_DP0 pid=380097) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=380097) 	cvt.rzi.s32.f32 	%r214, %r213;
(EngineCore_DP0 pid=380097) 	cvt.rzi.s32.f32 	%r215, %r212;
(EngineCore_DP0 pid=380097) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=380097) 	shl.b32 	%r216, %r215, 8;
(EngineCore_DP0 pid=380097) 	shl.b32 	%r217, %r214, 16;
(EngineCore_DP0 pid=380097) 	and.b32 	%r218, %r217, 16711680;
(EngineCore_DP0 pid=380097) 	and.b32 	%r219, %r216, 65280;
(EngineCore_DP0 pid=380097) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=380097) 	or.b32 	%r220, %r219, %r160;
(EngineCore_DP0 pid=380097) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=380097) 	max.f32 	%r221, %r177, 0fC3000000;
(EngineCore_DP0 pid=380097) 	max.f32 	%r222, %r169, 0fC3000000;
(EngineCore_DP0 pid=380097) 	min.f32 	%r223, %r222, 0f42FE0000;
(EngineCore_DP0 pid=380097) 	min.f32 	%r224, %r221, 0f42FE0000;
(EngineCore_DP0 pid=380097) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=380097) 	cvt.rzi.s32.f32 	%r225, %r224;
(EngineCore_DP0 pid=380097) 	cvt.rzi.s32.f32 	%r226, %r223;
(EngineCore_DP0 pid=380097) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=380097) 	shl.b32 	%r227, %r226, 8;
(EngineCore_DP0 pid=380097) 	shl.b32 	%r228, %r225, 16;
(EngineCore_DP0 pid=380097) 	and.b32 	%r229, %r228, 16711680;
(EngineCore_DP0 pid=380097) 	and.b32 	%r230, %r227, 65280;
(EngineCore_DP0 pid=380097) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=380097) 	or.b32 	%r231, %r230, %r161;
(EngineCore_DP0 pid=380097) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=380097) 	max.f32 	%r232, %r178, 0fC3000000;
(EngineCore_DP0 pid=380097) 	max.f32 	%r233, %r170, 0fC3000000;
(EngineCore_DP0 pid=380097) 	min.f32 	%r234, %r233, 0f42FE0000;
(EngineCore_DP0 pid=380097) 	min.f32 	%r235, %r232, 0f42FE0000;
(EngineCore_DP0 pid=380097) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=380097) 	cvt.rzi.s32.f32 	%r236, %r235;
(EngineCore_DP0 pid=380097) 	cvt.rzi.s32.f32 	%r237, %r234;
(EngineCore_DP0 pid=380097) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=380097) 	shl.b32 	%r238, %r237, 8;
(EngineCore_DP0 pid=380097) 	shl.b32 	%r239, %r236, 16;
(EngineCore_DP0 pid=380097) 	and.b32 	%r240, %r239, 16711680;
(EngineCore_DP0 pid=380097) 	and.b32 	%r241, %r238, 65280;
(EngineCore_DP0 pid=380097) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=380097) 	or.b32 	%r242, %r241, %r162;
(EngineCore_DP0 pid=380097) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=380097) 	or.b32 	%r243, %r209, %r207;
(EngineCore_DP0 pid=380097) 	or.b32 	%r244, %r220, %r218;
(EngineCore_DP0 pid=380097) 	or.b32 	%r245, %r231, %r229;
(EngineCore_DP0 pid=380097) 	or.b32 	%r246, %r242, %r240;
(EngineCore_DP0 pid=380097) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=380097) 	shl.b32 	%r247, %r195, 24;
(EngineCore_DP0 pid=380097) 	shl.b32 	%r248, %r196, 24;
(EngineCore_DP0 pid=380097) 	shl.b32 	%r249, %r197, 24;
(EngineCore_DP0 pid=380097) 	shl.b32 	%r250, %r198, 24;
(EngineCore_DP0 pid=380097) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=380097) 	or.b32 	%r82, %r243, %r247;
(EngineCore_DP0 pid=380097) 	or.b32 	%r83, %r244, %r248;
(EngineCore_DP0 pid=380097) 	or.b32 	%r84, %r245, %r249;
(EngineCore_DP0 pid=380097) 	or.b32 	%r85, %r246, %r250;
(EngineCore_DP0 pid=380097) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=380097) 	mad.wide.s32 	%rd24, %r86, 4, %rd2;
(EngineCore_DP0 pid=380097) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=380097) 	// begin inline asm
(EngineCore_DP0 pid=380097) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r82, %r83, %r84, %r85 };
(EngineCore_DP0 pid=380097) 	// end inline asm
(EngineCore_DP0 pid=380097) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=380097) 	add.s32 	%r254, %r254, 2048;
(EngineCore_DP0 pid=380097) 	setp.lt.s32 	%p42, %r254, %r15;
(EngineCore_DP0 pid=380097) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=380097) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=380097) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=380097) 	ret;
(EngineCore_DP0 pid=380097) $L__tmp3:
(EngineCore_DP0 pid=380097) $L__func_end0:
(EngineCore_DP0 pid=380097)                                         // -- End function
(EngineCore_DP0 pid=380097) }
(EngineCore_DP0 pid=380097) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=380097) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=380097) 	.section	.debug_abbrev
(EngineCore_DP0 pid=380097) 	{
(EngineCore_DP0 pid=380097) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=380097) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=380097) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=380097) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=380097) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=380097) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=380097) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=380097) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=380097) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=380097) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=380097) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=380097) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=380097) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=380097) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=380097) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=380097) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=380097) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=380097) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=380097) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=380097) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=380097) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=380097) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=380097) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=380097) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=380097) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=380097) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=380097) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=380097) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=380097) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=380097) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=380097) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=380097) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=380097) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=380097) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=380097) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=380097) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=380097) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=380097) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=380097) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=380097) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=380097) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=380097) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=380097) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=380097) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=380097) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=380097) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=380097) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=380097) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=380097) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=380097) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=380097) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=380097) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=380097) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=380097) 	}
(EngineCore_DP0 pid=380097) 	.section	.debug_info
(EngineCore_DP0 pid=380097) 	{
(EngineCore_DP0 pid=380097) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=380097) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=380097) .b8 0
(EngineCore_DP0 pid=380097) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=380097) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=380097) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=380097) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=380097) .b8 114
(EngineCore_DP0 pid=380097) .b8 105
(EngineCore_DP0 pid=380097) .b8 116
(EngineCore_DP0 pid=380097) .b8 111
(EngineCore_DP0 pid=380097) .b8 110
(EngineCore_DP0 pid=380097) .b8 0
(EngineCore_DP0 pid=380097) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=380097) .b8 0
(EngineCore_DP0 pid=380097) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=380097) .b8 117
(EngineCore_DP0 pid=380097) .b8 97
(EngineCore_DP0 pid=380097) .b8 110
(EngineCore_DP0 pid=380097) .b8 116
(EngineCore_DP0 pid=380097) .b8 95
(EngineCore_DP0 pid=380097) .b8 115
(EngineCore_DP0 pid=380097) .b8 108
(EngineCore_DP0 pid=380097) .b8 105
(EngineCore_DP0 pid=380097) .b8 100
(EngineCore_DP0 pid=380097) .b8 101
(EngineCore_DP0 pid=380097) .b8 95
(EngineCore_DP0 pid=380097) .b8 116
(EngineCore_DP0 pid=380097) .b8 117
(EngineCore_DP0 pid=380097) .b8 110
(EngineCore_DP0 pid=380097) .b8 101
(EngineCore_DP0 pid=380097) .b8 100
(EngineCore_DP0 pid=380097) .b8 95
(EngineCore_DP0 pid=380097) .b8 76
(EngineCore_DP0 pid=380097) .b8 108
(EngineCore_DP0 pid=380097) .b8 97
(EngineCore_DP0 pid=380097) .b8 109
(EngineCore_DP0 pid=380097) .b8 97
(EngineCore_DP0 pid=380097) .b8 51
(EngineCore_DP0 pid=380097) .b8 46
(EngineCore_DP0 pid=380097) .b8 50
(EngineCore_DP0 pid=380097) .b8 45
(EngineCore_DP0 pid=380097) .b8 51
(EngineCore_DP0 pid=380097) .b8 66
(EngineCore_DP0 pid=380097) .b8 46
(EngineCore_DP0 pid=380097) .b8 112
(EngineCore_DP0 pid=380097) .b8 121
(EngineCore_DP0 pid=380097) .b8 0
(EngineCore_DP0 pid=380097) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=380097) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=380097) .b8 114
(EngineCore_DP0 pid=380097) .b8 111
(EngineCore_DP0 pid=380097) .b8 111
(EngineCore_DP0 pid=380097) .b8 116
(EngineCore_DP0 pid=380097) .b8 47
(EngineCore_DP0 pid=380097) .b8 118
(EngineCore_DP0 pid=380097) .b8 108
(EngineCore_DP0 pid=380097) .b8 108
(EngineCore_DP0 pid=380097) .b8 109
(EngineCore_DP0 pid=380097) .b8 98
(EngineCore_DP0 pid=380097) .b8 101
(EngineCore_DP0 pid=380097) .b8 110
(EngineCore_DP0 pid=380097) .b8 99
(EngineCore_DP0 pid=380097) .b8 104
(EngineCore_DP0 pid=380097) .b8 47
(EngineCore_DP0 pid=380097) .b8 115
(EngineCore_DP0 pid=380097) .b8 108
(EngineCore_DP0 pid=380097) .b8 105
(EngineCore_DP0 pid=380097) .b8 100
(EngineCore_DP0 pid=380097) .b8 101
(EngineCore_DP0 pid=380097) .b8 115
(EngineCore_DP0 pid=380097) .b8 112
(EngineCore_DP0 pid=380097) .b8 97
(EngineCore_DP0 pid=380097) .b8 114
(EngineCore_DP0 pid=380097) .b8 115
(EngineCore_DP0 pid=380097) .b8 101
(EngineCore_DP0 pid=380097) .b8 47
(EngineCore_DP0 pid=380097) .b8 99
(EngineCore_DP0 pid=380097) .b8 115
(EngineCore_DP0 pid=380097) .b8 114
(EngineCore_DP0 pid=380097) .b8 99
(EngineCore_DP0 pid=380097) .b8 47
(EngineCore_DP0 pid=380097) .b8 102
(EngineCore_DP0 pid=380097) .b8 117
(EngineCore_DP0 pid=380097) .b8 115
(EngineCore_DP0 pid=380097) .b8 101
(EngineCore_DP0 pid=380097) .b8 100
(EngineCore_DP0 pid=380097) .b8 95
(EngineCore_DP0 pid=380097) .b8 113
(EngineCore_DP0 pid=380097) .b8 117
(EngineCore_DP0 pid=380097) .b8 97
(EngineCore_DP0 pid=380097) .b8 110
(EngineCore_DP0 pid=380097) .b8 116
(EngineCore_DP0 pid=380097) .b8 95
(EngineCore_DP0 pid=380097) .b8 115
(EngineCore_DP0 pid=380097) .b8 108
(EngineCore_DP0 pid=380097) .b8 105
(EngineCore_DP0 pid=380097) .b8 100
(EngineCore_DP0 pid=380097) .b8 101
(EngineCore_DP0 pid=380097) .b8 95
(EngineCore_DP0 pid=380097) .b8 116
(EngineCore_DP0 pid=380097) .b8 114
(EngineCore_DP0 pid=380097) .b8 105
(EngineCore_DP0 pid=380097) .b8 116
(EngineCore_DP0 pid=380097) .b8 111
(EngineCore_DP0 pid=380097) .b8 110
(EngineCore_DP0 pid=380097) .b8 47
(EngineCore_DP0 pid=380097) .b8 98
(EngineCore_DP0 pid=380097) .b8 117
(EngineCore_DP0 pid=380097) .b8 105
(EngineCore_DP0 pid=380097) .b8 108
(EngineCore_DP0 pid=380097) .b8 100
(EngineCore_DP0 pid=380097) .b8 47
(EngineCore_DP0 pid=380097) .b8 71
(EngineCore_DP0 pid=380097) .b8 66
(EngineCore_DP0 pid=380097) .b8 49
(EngineCore_DP0 pid=380097) .b8 48
(EngineCore_DP0 pid=380097) .b8 95
(EngineCore_DP0 pid=380097) .b8 99
(EngineCore_DP0 pid=380097) .b8 99
(EngineCore_DP0 pid=380097) .b8 49
(EngineCore_DP0 pid=380097) .b8 50
(EngineCore_DP0 pid=380097) .b8 49
(EngineCore_DP0 pid=380097) .b8 95
(EngineCore_DP0 pid=380097) .b8 112
(EngineCore_DP0 pid=380097) .b8 121
(EngineCore_DP0 pid=380097) .b8 51
(EngineCore_DP0 pid=380097) .b8 49
(EngineCore_DP0 pid=380097) .b8 50
(EngineCore_DP0 pid=380097) .b8 95
(EngineCore_DP0 pid=380097) .b8 99
(EngineCore_DP0 pid=380097) .b8 117
(EngineCore_DP0 pid=380097) .b8 49
(EngineCore_DP0 pid=380097) .b8 50
(EngineCore_DP0 pid=380097) .b8 57
(EngineCore_DP0 pid=380097) .b8 95
(EngineCore_DP0 pid=380097) .b8 97
(EngineCore_DP0 pid=380097) .b8 97
(EngineCore_DP0 pid=380097) .b8 114
(EngineCore_DP0 pid=380097) .b8 99
(EngineCore_DP0 pid=380097) .b8 104
(EngineCore_DP0 pid=380097) .b8 54
(EngineCore_DP0 pid=380097) .b8 52
(EngineCore_DP0 pid=380097) .b8 0
(EngineCore_DP0 pid=380097) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=380097) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=380097) .b8 113
(EngineCore_DP0 pid=380097) .b8 117
(EngineCore_DP0 pid=380097) .b8 97
(EngineCore_DP0 pid=380097) .b8 110
(EngineCore_DP0 pid=380097) .b8 116
(EngineCore_DP0 pid=380097) .b8 95
(EngineCore_DP0 pid=380097) .b8 115
(EngineCore_DP0 pid=380097) .b8 108
(EngineCore_DP0 pid=380097) .b8 105
(EngineCore_DP0 pid=380097) .b8 100
(EngineCore_DP0 pid=380097) .b8 101
(EngineCore_DP0 pid=380097) .b8 95
(EngineCore_DP0 pid=380097) .b8 105
(EngineCore_DP0 pid=380097) .b8 110
(EngineCore_DP0 pid=380097) .b8 116
(EngineCore_DP0 pid=380097) .b8 56
(EngineCore_DP0 pid=380097) .b8 95
(EngineCore_DP0 pid=380097) .b8 107
(EngineCore_DP0 pid=380097) .b8 101
(EngineCore_DP0 pid=380097) .b8 114
(EngineCore_DP0 pid=380097) .b8 110
(EngineCore_DP0 pid=380097) .b8 101
(EngineCore_DP0 pid=380097) .b8 108
(EngineCore_DP0 pid=380097) .b8 0
(EngineCore_DP0 pid=380097) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=380097) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=380097) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=380097) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=380097) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=380097) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=380097) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=380097) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=380097) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=380097) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=380097) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=380097) .b8 1
(EngineCore_DP0 pid=380097) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=380097) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=380097) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=380097) 	}
(EngineCore_DP0 pid=380097) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=380097) 
(EngineCore_DP0 pid=380097) ================================================================
(EngineCore_DP0 pid=380097) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=380097) 
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpbnjk4nbv.ptx', '-o', '/tmp/tmpbnjk4nbv.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866] 
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866] 
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866] 
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpbnjk4nbv.ptx -o /tmp/tmpbnjk4nbv.ptx.o
(EngineCore_DP0 pid=380097) ERROR 01-25 19:54:20 [core.py:866] 

STDERR:
[2026-01-25 19:53:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:53:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:53:44] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:53:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:53:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:53:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:53:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:53:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:53:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:53:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:53:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:53:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:53:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:53:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:53:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:53:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:53:47] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:53:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:53:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:53:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:53:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:53:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:53:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:53:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:53:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:53:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:53:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:53:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=380097) [2026-01-25 19:53:48] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=380097) [2026-01-25 19:53:48] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=380097) [2026-01-25 19:53:48] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=380097) [2026-01-25 19:53:48] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=380097) [2026-01-25 19:53:48] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=380097) [2026-01-25 19:53:48] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=380097) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=380097) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29<00:00, 29.15s/it]
(EngineCore_DP0 pid=380097) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29<00:00, 29.15s/it]
(EngineCore_DP0 pid=380097) 
(EngineCore_DP0 pid=380097) [2026-01-25 19:54:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=380097) [2026-01-25 19:54:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=380097) [2026-01-25 19:54:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=380097) [2026-01-25 19:54:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=380097) [2026-01-25 19:54:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=380097) [2026-01-25 19:54:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=380097) [2026-01-25 19:54:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=380097) [2026-01-25 19:54:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=380097) Process EngineCore_DP0:
(EngineCore_DP0 pid=380097) Traceback (most recent call last):
(EngineCore_DP0 pid=380097)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=380097)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=380097)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=380097)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=380097) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpbnjk4nbv.ptx', '-o', '/tmp/tmpbnjk4nbv.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=380097) 
(EngineCore_DP0 pid=380097) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=380097) 
(EngineCore_DP0 pid=380097) Traceback (most recent call last):
(EngineCore_DP0 pid=380097)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=380097)     self.run()
(EngineCore_DP0 pid=380097)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=380097)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=380097)     raise e
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=380097)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=380097)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=380097)     super().__init__(
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=380097)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=380097)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=380097)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=380097)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=380097)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=380097)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=380097)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=380097)     return func(*args, **kwargs)
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=380097)     return func(*args, **kwargs)
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=380097)     self.model_runner.profile_run()
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=380097)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=380097)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=380097)     return func(*args, **kwargs)
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=380097)     outputs = self.model(
(EngineCore_DP0 pid=380097)               ^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=380097)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=380097)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=380097)     model_output = self.model(
(EngineCore_DP0 pid=380097)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=380097)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=380097)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=380097)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=380097)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=380097)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=380097)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=380097)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=380097)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=380097)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=380097)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=380097)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=380097)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=380097)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=380097)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=380097)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=380097)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=380097)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=380097)     return self._linear_fn(
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=380097)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=380097)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=380097)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=380097)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=380097)     return fn(input, L)
(EngineCore_DP0 pid=380097)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=380097)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=380097)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=380097)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=380097)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=380097)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=380097)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=380097)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=380097)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=380097)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=380097)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=380097)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=380097)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=380097)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=380097)     raise PTXASError(error)
(EngineCore_DP0 pid=380097) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=380097) `ptxas` stderr:
(EngineCore_DP0 pid=380097) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=380097) 
(EngineCore_DP0 pid=380097) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpbnjk4nbv.ptx -o /tmp/tmpbnjk4nbv.ptx.o
(EngineCore_DP0 pid=380097) 
[rank0]:[W125 19:54:20.992223254 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 19:54:22
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:54:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:54:48 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=381178) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=381178) 
(EngineCore_DP0 pid=381178) 
(EngineCore_DP0 pid=381178) ================================================================
(EngineCore_DP0 pid=381178) Internal Triton PTX codegen error
(EngineCore_DP0 pid=381178) `ptxas` stderr:
(EngineCore_DP0 pid=381178) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=381178) 
(EngineCore_DP0 pid=381178) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp582tq32n.ptx -o /tmp/tmp582tq32n.ptx.o
(EngineCore_DP0 pid=381178) 
(EngineCore_DP0 pid=381178) 
(EngineCore_DP0 pid=381178) //
(EngineCore_DP0 pid=381178) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=381178) //
(EngineCore_DP0 pid=381178) 
(EngineCore_DP0 pid=381178) .version 8.7
(EngineCore_DP0 pid=381178) .target sm_121a
(EngineCore_DP0 pid=381178) .address_size 64
(EngineCore_DP0 pid=381178) 
(EngineCore_DP0 pid=381178) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=381178) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=381178)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=381178) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=381178) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=381178) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=381178) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=381178) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=381178) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=381178) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=381178) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=381178) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=381178) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=381178) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=381178) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=381178) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=381178) )
(EngineCore_DP0 pid=381178) .reqntid 512
(EngineCore_DP0 pid=381178) {
(EngineCore_DP0 pid=381178) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=381178) 	.reg .b16 	%rs<40>;
(EngineCore_DP0 pid=381178) 	.reg .b32 	%r<172>;
(EngineCore_DP0 pid=381178) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=381178) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=381178) $L__func_begin0:
(EngineCore_DP0 pid=381178) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=381178) 
(EngineCore_DP0 pid=381178) // %bb.0:
(EngineCore_DP0 pid=381178) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=381178) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=381178) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=381178) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=381178) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=381178) $L__tmp0:
(EngineCore_DP0 pid=381178) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=381178) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=381178) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=381178) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=381178) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=381178) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=381178) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=381178) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=381178) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=381178) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=381178) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=381178) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=381178) 	mov.b32 	%r170, 0f2B8CBCCC;
(EngineCore_DP0 pid=381178) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=381178) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=381178) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=381178) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=381178) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=381178) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=381178) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=381178) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=381178) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=381178) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=381178) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=381178) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=381178) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=381178) 	mov.b32 	%r168, 0f00000000;
(EngineCore_DP0 pid=381178) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=381178) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=381178) 	mov.b32 	%r169, %r45;
(EngineCore_DP0 pid=381178) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=381178) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=381178) 	add.s32 	%r55, %r4, %r169;
(EngineCore_DP0 pid=381178) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=381178) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=381178) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=381178) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=381178) 	// begin inline asm
(EngineCore_DP0 pid=381178) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=381178) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=381178) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=381178) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=381178) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=381178) 	// end inline asm
(EngineCore_DP0 pid=381178) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=381178) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=381178) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=381178) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=381178) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=381178) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=381178) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=381178) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=381178) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=381178) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=381178) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=381178) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=381178) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=381178) $L__tmp1:
(EngineCore_DP0 pid=381178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	bar.sync 	0;
(EngineCore_DP0 pid=381178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=381178) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=381178) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=381178) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=381178) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=381178) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=381178) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=381178) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=381178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=381178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=381178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=381178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=381178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=381178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=381178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=381178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=381178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=381178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=381178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	// begin inline asm
(EngineCore_DP0 pid=381178) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=381178) 	// end inline asm
(EngineCore_DP0 pid=381178) 	bar.sync 	0;
(EngineCore_DP0 pid=381178) 	// begin inline asm
(EngineCore_DP0 pid=381178) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=381178) 	// end inline asm
(EngineCore_DP0 pid=381178) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=381178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=381178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=381178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=381178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=381178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=381178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=381178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=381178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=381178) 	// begin inline asm
(EngineCore_DP0 pid=381178) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=381178) 	// end inline asm
(EngineCore_DP0 pid=381178) 	bar.sync 	0;
(EngineCore_DP0 pid=381178) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=381178) $L__tmp2:
(EngineCore_DP0 pid=381178) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=381178) 	max.f32 	%r168, %r168, %r73;
(EngineCore_DP0 pid=381178) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=381178) 	add.s32 	%r169, %r169, 4096;
(EngineCore_DP0 pid=381178) 	setp.lt.s32 	%p6, %r169, %r24;
(EngineCore_DP0 pid=381178) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=381178) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=381178) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=381178) 	max.f32 	%r170, %r168, 0f2B8CBCCC;
(EngineCore_DP0 pid=381178) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=381178) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=381178) 	mov.b32 	%r75, 0f42FE0000;
(EngineCore_DP0 pid=381178) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=381178) 	div.full.f32 	%r76, %r170, %r75;
(EngineCore_DP0 pid=381178) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=381178) 	max.f32 	%r74, %r76, 0f37810204;
(EngineCore_DP0 pid=381178) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=381178) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=381178) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=381178) 	// begin inline asm
(EngineCore_DP0 pid=381178) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=381178) 	// end inline asm
(EngineCore_DP0 pid=381178) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=381178) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=381178) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=381178) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=381178) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=381178) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=381178) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=381178) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=381178) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=381178) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=381178) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=381178) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=381178) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=381178) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=381178) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=381178) 	div.full.f32 	%r14, %r75, %r170;
(EngineCore_DP0 pid=381178) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=381178) 	mov.b32 	%r171, 0;
(EngineCore_DP0 pid=381178) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=381178)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=381178) 	.loc	1 327 31                        // quant_slide_tuned_Llama3.2-3B.py:327:31
(EngineCore_DP0 pid=381178) 	add.s32 	%r80, %r16, %r171;
(EngineCore_DP0 pid=381178) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=381178) 	add.s32 	%r81, %r80, 1;
(EngineCore_DP0 pid=381178) 	setp.lt.s32 	%p17, %r80, %r15;
(EngineCore_DP0 pid=381178) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=381178) 	shr.s32 	%r82, %r80, 31;
(EngineCore_DP0 pid=381178) 	shr.u32 	%r83, %r82, 30;
(EngineCore_DP0 pid=381178) 	add.s32 	%r84, %r80, %r83;
(EngineCore_DP0 pid=381178) 	shr.s32 	%r85, %r84, 2;
(EngineCore_DP0 pid=381178) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=381178) 	shr.s32 	%r86, %r81, 31;
(EngineCore_DP0 pid=381178) 	shr.u32 	%r87, %r86, 30;
(EngineCore_DP0 pid=381178) 	add.s32 	%r88, %r81, %r87;
(EngineCore_DP0 pid=381178) 	and.b32 	%r89, %r88, 2147483644;
(EngineCore_DP0 pid=381178) 	sub.s32 	%r90, %r81, %r89;
(EngineCore_DP0 pid=381178) 	and.b32 	%r91, %r84, 2147483644;
(EngineCore_DP0 pid=381178) 	sub.s32 	%r92, %r80, %r91;
(EngineCore_DP0 pid=381178) 	.loc	1 333 22                        // quant_slide_tuned_Llama3.2-3B.py:333:22
(EngineCore_DP0 pid=381178) 	mul.lo.s32 	%r93, %r85, 10;
(EngineCore_DP0 pid=381178) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=381178) 	shl.b32 	%r94, %r92, 1;
(EngineCore_DP0 pid=381178) 	shl.b32 	%r95, %r90, 1;
(EngineCore_DP0 pid=381178) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=381178) 	add.s32 	%r96, %r93, %r95;
(EngineCore_DP0 pid=381178) 	add.s32 	%r97, %r93, %r94;
(EngineCore_DP0 pid=381178) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=381178) 	setp.lt.s32 	%p18, %r97, %r23;
(EngineCore_DP0 pid=381178) 	setp.lt.s32 	%p19, %r96, %r23;
(EngineCore_DP0 pid=381178) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=381178) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=381178) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=381178) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=381178) 	mad.wide.s32 	%rd8, %r97, 2, %rd1;
(EngineCore_DP0 pid=381178) 	mad.wide.s32 	%rd9, %r96, 2, %rd1;
(EngineCore_DP0 pid=381178) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=381178) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=381178) 	// begin inline asm
(EngineCore_DP0 pid=381178) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=381178) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=381178) 	// end inline asm
(EngineCore_DP0 pid=381178) 	// begin inline asm
(EngineCore_DP0 pid=381178) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=381178) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=381178) 	// end inline asm
(EngineCore_DP0 pid=381178) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=381178) 	cvt.f32.bf16 	%r98, %rs24;
(EngineCore_DP0 pid=381178) 	cvt.f32.bf16 	%r99, %rs26;
(EngineCore_DP0 pid=381178) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=381178) 	or.b32 	%r100, %r97, 1;
(EngineCore_DP0 pid=381178) 	or.b32 	%r101, %r96, 1;
(EngineCore_DP0 pid=381178) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=381178) 	setp.lt.s32 	%p20, %r100, %r23;
(EngineCore_DP0 pid=381178) 	setp.lt.s32 	%p21, %r101, %r23;
(EngineCore_DP0 pid=381178) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=381178) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=381178) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=381178) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=381178) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=381178) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=381178) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=381178) 	// begin inline asm
(EngineCore_DP0 pid=381178) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=381178) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=381178) 	// end inline asm
(EngineCore_DP0 pid=381178) 	// begin inline asm
(EngineCore_DP0 pid=381178) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=381178) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=381178) 	// end inline asm
(EngineCore_DP0 pid=381178) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=381178) 	cvt.f32.bf16 	%r102, %rs28;
(EngineCore_DP0 pid=381178) 	cvt.f32.bf16 	%r103, %rs30;
(EngineCore_DP0 pid=381178) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=381178) 	add.s32 	%r104, %r97, 2;
(EngineCore_DP0 pid=381178) 	add.s32 	%r105, %r96, 2;
(EngineCore_DP0 pid=381178) 	add.s32 	%r106, %r97, 3;
(EngineCore_DP0 pid=381178) 	add.s32 	%r107, %r96, 3;
(EngineCore_DP0 pid=381178) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=381178) 	setp.lt.s32 	%p22, %r107, %r23;
(EngineCore_DP0 pid=381178) 	setp.lt.s32 	%p23, %r106, %r23;
(EngineCore_DP0 pid=381178) 	setp.lt.s32 	%p24, %r105, %r23;
(EngineCore_DP0 pid=381178) 	setp.lt.s32 	%p25, %r104, %r23;
(EngineCore_DP0 pid=381178) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=381178) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=381178) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=381178) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=381178) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=381178) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=381178) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=381178) 	// begin inline asm
(EngineCore_DP0 pid=381178) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=381178) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=381178) 	// end inline asm
(EngineCore_DP0 pid=381178) 	// begin inline asm
(EngineCore_DP0 pid=381178) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=381178) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=381178) 	// end inline asm
(EngineCore_DP0 pid=381178) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=381178) 	cvt.f32.bf16 	%r108, %rs32;
(EngineCore_DP0 pid=381178) 	cvt.f32.bf16 	%r109, %rs34;
(EngineCore_DP0 pid=381178) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=381178) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=381178) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=381178) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=381178) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=381178) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=381178) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=381178) 	// begin inline asm
(EngineCore_DP0 pid=381178) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=381178) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=381178) 	// end inline asm
(EngineCore_DP0 pid=381178) 	// begin inline asm
(EngineCore_DP0 pid=381178) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=381178) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=381178) 	// end inline asm
(EngineCore_DP0 pid=381178) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=381178) 	cvt.f32.bf16 	%r110, %rs36;
(EngineCore_DP0 pid=381178) 	cvt.f32.bf16 	%r111, %rs38;
(EngineCore_DP0 pid=381178) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=381178) 	mul.f32 	%r112, %r14, %r98;
(EngineCore_DP0 pid=381178) 	mul.f32 	%r113, %r14, %r99;
(EngineCore_DP0 pid=381178) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=381178) 	cvt.rni.f32.f32 	%r114, %r112;
(EngineCore_DP0 pid=381178) 	cvt.rni.f32.f32 	%r115, %r113;
(EngineCore_DP0 pid=381178) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=381178) 	max.f32 	%r116, %r114, 0fC3000000;
(EngineCore_DP0 pid=381178) 	min.f32 	%r117, %r116, 0f42FE0000;
(EngineCore_DP0 pid=381178) 	max.f32 	%r118, %r115, 0fC3000000;
(EngineCore_DP0 pid=381178) 	min.f32 	%r119, %r118, 0f42FE0000;
(EngineCore_DP0 pid=381178) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=381178) 	cvt.rzi.s32.f32 	%r120, %r117;
(EngineCore_DP0 pid=381178) 	cvt.rzi.s32.f32 	%r121, %r119;
(EngineCore_DP0 pid=381178) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=381178) 	and.b32 	%r122, %r120, 255;
(EngineCore_DP0 pid=381178) 	and.b32 	%r123, %r121, 255;
(EngineCore_DP0 pid=381178) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=381178) 	mul.f32 	%r124, %r14, %r102;
(EngineCore_DP0 pid=381178) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=381178) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=381178) 	cvt.rni.f32.f32 	%r126, %r124;
(EngineCore_DP0 pid=381178) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=381178) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=381178) 	mul.f32 	%r128, %r14, %r108;
(EngineCore_DP0 pid=381178) 	mul.f32 	%r129, %r14, %r109;
(EngineCore_DP0 pid=381178) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=381178) 	cvt.rni.f32.f32 	%r130, %r128;
(EngineCore_DP0 pid=381178) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=381178) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=381178) 	mul.f32 	%r132, %r14, %r110;
(EngineCore_DP0 pid=381178) 	mul.f32 	%r133, %r14, %r111;
(EngineCore_DP0 pid=381178) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=381178) 	cvt.rni.f32.f32 	%r134, %r132;
(EngineCore_DP0 pid=381178) 	cvt.rni.f32.f32 	%r135, %r133;
(EngineCore_DP0 pid=381178) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=381178) 	max.f32 	%r136, %r134, 0fC3000000;
(EngineCore_DP0 pid=381178) 	min.f32 	%r137, %r136, 0f42FE0000;
(EngineCore_DP0 pid=381178) 	max.f32 	%r138, %r135, 0fC3000000;
(EngineCore_DP0 pid=381178) 	min.f32 	%r139, %r138, 0f42FE0000;
(EngineCore_DP0 pid=381178) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=381178) 	cvt.rzi.s32.f32 	%r140, %r137;
(EngineCore_DP0 pid=381178) 	cvt.rzi.s32.f32 	%r141, %r139;
(EngineCore_DP0 pid=381178) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=381178) 	max.f32 	%r142, %r130, 0fC3000000;
(EngineCore_DP0 pid=381178) 	max.f32 	%r143, %r126, 0fC3000000;
(EngineCore_DP0 pid=381178) 	min.f32 	%r144, %r143, 0f42FE0000;
(EngineCore_DP0 pid=381178) 	min.f32 	%r145, %r142, 0f42FE0000;
(EngineCore_DP0 pid=381178) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=381178) 	cvt.rzi.s32.f32 	%r146, %r145;
(EngineCore_DP0 pid=381178) 	cvt.rzi.s32.f32 	%r147, %r144;
(EngineCore_DP0 pid=381178) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=381178) 	shl.b32 	%r148, %r147, 8;
(EngineCore_DP0 pid=381178) 	shl.b32 	%r149, %r146, 16;
(EngineCore_DP0 pid=381178) 	and.b32 	%r150, %r149, 16711680;
(EngineCore_DP0 pid=381178) 	and.b32 	%r151, %r148, 65280;
(EngineCore_DP0 pid=381178) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=381178) 	or.b32 	%r152, %r151, %r122;
(EngineCore_DP0 pid=381178) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=381178) 	max.f32 	%r153, %r131, 0fC3000000;
(EngineCore_DP0 pid=381178) 	max.f32 	%r154, %r127, 0fC3000000;
(EngineCore_DP0 pid=381178) 	min.f32 	%r155, %r154, 0f42FE0000;
(EngineCore_DP0 pid=381178) 	min.f32 	%r156, %r153, 0f42FE0000;
(EngineCore_DP0 pid=381178) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=381178) 	cvt.rzi.s32.f32 	%r157, %r156;
(EngineCore_DP0 pid=381178) 	cvt.rzi.s32.f32 	%r158, %r155;
(EngineCore_DP0 pid=381178) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=381178) 	shl.b32 	%r159, %r158, 8;
(EngineCore_DP0 pid=381178) 	shl.b32 	%r160, %r157, 16;
(EngineCore_DP0 pid=381178) 	and.b32 	%r161, %r160, 16711680;
(EngineCore_DP0 pid=381178) 	and.b32 	%r162, %r159, 65280;
(EngineCore_DP0 pid=381178) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=381178) 	or.b32 	%r163, %r162, %r123;
(EngineCore_DP0 pid=381178) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=381178) 	or.b32 	%r164, %r152, %r150;
(EngineCore_DP0 pid=381178) 	or.b32 	%r165, %r163, %r161;
(EngineCore_DP0 pid=381178) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=381178) 	shl.b32 	%r166, %r140, 24;
(EngineCore_DP0 pid=381178) 	shl.b32 	%r167, %r141, 24;
(EngineCore_DP0 pid=381178) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=381178) 	or.b32 	%r78, %r164, %r166;
(EngineCore_DP0 pid=381178) 	or.b32 	%r79, %r165, %r167;
(EngineCore_DP0 pid=381178) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=381178) 	mad.wide.s32 	%rd16, %r80, 4, %rd2;
(EngineCore_DP0 pid=381178) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=381178) 	// begin inline asm
(EngineCore_DP0 pid=381178) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r78, %r79 };
(EngineCore_DP0 pid=381178) 	// end inline asm
(EngineCore_DP0 pid=381178) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=381178) 	add.s32 	%r171, %r171, 1024;
(EngineCore_DP0 pid=381178) 	setp.lt.s32 	%p26, %r171, %r15;
(EngineCore_DP0 pid=381178) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=381178) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=381178) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=381178) 	ret;
(EngineCore_DP0 pid=381178) $L__tmp3:
(EngineCore_DP0 pid=381178) $L__func_end0:
(EngineCore_DP0 pid=381178)                                         // -- End function
(EngineCore_DP0 pid=381178) }
(EngineCore_DP0 pid=381178) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=381178) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=381178) 	.section	.debug_abbrev
(EngineCore_DP0 pid=381178) 	{
(EngineCore_DP0 pid=381178) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=381178) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=381178) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=381178) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=381178) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=381178) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=381178) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=381178) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=381178) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=381178) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=381178) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=381178) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=381178) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=381178) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=381178) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=381178) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=381178) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=381178) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=381178) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=381178) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=381178) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=381178) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=381178) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=381178) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=381178) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=381178) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=381178) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=381178) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=381178) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=381178) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=381178) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=381178) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=381178) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=381178) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=381178) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=381178) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=381178) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=381178) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=381178) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=381178) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=381178) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=381178) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=381178) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=381178) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=381178) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=381178) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=381178) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=381178) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=381178) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=381178) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=381178) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=381178) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=381178) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=381178) 	}
(EngineCore_DP0 pid=381178) 	.section	.debug_info
(EngineCore_DP0 pid=381178) 	{
(EngineCore_DP0 pid=381178) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=381178) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=381178) .b8 0
(EngineCore_DP0 pid=381178) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=381178) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=381178) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=381178) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=381178) .b8 114
(EngineCore_DP0 pid=381178) .b8 105
(EngineCore_DP0 pid=381178) .b8 116
(EngineCore_DP0 pid=381178) .b8 111
(EngineCore_DP0 pid=381178) .b8 110
(EngineCore_DP0 pid=381178) .b8 0
(EngineCore_DP0 pid=381178) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=381178) .b8 0
(EngineCore_DP0 pid=381178) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=381178) .b8 117
(EngineCore_DP0 pid=381178) .b8 97
(EngineCore_DP0 pid=381178) .b8 110
(EngineCore_DP0 pid=381178) .b8 116
(EngineCore_DP0 pid=381178) .b8 95
(EngineCore_DP0 pid=381178) .b8 115
(EngineCore_DP0 pid=381178) .b8 108
(EngineCore_DP0 pid=381178) .b8 105
(EngineCore_DP0 pid=381178) .b8 100
(EngineCore_DP0 pid=381178) .b8 101
(EngineCore_DP0 pid=381178) .b8 95
(EngineCore_DP0 pid=381178) .b8 116
(EngineCore_DP0 pid=381178) .b8 117
(EngineCore_DP0 pid=381178) .b8 110
(EngineCore_DP0 pid=381178) .b8 101
(EngineCore_DP0 pid=381178) .b8 100
(EngineCore_DP0 pid=381178) .b8 95
(EngineCore_DP0 pid=381178) .b8 76
(EngineCore_DP0 pid=381178) .b8 108
(EngineCore_DP0 pid=381178) .b8 97
(EngineCore_DP0 pid=381178) .b8 109
(EngineCore_DP0 pid=381178) .b8 97
(EngineCore_DP0 pid=381178) .b8 51
(EngineCore_DP0 pid=381178) .b8 46
(EngineCore_DP0 pid=381178) .b8 50
(EngineCore_DP0 pid=381178) .b8 45
(EngineCore_DP0 pid=381178) .b8 51
(EngineCore_DP0 pid=381178) .b8 66
(EngineCore_DP0 pid=381178) .b8 46
(EngineCore_DP0 pid=381178) .b8 112
(EngineCore_DP0 pid=381178) .b8 121
(EngineCore_DP0 pid=381178) .b8 0
(EngineCore_DP0 pid=381178) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=381178) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=381178) .b8 114
(EngineCore_DP0 pid=381178) .b8 111
(EngineCore_DP0 pid=381178) .b8 111
(EngineCore_DP0 pid=381178) .b8 116
(EngineCore_DP0 pid=381178) .b8 47
(EngineCore_DP0 pid=381178) .b8 118
(EngineCore_DP0 pid=381178) .b8 108
(EngineCore_DP0 pid=381178) .b8 108
(EngineCore_DP0 pid=381178) .b8 109
(EngineCore_DP0 pid=381178) .b8 98
(EngineCore_DP0 pid=381178) .b8 101
(EngineCore_DP0 pid=381178) .b8 110
(EngineCore_DP0 pid=381178) .b8 99
(EngineCore_DP0 pid=381178) .b8 104
(EngineCore_DP0 pid=381178) .b8 47
(EngineCore_DP0 pid=381178) .b8 115
(EngineCore_DP0 pid=381178) .b8 108
(EngineCore_DP0 pid=381178) .b8 105
(EngineCore_DP0 pid=381178) .b8 100
(EngineCore_DP0 pid=381178) .b8 101
(EngineCore_DP0 pid=381178) .b8 115
(EngineCore_DP0 pid=381178) .b8 112
(EngineCore_DP0 pid=381178) .b8 97
(EngineCore_DP0 pid=381178) .b8 114
(EngineCore_DP0 pid=381178) .b8 115
(EngineCore_DP0 pid=381178) .b8 101
(EngineCore_DP0 pid=381178) .b8 47
(EngineCore_DP0 pid=381178) .b8 99
(EngineCore_DP0 pid=381178) .b8 115
(EngineCore_DP0 pid=381178) .b8 114
(EngineCore_DP0 pid=381178) .b8 99
(EngineCore_DP0 pid=381178) .b8 47
(EngineCore_DP0 pid=381178) .b8 102
(EngineCore_DP0 pid=381178) .b8 117
(EngineCore_DP0 pid=381178) .b8 115
(EngineCore_DP0 pid=381178) .b8 101
(EngineCore_DP0 pid=381178) .b8 100
(EngineCore_DP0 pid=381178) .b8 95
(EngineCore_DP0 pid=381178) .b8 113
(EngineCore_DP0 pid=381178) .b8 117
(EngineCore_DP0 pid=381178) .b8 97
(EngineCore_DP0 pid=381178) .b8 110
(EngineCore_DP0 pid=381178) .b8 116
(EngineCore_DP0 pid=381178) .b8 95
(EngineCore_DP0 pid=381178) .b8 115
(EngineCore_DP0 pid=381178) .b8 108
(EngineCore_DP0 pid=381178) .b8 105
(EngineCore_DP0 pid=381178) .b8 100
(EngineCore_DP0 pid=381178) .b8 101
(EngineCore_DP0 pid=381178) .b8 95
(EngineCore_DP0 pid=381178) .b8 116
(EngineCore_DP0 pid=381178) .b8 114
(EngineCore_DP0 pid=381178) .b8 105
(EngineCore_DP0 pid=381178) .b8 116
(EngineCore_DP0 pid=381178) .b8 111
(EngineCore_DP0 pid=381178) .b8 110
(EngineCore_DP0 pid=381178) .b8 47
(EngineCore_DP0 pid=381178) .b8 98
(EngineCore_DP0 pid=381178) .b8 117
(EngineCore_DP0 pid=381178) .b8 105
(EngineCore_DP0 pid=381178) .b8 108
(EngineCore_DP0 pid=381178) .b8 100
(EngineCore_DP0 pid=381178) .b8 47
(EngineCore_DP0 pid=381178) .b8 71
(EngineCore_DP0 pid=381178) .b8 66
(EngineCore_DP0 pid=381178) .b8 49
(EngineCore_DP0 pid=381178) .b8 48
(EngineCore_DP0 pid=381178) .b8 95
(EngineCore_DP0 pid=381178) .b8 99
(EngineCore_DP0 pid=381178) .b8 99
(EngineCore_DP0 pid=381178) .b8 49
(EngineCore_DP0 pid=381178) .b8 50
(EngineCore_DP0 pid=381178) .b8 49
(EngineCore_DP0 pid=381178) .b8 95
(EngineCore_DP0 pid=381178) .b8 112
(EngineCore_DP0 pid=381178) .b8 121
(EngineCore_DP0 pid=381178) .b8 51
(EngineCore_DP0 pid=381178) .b8 49
(EngineCore_DP0 pid=381178) .b8 50
(EngineCore_DP0 pid=381178) .b8 95
(EngineCore_DP0 pid=381178) .b8 99
(EngineCore_DP0 pid=381178) .b8 117
(EngineCore_DP0 pid=381178) .b8 49
(EngineCore_DP0 pid=381178) .b8 50
(EngineCore_DP0 pid=381178) .b8 57
(EngineCore_DP0 pid=381178) .b8 95
(EngineCore_DP0 pid=381178) .b8 97
(EngineCore_DP0 pid=381178) .b8 97
(EngineCore_DP0 pid=381178) .b8 114
(EngineCore_DP0 pid=381178) .b8 99
(EngineCore_DP0 pid=381178) .b8 104
(EngineCore_DP0 pid=381178) .b8 54
(EngineCore_DP0 pid=381178) .b8 52
(EngineCore_DP0 pid=381178) .b8 0
(EngineCore_DP0 pid=381178) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=381178) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=381178) .b8 113
(EngineCore_DP0 pid=381178) .b8 117
(EngineCore_DP0 pid=381178) .b8 97
(EngineCore_DP0 pid=381178) .b8 110
(EngineCore_DP0 pid=381178) .b8 116
(EngineCore_DP0 pid=381178) .b8 95
(EngineCore_DP0 pid=381178) .b8 115
(EngineCore_DP0 pid=381178) .b8 108
(EngineCore_DP0 pid=381178) .b8 105
(EngineCore_DP0 pid=381178) .b8 100
(EngineCore_DP0 pid=381178) .b8 101
(EngineCore_DP0 pid=381178) .b8 95
(EngineCore_DP0 pid=381178) .b8 105
(EngineCore_DP0 pid=381178) .b8 110
(EngineCore_DP0 pid=381178) .b8 116
(EngineCore_DP0 pid=381178) .b8 56
(EngineCore_DP0 pid=381178) .b8 95
(EngineCore_DP0 pid=381178) .b8 107
(EngineCore_DP0 pid=381178) .b8 101
(EngineCore_DP0 pid=381178) .b8 114
(EngineCore_DP0 pid=381178) .b8 110
(EngineCore_DP0 pid=381178) .b8 101
(EngineCore_DP0 pid=381178) .b8 108
(EngineCore_DP0 pid=381178) .b8 0
(EngineCore_DP0 pid=381178) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=381178) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=381178) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=381178) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=381178) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=381178) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=381178) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=381178) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=381178) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=381178) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=381178) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=381178) .b8 1
(EngineCore_DP0 pid=381178) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=381178) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=381178) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=381178) 	}
(EngineCore_DP0 pid=381178) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=381178) 
(EngineCore_DP0 pid=381178) ================================================================
(EngineCore_DP0 pid=381178) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=381178) 
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp582tq32n.ptx', '-o', '/tmp/tmp582tq32n.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866] 
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866] 
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866] 
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp582tq32n.ptx -o /tmp/tmp582tq32n.ptx.o
(EngineCore_DP0 pid=381178) ERROR 01-25 19:55:24 [core.py:866] 

STDERR:
[2026-01-25 19:54:48] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:54:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:54:48] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:54:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:54:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:54:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:54:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:54:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:54:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:54:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:54:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:54:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:54:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:54:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:54:51] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:54:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:54:51] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:54:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:54:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:54:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:54:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:54:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:54:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:54:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:54:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:54:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:54:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:54:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=381178) [2026-01-25 19:54:53] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=381178) [2026-01-25 19:54:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=381178) [2026-01-25 19:54:53] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=381178) [2026-01-25 19:54:53] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=381178) [2026-01-25 19:54:53] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=381178) [2026-01-25 19:54:53] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=381178) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=381178) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29<00:00, 29.21s/it]
(EngineCore_DP0 pid=381178) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29<00:00, 29.21s/it]
(EngineCore_DP0 pid=381178) 
(EngineCore_DP0 pid=381178) [2026-01-25 19:55:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=381178) [2026-01-25 19:55:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=381178) [2026-01-25 19:55:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=381178) [2026-01-25 19:55:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=381178) [2026-01-25 19:55:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=381178) [2026-01-25 19:55:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=381178) [2026-01-25 19:55:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=381178) [2026-01-25 19:55:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=381178) Process EngineCore_DP0:
(EngineCore_DP0 pid=381178) Traceback (most recent call last):
(EngineCore_DP0 pid=381178)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=381178)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=381178)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=381178)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=381178) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp582tq32n.ptx', '-o', '/tmp/tmp582tq32n.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=381178) 
(EngineCore_DP0 pid=381178) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=381178) 
(EngineCore_DP0 pid=381178) Traceback (most recent call last):
(EngineCore_DP0 pid=381178)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=381178)     self.run()
(EngineCore_DP0 pid=381178)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=381178)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=381178)     raise e
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=381178)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=381178)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=381178)     super().__init__(
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=381178)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=381178)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=381178)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=381178)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=381178)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=381178)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=381178)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=381178)     return func(*args, **kwargs)
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=381178)     return func(*args, **kwargs)
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=381178)     self.model_runner.profile_run()
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=381178)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=381178)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=381178)     return func(*args, **kwargs)
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=381178)     outputs = self.model(
(EngineCore_DP0 pid=381178)               ^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=381178)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=381178)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=381178)     model_output = self.model(
(EngineCore_DP0 pid=381178)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=381178)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=381178)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=381178)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=381178)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=381178)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=381178)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=381178)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=381178)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=381178)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=381178)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=381178)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=381178)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=381178)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=381178)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=381178)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=381178)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=381178)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=381178)     return self._linear_fn(
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=381178)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=381178)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=381178)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=381178)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=381178)     return fn(input, L)
(EngineCore_DP0 pid=381178)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=381178)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=381178)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=381178)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=381178)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=381178)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=381178)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=381178)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=381178)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=381178)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=381178)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=381178)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=381178)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=381178)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=381178)     raise PTXASError(error)
(EngineCore_DP0 pid=381178) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=381178) `ptxas` stderr:
(EngineCore_DP0 pid=381178) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=381178) 
(EngineCore_DP0 pid=381178) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp582tq32n.ptx -o /tmp/tmp582tq32n.ptx.o
(EngineCore_DP0 pid=381178) 
[rank0]:[W125 19:55:25.396808649 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-25 20:57:46
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:57:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:57:50 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=447506) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=447506) 
(EngineCore_DP0 pid=447506) 
(EngineCore_DP0 pid=447506) ================================================================
(EngineCore_DP0 pid=447506) Internal Triton PTX codegen error
(EngineCore_DP0 pid=447506) `ptxas` stderr:
(EngineCore_DP0 pid=447506) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=447506) 
(EngineCore_DP0 pid=447506) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmppjeh84qs.ptx -o /tmp/tmppjeh84qs.ptx.o
(EngineCore_DP0 pid=447506) 
(EngineCore_DP0 pid=447506) 
(EngineCore_DP0 pid=447506) //
(EngineCore_DP0 pid=447506) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=447506) //
(EngineCore_DP0 pid=447506) 
(EngineCore_DP0 pid=447506) .version 8.7
(EngineCore_DP0 pid=447506) .target sm_121a
(EngineCore_DP0 pid=447506) .address_size 64
(EngineCore_DP0 pid=447506) 
(EngineCore_DP0 pid=447506) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=447506) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=447506)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=447506) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=447506) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=447506) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=447506) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=447506) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=447506) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=447506) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=447506) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=447506) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=447506) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=447506) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=447506) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=447506) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=447506) )
(EngineCore_DP0 pid=447506) .reqntid 1024
(EngineCore_DP0 pid=447506) {
(EngineCore_DP0 pid=447506) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=447506) 	.reg .b16 	%rs<20>;
(EngineCore_DP0 pid=447506) 	.reg .b32 	%r<120>;
(EngineCore_DP0 pid=447506) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=447506) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=447506) $L__func_begin0:
(EngineCore_DP0 pid=447506) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=447506) 
(EngineCore_DP0 pid=447506) // %bb.0:
(EngineCore_DP0 pid=447506) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=447506) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=447506) 	ld.param.b32 	%r17, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=447506) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=447506) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=447506) $L__tmp0:
(EngineCore_DP0 pid=447506) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=447506) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=447506) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=447506) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=447506) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=447506) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=447506) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=447506) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=447506) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=447506) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=447506) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=447506) 	mov.b32 	%r118, 0f2B8CBCCC;
(EngineCore_DP0 pid=447506) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=447506) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=447506) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=447506) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=447506) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=447506) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=447506) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=447506) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=447506) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=447506) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=447506) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=447506) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=447506) 	mov.b32 	%r116, 0f00000000;
(EngineCore_DP0 pid=447506) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=447506) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=447506) 	mov.b32 	%r117, %r37;
(EngineCore_DP0 pid=447506) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=447506) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=447506) 	add.s32 	%r45, %r3, %r117;
(EngineCore_DP0 pid=447506) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=447506) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=447506) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=447506) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=447506) 	// begin inline asm
(EngineCore_DP0 pid=447506) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=447506) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=447506) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=447506) 	// end inline asm
(EngineCore_DP0 pid=447506) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=447506) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=447506) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=447506) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=447506) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=447506) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=447506) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=447506) $L__tmp1:
(EngineCore_DP0 pid=447506) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	bar.sync 	0;
(EngineCore_DP0 pid=447506) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=447506) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=447506) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=447506) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=447506) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=447506) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=447506) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=447506) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=447506) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=447506) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=447506) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=447506) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=447506) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=447506) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=447506) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	// begin inline asm
(EngineCore_DP0 pid=447506) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=447506) 	// end inline asm
(EngineCore_DP0 pid=447506) 	bar.sync 	0;
(EngineCore_DP0 pid=447506) 	// begin inline asm
(EngineCore_DP0 pid=447506) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=447506) 	// end inline asm
(EngineCore_DP0 pid=447506) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=447506) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=447506) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=447506) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=447506) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=447506) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=447506) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=447506) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=447506) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=447506) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=447506) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=447506) 	// begin inline asm
(EngineCore_DP0 pid=447506) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=447506) 	// end inline asm
(EngineCore_DP0 pid=447506) 	bar.sync 	0;
(EngineCore_DP0 pid=447506) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=447506) $L__tmp2:
(EngineCore_DP0 pid=447506) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=447506) 	max.f32 	%r116, %r116, %r65;
(EngineCore_DP0 pid=447506) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=447506) 	add.s32 	%r117, %r117, 4096;
(EngineCore_DP0 pid=447506) 	setp.lt.s32 	%p6, %r117, %r18;
(EngineCore_DP0 pid=447506) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=447506) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=447506) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=447506) 	max.f32 	%r118, %r116, 0f2B8CBCCC;
(EngineCore_DP0 pid=447506) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=447506) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=447506) 	mov.b32 	%r67, 0f42FE0000;
(EngineCore_DP0 pid=447506) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=447506) 	div.full.f32 	%r68, %r118, %r67;
(EngineCore_DP0 pid=447506) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=447506) 	max.f32 	%r66, %r68, 0f37810204;
(EngineCore_DP0 pid=447506) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=447506) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=447506) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=447506) 	// begin inline asm
(EngineCore_DP0 pid=447506) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=447506) 	// end inline asm
(EngineCore_DP0 pid=447506) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=447506) 	shl.b32 	%r14, %r19, 2;
(EngineCore_DP0 pid=447506) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=447506) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=447506) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=447506) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=447506) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=447506) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=447506) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=447506) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=447506) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=447506) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=447506) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=447506) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=447506) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=447506) 	div.full.f32 	%r13, %r67, %r118;
(EngineCore_DP0 pid=447506) 	mov.b32 	%r119, 0;
(EngineCore_DP0 pid=447506) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=447506)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=447506) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=447506) 	add.s32 	%r72, %r2, %r119;
(EngineCore_DP0 pid=447506) 	setp.lt.s32 	%p13, %r72, %r14;
(EngineCore_DP0 pid=447506) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=447506) 	shr.s32 	%r73, %r72, 31;
(EngineCore_DP0 pid=447506) 	shr.u32 	%r74, %r73, 30;
(EngineCore_DP0 pid=447506) 	add.s32 	%r75, %r72, %r74;
(EngineCore_DP0 pid=447506) 	shr.s32 	%r76, %r75, 2;
(EngineCore_DP0 pid=447506) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=447506) 	and.b32 	%r77, %r75, 2147483644;
(EngineCore_DP0 pid=447506) 	sub.s32 	%r78, %r72, %r77;
(EngineCore_DP0 pid=447506) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=447506) 	shl.b32 	%r79, %r78, 1;
(EngineCore_DP0 pid=447506) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=447506) 	mad.lo.s32 	%r80, %r76, 10, %r79;
(EngineCore_DP0 pid=447506) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=447506) 	setp.lt.s32 	%p14, %r80, %r17;
(EngineCore_DP0 pid=447506) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=447506) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=447506) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=447506) 	mad.wide.s32 	%rd8, %r80, 2, %rd1;
(EngineCore_DP0 pid=447506) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=447506) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=447506) 	// begin inline asm
(EngineCore_DP0 pid=447506) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=447506) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=447506) 	// end inline asm
(EngineCore_DP0 pid=447506) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=447506) 	cvt.f32.bf16 	%r81, %rs12;
(EngineCore_DP0 pid=447506) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=447506) 	or.b32 	%r82, %r80, 1;
(EngineCore_DP0 pid=447506) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=447506) 	setp.lt.s32 	%p15, %r82, %r17;
(EngineCore_DP0 pid=447506) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=447506) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=447506) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=447506) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=447506) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=447506) 	// begin inline asm
(EngineCore_DP0 pid=447506) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=447506) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=447506) 	// end inline asm
(EngineCore_DP0 pid=447506) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=447506) 	cvt.f32.bf16 	%r83, %rs14;
(EngineCore_DP0 pid=447506) 	.loc	1 292 48                        // quant_slide_tuned_Qwen2.5-7B.py:292:48
(EngineCore_DP0 pid=447506) 	add.s32 	%r84, %r80, 2;
(EngineCore_DP0 pid=447506) 	.loc	1 292 53                        // quant_slide_tuned_Qwen2.5-7B.py:292:53
(EngineCore_DP0 pid=447506) 	setp.lt.s32 	%p16, %r84, %r17;
(EngineCore_DP0 pid=447506) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=447506) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=447506) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=447506) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=447506) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=447506) 	// begin inline asm
(EngineCore_DP0 pid=447506) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=447506) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=447506) 	// end inline asm
(EngineCore_DP0 pid=447506) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=447506) 	cvt.f32.bf16 	%r85, %rs16;
(EngineCore_DP0 pid=447506) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=447506) 	add.s32 	%r86, %r80, 3;
(EngineCore_DP0 pid=447506) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=447506) 	setp.lt.s32 	%p17, %r86, %r17;
(EngineCore_DP0 pid=447506) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=447506) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=447506) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=447506) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=447506) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=447506) 	// begin inline asm
(EngineCore_DP0 pid=447506) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=447506) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=447506) 	// end inline asm
(EngineCore_DP0 pid=447506) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=447506) 	cvt.f32.bf16 	%r87, %rs18;
(EngineCore_DP0 pid=447506) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=447506) 	mul.f32 	%r88, %r13, %r81;
(EngineCore_DP0 pid=447506) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=447506) 	cvt.rni.f32.f32 	%r89, %r88;
(EngineCore_DP0 pid=447506) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=447506) 	max.f32 	%r90, %r89, 0fC3000000;
(EngineCore_DP0 pid=447506) 	min.f32 	%r91, %r90, 0f42FE0000;
(EngineCore_DP0 pid=447506) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=447506) 	cvt.rzi.s32.f32 	%r92, %r91;
(EngineCore_DP0 pid=447506) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=447506) 	and.b32 	%r93, %r92, 255;
(EngineCore_DP0 pid=447506) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=447506) 	mul.f32 	%r94, %r13, %r83;
(EngineCore_DP0 pid=447506) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=447506) 	cvt.rni.f32.f32 	%r95, %r94;
(EngineCore_DP0 pid=447506) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=447506) 	mul.f32 	%r96, %r13, %r85;
(EngineCore_DP0 pid=447506) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=447506) 	cvt.rni.f32.f32 	%r97, %r96;
(EngineCore_DP0 pid=447506) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=447506) 	mul.f32 	%r98, %r13, %r87;
(EngineCore_DP0 pid=447506) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=447506) 	cvt.rni.f32.f32 	%r99, %r98;
(EngineCore_DP0 pid=447506) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=447506) 	max.f32 	%r100, %r99, 0fC3000000;
(EngineCore_DP0 pid=447506) 	min.f32 	%r101, %r100, 0f42FE0000;
(EngineCore_DP0 pid=447506) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=447506) 	cvt.rzi.s32.f32 	%r102, %r101;
(EngineCore_DP0 pid=447506) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=447506) 	max.f32 	%r103, %r97, 0fC3000000;
(EngineCore_DP0 pid=447506) 	max.f32 	%r104, %r95, 0fC3000000;
(EngineCore_DP0 pid=447506) 	min.f32 	%r105, %r104, 0f42FE0000;
(EngineCore_DP0 pid=447506) 	min.f32 	%r106, %r103, 0f42FE0000;
(EngineCore_DP0 pid=447506) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=447506) 	cvt.rzi.s32.f32 	%r107, %r106;
(EngineCore_DP0 pid=447506) 	cvt.rzi.s32.f32 	%r108, %r105;
(EngineCore_DP0 pid=447506) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=447506) 	shl.b32 	%r109, %r108, 8;
(EngineCore_DP0 pid=447506) 	shl.b32 	%r110, %r107, 16;
(EngineCore_DP0 pid=447506) 	and.b32 	%r111, %r110, 16711680;
(EngineCore_DP0 pid=447506) 	and.b32 	%r112, %r109, 65280;
(EngineCore_DP0 pid=447506) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=447506) 	or.b32 	%r113, %r112, %r93;
(EngineCore_DP0 pid=447506) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=447506) 	or.b32 	%r114, %r113, %r111;
(EngineCore_DP0 pid=447506) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=447506) 	shl.b32 	%r115, %r102, 24;
(EngineCore_DP0 pid=447506) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=447506) 	or.b32 	%r70, %r114, %r115;
(EngineCore_DP0 pid=447506) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=447506) 	mad.wide.s32 	%rd12, %r72, 4, %rd2;
(EngineCore_DP0 pid=447506) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=447506) 	// begin inline asm
(EngineCore_DP0 pid=447506) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r70 };
(EngineCore_DP0 pid=447506) 	// end inline asm
(EngineCore_DP0 pid=447506) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=447506) 	add.s32 	%r119, %r119, 1024;
(EngineCore_DP0 pid=447506) 	setp.lt.s32 	%p18, %r119, %r14;
(EngineCore_DP0 pid=447506) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=447506) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=447506) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=447506) 	ret;
(EngineCore_DP0 pid=447506) $L__tmp3:
(EngineCore_DP0 pid=447506) $L__func_end0:
(EngineCore_DP0 pid=447506)                                         // -- End function
(EngineCore_DP0 pid=447506) }
(EngineCore_DP0 pid=447506) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=447506) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=447506) 	.section	.debug_abbrev
(EngineCore_DP0 pid=447506) 	{
(EngineCore_DP0 pid=447506) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=447506) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=447506) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=447506) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=447506) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=447506) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=447506) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=447506) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=447506) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=447506) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=447506) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=447506) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=447506) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=447506) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=447506) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=447506) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=447506) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=447506) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=447506) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=447506) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=447506) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=447506) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=447506) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=447506) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=447506) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=447506) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=447506) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=447506) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=447506) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=447506) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=447506) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=447506) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=447506) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=447506) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=447506) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=447506) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=447506) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=447506) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=447506) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=447506) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=447506) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=447506) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=447506) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=447506) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=447506) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=447506) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=447506) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=447506) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=447506) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=447506) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=447506) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=447506) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=447506) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=447506) 	}
(EngineCore_DP0 pid=447506) 	.section	.debug_info
(EngineCore_DP0 pid=447506) 	{
(EngineCore_DP0 pid=447506) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=447506) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=447506) .b8 0
(EngineCore_DP0 pid=447506) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=447506) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=447506) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=447506) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=447506) .b8 114
(EngineCore_DP0 pid=447506) .b8 105
(EngineCore_DP0 pid=447506) .b8 116
(EngineCore_DP0 pid=447506) .b8 111
(EngineCore_DP0 pid=447506) .b8 110
(EngineCore_DP0 pid=447506) .b8 0
(EngineCore_DP0 pid=447506) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=447506) .b8 0
(EngineCore_DP0 pid=447506) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=447506) .b8 117
(EngineCore_DP0 pid=447506) .b8 97
(EngineCore_DP0 pid=447506) .b8 110
(EngineCore_DP0 pid=447506) .b8 116
(EngineCore_DP0 pid=447506) .b8 95
(EngineCore_DP0 pid=447506) .b8 115
(EngineCore_DP0 pid=447506) .b8 108
(EngineCore_DP0 pid=447506) .b8 105
(EngineCore_DP0 pid=447506) .b8 100
(EngineCore_DP0 pid=447506) .b8 101
(EngineCore_DP0 pid=447506) .b8 95
(EngineCore_DP0 pid=447506) .b8 116
(EngineCore_DP0 pid=447506) .b8 117
(EngineCore_DP0 pid=447506) .b8 110
(EngineCore_DP0 pid=447506) .b8 101
(EngineCore_DP0 pid=447506) .b8 100
(EngineCore_DP0 pid=447506) .b8 95
(EngineCore_DP0 pid=447506) .b8 81
(EngineCore_DP0 pid=447506) .b8 119
(EngineCore_DP0 pid=447506) .b8 101
(EngineCore_DP0 pid=447506) .b8 110
(EngineCore_DP0 pid=447506) .b8 50
(EngineCore_DP0 pid=447506) .b8 46
(EngineCore_DP0 pid=447506) .b8 53
(EngineCore_DP0 pid=447506) .b8 45
(EngineCore_DP0 pid=447506) .b8 55
(EngineCore_DP0 pid=447506) .b8 66
(EngineCore_DP0 pid=447506) .b8 46
(EngineCore_DP0 pid=447506) .b8 112
(EngineCore_DP0 pid=447506) .b8 121
(EngineCore_DP0 pid=447506) .b8 0
(EngineCore_DP0 pid=447506) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=447506) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=447506) .b8 114
(EngineCore_DP0 pid=447506) .b8 111
(EngineCore_DP0 pid=447506) .b8 111
(EngineCore_DP0 pid=447506) .b8 116
(EngineCore_DP0 pid=447506) .b8 47
(EngineCore_DP0 pid=447506) .b8 118
(EngineCore_DP0 pid=447506) .b8 108
(EngineCore_DP0 pid=447506) .b8 108
(EngineCore_DP0 pid=447506) .b8 109
(EngineCore_DP0 pid=447506) .b8 98
(EngineCore_DP0 pid=447506) .b8 101
(EngineCore_DP0 pid=447506) .b8 110
(EngineCore_DP0 pid=447506) .b8 99
(EngineCore_DP0 pid=447506) .b8 104
(EngineCore_DP0 pid=447506) .b8 47
(EngineCore_DP0 pid=447506) .b8 115
(EngineCore_DP0 pid=447506) .b8 108
(EngineCore_DP0 pid=447506) .b8 105
(EngineCore_DP0 pid=447506) .b8 100
(EngineCore_DP0 pid=447506) .b8 101
(EngineCore_DP0 pid=447506) .b8 115
(EngineCore_DP0 pid=447506) .b8 112
(EngineCore_DP0 pid=447506) .b8 97
(EngineCore_DP0 pid=447506) .b8 114
(EngineCore_DP0 pid=447506) .b8 115
(EngineCore_DP0 pid=447506) .b8 101
(EngineCore_DP0 pid=447506) .b8 47
(EngineCore_DP0 pid=447506) .b8 99
(EngineCore_DP0 pid=447506) .b8 115
(EngineCore_DP0 pid=447506) .b8 114
(EngineCore_DP0 pid=447506) .b8 99
(EngineCore_DP0 pid=447506) .b8 47
(EngineCore_DP0 pid=447506) .b8 102
(EngineCore_DP0 pid=447506) .b8 117
(EngineCore_DP0 pid=447506) .b8 115
(EngineCore_DP0 pid=447506) .b8 101
(EngineCore_DP0 pid=447506) .b8 100
(EngineCore_DP0 pid=447506) .b8 95
(EngineCore_DP0 pid=447506) .b8 113
(EngineCore_DP0 pid=447506) .b8 117
(EngineCore_DP0 pid=447506) .b8 97
(EngineCore_DP0 pid=447506) .b8 110
(EngineCore_DP0 pid=447506) .b8 116
(EngineCore_DP0 pid=447506) .b8 95
(EngineCore_DP0 pid=447506) .b8 115
(EngineCore_DP0 pid=447506) .b8 108
(EngineCore_DP0 pid=447506) .b8 105
(EngineCore_DP0 pid=447506) .b8 100
(EngineCore_DP0 pid=447506) .b8 101
(EngineCore_DP0 pid=447506) .b8 95
(EngineCore_DP0 pid=447506) .b8 116
(EngineCore_DP0 pid=447506) .b8 114
(EngineCore_DP0 pid=447506) .b8 105
(EngineCore_DP0 pid=447506) .b8 116
(EngineCore_DP0 pid=447506) .b8 111
(EngineCore_DP0 pid=447506) .b8 110
(EngineCore_DP0 pid=447506) .b8 47
(EngineCore_DP0 pid=447506) .b8 98
(EngineCore_DP0 pid=447506) .b8 117
(EngineCore_DP0 pid=447506) .b8 105
(EngineCore_DP0 pid=447506) .b8 108
(EngineCore_DP0 pid=447506) .b8 100
(EngineCore_DP0 pid=447506) .b8 47
(EngineCore_DP0 pid=447506) .b8 71
(EngineCore_DP0 pid=447506) .b8 66
(EngineCore_DP0 pid=447506) .b8 49
(EngineCore_DP0 pid=447506) .b8 48
(EngineCore_DP0 pid=447506) .b8 95
(EngineCore_DP0 pid=447506) .b8 99
(EngineCore_DP0 pid=447506) .b8 99
(EngineCore_DP0 pid=447506) .b8 49
(EngineCore_DP0 pid=447506) .b8 50
(EngineCore_DP0 pid=447506) .b8 49
(EngineCore_DP0 pid=447506) .b8 95
(EngineCore_DP0 pid=447506) .b8 112
(EngineCore_DP0 pid=447506) .b8 121
(EngineCore_DP0 pid=447506) .b8 51
(EngineCore_DP0 pid=447506) .b8 49
(EngineCore_DP0 pid=447506) .b8 50
(EngineCore_DP0 pid=447506) .b8 95
(EngineCore_DP0 pid=447506) .b8 99
(EngineCore_DP0 pid=447506) .b8 117
(EngineCore_DP0 pid=447506) .b8 49
(EngineCore_DP0 pid=447506) .b8 50
(EngineCore_DP0 pid=447506) .b8 57
(EngineCore_DP0 pid=447506) .b8 95
(EngineCore_DP0 pid=447506) .b8 97
(EngineCore_DP0 pid=447506) .b8 97
(EngineCore_DP0 pid=447506) .b8 114
(EngineCore_DP0 pid=447506) .b8 99
(EngineCore_DP0 pid=447506) .b8 104
(EngineCore_DP0 pid=447506) .b8 54
(EngineCore_DP0 pid=447506) .b8 52
(EngineCore_DP0 pid=447506) .b8 0
(EngineCore_DP0 pid=447506) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=447506) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=447506) .b8 113
(EngineCore_DP0 pid=447506) .b8 117
(EngineCore_DP0 pid=447506) .b8 97
(EngineCore_DP0 pid=447506) .b8 110
(EngineCore_DP0 pid=447506) .b8 116
(EngineCore_DP0 pid=447506) .b8 95
(EngineCore_DP0 pid=447506) .b8 115
(EngineCore_DP0 pid=447506) .b8 108
(EngineCore_DP0 pid=447506) .b8 105
(EngineCore_DP0 pid=447506) .b8 100
(EngineCore_DP0 pid=447506) .b8 101
(EngineCore_DP0 pid=447506) .b8 95
(EngineCore_DP0 pid=447506) .b8 105
(EngineCore_DP0 pid=447506) .b8 110
(EngineCore_DP0 pid=447506) .b8 116
(EngineCore_DP0 pid=447506) .b8 56
(EngineCore_DP0 pid=447506) .b8 95
(EngineCore_DP0 pid=447506) .b8 107
(EngineCore_DP0 pid=447506) .b8 101
(EngineCore_DP0 pid=447506) .b8 114
(EngineCore_DP0 pid=447506) .b8 110
(EngineCore_DP0 pid=447506) .b8 101
(EngineCore_DP0 pid=447506) .b8 108
(EngineCore_DP0 pid=447506) .b8 0
(EngineCore_DP0 pid=447506) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=447506) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=447506) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=447506) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=447506) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=447506) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=447506) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=447506) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=447506) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=447506) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=447506) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=447506) .b8 1
(EngineCore_DP0 pid=447506) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=447506) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=447506) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=447506) 	}
(EngineCore_DP0 pid=447506) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=447506) 
(EngineCore_DP0 pid=447506) ================================================================
(EngineCore_DP0 pid=447506) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=447506) 
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmppjeh84qs.ptx', '-o', '/tmp/tmppjeh84qs.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866] 
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866] 
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866] 
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmppjeh84qs.ptx -o /tmp/tmppjeh84qs.ptx.o
(EngineCore_DP0 pid=447506) ERROR 01-25 20:59:04 [core.py:866] 

STDERR:
[2026-01-25 20:57:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:57:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:57:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:57:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:57:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:57:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:57:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:57:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:57:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:57:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:57:53] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:57:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:57:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:57:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:57:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:57:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:57:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=447506) [2026-01-25 20:57:54] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=447506) [2026-01-25 20:57:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=447506) [2026-01-25 20:57:54] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=447506) [2026-01-25 20:57:54] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=447506) [2026-01-25 20:57:54] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=447506) [2026-01-25 20:57:54] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=447506) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=447506) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.30s/it]
(EngineCore_DP0 pid=447506) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:06<00:00, 33.88s/it]
(EngineCore_DP0 pid=447506) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:06<00:00, 33.04s/it]
(EngineCore_DP0 pid=447506) 
(EngineCore_DP0 pid=447506) [2026-01-25 20:59:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=447506) [2026-01-25 20:59:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=447506) [2026-01-25 20:59:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=447506) [2026-01-25 20:59:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=447506) [2026-01-25 20:59:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=447506) [2026-01-25 20:59:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=447506) [2026-01-25 20:59:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=447506) [2026-01-25 20:59:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=447506) Process EngineCore_DP0:
(EngineCore_DP0 pid=447506) Traceback (most recent call last):
(EngineCore_DP0 pid=447506)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=447506)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=447506)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=447506)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=447506) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmppjeh84qs.ptx', '-o', '/tmp/tmppjeh84qs.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=447506) 
(EngineCore_DP0 pid=447506) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=447506) 
(EngineCore_DP0 pid=447506) Traceback (most recent call last):
(EngineCore_DP0 pid=447506)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=447506)     self.run()
(EngineCore_DP0 pid=447506)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=447506)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=447506)     raise e
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=447506)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=447506)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=447506)     super().__init__(
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=447506)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=447506)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=447506)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=447506)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=447506)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=447506)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=447506)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=447506)     return func(*args, **kwargs)
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=447506)     return func(*args, **kwargs)
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=447506)     self.model_runner.profile_run()
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=447506)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=447506)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=447506)     return func(*args, **kwargs)
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=447506)     outputs = self.model(
(EngineCore_DP0 pid=447506)               ^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=447506)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=447506)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=447506)     hidden_states = self.model(
(EngineCore_DP0 pid=447506)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=447506)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=447506)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=447506)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=447506)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=447506)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=447506)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=447506)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=447506)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=447506)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=447506)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=447506)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=447506)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=447506)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=447506)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=447506)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=447506)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=447506)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=447506)     return self._linear_fn(
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=447506)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=447506)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=447506)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=447506)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=447506)     return fn(input, L)
(EngineCore_DP0 pid=447506)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=447506)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=447506)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=447506)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=447506)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=447506)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=447506)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=447506)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=447506)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=447506)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=447506)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=447506)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=447506)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=447506)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=447506)     raise PTXASError(error)
(EngineCore_DP0 pid=447506) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=447506) `ptxas` stderr:
(EngineCore_DP0 pid=447506) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=447506) 
(EngineCore_DP0 pid=447506) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmppjeh84qs.ptx -o /tmp/tmppjeh84qs.ptx.o
(EngineCore_DP0 pid=447506) 
[rank0]:[W125 20:59:04.964930854 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 20:59:06
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:59:10 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:59:10 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=448801) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=448801) 
(EngineCore_DP0 pid=448801) 
(EngineCore_DP0 pid=448801) ================================================================
(EngineCore_DP0 pid=448801) Internal Triton PTX codegen error
(EngineCore_DP0 pid=448801) `ptxas` stderr:
(EngineCore_DP0 pid=448801) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=448801) 
(EngineCore_DP0 pid=448801) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpeubp0q9o.ptx -o /tmp/tmpeubp0q9o.ptx.o
(EngineCore_DP0 pid=448801) 
(EngineCore_DP0 pid=448801) 
(EngineCore_DP0 pid=448801) //
(EngineCore_DP0 pid=448801) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=448801) //
(EngineCore_DP0 pid=448801) 
(EngineCore_DP0 pid=448801) .version 8.7
(EngineCore_DP0 pid=448801) .target sm_121a
(EngineCore_DP0 pid=448801) .address_size 64
(EngineCore_DP0 pid=448801) 
(EngineCore_DP0 pid=448801) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=448801) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=448801)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=448801) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=448801) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=448801) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=448801) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=448801) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=448801) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=448801) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=448801) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=448801) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=448801) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=448801) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=448801) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=448801) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=448801) )
(EngineCore_DP0 pid=448801) .reqntid 512
(EngineCore_DP0 pid=448801) {
(EngineCore_DP0 pid=448801) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=448801) 	.reg .b16 	%rs<40>;
(EngineCore_DP0 pid=448801) 	.reg .b32 	%r<172>;
(EngineCore_DP0 pid=448801) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=448801) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=448801) $L__func_begin0:
(EngineCore_DP0 pid=448801) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=448801) 
(EngineCore_DP0 pid=448801) // %bb.0:
(EngineCore_DP0 pid=448801) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=448801) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=448801) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=448801) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=448801) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=448801) $L__tmp0:
(EngineCore_DP0 pid=448801) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=448801) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=448801) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=448801) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=448801) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=448801) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=448801) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=448801) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=448801) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=448801) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=448801) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=448801) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=448801) 	mov.b32 	%r170, 0f2B8CBCCC;
(EngineCore_DP0 pid=448801) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=448801) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=448801) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=448801) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=448801) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=448801) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=448801) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=448801) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=448801) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=448801) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=448801) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=448801) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=448801) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=448801) 	mov.b32 	%r168, 0f00000000;
(EngineCore_DP0 pid=448801) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=448801) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=448801) 	mov.b32 	%r169, %r45;
(EngineCore_DP0 pid=448801) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=448801) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=448801) 	add.s32 	%r55, %r4, %r169;
(EngineCore_DP0 pid=448801) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=448801) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=448801) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=448801) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=448801) 	// begin inline asm
(EngineCore_DP0 pid=448801) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=448801) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=448801) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=448801) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=448801) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=448801) 	// end inline asm
(EngineCore_DP0 pid=448801) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=448801) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=448801) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=448801) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=448801) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=448801) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=448801) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=448801) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=448801) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=448801) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=448801) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=448801) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=448801) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=448801) $L__tmp1:
(EngineCore_DP0 pid=448801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	bar.sync 	0;
(EngineCore_DP0 pid=448801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=448801) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=448801) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=448801) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=448801) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=448801) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=448801) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=448801) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=448801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=448801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=448801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=448801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=448801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=448801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=448801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=448801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=448801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=448801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=448801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	// begin inline asm
(EngineCore_DP0 pid=448801) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=448801) 	// end inline asm
(EngineCore_DP0 pid=448801) 	bar.sync 	0;
(EngineCore_DP0 pid=448801) 	// begin inline asm
(EngineCore_DP0 pid=448801) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=448801) 	// end inline asm
(EngineCore_DP0 pid=448801) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=448801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=448801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=448801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=448801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=448801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=448801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=448801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=448801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=448801) 	// begin inline asm
(EngineCore_DP0 pid=448801) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=448801) 	// end inline asm
(EngineCore_DP0 pid=448801) 	bar.sync 	0;
(EngineCore_DP0 pid=448801) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=448801) $L__tmp2:
(EngineCore_DP0 pid=448801) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=448801) 	max.f32 	%r168, %r168, %r73;
(EngineCore_DP0 pid=448801) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=448801) 	add.s32 	%r169, %r169, 4096;
(EngineCore_DP0 pid=448801) 	setp.lt.s32 	%p6, %r169, %r24;
(EngineCore_DP0 pid=448801) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=448801) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=448801) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=448801) 	max.f32 	%r170, %r168, 0f2B8CBCCC;
(EngineCore_DP0 pid=448801) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=448801) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=448801) 	mov.b32 	%r75, 0f42FE0000;
(EngineCore_DP0 pid=448801) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=448801) 	div.full.f32 	%r76, %r170, %r75;
(EngineCore_DP0 pid=448801) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=448801) 	max.f32 	%r74, %r76, 0f37810204;
(EngineCore_DP0 pid=448801) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=448801) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=448801) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=448801) 	// begin inline asm
(EngineCore_DP0 pid=448801) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=448801) 	// end inline asm
(EngineCore_DP0 pid=448801) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=448801) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=448801) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=448801) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=448801) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=448801) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=448801) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=448801) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=448801) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=448801) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=448801) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=448801) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=448801) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=448801) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=448801) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=448801) 	div.full.f32 	%r14, %r75, %r170;
(EngineCore_DP0 pid=448801) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=448801) 	mov.b32 	%r171, 0;
(EngineCore_DP0 pid=448801) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=448801)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=448801) 	.loc	1 279 31                        // quant_slide_tuned_Qwen2.5-7B.py:279:31
(EngineCore_DP0 pid=448801) 	add.s32 	%r80, %r16, %r171;
(EngineCore_DP0 pid=448801) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=448801) 	add.s32 	%r81, %r80, 1;
(EngineCore_DP0 pid=448801) 	setp.lt.s32 	%p17, %r80, %r15;
(EngineCore_DP0 pid=448801) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=448801) 	shr.s32 	%r82, %r80, 31;
(EngineCore_DP0 pid=448801) 	shr.u32 	%r83, %r82, 30;
(EngineCore_DP0 pid=448801) 	add.s32 	%r84, %r80, %r83;
(EngineCore_DP0 pid=448801) 	shr.s32 	%r85, %r84, 2;
(EngineCore_DP0 pid=448801) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=448801) 	shr.s32 	%r86, %r81, 31;
(EngineCore_DP0 pid=448801) 	shr.u32 	%r87, %r86, 30;
(EngineCore_DP0 pid=448801) 	add.s32 	%r88, %r81, %r87;
(EngineCore_DP0 pid=448801) 	and.b32 	%r89, %r88, 2147483644;
(EngineCore_DP0 pid=448801) 	sub.s32 	%r90, %r81, %r89;
(EngineCore_DP0 pid=448801) 	and.b32 	%r91, %r84, 2147483644;
(EngineCore_DP0 pid=448801) 	sub.s32 	%r92, %r80, %r91;
(EngineCore_DP0 pid=448801) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=448801) 	mul.lo.s32 	%r93, %r85, 10;
(EngineCore_DP0 pid=448801) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=448801) 	shl.b32 	%r94, %r92, 1;
(EngineCore_DP0 pid=448801) 	shl.b32 	%r95, %r90, 1;
(EngineCore_DP0 pid=448801) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=448801) 	add.s32 	%r96, %r93, %r95;
(EngineCore_DP0 pid=448801) 	add.s32 	%r97, %r93, %r94;
(EngineCore_DP0 pid=448801) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=448801) 	setp.lt.s32 	%p18, %r97, %r23;
(EngineCore_DP0 pid=448801) 	setp.lt.s32 	%p19, %r96, %r23;
(EngineCore_DP0 pid=448801) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=448801) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=448801) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=448801) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=448801) 	mad.wide.s32 	%rd8, %r97, 2, %rd1;
(EngineCore_DP0 pid=448801) 	mad.wide.s32 	%rd9, %r96, 2, %rd1;
(EngineCore_DP0 pid=448801) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=448801) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=448801) 	// begin inline asm
(EngineCore_DP0 pid=448801) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=448801) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=448801) 	// end inline asm
(EngineCore_DP0 pid=448801) 	// begin inline asm
(EngineCore_DP0 pid=448801) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=448801) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=448801) 	// end inline asm
(EngineCore_DP0 pid=448801) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=448801) 	cvt.f32.bf16 	%r98, %rs24;
(EngineCore_DP0 pid=448801) 	cvt.f32.bf16 	%r99, %rs26;
(EngineCore_DP0 pid=448801) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=448801) 	or.b32 	%r100, %r97, 1;
(EngineCore_DP0 pid=448801) 	or.b32 	%r101, %r96, 1;
(EngineCore_DP0 pid=448801) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=448801) 	setp.lt.s32 	%p20, %r100, %r23;
(EngineCore_DP0 pid=448801) 	setp.lt.s32 	%p21, %r101, %r23;
(EngineCore_DP0 pid=448801) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=448801) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=448801) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=448801) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=448801) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=448801) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=448801) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=448801) 	// begin inline asm
(EngineCore_DP0 pid=448801) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=448801) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=448801) 	// end inline asm
(EngineCore_DP0 pid=448801) 	// begin inline asm
(EngineCore_DP0 pid=448801) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=448801) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=448801) 	// end inline asm
(EngineCore_DP0 pid=448801) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=448801) 	cvt.f32.bf16 	%r102, %rs28;
(EngineCore_DP0 pid=448801) 	cvt.f32.bf16 	%r103, %rs30;
(EngineCore_DP0 pid=448801) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=448801) 	add.s32 	%r104, %r97, 2;
(EngineCore_DP0 pid=448801) 	add.s32 	%r105, %r96, 2;
(EngineCore_DP0 pid=448801) 	add.s32 	%r106, %r97, 3;
(EngineCore_DP0 pid=448801) 	add.s32 	%r107, %r96, 3;
(EngineCore_DP0 pid=448801) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=448801) 	setp.lt.s32 	%p22, %r107, %r23;
(EngineCore_DP0 pid=448801) 	setp.lt.s32 	%p23, %r106, %r23;
(EngineCore_DP0 pid=448801) 	setp.lt.s32 	%p24, %r105, %r23;
(EngineCore_DP0 pid=448801) 	setp.lt.s32 	%p25, %r104, %r23;
(EngineCore_DP0 pid=448801) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=448801) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=448801) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=448801) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=448801) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=448801) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=448801) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=448801) 	// begin inline asm
(EngineCore_DP0 pid=448801) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=448801) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=448801) 	// end inline asm
(EngineCore_DP0 pid=448801) 	// begin inline asm
(EngineCore_DP0 pid=448801) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=448801) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=448801) 	// end inline asm
(EngineCore_DP0 pid=448801) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=448801) 	cvt.f32.bf16 	%r108, %rs32;
(EngineCore_DP0 pid=448801) 	cvt.f32.bf16 	%r109, %rs34;
(EngineCore_DP0 pid=448801) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=448801) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=448801) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=448801) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=448801) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=448801) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=448801) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=448801) 	// begin inline asm
(EngineCore_DP0 pid=448801) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=448801) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=448801) 	// end inline asm
(EngineCore_DP0 pid=448801) 	// begin inline asm
(EngineCore_DP0 pid=448801) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=448801) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=448801) 	// end inline asm
(EngineCore_DP0 pid=448801) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=448801) 	cvt.f32.bf16 	%r110, %rs36;
(EngineCore_DP0 pid=448801) 	cvt.f32.bf16 	%r111, %rs38;
(EngineCore_DP0 pid=448801) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=448801) 	mul.f32 	%r112, %r14, %r98;
(EngineCore_DP0 pid=448801) 	mul.f32 	%r113, %r14, %r99;
(EngineCore_DP0 pid=448801) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=448801) 	cvt.rni.f32.f32 	%r114, %r112;
(EngineCore_DP0 pid=448801) 	cvt.rni.f32.f32 	%r115, %r113;
(EngineCore_DP0 pid=448801) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=448801) 	max.f32 	%r116, %r114, 0fC3000000;
(EngineCore_DP0 pid=448801) 	min.f32 	%r117, %r116, 0f42FE0000;
(EngineCore_DP0 pid=448801) 	max.f32 	%r118, %r115, 0fC3000000;
(EngineCore_DP0 pid=448801) 	min.f32 	%r119, %r118, 0f42FE0000;
(EngineCore_DP0 pid=448801) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=448801) 	cvt.rzi.s32.f32 	%r120, %r117;
(EngineCore_DP0 pid=448801) 	cvt.rzi.s32.f32 	%r121, %r119;
(EngineCore_DP0 pid=448801) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=448801) 	and.b32 	%r122, %r120, 255;
(EngineCore_DP0 pid=448801) 	and.b32 	%r123, %r121, 255;
(EngineCore_DP0 pid=448801) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=448801) 	mul.f32 	%r124, %r14, %r102;
(EngineCore_DP0 pid=448801) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=448801) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=448801) 	cvt.rni.f32.f32 	%r126, %r124;
(EngineCore_DP0 pid=448801) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=448801) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=448801) 	mul.f32 	%r128, %r14, %r108;
(EngineCore_DP0 pid=448801) 	mul.f32 	%r129, %r14, %r109;
(EngineCore_DP0 pid=448801) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=448801) 	cvt.rni.f32.f32 	%r130, %r128;
(EngineCore_DP0 pid=448801) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=448801) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=448801) 	mul.f32 	%r132, %r14, %r110;
(EngineCore_DP0 pid=448801) 	mul.f32 	%r133, %r14, %r111;
(EngineCore_DP0 pid=448801) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=448801) 	cvt.rni.f32.f32 	%r134, %r132;
(EngineCore_DP0 pid=448801) 	cvt.rni.f32.f32 	%r135, %r133;
(EngineCore_DP0 pid=448801) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=448801) 	max.f32 	%r136, %r134, 0fC3000000;
(EngineCore_DP0 pid=448801) 	min.f32 	%r137, %r136, 0f42FE0000;
(EngineCore_DP0 pid=448801) 	max.f32 	%r138, %r135, 0fC3000000;
(EngineCore_DP0 pid=448801) 	min.f32 	%r139, %r138, 0f42FE0000;
(EngineCore_DP0 pid=448801) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=448801) 	cvt.rzi.s32.f32 	%r140, %r137;
(EngineCore_DP0 pid=448801) 	cvt.rzi.s32.f32 	%r141, %r139;
(EngineCore_DP0 pid=448801) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=448801) 	max.f32 	%r142, %r130, 0fC3000000;
(EngineCore_DP0 pid=448801) 	max.f32 	%r143, %r126, 0fC3000000;
(EngineCore_DP0 pid=448801) 	min.f32 	%r144, %r143, 0f42FE0000;
(EngineCore_DP0 pid=448801) 	min.f32 	%r145, %r142, 0f42FE0000;
(EngineCore_DP0 pid=448801) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=448801) 	cvt.rzi.s32.f32 	%r146, %r145;
(EngineCore_DP0 pid=448801) 	cvt.rzi.s32.f32 	%r147, %r144;
(EngineCore_DP0 pid=448801) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=448801) 	shl.b32 	%r148, %r147, 8;
(EngineCore_DP0 pid=448801) 	shl.b32 	%r149, %r146, 16;
(EngineCore_DP0 pid=448801) 	and.b32 	%r150, %r149, 16711680;
(EngineCore_DP0 pid=448801) 	and.b32 	%r151, %r148, 65280;
(EngineCore_DP0 pid=448801) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=448801) 	or.b32 	%r152, %r151, %r122;
(EngineCore_DP0 pid=448801) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=448801) 	max.f32 	%r153, %r131, 0fC3000000;
(EngineCore_DP0 pid=448801) 	max.f32 	%r154, %r127, 0fC3000000;
(EngineCore_DP0 pid=448801) 	min.f32 	%r155, %r154, 0f42FE0000;
(EngineCore_DP0 pid=448801) 	min.f32 	%r156, %r153, 0f42FE0000;
(EngineCore_DP0 pid=448801) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=448801) 	cvt.rzi.s32.f32 	%r157, %r156;
(EngineCore_DP0 pid=448801) 	cvt.rzi.s32.f32 	%r158, %r155;
(EngineCore_DP0 pid=448801) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=448801) 	shl.b32 	%r159, %r158, 8;
(EngineCore_DP0 pid=448801) 	shl.b32 	%r160, %r157, 16;
(EngineCore_DP0 pid=448801) 	and.b32 	%r161, %r160, 16711680;
(EngineCore_DP0 pid=448801) 	and.b32 	%r162, %r159, 65280;
(EngineCore_DP0 pid=448801) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=448801) 	or.b32 	%r163, %r162, %r123;
(EngineCore_DP0 pid=448801) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=448801) 	or.b32 	%r164, %r152, %r150;
(EngineCore_DP0 pid=448801) 	or.b32 	%r165, %r163, %r161;
(EngineCore_DP0 pid=448801) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=448801) 	shl.b32 	%r166, %r140, 24;
(EngineCore_DP0 pid=448801) 	shl.b32 	%r167, %r141, 24;
(EngineCore_DP0 pid=448801) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=448801) 	or.b32 	%r78, %r164, %r166;
(EngineCore_DP0 pid=448801) 	or.b32 	%r79, %r165, %r167;
(EngineCore_DP0 pid=448801) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=448801) 	mad.wide.s32 	%rd16, %r80, 4, %rd2;
(EngineCore_DP0 pid=448801) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=448801) 	// begin inline asm
(EngineCore_DP0 pid=448801) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r78, %r79 };
(EngineCore_DP0 pid=448801) 	// end inline asm
(EngineCore_DP0 pid=448801) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=448801) 	add.s32 	%r171, %r171, 1024;
(EngineCore_DP0 pid=448801) 	setp.lt.s32 	%p26, %r171, %r15;
(EngineCore_DP0 pid=448801) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=448801) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=448801) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=448801) 	ret;
(EngineCore_DP0 pid=448801) $L__tmp3:
(EngineCore_DP0 pid=448801) $L__func_end0:
(EngineCore_DP0 pid=448801)                                         // -- End function
(EngineCore_DP0 pid=448801) }
(EngineCore_DP0 pid=448801) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=448801) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=448801) 	.section	.debug_abbrev
(EngineCore_DP0 pid=448801) 	{
(EngineCore_DP0 pid=448801) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=448801) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=448801) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=448801) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=448801) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=448801) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=448801) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=448801) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=448801) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=448801) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=448801) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=448801) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=448801) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=448801) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=448801) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=448801) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=448801) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=448801) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=448801) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=448801) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=448801) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=448801) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=448801) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=448801) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=448801) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=448801) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=448801) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=448801) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=448801) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=448801) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=448801) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=448801) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=448801) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=448801) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=448801) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=448801) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=448801) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=448801) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=448801) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=448801) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=448801) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=448801) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=448801) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=448801) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=448801) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=448801) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=448801) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=448801) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=448801) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=448801) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=448801) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=448801) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=448801) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=448801) 	}
(EngineCore_DP0 pid=448801) 	.section	.debug_info
(EngineCore_DP0 pid=448801) 	{
(EngineCore_DP0 pid=448801) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=448801) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=448801) .b8 0
(EngineCore_DP0 pid=448801) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=448801) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=448801) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=448801) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=448801) .b8 114
(EngineCore_DP0 pid=448801) .b8 105
(EngineCore_DP0 pid=448801) .b8 116
(EngineCore_DP0 pid=448801) .b8 111
(EngineCore_DP0 pid=448801) .b8 110
(EngineCore_DP0 pid=448801) .b8 0
(EngineCore_DP0 pid=448801) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=448801) .b8 0
(EngineCore_DP0 pid=448801) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=448801) .b8 117
(EngineCore_DP0 pid=448801) .b8 97
(EngineCore_DP0 pid=448801) .b8 110
(EngineCore_DP0 pid=448801) .b8 116
(EngineCore_DP0 pid=448801) .b8 95
(EngineCore_DP0 pid=448801) .b8 115
(EngineCore_DP0 pid=448801) .b8 108
(EngineCore_DP0 pid=448801) .b8 105
(EngineCore_DP0 pid=448801) .b8 100
(EngineCore_DP0 pid=448801) .b8 101
(EngineCore_DP0 pid=448801) .b8 95
(EngineCore_DP0 pid=448801) .b8 116
(EngineCore_DP0 pid=448801) .b8 117
(EngineCore_DP0 pid=448801) .b8 110
(EngineCore_DP0 pid=448801) .b8 101
(EngineCore_DP0 pid=448801) .b8 100
(EngineCore_DP0 pid=448801) .b8 95
(EngineCore_DP0 pid=448801) .b8 81
(EngineCore_DP0 pid=448801) .b8 119
(EngineCore_DP0 pid=448801) .b8 101
(EngineCore_DP0 pid=448801) .b8 110
(EngineCore_DP0 pid=448801) .b8 50
(EngineCore_DP0 pid=448801) .b8 46
(EngineCore_DP0 pid=448801) .b8 53
(EngineCore_DP0 pid=448801) .b8 45
(EngineCore_DP0 pid=448801) .b8 55
(EngineCore_DP0 pid=448801) .b8 66
(EngineCore_DP0 pid=448801) .b8 46
(EngineCore_DP0 pid=448801) .b8 112
(EngineCore_DP0 pid=448801) .b8 121
(EngineCore_DP0 pid=448801) .b8 0
(EngineCore_DP0 pid=448801) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=448801) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=448801) .b8 114
(EngineCore_DP0 pid=448801) .b8 111
(EngineCore_DP0 pid=448801) .b8 111
(EngineCore_DP0 pid=448801) .b8 116
(EngineCore_DP0 pid=448801) .b8 47
(EngineCore_DP0 pid=448801) .b8 118
(EngineCore_DP0 pid=448801) .b8 108
(EngineCore_DP0 pid=448801) .b8 108
(EngineCore_DP0 pid=448801) .b8 109
(EngineCore_DP0 pid=448801) .b8 98
(EngineCore_DP0 pid=448801) .b8 101
(EngineCore_DP0 pid=448801) .b8 110
(EngineCore_DP0 pid=448801) .b8 99
(EngineCore_DP0 pid=448801) .b8 104
(EngineCore_DP0 pid=448801) .b8 47
(EngineCore_DP0 pid=448801) .b8 115
(EngineCore_DP0 pid=448801) .b8 108
(EngineCore_DP0 pid=448801) .b8 105
(EngineCore_DP0 pid=448801) .b8 100
(EngineCore_DP0 pid=448801) .b8 101
(EngineCore_DP0 pid=448801) .b8 115
(EngineCore_DP0 pid=448801) .b8 112
(EngineCore_DP0 pid=448801) .b8 97
(EngineCore_DP0 pid=448801) .b8 114
(EngineCore_DP0 pid=448801) .b8 115
(EngineCore_DP0 pid=448801) .b8 101
(EngineCore_DP0 pid=448801) .b8 47
(EngineCore_DP0 pid=448801) .b8 99
(EngineCore_DP0 pid=448801) .b8 115
(EngineCore_DP0 pid=448801) .b8 114
(EngineCore_DP0 pid=448801) .b8 99
(EngineCore_DP0 pid=448801) .b8 47
(EngineCore_DP0 pid=448801) .b8 102
(EngineCore_DP0 pid=448801) .b8 117
(EngineCore_DP0 pid=448801) .b8 115
(EngineCore_DP0 pid=448801) .b8 101
(EngineCore_DP0 pid=448801) .b8 100
(EngineCore_DP0 pid=448801) .b8 95
(EngineCore_DP0 pid=448801) .b8 113
(EngineCore_DP0 pid=448801) .b8 117
(EngineCore_DP0 pid=448801) .b8 97
(EngineCore_DP0 pid=448801) .b8 110
(EngineCore_DP0 pid=448801) .b8 116
(EngineCore_DP0 pid=448801) .b8 95
(EngineCore_DP0 pid=448801) .b8 115
(EngineCore_DP0 pid=448801) .b8 108
(EngineCore_DP0 pid=448801) .b8 105
(EngineCore_DP0 pid=448801) .b8 100
(EngineCore_DP0 pid=448801) .b8 101
(EngineCore_DP0 pid=448801) .b8 95
(EngineCore_DP0 pid=448801) .b8 116
(EngineCore_DP0 pid=448801) .b8 114
(EngineCore_DP0 pid=448801) .b8 105
(EngineCore_DP0 pid=448801) .b8 116
(EngineCore_DP0 pid=448801) .b8 111
(EngineCore_DP0 pid=448801) .b8 110
(EngineCore_DP0 pid=448801) .b8 47
(EngineCore_DP0 pid=448801) .b8 98
(EngineCore_DP0 pid=448801) .b8 117
(EngineCore_DP0 pid=448801) .b8 105
(EngineCore_DP0 pid=448801) .b8 108
(EngineCore_DP0 pid=448801) .b8 100
(EngineCore_DP0 pid=448801) .b8 47
(EngineCore_DP0 pid=448801) .b8 71
(EngineCore_DP0 pid=448801) .b8 66
(EngineCore_DP0 pid=448801) .b8 49
(EngineCore_DP0 pid=448801) .b8 48
(EngineCore_DP0 pid=448801) .b8 95
(EngineCore_DP0 pid=448801) .b8 99
(EngineCore_DP0 pid=448801) .b8 99
(EngineCore_DP0 pid=448801) .b8 49
(EngineCore_DP0 pid=448801) .b8 50
(EngineCore_DP0 pid=448801) .b8 49
(EngineCore_DP0 pid=448801) .b8 95
(EngineCore_DP0 pid=448801) .b8 112
(EngineCore_DP0 pid=448801) .b8 121
(EngineCore_DP0 pid=448801) .b8 51
(EngineCore_DP0 pid=448801) .b8 49
(EngineCore_DP0 pid=448801) .b8 50
(EngineCore_DP0 pid=448801) .b8 95
(EngineCore_DP0 pid=448801) .b8 99
(EngineCore_DP0 pid=448801) .b8 117
(EngineCore_DP0 pid=448801) .b8 49
(EngineCore_DP0 pid=448801) .b8 50
(EngineCore_DP0 pid=448801) .b8 57
(EngineCore_DP0 pid=448801) .b8 95
(EngineCore_DP0 pid=448801) .b8 97
(EngineCore_DP0 pid=448801) .b8 97
(EngineCore_DP0 pid=448801) .b8 114
(EngineCore_DP0 pid=448801) .b8 99
(EngineCore_DP0 pid=448801) .b8 104
(EngineCore_DP0 pid=448801) .b8 54
(EngineCore_DP0 pid=448801) .b8 52
(EngineCore_DP0 pid=448801) .b8 0
(EngineCore_DP0 pid=448801) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=448801) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=448801) .b8 113
(EngineCore_DP0 pid=448801) .b8 117
(EngineCore_DP0 pid=448801) .b8 97
(EngineCore_DP0 pid=448801) .b8 110
(EngineCore_DP0 pid=448801) .b8 116
(EngineCore_DP0 pid=448801) .b8 95
(EngineCore_DP0 pid=448801) .b8 115
(EngineCore_DP0 pid=448801) .b8 108
(EngineCore_DP0 pid=448801) .b8 105
(EngineCore_DP0 pid=448801) .b8 100
(EngineCore_DP0 pid=448801) .b8 101
(EngineCore_DP0 pid=448801) .b8 95
(EngineCore_DP0 pid=448801) .b8 105
(EngineCore_DP0 pid=448801) .b8 110
(EngineCore_DP0 pid=448801) .b8 116
(EngineCore_DP0 pid=448801) .b8 56
(EngineCore_DP0 pid=448801) .b8 95
(EngineCore_DP0 pid=448801) .b8 107
(EngineCore_DP0 pid=448801) .b8 101
(EngineCore_DP0 pid=448801) .b8 114
(EngineCore_DP0 pid=448801) .b8 110
(EngineCore_DP0 pid=448801) .b8 101
(EngineCore_DP0 pid=448801) .b8 108
(EngineCore_DP0 pid=448801) .b8 0
(EngineCore_DP0 pid=448801) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=448801) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=448801) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=448801) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=448801) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=448801) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=448801) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=448801) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=448801) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=448801) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=448801) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=448801) .b8 1
(EngineCore_DP0 pid=448801) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=448801) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=448801) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=448801) 	}
(EngineCore_DP0 pid=448801) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=448801) 
(EngineCore_DP0 pid=448801) ================================================================
(EngineCore_DP0 pid=448801) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=448801) 
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpeubp0q9o.ptx', '-o', '/tmp/tmpeubp0q9o.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866] 
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866] 
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866] 
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpeubp0q9o.ptx -o /tmp/tmpeubp0q9o.ptx.o
(EngineCore_DP0 pid=448801) ERROR 01-25 21:00:22 [core.py:866] 

STDERR:
[2026-01-25 20:59:10] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:59:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:59:10] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:59:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:59:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:59:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:59:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:59:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:59:13] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:59:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:59:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:59:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:59:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:59:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:59:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:59:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:59:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=448801) [2026-01-25 20:59:14] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=448801) [2026-01-25 20:59:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=448801) [2026-01-25 20:59:14] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=448801) [2026-01-25 20:59:14] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=448801) [2026-01-25 20:59:14] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=448801) [2026-01-25 20:59:14] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=448801) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=448801) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.79s/it]
(EngineCore_DP0 pid=448801) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 33.20s/it]
(EngineCore_DP0 pid=448801) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 32.39s/it]
(EngineCore_DP0 pid=448801) 
(EngineCore_DP0 pid=448801) [2026-01-25 21:00:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=448801) [2026-01-25 21:00:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=448801) [2026-01-25 21:00:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=448801) [2026-01-25 21:00:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=448801) [2026-01-25 21:00:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=448801) [2026-01-25 21:00:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=448801) [2026-01-25 21:00:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=448801) [2026-01-25 21:00:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=448801) Process EngineCore_DP0:
(EngineCore_DP0 pid=448801) Traceback (most recent call last):
(EngineCore_DP0 pid=448801)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=448801)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=448801)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=448801)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=448801) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpeubp0q9o.ptx', '-o', '/tmp/tmpeubp0q9o.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=448801) 
(EngineCore_DP0 pid=448801) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=448801) 
(EngineCore_DP0 pid=448801) Traceback (most recent call last):
(EngineCore_DP0 pid=448801)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=448801)     self.run()
(EngineCore_DP0 pid=448801)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=448801)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=448801)     raise e
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=448801)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=448801)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=448801)     super().__init__(
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=448801)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=448801)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=448801)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=448801)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=448801)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=448801)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=448801)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=448801)     return func(*args, **kwargs)
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=448801)     return func(*args, **kwargs)
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=448801)     self.model_runner.profile_run()
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=448801)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=448801)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=448801)     return func(*args, **kwargs)
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=448801)     outputs = self.model(
(EngineCore_DP0 pid=448801)               ^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=448801)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=448801)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=448801)     hidden_states = self.model(
(EngineCore_DP0 pid=448801)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=448801)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=448801)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=448801)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=448801)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=448801)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=448801)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=448801)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=448801)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=448801)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=448801)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=448801)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=448801)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=448801)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=448801)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=448801)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=448801)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=448801)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=448801)     return self._linear_fn(
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=448801)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=448801)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=448801)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=448801)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=448801)     return fn(input, L)
(EngineCore_DP0 pid=448801)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=448801)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=448801)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=448801)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=448801)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=448801)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=448801)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=448801)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=448801)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=448801)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=448801)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=448801)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=448801)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=448801)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=448801)     raise PTXASError(error)
(EngineCore_DP0 pid=448801) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=448801) `ptxas` stderr:
(EngineCore_DP0 pid=448801) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=448801) 
(EngineCore_DP0 pid=448801) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpeubp0q9o.ptx -o /tmp/tmpeubp0q9o.ptx.o
(EngineCore_DP0 pid=448801) 
[rank0]:[W125 21:00:23.440082732 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 21:00:24
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:00:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:00:29 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=450090) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=450090) 
(EngineCore_DP0 pid=450090) 
(EngineCore_DP0 pid=450090) ================================================================
(EngineCore_DP0 pid=450090) Internal Triton PTX codegen error
(EngineCore_DP0 pid=450090) `ptxas` stderr:
(EngineCore_DP0 pid=450090) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=450090) 
(EngineCore_DP0 pid=450090) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpoqou0njn.ptx -o /tmp/tmpoqou0njn.ptx.o
(EngineCore_DP0 pid=450090) 
(EngineCore_DP0 pid=450090) 
(EngineCore_DP0 pid=450090) //
(EngineCore_DP0 pid=450090) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=450090) //
(EngineCore_DP0 pid=450090) 
(EngineCore_DP0 pid=450090) .version 8.7
(EngineCore_DP0 pid=450090) .target sm_121a
(EngineCore_DP0 pid=450090) .address_size 64
(EngineCore_DP0 pid=450090) 
(EngineCore_DP0 pid=450090) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=450090) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=450090)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=450090) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=450090) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=450090) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=450090) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=450090) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=450090) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=450090) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=450090) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=450090) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=450090) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=450090) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=450090) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=450090) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=450090) )
(EngineCore_DP0 pid=450090) .reqntid 512
(EngineCore_DP0 pid=450090) {
(EngineCore_DP0 pid=450090) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=450090) 	.reg .b16 	%rs<40>;
(EngineCore_DP0 pid=450090) 	.reg .b32 	%r<172>;
(EngineCore_DP0 pid=450090) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=450090) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=450090) $L__func_begin0:
(EngineCore_DP0 pid=450090) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=450090) 
(EngineCore_DP0 pid=450090) // %bb.0:
(EngineCore_DP0 pid=450090) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=450090) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=450090) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=450090) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=450090) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=450090) $L__tmp0:
(EngineCore_DP0 pid=450090) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=450090) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=450090) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=450090) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=450090) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=450090) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=450090) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=450090) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=450090) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=450090) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=450090) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=450090) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=450090) 	mov.b32 	%r170, 0f2B8CBCCC;
(EngineCore_DP0 pid=450090) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=450090) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=450090) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=450090) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=450090) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=450090) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=450090) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=450090) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=450090) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=450090) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=450090) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=450090) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=450090) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=450090) 	mov.b32 	%r168, 0f00000000;
(EngineCore_DP0 pid=450090) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=450090) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=450090) 	mov.b32 	%r169, %r45;
(EngineCore_DP0 pid=450090) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=450090) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=450090) 	add.s32 	%r55, %r4, %r169;
(EngineCore_DP0 pid=450090) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=450090) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=450090) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=450090) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=450090) 	// begin inline asm
(EngineCore_DP0 pid=450090) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=450090) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=450090) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=450090) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=450090) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=450090) 	// end inline asm
(EngineCore_DP0 pid=450090) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=450090) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=450090) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=450090) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=450090) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=450090) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=450090) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=450090) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=450090) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=450090) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=450090) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=450090) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=450090) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=450090) $L__tmp1:
(EngineCore_DP0 pid=450090) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	bar.sync 	0;
(EngineCore_DP0 pid=450090) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=450090) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=450090) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=450090) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=450090) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=450090) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=450090) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=450090) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=450090) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=450090) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=450090) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=450090) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=450090) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=450090) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=450090) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=450090) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=450090) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=450090) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=450090) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	// begin inline asm
(EngineCore_DP0 pid=450090) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=450090) 	// end inline asm
(EngineCore_DP0 pid=450090) 	bar.sync 	0;
(EngineCore_DP0 pid=450090) 	// begin inline asm
(EngineCore_DP0 pid=450090) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=450090) 	// end inline asm
(EngineCore_DP0 pid=450090) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=450090) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=450090) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=450090) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=450090) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=450090) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=450090) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=450090) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=450090) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=450090) 	// begin inline asm
(EngineCore_DP0 pid=450090) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=450090) 	// end inline asm
(EngineCore_DP0 pid=450090) 	bar.sync 	0;
(EngineCore_DP0 pid=450090) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=450090) $L__tmp2:
(EngineCore_DP0 pid=450090) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=450090) 	max.f32 	%r168, %r168, %r73;
(EngineCore_DP0 pid=450090) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=450090) 	add.s32 	%r169, %r169, 4096;
(EngineCore_DP0 pid=450090) 	setp.lt.s32 	%p6, %r169, %r24;
(EngineCore_DP0 pid=450090) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=450090) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=450090) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=450090) 	max.f32 	%r170, %r168, 0f2B8CBCCC;
(EngineCore_DP0 pid=450090) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=450090) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=450090) 	mov.b32 	%r75, 0f42FE0000;
(EngineCore_DP0 pid=450090) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=450090) 	div.full.f32 	%r76, %r170, %r75;
(EngineCore_DP0 pid=450090) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=450090) 	max.f32 	%r74, %r76, 0f37810204;
(EngineCore_DP0 pid=450090) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=450090) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=450090) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=450090) 	// begin inline asm
(EngineCore_DP0 pid=450090) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=450090) 	// end inline asm
(EngineCore_DP0 pid=450090) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=450090) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=450090) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=450090) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=450090) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=450090) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=450090) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=450090) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=450090) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=450090) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=450090) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=450090) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=450090) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=450090) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=450090) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=450090) 	div.full.f32 	%r14, %r75, %r170;
(EngineCore_DP0 pid=450090) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=450090) 	mov.b32 	%r171, 0;
(EngineCore_DP0 pid=450090) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=450090)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=450090) 	.loc	1 279 31                        // quant_slide_tuned_Qwen2.5-7B.py:279:31
(EngineCore_DP0 pid=450090) 	add.s32 	%r80, %r16, %r171;
(EngineCore_DP0 pid=450090) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=450090) 	add.s32 	%r81, %r80, 1;
(EngineCore_DP0 pid=450090) 	setp.lt.s32 	%p17, %r80, %r15;
(EngineCore_DP0 pid=450090) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=450090) 	shr.s32 	%r82, %r80, 31;
(EngineCore_DP0 pid=450090) 	shr.u32 	%r83, %r82, 30;
(EngineCore_DP0 pid=450090) 	add.s32 	%r84, %r80, %r83;
(EngineCore_DP0 pid=450090) 	shr.s32 	%r85, %r84, 2;
(EngineCore_DP0 pid=450090) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=450090) 	shr.s32 	%r86, %r81, 31;
(EngineCore_DP0 pid=450090) 	shr.u32 	%r87, %r86, 30;
(EngineCore_DP0 pid=450090) 	add.s32 	%r88, %r81, %r87;
(EngineCore_DP0 pid=450090) 	and.b32 	%r89, %r88, 2147483644;
(EngineCore_DP0 pid=450090) 	sub.s32 	%r90, %r81, %r89;
(EngineCore_DP0 pid=450090) 	and.b32 	%r91, %r84, 2147483644;
(EngineCore_DP0 pid=450090) 	sub.s32 	%r92, %r80, %r91;
(EngineCore_DP0 pid=450090) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=450090) 	mul.lo.s32 	%r93, %r85, 10;
(EngineCore_DP0 pid=450090) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=450090) 	shl.b32 	%r94, %r92, 1;
(EngineCore_DP0 pid=450090) 	shl.b32 	%r95, %r90, 1;
(EngineCore_DP0 pid=450090) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=450090) 	add.s32 	%r96, %r93, %r95;
(EngineCore_DP0 pid=450090) 	add.s32 	%r97, %r93, %r94;
(EngineCore_DP0 pid=450090) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=450090) 	setp.lt.s32 	%p18, %r97, %r23;
(EngineCore_DP0 pid=450090) 	setp.lt.s32 	%p19, %r96, %r23;
(EngineCore_DP0 pid=450090) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=450090) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=450090) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=450090) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=450090) 	mad.wide.s32 	%rd8, %r97, 2, %rd1;
(EngineCore_DP0 pid=450090) 	mad.wide.s32 	%rd9, %r96, 2, %rd1;
(EngineCore_DP0 pid=450090) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=450090) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=450090) 	// begin inline asm
(EngineCore_DP0 pid=450090) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=450090) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=450090) 	// end inline asm
(EngineCore_DP0 pid=450090) 	// begin inline asm
(EngineCore_DP0 pid=450090) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=450090) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=450090) 	// end inline asm
(EngineCore_DP0 pid=450090) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=450090) 	cvt.f32.bf16 	%r98, %rs24;
(EngineCore_DP0 pid=450090) 	cvt.f32.bf16 	%r99, %rs26;
(EngineCore_DP0 pid=450090) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=450090) 	or.b32 	%r100, %r97, 1;
(EngineCore_DP0 pid=450090) 	or.b32 	%r101, %r96, 1;
(EngineCore_DP0 pid=450090) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=450090) 	setp.lt.s32 	%p20, %r100, %r23;
(EngineCore_DP0 pid=450090) 	setp.lt.s32 	%p21, %r101, %r23;
(EngineCore_DP0 pid=450090) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=450090) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=450090) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=450090) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=450090) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=450090) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=450090) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=450090) 	// begin inline asm
(EngineCore_DP0 pid=450090) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=450090) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=450090) 	// end inline asm
(EngineCore_DP0 pid=450090) 	// begin inline asm
(EngineCore_DP0 pid=450090) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=450090) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=450090) 	// end inline asm
(EngineCore_DP0 pid=450090) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=450090) 	cvt.f32.bf16 	%r102, %rs28;
(EngineCore_DP0 pid=450090) 	cvt.f32.bf16 	%r103, %rs30;
(EngineCore_DP0 pid=450090) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=450090) 	add.s32 	%r104, %r97, 2;
(EngineCore_DP0 pid=450090) 	add.s32 	%r105, %r96, 2;
(EngineCore_DP0 pid=450090) 	add.s32 	%r106, %r97, 3;
(EngineCore_DP0 pid=450090) 	add.s32 	%r107, %r96, 3;
(EngineCore_DP0 pid=450090) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=450090) 	setp.lt.s32 	%p22, %r107, %r23;
(EngineCore_DP0 pid=450090) 	setp.lt.s32 	%p23, %r106, %r23;
(EngineCore_DP0 pid=450090) 	setp.lt.s32 	%p24, %r105, %r23;
(EngineCore_DP0 pid=450090) 	setp.lt.s32 	%p25, %r104, %r23;
(EngineCore_DP0 pid=450090) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=450090) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=450090) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=450090) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=450090) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=450090) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=450090) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=450090) 	// begin inline asm
(EngineCore_DP0 pid=450090) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=450090) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=450090) 	// end inline asm
(EngineCore_DP0 pid=450090) 	// begin inline asm
(EngineCore_DP0 pid=450090) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=450090) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=450090) 	// end inline asm
(EngineCore_DP0 pid=450090) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=450090) 	cvt.f32.bf16 	%r108, %rs32;
(EngineCore_DP0 pid=450090) 	cvt.f32.bf16 	%r109, %rs34;
(EngineCore_DP0 pid=450090) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=450090) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=450090) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=450090) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=450090) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=450090) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=450090) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=450090) 	// begin inline asm
(EngineCore_DP0 pid=450090) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=450090) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=450090) 	// end inline asm
(EngineCore_DP0 pid=450090) 	// begin inline asm
(EngineCore_DP0 pid=450090) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=450090) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=450090) 	// end inline asm
(EngineCore_DP0 pid=450090) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=450090) 	cvt.f32.bf16 	%r110, %rs36;
(EngineCore_DP0 pid=450090) 	cvt.f32.bf16 	%r111, %rs38;
(EngineCore_DP0 pid=450090) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=450090) 	mul.f32 	%r112, %r14, %r98;
(EngineCore_DP0 pid=450090) 	mul.f32 	%r113, %r14, %r99;
(EngineCore_DP0 pid=450090) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=450090) 	cvt.rni.f32.f32 	%r114, %r112;
(EngineCore_DP0 pid=450090) 	cvt.rni.f32.f32 	%r115, %r113;
(EngineCore_DP0 pid=450090) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=450090) 	max.f32 	%r116, %r114, 0fC3000000;
(EngineCore_DP0 pid=450090) 	min.f32 	%r117, %r116, 0f42FE0000;
(EngineCore_DP0 pid=450090) 	max.f32 	%r118, %r115, 0fC3000000;
(EngineCore_DP0 pid=450090) 	min.f32 	%r119, %r118, 0f42FE0000;
(EngineCore_DP0 pid=450090) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=450090) 	cvt.rzi.s32.f32 	%r120, %r117;
(EngineCore_DP0 pid=450090) 	cvt.rzi.s32.f32 	%r121, %r119;
(EngineCore_DP0 pid=450090) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=450090) 	and.b32 	%r122, %r120, 255;
(EngineCore_DP0 pid=450090) 	and.b32 	%r123, %r121, 255;
(EngineCore_DP0 pid=450090) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=450090) 	mul.f32 	%r124, %r14, %r102;
(EngineCore_DP0 pid=450090) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=450090) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=450090) 	cvt.rni.f32.f32 	%r126, %r124;
(EngineCore_DP0 pid=450090) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=450090) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=450090) 	mul.f32 	%r128, %r14, %r108;
(EngineCore_DP0 pid=450090) 	mul.f32 	%r129, %r14, %r109;
(EngineCore_DP0 pid=450090) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=450090) 	cvt.rni.f32.f32 	%r130, %r128;
(EngineCore_DP0 pid=450090) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=450090) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=450090) 	mul.f32 	%r132, %r14, %r110;
(EngineCore_DP0 pid=450090) 	mul.f32 	%r133, %r14, %r111;
(EngineCore_DP0 pid=450090) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=450090) 	cvt.rni.f32.f32 	%r134, %r132;
(EngineCore_DP0 pid=450090) 	cvt.rni.f32.f32 	%r135, %r133;
(EngineCore_DP0 pid=450090) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=450090) 	max.f32 	%r136, %r134, 0fC3000000;
(EngineCore_DP0 pid=450090) 	min.f32 	%r137, %r136, 0f42FE0000;
(EngineCore_DP0 pid=450090) 	max.f32 	%r138, %r135, 0fC3000000;
(EngineCore_DP0 pid=450090) 	min.f32 	%r139, %r138, 0f42FE0000;
(EngineCore_DP0 pid=450090) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=450090) 	cvt.rzi.s32.f32 	%r140, %r137;
(EngineCore_DP0 pid=450090) 	cvt.rzi.s32.f32 	%r141, %r139;
(EngineCore_DP0 pid=450090) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=450090) 	max.f32 	%r142, %r130, 0fC3000000;
(EngineCore_DP0 pid=450090) 	max.f32 	%r143, %r126, 0fC3000000;
(EngineCore_DP0 pid=450090) 	min.f32 	%r144, %r143, 0f42FE0000;
(EngineCore_DP0 pid=450090) 	min.f32 	%r145, %r142, 0f42FE0000;
(EngineCore_DP0 pid=450090) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=450090) 	cvt.rzi.s32.f32 	%r146, %r145;
(EngineCore_DP0 pid=450090) 	cvt.rzi.s32.f32 	%r147, %r144;
(EngineCore_DP0 pid=450090) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=450090) 	shl.b32 	%r148, %r147, 8;
(EngineCore_DP0 pid=450090) 	shl.b32 	%r149, %r146, 16;
(EngineCore_DP0 pid=450090) 	and.b32 	%r150, %r149, 16711680;
(EngineCore_DP0 pid=450090) 	and.b32 	%r151, %r148, 65280;
(EngineCore_DP0 pid=450090) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=450090) 	or.b32 	%r152, %r151, %r122;
(EngineCore_DP0 pid=450090) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=450090) 	max.f32 	%r153, %r131, 0fC3000000;
(EngineCore_DP0 pid=450090) 	max.f32 	%r154, %r127, 0fC3000000;
(EngineCore_DP0 pid=450090) 	min.f32 	%r155, %r154, 0f42FE0000;
(EngineCore_DP0 pid=450090) 	min.f32 	%r156, %r153, 0f42FE0000;
(EngineCore_DP0 pid=450090) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=450090) 	cvt.rzi.s32.f32 	%r157, %r156;
(EngineCore_DP0 pid=450090) 	cvt.rzi.s32.f32 	%r158, %r155;
(EngineCore_DP0 pid=450090) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=450090) 	shl.b32 	%r159, %r158, 8;
(EngineCore_DP0 pid=450090) 	shl.b32 	%r160, %r157, 16;
(EngineCore_DP0 pid=450090) 	and.b32 	%r161, %r160, 16711680;
(EngineCore_DP0 pid=450090) 	and.b32 	%r162, %r159, 65280;
(EngineCore_DP0 pid=450090) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=450090) 	or.b32 	%r163, %r162, %r123;
(EngineCore_DP0 pid=450090) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=450090) 	or.b32 	%r164, %r152, %r150;
(EngineCore_DP0 pid=450090) 	or.b32 	%r165, %r163, %r161;
(EngineCore_DP0 pid=450090) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=450090) 	shl.b32 	%r166, %r140, 24;
(EngineCore_DP0 pid=450090) 	shl.b32 	%r167, %r141, 24;
(EngineCore_DP0 pid=450090) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=450090) 	or.b32 	%r78, %r164, %r166;
(EngineCore_DP0 pid=450090) 	or.b32 	%r79, %r165, %r167;
(EngineCore_DP0 pid=450090) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=450090) 	mad.wide.s32 	%rd16, %r80, 4, %rd2;
(EngineCore_DP0 pid=450090) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=450090) 	// begin inline asm
(EngineCore_DP0 pid=450090) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r78, %r79 };
(EngineCore_DP0 pid=450090) 	// end inline asm
(EngineCore_DP0 pid=450090) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=450090) 	add.s32 	%r171, %r171, 1024;
(EngineCore_DP0 pid=450090) 	setp.lt.s32 	%p26, %r171, %r15;
(EngineCore_DP0 pid=450090) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=450090) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=450090) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=450090) 	ret;
(EngineCore_DP0 pid=450090) $L__tmp3:
(EngineCore_DP0 pid=450090) $L__func_end0:
(EngineCore_DP0 pid=450090)                                         // -- End function
(EngineCore_DP0 pid=450090) }
(EngineCore_DP0 pid=450090) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=450090) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=450090) 	.section	.debug_abbrev
(EngineCore_DP0 pid=450090) 	{
(EngineCore_DP0 pid=450090) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=450090) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=450090) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=450090) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=450090) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=450090) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=450090) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=450090) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=450090) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=450090) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=450090) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=450090) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=450090) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=450090) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=450090) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=450090) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=450090) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=450090) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=450090) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=450090) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=450090) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=450090) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=450090) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=450090) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=450090) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=450090) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=450090) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=450090) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=450090) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=450090) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=450090) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=450090) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=450090) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=450090) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=450090) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=450090) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=450090) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=450090) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=450090) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=450090) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=450090) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=450090) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=450090) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=450090) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=450090) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=450090) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=450090) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=450090) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=450090) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=450090) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=450090) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=450090) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=450090) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=450090) 	}
(EngineCore_DP0 pid=450090) 	.section	.debug_info
(EngineCore_DP0 pid=450090) 	{
(EngineCore_DP0 pid=450090) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=450090) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=450090) .b8 0
(EngineCore_DP0 pid=450090) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=450090) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=450090) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=450090) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=450090) .b8 114
(EngineCore_DP0 pid=450090) .b8 105
(EngineCore_DP0 pid=450090) .b8 116
(EngineCore_DP0 pid=450090) .b8 111
(EngineCore_DP0 pid=450090) .b8 110
(EngineCore_DP0 pid=450090) .b8 0
(EngineCore_DP0 pid=450090) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=450090) .b8 0
(EngineCore_DP0 pid=450090) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=450090) .b8 117
(EngineCore_DP0 pid=450090) .b8 97
(EngineCore_DP0 pid=450090) .b8 110
(EngineCore_DP0 pid=450090) .b8 116
(EngineCore_DP0 pid=450090) .b8 95
(EngineCore_DP0 pid=450090) .b8 115
(EngineCore_DP0 pid=450090) .b8 108
(EngineCore_DP0 pid=450090) .b8 105
(EngineCore_DP0 pid=450090) .b8 100
(EngineCore_DP0 pid=450090) .b8 101
(EngineCore_DP0 pid=450090) .b8 95
(EngineCore_DP0 pid=450090) .b8 116
(EngineCore_DP0 pid=450090) .b8 117
(EngineCore_DP0 pid=450090) .b8 110
(EngineCore_DP0 pid=450090) .b8 101
(EngineCore_DP0 pid=450090) .b8 100
(EngineCore_DP0 pid=450090) .b8 95
(EngineCore_DP0 pid=450090) .b8 81
(EngineCore_DP0 pid=450090) .b8 119
(EngineCore_DP0 pid=450090) .b8 101
(EngineCore_DP0 pid=450090) .b8 110
(EngineCore_DP0 pid=450090) .b8 50
(EngineCore_DP0 pid=450090) .b8 46
(EngineCore_DP0 pid=450090) .b8 53
(EngineCore_DP0 pid=450090) .b8 45
(EngineCore_DP0 pid=450090) .b8 55
(EngineCore_DP0 pid=450090) .b8 66
(EngineCore_DP0 pid=450090) .b8 46
(EngineCore_DP0 pid=450090) .b8 112
(EngineCore_DP0 pid=450090) .b8 121
(EngineCore_DP0 pid=450090) .b8 0
(EngineCore_DP0 pid=450090) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=450090) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=450090) .b8 114
(EngineCore_DP0 pid=450090) .b8 111
(EngineCore_DP0 pid=450090) .b8 111
(EngineCore_DP0 pid=450090) .b8 116
(EngineCore_DP0 pid=450090) .b8 47
(EngineCore_DP0 pid=450090) .b8 118
(EngineCore_DP0 pid=450090) .b8 108
(EngineCore_DP0 pid=450090) .b8 108
(EngineCore_DP0 pid=450090) .b8 109
(EngineCore_DP0 pid=450090) .b8 98
(EngineCore_DP0 pid=450090) .b8 101
(EngineCore_DP0 pid=450090) .b8 110
(EngineCore_DP0 pid=450090) .b8 99
(EngineCore_DP0 pid=450090) .b8 104
(EngineCore_DP0 pid=450090) .b8 47
(EngineCore_DP0 pid=450090) .b8 115
(EngineCore_DP0 pid=450090) .b8 108
(EngineCore_DP0 pid=450090) .b8 105
(EngineCore_DP0 pid=450090) .b8 100
(EngineCore_DP0 pid=450090) .b8 101
(EngineCore_DP0 pid=450090) .b8 115
(EngineCore_DP0 pid=450090) .b8 112
(EngineCore_DP0 pid=450090) .b8 97
(EngineCore_DP0 pid=450090) .b8 114
(EngineCore_DP0 pid=450090) .b8 115
(EngineCore_DP0 pid=450090) .b8 101
(EngineCore_DP0 pid=450090) .b8 47
(EngineCore_DP0 pid=450090) .b8 99
(EngineCore_DP0 pid=450090) .b8 115
(EngineCore_DP0 pid=450090) .b8 114
(EngineCore_DP0 pid=450090) .b8 99
(EngineCore_DP0 pid=450090) .b8 47
(EngineCore_DP0 pid=450090) .b8 102
(EngineCore_DP0 pid=450090) .b8 117
(EngineCore_DP0 pid=450090) .b8 115
(EngineCore_DP0 pid=450090) .b8 101
(EngineCore_DP0 pid=450090) .b8 100
(EngineCore_DP0 pid=450090) .b8 95
(EngineCore_DP0 pid=450090) .b8 113
(EngineCore_DP0 pid=450090) .b8 117
(EngineCore_DP0 pid=450090) .b8 97
(EngineCore_DP0 pid=450090) .b8 110
(EngineCore_DP0 pid=450090) .b8 116
(EngineCore_DP0 pid=450090) .b8 95
(EngineCore_DP0 pid=450090) .b8 115
(EngineCore_DP0 pid=450090) .b8 108
(EngineCore_DP0 pid=450090) .b8 105
(EngineCore_DP0 pid=450090) .b8 100
(EngineCore_DP0 pid=450090) .b8 101
(EngineCore_DP0 pid=450090) .b8 95
(EngineCore_DP0 pid=450090) .b8 116
(EngineCore_DP0 pid=450090) .b8 114
(EngineCore_DP0 pid=450090) .b8 105
(EngineCore_DP0 pid=450090) .b8 116
(EngineCore_DP0 pid=450090) .b8 111
(EngineCore_DP0 pid=450090) .b8 110
(EngineCore_DP0 pid=450090) .b8 47
(EngineCore_DP0 pid=450090) .b8 98
(EngineCore_DP0 pid=450090) .b8 117
(EngineCore_DP0 pid=450090) .b8 105
(EngineCore_DP0 pid=450090) .b8 108
(EngineCore_DP0 pid=450090) .b8 100
(EngineCore_DP0 pid=450090) .b8 47
(EngineCore_DP0 pid=450090) .b8 71
(EngineCore_DP0 pid=450090) .b8 66
(EngineCore_DP0 pid=450090) .b8 49
(EngineCore_DP0 pid=450090) .b8 48
(EngineCore_DP0 pid=450090) .b8 95
(EngineCore_DP0 pid=450090) .b8 99
(EngineCore_DP0 pid=450090) .b8 99
(EngineCore_DP0 pid=450090) .b8 49
(EngineCore_DP0 pid=450090) .b8 50
(EngineCore_DP0 pid=450090) .b8 49
(EngineCore_DP0 pid=450090) .b8 95
(EngineCore_DP0 pid=450090) .b8 112
(EngineCore_DP0 pid=450090) .b8 121
(EngineCore_DP0 pid=450090) .b8 51
(EngineCore_DP0 pid=450090) .b8 49
(EngineCore_DP0 pid=450090) .b8 50
(EngineCore_DP0 pid=450090) .b8 95
(EngineCore_DP0 pid=450090) .b8 99
(EngineCore_DP0 pid=450090) .b8 117
(EngineCore_DP0 pid=450090) .b8 49
(EngineCore_DP0 pid=450090) .b8 50
(EngineCore_DP0 pid=450090) .b8 57
(EngineCore_DP0 pid=450090) .b8 95
(EngineCore_DP0 pid=450090) .b8 97
(EngineCore_DP0 pid=450090) .b8 97
(EngineCore_DP0 pid=450090) .b8 114
(EngineCore_DP0 pid=450090) .b8 99
(EngineCore_DP0 pid=450090) .b8 104
(EngineCore_DP0 pid=450090) .b8 54
(EngineCore_DP0 pid=450090) .b8 52
(EngineCore_DP0 pid=450090) .b8 0
(EngineCore_DP0 pid=450090) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=450090) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=450090) .b8 113
(EngineCore_DP0 pid=450090) .b8 117
(EngineCore_DP0 pid=450090) .b8 97
(EngineCore_DP0 pid=450090) .b8 110
(EngineCore_DP0 pid=450090) .b8 116
(EngineCore_DP0 pid=450090) .b8 95
(EngineCore_DP0 pid=450090) .b8 115
(EngineCore_DP0 pid=450090) .b8 108
(EngineCore_DP0 pid=450090) .b8 105
(EngineCore_DP0 pid=450090) .b8 100
(EngineCore_DP0 pid=450090) .b8 101
(EngineCore_DP0 pid=450090) .b8 95
(EngineCore_DP0 pid=450090) .b8 105
(EngineCore_DP0 pid=450090) .b8 110
(EngineCore_DP0 pid=450090) .b8 116
(EngineCore_DP0 pid=450090) .b8 56
(EngineCore_DP0 pid=450090) .b8 95
(EngineCore_DP0 pid=450090) .b8 107
(EngineCore_DP0 pid=450090) .b8 101
(EngineCore_DP0 pid=450090) .b8 114
(EngineCore_DP0 pid=450090) .b8 110
(EngineCore_DP0 pid=450090) .b8 101
(EngineCore_DP0 pid=450090) .b8 108
(EngineCore_DP0 pid=450090) .b8 0
(EngineCore_DP0 pid=450090) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=450090) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=450090) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=450090) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=450090) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=450090) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=450090) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=450090) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=450090) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=450090) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=450090) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=450090) .b8 1
(EngineCore_DP0 pid=450090) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=450090) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=450090) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=450090) 	}
(EngineCore_DP0 pid=450090) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=450090) 
(EngineCore_DP0 pid=450090) ================================================================
(EngineCore_DP0 pid=450090) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=450090) 
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpoqou0njn.ptx', '-o', '/tmp/tmpoqou0njn.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866] 
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866] 
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866] 
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpoqou0njn.ptx -o /tmp/tmpoqou0njn.ptx.o
(EngineCore_DP0 pid=450090) ERROR 01-25 21:01:42 [core.py:866] 

STDERR:
[2026-01-25 21:00:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:00:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:00:29] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:00:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:00:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:00:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:00:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:00:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:00:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:00:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:00:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:00:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:00:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:00:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:00:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:00:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:00:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=450090) [2026-01-25 21:00:33] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=450090) [2026-01-25 21:00:33] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=450090) [2026-01-25 21:00:33] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=450090) [2026-01-25 21:00:33] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=450090) [2026-01-25 21:00:33] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=450090) [2026-01-25 21:00:33] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=450090) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=450090) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.23s/it]
(EngineCore_DP0 pid=450090) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 33.25s/it]
(EngineCore_DP0 pid=450090) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 32.49s/it]
(EngineCore_DP0 pid=450090) 
(EngineCore_DP0 pid=450090) [2026-01-25 21:01:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=450090) [2026-01-25 21:01:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=450090) [2026-01-25 21:01:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=450090) [2026-01-25 21:01:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=450090) [2026-01-25 21:01:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=450090) [2026-01-25 21:01:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=450090) [2026-01-25 21:01:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=450090) [2026-01-25 21:01:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=450090) Process EngineCore_DP0:
(EngineCore_DP0 pid=450090) Traceback (most recent call last):
(EngineCore_DP0 pid=450090)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=450090)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=450090)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=450090)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=450090) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpoqou0njn.ptx', '-o', '/tmp/tmpoqou0njn.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=450090) 
(EngineCore_DP0 pid=450090) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=450090) 
(EngineCore_DP0 pid=450090) Traceback (most recent call last):
(EngineCore_DP0 pid=450090)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=450090)     self.run()
(EngineCore_DP0 pid=450090)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=450090)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=450090)     raise e
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=450090)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=450090)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=450090)     super().__init__(
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=450090)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=450090)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=450090)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=450090)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=450090)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=450090)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=450090)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=450090)     return func(*args, **kwargs)
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=450090)     return func(*args, **kwargs)
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=450090)     self.model_runner.profile_run()
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=450090)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=450090)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=450090)     return func(*args, **kwargs)
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=450090)     outputs = self.model(
(EngineCore_DP0 pid=450090)               ^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=450090)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=450090)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=450090)     hidden_states = self.model(
(EngineCore_DP0 pid=450090)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=450090)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=450090)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=450090)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=450090)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=450090)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=450090)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=450090)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=450090)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=450090)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=450090)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=450090)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=450090)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=450090)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=450090)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=450090)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=450090)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=450090)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=450090)     return self._linear_fn(
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=450090)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=450090)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=450090)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=450090)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=450090)     return fn(input, L)
(EngineCore_DP0 pid=450090)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=450090)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=450090)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=450090)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=450090)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=450090)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=450090)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=450090)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=450090)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=450090)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=450090)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=450090)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=450090)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=450090)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=450090)     raise PTXASError(error)
(EngineCore_DP0 pid=450090) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=450090) `ptxas` stderr:
(EngineCore_DP0 pid=450090) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=450090) 
(EngineCore_DP0 pid=450090) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpoqou0njn.ptx -o /tmp/tmpoqou0njn.ptx.o
(EngineCore_DP0 pid=450090) 
[rank0]:[W125 21:01:42.652757673 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 21:01:44
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:01:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:01:49 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=451391) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=451391) 
(EngineCore_DP0 pid=451391) 
(EngineCore_DP0 pid=451391) ================================================================
(EngineCore_DP0 pid=451391) Internal Triton PTX codegen error
(EngineCore_DP0 pid=451391) `ptxas` stderr:
(EngineCore_DP0 pid=451391) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=451391) 
(EngineCore_DP0 pid=451391) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp7nrmqeoa.ptx -o /tmp/tmp7nrmqeoa.ptx.o
(EngineCore_DP0 pid=451391) 
(EngineCore_DP0 pid=451391) 
(EngineCore_DP0 pid=451391) //
(EngineCore_DP0 pid=451391) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=451391) //
(EngineCore_DP0 pid=451391) 
(EngineCore_DP0 pid=451391) .version 8.7
(EngineCore_DP0 pid=451391) .target sm_121a
(EngineCore_DP0 pid=451391) .address_size 64
(EngineCore_DP0 pid=451391) 
(EngineCore_DP0 pid=451391) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=451391) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=451391)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=451391) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=451391) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=451391) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=451391) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=451391) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=451391) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=451391) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=451391) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=451391) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=451391) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=451391) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=451391) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=451391) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=451391) )
(EngineCore_DP0 pid=451391) .reqntid 512
(EngineCore_DP0 pid=451391) {
(EngineCore_DP0 pid=451391) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=451391) 	.reg .b16 	%rs<40>;
(EngineCore_DP0 pid=451391) 	.reg .b32 	%r<172>;
(EngineCore_DP0 pid=451391) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=451391) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=451391) $L__func_begin0:
(EngineCore_DP0 pid=451391) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=451391) 
(EngineCore_DP0 pid=451391) // %bb.0:
(EngineCore_DP0 pid=451391) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=451391) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=451391) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=451391) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=451391) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=451391) $L__tmp0:
(EngineCore_DP0 pid=451391) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=451391) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=451391) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=451391) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=451391) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=451391) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=451391) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=451391) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=451391) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=451391) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=451391) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=451391) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=451391) 	mov.b32 	%r170, 0f2B8CBCCC;
(EngineCore_DP0 pid=451391) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=451391) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=451391) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=451391) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=451391) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=451391) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=451391) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=451391) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=451391) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=451391) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=451391) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=451391) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=451391) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=451391) 	mov.b32 	%r168, 0f00000000;
(EngineCore_DP0 pid=451391) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=451391) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=451391) 	mov.b32 	%r169, %r45;
(EngineCore_DP0 pid=451391) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=451391) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=451391) 	add.s32 	%r55, %r4, %r169;
(EngineCore_DP0 pid=451391) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=451391) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=451391) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=451391) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=451391) 	// begin inline asm
(EngineCore_DP0 pid=451391) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=451391) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=451391) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=451391) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=451391) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=451391) 	// end inline asm
(EngineCore_DP0 pid=451391) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=451391) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=451391) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=451391) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=451391) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=451391) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=451391) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=451391) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=451391) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=451391) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=451391) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=451391) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=451391) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=451391) $L__tmp1:
(EngineCore_DP0 pid=451391) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	bar.sync 	0;
(EngineCore_DP0 pid=451391) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=451391) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=451391) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=451391) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=451391) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=451391) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=451391) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=451391) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=451391) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=451391) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=451391) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=451391) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=451391) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=451391) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=451391) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=451391) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=451391) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=451391) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=451391) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	// begin inline asm
(EngineCore_DP0 pid=451391) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=451391) 	// end inline asm
(EngineCore_DP0 pid=451391) 	bar.sync 	0;
(EngineCore_DP0 pid=451391) 	// begin inline asm
(EngineCore_DP0 pid=451391) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=451391) 	// end inline asm
(EngineCore_DP0 pid=451391) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=451391) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=451391) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=451391) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=451391) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=451391) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=451391) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=451391) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=451391) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=451391) 	// begin inline asm
(EngineCore_DP0 pid=451391) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=451391) 	// end inline asm
(EngineCore_DP0 pid=451391) 	bar.sync 	0;
(EngineCore_DP0 pid=451391) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=451391) $L__tmp2:
(EngineCore_DP0 pid=451391) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=451391) 	max.f32 	%r168, %r168, %r73;
(EngineCore_DP0 pid=451391) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=451391) 	add.s32 	%r169, %r169, 4096;
(EngineCore_DP0 pid=451391) 	setp.lt.s32 	%p6, %r169, %r24;
(EngineCore_DP0 pid=451391) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=451391) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=451391) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=451391) 	max.f32 	%r170, %r168, 0f2B8CBCCC;
(EngineCore_DP0 pid=451391) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=451391) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=451391) 	mov.b32 	%r75, 0f42FE0000;
(EngineCore_DP0 pid=451391) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=451391) 	div.full.f32 	%r76, %r170, %r75;
(EngineCore_DP0 pid=451391) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=451391) 	max.f32 	%r74, %r76, 0f37810204;
(EngineCore_DP0 pid=451391) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=451391) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=451391) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=451391) 	// begin inline asm
(EngineCore_DP0 pid=451391) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=451391) 	// end inline asm
(EngineCore_DP0 pid=451391) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=451391) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=451391) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=451391) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=451391) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=451391) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=451391) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=451391) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=451391) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=451391) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=451391) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=451391) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=451391) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=451391) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=451391) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=451391) 	div.full.f32 	%r14, %r75, %r170;
(EngineCore_DP0 pid=451391) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=451391) 	mov.b32 	%r171, 0;
(EngineCore_DP0 pid=451391) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=451391)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=451391) 	.loc	1 279 31                        // quant_slide_tuned_Qwen2.5-7B.py:279:31
(EngineCore_DP0 pid=451391) 	add.s32 	%r80, %r16, %r171;
(EngineCore_DP0 pid=451391) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=451391) 	add.s32 	%r81, %r80, 1;
(EngineCore_DP0 pid=451391) 	setp.lt.s32 	%p17, %r80, %r15;
(EngineCore_DP0 pid=451391) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=451391) 	shr.s32 	%r82, %r80, 31;
(EngineCore_DP0 pid=451391) 	shr.u32 	%r83, %r82, 30;
(EngineCore_DP0 pid=451391) 	add.s32 	%r84, %r80, %r83;
(EngineCore_DP0 pid=451391) 	shr.s32 	%r85, %r84, 2;
(EngineCore_DP0 pid=451391) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=451391) 	shr.s32 	%r86, %r81, 31;
(EngineCore_DP0 pid=451391) 	shr.u32 	%r87, %r86, 30;
(EngineCore_DP0 pid=451391) 	add.s32 	%r88, %r81, %r87;
(EngineCore_DP0 pid=451391) 	and.b32 	%r89, %r88, 2147483644;
(EngineCore_DP0 pid=451391) 	sub.s32 	%r90, %r81, %r89;
(EngineCore_DP0 pid=451391) 	and.b32 	%r91, %r84, 2147483644;
(EngineCore_DP0 pid=451391) 	sub.s32 	%r92, %r80, %r91;
(EngineCore_DP0 pid=451391) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=451391) 	mul.lo.s32 	%r93, %r85, 10;
(EngineCore_DP0 pid=451391) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=451391) 	shl.b32 	%r94, %r92, 1;
(EngineCore_DP0 pid=451391) 	shl.b32 	%r95, %r90, 1;
(EngineCore_DP0 pid=451391) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=451391) 	add.s32 	%r96, %r93, %r95;
(EngineCore_DP0 pid=451391) 	add.s32 	%r97, %r93, %r94;
(EngineCore_DP0 pid=451391) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=451391) 	setp.lt.s32 	%p18, %r97, %r23;
(EngineCore_DP0 pid=451391) 	setp.lt.s32 	%p19, %r96, %r23;
(EngineCore_DP0 pid=451391) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=451391) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=451391) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=451391) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=451391) 	mad.wide.s32 	%rd8, %r97, 2, %rd1;
(EngineCore_DP0 pid=451391) 	mad.wide.s32 	%rd9, %r96, 2, %rd1;
(EngineCore_DP0 pid=451391) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=451391) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=451391) 	// begin inline asm
(EngineCore_DP0 pid=451391) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=451391) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=451391) 	// end inline asm
(EngineCore_DP0 pid=451391) 	// begin inline asm
(EngineCore_DP0 pid=451391) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=451391) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=451391) 	// end inline asm
(EngineCore_DP0 pid=451391) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=451391) 	cvt.f32.bf16 	%r98, %rs24;
(EngineCore_DP0 pid=451391) 	cvt.f32.bf16 	%r99, %rs26;
(EngineCore_DP0 pid=451391) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=451391) 	or.b32 	%r100, %r97, 1;
(EngineCore_DP0 pid=451391) 	or.b32 	%r101, %r96, 1;
(EngineCore_DP0 pid=451391) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=451391) 	setp.lt.s32 	%p20, %r100, %r23;
(EngineCore_DP0 pid=451391) 	setp.lt.s32 	%p21, %r101, %r23;
(EngineCore_DP0 pid=451391) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=451391) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=451391) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=451391) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=451391) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=451391) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=451391) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=451391) 	// begin inline asm
(EngineCore_DP0 pid=451391) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=451391) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=451391) 	// end inline asm
(EngineCore_DP0 pid=451391) 	// begin inline asm
(EngineCore_DP0 pid=451391) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=451391) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=451391) 	// end inline asm
(EngineCore_DP0 pid=451391) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=451391) 	cvt.f32.bf16 	%r102, %rs28;
(EngineCore_DP0 pid=451391) 	cvt.f32.bf16 	%r103, %rs30;
(EngineCore_DP0 pid=451391) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=451391) 	add.s32 	%r104, %r97, 2;
(EngineCore_DP0 pid=451391) 	add.s32 	%r105, %r96, 2;
(EngineCore_DP0 pid=451391) 	add.s32 	%r106, %r97, 3;
(EngineCore_DP0 pid=451391) 	add.s32 	%r107, %r96, 3;
(EngineCore_DP0 pid=451391) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=451391) 	setp.lt.s32 	%p22, %r107, %r23;
(EngineCore_DP0 pid=451391) 	setp.lt.s32 	%p23, %r106, %r23;
(EngineCore_DP0 pid=451391) 	setp.lt.s32 	%p24, %r105, %r23;
(EngineCore_DP0 pid=451391) 	setp.lt.s32 	%p25, %r104, %r23;
(EngineCore_DP0 pid=451391) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=451391) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=451391) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=451391) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=451391) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=451391) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=451391) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=451391) 	// begin inline asm
(EngineCore_DP0 pid=451391) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=451391) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=451391) 	// end inline asm
(EngineCore_DP0 pid=451391) 	// begin inline asm
(EngineCore_DP0 pid=451391) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=451391) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=451391) 	// end inline asm
(EngineCore_DP0 pid=451391) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=451391) 	cvt.f32.bf16 	%r108, %rs32;
(EngineCore_DP0 pid=451391) 	cvt.f32.bf16 	%r109, %rs34;
(EngineCore_DP0 pid=451391) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=451391) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=451391) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=451391) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=451391) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=451391) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=451391) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=451391) 	// begin inline asm
(EngineCore_DP0 pid=451391) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=451391) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=451391) 	// end inline asm
(EngineCore_DP0 pid=451391) 	// begin inline asm
(EngineCore_DP0 pid=451391) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=451391) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=451391) 	// end inline asm
(EngineCore_DP0 pid=451391) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=451391) 	cvt.f32.bf16 	%r110, %rs36;
(EngineCore_DP0 pid=451391) 	cvt.f32.bf16 	%r111, %rs38;
(EngineCore_DP0 pid=451391) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=451391) 	mul.f32 	%r112, %r14, %r98;
(EngineCore_DP0 pid=451391) 	mul.f32 	%r113, %r14, %r99;
(EngineCore_DP0 pid=451391) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=451391) 	cvt.rni.f32.f32 	%r114, %r112;
(EngineCore_DP0 pid=451391) 	cvt.rni.f32.f32 	%r115, %r113;
(EngineCore_DP0 pid=451391) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=451391) 	max.f32 	%r116, %r114, 0fC3000000;
(EngineCore_DP0 pid=451391) 	min.f32 	%r117, %r116, 0f42FE0000;
(EngineCore_DP0 pid=451391) 	max.f32 	%r118, %r115, 0fC3000000;
(EngineCore_DP0 pid=451391) 	min.f32 	%r119, %r118, 0f42FE0000;
(EngineCore_DP0 pid=451391) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=451391) 	cvt.rzi.s32.f32 	%r120, %r117;
(EngineCore_DP0 pid=451391) 	cvt.rzi.s32.f32 	%r121, %r119;
(EngineCore_DP0 pid=451391) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=451391) 	and.b32 	%r122, %r120, 255;
(EngineCore_DP0 pid=451391) 	and.b32 	%r123, %r121, 255;
(EngineCore_DP0 pid=451391) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=451391) 	mul.f32 	%r124, %r14, %r102;
(EngineCore_DP0 pid=451391) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=451391) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=451391) 	cvt.rni.f32.f32 	%r126, %r124;
(EngineCore_DP0 pid=451391) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=451391) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=451391) 	mul.f32 	%r128, %r14, %r108;
(EngineCore_DP0 pid=451391) 	mul.f32 	%r129, %r14, %r109;
(EngineCore_DP0 pid=451391) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=451391) 	cvt.rni.f32.f32 	%r130, %r128;
(EngineCore_DP0 pid=451391) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=451391) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=451391) 	mul.f32 	%r132, %r14, %r110;
(EngineCore_DP0 pid=451391) 	mul.f32 	%r133, %r14, %r111;
(EngineCore_DP0 pid=451391) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=451391) 	cvt.rni.f32.f32 	%r134, %r132;
(EngineCore_DP0 pid=451391) 	cvt.rni.f32.f32 	%r135, %r133;
(EngineCore_DP0 pid=451391) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=451391) 	max.f32 	%r136, %r134, 0fC3000000;
(EngineCore_DP0 pid=451391) 	min.f32 	%r137, %r136, 0f42FE0000;
(EngineCore_DP0 pid=451391) 	max.f32 	%r138, %r135, 0fC3000000;
(EngineCore_DP0 pid=451391) 	min.f32 	%r139, %r138, 0f42FE0000;
(EngineCore_DP0 pid=451391) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=451391) 	cvt.rzi.s32.f32 	%r140, %r137;
(EngineCore_DP0 pid=451391) 	cvt.rzi.s32.f32 	%r141, %r139;
(EngineCore_DP0 pid=451391) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=451391) 	max.f32 	%r142, %r130, 0fC3000000;
(EngineCore_DP0 pid=451391) 	max.f32 	%r143, %r126, 0fC3000000;
(EngineCore_DP0 pid=451391) 	min.f32 	%r144, %r143, 0f42FE0000;
(EngineCore_DP0 pid=451391) 	min.f32 	%r145, %r142, 0f42FE0000;
(EngineCore_DP0 pid=451391) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=451391) 	cvt.rzi.s32.f32 	%r146, %r145;
(EngineCore_DP0 pid=451391) 	cvt.rzi.s32.f32 	%r147, %r144;
(EngineCore_DP0 pid=451391) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=451391) 	shl.b32 	%r148, %r147, 8;
(EngineCore_DP0 pid=451391) 	shl.b32 	%r149, %r146, 16;
(EngineCore_DP0 pid=451391) 	and.b32 	%r150, %r149, 16711680;
(EngineCore_DP0 pid=451391) 	and.b32 	%r151, %r148, 65280;
(EngineCore_DP0 pid=451391) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=451391) 	or.b32 	%r152, %r151, %r122;
(EngineCore_DP0 pid=451391) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=451391) 	max.f32 	%r153, %r131, 0fC3000000;
(EngineCore_DP0 pid=451391) 	max.f32 	%r154, %r127, 0fC3000000;
(EngineCore_DP0 pid=451391) 	min.f32 	%r155, %r154, 0f42FE0000;
(EngineCore_DP0 pid=451391) 	min.f32 	%r156, %r153, 0f42FE0000;
(EngineCore_DP0 pid=451391) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=451391) 	cvt.rzi.s32.f32 	%r157, %r156;
(EngineCore_DP0 pid=451391) 	cvt.rzi.s32.f32 	%r158, %r155;
(EngineCore_DP0 pid=451391) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=451391) 	shl.b32 	%r159, %r158, 8;
(EngineCore_DP0 pid=451391) 	shl.b32 	%r160, %r157, 16;
(EngineCore_DP0 pid=451391) 	and.b32 	%r161, %r160, 16711680;
(EngineCore_DP0 pid=451391) 	and.b32 	%r162, %r159, 65280;
(EngineCore_DP0 pid=451391) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=451391) 	or.b32 	%r163, %r162, %r123;
(EngineCore_DP0 pid=451391) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=451391) 	or.b32 	%r164, %r152, %r150;
(EngineCore_DP0 pid=451391) 	or.b32 	%r165, %r163, %r161;
(EngineCore_DP0 pid=451391) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=451391) 	shl.b32 	%r166, %r140, 24;
(EngineCore_DP0 pid=451391) 	shl.b32 	%r167, %r141, 24;
(EngineCore_DP0 pid=451391) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=451391) 	or.b32 	%r78, %r164, %r166;
(EngineCore_DP0 pid=451391) 	or.b32 	%r79, %r165, %r167;
(EngineCore_DP0 pid=451391) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=451391) 	mad.wide.s32 	%rd16, %r80, 4, %rd2;
(EngineCore_DP0 pid=451391) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=451391) 	// begin inline asm
(EngineCore_DP0 pid=451391) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r78, %r79 };
(EngineCore_DP0 pid=451391) 	// end inline asm
(EngineCore_DP0 pid=451391) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=451391) 	add.s32 	%r171, %r171, 1024;
(EngineCore_DP0 pid=451391) 	setp.lt.s32 	%p26, %r171, %r15;
(EngineCore_DP0 pid=451391) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=451391) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=451391) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=451391) 	ret;
(EngineCore_DP0 pid=451391) $L__tmp3:
(EngineCore_DP0 pid=451391) $L__func_end0:
(EngineCore_DP0 pid=451391)                                         // -- End function
(EngineCore_DP0 pid=451391) }
(EngineCore_DP0 pid=451391) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=451391) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=451391) 	.section	.debug_abbrev
(EngineCore_DP0 pid=451391) 	{
(EngineCore_DP0 pid=451391) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=451391) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=451391) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=451391) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=451391) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=451391) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=451391) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=451391) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=451391) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=451391) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=451391) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=451391) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=451391) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=451391) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=451391) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=451391) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=451391) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=451391) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=451391) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=451391) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=451391) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=451391) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=451391) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=451391) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=451391) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=451391) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=451391) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=451391) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=451391) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=451391) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=451391) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=451391) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=451391) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=451391) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=451391) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=451391) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=451391) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=451391) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=451391) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=451391) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=451391) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=451391) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=451391) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=451391) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=451391) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=451391) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=451391) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=451391) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=451391) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=451391) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=451391) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=451391) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=451391) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=451391) 	}
(EngineCore_DP0 pid=451391) 	.section	.debug_info
(EngineCore_DP0 pid=451391) 	{
(EngineCore_DP0 pid=451391) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=451391) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=451391) .b8 0
(EngineCore_DP0 pid=451391) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=451391) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=451391) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=451391) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=451391) .b8 114
(EngineCore_DP0 pid=451391) .b8 105
(EngineCore_DP0 pid=451391) .b8 116
(EngineCore_DP0 pid=451391) .b8 111
(EngineCore_DP0 pid=451391) .b8 110
(EngineCore_DP0 pid=451391) .b8 0
(EngineCore_DP0 pid=451391) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=451391) .b8 0
(EngineCore_DP0 pid=451391) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=451391) .b8 117
(EngineCore_DP0 pid=451391) .b8 97
(EngineCore_DP0 pid=451391) .b8 110
(EngineCore_DP0 pid=451391) .b8 116
(EngineCore_DP0 pid=451391) .b8 95
(EngineCore_DP0 pid=451391) .b8 115
(EngineCore_DP0 pid=451391) .b8 108
(EngineCore_DP0 pid=451391) .b8 105
(EngineCore_DP0 pid=451391) .b8 100
(EngineCore_DP0 pid=451391) .b8 101
(EngineCore_DP0 pid=451391) .b8 95
(EngineCore_DP0 pid=451391) .b8 116
(EngineCore_DP0 pid=451391) .b8 117
(EngineCore_DP0 pid=451391) .b8 110
(EngineCore_DP0 pid=451391) .b8 101
(EngineCore_DP0 pid=451391) .b8 100
(EngineCore_DP0 pid=451391) .b8 95
(EngineCore_DP0 pid=451391) .b8 81
(EngineCore_DP0 pid=451391) .b8 119
(EngineCore_DP0 pid=451391) .b8 101
(EngineCore_DP0 pid=451391) .b8 110
(EngineCore_DP0 pid=451391) .b8 50
(EngineCore_DP0 pid=451391) .b8 46
(EngineCore_DP0 pid=451391) .b8 53
(EngineCore_DP0 pid=451391) .b8 45
(EngineCore_DP0 pid=451391) .b8 55
(EngineCore_DP0 pid=451391) .b8 66
(EngineCore_DP0 pid=451391) .b8 46
(EngineCore_DP0 pid=451391) .b8 112
(EngineCore_DP0 pid=451391) .b8 121
(EngineCore_DP0 pid=451391) .b8 0
(EngineCore_DP0 pid=451391) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=451391) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=451391) .b8 114
(EngineCore_DP0 pid=451391) .b8 111
(EngineCore_DP0 pid=451391) .b8 111
(EngineCore_DP0 pid=451391) .b8 116
(EngineCore_DP0 pid=451391) .b8 47
(EngineCore_DP0 pid=451391) .b8 118
(EngineCore_DP0 pid=451391) .b8 108
(EngineCore_DP0 pid=451391) .b8 108
(EngineCore_DP0 pid=451391) .b8 109
(EngineCore_DP0 pid=451391) .b8 98
(EngineCore_DP0 pid=451391) .b8 101
(EngineCore_DP0 pid=451391) .b8 110
(EngineCore_DP0 pid=451391) .b8 99
(EngineCore_DP0 pid=451391) .b8 104
(EngineCore_DP0 pid=451391) .b8 47
(EngineCore_DP0 pid=451391) .b8 115
(EngineCore_DP0 pid=451391) .b8 108
(EngineCore_DP0 pid=451391) .b8 105
(EngineCore_DP0 pid=451391) .b8 100
(EngineCore_DP0 pid=451391) .b8 101
(EngineCore_DP0 pid=451391) .b8 115
(EngineCore_DP0 pid=451391) .b8 112
(EngineCore_DP0 pid=451391) .b8 97
(EngineCore_DP0 pid=451391) .b8 114
(EngineCore_DP0 pid=451391) .b8 115
(EngineCore_DP0 pid=451391) .b8 101
(EngineCore_DP0 pid=451391) .b8 47
(EngineCore_DP0 pid=451391) .b8 99
(EngineCore_DP0 pid=451391) .b8 115
(EngineCore_DP0 pid=451391) .b8 114
(EngineCore_DP0 pid=451391) .b8 99
(EngineCore_DP0 pid=451391) .b8 47
(EngineCore_DP0 pid=451391) .b8 102
(EngineCore_DP0 pid=451391) .b8 117
(EngineCore_DP0 pid=451391) .b8 115
(EngineCore_DP0 pid=451391) .b8 101
(EngineCore_DP0 pid=451391) .b8 100
(EngineCore_DP0 pid=451391) .b8 95
(EngineCore_DP0 pid=451391) .b8 113
(EngineCore_DP0 pid=451391) .b8 117
(EngineCore_DP0 pid=451391) .b8 97
(EngineCore_DP0 pid=451391) .b8 110
(EngineCore_DP0 pid=451391) .b8 116
(EngineCore_DP0 pid=451391) .b8 95
(EngineCore_DP0 pid=451391) .b8 115
(EngineCore_DP0 pid=451391) .b8 108
(EngineCore_DP0 pid=451391) .b8 105
(EngineCore_DP0 pid=451391) .b8 100
(EngineCore_DP0 pid=451391) .b8 101
(EngineCore_DP0 pid=451391) .b8 95
(EngineCore_DP0 pid=451391) .b8 116
(EngineCore_DP0 pid=451391) .b8 114
(EngineCore_DP0 pid=451391) .b8 105
(EngineCore_DP0 pid=451391) .b8 116
(EngineCore_DP0 pid=451391) .b8 111
(EngineCore_DP0 pid=451391) .b8 110
(EngineCore_DP0 pid=451391) .b8 47
(EngineCore_DP0 pid=451391) .b8 98
(EngineCore_DP0 pid=451391) .b8 117
(EngineCore_DP0 pid=451391) .b8 105
(EngineCore_DP0 pid=451391) .b8 108
(EngineCore_DP0 pid=451391) .b8 100
(EngineCore_DP0 pid=451391) .b8 47
(EngineCore_DP0 pid=451391) .b8 71
(EngineCore_DP0 pid=451391) .b8 66
(EngineCore_DP0 pid=451391) .b8 49
(EngineCore_DP0 pid=451391) .b8 48
(EngineCore_DP0 pid=451391) .b8 95
(EngineCore_DP0 pid=451391) .b8 99
(EngineCore_DP0 pid=451391) .b8 99
(EngineCore_DP0 pid=451391) .b8 49
(EngineCore_DP0 pid=451391) .b8 50
(EngineCore_DP0 pid=451391) .b8 49
(EngineCore_DP0 pid=451391) .b8 95
(EngineCore_DP0 pid=451391) .b8 112
(EngineCore_DP0 pid=451391) .b8 121
(EngineCore_DP0 pid=451391) .b8 51
(EngineCore_DP0 pid=451391) .b8 49
(EngineCore_DP0 pid=451391) .b8 50
(EngineCore_DP0 pid=451391) .b8 95
(EngineCore_DP0 pid=451391) .b8 99
(EngineCore_DP0 pid=451391) .b8 117
(EngineCore_DP0 pid=451391) .b8 49
(EngineCore_DP0 pid=451391) .b8 50
(EngineCore_DP0 pid=451391) .b8 57
(EngineCore_DP0 pid=451391) .b8 95
(EngineCore_DP0 pid=451391) .b8 97
(EngineCore_DP0 pid=451391) .b8 97
(EngineCore_DP0 pid=451391) .b8 114
(EngineCore_DP0 pid=451391) .b8 99
(EngineCore_DP0 pid=451391) .b8 104
(EngineCore_DP0 pid=451391) .b8 54
(EngineCore_DP0 pid=451391) .b8 52
(EngineCore_DP0 pid=451391) .b8 0
(EngineCore_DP0 pid=451391) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=451391) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=451391) .b8 113
(EngineCore_DP0 pid=451391) .b8 117
(EngineCore_DP0 pid=451391) .b8 97
(EngineCore_DP0 pid=451391) .b8 110
(EngineCore_DP0 pid=451391) .b8 116
(EngineCore_DP0 pid=451391) .b8 95
(EngineCore_DP0 pid=451391) .b8 115
(EngineCore_DP0 pid=451391) .b8 108
(EngineCore_DP0 pid=451391) .b8 105
(EngineCore_DP0 pid=451391) .b8 100
(EngineCore_DP0 pid=451391) .b8 101
(EngineCore_DP0 pid=451391) .b8 95
(EngineCore_DP0 pid=451391) .b8 105
(EngineCore_DP0 pid=451391) .b8 110
(EngineCore_DP0 pid=451391) .b8 116
(EngineCore_DP0 pid=451391) .b8 56
(EngineCore_DP0 pid=451391) .b8 95
(EngineCore_DP0 pid=451391) .b8 107
(EngineCore_DP0 pid=451391) .b8 101
(EngineCore_DP0 pid=451391) .b8 114
(EngineCore_DP0 pid=451391) .b8 110
(EngineCore_DP0 pid=451391) .b8 101
(EngineCore_DP0 pid=451391) .b8 108
(EngineCore_DP0 pid=451391) .b8 0
(EngineCore_DP0 pid=451391) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=451391) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=451391) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=451391) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=451391) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=451391) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=451391) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=451391) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=451391) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=451391) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=451391) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=451391) .b8 1
(EngineCore_DP0 pid=451391) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=451391) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=451391) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=451391) 	}
(EngineCore_DP0 pid=451391) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=451391) 
(EngineCore_DP0 pid=451391) ================================================================
(EngineCore_DP0 pid=451391) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=451391) 
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp7nrmqeoa.ptx', '-o', '/tmp/tmp7nrmqeoa.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866] 
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866] 
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866] 
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp7nrmqeoa.ptx -o /tmp/tmp7nrmqeoa.ptx.o
(EngineCore_DP0 pid=451391) ERROR 01-25 21:03:02 [core.py:866] 

STDERR:
[2026-01-25 21:01:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:01:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:01:49] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:01:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:01:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:01:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:01:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:01:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:01:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:01:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:01:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:01:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:01:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:01:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:01:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:01:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:01:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=451391) [2026-01-25 21:01:53] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=451391) [2026-01-25 21:01:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=451391) [2026-01-25 21:01:53] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=451391) [2026-01-25 21:01:53] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=451391) [2026-01-25 21:01:53] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=451391) [2026-01-25 21:01:53] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=451391) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=451391) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.78s/it]
(EngineCore_DP0 pid=451391) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 33.32s/it]
(EngineCore_DP0 pid=451391) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 32.49s/it]
(EngineCore_DP0 pid=451391) 
(EngineCore_DP0 pid=451391) [2026-01-25 21:02:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=451391) [2026-01-25 21:02:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=451391) [2026-01-25 21:02:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=451391) [2026-01-25 21:02:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=451391) [2026-01-25 21:02:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=451391) [2026-01-25 21:02:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=451391) [2026-01-25 21:02:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=451391) [2026-01-25 21:02:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=451391) Process EngineCore_DP0:
(EngineCore_DP0 pid=451391) Traceback (most recent call last):
(EngineCore_DP0 pid=451391)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=451391)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=451391)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=451391)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=451391) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp7nrmqeoa.ptx', '-o', '/tmp/tmp7nrmqeoa.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=451391) 
(EngineCore_DP0 pid=451391) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=451391) 
(EngineCore_DP0 pid=451391) Traceback (most recent call last):
(EngineCore_DP0 pid=451391)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=451391)     self.run()
(EngineCore_DP0 pid=451391)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=451391)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=451391)     raise e
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=451391)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=451391)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=451391)     super().__init__(
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=451391)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=451391)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=451391)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=451391)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=451391)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=451391)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=451391)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=451391)     return func(*args, **kwargs)
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=451391)     return func(*args, **kwargs)
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=451391)     self.model_runner.profile_run()
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=451391)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=451391)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=451391)     return func(*args, **kwargs)
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=451391)     outputs = self.model(
(EngineCore_DP0 pid=451391)               ^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=451391)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=451391)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=451391)     hidden_states = self.model(
(EngineCore_DP0 pid=451391)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=451391)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=451391)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=451391)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=451391)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=451391)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=451391)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=451391)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=451391)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=451391)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=451391)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=451391)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=451391)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=451391)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=451391)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=451391)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=451391)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=451391)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=451391)     return self._linear_fn(
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=451391)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=451391)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=451391)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=451391)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=451391)     return fn(input, L)
(EngineCore_DP0 pid=451391)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=451391)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=451391)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=451391)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=451391)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=451391)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=451391)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=451391)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=451391)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=451391)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=451391)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=451391)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=451391)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=451391)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=451391)     raise PTXASError(error)
(EngineCore_DP0 pid=451391) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=451391) `ptxas` stderr:
(EngineCore_DP0 pid=451391) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=451391) 
(EngineCore_DP0 pid=451391) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp7nrmqeoa.ptx -o /tmp/tmp7nrmqeoa.ptx.o
(EngineCore_DP0 pid=451391) 
[rank0]:[W125 21:03:02.809789543 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 21:03:04
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:03:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:03:11 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=452734) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=452734) 
(EngineCore_DP0 pid=452734) 
(EngineCore_DP0 pid=452734) ================================================================
(EngineCore_DP0 pid=452734) Internal Triton PTX codegen error
(EngineCore_DP0 pid=452734) `ptxas` stderr:
(EngineCore_DP0 pid=452734) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=452734) 
(EngineCore_DP0 pid=452734) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp63dwxfmz.ptx -o /tmp/tmp63dwxfmz.ptx.o
(EngineCore_DP0 pid=452734) 
(EngineCore_DP0 pid=452734) 
(EngineCore_DP0 pid=452734) //
(EngineCore_DP0 pid=452734) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=452734) //
(EngineCore_DP0 pid=452734) 
(EngineCore_DP0 pid=452734) .version 8.7
(EngineCore_DP0 pid=452734) .target sm_121a
(EngineCore_DP0 pid=452734) .address_size 64
(EngineCore_DP0 pid=452734) 
(EngineCore_DP0 pid=452734) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=452734) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=452734)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=452734) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=452734) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=452734) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=452734) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=452734) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=452734) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=452734) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=452734) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=452734) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=452734) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=452734) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=452734) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=452734) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=452734) )
(EngineCore_DP0 pid=452734) .reqntid 512
(EngineCore_DP0 pid=452734) {
(EngineCore_DP0 pid=452734) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=452734) 	.reg .b16 	%rs<64>;
(EngineCore_DP0 pid=452734) 	.reg .b32 	%r<181>;
(EngineCore_DP0 pid=452734) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=452734) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=452734) $L__func_begin0:
(EngineCore_DP0 pid=452734) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=452734) 
(EngineCore_DP0 pid=452734) // %bb.0:
(EngineCore_DP0 pid=452734) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=452734) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=452734) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=452734) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=452734) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=452734) $L__tmp0:
(EngineCore_DP0 pid=452734) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=452734) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=452734) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=452734) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=452734) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=452734) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=452734) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=452734) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=452734) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=452734) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=452734) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=452734) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=452734) 	mov.b32 	%r179, 0f2B8CBCCC;
(EngineCore_DP0 pid=452734) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=452734) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=452734) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=452734) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=452734) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=452734) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=452734) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=452734) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=452734) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=452734) 	add.s32 	%r57, %r39, %r38;
(EngineCore_DP0 pid=452734) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=452734) 	add.s32 	%r60, %r39, %r40;
(EngineCore_DP0 pid=452734) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=452734) 	mov.b32 	%r177, 0f00000000;
(EngineCore_DP0 pid=452734) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=452734) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=452734) 	mov.b32 	%r178, %r45;
(EngineCore_DP0 pid=452734) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=452734) 	.loc	1 265 19                        // quant_slide_tuned_Qwen2.5-7B.py:265:19
(EngineCore_DP0 pid=452734) 	add.s32 	%r63, %r4, %r178;
(EngineCore_DP0 pid=452734) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=452734) 	add.s32 	%r64, %r63, 4096;
(EngineCore_DP0 pid=452734) 	setp.lt.s32 	%p2, %r63, %r23;
(EngineCore_DP0 pid=452734) 	setp.lt.s32 	%p3, %r64, %r23;
(EngineCore_DP0 pid=452734) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=452734) 	mad.wide.s32 	%rd6, %r63, 2, %rd1;
(EngineCore_DP0 pid=452734) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=452734) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=452734) 	// begin inline asm
(EngineCore_DP0 pid=452734) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=452734) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=452734) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=452734) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=452734) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=452734) 	// end inline asm
(EngineCore_DP0 pid=452734) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=452734) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=452734) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=452734) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=452734) 	// begin inline asm
(EngineCore_DP0 pid=452734) 	mov.u32 %r49, %r45;
(EngineCore_DP0 pid=452734) 	mov.u32 %r50, %r45;
(EngineCore_DP0 pid=452734) 	mov.u32 %r51, %r45;
(EngineCore_DP0 pid=452734) 	mov.u32 %r52, %r45;
(EngineCore_DP0 pid=452734) 	@%p3 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=452734) 	// end inline asm
(EngineCore_DP0 pid=452734) 	mov.b32 	{%rs9, %rs10}, %r49;
(EngineCore_DP0 pid=452734) 	mov.b32 	{%rs11, %rs12}, %r50;
(EngineCore_DP0 pid=452734) 	mov.b32 	{%rs13, %rs14}, %r51;
(EngineCore_DP0 pid=452734) 	mov.b32 	{%rs15, %rs16}, %r52;
(EngineCore_DP0 pid=452734) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=452734) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=452734) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=452734) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=452734) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=452734) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=452734) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=452734) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=452734) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=452734) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=452734) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=452734) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=452734) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=452734) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=452734) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=452734) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=452734) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=452734) $L__tmp1:
(EngineCore_DP0 pid=452734) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	bar.sync 	0;
(EngineCore_DP0 pid=452734) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=452734) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=452734) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=452734) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=452734) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=452734) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=452734) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=452734) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=452734) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=452734) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=452734) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=452734) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=452734) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=452734) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=452734) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=452734) 	cvt.f32.bf16 	%r65, %rs47;
(EngineCore_DP0 pid=452734) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	shfl.sync.bfly.b32 	%r66, %r65, 16, 31, -1;
(EngineCore_DP0 pid=452734) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=452734) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	shfl.sync.bfly.b32 	%r68, %r67, 8, 31, -1;
(EngineCore_DP0 pid=452734) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=452734) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	shfl.sync.bfly.b32 	%r70, %r69, 4, 31, -1;
(EngineCore_DP0 pid=452734) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=452734) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	shfl.sync.bfly.b32 	%r72, %r71, 2, 31, -1;
(EngineCore_DP0 pid=452734) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=452734) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	shfl.sync.bfly.b32 	%r74, %r73, 1, 31, -1;
(EngineCore_DP0 pid=452734) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	max.f32 	%r58, %r73, %r74;
(EngineCore_DP0 pid=452734) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	// begin inline asm
(EngineCore_DP0 pid=452734) 	@%p4 st.shared.b32 [ %r57 + 0 ], %r58;
(EngineCore_DP0 pid=452734) 	// end inline asm
(EngineCore_DP0 pid=452734) 	bar.sync 	0;
(EngineCore_DP0 pid=452734) 	// begin inline asm
(EngineCore_DP0 pid=452734) 	@%p5 ld.shared.b32 %r59, [ %r60 + 0 ];
(EngineCore_DP0 pid=452734) 	// end inline asm
(EngineCore_DP0 pid=452734) 	shfl.sync.bfly.b32 	%r75, %r59, 8, 31, -1;
(EngineCore_DP0 pid=452734) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	max.f32 	%r76, %r59, %r75;
(EngineCore_DP0 pid=452734) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	shfl.sync.bfly.b32 	%r77, %r76, 4, 31, -1;
(EngineCore_DP0 pid=452734) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=452734) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	shfl.sync.bfly.b32 	%r79, %r78, 2, 31, -1;
(EngineCore_DP0 pid=452734) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	max.f32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=452734) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	shfl.sync.bfly.b32 	%r81, %r80, 1, 31, -1;
(EngineCore_DP0 pid=452734) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	max.f32 	%r62, %r80, %r81;
(EngineCore_DP0 pid=452734) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=452734) 	// begin inline asm
(EngineCore_DP0 pid=452734) 	@%p28 st.shared.b32 [ %r60 + 0 ], %r62;
(EngineCore_DP0 pid=452734) 	// end inline asm
(EngineCore_DP0 pid=452734) 	bar.sync 	0;
(EngineCore_DP0 pid=452734) 	ld.shared.b32 	%r82, [global_smem];
(EngineCore_DP0 pid=452734) $L__tmp2:
(EngineCore_DP0 pid=452734) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=452734) 	max.f32 	%r177, %r177, %r82;
(EngineCore_DP0 pid=452734) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=452734) 	add.s32 	%r178, %r178, 8192;
(EngineCore_DP0 pid=452734) 	setp.lt.s32 	%p7, %r178, %r24;
(EngineCore_DP0 pid=452734) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=452734) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=452734) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=452734) 	max.f32 	%r179, %r177, 0f2B8CBCCC;
(EngineCore_DP0 pid=452734) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=452734) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=452734) 	mov.b32 	%r84, 0f42FE0000;
(EngineCore_DP0 pid=452734) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=452734) 	div.full.f32 	%r85, %r179, %r84;
(EngineCore_DP0 pid=452734) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=452734) 	max.f32 	%r83, %r85, 0f37810204;
(EngineCore_DP0 pid=452734) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=452734) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=452734) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=452734) 	// begin inline asm
(EngineCore_DP0 pid=452734) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r83 };
(EngineCore_DP0 pid=452734) 	// end inline asm
(EngineCore_DP0 pid=452734) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=452734) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=452734) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=452734) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=452734) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=452734) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=452734) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=452734) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=452734) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=452734) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=452734) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=452734) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=452734) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=452734) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=452734) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=452734) 	div.full.f32 	%r14, %r84, %r179;
(EngineCore_DP0 pid=452734) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=452734) 	mov.b32 	%r180, 0;
(EngineCore_DP0 pid=452734) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=452734)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=452734) 	.loc	1 279 31                        // quant_slide_tuned_Qwen2.5-7B.py:279:31
(EngineCore_DP0 pid=452734) 	add.s32 	%r89, %r16, %r180;
(EngineCore_DP0 pid=452734) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=452734) 	add.s32 	%r90, %r89, 1;
(EngineCore_DP0 pid=452734) 	setp.lt.s32 	%p18, %r89, %r15;
(EngineCore_DP0 pid=452734) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=452734) 	shr.s32 	%r91, %r89, 31;
(EngineCore_DP0 pid=452734) 	shr.u32 	%r92, %r91, 30;
(EngineCore_DP0 pid=452734) 	add.s32 	%r93, %r89, %r92;
(EngineCore_DP0 pid=452734) 	shr.s32 	%r94, %r93, 2;
(EngineCore_DP0 pid=452734) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=452734) 	shr.s32 	%r95, %r90, 31;
(EngineCore_DP0 pid=452734) 	shr.u32 	%r96, %r95, 30;
(EngineCore_DP0 pid=452734) 	add.s32 	%r97, %r90, %r96;
(EngineCore_DP0 pid=452734) 	and.b32 	%r98, %r97, 2147483644;
(EngineCore_DP0 pid=452734) 	sub.s32 	%r99, %r90, %r98;
(EngineCore_DP0 pid=452734) 	and.b32 	%r100, %r93, 2147483644;
(EngineCore_DP0 pid=452734) 	sub.s32 	%r101, %r89, %r100;
(EngineCore_DP0 pid=452734) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=452734) 	mul.lo.s32 	%r102, %r94, 10;
(EngineCore_DP0 pid=452734) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=452734) 	shl.b32 	%r103, %r101, 1;
(EngineCore_DP0 pid=452734) 	shl.b32 	%r104, %r99, 1;
(EngineCore_DP0 pid=452734) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=452734) 	add.s32 	%r105, %r102, %r104;
(EngineCore_DP0 pid=452734) 	add.s32 	%r106, %r102, %r103;
(EngineCore_DP0 pid=452734) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=452734) 	setp.lt.s32 	%p19, %r106, %r23;
(EngineCore_DP0 pid=452734) 	setp.lt.s32 	%p20, %r105, %r23;
(EngineCore_DP0 pid=452734) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=452734) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=452734) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=452734) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=452734) 	mad.wide.s32 	%rd9, %r106, 2, %rd1;
(EngineCore_DP0 pid=452734) 	mad.wide.s32 	%rd10, %r105, 2, %rd1;
(EngineCore_DP0 pid=452734) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=452734) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=452734) 	// begin inline asm
(EngineCore_DP0 pid=452734) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=452734) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=452734) 	// end inline asm
(EngineCore_DP0 pid=452734) 	// begin inline asm
(EngineCore_DP0 pid=452734) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=452734) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=452734) 	// end inline asm
(EngineCore_DP0 pid=452734) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=452734) 	cvt.f32.bf16 	%r107, %rs48;
(EngineCore_DP0 pid=452734) 	cvt.f32.bf16 	%r108, %rs50;
(EngineCore_DP0 pid=452734) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=452734) 	or.b32 	%r109, %r106, 1;
(EngineCore_DP0 pid=452734) 	or.b32 	%r110, %r105, 1;
(EngineCore_DP0 pid=452734) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=452734) 	setp.lt.s32 	%p21, %r109, %r23;
(EngineCore_DP0 pid=452734) 	setp.lt.s32 	%p22, %r110, %r23;
(EngineCore_DP0 pid=452734) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=452734) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=452734) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=452734) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=452734) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=452734) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=452734) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=452734) 	// begin inline asm
(EngineCore_DP0 pid=452734) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=452734) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=452734) 	// end inline asm
(EngineCore_DP0 pid=452734) 	// begin inline asm
(EngineCore_DP0 pid=452734) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=452734) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=452734) 	// end inline asm
(EngineCore_DP0 pid=452734) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=452734) 	cvt.f32.bf16 	%r111, %rs52;
(EngineCore_DP0 pid=452734) 	cvt.f32.bf16 	%r112, %rs54;
(EngineCore_DP0 pid=452734) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=452734) 	add.s32 	%r113, %r106, 2;
(EngineCore_DP0 pid=452734) 	add.s32 	%r114, %r105, 2;
(EngineCore_DP0 pid=452734) 	add.s32 	%r115, %r106, 3;
(EngineCore_DP0 pid=452734) 	add.s32 	%r116, %r105, 3;
(EngineCore_DP0 pid=452734) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=452734) 	setp.lt.s32 	%p23, %r116, %r23;
(EngineCore_DP0 pid=452734) 	setp.lt.s32 	%p24, %r115, %r23;
(EngineCore_DP0 pid=452734) 	setp.lt.s32 	%p25, %r114, %r23;
(EngineCore_DP0 pid=452734) 	setp.lt.s32 	%p26, %r113, %r23;
(EngineCore_DP0 pid=452734) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=452734) 	and.pred 	%p14, %p18, %p26;
(EngineCore_DP0 pid=452734) 	and.pred 	%p15, %p18, %p25;
(EngineCore_DP0 pid=452734) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=452734) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=452734) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=452734) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=452734) 	// begin inline asm
(EngineCore_DP0 pid=452734) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=452734) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=452734) 	// end inline asm
(EngineCore_DP0 pid=452734) 	// begin inline asm
(EngineCore_DP0 pid=452734) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=452734) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=452734) 	// end inline asm
(EngineCore_DP0 pid=452734) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=452734) 	cvt.f32.bf16 	%r117, %rs56;
(EngineCore_DP0 pid=452734) 	cvt.f32.bf16 	%r118, %rs58;
(EngineCore_DP0 pid=452734) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=452734) 	and.pred 	%p16, %p18, %p24;
(EngineCore_DP0 pid=452734) 	and.pred 	%p17, %p18, %p23;
(EngineCore_DP0 pid=452734) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=452734) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=452734) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=452734) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=452734) 	// begin inline asm
(EngineCore_DP0 pid=452734) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=452734) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=452734) 	// end inline asm
(EngineCore_DP0 pid=452734) 	// begin inline asm
(EngineCore_DP0 pid=452734) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=452734) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=452734) 	// end inline asm
(EngineCore_DP0 pid=452734) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=452734) 	cvt.f32.bf16 	%r119, %rs60;
(EngineCore_DP0 pid=452734) 	cvt.f32.bf16 	%r120, %rs62;
(EngineCore_DP0 pid=452734) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=452734) 	mul.f32 	%r121, %r14, %r107;
(EngineCore_DP0 pid=452734) 	mul.f32 	%r122, %r14, %r108;
(EngineCore_DP0 pid=452734) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=452734) 	cvt.rni.f32.f32 	%r123, %r121;
(EngineCore_DP0 pid=452734) 	cvt.rni.f32.f32 	%r124, %r122;
(EngineCore_DP0 pid=452734) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=452734) 	max.f32 	%r125, %r123, 0fC3000000;
(EngineCore_DP0 pid=452734) 	min.f32 	%r126, %r125, 0f42FE0000;
(EngineCore_DP0 pid=452734) 	max.f32 	%r127, %r124, 0fC3000000;
(EngineCore_DP0 pid=452734) 	min.f32 	%r128, %r127, 0f42FE0000;
(EngineCore_DP0 pid=452734) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=452734) 	cvt.rzi.s32.f32 	%r129, %r126;
(EngineCore_DP0 pid=452734) 	cvt.rzi.s32.f32 	%r130, %r128;
(EngineCore_DP0 pid=452734) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=452734) 	and.b32 	%r131, %r129, 255;
(EngineCore_DP0 pid=452734) 	and.b32 	%r132, %r130, 255;
(EngineCore_DP0 pid=452734) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=452734) 	mul.f32 	%r133, %r14, %r111;
(EngineCore_DP0 pid=452734) 	mul.f32 	%r134, %r14, %r112;
(EngineCore_DP0 pid=452734) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=452734) 	cvt.rni.f32.f32 	%r135, %r133;
(EngineCore_DP0 pid=452734) 	cvt.rni.f32.f32 	%r136, %r134;
(EngineCore_DP0 pid=452734) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=452734) 	mul.f32 	%r137, %r14, %r117;
(EngineCore_DP0 pid=452734) 	mul.f32 	%r138, %r14, %r118;
(EngineCore_DP0 pid=452734) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=452734) 	cvt.rni.f32.f32 	%r139, %r137;
(EngineCore_DP0 pid=452734) 	cvt.rni.f32.f32 	%r140, %r138;
(EngineCore_DP0 pid=452734) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=452734) 	mul.f32 	%r141, %r14, %r119;
(EngineCore_DP0 pid=452734) 	mul.f32 	%r142, %r14, %r120;
(EngineCore_DP0 pid=452734) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=452734) 	cvt.rni.f32.f32 	%r143, %r141;
(EngineCore_DP0 pid=452734) 	cvt.rni.f32.f32 	%r144, %r142;
(EngineCore_DP0 pid=452734) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=452734) 	max.f32 	%r145, %r143, 0fC3000000;
(EngineCore_DP0 pid=452734) 	min.f32 	%r146, %r145, 0f42FE0000;
(EngineCore_DP0 pid=452734) 	max.f32 	%r147, %r144, 0fC3000000;
(EngineCore_DP0 pid=452734) 	min.f32 	%r148, %r147, 0f42FE0000;
(EngineCore_DP0 pid=452734) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=452734) 	cvt.rzi.s32.f32 	%r149, %r146;
(EngineCore_DP0 pid=452734) 	cvt.rzi.s32.f32 	%r150, %r148;
(EngineCore_DP0 pid=452734) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=452734) 	max.f32 	%r151, %r139, 0fC3000000;
(EngineCore_DP0 pid=452734) 	max.f32 	%r152, %r135, 0fC3000000;
(EngineCore_DP0 pid=452734) 	min.f32 	%r153, %r152, 0f42FE0000;
(EngineCore_DP0 pid=452734) 	min.f32 	%r154, %r151, 0f42FE0000;
(EngineCore_DP0 pid=452734) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=452734) 	cvt.rzi.s32.f32 	%r155, %r154;
(EngineCore_DP0 pid=452734) 	cvt.rzi.s32.f32 	%r156, %r153;
(EngineCore_DP0 pid=452734) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=452734) 	shl.b32 	%r157, %r156, 8;
(EngineCore_DP0 pid=452734) 	shl.b32 	%r158, %r155, 16;
(EngineCore_DP0 pid=452734) 	and.b32 	%r159, %r158, 16711680;
(EngineCore_DP0 pid=452734) 	and.b32 	%r160, %r157, 65280;
(EngineCore_DP0 pid=452734) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=452734) 	or.b32 	%r161, %r160, %r131;
(EngineCore_DP0 pid=452734) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=452734) 	max.f32 	%r162, %r140, 0fC3000000;
(EngineCore_DP0 pid=452734) 	max.f32 	%r163, %r136, 0fC3000000;
(EngineCore_DP0 pid=452734) 	min.f32 	%r164, %r163, 0f42FE0000;
(EngineCore_DP0 pid=452734) 	min.f32 	%r165, %r162, 0f42FE0000;
(EngineCore_DP0 pid=452734) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=452734) 	cvt.rzi.s32.f32 	%r166, %r165;
(EngineCore_DP0 pid=452734) 	cvt.rzi.s32.f32 	%r167, %r164;
(EngineCore_DP0 pid=452734) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=452734) 	shl.b32 	%r168, %r167, 8;
(EngineCore_DP0 pid=452734) 	shl.b32 	%r169, %r166, 16;
(EngineCore_DP0 pid=452734) 	and.b32 	%r170, %r169, 16711680;
(EngineCore_DP0 pid=452734) 	and.b32 	%r171, %r168, 65280;
(EngineCore_DP0 pid=452734) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=452734) 	or.b32 	%r172, %r171, %r132;
(EngineCore_DP0 pid=452734) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=452734) 	or.b32 	%r173, %r161, %r159;
(EngineCore_DP0 pid=452734) 	or.b32 	%r174, %r172, %r170;
(EngineCore_DP0 pid=452734) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=452734) 	shl.b32 	%r175, %r149, 24;
(EngineCore_DP0 pid=452734) 	shl.b32 	%r176, %r150, 24;
(EngineCore_DP0 pid=452734) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=452734) 	or.b32 	%r87, %r173, %r175;
(EngineCore_DP0 pid=452734) 	or.b32 	%r88, %r174, %r176;
(EngineCore_DP0 pid=452734) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=452734) 	mad.wide.s32 	%rd17, %r89, 4, %rd2;
(EngineCore_DP0 pid=452734) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=452734) 	// begin inline asm
(EngineCore_DP0 pid=452734) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r87, %r88 };
(EngineCore_DP0 pid=452734) 	// end inline asm
(EngineCore_DP0 pid=452734) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=452734) 	add.s32 	%r180, %r180, 1024;
(EngineCore_DP0 pid=452734) 	setp.lt.s32 	%p27, %r180, %r15;
(EngineCore_DP0 pid=452734) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=452734) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=452734) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=452734) 	ret;
(EngineCore_DP0 pid=452734) $L__tmp3:
(EngineCore_DP0 pid=452734) $L__func_end0:
(EngineCore_DP0 pid=452734)                                         // -- End function
(EngineCore_DP0 pid=452734) }
(EngineCore_DP0 pid=452734) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=452734) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=452734) 	.section	.debug_abbrev
(EngineCore_DP0 pid=452734) 	{
(EngineCore_DP0 pid=452734) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=452734) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=452734) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=452734) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=452734) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=452734) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=452734) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=452734) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=452734) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=452734) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=452734) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=452734) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=452734) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=452734) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=452734) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=452734) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=452734) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=452734) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=452734) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=452734) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=452734) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=452734) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=452734) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=452734) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=452734) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=452734) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=452734) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=452734) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=452734) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=452734) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=452734) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=452734) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=452734) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=452734) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=452734) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=452734) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=452734) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=452734) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=452734) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=452734) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=452734) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=452734) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=452734) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=452734) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=452734) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=452734) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=452734) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=452734) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=452734) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=452734) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=452734) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=452734) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=452734) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=452734) 	}
(EngineCore_DP0 pid=452734) 	.section	.debug_info
(EngineCore_DP0 pid=452734) 	{
(EngineCore_DP0 pid=452734) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=452734) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=452734) .b8 0
(EngineCore_DP0 pid=452734) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=452734) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=452734) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=452734) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=452734) .b8 114
(EngineCore_DP0 pid=452734) .b8 105
(EngineCore_DP0 pid=452734) .b8 116
(EngineCore_DP0 pid=452734) .b8 111
(EngineCore_DP0 pid=452734) .b8 110
(EngineCore_DP0 pid=452734) .b8 0
(EngineCore_DP0 pid=452734) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=452734) .b8 0
(EngineCore_DP0 pid=452734) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=452734) .b8 117
(EngineCore_DP0 pid=452734) .b8 97
(EngineCore_DP0 pid=452734) .b8 110
(EngineCore_DP0 pid=452734) .b8 116
(EngineCore_DP0 pid=452734) .b8 95
(EngineCore_DP0 pid=452734) .b8 115
(EngineCore_DP0 pid=452734) .b8 108
(EngineCore_DP0 pid=452734) .b8 105
(EngineCore_DP0 pid=452734) .b8 100
(EngineCore_DP0 pid=452734) .b8 101
(EngineCore_DP0 pid=452734) .b8 95
(EngineCore_DP0 pid=452734) .b8 116
(EngineCore_DP0 pid=452734) .b8 117
(EngineCore_DP0 pid=452734) .b8 110
(EngineCore_DP0 pid=452734) .b8 101
(EngineCore_DP0 pid=452734) .b8 100
(EngineCore_DP0 pid=452734) .b8 95
(EngineCore_DP0 pid=452734) .b8 81
(EngineCore_DP0 pid=452734) .b8 119
(EngineCore_DP0 pid=452734) .b8 101
(EngineCore_DP0 pid=452734) .b8 110
(EngineCore_DP0 pid=452734) .b8 50
(EngineCore_DP0 pid=452734) .b8 46
(EngineCore_DP0 pid=452734) .b8 53
(EngineCore_DP0 pid=452734) .b8 45
(EngineCore_DP0 pid=452734) .b8 55
(EngineCore_DP0 pid=452734) .b8 66
(EngineCore_DP0 pid=452734) .b8 46
(EngineCore_DP0 pid=452734) .b8 112
(EngineCore_DP0 pid=452734) .b8 121
(EngineCore_DP0 pid=452734) .b8 0
(EngineCore_DP0 pid=452734) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=452734) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=452734) .b8 114
(EngineCore_DP0 pid=452734) .b8 111
(EngineCore_DP0 pid=452734) .b8 111
(EngineCore_DP0 pid=452734) .b8 116
(EngineCore_DP0 pid=452734) .b8 47
(EngineCore_DP0 pid=452734) .b8 118
(EngineCore_DP0 pid=452734) .b8 108
(EngineCore_DP0 pid=452734) .b8 108
(EngineCore_DP0 pid=452734) .b8 109
(EngineCore_DP0 pid=452734) .b8 98
(EngineCore_DP0 pid=452734) .b8 101
(EngineCore_DP0 pid=452734) .b8 110
(EngineCore_DP0 pid=452734) .b8 99
(EngineCore_DP0 pid=452734) .b8 104
(EngineCore_DP0 pid=452734) .b8 47
(EngineCore_DP0 pid=452734) .b8 115
(EngineCore_DP0 pid=452734) .b8 108
(EngineCore_DP0 pid=452734) .b8 105
(EngineCore_DP0 pid=452734) .b8 100
(EngineCore_DP0 pid=452734) .b8 101
(EngineCore_DP0 pid=452734) .b8 115
(EngineCore_DP0 pid=452734) .b8 112
(EngineCore_DP0 pid=452734) .b8 97
(EngineCore_DP0 pid=452734) .b8 114
(EngineCore_DP0 pid=452734) .b8 115
(EngineCore_DP0 pid=452734) .b8 101
(EngineCore_DP0 pid=452734) .b8 47
(EngineCore_DP0 pid=452734) .b8 99
(EngineCore_DP0 pid=452734) .b8 115
(EngineCore_DP0 pid=452734) .b8 114
(EngineCore_DP0 pid=452734) .b8 99
(EngineCore_DP0 pid=452734) .b8 47
(EngineCore_DP0 pid=452734) .b8 102
(EngineCore_DP0 pid=452734) .b8 117
(EngineCore_DP0 pid=452734) .b8 115
(EngineCore_DP0 pid=452734) .b8 101
(EngineCore_DP0 pid=452734) .b8 100
(EngineCore_DP0 pid=452734) .b8 95
(EngineCore_DP0 pid=452734) .b8 113
(EngineCore_DP0 pid=452734) .b8 117
(EngineCore_DP0 pid=452734) .b8 97
(EngineCore_DP0 pid=452734) .b8 110
(EngineCore_DP0 pid=452734) .b8 116
(EngineCore_DP0 pid=452734) .b8 95
(EngineCore_DP0 pid=452734) .b8 115
(EngineCore_DP0 pid=452734) .b8 108
(EngineCore_DP0 pid=452734) .b8 105
(EngineCore_DP0 pid=452734) .b8 100
(EngineCore_DP0 pid=452734) .b8 101
(EngineCore_DP0 pid=452734) .b8 95
(EngineCore_DP0 pid=452734) .b8 116
(EngineCore_DP0 pid=452734) .b8 114
(EngineCore_DP0 pid=452734) .b8 105
(EngineCore_DP0 pid=452734) .b8 116
(EngineCore_DP0 pid=452734) .b8 111
(EngineCore_DP0 pid=452734) .b8 110
(EngineCore_DP0 pid=452734) .b8 47
(EngineCore_DP0 pid=452734) .b8 98
(EngineCore_DP0 pid=452734) .b8 117
(EngineCore_DP0 pid=452734) .b8 105
(EngineCore_DP0 pid=452734) .b8 108
(EngineCore_DP0 pid=452734) .b8 100
(EngineCore_DP0 pid=452734) .b8 47
(EngineCore_DP0 pid=452734) .b8 71
(EngineCore_DP0 pid=452734) .b8 66
(EngineCore_DP0 pid=452734) .b8 49
(EngineCore_DP0 pid=452734) .b8 48
(EngineCore_DP0 pid=452734) .b8 95
(EngineCore_DP0 pid=452734) .b8 99
(EngineCore_DP0 pid=452734) .b8 99
(EngineCore_DP0 pid=452734) .b8 49
(EngineCore_DP0 pid=452734) .b8 50
(EngineCore_DP0 pid=452734) .b8 49
(EngineCore_DP0 pid=452734) .b8 95
(EngineCore_DP0 pid=452734) .b8 112
(EngineCore_DP0 pid=452734) .b8 121
(EngineCore_DP0 pid=452734) .b8 51
(EngineCore_DP0 pid=452734) .b8 49
(EngineCore_DP0 pid=452734) .b8 50
(EngineCore_DP0 pid=452734) .b8 95
(EngineCore_DP0 pid=452734) .b8 99
(EngineCore_DP0 pid=452734) .b8 117
(EngineCore_DP0 pid=452734) .b8 49
(EngineCore_DP0 pid=452734) .b8 50
(EngineCore_DP0 pid=452734) .b8 57
(EngineCore_DP0 pid=452734) .b8 95
(EngineCore_DP0 pid=452734) .b8 97
(EngineCore_DP0 pid=452734) .b8 97
(EngineCore_DP0 pid=452734) .b8 114
(EngineCore_DP0 pid=452734) .b8 99
(EngineCore_DP0 pid=452734) .b8 104
(EngineCore_DP0 pid=452734) .b8 54
(EngineCore_DP0 pid=452734) .b8 52
(EngineCore_DP0 pid=452734) .b8 0
(EngineCore_DP0 pid=452734) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=452734) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=452734) .b8 113
(EngineCore_DP0 pid=452734) .b8 117
(EngineCore_DP0 pid=452734) .b8 97
(EngineCore_DP0 pid=452734) .b8 110
(EngineCore_DP0 pid=452734) .b8 116
(EngineCore_DP0 pid=452734) .b8 95
(EngineCore_DP0 pid=452734) .b8 115
(EngineCore_DP0 pid=452734) .b8 108
(EngineCore_DP0 pid=452734) .b8 105
(EngineCore_DP0 pid=452734) .b8 100
(EngineCore_DP0 pid=452734) .b8 101
(EngineCore_DP0 pid=452734) .b8 95
(EngineCore_DP0 pid=452734) .b8 105
(EngineCore_DP0 pid=452734) .b8 110
(EngineCore_DP0 pid=452734) .b8 116
(EngineCore_DP0 pid=452734) .b8 56
(EngineCore_DP0 pid=452734) .b8 95
(EngineCore_DP0 pid=452734) .b8 107
(EngineCore_DP0 pid=452734) .b8 101
(EngineCore_DP0 pid=452734) .b8 114
(EngineCore_DP0 pid=452734) .b8 110
(EngineCore_DP0 pid=452734) .b8 101
(EngineCore_DP0 pid=452734) .b8 108
(EngineCore_DP0 pid=452734) .b8 0
(EngineCore_DP0 pid=452734) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=452734) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=452734) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=452734) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=452734) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=452734) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=452734) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=452734) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=452734) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=452734) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=452734) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=452734) .b8 1
(EngineCore_DP0 pid=452734) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=452734) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=452734) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=452734) 	}
(EngineCore_DP0 pid=452734) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=452734) 
(EngineCore_DP0 pid=452734) ================================================================
(EngineCore_DP0 pid=452734) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=452734) 
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp63dwxfmz.ptx', '-o', '/tmp/tmp63dwxfmz.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866] 
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866] 
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866] 
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp63dwxfmz.ptx -o /tmp/tmp63dwxfmz.ptx.o
(EngineCore_DP0 pid=452734) ERROR 01-25 21:04:23 [core.py:866] 

STDERR:
[2026-01-25 21:03:11] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:03:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:03:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:03:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:03:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:03:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:03:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:03:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:03:14] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:03:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:03:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:03:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:03:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:03:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:03:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:03:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:03:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=452734) [2026-01-25 21:03:15] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=452734) [2026-01-25 21:03:15] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=452734) [2026-01-25 21:03:15] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=452734) [2026-01-25 21:03:15] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=452734) [2026-01-25 21:03:15] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=452734) [2026-01-25 21:03:15] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=452734) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=452734) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.87s/it]
(EngineCore_DP0 pid=452734) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 33.13s/it]
(EngineCore_DP0 pid=452734) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 32.34s/it]
(EngineCore_DP0 pid=452734) 
(EngineCore_DP0 pid=452734) [2026-01-25 21:04:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=452734) [2026-01-25 21:04:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=452734) [2026-01-25 21:04:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=452734) [2026-01-25 21:04:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=452734) [2026-01-25 21:04:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=452734) [2026-01-25 21:04:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=452734) [2026-01-25 21:04:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=452734) [2026-01-25 21:04:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=452734) Process EngineCore_DP0:
(EngineCore_DP0 pid=452734) Traceback (most recent call last):
(EngineCore_DP0 pid=452734)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=452734)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=452734)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=452734)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=452734) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp63dwxfmz.ptx', '-o', '/tmp/tmp63dwxfmz.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=452734) 
(EngineCore_DP0 pid=452734) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=452734) 
(EngineCore_DP0 pid=452734) Traceback (most recent call last):
(EngineCore_DP0 pid=452734)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=452734)     self.run()
(EngineCore_DP0 pid=452734)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=452734)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=452734)     raise e
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=452734)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=452734)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=452734)     super().__init__(
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=452734)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=452734)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=452734)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=452734)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=452734)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=452734)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=452734)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=452734)     return func(*args, **kwargs)
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=452734)     return func(*args, **kwargs)
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=452734)     self.model_runner.profile_run()
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=452734)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=452734)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=452734)     return func(*args, **kwargs)
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=452734)     outputs = self.model(
(EngineCore_DP0 pid=452734)               ^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=452734)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=452734)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=452734)     hidden_states = self.model(
(EngineCore_DP0 pid=452734)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=452734)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=452734)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=452734)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=452734)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=452734)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=452734)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=452734)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=452734)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=452734)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=452734)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=452734)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=452734)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=452734)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=452734)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=452734)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=452734)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=452734)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=452734)     return self._linear_fn(
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=452734)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=452734)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=452734)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=452734)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=452734)     return fn(input, L)
(EngineCore_DP0 pid=452734)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=452734)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=452734)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=452734)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=452734)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=452734)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=452734)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=452734)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=452734)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=452734)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=452734)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=452734)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=452734)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=452734)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=452734)     raise PTXASError(error)
(EngineCore_DP0 pid=452734) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=452734) `ptxas` stderr:
(EngineCore_DP0 pid=452734) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=452734) 
(EngineCore_DP0 pid=452734) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp63dwxfmz.ptx -o /tmp/tmp63dwxfmz.ptx.o
(EngineCore_DP0 pid=452734) 
[rank0]:[W125 21:04:24.475214015 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 21:04:26
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:04:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:04:36 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=454104) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=454104) 
(EngineCore_DP0 pid=454104) 
(EngineCore_DP0 pid=454104) ================================================================
(EngineCore_DP0 pid=454104) Internal Triton PTX codegen error
(EngineCore_DP0 pid=454104) `ptxas` stderr:
(EngineCore_DP0 pid=454104) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=454104) 
(EngineCore_DP0 pid=454104) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpnmvodkxz.ptx -o /tmp/tmpnmvodkxz.ptx.o
(EngineCore_DP0 pid=454104) 
(EngineCore_DP0 pid=454104) 
(EngineCore_DP0 pid=454104) //
(EngineCore_DP0 pid=454104) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=454104) //
(EngineCore_DP0 pid=454104) 
(EngineCore_DP0 pid=454104) .version 8.7
(EngineCore_DP0 pid=454104) .target sm_121a
(EngineCore_DP0 pid=454104) .address_size 64
(EngineCore_DP0 pid=454104) 
(EngineCore_DP0 pid=454104) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=454104) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=454104)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=454104) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=454104) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=454104) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=454104) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=454104) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=454104) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=454104) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=454104) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=454104) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=454104) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=454104) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=454104) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=454104) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=454104) )
(EngineCore_DP0 pid=454104) .reqntid 512
(EngineCore_DP0 pid=454104) {
(EngineCore_DP0 pid=454104) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=454104) 	.reg .b16 	%rs<64>;
(EngineCore_DP0 pid=454104) 	.reg .b32 	%r<181>;
(EngineCore_DP0 pid=454104) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=454104) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=454104) $L__func_begin0:
(EngineCore_DP0 pid=454104) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=454104) 
(EngineCore_DP0 pid=454104) // %bb.0:
(EngineCore_DP0 pid=454104) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=454104) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=454104) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=454104) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=454104) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=454104) $L__tmp0:
(EngineCore_DP0 pid=454104) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=454104) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=454104) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=454104) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=454104) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=454104) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=454104) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=454104) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=454104) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=454104) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=454104) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=454104) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=454104) 	mov.b32 	%r179, 0f2B8CBCCC;
(EngineCore_DP0 pid=454104) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=454104) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=454104) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=454104) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=454104) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=454104) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=454104) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=454104) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=454104) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=454104) 	add.s32 	%r57, %r39, %r38;
(EngineCore_DP0 pid=454104) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=454104) 	add.s32 	%r60, %r39, %r40;
(EngineCore_DP0 pid=454104) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=454104) 	mov.b32 	%r177, 0f00000000;
(EngineCore_DP0 pid=454104) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=454104) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=454104) 	mov.b32 	%r178, %r45;
(EngineCore_DP0 pid=454104) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=454104) 	.loc	1 265 19                        // quant_slide_tuned_Qwen2.5-7B.py:265:19
(EngineCore_DP0 pid=454104) 	add.s32 	%r63, %r4, %r178;
(EngineCore_DP0 pid=454104) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=454104) 	add.s32 	%r64, %r63, 4096;
(EngineCore_DP0 pid=454104) 	setp.lt.s32 	%p2, %r63, %r23;
(EngineCore_DP0 pid=454104) 	setp.lt.s32 	%p3, %r64, %r23;
(EngineCore_DP0 pid=454104) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=454104) 	mad.wide.s32 	%rd6, %r63, 2, %rd1;
(EngineCore_DP0 pid=454104) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=454104) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=454104) 	// begin inline asm
(EngineCore_DP0 pid=454104) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=454104) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=454104) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=454104) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=454104) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=454104) 	// end inline asm
(EngineCore_DP0 pid=454104) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=454104) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=454104) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=454104) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=454104) 	// begin inline asm
(EngineCore_DP0 pid=454104) 	mov.u32 %r49, %r45;
(EngineCore_DP0 pid=454104) 	mov.u32 %r50, %r45;
(EngineCore_DP0 pid=454104) 	mov.u32 %r51, %r45;
(EngineCore_DP0 pid=454104) 	mov.u32 %r52, %r45;
(EngineCore_DP0 pid=454104) 	@%p3 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=454104) 	// end inline asm
(EngineCore_DP0 pid=454104) 	mov.b32 	{%rs9, %rs10}, %r49;
(EngineCore_DP0 pid=454104) 	mov.b32 	{%rs11, %rs12}, %r50;
(EngineCore_DP0 pid=454104) 	mov.b32 	{%rs13, %rs14}, %r51;
(EngineCore_DP0 pid=454104) 	mov.b32 	{%rs15, %rs16}, %r52;
(EngineCore_DP0 pid=454104) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=454104) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=454104) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=454104) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=454104) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=454104) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=454104) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=454104) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=454104) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=454104) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=454104) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=454104) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=454104) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=454104) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=454104) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=454104) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=454104) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=454104) $L__tmp1:
(EngineCore_DP0 pid=454104) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	bar.sync 	0;
(EngineCore_DP0 pid=454104) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=454104) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=454104) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=454104) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=454104) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=454104) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=454104) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=454104) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=454104) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=454104) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=454104) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=454104) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=454104) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=454104) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=454104) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=454104) 	cvt.f32.bf16 	%r65, %rs47;
(EngineCore_DP0 pid=454104) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	shfl.sync.bfly.b32 	%r66, %r65, 16, 31, -1;
(EngineCore_DP0 pid=454104) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=454104) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	shfl.sync.bfly.b32 	%r68, %r67, 8, 31, -1;
(EngineCore_DP0 pid=454104) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=454104) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	shfl.sync.bfly.b32 	%r70, %r69, 4, 31, -1;
(EngineCore_DP0 pid=454104) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=454104) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	shfl.sync.bfly.b32 	%r72, %r71, 2, 31, -1;
(EngineCore_DP0 pid=454104) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=454104) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	shfl.sync.bfly.b32 	%r74, %r73, 1, 31, -1;
(EngineCore_DP0 pid=454104) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	max.f32 	%r58, %r73, %r74;
(EngineCore_DP0 pid=454104) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	// begin inline asm
(EngineCore_DP0 pid=454104) 	@%p4 st.shared.b32 [ %r57 + 0 ], %r58;
(EngineCore_DP0 pid=454104) 	// end inline asm
(EngineCore_DP0 pid=454104) 	bar.sync 	0;
(EngineCore_DP0 pid=454104) 	// begin inline asm
(EngineCore_DP0 pid=454104) 	@%p5 ld.shared.b32 %r59, [ %r60 + 0 ];
(EngineCore_DP0 pid=454104) 	// end inline asm
(EngineCore_DP0 pid=454104) 	shfl.sync.bfly.b32 	%r75, %r59, 8, 31, -1;
(EngineCore_DP0 pid=454104) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	max.f32 	%r76, %r59, %r75;
(EngineCore_DP0 pid=454104) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	shfl.sync.bfly.b32 	%r77, %r76, 4, 31, -1;
(EngineCore_DP0 pid=454104) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=454104) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	shfl.sync.bfly.b32 	%r79, %r78, 2, 31, -1;
(EngineCore_DP0 pid=454104) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	max.f32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=454104) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	shfl.sync.bfly.b32 	%r81, %r80, 1, 31, -1;
(EngineCore_DP0 pid=454104) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	max.f32 	%r62, %r80, %r81;
(EngineCore_DP0 pid=454104) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=454104) 	// begin inline asm
(EngineCore_DP0 pid=454104) 	@%p28 st.shared.b32 [ %r60 + 0 ], %r62;
(EngineCore_DP0 pid=454104) 	// end inline asm
(EngineCore_DP0 pid=454104) 	bar.sync 	0;
(EngineCore_DP0 pid=454104) 	ld.shared.b32 	%r82, [global_smem];
(EngineCore_DP0 pid=454104) $L__tmp2:
(EngineCore_DP0 pid=454104) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=454104) 	max.f32 	%r177, %r177, %r82;
(EngineCore_DP0 pid=454104) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=454104) 	add.s32 	%r178, %r178, 8192;
(EngineCore_DP0 pid=454104) 	setp.lt.s32 	%p7, %r178, %r24;
(EngineCore_DP0 pid=454104) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=454104) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=454104) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=454104) 	max.f32 	%r179, %r177, 0f2B8CBCCC;
(EngineCore_DP0 pid=454104) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=454104) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=454104) 	mov.b32 	%r84, 0f42FE0000;
(EngineCore_DP0 pid=454104) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=454104) 	div.full.f32 	%r85, %r179, %r84;
(EngineCore_DP0 pid=454104) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=454104) 	max.f32 	%r83, %r85, 0f37810204;
(EngineCore_DP0 pid=454104) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=454104) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=454104) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=454104) 	// begin inline asm
(EngineCore_DP0 pid=454104) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r83 };
(EngineCore_DP0 pid=454104) 	// end inline asm
(EngineCore_DP0 pid=454104) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=454104) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=454104) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=454104) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=454104) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=454104) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=454104) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=454104) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=454104) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=454104) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=454104) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=454104) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=454104) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=454104) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=454104) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=454104) 	div.full.f32 	%r14, %r84, %r179;
(EngineCore_DP0 pid=454104) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=454104) 	mov.b32 	%r180, 0;
(EngineCore_DP0 pid=454104) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=454104)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=454104) 	.loc	1 279 31                        // quant_slide_tuned_Qwen2.5-7B.py:279:31
(EngineCore_DP0 pid=454104) 	add.s32 	%r89, %r16, %r180;
(EngineCore_DP0 pid=454104) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=454104) 	add.s32 	%r90, %r89, 1;
(EngineCore_DP0 pid=454104) 	setp.lt.s32 	%p18, %r89, %r15;
(EngineCore_DP0 pid=454104) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=454104) 	shr.s32 	%r91, %r89, 31;
(EngineCore_DP0 pid=454104) 	shr.u32 	%r92, %r91, 30;
(EngineCore_DP0 pid=454104) 	add.s32 	%r93, %r89, %r92;
(EngineCore_DP0 pid=454104) 	shr.s32 	%r94, %r93, 2;
(EngineCore_DP0 pid=454104) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=454104) 	shr.s32 	%r95, %r90, 31;
(EngineCore_DP0 pid=454104) 	shr.u32 	%r96, %r95, 30;
(EngineCore_DP0 pid=454104) 	add.s32 	%r97, %r90, %r96;
(EngineCore_DP0 pid=454104) 	and.b32 	%r98, %r97, 2147483644;
(EngineCore_DP0 pid=454104) 	sub.s32 	%r99, %r90, %r98;
(EngineCore_DP0 pid=454104) 	and.b32 	%r100, %r93, 2147483644;
(EngineCore_DP0 pid=454104) 	sub.s32 	%r101, %r89, %r100;
(EngineCore_DP0 pid=454104) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=454104) 	mul.lo.s32 	%r102, %r94, 10;
(EngineCore_DP0 pid=454104) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=454104) 	shl.b32 	%r103, %r101, 1;
(EngineCore_DP0 pid=454104) 	shl.b32 	%r104, %r99, 1;
(EngineCore_DP0 pid=454104) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=454104) 	add.s32 	%r105, %r102, %r104;
(EngineCore_DP0 pid=454104) 	add.s32 	%r106, %r102, %r103;
(EngineCore_DP0 pid=454104) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=454104) 	setp.lt.s32 	%p19, %r106, %r23;
(EngineCore_DP0 pid=454104) 	setp.lt.s32 	%p20, %r105, %r23;
(EngineCore_DP0 pid=454104) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=454104) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=454104) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=454104) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=454104) 	mad.wide.s32 	%rd9, %r106, 2, %rd1;
(EngineCore_DP0 pid=454104) 	mad.wide.s32 	%rd10, %r105, 2, %rd1;
(EngineCore_DP0 pid=454104) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=454104) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=454104) 	// begin inline asm
(EngineCore_DP0 pid=454104) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=454104) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=454104) 	// end inline asm
(EngineCore_DP0 pid=454104) 	// begin inline asm
(EngineCore_DP0 pid=454104) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=454104) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=454104) 	// end inline asm
(EngineCore_DP0 pid=454104) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=454104) 	cvt.f32.bf16 	%r107, %rs48;
(EngineCore_DP0 pid=454104) 	cvt.f32.bf16 	%r108, %rs50;
(EngineCore_DP0 pid=454104) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=454104) 	or.b32 	%r109, %r106, 1;
(EngineCore_DP0 pid=454104) 	or.b32 	%r110, %r105, 1;
(EngineCore_DP0 pid=454104) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=454104) 	setp.lt.s32 	%p21, %r109, %r23;
(EngineCore_DP0 pid=454104) 	setp.lt.s32 	%p22, %r110, %r23;
(EngineCore_DP0 pid=454104) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=454104) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=454104) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=454104) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=454104) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=454104) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=454104) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=454104) 	// begin inline asm
(EngineCore_DP0 pid=454104) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=454104) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=454104) 	// end inline asm
(EngineCore_DP0 pid=454104) 	// begin inline asm
(EngineCore_DP0 pid=454104) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=454104) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=454104) 	// end inline asm
(EngineCore_DP0 pid=454104) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=454104) 	cvt.f32.bf16 	%r111, %rs52;
(EngineCore_DP0 pid=454104) 	cvt.f32.bf16 	%r112, %rs54;
(EngineCore_DP0 pid=454104) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=454104) 	add.s32 	%r113, %r106, 2;
(EngineCore_DP0 pid=454104) 	add.s32 	%r114, %r105, 2;
(EngineCore_DP0 pid=454104) 	add.s32 	%r115, %r106, 3;
(EngineCore_DP0 pid=454104) 	add.s32 	%r116, %r105, 3;
(EngineCore_DP0 pid=454104) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=454104) 	setp.lt.s32 	%p23, %r116, %r23;
(EngineCore_DP0 pid=454104) 	setp.lt.s32 	%p24, %r115, %r23;
(EngineCore_DP0 pid=454104) 	setp.lt.s32 	%p25, %r114, %r23;
(EngineCore_DP0 pid=454104) 	setp.lt.s32 	%p26, %r113, %r23;
(EngineCore_DP0 pid=454104) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=454104) 	and.pred 	%p14, %p18, %p26;
(EngineCore_DP0 pid=454104) 	and.pred 	%p15, %p18, %p25;
(EngineCore_DP0 pid=454104) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=454104) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=454104) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=454104) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=454104) 	// begin inline asm
(EngineCore_DP0 pid=454104) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=454104) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=454104) 	// end inline asm
(EngineCore_DP0 pid=454104) 	// begin inline asm
(EngineCore_DP0 pid=454104) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=454104) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=454104) 	// end inline asm
(EngineCore_DP0 pid=454104) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=454104) 	cvt.f32.bf16 	%r117, %rs56;
(EngineCore_DP0 pid=454104) 	cvt.f32.bf16 	%r118, %rs58;
(EngineCore_DP0 pid=454104) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=454104) 	and.pred 	%p16, %p18, %p24;
(EngineCore_DP0 pid=454104) 	and.pred 	%p17, %p18, %p23;
(EngineCore_DP0 pid=454104) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=454104) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=454104) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=454104) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=454104) 	// begin inline asm
(EngineCore_DP0 pid=454104) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=454104) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=454104) 	// end inline asm
(EngineCore_DP0 pid=454104) 	// begin inline asm
(EngineCore_DP0 pid=454104) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=454104) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=454104) 	// end inline asm
(EngineCore_DP0 pid=454104) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=454104) 	cvt.f32.bf16 	%r119, %rs60;
(EngineCore_DP0 pid=454104) 	cvt.f32.bf16 	%r120, %rs62;
(EngineCore_DP0 pid=454104) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=454104) 	mul.f32 	%r121, %r14, %r107;
(EngineCore_DP0 pid=454104) 	mul.f32 	%r122, %r14, %r108;
(EngineCore_DP0 pid=454104) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=454104) 	cvt.rni.f32.f32 	%r123, %r121;
(EngineCore_DP0 pid=454104) 	cvt.rni.f32.f32 	%r124, %r122;
(EngineCore_DP0 pid=454104) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=454104) 	max.f32 	%r125, %r123, 0fC3000000;
(EngineCore_DP0 pid=454104) 	min.f32 	%r126, %r125, 0f42FE0000;
(EngineCore_DP0 pid=454104) 	max.f32 	%r127, %r124, 0fC3000000;
(EngineCore_DP0 pid=454104) 	min.f32 	%r128, %r127, 0f42FE0000;
(EngineCore_DP0 pid=454104) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=454104) 	cvt.rzi.s32.f32 	%r129, %r126;
(EngineCore_DP0 pid=454104) 	cvt.rzi.s32.f32 	%r130, %r128;
(EngineCore_DP0 pid=454104) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=454104) 	and.b32 	%r131, %r129, 255;
(EngineCore_DP0 pid=454104) 	and.b32 	%r132, %r130, 255;
(EngineCore_DP0 pid=454104) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=454104) 	mul.f32 	%r133, %r14, %r111;
(EngineCore_DP0 pid=454104) 	mul.f32 	%r134, %r14, %r112;
(EngineCore_DP0 pid=454104) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=454104) 	cvt.rni.f32.f32 	%r135, %r133;
(EngineCore_DP0 pid=454104) 	cvt.rni.f32.f32 	%r136, %r134;
(EngineCore_DP0 pid=454104) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=454104) 	mul.f32 	%r137, %r14, %r117;
(EngineCore_DP0 pid=454104) 	mul.f32 	%r138, %r14, %r118;
(EngineCore_DP0 pid=454104) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=454104) 	cvt.rni.f32.f32 	%r139, %r137;
(EngineCore_DP0 pid=454104) 	cvt.rni.f32.f32 	%r140, %r138;
(EngineCore_DP0 pid=454104) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=454104) 	mul.f32 	%r141, %r14, %r119;
(EngineCore_DP0 pid=454104) 	mul.f32 	%r142, %r14, %r120;
(EngineCore_DP0 pid=454104) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=454104) 	cvt.rni.f32.f32 	%r143, %r141;
(EngineCore_DP0 pid=454104) 	cvt.rni.f32.f32 	%r144, %r142;
(EngineCore_DP0 pid=454104) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=454104) 	max.f32 	%r145, %r143, 0fC3000000;
(EngineCore_DP0 pid=454104) 	min.f32 	%r146, %r145, 0f42FE0000;
(EngineCore_DP0 pid=454104) 	max.f32 	%r147, %r144, 0fC3000000;
(EngineCore_DP0 pid=454104) 	min.f32 	%r148, %r147, 0f42FE0000;
(EngineCore_DP0 pid=454104) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=454104) 	cvt.rzi.s32.f32 	%r149, %r146;
(EngineCore_DP0 pid=454104) 	cvt.rzi.s32.f32 	%r150, %r148;
(EngineCore_DP0 pid=454104) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=454104) 	max.f32 	%r151, %r139, 0fC3000000;
(EngineCore_DP0 pid=454104) 	max.f32 	%r152, %r135, 0fC3000000;
(EngineCore_DP0 pid=454104) 	min.f32 	%r153, %r152, 0f42FE0000;
(EngineCore_DP0 pid=454104) 	min.f32 	%r154, %r151, 0f42FE0000;
(EngineCore_DP0 pid=454104) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=454104) 	cvt.rzi.s32.f32 	%r155, %r154;
(EngineCore_DP0 pid=454104) 	cvt.rzi.s32.f32 	%r156, %r153;
(EngineCore_DP0 pid=454104) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=454104) 	shl.b32 	%r157, %r156, 8;
(EngineCore_DP0 pid=454104) 	shl.b32 	%r158, %r155, 16;
(EngineCore_DP0 pid=454104) 	and.b32 	%r159, %r158, 16711680;
(EngineCore_DP0 pid=454104) 	and.b32 	%r160, %r157, 65280;
(EngineCore_DP0 pid=454104) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=454104) 	or.b32 	%r161, %r160, %r131;
(EngineCore_DP0 pid=454104) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=454104) 	max.f32 	%r162, %r140, 0fC3000000;
(EngineCore_DP0 pid=454104) 	max.f32 	%r163, %r136, 0fC3000000;
(EngineCore_DP0 pid=454104) 	min.f32 	%r164, %r163, 0f42FE0000;
(EngineCore_DP0 pid=454104) 	min.f32 	%r165, %r162, 0f42FE0000;
(EngineCore_DP0 pid=454104) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=454104) 	cvt.rzi.s32.f32 	%r166, %r165;
(EngineCore_DP0 pid=454104) 	cvt.rzi.s32.f32 	%r167, %r164;
(EngineCore_DP0 pid=454104) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=454104) 	shl.b32 	%r168, %r167, 8;
(EngineCore_DP0 pid=454104) 	shl.b32 	%r169, %r166, 16;
(EngineCore_DP0 pid=454104) 	and.b32 	%r170, %r169, 16711680;
(EngineCore_DP0 pid=454104) 	and.b32 	%r171, %r168, 65280;
(EngineCore_DP0 pid=454104) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=454104) 	or.b32 	%r172, %r171, %r132;
(EngineCore_DP0 pid=454104) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=454104) 	or.b32 	%r173, %r161, %r159;
(EngineCore_DP0 pid=454104) 	or.b32 	%r174, %r172, %r170;
(EngineCore_DP0 pid=454104) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=454104) 	shl.b32 	%r175, %r149, 24;
(EngineCore_DP0 pid=454104) 	shl.b32 	%r176, %r150, 24;
(EngineCore_DP0 pid=454104) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=454104) 	or.b32 	%r87, %r173, %r175;
(EngineCore_DP0 pid=454104) 	or.b32 	%r88, %r174, %r176;
(EngineCore_DP0 pid=454104) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=454104) 	mad.wide.s32 	%rd17, %r89, 4, %rd2;
(EngineCore_DP0 pid=454104) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=454104) 	// begin inline asm
(EngineCore_DP0 pid=454104) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r87, %r88 };
(EngineCore_DP0 pid=454104) 	// end inline asm
(EngineCore_DP0 pid=454104) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=454104) 	add.s32 	%r180, %r180, 1024;
(EngineCore_DP0 pid=454104) 	setp.lt.s32 	%p27, %r180, %r15;
(EngineCore_DP0 pid=454104) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=454104) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=454104) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=454104) 	ret;
(EngineCore_DP0 pid=454104) $L__tmp3:
(EngineCore_DP0 pid=454104) $L__func_end0:
(EngineCore_DP0 pid=454104)                                         // -- End function
(EngineCore_DP0 pid=454104) }
(EngineCore_DP0 pid=454104) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=454104) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=454104) 	.section	.debug_abbrev
(EngineCore_DP0 pid=454104) 	{
(EngineCore_DP0 pid=454104) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=454104) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=454104) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=454104) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=454104) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=454104) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=454104) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=454104) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=454104) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=454104) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=454104) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=454104) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=454104) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=454104) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=454104) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=454104) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=454104) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=454104) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=454104) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=454104) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=454104) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=454104) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=454104) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=454104) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=454104) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=454104) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=454104) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=454104) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=454104) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=454104) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=454104) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=454104) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=454104) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=454104) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=454104) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=454104) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=454104) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=454104) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=454104) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=454104) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=454104) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=454104) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=454104) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=454104) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=454104) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=454104) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=454104) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=454104) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=454104) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=454104) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=454104) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=454104) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=454104) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=454104) 	}
(EngineCore_DP0 pid=454104) 	.section	.debug_info
(EngineCore_DP0 pid=454104) 	{
(EngineCore_DP0 pid=454104) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=454104) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=454104) .b8 0
(EngineCore_DP0 pid=454104) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=454104) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=454104) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=454104) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=454104) .b8 114
(EngineCore_DP0 pid=454104) .b8 105
(EngineCore_DP0 pid=454104) .b8 116
(EngineCore_DP0 pid=454104) .b8 111
(EngineCore_DP0 pid=454104) .b8 110
(EngineCore_DP0 pid=454104) .b8 0
(EngineCore_DP0 pid=454104) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=454104) .b8 0
(EngineCore_DP0 pid=454104) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=454104) .b8 117
(EngineCore_DP0 pid=454104) .b8 97
(EngineCore_DP0 pid=454104) .b8 110
(EngineCore_DP0 pid=454104) .b8 116
(EngineCore_DP0 pid=454104) .b8 95
(EngineCore_DP0 pid=454104) .b8 115
(EngineCore_DP0 pid=454104) .b8 108
(EngineCore_DP0 pid=454104) .b8 105
(EngineCore_DP0 pid=454104) .b8 100
(EngineCore_DP0 pid=454104) .b8 101
(EngineCore_DP0 pid=454104) .b8 95
(EngineCore_DP0 pid=454104) .b8 116
(EngineCore_DP0 pid=454104) .b8 117
(EngineCore_DP0 pid=454104) .b8 110
(EngineCore_DP0 pid=454104) .b8 101
(EngineCore_DP0 pid=454104) .b8 100
(EngineCore_DP0 pid=454104) .b8 95
(EngineCore_DP0 pid=454104) .b8 81
(EngineCore_DP0 pid=454104) .b8 119
(EngineCore_DP0 pid=454104) .b8 101
(EngineCore_DP0 pid=454104) .b8 110
(EngineCore_DP0 pid=454104) .b8 50
(EngineCore_DP0 pid=454104) .b8 46
(EngineCore_DP0 pid=454104) .b8 53
(EngineCore_DP0 pid=454104) .b8 45
(EngineCore_DP0 pid=454104) .b8 55
(EngineCore_DP0 pid=454104) .b8 66
(EngineCore_DP0 pid=454104) .b8 46
(EngineCore_DP0 pid=454104) .b8 112
(EngineCore_DP0 pid=454104) .b8 121
(EngineCore_DP0 pid=454104) .b8 0
(EngineCore_DP0 pid=454104) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=454104) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=454104) .b8 114
(EngineCore_DP0 pid=454104) .b8 111
(EngineCore_DP0 pid=454104) .b8 111
(EngineCore_DP0 pid=454104) .b8 116
(EngineCore_DP0 pid=454104) .b8 47
(EngineCore_DP0 pid=454104) .b8 118
(EngineCore_DP0 pid=454104) .b8 108
(EngineCore_DP0 pid=454104) .b8 108
(EngineCore_DP0 pid=454104) .b8 109
(EngineCore_DP0 pid=454104) .b8 98
(EngineCore_DP0 pid=454104) .b8 101
(EngineCore_DP0 pid=454104) .b8 110
(EngineCore_DP0 pid=454104) .b8 99
(EngineCore_DP0 pid=454104) .b8 104
(EngineCore_DP0 pid=454104) .b8 47
(EngineCore_DP0 pid=454104) .b8 115
(EngineCore_DP0 pid=454104) .b8 108
(EngineCore_DP0 pid=454104) .b8 105
(EngineCore_DP0 pid=454104) .b8 100
(EngineCore_DP0 pid=454104) .b8 101
(EngineCore_DP0 pid=454104) .b8 115
(EngineCore_DP0 pid=454104) .b8 112
(EngineCore_DP0 pid=454104) .b8 97
(EngineCore_DP0 pid=454104) .b8 114
(EngineCore_DP0 pid=454104) .b8 115
(EngineCore_DP0 pid=454104) .b8 101
(EngineCore_DP0 pid=454104) .b8 47
(EngineCore_DP0 pid=454104) .b8 99
(EngineCore_DP0 pid=454104) .b8 115
(EngineCore_DP0 pid=454104) .b8 114
(EngineCore_DP0 pid=454104) .b8 99
(EngineCore_DP0 pid=454104) .b8 47
(EngineCore_DP0 pid=454104) .b8 102
(EngineCore_DP0 pid=454104) .b8 117
(EngineCore_DP0 pid=454104) .b8 115
(EngineCore_DP0 pid=454104) .b8 101
(EngineCore_DP0 pid=454104) .b8 100
(EngineCore_DP0 pid=454104) .b8 95
(EngineCore_DP0 pid=454104) .b8 113
(EngineCore_DP0 pid=454104) .b8 117
(EngineCore_DP0 pid=454104) .b8 97
(EngineCore_DP0 pid=454104) .b8 110
(EngineCore_DP0 pid=454104) .b8 116
(EngineCore_DP0 pid=454104) .b8 95
(EngineCore_DP0 pid=454104) .b8 115
(EngineCore_DP0 pid=454104) .b8 108
(EngineCore_DP0 pid=454104) .b8 105
(EngineCore_DP0 pid=454104) .b8 100
(EngineCore_DP0 pid=454104) .b8 101
(EngineCore_DP0 pid=454104) .b8 95
(EngineCore_DP0 pid=454104) .b8 116
(EngineCore_DP0 pid=454104) .b8 114
(EngineCore_DP0 pid=454104) .b8 105
(EngineCore_DP0 pid=454104) .b8 116
(EngineCore_DP0 pid=454104) .b8 111
(EngineCore_DP0 pid=454104) .b8 110
(EngineCore_DP0 pid=454104) .b8 47
(EngineCore_DP0 pid=454104) .b8 98
(EngineCore_DP0 pid=454104) .b8 117
(EngineCore_DP0 pid=454104) .b8 105
(EngineCore_DP0 pid=454104) .b8 108
(EngineCore_DP0 pid=454104) .b8 100
(EngineCore_DP0 pid=454104) .b8 47
(EngineCore_DP0 pid=454104) .b8 71
(EngineCore_DP0 pid=454104) .b8 66
(EngineCore_DP0 pid=454104) .b8 49
(EngineCore_DP0 pid=454104) .b8 48
(EngineCore_DP0 pid=454104) .b8 95
(EngineCore_DP0 pid=454104) .b8 99
(EngineCore_DP0 pid=454104) .b8 99
(EngineCore_DP0 pid=454104) .b8 49
(EngineCore_DP0 pid=454104) .b8 50
(EngineCore_DP0 pid=454104) .b8 49
(EngineCore_DP0 pid=454104) .b8 95
(EngineCore_DP0 pid=454104) .b8 112
(EngineCore_DP0 pid=454104) .b8 121
(EngineCore_DP0 pid=454104) .b8 51
(EngineCore_DP0 pid=454104) .b8 49
(EngineCore_DP0 pid=454104) .b8 50
(EngineCore_DP0 pid=454104) .b8 95
(EngineCore_DP0 pid=454104) .b8 99
(EngineCore_DP0 pid=454104) .b8 117
(EngineCore_DP0 pid=454104) .b8 49
(EngineCore_DP0 pid=454104) .b8 50
(EngineCore_DP0 pid=454104) .b8 57
(EngineCore_DP0 pid=454104) .b8 95
(EngineCore_DP0 pid=454104) .b8 97
(EngineCore_DP0 pid=454104) .b8 97
(EngineCore_DP0 pid=454104) .b8 114
(EngineCore_DP0 pid=454104) .b8 99
(EngineCore_DP0 pid=454104) .b8 104
(EngineCore_DP0 pid=454104) .b8 54
(EngineCore_DP0 pid=454104) .b8 52
(EngineCore_DP0 pid=454104) .b8 0
(EngineCore_DP0 pid=454104) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=454104) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=454104) .b8 113
(EngineCore_DP0 pid=454104) .b8 117
(EngineCore_DP0 pid=454104) .b8 97
(EngineCore_DP0 pid=454104) .b8 110
(EngineCore_DP0 pid=454104) .b8 116
(EngineCore_DP0 pid=454104) .b8 95
(EngineCore_DP0 pid=454104) .b8 115
(EngineCore_DP0 pid=454104) .b8 108
(EngineCore_DP0 pid=454104) .b8 105
(EngineCore_DP0 pid=454104) .b8 100
(EngineCore_DP0 pid=454104) .b8 101
(EngineCore_DP0 pid=454104) .b8 95
(EngineCore_DP0 pid=454104) .b8 105
(EngineCore_DP0 pid=454104) .b8 110
(EngineCore_DP0 pid=454104) .b8 116
(EngineCore_DP0 pid=454104) .b8 56
(EngineCore_DP0 pid=454104) .b8 95
(EngineCore_DP0 pid=454104) .b8 107
(EngineCore_DP0 pid=454104) .b8 101
(EngineCore_DP0 pid=454104) .b8 114
(EngineCore_DP0 pid=454104) .b8 110
(EngineCore_DP0 pid=454104) .b8 101
(EngineCore_DP0 pid=454104) .b8 108
(EngineCore_DP0 pid=454104) .b8 0
(EngineCore_DP0 pid=454104) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=454104) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=454104) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=454104) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=454104) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=454104) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=454104) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=454104) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=454104) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=454104) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=454104) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=454104) .b8 1
(EngineCore_DP0 pid=454104) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=454104) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=454104) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=454104) 	}
(EngineCore_DP0 pid=454104) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=454104) 
(EngineCore_DP0 pid=454104) ================================================================
(EngineCore_DP0 pid=454104) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=454104) 
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpnmvodkxz.ptx', '-o', '/tmp/tmpnmvodkxz.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866] 
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866] 
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866] 
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpnmvodkxz.ptx -o /tmp/tmpnmvodkxz.ptx.o
(EngineCore_DP0 pid=454104) ERROR 01-25 21:05:48 [core.py:866] 

STDERR:
[2026-01-25 21:04:36] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:04:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:04:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:04:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:04:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:04:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:04:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:04:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:04:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:04:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:04:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:04:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:04:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:04:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:04:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:04:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:04:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=454104) [2026-01-25 21:04:40] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=454104) [2026-01-25 21:04:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=454104) [2026-01-25 21:04:40] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=454104) [2026-01-25 21:04:40] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=454104) [2026-01-25 21:04:40] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=454104) [2026-01-25 21:04:40] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=454104) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=454104) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.68s/it]
(EngineCore_DP0 pid=454104) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 32.96s/it]
(EngineCore_DP0 pid=454104) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 32.17s/it]
(EngineCore_DP0 pid=454104) 
(EngineCore_DP0 pid=454104) [2026-01-25 21:05:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=454104) [2026-01-25 21:05:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=454104) [2026-01-25 21:05:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=454104) [2026-01-25 21:05:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=454104) [2026-01-25 21:05:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=454104) [2026-01-25 21:05:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=454104) [2026-01-25 21:05:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=454104) [2026-01-25 21:05:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=454104) Process EngineCore_DP0:
(EngineCore_DP0 pid=454104) Traceback (most recent call last):
(EngineCore_DP0 pid=454104)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=454104)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=454104)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=454104)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=454104) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpnmvodkxz.ptx', '-o', '/tmp/tmpnmvodkxz.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=454104) 
(EngineCore_DP0 pid=454104) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=454104) 
(EngineCore_DP0 pid=454104) Traceback (most recent call last):
(EngineCore_DP0 pid=454104)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=454104)     self.run()
(EngineCore_DP0 pid=454104)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=454104)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=454104)     raise e
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=454104)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=454104)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=454104)     super().__init__(
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=454104)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=454104)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=454104)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=454104)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=454104)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=454104)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=454104)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=454104)     return func(*args, **kwargs)
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=454104)     return func(*args, **kwargs)
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=454104)     self.model_runner.profile_run()
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=454104)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=454104)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=454104)     return func(*args, **kwargs)
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=454104)     outputs = self.model(
(EngineCore_DP0 pid=454104)               ^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=454104)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=454104)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=454104)     hidden_states = self.model(
(EngineCore_DP0 pid=454104)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=454104)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=454104)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=454104)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=454104)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=454104)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=454104)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=454104)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=454104)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=454104)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=454104)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=454104)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=454104)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=454104)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=454104)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=454104)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=454104)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=454104)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=454104)     return self._linear_fn(
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=454104)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=454104)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=454104)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=454104)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=454104)     return fn(input, L)
(EngineCore_DP0 pid=454104)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=454104)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=454104)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=454104)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=454104)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=454104)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=454104)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=454104)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=454104)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=454104)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=454104)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=454104)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=454104)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=454104)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=454104)     raise PTXASError(error)
(EngineCore_DP0 pid=454104) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=454104) `ptxas` stderr:
(EngineCore_DP0 pid=454104) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=454104) 
(EngineCore_DP0 pid=454104) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpnmvodkxz.ptx -o /tmp/tmpnmvodkxz.ptx.o
(EngineCore_DP0 pid=454104) 
[rank0]:[W125 21:05:49.310999677 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 21:05:50
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:06:08 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:06:08 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=455561) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=455561) 
(EngineCore_DP0 pid=455561) 
(EngineCore_DP0 pid=455561) ================================================================
(EngineCore_DP0 pid=455561) Internal Triton PTX codegen error
(EngineCore_DP0 pid=455561) `ptxas` stderr:
(EngineCore_DP0 pid=455561) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=455561) 
(EngineCore_DP0 pid=455561) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp9j6gy6zs.ptx -o /tmp/tmp9j6gy6zs.ptx.o
(EngineCore_DP0 pid=455561) 
(EngineCore_DP0 pid=455561) 
(EngineCore_DP0 pid=455561) //
(EngineCore_DP0 pid=455561) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=455561) //
(EngineCore_DP0 pid=455561) 
(EngineCore_DP0 pid=455561) .version 8.7
(EngineCore_DP0 pid=455561) .target sm_121a
(EngineCore_DP0 pid=455561) .address_size 64
(EngineCore_DP0 pid=455561) 
(EngineCore_DP0 pid=455561) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=455561) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=455561)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=455561) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=455561) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=455561) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=455561) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=455561) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=455561) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=455561) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=455561) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=455561) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=455561) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=455561) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=455561) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=455561) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=455561) )
(EngineCore_DP0 pid=455561) .reqntid 512
(EngineCore_DP0 pid=455561) {
(EngineCore_DP0 pid=455561) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=455561) 	.reg .b16 	%rs<40>;
(EngineCore_DP0 pid=455561) 	.reg .b32 	%r<172>;
(EngineCore_DP0 pid=455561) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=455561) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=455561) $L__func_begin0:
(EngineCore_DP0 pid=455561) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=455561) 
(EngineCore_DP0 pid=455561) // %bb.0:
(EngineCore_DP0 pid=455561) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=455561) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=455561) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=455561) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=455561) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=455561) $L__tmp0:
(EngineCore_DP0 pid=455561) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=455561) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=455561) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=455561) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=455561) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=455561) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=455561) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=455561) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=455561) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=455561) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=455561) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=455561) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=455561) 	mov.b32 	%r170, 0f2B8CBCCC;
(EngineCore_DP0 pid=455561) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=455561) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=455561) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=455561) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=455561) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=455561) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=455561) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=455561) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=455561) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=455561) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=455561) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=455561) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=455561) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=455561) 	mov.b32 	%r168, 0f00000000;
(EngineCore_DP0 pid=455561) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=455561) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=455561) 	mov.b32 	%r169, %r45;
(EngineCore_DP0 pid=455561) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=455561) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=455561) 	add.s32 	%r55, %r4, %r169;
(EngineCore_DP0 pid=455561) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=455561) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=455561) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=455561) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=455561) 	// begin inline asm
(EngineCore_DP0 pid=455561) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=455561) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=455561) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=455561) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=455561) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=455561) 	// end inline asm
(EngineCore_DP0 pid=455561) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=455561) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=455561) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=455561) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=455561) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=455561) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=455561) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=455561) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=455561) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=455561) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=455561) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=455561) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=455561) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=455561) $L__tmp1:
(EngineCore_DP0 pid=455561) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	bar.sync 	0;
(EngineCore_DP0 pid=455561) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=455561) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=455561) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=455561) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=455561) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=455561) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=455561) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=455561) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=455561) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=455561) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=455561) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=455561) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=455561) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=455561) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=455561) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=455561) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=455561) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=455561) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=455561) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	// begin inline asm
(EngineCore_DP0 pid=455561) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=455561) 	// end inline asm
(EngineCore_DP0 pid=455561) 	bar.sync 	0;
(EngineCore_DP0 pid=455561) 	// begin inline asm
(EngineCore_DP0 pid=455561) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=455561) 	// end inline asm
(EngineCore_DP0 pid=455561) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=455561) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=455561) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=455561) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=455561) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=455561) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=455561) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=455561) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=455561) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=455561) 	// begin inline asm
(EngineCore_DP0 pid=455561) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=455561) 	// end inline asm
(EngineCore_DP0 pid=455561) 	bar.sync 	0;
(EngineCore_DP0 pid=455561) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=455561) $L__tmp2:
(EngineCore_DP0 pid=455561) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=455561) 	max.f32 	%r168, %r168, %r73;
(EngineCore_DP0 pid=455561) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=455561) 	add.s32 	%r169, %r169, 4096;
(EngineCore_DP0 pid=455561) 	setp.lt.s32 	%p6, %r169, %r24;
(EngineCore_DP0 pid=455561) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=455561) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=455561) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=455561) 	max.f32 	%r170, %r168, 0f2B8CBCCC;
(EngineCore_DP0 pid=455561) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=455561) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=455561) 	mov.b32 	%r75, 0f42FE0000;
(EngineCore_DP0 pid=455561) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=455561) 	div.full.f32 	%r76, %r170, %r75;
(EngineCore_DP0 pid=455561) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=455561) 	max.f32 	%r74, %r76, 0f37810204;
(EngineCore_DP0 pid=455561) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=455561) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=455561) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=455561) 	// begin inline asm
(EngineCore_DP0 pid=455561) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=455561) 	// end inline asm
(EngineCore_DP0 pid=455561) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=455561) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=455561) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=455561) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=455561) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=455561) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=455561) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=455561) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=455561) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=455561) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=455561) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=455561) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=455561) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=455561) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=455561) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=455561) 	div.full.f32 	%r14, %r75, %r170;
(EngineCore_DP0 pid=455561) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=455561) 	mov.b32 	%r171, 0;
(EngineCore_DP0 pid=455561) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=455561)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=455561) 	.loc	1 279 31                        // quant_slide_tuned_Qwen2.5-7B.py:279:31
(EngineCore_DP0 pid=455561) 	add.s32 	%r80, %r16, %r171;
(EngineCore_DP0 pid=455561) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=455561) 	add.s32 	%r81, %r80, 1;
(EngineCore_DP0 pid=455561) 	setp.lt.s32 	%p17, %r80, %r15;
(EngineCore_DP0 pid=455561) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=455561) 	shr.s32 	%r82, %r80, 31;
(EngineCore_DP0 pid=455561) 	shr.u32 	%r83, %r82, 30;
(EngineCore_DP0 pid=455561) 	add.s32 	%r84, %r80, %r83;
(EngineCore_DP0 pid=455561) 	shr.s32 	%r85, %r84, 2;
(EngineCore_DP0 pid=455561) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=455561) 	shr.s32 	%r86, %r81, 31;
(EngineCore_DP0 pid=455561) 	shr.u32 	%r87, %r86, 30;
(EngineCore_DP0 pid=455561) 	add.s32 	%r88, %r81, %r87;
(EngineCore_DP0 pid=455561) 	and.b32 	%r89, %r88, 2147483644;
(EngineCore_DP0 pid=455561) 	sub.s32 	%r90, %r81, %r89;
(EngineCore_DP0 pid=455561) 	and.b32 	%r91, %r84, 2147483644;
(EngineCore_DP0 pid=455561) 	sub.s32 	%r92, %r80, %r91;
(EngineCore_DP0 pid=455561) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=455561) 	mul.lo.s32 	%r93, %r85, 10;
(EngineCore_DP0 pid=455561) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=455561) 	shl.b32 	%r94, %r92, 1;
(EngineCore_DP0 pid=455561) 	shl.b32 	%r95, %r90, 1;
(EngineCore_DP0 pid=455561) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=455561) 	add.s32 	%r96, %r93, %r95;
(EngineCore_DP0 pid=455561) 	add.s32 	%r97, %r93, %r94;
(EngineCore_DP0 pid=455561) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=455561) 	setp.lt.s32 	%p18, %r97, %r23;
(EngineCore_DP0 pid=455561) 	setp.lt.s32 	%p19, %r96, %r23;
(EngineCore_DP0 pid=455561) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=455561) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=455561) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=455561) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=455561) 	mad.wide.s32 	%rd8, %r97, 2, %rd1;
(EngineCore_DP0 pid=455561) 	mad.wide.s32 	%rd9, %r96, 2, %rd1;
(EngineCore_DP0 pid=455561) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=455561) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=455561) 	// begin inline asm
(EngineCore_DP0 pid=455561) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=455561) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=455561) 	// end inline asm
(EngineCore_DP0 pid=455561) 	// begin inline asm
(EngineCore_DP0 pid=455561) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=455561) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=455561) 	// end inline asm
(EngineCore_DP0 pid=455561) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=455561) 	cvt.f32.bf16 	%r98, %rs24;
(EngineCore_DP0 pid=455561) 	cvt.f32.bf16 	%r99, %rs26;
(EngineCore_DP0 pid=455561) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=455561) 	or.b32 	%r100, %r97, 1;
(EngineCore_DP0 pid=455561) 	or.b32 	%r101, %r96, 1;
(EngineCore_DP0 pid=455561) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=455561) 	setp.lt.s32 	%p20, %r100, %r23;
(EngineCore_DP0 pid=455561) 	setp.lt.s32 	%p21, %r101, %r23;
(EngineCore_DP0 pid=455561) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=455561) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=455561) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=455561) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=455561) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=455561) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=455561) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=455561) 	// begin inline asm
(EngineCore_DP0 pid=455561) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=455561) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=455561) 	// end inline asm
(EngineCore_DP0 pid=455561) 	// begin inline asm
(EngineCore_DP0 pid=455561) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=455561) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=455561) 	// end inline asm
(EngineCore_DP0 pid=455561) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=455561) 	cvt.f32.bf16 	%r102, %rs28;
(EngineCore_DP0 pid=455561) 	cvt.f32.bf16 	%r103, %rs30;
(EngineCore_DP0 pid=455561) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=455561) 	add.s32 	%r104, %r97, 2;
(EngineCore_DP0 pid=455561) 	add.s32 	%r105, %r96, 2;
(EngineCore_DP0 pid=455561) 	add.s32 	%r106, %r97, 3;
(EngineCore_DP0 pid=455561) 	add.s32 	%r107, %r96, 3;
(EngineCore_DP0 pid=455561) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=455561) 	setp.lt.s32 	%p22, %r107, %r23;
(EngineCore_DP0 pid=455561) 	setp.lt.s32 	%p23, %r106, %r23;
(EngineCore_DP0 pid=455561) 	setp.lt.s32 	%p24, %r105, %r23;
(EngineCore_DP0 pid=455561) 	setp.lt.s32 	%p25, %r104, %r23;
(EngineCore_DP0 pid=455561) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=455561) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=455561) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=455561) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=455561) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=455561) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=455561) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=455561) 	// begin inline asm
(EngineCore_DP0 pid=455561) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=455561) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=455561) 	// end inline asm
(EngineCore_DP0 pid=455561) 	// begin inline asm
(EngineCore_DP0 pid=455561) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=455561) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=455561) 	// end inline asm
(EngineCore_DP0 pid=455561) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=455561) 	cvt.f32.bf16 	%r108, %rs32;
(EngineCore_DP0 pid=455561) 	cvt.f32.bf16 	%r109, %rs34;
(EngineCore_DP0 pid=455561) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=455561) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=455561) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=455561) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=455561) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=455561) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=455561) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=455561) 	// begin inline asm
(EngineCore_DP0 pid=455561) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=455561) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=455561) 	// end inline asm
(EngineCore_DP0 pid=455561) 	// begin inline asm
(EngineCore_DP0 pid=455561) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=455561) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=455561) 	// end inline asm
(EngineCore_DP0 pid=455561) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=455561) 	cvt.f32.bf16 	%r110, %rs36;
(EngineCore_DP0 pid=455561) 	cvt.f32.bf16 	%r111, %rs38;
(EngineCore_DP0 pid=455561) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=455561) 	mul.f32 	%r112, %r14, %r98;
(EngineCore_DP0 pid=455561) 	mul.f32 	%r113, %r14, %r99;
(EngineCore_DP0 pid=455561) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=455561) 	cvt.rni.f32.f32 	%r114, %r112;
(EngineCore_DP0 pid=455561) 	cvt.rni.f32.f32 	%r115, %r113;
(EngineCore_DP0 pid=455561) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=455561) 	max.f32 	%r116, %r114, 0fC3000000;
(EngineCore_DP0 pid=455561) 	min.f32 	%r117, %r116, 0f42FE0000;
(EngineCore_DP0 pid=455561) 	max.f32 	%r118, %r115, 0fC3000000;
(EngineCore_DP0 pid=455561) 	min.f32 	%r119, %r118, 0f42FE0000;
(EngineCore_DP0 pid=455561) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=455561) 	cvt.rzi.s32.f32 	%r120, %r117;
(EngineCore_DP0 pid=455561) 	cvt.rzi.s32.f32 	%r121, %r119;
(EngineCore_DP0 pid=455561) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=455561) 	and.b32 	%r122, %r120, 255;
(EngineCore_DP0 pid=455561) 	and.b32 	%r123, %r121, 255;
(EngineCore_DP0 pid=455561) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=455561) 	mul.f32 	%r124, %r14, %r102;
(EngineCore_DP0 pid=455561) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=455561) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=455561) 	cvt.rni.f32.f32 	%r126, %r124;
(EngineCore_DP0 pid=455561) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=455561) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=455561) 	mul.f32 	%r128, %r14, %r108;
(EngineCore_DP0 pid=455561) 	mul.f32 	%r129, %r14, %r109;
(EngineCore_DP0 pid=455561) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=455561) 	cvt.rni.f32.f32 	%r130, %r128;
(EngineCore_DP0 pid=455561) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=455561) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=455561) 	mul.f32 	%r132, %r14, %r110;
(EngineCore_DP0 pid=455561) 	mul.f32 	%r133, %r14, %r111;
(EngineCore_DP0 pid=455561) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=455561) 	cvt.rni.f32.f32 	%r134, %r132;
(EngineCore_DP0 pid=455561) 	cvt.rni.f32.f32 	%r135, %r133;
(EngineCore_DP0 pid=455561) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=455561) 	max.f32 	%r136, %r134, 0fC3000000;
(EngineCore_DP0 pid=455561) 	min.f32 	%r137, %r136, 0f42FE0000;
(EngineCore_DP0 pid=455561) 	max.f32 	%r138, %r135, 0fC3000000;
(EngineCore_DP0 pid=455561) 	min.f32 	%r139, %r138, 0f42FE0000;
(EngineCore_DP0 pid=455561) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=455561) 	cvt.rzi.s32.f32 	%r140, %r137;
(EngineCore_DP0 pid=455561) 	cvt.rzi.s32.f32 	%r141, %r139;
(EngineCore_DP0 pid=455561) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=455561) 	max.f32 	%r142, %r130, 0fC3000000;
(EngineCore_DP0 pid=455561) 	max.f32 	%r143, %r126, 0fC3000000;
(EngineCore_DP0 pid=455561) 	min.f32 	%r144, %r143, 0f42FE0000;
(EngineCore_DP0 pid=455561) 	min.f32 	%r145, %r142, 0f42FE0000;
(EngineCore_DP0 pid=455561) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=455561) 	cvt.rzi.s32.f32 	%r146, %r145;
(EngineCore_DP0 pid=455561) 	cvt.rzi.s32.f32 	%r147, %r144;
(EngineCore_DP0 pid=455561) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=455561) 	shl.b32 	%r148, %r147, 8;
(EngineCore_DP0 pid=455561) 	shl.b32 	%r149, %r146, 16;
(EngineCore_DP0 pid=455561) 	and.b32 	%r150, %r149, 16711680;
(EngineCore_DP0 pid=455561) 	and.b32 	%r151, %r148, 65280;
(EngineCore_DP0 pid=455561) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=455561) 	or.b32 	%r152, %r151, %r122;
(EngineCore_DP0 pid=455561) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=455561) 	max.f32 	%r153, %r131, 0fC3000000;
(EngineCore_DP0 pid=455561) 	max.f32 	%r154, %r127, 0fC3000000;
(EngineCore_DP0 pid=455561) 	min.f32 	%r155, %r154, 0f42FE0000;
(EngineCore_DP0 pid=455561) 	min.f32 	%r156, %r153, 0f42FE0000;
(EngineCore_DP0 pid=455561) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=455561) 	cvt.rzi.s32.f32 	%r157, %r156;
(EngineCore_DP0 pid=455561) 	cvt.rzi.s32.f32 	%r158, %r155;
(EngineCore_DP0 pid=455561) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=455561) 	shl.b32 	%r159, %r158, 8;
(EngineCore_DP0 pid=455561) 	shl.b32 	%r160, %r157, 16;
(EngineCore_DP0 pid=455561) 	and.b32 	%r161, %r160, 16711680;
(EngineCore_DP0 pid=455561) 	and.b32 	%r162, %r159, 65280;
(EngineCore_DP0 pid=455561) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=455561) 	or.b32 	%r163, %r162, %r123;
(EngineCore_DP0 pid=455561) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=455561) 	or.b32 	%r164, %r152, %r150;
(EngineCore_DP0 pid=455561) 	or.b32 	%r165, %r163, %r161;
(EngineCore_DP0 pid=455561) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=455561) 	shl.b32 	%r166, %r140, 24;
(EngineCore_DP0 pid=455561) 	shl.b32 	%r167, %r141, 24;
(EngineCore_DP0 pid=455561) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=455561) 	or.b32 	%r78, %r164, %r166;
(EngineCore_DP0 pid=455561) 	or.b32 	%r79, %r165, %r167;
(EngineCore_DP0 pid=455561) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=455561) 	mad.wide.s32 	%rd16, %r80, 4, %rd2;
(EngineCore_DP0 pid=455561) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=455561) 	// begin inline asm
(EngineCore_DP0 pid=455561) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r78, %r79 };
(EngineCore_DP0 pid=455561) 	// end inline asm
(EngineCore_DP0 pid=455561) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=455561) 	add.s32 	%r171, %r171, 1024;
(EngineCore_DP0 pid=455561) 	setp.lt.s32 	%p26, %r171, %r15;
(EngineCore_DP0 pid=455561) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=455561) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=455561) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=455561) 	ret;
(EngineCore_DP0 pid=455561) $L__tmp3:
(EngineCore_DP0 pid=455561) $L__func_end0:
(EngineCore_DP0 pid=455561)                                         // -- End function
(EngineCore_DP0 pid=455561) }
(EngineCore_DP0 pid=455561) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=455561) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=455561) 	.section	.debug_abbrev
(EngineCore_DP0 pid=455561) 	{
(EngineCore_DP0 pid=455561) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=455561) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=455561) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=455561) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=455561) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=455561) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=455561) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=455561) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=455561) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=455561) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=455561) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=455561) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=455561) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=455561) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=455561) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=455561) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=455561) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=455561) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=455561) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=455561) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=455561) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=455561) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=455561) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=455561) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=455561) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=455561) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=455561) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=455561) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=455561) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=455561) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=455561) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=455561) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=455561) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=455561) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=455561) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=455561) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=455561) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=455561) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=455561) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=455561) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=455561) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=455561) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=455561) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=455561) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=455561) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=455561) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=455561) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=455561) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=455561) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=455561) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=455561) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=455561) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=455561) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=455561) 	}
(EngineCore_DP0 pid=455561) 	.section	.debug_info
(EngineCore_DP0 pid=455561) 	{
(EngineCore_DP0 pid=455561) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=455561) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=455561) .b8 0
(EngineCore_DP0 pid=455561) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=455561) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=455561) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=455561) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=455561) .b8 114
(EngineCore_DP0 pid=455561) .b8 105
(EngineCore_DP0 pid=455561) .b8 116
(EngineCore_DP0 pid=455561) .b8 111
(EngineCore_DP0 pid=455561) .b8 110
(EngineCore_DP0 pid=455561) .b8 0
(EngineCore_DP0 pid=455561) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=455561) .b8 0
(EngineCore_DP0 pid=455561) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=455561) .b8 117
(EngineCore_DP0 pid=455561) .b8 97
(EngineCore_DP0 pid=455561) .b8 110
(EngineCore_DP0 pid=455561) .b8 116
(EngineCore_DP0 pid=455561) .b8 95
(EngineCore_DP0 pid=455561) .b8 115
(EngineCore_DP0 pid=455561) .b8 108
(EngineCore_DP0 pid=455561) .b8 105
(EngineCore_DP0 pid=455561) .b8 100
(EngineCore_DP0 pid=455561) .b8 101
(EngineCore_DP0 pid=455561) .b8 95
(EngineCore_DP0 pid=455561) .b8 116
(EngineCore_DP0 pid=455561) .b8 117
(EngineCore_DP0 pid=455561) .b8 110
(EngineCore_DP0 pid=455561) .b8 101
(EngineCore_DP0 pid=455561) .b8 100
(EngineCore_DP0 pid=455561) .b8 95
(EngineCore_DP0 pid=455561) .b8 81
(EngineCore_DP0 pid=455561) .b8 119
(EngineCore_DP0 pid=455561) .b8 101
(EngineCore_DP0 pid=455561) .b8 110
(EngineCore_DP0 pid=455561) .b8 50
(EngineCore_DP0 pid=455561) .b8 46
(EngineCore_DP0 pid=455561) .b8 53
(EngineCore_DP0 pid=455561) .b8 45
(EngineCore_DP0 pid=455561) .b8 55
(EngineCore_DP0 pid=455561) .b8 66
(EngineCore_DP0 pid=455561) .b8 46
(EngineCore_DP0 pid=455561) .b8 112
(EngineCore_DP0 pid=455561) .b8 121
(EngineCore_DP0 pid=455561) .b8 0
(EngineCore_DP0 pid=455561) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=455561) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=455561) .b8 114
(EngineCore_DP0 pid=455561) .b8 111
(EngineCore_DP0 pid=455561) .b8 111
(EngineCore_DP0 pid=455561) .b8 116
(EngineCore_DP0 pid=455561) .b8 47
(EngineCore_DP0 pid=455561) .b8 118
(EngineCore_DP0 pid=455561) .b8 108
(EngineCore_DP0 pid=455561) .b8 108
(EngineCore_DP0 pid=455561) .b8 109
(EngineCore_DP0 pid=455561) .b8 98
(EngineCore_DP0 pid=455561) .b8 101
(EngineCore_DP0 pid=455561) .b8 110
(EngineCore_DP0 pid=455561) .b8 99
(EngineCore_DP0 pid=455561) .b8 104
(EngineCore_DP0 pid=455561) .b8 47
(EngineCore_DP0 pid=455561) .b8 115
(EngineCore_DP0 pid=455561) .b8 108
(EngineCore_DP0 pid=455561) .b8 105
(EngineCore_DP0 pid=455561) .b8 100
(EngineCore_DP0 pid=455561) .b8 101
(EngineCore_DP0 pid=455561) .b8 115
(EngineCore_DP0 pid=455561) .b8 112
(EngineCore_DP0 pid=455561) .b8 97
(EngineCore_DP0 pid=455561) .b8 114
(EngineCore_DP0 pid=455561) .b8 115
(EngineCore_DP0 pid=455561) .b8 101
(EngineCore_DP0 pid=455561) .b8 47
(EngineCore_DP0 pid=455561) .b8 99
(EngineCore_DP0 pid=455561) .b8 115
(EngineCore_DP0 pid=455561) .b8 114
(EngineCore_DP0 pid=455561) .b8 99
(EngineCore_DP0 pid=455561) .b8 47
(EngineCore_DP0 pid=455561) .b8 102
(EngineCore_DP0 pid=455561) .b8 117
(EngineCore_DP0 pid=455561) .b8 115
(EngineCore_DP0 pid=455561) .b8 101
(EngineCore_DP0 pid=455561) .b8 100
(EngineCore_DP0 pid=455561) .b8 95
(EngineCore_DP0 pid=455561) .b8 113
(EngineCore_DP0 pid=455561) .b8 117
(EngineCore_DP0 pid=455561) .b8 97
(EngineCore_DP0 pid=455561) .b8 110
(EngineCore_DP0 pid=455561) .b8 116
(EngineCore_DP0 pid=455561) .b8 95
(EngineCore_DP0 pid=455561) .b8 115
(EngineCore_DP0 pid=455561) .b8 108
(EngineCore_DP0 pid=455561) .b8 105
(EngineCore_DP0 pid=455561) .b8 100
(EngineCore_DP0 pid=455561) .b8 101
(EngineCore_DP0 pid=455561) .b8 95
(EngineCore_DP0 pid=455561) .b8 116
(EngineCore_DP0 pid=455561) .b8 114
(EngineCore_DP0 pid=455561) .b8 105
(EngineCore_DP0 pid=455561) .b8 116
(EngineCore_DP0 pid=455561) .b8 111
(EngineCore_DP0 pid=455561) .b8 110
(EngineCore_DP0 pid=455561) .b8 47
(EngineCore_DP0 pid=455561) .b8 98
(EngineCore_DP0 pid=455561) .b8 117
(EngineCore_DP0 pid=455561) .b8 105
(EngineCore_DP0 pid=455561) .b8 108
(EngineCore_DP0 pid=455561) .b8 100
(EngineCore_DP0 pid=455561) .b8 47
(EngineCore_DP0 pid=455561) .b8 71
(EngineCore_DP0 pid=455561) .b8 66
(EngineCore_DP0 pid=455561) .b8 49
(EngineCore_DP0 pid=455561) .b8 48
(EngineCore_DP0 pid=455561) .b8 95
(EngineCore_DP0 pid=455561) .b8 99
(EngineCore_DP0 pid=455561) .b8 99
(EngineCore_DP0 pid=455561) .b8 49
(EngineCore_DP0 pid=455561) .b8 50
(EngineCore_DP0 pid=455561) .b8 49
(EngineCore_DP0 pid=455561) .b8 95
(EngineCore_DP0 pid=455561) .b8 112
(EngineCore_DP0 pid=455561) .b8 121
(EngineCore_DP0 pid=455561) .b8 51
(EngineCore_DP0 pid=455561) .b8 49
(EngineCore_DP0 pid=455561) .b8 50
(EngineCore_DP0 pid=455561) .b8 95
(EngineCore_DP0 pid=455561) .b8 99
(EngineCore_DP0 pid=455561) .b8 117
(EngineCore_DP0 pid=455561) .b8 49
(EngineCore_DP0 pid=455561) .b8 50
(EngineCore_DP0 pid=455561) .b8 57
(EngineCore_DP0 pid=455561) .b8 95
(EngineCore_DP0 pid=455561) .b8 97
(EngineCore_DP0 pid=455561) .b8 97
(EngineCore_DP0 pid=455561) .b8 114
(EngineCore_DP0 pid=455561) .b8 99
(EngineCore_DP0 pid=455561) .b8 104
(EngineCore_DP0 pid=455561) .b8 54
(EngineCore_DP0 pid=455561) .b8 52
(EngineCore_DP0 pid=455561) .b8 0
(EngineCore_DP0 pid=455561) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=455561) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=455561) .b8 113
(EngineCore_DP0 pid=455561) .b8 117
(EngineCore_DP0 pid=455561) .b8 97
(EngineCore_DP0 pid=455561) .b8 110
(EngineCore_DP0 pid=455561) .b8 116
(EngineCore_DP0 pid=455561) .b8 95
(EngineCore_DP0 pid=455561) .b8 115
(EngineCore_DP0 pid=455561) .b8 108
(EngineCore_DP0 pid=455561) .b8 105
(EngineCore_DP0 pid=455561) .b8 100
(EngineCore_DP0 pid=455561) .b8 101
(EngineCore_DP0 pid=455561) .b8 95
(EngineCore_DP0 pid=455561) .b8 105
(EngineCore_DP0 pid=455561) .b8 110
(EngineCore_DP0 pid=455561) .b8 116
(EngineCore_DP0 pid=455561) .b8 56
(EngineCore_DP0 pid=455561) .b8 95
(EngineCore_DP0 pid=455561) .b8 107
(EngineCore_DP0 pid=455561) .b8 101
(EngineCore_DP0 pid=455561) .b8 114
(EngineCore_DP0 pid=455561) .b8 110
(EngineCore_DP0 pid=455561) .b8 101
(EngineCore_DP0 pid=455561) .b8 108
(EngineCore_DP0 pid=455561) .b8 0
(EngineCore_DP0 pid=455561) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=455561) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=455561) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=455561) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=455561) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=455561) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=455561) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=455561) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=455561) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=455561) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=455561) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=455561) .b8 1
(EngineCore_DP0 pid=455561) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=455561) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=455561) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=455561) 	}
(EngineCore_DP0 pid=455561) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=455561) 
(EngineCore_DP0 pid=455561) ================================================================
(EngineCore_DP0 pid=455561) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=455561) 
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp9j6gy6zs.ptx', '-o', '/tmp/tmp9j6gy6zs.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866] 
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866] 
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866] 
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp9j6gy6zs.ptx -o /tmp/tmp9j6gy6zs.ptx.o
(EngineCore_DP0 pid=455561) ERROR 01-25 21:07:20 [core.py:866] 

STDERR:
[2026-01-25 21:06:08] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:06:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:06:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:06:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:06:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:06:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:06:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:06:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:06:12] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:06:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:06:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:06:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:06:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:06:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:06:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:06:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:06:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=455561) [2026-01-25 21:06:13] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=455561) [2026-01-25 21:06:13] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=455561) [2026-01-25 21:06:13] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=455561) [2026-01-25 21:06:13] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=455561) [2026-01-25 21:06:13] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=455561) [2026-01-25 21:06:13] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=455561) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=455561) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.38s/it]
(EngineCore_DP0 pid=455561) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:03<00:00, 32.61s/it]
(EngineCore_DP0 pid=455561) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:03<00:00, 31.83s/it]
(EngineCore_DP0 pid=455561) 
(EngineCore_DP0 pid=455561) [2026-01-25 21:07:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=455561) [2026-01-25 21:07:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=455561) [2026-01-25 21:07:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=455561) [2026-01-25 21:07:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=455561) [2026-01-25 21:07:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=455561) [2026-01-25 21:07:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=455561) [2026-01-25 21:07:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=455561) [2026-01-25 21:07:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=455561) Process EngineCore_DP0:
(EngineCore_DP0 pid=455561) Traceback (most recent call last):
(EngineCore_DP0 pid=455561)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=455561)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=455561)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=455561)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=455561) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp9j6gy6zs.ptx', '-o', '/tmp/tmp9j6gy6zs.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=455561) 
(EngineCore_DP0 pid=455561) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=455561) 
(EngineCore_DP0 pid=455561) Traceback (most recent call last):
(EngineCore_DP0 pid=455561)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=455561)     self.run()
(EngineCore_DP0 pid=455561)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=455561)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=455561)     raise e
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=455561)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=455561)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=455561)     super().__init__(
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=455561)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=455561)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=455561)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=455561)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=455561)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=455561)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=455561)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=455561)     return func(*args, **kwargs)
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=455561)     return func(*args, **kwargs)
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=455561)     self.model_runner.profile_run()
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=455561)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=455561)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=455561)     return func(*args, **kwargs)
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=455561)     outputs = self.model(
(EngineCore_DP0 pid=455561)               ^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=455561)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=455561)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=455561)     hidden_states = self.model(
(EngineCore_DP0 pid=455561)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=455561)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=455561)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=455561)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=455561)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=455561)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=455561)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=455561)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=455561)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=455561)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=455561)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=455561)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=455561)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=455561)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=455561)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=455561)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=455561)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=455561)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=455561)     return self._linear_fn(
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=455561)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=455561)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=455561)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=455561)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=455561)     return fn(input, L)
(EngineCore_DP0 pid=455561)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=455561)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=455561)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=455561)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=455561)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=455561)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=455561)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=455561)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=455561)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=455561)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=455561)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=455561)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=455561)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=455561)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=455561)     raise PTXASError(error)
(EngineCore_DP0 pid=455561) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=455561) `ptxas` stderr:
(EngineCore_DP0 pid=455561) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=455561) 
(EngineCore_DP0 pid=455561) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp9j6gy6zs.ptx -o /tmp/tmp9j6gy6zs.ptx.o
(EngineCore_DP0 pid=455561) 
[rank0]:[W125 21:07:20.718116124 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 21:07:22
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:07:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:07:54 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=457209) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=457209) 
(EngineCore_DP0 pid=457209) 
(EngineCore_DP0 pid=457209) ================================================================
(EngineCore_DP0 pid=457209) Internal Triton PTX codegen error
(EngineCore_DP0 pid=457209) `ptxas` stderr:
(EngineCore_DP0 pid=457209) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=457209) 
(EngineCore_DP0 pid=457209) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp34gt9fxs.ptx -o /tmp/tmp34gt9fxs.ptx.o
(EngineCore_DP0 pid=457209) 
(EngineCore_DP0 pid=457209) 
(EngineCore_DP0 pid=457209) //
(EngineCore_DP0 pid=457209) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=457209) //
(EngineCore_DP0 pid=457209) 
(EngineCore_DP0 pid=457209) .version 8.7
(EngineCore_DP0 pid=457209) .target sm_121a
(EngineCore_DP0 pid=457209) .address_size 64
(EngineCore_DP0 pid=457209) 
(EngineCore_DP0 pid=457209) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=457209) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=457209)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=457209) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=457209) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=457209) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=457209) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=457209) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=457209) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=457209) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=457209) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=457209) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=457209) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=457209) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=457209) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=457209) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=457209) )
(EngineCore_DP0 pid=457209) .reqntid 512
(EngineCore_DP0 pid=457209) {
(EngineCore_DP0 pid=457209) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=457209) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=457209) 	.reg .b32 	%r<132>;
(EngineCore_DP0 pid=457209) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=457209) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=457209) $L__func_begin0:
(EngineCore_DP0 pid=457209) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=457209) 
(EngineCore_DP0 pid=457209) // %bb.0:
(EngineCore_DP0 pid=457209) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=457209) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=457209) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=457209) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=457209) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=457209) $L__tmp0:
(EngineCore_DP0 pid=457209) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=457209) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=457209) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=457209) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=457209) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=457209) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=457209) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=457209) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=457209) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=457209) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=457209) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=457209) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=457209) 	mov.b32 	%r130, 0f2B8CBCCC;
(EngineCore_DP0 pid=457209) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=457209) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=457209) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=457209) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=457209) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=457209) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=457209) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=457209) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=457209) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=457209) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=457209) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=457209) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=457209) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=457209) 	mov.b32 	%r128, 0f00000000;
(EngineCore_DP0 pid=457209) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=457209) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=457209) 	mov.b32 	%r129, %r40;
(EngineCore_DP0 pid=457209) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=457209) 	.loc	1 265 19                        // quant_slide_tuned_Qwen2.5-7B.py:265:19
(EngineCore_DP0 pid=457209) 	add.s32 	%r58, %r4, %r129;
(EngineCore_DP0 pid=457209) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=457209) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=457209) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=457209) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=457209) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=457209) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=457209) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=457209) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=457209) 	// begin inline asm
(EngineCore_DP0 pid=457209) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=457209) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=457209) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=457209) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=457209) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=457209) 	// end inline asm
(EngineCore_DP0 pid=457209) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=457209) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=457209) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=457209) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=457209) 	// begin inline asm
(EngineCore_DP0 pid=457209) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=457209) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=457209) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=457209) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=457209) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=457209) 	// end inline asm
(EngineCore_DP0 pid=457209) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=457209) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=457209) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=457209) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=457209) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=457209) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=457209) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=457209) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=457209) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=457209) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=457209) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=457209) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=457209) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=457209) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=457209) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=457209) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=457209) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=457209) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=457209) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=457209) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=457209) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=457209) $L__tmp1:
(EngineCore_DP0 pid=457209) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	bar.sync 	0;
(EngineCore_DP0 pid=457209) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=457209) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=457209) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=457209) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=457209) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=457209) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=457209) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=457209) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=457209) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=457209) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=457209) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=457209) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=457209) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=457209) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=457209) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=457209) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=457209) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=457209) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=457209) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=457209) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=457209) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=457209) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=457209) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=457209) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=457209) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=457209) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=457209) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	// begin inline asm
(EngineCore_DP0 pid=457209) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=457209) 	// end inline asm
(EngineCore_DP0 pid=457209) 	bar.sync 	0;
(EngineCore_DP0 pid=457209) 	// begin inline asm
(EngineCore_DP0 pid=457209) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=457209) 	// end inline asm
(EngineCore_DP0 pid=457209) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=457209) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=457209) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=457209) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=457209) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=457209) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=457209) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=457209) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=457209) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=457209) 	// begin inline asm
(EngineCore_DP0 pid=457209) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=457209) 	// end inline asm
(EngineCore_DP0 pid=457209) 	bar.sync 	0;
(EngineCore_DP0 pid=457209) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=457209) $L__tmp2:
(EngineCore_DP0 pid=457209) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=457209) 	max.f32 	%r128, %r128, %r77;
(EngineCore_DP0 pid=457209) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=457209) 	add.s32 	%r129, %r129, 8192;
(EngineCore_DP0 pid=457209) 	setp.lt.s32 	%p7, %r129, %r19;
(EngineCore_DP0 pid=457209) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=457209) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=457209) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=457209) 	max.f32 	%r130, %r128, 0f2B8CBCCC;
(EngineCore_DP0 pid=457209) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=457209) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=457209) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=457209) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=457209) 	div.full.f32 	%r80, %r130, %r79;
(EngineCore_DP0 pid=457209) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=457209) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=457209) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=457209) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=457209) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=457209) 	// begin inline asm
(EngineCore_DP0 pid=457209) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=457209) 	// end inline asm
(EngineCore_DP0 pid=457209) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=457209) 	shl.b32 	%r15, %r20, 2;
(EngineCore_DP0 pid=457209) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=457209) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=457209) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=457209) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=457209) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=457209) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=457209) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=457209) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=457209) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=457209) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=457209) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=457209) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=457209) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=457209) 	div.full.f32 	%r14, %r79, %r130;
(EngineCore_DP0 pid=457209) 	mov.b32 	%r131, 0;
(EngineCore_DP0 pid=457209) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=457209)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=457209) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=457209) 	add.s32 	%r84, %r3, %r131;
(EngineCore_DP0 pid=457209) 	setp.lt.s32 	%p14, %r84, %r15;
(EngineCore_DP0 pid=457209) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=457209) 	shr.s32 	%r85, %r84, 31;
(EngineCore_DP0 pid=457209) 	shr.u32 	%r86, %r85, 30;
(EngineCore_DP0 pid=457209) 	add.s32 	%r87, %r84, %r86;
(EngineCore_DP0 pid=457209) 	shr.s32 	%r88, %r87, 2;
(EngineCore_DP0 pid=457209) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=457209) 	and.b32 	%r89, %r87, 2147483644;
(EngineCore_DP0 pid=457209) 	sub.s32 	%r90, %r84, %r89;
(EngineCore_DP0 pid=457209) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=457209) 	shl.b32 	%r91, %r90, 1;
(EngineCore_DP0 pid=457209) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=457209) 	mad.lo.s32 	%r92, %r88, 10, %r91;
(EngineCore_DP0 pid=457209) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=457209) 	setp.lt.s32 	%p15, %r92, %r18;
(EngineCore_DP0 pid=457209) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=457209) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=457209) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=457209) 	mad.wide.s32 	%rd9, %r92, 2, %rd1;
(EngineCore_DP0 pid=457209) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=457209) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=457209) 	// begin inline asm
(EngineCore_DP0 pid=457209) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=457209) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=457209) 	// end inline asm
(EngineCore_DP0 pid=457209) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=457209) 	cvt.f32.bf16 	%r93, %rs48;
(EngineCore_DP0 pid=457209) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=457209) 	or.b32 	%r94, %r92, 1;
(EngineCore_DP0 pid=457209) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=457209) 	setp.lt.s32 	%p16, %r94, %r18;
(EngineCore_DP0 pid=457209) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=457209) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=457209) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=457209) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=457209) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=457209) 	// begin inline asm
(EngineCore_DP0 pid=457209) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=457209) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=457209) 	// end inline asm
(EngineCore_DP0 pid=457209) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=457209) 	cvt.f32.bf16 	%r95, %rs50;
(EngineCore_DP0 pid=457209) 	.loc	1 292 48                        // quant_slide_tuned_Qwen2.5-7B.py:292:48
(EngineCore_DP0 pid=457209) 	add.s32 	%r96, %r92, 2;
(EngineCore_DP0 pid=457209) 	.loc	1 292 53                        // quant_slide_tuned_Qwen2.5-7B.py:292:53
(EngineCore_DP0 pid=457209) 	setp.lt.s32 	%p17, %r96, %r18;
(EngineCore_DP0 pid=457209) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=457209) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=457209) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=457209) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=457209) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=457209) 	// begin inline asm
(EngineCore_DP0 pid=457209) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=457209) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=457209) 	// end inline asm
(EngineCore_DP0 pid=457209) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=457209) 	cvt.f32.bf16 	%r97, %rs52;
(EngineCore_DP0 pid=457209) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=457209) 	add.s32 	%r98, %r92, 3;
(EngineCore_DP0 pid=457209) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=457209) 	setp.lt.s32 	%p18, %r98, %r18;
(EngineCore_DP0 pid=457209) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=457209) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=457209) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=457209) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=457209) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=457209) 	// begin inline asm
(EngineCore_DP0 pid=457209) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=457209) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=457209) 	// end inline asm
(EngineCore_DP0 pid=457209) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=457209) 	cvt.f32.bf16 	%r99, %rs54;
(EngineCore_DP0 pid=457209) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=457209) 	mul.f32 	%r100, %r14, %r93;
(EngineCore_DP0 pid=457209) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=457209) 	cvt.rni.f32.f32 	%r101, %r100;
(EngineCore_DP0 pid=457209) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=457209) 	max.f32 	%r102, %r101, 0fC3000000;
(EngineCore_DP0 pid=457209) 	min.f32 	%r103, %r102, 0f42FE0000;
(EngineCore_DP0 pid=457209) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=457209) 	cvt.rzi.s32.f32 	%r104, %r103;
(EngineCore_DP0 pid=457209) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=457209) 	and.b32 	%r105, %r104, 255;
(EngineCore_DP0 pid=457209) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=457209) 	mul.f32 	%r106, %r14, %r95;
(EngineCore_DP0 pid=457209) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=457209) 	cvt.rni.f32.f32 	%r107, %r106;
(EngineCore_DP0 pid=457209) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=457209) 	mul.f32 	%r108, %r14, %r97;
(EngineCore_DP0 pid=457209) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=457209) 	cvt.rni.f32.f32 	%r109, %r108;
(EngineCore_DP0 pid=457209) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=457209) 	mul.f32 	%r110, %r14, %r99;
(EngineCore_DP0 pid=457209) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=457209) 	cvt.rni.f32.f32 	%r111, %r110;
(EngineCore_DP0 pid=457209) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=457209) 	max.f32 	%r112, %r111, 0fC3000000;
(EngineCore_DP0 pid=457209) 	min.f32 	%r113, %r112, 0f42FE0000;
(EngineCore_DP0 pid=457209) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=457209) 	cvt.rzi.s32.f32 	%r114, %r113;
(EngineCore_DP0 pid=457209) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=457209) 	max.f32 	%r115, %r109, 0fC3000000;
(EngineCore_DP0 pid=457209) 	max.f32 	%r116, %r107, 0fC3000000;
(EngineCore_DP0 pid=457209) 	min.f32 	%r117, %r116, 0f42FE0000;
(EngineCore_DP0 pid=457209) 	min.f32 	%r118, %r115, 0f42FE0000;
(EngineCore_DP0 pid=457209) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=457209) 	cvt.rzi.s32.f32 	%r119, %r118;
(EngineCore_DP0 pid=457209) 	cvt.rzi.s32.f32 	%r120, %r117;
(EngineCore_DP0 pid=457209) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=457209) 	shl.b32 	%r121, %r120, 8;
(EngineCore_DP0 pid=457209) 	shl.b32 	%r122, %r119, 16;
(EngineCore_DP0 pid=457209) 	and.b32 	%r123, %r122, 16711680;
(EngineCore_DP0 pid=457209) 	and.b32 	%r124, %r121, 65280;
(EngineCore_DP0 pid=457209) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=457209) 	or.b32 	%r125, %r124, %r105;
(EngineCore_DP0 pid=457209) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=457209) 	or.b32 	%r126, %r125, %r123;
(EngineCore_DP0 pid=457209) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=457209) 	shl.b32 	%r127, %r114, 24;
(EngineCore_DP0 pid=457209) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=457209) 	or.b32 	%r82, %r126, %r127;
(EngineCore_DP0 pid=457209) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=457209) 	mad.wide.s32 	%rd13, %r84, 4, %rd2;
(EngineCore_DP0 pid=457209) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=457209) 	// begin inline asm
(EngineCore_DP0 pid=457209) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r82 };
(EngineCore_DP0 pid=457209) 	// end inline asm
(EngineCore_DP0 pid=457209) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=457209) 	add.s32 	%r131, %r131, 512;
(EngineCore_DP0 pid=457209) 	setp.lt.s32 	%p19, %r131, %r15;
(EngineCore_DP0 pid=457209) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=457209) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=457209) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=457209) 	ret;
(EngineCore_DP0 pid=457209) $L__tmp3:
(EngineCore_DP0 pid=457209) $L__func_end0:
(EngineCore_DP0 pid=457209)                                         // -- End function
(EngineCore_DP0 pid=457209) }
(EngineCore_DP0 pid=457209) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=457209) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=457209) 	.section	.debug_abbrev
(EngineCore_DP0 pid=457209) 	{
(EngineCore_DP0 pid=457209) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=457209) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=457209) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=457209) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=457209) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=457209) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=457209) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=457209) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=457209) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=457209) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=457209) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=457209) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=457209) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=457209) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=457209) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=457209) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=457209) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=457209) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=457209) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=457209) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=457209) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=457209) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=457209) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=457209) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=457209) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=457209) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=457209) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=457209) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=457209) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=457209) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=457209) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=457209) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=457209) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=457209) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=457209) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=457209) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=457209) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=457209) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=457209) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=457209) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=457209) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=457209) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=457209) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=457209) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=457209) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=457209) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=457209) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=457209) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=457209) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=457209) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=457209) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=457209) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=457209) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=457209) 	}
(EngineCore_DP0 pid=457209) 	.section	.debug_info
(EngineCore_DP0 pid=457209) 	{
(EngineCore_DP0 pid=457209) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=457209) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=457209) .b8 0
(EngineCore_DP0 pid=457209) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=457209) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=457209) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=457209) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=457209) .b8 114
(EngineCore_DP0 pid=457209) .b8 105
(EngineCore_DP0 pid=457209) .b8 116
(EngineCore_DP0 pid=457209) .b8 111
(EngineCore_DP0 pid=457209) .b8 110
(EngineCore_DP0 pid=457209) .b8 0
(EngineCore_DP0 pid=457209) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=457209) .b8 0
(EngineCore_DP0 pid=457209) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=457209) .b8 117
(EngineCore_DP0 pid=457209) .b8 97
(EngineCore_DP0 pid=457209) .b8 110
(EngineCore_DP0 pid=457209) .b8 116
(EngineCore_DP0 pid=457209) .b8 95
(EngineCore_DP0 pid=457209) .b8 115
(EngineCore_DP0 pid=457209) .b8 108
(EngineCore_DP0 pid=457209) .b8 105
(EngineCore_DP0 pid=457209) .b8 100
(EngineCore_DP0 pid=457209) .b8 101
(EngineCore_DP0 pid=457209) .b8 95
(EngineCore_DP0 pid=457209) .b8 116
(EngineCore_DP0 pid=457209) .b8 117
(EngineCore_DP0 pid=457209) .b8 110
(EngineCore_DP0 pid=457209) .b8 101
(EngineCore_DP0 pid=457209) .b8 100
(EngineCore_DP0 pid=457209) .b8 95
(EngineCore_DP0 pid=457209) .b8 81
(EngineCore_DP0 pid=457209) .b8 119
(EngineCore_DP0 pid=457209) .b8 101
(EngineCore_DP0 pid=457209) .b8 110
(EngineCore_DP0 pid=457209) .b8 50
(EngineCore_DP0 pid=457209) .b8 46
(EngineCore_DP0 pid=457209) .b8 53
(EngineCore_DP0 pid=457209) .b8 45
(EngineCore_DP0 pid=457209) .b8 55
(EngineCore_DP0 pid=457209) .b8 66
(EngineCore_DP0 pid=457209) .b8 46
(EngineCore_DP0 pid=457209) .b8 112
(EngineCore_DP0 pid=457209) .b8 121
(EngineCore_DP0 pid=457209) .b8 0
(EngineCore_DP0 pid=457209) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=457209) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=457209) .b8 114
(EngineCore_DP0 pid=457209) .b8 111
(EngineCore_DP0 pid=457209) .b8 111
(EngineCore_DP0 pid=457209) .b8 116
(EngineCore_DP0 pid=457209) .b8 47
(EngineCore_DP0 pid=457209) .b8 118
(EngineCore_DP0 pid=457209) .b8 108
(EngineCore_DP0 pid=457209) .b8 108
(EngineCore_DP0 pid=457209) .b8 109
(EngineCore_DP0 pid=457209) .b8 98
(EngineCore_DP0 pid=457209) .b8 101
(EngineCore_DP0 pid=457209) .b8 110
(EngineCore_DP0 pid=457209) .b8 99
(EngineCore_DP0 pid=457209) .b8 104
(EngineCore_DP0 pid=457209) .b8 47
(EngineCore_DP0 pid=457209) .b8 115
(EngineCore_DP0 pid=457209) .b8 108
(EngineCore_DP0 pid=457209) .b8 105
(EngineCore_DP0 pid=457209) .b8 100
(EngineCore_DP0 pid=457209) .b8 101
(EngineCore_DP0 pid=457209) .b8 115
(EngineCore_DP0 pid=457209) .b8 112
(EngineCore_DP0 pid=457209) .b8 97
(EngineCore_DP0 pid=457209) .b8 114
(EngineCore_DP0 pid=457209) .b8 115
(EngineCore_DP0 pid=457209) .b8 101
(EngineCore_DP0 pid=457209) .b8 47
(EngineCore_DP0 pid=457209) .b8 99
(EngineCore_DP0 pid=457209) .b8 115
(EngineCore_DP0 pid=457209) .b8 114
(EngineCore_DP0 pid=457209) .b8 99
(EngineCore_DP0 pid=457209) .b8 47
(EngineCore_DP0 pid=457209) .b8 102
(EngineCore_DP0 pid=457209) .b8 117
(EngineCore_DP0 pid=457209) .b8 115
(EngineCore_DP0 pid=457209) .b8 101
(EngineCore_DP0 pid=457209) .b8 100
(EngineCore_DP0 pid=457209) .b8 95
(EngineCore_DP0 pid=457209) .b8 113
(EngineCore_DP0 pid=457209) .b8 117
(EngineCore_DP0 pid=457209) .b8 97
(EngineCore_DP0 pid=457209) .b8 110
(EngineCore_DP0 pid=457209) .b8 116
(EngineCore_DP0 pid=457209) .b8 95
(EngineCore_DP0 pid=457209) .b8 115
(EngineCore_DP0 pid=457209) .b8 108
(EngineCore_DP0 pid=457209) .b8 105
(EngineCore_DP0 pid=457209) .b8 100
(EngineCore_DP0 pid=457209) .b8 101
(EngineCore_DP0 pid=457209) .b8 95
(EngineCore_DP0 pid=457209) .b8 116
(EngineCore_DP0 pid=457209) .b8 114
(EngineCore_DP0 pid=457209) .b8 105
(EngineCore_DP0 pid=457209) .b8 116
(EngineCore_DP0 pid=457209) .b8 111
(EngineCore_DP0 pid=457209) .b8 110
(EngineCore_DP0 pid=457209) .b8 47
(EngineCore_DP0 pid=457209) .b8 98
(EngineCore_DP0 pid=457209) .b8 117
(EngineCore_DP0 pid=457209) .b8 105
(EngineCore_DP0 pid=457209) .b8 108
(EngineCore_DP0 pid=457209) .b8 100
(EngineCore_DP0 pid=457209) .b8 47
(EngineCore_DP0 pid=457209) .b8 71
(EngineCore_DP0 pid=457209) .b8 66
(EngineCore_DP0 pid=457209) .b8 49
(EngineCore_DP0 pid=457209) .b8 48
(EngineCore_DP0 pid=457209) .b8 95
(EngineCore_DP0 pid=457209) .b8 99
(EngineCore_DP0 pid=457209) .b8 99
(EngineCore_DP0 pid=457209) .b8 49
(EngineCore_DP0 pid=457209) .b8 50
(EngineCore_DP0 pid=457209) .b8 49
(EngineCore_DP0 pid=457209) .b8 95
(EngineCore_DP0 pid=457209) .b8 112
(EngineCore_DP0 pid=457209) .b8 121
(EngineCore_DP0 pid=457209) .b8 51
(EngineCore_DP0 pid=457209) .b8 49
(EngineCore_DP0 pid=457209) .b8 50
(EngineCore_DP0 pid=457209) .b8 95
(EngineCore_DP0 pid=457209) .b8 99
(EngineCore_DP0 pid=457209) .b8 117
(EngineCore_DP0 pid=457209) .b8 49
(EngineCore_DP0 pid=457209) .b8 50
(EngineCore_DP0 pid=457209) .b8 57
(EngineCore_DP0 pid=457209) .b8 95
(EngineCore_DP0 pid=457209) .b8 97
(EngineCore_DP0 pid=457209) .b8 97
(EngineCore_DP0 pid=457209) .b8 114
(EngineCore_DP0 pid=457209) .b8 99
(EngineCore_DP0 pid=457209) .b8 104
(EngineCore_DP0 pid=457209) .b8 54
(EngineCore_DP0 pid=457209) .b8 52
(EngineCore_DP0 pid=457209) .b8 0
(EngineCore_DP0 pid=457209) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=457209) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=457209) .b8 113
(EngineCore_DP0 pid=457209) .b8 117
(EngineCore_DP0 pid=457209) .b8 97
(EngineCore_DP0 pid=457209) .b8 110
(EngineCore_DP0 pid=457209) .b8 116
(EngineCore_DP0 pid=457209) .b8 95
(EngineCore_DP0 pid=457209) .b8 115
(EngineCore_DP0 pid=457209) .b8 108
(EngineCore_DP0 pid=457209) .b8 105
(EngineCore_DP0 pid=457209) .b8 100
(EngineCore_DP0 pid=457209) .b8 101
(EngineCore_DP0 pid=457209) .b8 95
(EngineCore_DP0 pid=457209) .b8 105
(EngineCore_DP0 pid=457209) .b8 110
(EngineCore_DP0 pid=457209) .b8 116
(EngineCore_DP0 pid=457209) .b8 56
(EngineCore_DP0 pid=457209) .b8 95
(EngineCore_DP0 pid=457209) .b8 107
(EngineCore_DP0 pid=457209) .b8 101
(EngineCore_DP0 pid=457209) .b8 114
(EngineCore_DP0 pid=457209) .b8 110
(EngineCore_DP0 pid=457209) .b8 101
(EngineCore_DP0 pid=457209) .b8 108
(EngineCore_DP0 pid=457209) .b8 0
(EngineCore_DP0 pid=457209) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=457209) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=457209) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=457209) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=457209) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=457209) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=457209) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=457209) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=457209) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=457209) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=457209) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=457209) .b8 1
(EngineCore_DP0 pid=457209) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=457209) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=457209) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=457209) 	}
(EngineCore_DP0 pid=457209) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=457209) 
(EngineCore_DP0 pid=457209) ================================================================
(EngineCore_DP0 pid=457209) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=457209) 
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp34gt9fxs.ptx', '-o', '/tmp/tmp34gt9fxs.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866] 
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866] 
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866] 
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp34gt9fxs.ptx -o /tmp/tmp34gt9fxs.ptx.o
(EngineCore_DP0 pid=457209) ERROR 01-25 21:09:06 [core.py:866] 

STDERR:
[2026-01-25 21:07:54] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:07:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:07:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:07:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:07:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:07:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:07:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:07:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:07:57] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:07:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:07:57] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 21:07:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 21:07:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 21:07:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:07:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:07:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:07:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=457209) [2026-01-25 21:07:58] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=457209) [2026-01-25 21:07:58] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=457209) [2026-01-25 21:07:58] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=457209) [2026-01-25 21:07:58] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=457209) [2026-01-25 21:07:58] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=457209) [2026-01-25 21:07:58] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=457209) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=457209) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.83s/it]
(EngineCore_DP0 pid=457209) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 32.94s/it]
(EngineCore_DP0 pid=457209) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 32.18s/it]
(EngineCore_DP0 pid=457209) 
(EngineCore_DP0 pid=457209) [2026-01-25 21:09:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=457209) [2026-01-25 21:09:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=457209) [2026-01-25 21:09:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=457209) [2026-01-25 21:09:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=457209) [2026-01-25 21:09:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=457209) [2026-01-25 21:09:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=457209) [2026-01-25 21:09:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=457209) [2026-01-25 21:09:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=457209) Process EngineCore_DP0:
(EngineCore_DP0 pid=457209) Traceback (most recent call last):
(EngineCore_DP0 pid=457209)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=457209)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=457209)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=457209)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=457209) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp34gt9fxs.ptx', '-o', '/tmp/tmp34gt9fxs.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=457209) 
(EngineCore_DP0 pid=457209) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=457209) 
(EngineCore_DP0 pid=457209) Traceback (most recent call last):
(EngineCore_DP0 pid=457209)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=457209)     self.run()
(EngineCore_DP0 pid=457209)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=457209)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=457209)     raise e
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=457209)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=457209)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=457209)     super().__init__(
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=457209)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=457209)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=457209)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=457209)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=457209)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=457209)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=457209)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=457209)     return func(*args, **kwargs)
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=457209)     return func(*args, **kwargs)
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=457209)     self.model_runner.profile_run()
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=457209)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=457209)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=457209)     return func(*args, **kwargs)
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=457209)     outputs = self.model(
(EngineCore_DP0 pid=457209)               ^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=457209)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=457209)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=457209)     hidden_states = self.model(
(EngineCore_DP0 pid=457209)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=457209)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=457209)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=457209)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=457209)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=457209)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=457209)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=457209)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=457209)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=457209)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=457209)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=457209)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=457209)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=457209)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=457209)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=457209)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=457209)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=457209)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=457209)     return self._linear_fn(
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=457209)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=457209)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=457209)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=457209)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=457209)     return fn(input, L)
(EngineCore_DP0 pid=457209)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=457209)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=457209)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=457209)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=457209)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=457209)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=457209)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=457209)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=457209)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=457209)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=457209)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=457209)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=457209)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=457209)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=457209)     raise PTXASError(error)
(EngineCore_DP0 pid=457209) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=457209) `ptxas` stderr:
(EngineCore_DP0 pid=457209) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=457209) 
(EngineCore_DP0 pid=457209) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp34gt9fxs.ptx -o /tmp/tmp34gt9fxs.ptx.o
(EngineCore_DP0 pid=457209) 
[rank0]:[W125 21:09:07.398014676 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=16 ==========
Time: 2026-01-26 02:29:45
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M16.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:29:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:29:49 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=744634) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=744634) WARNING 01-26 02:30:11 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 73.28 requests/s, 1245.75 total tokens/s, 73.28 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  128

STDERR:
[2026-01-26 02:29:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:29:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 02:29:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 02:29:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:29:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:29:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:29:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:29:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:29:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 02:29:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:29:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:29:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:29:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:29:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:29:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:29:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 02:29:52] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 02:29:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:29:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:29:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:29:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:29:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:29:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 02:29:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:29:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:29:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:29:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:29:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=744634) [2026-01-26 02:29:53] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=744634) [2026-01-26 02:29:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=744634) [2026-01-26 02:29:53] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=744634) [2026-01-26 02:29:53] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=744634) [2026-01-26 02:29:53] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=744634) [2026-01-26 02:29:53] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=744634) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=744634) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.70s/it]
(EngineCore_DP0 pid=744634) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.70s/it]
(EngineCore_DP0 pid=744634) 
(EngineCore_DP0 pid=744634) [2026-01-26 02:30:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=744634) [2026-01-26 02:30:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=744634) [2026-01-26 02:30:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=744634) [2026-01-26 02:30:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=744634) [2026-01-26 02:30:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=744634) [2026-01-26 02:30:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=744634) [2026-01-26 02:30:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=744634) [2026-01-26 02:30:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=744634) 2026-01-26 02:30:10,712 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=744634) 2026-01-26 02:30:10,721 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 13232.55it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:31,  4.07it/s, est. speed input: 65.13 toks/s, output: 4.07 toks/s]
Processed prompts:   8%|         | 10/128 [00:00<00:03, 35.05it/s, est. speed input: 456.62 toks/s, output: 28.54 toks/s]
Processed prompts:  15%|        | 19/128 [00:00<00:02, 53.28it/s, est. speed input: 670.98 toks/s, output: 41.93 toks/s]
Processed prompts:  21%|        | 27/128 [00:00<00:01, 61.81it/s, est. speed input: 780.02 toks/s, output: 48.75 toks/s]
Processed prompts:  27%|       | 35/128 [00:00<00:01, 65.37it/s, est. speed input: 842.76 toks/s, output: 52.67 toks/s]
Processed prompts:  34%|      | 44/128 [00:00<00:01, 71.86it/s, est. speed input: 915.34 toks/s, output: 57.21 toks/s]
Processed prompts:  41%|     | 53/128 [00:00<00:00, 76.75it/s, est. speed input: 973.03 toks/s, output: 60.81 toks/s]
Processed prompts:  48%|     | 62/128 [00:00<00:00, 79.90it/s, est. speed input: 1017.54 toks/s, output: 63.60 toks/s]
Processed prompts:  55%|    | 71/128 [00:01<00:00, 81.88it/s, est. speed input: 1052.74 toks/s, output: 65.79 toks/s]
Processed prompts:  62%|   | 80/128 [00:01<00:00, 83.58it/s, est. speed input: 1082.98 toks/s, output: 67.68 toks/s]
Processed prompts:  70%|   | 89/128 [00:01<00:00, 83.63it/s, est. speed input: 1104.38 toks/s, output: 69.02 toks/s]
Processed prompts:  77%|  | 98/128 [00:01<00:00, 84.31it/s, est. speed input: 1124.68 toks/s, output: 70.29 toks/s]
Processed prompts:  84%| | 107/128 [00:01<00:00, 85.25it/s, est. speed input: 1143.56 toks/s, output: 71.47 toks/s]
Processed prompts:  91%| | 116/128 [00:01<00:00, 86.19it/s, est. speed input: 1160.82 toks/s, output: 72.55 toks/s]
Processed prompts:  98%|| 125/128 [00:01<00:00, 86.30it/s, est. speed input: 1174.51 toks/s, output: 73.41 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 86.30it/s, est. speed input: 1179.69 toks/s, output: 73.73 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 73.72it/s, est. speed input: 1179.69 toks/s, output: 73.73 toks/s]
[rank0]:[W126 02:30:13.538338572 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 02:30:15
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M128.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:30:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:30:19 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=745246) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=745246) WARNING 01-26 02:30:41 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 64.66 requests/s, 8341.72 total tokens/s, 64.66 output tokens/s
Total num prompt tokens:  16384
Total num output tokens:  128

STDERR:
[2026-01-26 02:30:19] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:30:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 02:30:19] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 02:30:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 02:30:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:30:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:30:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:30:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:30:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:30:22] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:30:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 02:30:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 02:30:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 02:30:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:30:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:30:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:30:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:30:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=745246) [2026-01-26 02:30:23] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=745246) [2026-01-26 02:30:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=745246) [2026-01-26 02:30:23] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=745246) [2026-01-26 02:30:23] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=745246) [2026-01-26 02:30:23] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=745246) [2026-01-26 02:30:23] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=745246) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=745246) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.66s/it]
(EngineCore_DP0 pid=745246) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.66s/it]
(EngineCore_DP0 pid=745246) 
(EngineCore_DP0 pid=745246) [2026-01-26 02:30:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=745246) [2026-01-26 02:30:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=745246) [2026-01-26 02:30:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=745246) [2026-01-26 02:30:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=745246) [2026-01-26 02:30:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=745246) [2026-01-26 02:30:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=745246) [2026-01-26 02:30:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=745246) [2026-01-26 02:30:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=745246) 2026-01-26 02:30:41,050 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=745246) 2026-01-26 02:30:41,057 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 3598.43it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:28,  4.48it/s, est. speed input: 573.14 toks/s, output: 4.48 toks/s]
Processed prompts:   7%|         | 9/128 [00:00<00:03, 32.58it/s, est. speed input: 3448.89 toks/s, output: 26.94 toks/s]
Processed prompts:  13%|        | 17/128 [00:00<00:02, 48.04it/s, est. speed input: 4940.96 toks/s, output: 38.60 toks/s]
Processed prompts:  20%|        | 25/128 [00:00<00:01, 57.03it/s, est. speed input: 5836.21 toks/s, output: 45.59 toks/s]
Processed prompts:  25%|       | 32/128 [00:00<00:01, 59.65it/s, est. speed input: 6243.48 toks/s, output: 48.78 toks/s]
Processed prompts:  30%|       | 39/128 [00:00<00:01, 60.03it/s, est. speed input: 6472.91 toks/s, output: 50.57 toks/s]
Processed prompts:  37%|      | 47/128 [00:00<00:01, 64.80it/s, est. speed input: 6860.64 toks/s, output: 53.60 toks/s]
Processed prompts:  43%|     | 55/128 [00:00<00:01, 68.42it/s, est. speed input: 7176.45 toks/s, output: 56.06 toks/s]
Processed prompts:  49%|     | 63/128 [00:01<00:00, 70.95it/s, est. speed input: 7431.55 toks/s, output: 58.06 toks/s]
Processed prompts:  55%|    | 71/128 [00:01<00:00, 72.53it/s, est. speed input: 7636.10 toks/s, output: 59.66 toks/s]
Processed prompts:  62%|   | 79/128 [00:01<00:00, 73.81it/s, est. speed input: 7812.61 toks/s, output: 61.04 toks/s]
Processed prompts:  68%|   | 87/128 [00:01<00:00, 73.34it/s, est. speed input: 7926.28 toks/s, output: 61.92 toks/s]
Processed prompts:  74%|  | 95/128 [00:01<00:00, 73.73it/s, est. speed input: 8041.70 toks/s, output: 62.83 toks/s]
Processed prompts:  80%|  | 103/128 [00:01<00:00, 74.67it/s, est. speed input: 8157.74 toks/s, output: 63.73 toks/s]
Processed prompts:  87%| | 111/128 [00:01<00:00, 75.28it/s, est. speed input: 8258.56 toks/s, output: 64.52 toks/s]
Processed prompts:  93%|| 119/128 [00:01<00:00, 75.52it/s, est. speed input: 8343.87 toks/s, output: 65.19 toks/s]
Processed prompts:  99%|| 127/128 [00:01<00:00, 75.81it/s, est. speed input: 8422.13 toks/s, output: 65.80 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 75.81it/s, est. speed input: 8432.38 toks/s, output: 65.88 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 65.87it/s, est. speed input: 8432.38 toks/s, output: 65.88 toks/s]
[rank0]:[W126 02:30:43.943537859 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 02:30:45
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M256.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:30:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:30:49 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=745854) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=745854) WARNING 01-26 02:31:11 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 57.14 requests/s, 14685.97 total tokens/s, 57.14 output tokens/s
Total num prompt tokens:  32768
Total num output tokens:  128

STDERR:
[2026-01-26 02:30:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:30:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 02:30:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 02:30:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 02:30:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:30:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:30:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:30:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:30:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:30:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:30:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 02:30:52] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 02:30:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:30:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 02:30:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:30:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:30:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:30:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:30:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=745854) [2026-01-26 02:30:53] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=745854) [2026-01-26 02:30:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=745854) [2026-01-26 02:30:53] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=745854) [2026-01-26 02:30:53] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=745854) [2026-01-26 02:30:53] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=745854) [2026-01-26 02:30:53] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=745854) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=745854) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.91s/it]
(EngineCore_DP0 pid=745854) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.91s/it]
(EngineCore_DP0 pid=745854) 
(EngineCore_DP0 pid=745854) [2026-01-26 02:31:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=745854) [2026-01-26 02:31:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=745854) [2026-01-26 02:31:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=745854) [2026-01-26 02:31:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=745854) [2026-01-26 02:31:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=745854) [2026-01-26 02:31:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=745854) [2026-01-26 02:31:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=745854) [2026-01-26 02:31:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=745854) 2026-01-26 02:31:10,662 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=745854) 2026-01-26 02:31:10,669 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 2380.00it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:25,  4.92it/s, est. speed input: 1259.22 toks/s, output: 4.92 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:03, 30.65it/s, est. speed input: 6559.97 toks/s, output: 25.62 toks/s]
Processed prompts:  12%|        | 15/128 [00:00<00:02, 43.80it/s, est. speed input: 9159.58 toks/s, output: 35.78 toks/s]
Processed prompts:  16%|        | 21/128 [00:00<00:02, 48.93it/s, est. speed input: 10317.11 toks/s, output: 40.30 toks/s]
Processed prompts:  21%|        | 27/128 [00:00<00:01, 52.30it/s, est. speed input: 11107.52 toks/s, output: 43.39 toks/s]
Processed prompts:  27%|       | 34/128 [00:00<00:01, 56.43it/s, est. speed input: 11916.64 toks/s, output: 46.55 toks/s]
Processed prompts:  32%|      | 41/128 [00:00<00:01, 59.02it/s, est. speed input: 12510.44 toks/s, output: 48.87 toks/s]
Processed prompts:  38%|      | 48/128 [00:00<00:01, 61.11it/s, est. speed input: 12996.68 toks/s, output: 50.77 toks/s]
Processed prompts:  43%|     | 55/128 [00:01<00:01, 61.84it/s, est. speed input: 13335.27 toks/s, output: 52.09 toks/s]
Processed prompts:  48%|     | 62/128 [00:01<00:01, 62.73it/s, est. speed input: 13636.65 toks/s, output: 53.27 toks/s]
Processed prompts:  54%|    | 69/128 [00:01<00:00, 63.12it/s, est. speed input: 13872.54 toks/s, output: 54.19 toks/s]
Processed prompts:  59%|    | 76/128 [00:01<00:00, 63.79it/s, est. speed input: 14094.40 toks/s, output: 55.06 toks/s]
Processed prompts:  65%|   | 83/128 [00:01<00:00, 63.91it/s, est. speed input: 14265.27 toks/s, output: 55.72 toks/s]
Processed prompts:  70%|   | 90/128 [00:01<00:00, 64.62it/s, est. speed input: 14444.54 toks/s, output: 56.42 toks/s]
Processed prompts:  76%|  | 97/128 [00:01<00:00, 65.31it/s, est. speed input: 14610.48 toks/s, output: 57.07 toks/s]
Processed prompts:  81%| | 104/128 [00:01<00:00, 65.28it/s, est. speed input: 14734.08 toks/s, output: 57.55 toks/s]
Processed prompts:  87%| | 111/128 [00:01<00:00, 65.12it/s, est. speed input: 14838.18 toks/s, output: 57.96 toks/s]
Processed prompts:  92%|| 118/128 [00:02<00:00, 64.53it/s, est. speed input: 14911.45 toks/s, output: 58.25 toks/s]
Processed prompts:  98%|| 125/128 [00:02<00:00, 63.81it/s, est. speed input: 14964.62 toks/s, output: 58.46 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 63.81it/s, est. speed input: 14995.12 toks/s, output: 58.57 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 58.57it/s, est. speed input: 14995.12 toks/s, output: 58.57 toks/s]
[rank0]:[W126 02:31:13.834414162 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 03:39:51
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:39:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:39:55 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=814655) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=814655) WARNING 01-26 03:40:16 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 46.01 requests/s, 23603.49 total tokens/s, 46.01 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 03:39:55] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:39:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:39:55] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:39:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:39:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:39:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:39:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:39:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:39:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:39:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:39:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:39:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:39:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:39:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:39:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:39:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:39:58] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:39:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:39:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:39:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:39:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:39:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:39:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:39:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:39:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:39:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:39:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:39:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=814655) [2026-01-26 03:39:59] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=814655) [2026-01-26 03:39:59] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=814655) [2026-01-26 03:39:59] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=814655) [2026-01-26 03:39:59] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=814655) [2026-01-26 03:39:59] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=814655) [2026-01-26 03:39:59] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=814655) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=814655) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.76s/it]
(EngineCore_DP0 pid=814655) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.76s/it]
(EngineCore_DP0 pid=814655) 
(EngineCore_DP0 pid=814655) [2026-01-26 03:40:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=814655) [2026-01-26 03:40:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=814655) [2026-01-26 03:40:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=814655) [2026-01-26 03:40:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=814655) [2026-01-26 03:40:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=814655) [2026-01-26 03:40:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=814655) [2026-01-26 03:40:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=814655) [2026-01-26 03:40:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=814655) 2026-01-26 03:40:16,400 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=814655) 2026-01-26 03:40:16,406 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  98%|| 125/128 [00:00<00:00, 1240.71it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1239.54it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 6/128 [00:00<00:02, 55.80it/s, est. speed input: 28573.56 toks/s, output: 55.80 toks/s]
Processed prompts:   9%|         | 12/128 [00:00<00:02, 50.42it/s, est. speed input: 26199.10 toks/s, output: 51.17 toks/s]
Processed prompts:  14%|        | 18/128 [00:00<00:02, 49.70it/s, est. speed input: 25794.88 toks/s, output: 50.38 toks/s]
Processed prompts:  18%|        | 23/128 [00:00<00:02, 44.88it/s, est. speed input: 24101.07 toks/s, output: 47.07 toks/s]
Processed prompts:  22%|       | 28/128 [00:00<00:02, 42.75it/s, est. speed input: 23250.31 toks/s, output: 45.41 toks/s]
Processed prompts:  26%|       | 33/128 [00:00<00:02, 44.23it/s, est. speed input: 23420.81 toks/s, output: 45.74 toks/s]
Processed prompts:  30%|       | 38/128 [00:00<00:02, 44.74it/s, est. speed input: 23429.15 toks/s, output: 45.76 toks/s]
Processed prompts:  34%|      | 43/128 [00:00<00:01, 45.90it/s, est. speed input: 23596.06 toks/s, output: 46.08 toks/s]
Processed prompts:  38%|      | 48/128 [00:01<00:01, 46.61it/s, est. speed input: 23708.44 toks/s, output: 46.30 toks/s]
Processed prompts:  41%|     | 53/128 [00:01<00:01, 47.19it/s, est. speed input: 23812.36 toks/s, output: 46.51 toks/s]
Processed prompts:  45%|     | 58/128 [00:01<00:01, 47.78it/s, est. speed input: 23924.73 toks/s, output: 46.73 toks/s]
Processed prompts:  49%|     | 63/128 [00:01<00:01, 48.10it/s, est. speed input: 24008.03 toks/s, output: 46.89 toks/s]
Processed prompts:  53%|    | 68/128 [00:01<00:01, 48.37it/s, est. speed input: 24083.85 toks/s, output: 47.04 toks/s]
Processed prompts:  57%|    | 73/128 [00:01<00:01, 48.55it/s, est. speed input: 24149.40 toks/s, output: 47.17 toks/s]
Processed prompts:  61%|    | 78/128 [00:01<00:01, 48.91it/s, est. speed input: 24230.67 toks/s, output: 47.32 toks/s]
Processed prompts:  65%|   | 83/128 [00:01<00:00, 48.64it/s, est. speed input: 24252.16 toks/s, output: 47.37 toks/s]
Processed prompts:  69%|   | 88/128 [00:01<00:00, 47.79it/s, est. speed input: 24208.61 toks/s, output: 47.28 toks/s]
Processed prompts:  73%|  | 93/128 [00:01<00:00, 48.08it/s, est. speed input: 24248.23 toks/s, output: 47.36 toks/s]
Processed prompts:  77%|  | 98/128 [00:02<00:00, 48.31it/s, est. speed input: 24286.22 toks/s, output: 47.43 toks/s]
Processed prompts:  80%|  | 103/128 [00:02<00:00, 48.54it/s, est. speed input: 24326.20 toks/s, output: 47.51 toks/s]
Processed prompts:  84%| | 108/128 [00:02<00:00, 48.66it/s, est. speed input: 24359.05 toks/s, output: 47.58 toks/s]
Processed prompts:  88%| | 113/128 [00:02<00:00, 48.89it/s, est. speed input: 24399.80 toks/s, output: 47.66 toks/s]
Processed prompts:  92%|| 118/128 [00:02<00:00, 49.03it/s, est. speed input: 24435.32 toks/s, output: 47.72 toks/s]
Processed prompts:  96%|| 123/128 [00:02<00:00, 48.86it/s, est. speed input: 24450.48 toks/s, output: 47.75 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 48.89it/s, est. speed input: 24474.06 toks/s, output: 47.80 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 48.89it/s, est. speed input: 24474.06 toks/s, output: 47.80 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 47.80it/s, est. speed input: 24474.06 toks/s, output: 47.80 toks/s]
[rank0]:[W126 03:40:19.135449244 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 03:40:22
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:40:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:40:26 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=815269) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=815269) WARNING 01-26 03:40:47 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 25.41 requests/s, 26046.33 total tokens/s, 25.41 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 03:40:25] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:40:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:40:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:40:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:40:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:40:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:40:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:40:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:40:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:40:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:40:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:40:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:40:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:40:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:40:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:40:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:40:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:40:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:40:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:40:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:40:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:40:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:40:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:40:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:40:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:40:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:40:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:40:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=815269) [2026-01-26 03:40:30] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=815269) [2026-01-26 03:40:30] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=815269) [2026-01-26 03:40:30] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=815269) [2026-01-26 03:40:30] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=815269) [2026-01-26 03:40:30] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=815269) [2026-01-26 03:40:30] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=815269) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=815269) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.68s/it]
(EngineCore_DP0 pid=815269) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.68s/it]
(EngineCore_DP0 pid=815269) 
(EngineCore_DP0 pid=815269) [2026-01-26 03:40:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=815269) [2026-01-26 03:40:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=815269) [2026-01-26 03:40:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=815269) [2026-01-26 03:40:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=815269) [2026-01-26 03:40:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=815269) [2026-01-26 03:40:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=815269) [2026-01-26 03:40:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=815269) [2026-01-26 03:40:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=815269) 2026-01-26 03:40:46,985 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=815269) 2026-01-26 03:40:46,991 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  50%|     | 64/128 [00:00<00:00, 633.07it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 599.19it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 603.01it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:02, 53.83it/s, est. speed input: 55132.85 toks/s, output: 53.84 toks/s]
Processed prompts:  10%|         | 13/128 [00:00<00:03, 33.79it/s, est. speed input: 36821.81 toks/s, output: 35.96 toks/s]
Processed prompts:  13%|        | 17/128 [00:00<00:03, 30.85it/s, est. speed input: 33948.02 toks/s, output: 33.15 toks/s]
Processed prompts:  16%|        | 21/128 [00:00<00:03, 29.21it/s, est. speed input: 32359.23 toks/s, output: 31.60 toks/s]
Processed prompts:  20%|        | 25/128 [00:00<00:03, 28.12it/s, est. speed input: 31292.52 toks/s, output: 30.56 toks/s]
Processed prompts:  22%|       | 28/128 [00:00<00:03, 27.57it/s, est. speed input: 30728.92 toks/s, output: 30.01 toks/s]
Processed prompts:  24%|       | 31/128 [00:01<00:03, 27.13it/s, est. speed input: 30278.29 toks/s, output: 29.57 toks/s]
Processed prompts:  27%|       | 34/128 [00:01<00:03, 26.92it/s, est. speed input: 29957.63 toks/s, output: 29.26 toks/s]
Processed prompts:  29%|       | 37/128 [00:01<00:03, 26.76it/s, est. speed input: 29694.19 toks/s, output: 29.00 toks/s]
Processed prompts:  31%|      | 40/128 [00:01<00:03, 26.25it/s, est. speed input: 29349.15 toks/s, output: 28.66 toks/s]
Processed prompts:  34%|      | 43/128 [00:01<00:03, 26.23it/s, est. speed input: 29156.47 toks/s, output: 28.47 toks/s]
Processed prompts:  36%|      | 46/128 [00:01<00:03, 26.46it/s, est. speed input: 29056.18 toks/s, output: 28.37 toks/s]
Processed prompts:  38%|      | 49/128 [00:01<00:02, 26.63it/s, est. speed input: 28968.01 toks/s, output: 28.29 toks/s]
Processed prompts:  41%|      | 52/128 [00:01<00:02, 26.55it/s, est. speed input: 28848.08 toks/s, output: 28.17 toks/s]
Processed prompts:  43%|     | 55/128 [00:01<00:02, 26.66it/s, est. speed input: 28773.25 toks/s, output: 28.10 toks/s]
Processed prompts:  45%|     | 58/128 [00:02<00:02, 26.62it/s, est. speed input: 28684.89 toks/s, output: 28.01 toks/s]
Processed prompts:  48%|     | 61/128 [00:02<00:02, 26.81it/s, est. speed input: 28646.49 toks/s, output: 27.97 toks/s]
Processed prompts:  50%|     | 64/128 [00:02<00:02, 26.39it/s, est. speed input: 28513.80 toks/s, output: 27.85 toks/s]
Processed prompts:  52%|    | 67/128 [00:02<00:02, 23.00it/s, est. speed input: 27799.58 toks/s, output: 27.15 toks/s]
Processed prompts:  55%|    | 70/128 [00:02<00:02, 21.40it/s, est. speed input: 27245.20 toks/s, output: 26.61 toks/s]
Processed prompts:  57%|    | 73/128 [00:02<00:02, 22.80it/s, est. speed input: 27257.64 toks/s, output: 26.62 toks/s]
Processed prompts:  59%|    | 76/128 [00:02<00:02, 23.86it/s, est. speed input: 27264.04 toks/s, output: 26.62 toks/s]
Processed prompts:  62%|   | 79/128 [00:02<00:02, 24.47it/s, est. speed input: 27240.59 toks/s, output: 26.60 toks/s]
Processed prompts:  64%|   | 82/128 [00:03<00:01, 25.09it/s, est. speed input: 27242.06 toks/s, output: 26.60 toks/s]
Processed prompts:  66%|   | 85/128 [00:03<00:01, 25.57it/s, est. speed input: 27248.06 toks/s, output: 26.61 toks/s]
Processed prompts:  69%|   | 88/128 [00:03<00:01, 25.80it/s, est. speed input: 27239.23 toks/s, output: 26.60 toks/s]
Processed prompts:  71%|   | 91/128 [00:03<00:01, 25.77it/s, est. speed input: 27207.50 toks/s, output: 26.57 toks/s]
Processed prompts:  73%|  | 94/128 [00:03<00:01, 25.65it/s, est. speed input: 27166.54 toks/s, output: 26.53 toks/s]
Processed prompts:  76%|  | 97/128 [00:03<00:01, 25.95it/s, est. speed input: 27171.78 toks/s, output: 26.53 toks/s]
Processed prompts:  78%|  | 100/128 [00:03<00:01, 26.15it/s, est. speed input: 27174.10 toks/s, output: 26.54 toks/s]
Processed prompts:  80%|  | 103/128 [00:03<00:00, 26.31it/s, est. speed input: 27178.85 toks/s, output: 26.54 toks/s]
Processed prompts:  83%| | 106/128 [00:03<00:00, 26.44it/s, est. speed input: 27184.69 toks/s, output: 26.55 toks/s]
Processed prompts:  85%| | 109/128 [00:04<00:00, 26.62it/s, est. speed input: 27198.56 toks/s, output: 26.56 toks/s]
Processed prompts:  88%| | 112/128 [00:04<00:00, 26.46it/s, est. speed input: 27185.43 toks/s, output: 26.55 toks/s]
Processed prompts:  90%| | 115/128 [00:04<00:00, 26.65it/s, est. speed input: 27199.71 toks/s, output: 26.56 toks/s]
Processed prompts:  92%|| 118/128 [00:04<00:00, 26.69it/s, est. speed input: 27205.34 toks/s, output: 26.57 toks/s]
Processed prompts:  95%|| 121/128 [00:04<00:00, 26.25it/s, est. speed input: 27170.97 toks/s, output: 26.53 toks/s]
Processed prompts:  97%|| 124/128 [00:04<00:00, 26.34it/s, est. speed input: 27171.27 toks/s, output: 26.53 toks/s]
Processed prompts:  99%|| 127/128 [00:04<00:00, 26.39it/s, est. speed input: 27170.98 toks/s, output: 26.53 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 26.39it/s, est. speed input: 27170.98 toks/s, output: 26.53 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 26.53it/s, est. speed input: 27170.98 toks/s, output: 26.53 toks/s]
[rank0]:[W126 03:40:52.970035709 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 03:40:55
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:40:59 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:40:59 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=815934) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=815934) WARNING 01-26 03:41:20 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 26.69 requests/s, 27362.36 total tokens/s, 26.69 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 03:40:59] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:40:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:40:59] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:40:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:40:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:40:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:40:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:40:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:40:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:40:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:40:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:40:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:40:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:40:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:41:02] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:41:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:41:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:41:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:41:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:41:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:41:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:41:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:41:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:41:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:41:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:41:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:41:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:41:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=815934) [2026-01-26 03:41:03] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=815934) [2026-01-26 03:41:03] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=815934) [2026-01-26 03:41:03] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=815934) [2026-01-26 03:41:03] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=815934) [2026-01-26 03:41:03] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=815934) [2026-01-26 03:41:03] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=815934) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=815934) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.63s/it]
(EngineCore_DP0 pid=815934) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.63s/it]
(EngineCore_DP0 pid=815934) 
(EngineCore_DP0 pid=815934) [2026-01-26 03:41:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=815934) [2026-01-26 03:41:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=815934) [2026-01-26 03:41:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=815934) [2026-01-26 03:41:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=815934) [2026-01-26 03:41:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=815934) [2026-01-26 03:41:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=815934) [2026-01-26 03:41:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=815934) [2026-01-26 03:41:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=815934) 2026-01-26 03:41:20,079 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=815934) 2026-01-26 03:41:20,086 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  16%|        | 42/256 [00:00<00:00, 418.75it/s]
Adding requests:  40%|      | 102/256 [00:00<00:00, 524.86it/s]
Adding requests:  62%|   | 158/256 [00:00<00:00, 538.86it/s]
Adding requests:  83%| | 212/256 [00:00<00:00, 535.08it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 533.88it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 12/256 [00:00<00:02, 101.52it/s, est. speed input: 103968.14 toks/s, output: 101.52 toks/s]
Processed prompts:   9%|         | 23/256 [00:00<00:05, 43.59it/s, est. speed input: 49017.34 toks/s, output: 47.87 toks/s]   
Processed prompts:  11%|        | 29/256 [00:00<00:06, 36.78it/s, est. speed input: 42345.26 toks/s, output: 41.35 toks/s]
Processed prompts:  13%|        | 34/256 [00:00<00:06, 31.80it/s, est. speed input: 37971.22 toks/s, output: 37.08 toks/s]
Processed prompts:  15%|        | 38/256 [00:01<00:07, 30.75it/s, est. speed input: 36673.02 toks/s, output: 35.81 toks/s]
Processed prompts:  16%|        | 42/256 [00:01<00:07, 29.85it/s, est. speed input: 35641.19 toks/s, output: 34.81 toks/s]
Processed prompts:  18%|        | 46/256 [00:01<00:07, 28.92it/s, est. speed input: 34710.29 toks/s, output: 33.90 toks/s]
Processed prompts:  20%|        | 50/256 [00:01<00:07, 28.76it/s, est. speed input: 34173.50 toks/s, output: 33.37 toks/s]
Processed prompts:  21%|        | 54/256 [00:01<00:07, 28.38it/s, est. speed input: 33635.92 toks/s, output: 32.85 toks/s]
Processed prompts:  23%|       | 58/256 [00:01<00:07, 24.82it/s, est. speed input: 32008.08 toks/s, output: 31.26 toks/s]
Processed prompts:  24%|       | 61/256 [00:01<00:07, 24.69it/s, est. speed input: 31562.43 toks/s, output: 30.82 toks/s]
Processed prompts:  25%|       | 64/256 [00:02<00:09, 20.41it/s, est. speed input: 29763.93 toks/s, output: 29.07 toks/s]
Processed prompts:  27%|       | 68/256 [00:02<00:08, 22.03it/s, est. speed input: 29586.56 toks/s, output: 28.89 toks/s]
Processed prompts:  28%|       | 72/256 [00:02<00:07, 23.70it/s, est. speed input: 29554.67 toks/s, output: 28.86 toks/s]
Processed prompts:  30%|       | 76/256 [00:02<00:07, 24.74it/s, est. speed input: 29471.85 toks/s, output: 28.78 toks/s]
Processed prompts:  31%|      | 80/256 [00:02<00:06, 25.56it/s, est. speed input: 29411.35 toks/s, output: 28.72 toks/s]
Processed prompts:  33%|      | 84/256 [00:02<00:06, 26.21it/s, est. speed input: 29366.15 toks/s, output: 28.68 toks/s]
Processed prompts:  34%|      | 88/256 [00:03<00:06, 26.69it/s, est. speed input: 29326.63 toks/s, output: 28.64 toks/s]
Processed prompts:  36%|      | 92/256 [00:03<00:06, 26.96it/s, est. speed input: 29278.42 toks/s, output: 28.59 toks/s]
Processed prompts:  38%|      | 96/256 [00:03<00:05, 27.09it/s, est. speed input: 29225.38 toks/s, output: 28.54 toks/s]
Processed prompts:  39%|      | 100/256 [00:03<00:05, 27.27it/s, est. speed input: 29189.87 toks/s, output: 28.51 toks/s]
Processed prompts:  41%|      | 104/256 [00:03<00:05, 27.52it/s, est. speed input: 29174.76 toks/s, output: 28.49 toks/s]
Processed prompts:  42%|     | 108/256 [00:03<00:05, 27.61it/s, est. speed input: 29149.13 toks/s, output: 28.47 toks/s]
Processed prompts:  44%|     | 112/256 [00:03<00:05, 27.70it/s, est. speed input: 29127.69 toks/s, output: 28.44 toks/s]
Processed prompts:  45%|     | 116/256 [00:04<00:05, 27.67it/s, est. speed input: 29097.80 toks/s, output: 28.42 toks/s]
Processed prompts:  47%|     | 120/256 [00:04<00:04, 27.59it/s, est. speed input: 29061.89 toks/s, output: 28.38 toks/s]
Processed prompts:  48%|     | 124/256 [00:04<00:04, 27.59it/s, est. speed input: 29034.38 toks/s, output: 28.35 toks/s]
Processed prompts:  50%|     | 128/256 [00:04<00:04, 27.38it/s, est. speed input: 28985.36 toks/s, output: 28.31 toks/s]
Processed prompts:  52%|    | 132/256 [00:04<00:04, 27.47it/s, est. speed input: 28966.12 toks/s, output: 28.29 toks/s]
Processed prompts:  53%|    | 136/256 [00:04<00:04, 27.50it/s, est. speed input: 28943.41 toks/s, output: 28.26 toks/s]
Processed prompts:  55%|    | 140/256 [00:04<00:04, 27.63it/s, est. speed input: 28934.24 toks/s, output: 28.26 toks/s]
Processed prompts:  56%|    | 144/256 [00:05<00:04, 27.78it/s, est. speed input: 28930.53 toks/s, output: 28.25 toks/s]
Processed prompts:  58%|    | 148/256 [00:05<00:03, 27.81it/s, est. speed input: 28920.22 toks/s, output: 28.24 toks/s]
Processed prompts:  59%|    | 152/256 [00:05<00:03, 27.97it/s, est. speed input: 28922.92 toks/s, output: 28.24 toks/s]
Processed prompts:  61%|    | 156/256 [00:05<00:03, 27.59it/s, est. speed input: 28881.43 toks/s, output: 28.20 toks/s]
Processed prompts:  62%|   | 160/256 [00:05<00:03, 27.71it/s, est. speed input: 28875.57 toks/s, output: 28.20 toks/s]
Processed prompts:  64%|   | 164/256 [00:05<00:03, 27.77it/s, est. speed input: 28868.65 toks/s, output: 28.19 toks/s]
Processed prompts:  66%|   | 168/256 [00:05<00:03, 27.86it/s, est. speed input: 28865.55 toks/s, output: 28.19 toks/s]
Processed prompts:  67%|   | 172/256 [00:06<00:03, 27.83it/s, est. speed input: 28855.05 toks/s, output: 28.18 toks/s]
Processed prompts:  69%|   | 176/256 [00:06<00:02, 27.71it/s, est. speed input: 28837.42 toks/s, output: 28.16 toks/s]
Processed prompts:  70%|   | 180/256 [00:06<00:02, 27.62it/s, est. speed input: 28819.90 toks/s, output: 28.14 toks/s]
Processed prompts:  72%|  | 184/256 [00:06<00:02, 27.43it/s, est. speed input: 28792.91 toks/s, output: 28.12 toks/s]
Processed prompts:  73%|  | 188/256 [00:06<00:02, 27.54it/s, est. speed input: 28785.84 toks/s, output: 28.11 toks/s]
Processed prompts:  75%|  | 192/256 [00:06<00:02, 27.47it/s, est. speed input: 28768.32 toks/s, output: 28.09 toks/s]
Processed prompts:  77%|  | 196/256 [00:06<00:02, 27.53it/s, est. speed input: 28759.28 toks/s, output: 28.09 toks/s]
Processed prompts:  78%|  | 200/256 [00:07<00:02, 27.59it/s, est. speed input: 28751.78 toks/s, output: 28.08 toks/s]
Processed prompts:  80%|  | 204/256 [00:07<00:01, 27.63it/s, est. speed input: 28744.66 toks/s, output: 28.07 toks/s]
Processed prompts:  81%| | 208/256 [00:07<00:01, 27.74it/s, est. speed input: 28743.11 toks/s, output: 28.07 toks/s]
Processed prompts:  83%| | 212/256 [00:07<00:01, 27.37it/s, est. speed input: 28712.03 toks/s, output: 28.04 toks/s]
Processed prompts:  84%| | 216/256 [00:07<00:01, 27.46it/s, est. speed input: 28705.07 toks/s, output: 28.03 toks/s]
Processed prompts:  86%| | 220/256 [00:07<00:01, 27.57it/s, est. speed input: 28701.02 toks/s, output: 28.03 toks/s]
Processed prompts:  88%| | 224/256 [00:07<00:01, 27.81it/s, est. speed input: 28707.63 toks/s, output: 28.03 toks/s]
Processed prompts:  89%| | 228/256 [00:08<00:01, 27.81it/s, est. speed input: 28703.38 toks/s, output: 28.03 toks/s]
Processed prompts:  91%| | 232/256 [00:08<00:00, 27.85it/s, est. speed input: 28701.86 toks/s, output: 28.03 toks/s]
Processed prompts:  92%|| 236/256 [00:08<00:00, 27.82it/s, est. speed input: 28696.94 toks/s, output: 28.02 toks/s]
Processed prompts:  94%|| 240/256 [00:08<00:00, 27.96it/s, est. speed input: 28701.27 toks/s, output: 28.03 toks/s]
Processed prompts:  95%|| 244/256 [00:08<00:00, 27.53it/s, est. speed input: 28675.62 toks/s, output: 28.00 toks/s]
Processed prompts:  97%|| 248/256 [00:08<00:00, 27.71it/s, est. speed input: 28677.80 toks/s, output: 28.01 toks/s]
Processed prompts:  98%|| 252/256 [00:08<00:00, 27.88it/s, est. speed input: 28682.37 toks/s, output: 28.01 toks/s]
Processed prompts: 100%|| 256/256 [00:09<00:00, 29.84it/s, est. speed input: 28779.18 toks/s, output: 28.10 toks/s]
Processed prompts: 100%|| 256/256 [00:09<00:00, 29.84it/s, est. speed input: 28779.18 toks/s, output: 28.10 toks/s]
Processed prompts: 100%|| 256/256 [00:09<00:00, 28.10it/s, est. speed input: 28779.18 toks/s, output: 28.10 toks/s]
[rank0]:[W126 03:41:30.642577186 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 03:41:32
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:41:37 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:41:37 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=816668) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=816668) WARNING 01-26 03:41:59 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 26.67 requests/s, 27335.65 total tokens/s, 26.67 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 03:41:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:41:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:41:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:41:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:41:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:41:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:41:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:41:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:41:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:41:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:41:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:41:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:41:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:41:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:41:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:41:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:41:40] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:41:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:41:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:41:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:41:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:41:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:41:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:41:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:41:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:41:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:41:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:41:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=816668) [2026-01-26 03:41:41] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=816668) [2026-01-26 03:41:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=816668) [2026-01-26 03:41:41] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=816668) [2026-01-26 03:41:41] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=816668) [2026-01-26 03:41:41] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=816668) [2026-01-26 03:41:41] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=816668) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=816668) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.78s/it]
(EngineCore_DP0 pid=816668) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.79s/it]
(EngineCore_DP0 pid=816668) 
(EngineCore_DP0 pid=816668) [2026-01-26 03:41:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=816668) [2026-01-26 03:41:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=816668) [2026-01-26 03:41:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=816668) [2026-01-26 03:41:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=816668) [2026-01-26 03:41:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=816668) [2026-01-26 03:41:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=816668) [2026-01-26 03:41:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=816668) [2026-01-26 03:41:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=816668) 2026-01-26 03:41:58,523 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=816668) 2026-01-26 03:41:58,530 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  12%|        | 63/512 [00:00<00:00, 618.08it/s]
Adding requests:  24%|       | 125/512 [00:00<00:00, 603.92it/s]
Adding requests:  36%|      | 186/512 [00:00<00:00, 581.23it/s]
Adding requests:  48%|     | 245/512 [00:00<00:00, 571.85it/s]
Adding requests:  59%|    | 303/512 [00:00<00:00, 558.60it/s]
Adding requests:  71%|   | 361/512 [00:00<00:00, 565.35it/s]
Adding requests:  82%| | 418/512 [00:00<00:00, 560.67it/s]
Adding requests:  93%|| 475/512 [00:00<00:00, 556.14it/s]
Adding requests: 100%|| 512/512 [00:00<00:00, 564.02it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|         | 22/512 [00:00<00:03, 142.33it/s, est. speed input: 145761.01 toks/s, output: 142.33 toks/s]
Processed prompts:   7%|         | 37/512 [00:00<00:08, 55.15it/s, est. speed input: 63396.75 toks/s, output: 61.91 toks/s]   
Processed prompts:   9%|         | 45/512 [00:00<00:10, 42.80it/s, est. speed input: 51436.69 toks/s, output: 50.23 toks/s]
Processed prompts:  10%|         | 51/512 [00:01<00:13, 33.93it/s, est. speed input: 43597.95 toks/s, output: 42.58 toks/s]
Processed prompts:  11%|         | 56/512 [00:01<00:13, 33.90it/s, est. speed input: 42610.70 toks/s, output: 41.61 toks/s]
Processed prompts:  12%|        | 60/512 [00:01<00:14, 32.28it/s, est. speed input: 41120.44 toks/s, output: 40.16 toks/s]
Processed prompts:  12%|        | 64/512 [00:01<00:14, 30.89it/s, est. speed input: 39874.11 toks/s, output: 38.94 toks/s]
Processed prompts:  13%|        | 68/512 [00:01<00:14, 29.78it/s, est. speed input: 38826.53 toks/s, output: 37.92 toks/s]
Processed prompts:  14%|        | 72/512 [00:01<00:15, 28.95it/s, est. speed input: 37946.08 toks/s, output: 37.06 toks/s]
Processed prompts:  15%|        | 75/512 [00:02<00:16, 26.26it/s, est. speed input: 36636.13 toks/s, output: 35.78 toks/s]
Processed prompts:  15%|        | 78/512 [00:02<00:17, 24.41it/s, est. speed input: 35535.59 toks/s, output: 34.70 toks/s]
Processed prompts:  16%|        | 82/512 [00:02<00:17, 25.18it/s, est. speed input: 35058.67 toks/s, output: 34.24 toks/s]
Processed prompts:  17%|        | 86/512 [00:02<00:16, 25.78it/s, est. speed input: 34645.47 toks/s, output: 33.83 toks/s]
Processed prompts:  18%|        | 90/512 [00:02<00:16, 26.02it/s, est. speed input: 34230.08 toks/s, output: 33.43 toks/s]
Processed prompts:  18%|        | 94/512 [00:02<00:15, 26.42it/s, est. speed input: 33912.10 toks/s, output: 33.12 toks/s]
Processed prompts:  19%|        | 98/512 [00:02<00:15, 26.55it/s, est. speed input: 33591.78 toks/s, output: 32.80 toks/s]
Processed prompts:  20%|        | 102/512 [00:03<00:15, 26.36it/s, est. speed input: 33246.91 toks/s, output: 32.47 toks/s]
Processed prompts:  21%|        | 106/512 [00:03<00:15, 26.50it/s, est. speed input: 32984.26 toks/s, output: 32.21 toks/s]
Processed prompts:  21%|       | 110/512 [00:03<00:14, 26.83it/s, est. speed input: 32787.26 toks/s, output: 32.02 toks/s]
Processed prompts:  22%|       | 114/512 [00:03<00:14, 26.96it/s, est. speed input: 32587.78 toks/s, output: 31.82 toks/s]
Processed prompts:  23%|       | 118/512 [00:03<00:14, 26.91it/s, est. speed input: 32381.51 toks/s, output: 31.62 toks/s]
Processed prompts:  24%|       | 122/512 [00:03<00:14, 26.98it/s, est. speed input: 32207.30 toks/s, output: 31.45 toks/s]
Processed prompts:  25%|       | 126/512 [00:04<00:14, 27.04it/s, est. speed input: 32047.00 toks/s, output: 31.30 toks/s]
Processed prompts:  25%|       | 130/512 [00:04<00:14, 26.57it/s, est. speed input: 31826.46 toks/s, output: 31.08 toks/s]
Processed prompts:  26%|       | 134/512 [00:04<00:14, 26.57it/s, est. speed input: 31665.39 toks/s, output: 30.92 toks/s]
Processed prompts:  27%|       | 138/512 [00:04<00:13, 26.76it/s, est. speed input: 31540.83 toks/s, output: 30.80 toks/s]
Processed prompts:  28%|       | 142/512 [00:04<00:13, 26.67it/s, est. speed input: 31396.61 toks/s, output: 30.66 toks/s]
Processed prompts:  29%|       | 146/512 [00:04<00:13, 26.67it/s, est. speed input: 31268.48 toks/s, output: 30.54 toks/s]
Processed prompts:  29%|       | 150/512 [00:04<00:13, 26.81it/s, est. speed input: 31163.92 toks/s, output: 30.43 toks/s]
Processed prompts:  30%|       | 154/512 [00:05<00:13, 26.81it/s, est. speed input: 31055.66 toks/s, output: 30.33 toks/s]
Processed prompts:  31%|       | 158/512 [00:05<00:13, 26.66it/s, est. speed input: 30936.08 toks/s, output: 30.21 toks/s]
Processed prompts:  32%|      | 162/512 [00:05<00:13, 26.67it/s, est. speed input: 30836.08 toks/s, output: 30.11 toks/s]
Processed prompts:  32%|      | 166/512 [00:05<00:12, 26.72it/s, est. speed input: 30745.78 toks/s, output: 30.03 toks/s]
Processed prompts:  33%|      | 170/512 [00:05<00:12, 26.70it/s, est. speed input: 30654.12 toks/s, output: 29.94 toks/s]
Processed prompts:  34%|      | 174/512 [00:05<00:12, 26.93it/s, est. speed input: 30591.59 toks/s, output: 29.87 toks/s]
Processed prompts:  35%|      | 178/512 [00:05<00:12, 27.12it/s, est. speed input: 30534.16 toks/s, output: 29.82 toks/s]
Processed prompts:  36%|      | 182/512 [00:06<00:12, 27.21it/s, est. speed input: 30475.79 toks/s, output: 29.76 toks/s]
Processed prompts:  36%|      | 186/512 [00:06<00:12, 26.95it/s, est. speed input: 30391.22 toks/s, output: 29.68 toks/s]
Processed prompts:  37%|      | 190/512 [00:06<00:12, 26.80it/s, est. speed input: 30313.42 toks/s, output: 29.60 toks/s]
Processed prompts:  38%|      | 194/512 [00:06<00:11, 26.89it/s, est. speed input: 30255.84 toks/s, output: 29.55 toks/s]
Processed prompts:  39%|      | 198/512 [00:06<00:11, 26.89it/s, est. speed input: 30195.78 toks/s, output: 29.49 toks/s]
Processed prompts:  39%|      | 202/512 [00:06<00:11, 26.85it/s, est. speed input: 30134.71 toks/s, output: 29.43 toks/s]
Processed prompts:  40%|      | 206/512 [00:07<00:11, 26.99it/s, est. speed input: 30089.42 toks/s, output: 29.38 toks/s]
Processed prompts:  41%|      | 210/512 [00:07<00:11, 26.96it/s, est. speed input: 30036.50 toks/s, output: 29.33 toks/s]
Processed prompts:  42%|     | 214/512 [00:07<00:11, 26.89it/s, est. speed input: 29982.04 toks/s, output: 29.28 toks/s]
Processed prompts:  43%|     | 218/512 [00:07<00:11, 26.58it/s, est. speed input: 29910.14 toks/s, output: 29.21 toks/s]
Processed prompts:  43%|     | 222/512 [00:07<00:10, 26.64it/s, est. speed input: 29860.88 toks/s, output: 29.16 toks/s]
Processed prompts:  44%|     | 226/512 [00:07<00:10, 26.75it/s, est. speed input: 29818.84 toks/s, output: 29.12 toks/s]
Processed prompts:  45%|     | 230/512 [00:07<00:10, 26.65it/s, est. speed input: 29766.25 toks/s, output: 29.07 toks/s]
Processed prompts:  46%|     | 234/512 [00:08<00:10, 26.75it/s, est. speed input: 29727.31 toks/s, output: 29.03 toks/s]
Processed prompts:  46%|     | 238/512 [00:08<00:10, 26.74it/s, est. speed input: 29683.93 toks/s, output: 28.99 toks/s]
Processed prompts:  47%|     | 242/512 [00:08<00:10, 26.75it/s, est. speed input: 29643.54 toks/s, output: 28.95 toks/s]
Processed prompts:  48%|     | 246/512 [00:08<00:10, 26.55it/s, est. speed input: 29590.62 toks/s, output: 28.90 toks/s]
Processed prompts:  49%|     | 250/512 [00:08<00:09, 26.65it/s, est. speed input: 29555.12 toks/s, output: 28.86 toks/s]
Processed prompts:  50%|     | 254/512 [00:08<00:09, 26.81it/s, est. speed input: 29526.95 toks/s, output: 28.83 toks/s]
Processed prompts:  50%|     | 258/512 [00:08<00:09, 26.76it/s, est. speed input: 29489.24 toks/s, output: 28.80 toks/s]
Processed prompts:  51%|     | 262/512 [00:09<00:09, 26.85it/s, est. speed input: 29460.37 toks/s, output: 28.77 toks/s]
Processed prompts:  52%|    | 266/512 [00:09<00:09, 26.84it/s, est. speed input: 29427.84 toks/s, output: 28.74 toks/s]
Processed prompts:  53%|    | 270/512 [00:09<00:09, 26.88it/s, est. speed input: 29399.19 toks/s, output: 28.71 toks/s]
Processed prompts:  54%|    | 274/512 [00:09<00:08, 26.61it/s, est. speed input: 29354.67 toks/s, output: 28.67 toks/s]
Processed prompts:  54%|    | 278/512 [00:09<00:08, 26.66it/s, est. speed input: 29324.70 toks/s, output: 28.64 toks/s]
Processed prompts:  55%|    | 282/512 [00:09<00:08, 26.72it/s, est. speed input: 29297.52 toks/s, output: 28.61 toks/s]
Processed prompts:  56%|    | 286/512 [00:10<00:08, 26.69it/s, est. speed input: 29266.93 toks/s, output: 28.58 toks/s]
Processed prompts:  57%|    | 290/512 [00:10<00:08, 26.68it/s, est. speed input: 29237.88 toks/s, output: 28.55 toks/s]
Processed prompts:  57%|    | 294/512 [00:10<00:08, 26.68it/s, est. speed input: 29209.82 toks/s, output: 28.53 toks/s]
Processed prompts:  58%|    | 298/512 [00:10<00:08, 26.71it/s, est. speed input: 29184.57 toks/s, output: 28.50 toks/s]
Processed prompts:  59%|    | 302/512 [00:10<00:07, 26.52it/s, est. speed input: 29148.45 toks/s, output: 28.47 toks/s]
Processed prompts:  60%|    | 306/512 [00:10<00:07, 26.64it/s, est. speed input: 29127.01 toks/s, output: 28.44 toks/s]
Processed prompts:  61%|    | 310/512 [00:10<00:07, 26.81it/s, est. speed input: 29110.13 toks/s, output: 28.43 toks/s]
Processed prompts:  61%|   | 314/512 [00:11<00:07, 26.83it/s, est. speed input: 29088.55 toks/s, output: 28.41 toks/s]
Processed prompts:  62%|   | 318/512 [00:11<00:07, 26.79it/s, est. speed input: 29064.98 toks/s, output: 28.38 toks/s]
Processed prompts:  63%|   | 322/512 [00:11<00:07, 26.97it/s, est. speed input: 29052.24 toks/s, output: 28.37 toks/s]
Processed prompts:  64%|   | 326/512 [00:11<00:06, 27.07it/s, est. speed input: 29038.32 toks/s, output: 28.36 toks/s]
Processed prompts:  64%|   | 330/512 [00:11<00:06, 26.69it/s, est. speed input: 29003.94 toks/s, output: 28.32 toks/s]
Processed prompts:  65%|   | 334/512 [00:11<00:06, 26.91it/s, est. speed input: 28992.60 toks/s, output: 28.31 toks/s]
Processed prompts:  66%|   | 338/512 [00:11<00:06, 27.00it/s, est. speed input: 28978.86 toks/s, output: 28.30 toks/s]
Processed prompts:  67%|   | 342/512 [00:12<00:06, 27.69it/s, est. speed input: 28992.09 toks/s, output: 28.31 toks/s]
Processed prompts:  68%|   | 346/512 [00:12<00:06, 27.59it/s, est. speed input: 28980.42 toks/s, output: 28.30 toks/s]
Processed prompts:  68%|   | 350/512 [00:12<00:05, 27.42it/s, est. speed input: 28964.73 toks/s, output: 28.29 toks/s]
Processed prompts:  69%|   | 354/512 [00:12<00:05, 27.36it/s, est. speed input: 28952.05 toks/s, output: 28.27 toks/s]
Processed prompts:  70%|   | 358/512 [00:12<00:05, 26.95it/s, est. speed input: 28924.50 toks/s, output: 28.25 toks/s]
Processed prompts:  71%|   | 362/512 [00:12<00:05, 26.90it/s, est. speed input: 28906.72 toks/s, output: 28.23 toks/s]
Processed prompts:  71%|  | 366/512 [00:12<00:05, 27.00it/s, est. speed input: 28895.30 toks/s, output: 28.22 toks/s]
Processed prompts:  72%|  | 370/512 [00:13<00:05, 27.07it/s, est. speed input: 28883.94 toks/s, output: 28.21 toks/s]
Processed prompts:  73%|  | 374/512 [00:13<00:05, 27.08it/s, est. speed input: 28871.33 toks/s, output: 28.19 toks/s]
Processed prompts:  74%|  | 378/512 [00:13<00:04, 27.08it/s, est. speed input: 28858.90 toks/s, output: 28.18 toks/s]
Processed prompts:  75%|  | 382/512 [00:13<00:04, 27.22it/s, est. speed input: 28851.92 toks/s, output: 28.18 toks/s]
Processed prompts:  75%|  | 386/512 [00:13<00:04, 26.68it/s, est. speed input: 28820.71 toks/s, output: 28.15 toks/s]
Processed prompts:  76%|  | 390/512 [00:13<00:04, 26.75it/s, est. speed input: 28807.02 toks/s, output: 28.13 toks/s]
Processed prompts:  77%|  | 394/512 [00:14<00:04, 26.79it/s, est. speed input: 28793.60 toks/s, output: 28.12 toks/s]
Processed prompts:  78%|  | 398/512 [00:14<00:04, 26.84it/s, est. speed input: 28781.01 toks/s, output: 28.11 toks/s]
Processed prompts:  79%|  | 402/512 [00:14<00:04, 26.89it/s, est. speed input: 28769.52 toks/s, output: 28.10 toks/s]
Processed prompts:  79%|  | 406/512 [00:14<00:03, 27.03it/s, est. speed input: 28761.84 toks/s, output: 28.09 toks/s]
Processed prompts:  80%|  | 410/512 [00:14<00:03, 26.89it/s, est. speed input: 28745.92 toks/s, output: 28.07 toks/s]
Processed prompts:  81%|  | 414/512 [00:14<00:03, 26.64it/s, est. speed input: 28724.51 toks/s, output: 28.05 toks/s]
Processed prompts:  82%| | 418/512 [00:14<00:03, 26.80it/s, est. speed input: 28715.84 toks/s, output: 28.04 toks/s]
Processed prompts:  82%| | 422/512 [00:15<00:03, 26.75it/s, est. speed input: 28701.37 toks/s, output: 28.03 toks/s]
Processed prompts:  83%| | 426/512 [00:15<00:03, 26.77it/s, est. speed input: 28689.35 toks/s, output: 28.02 toks/s]
Processed prompts:  84%| | 430/512 [00:15<00:03, 26.82it/s, est. speed input: 28678.62 toks/s, output: 28.01 toks/s]
Processed prompts:  85%| | 434/512 [00:15<00:02, 26.95it/s, est. speed input: 28671.32 toks/s, output: 28.00 toks/s]
Processed prompts:  86%| | 438/512 [00:15<00:02, 26.92it/s, est. speed input: 28660.11 toks/s, output: 27.99 toks/s]
Processed prompts:  86%| | 442/512 [00:15<00:02, 26.62it/s, est. speed input: 28639.72 toks/s, output: 27.97 toks/s]
Processed prompts:  87%| | 446/512 [00:15<00:02, 26.66it/s, est. speed input: 28628.19 toks/s, output: 27.96 toks/s]
Processed prompts:  88%| | 450/512 [00:16<00:02, 28.12it/s, est. speed input: 28661.86 toks/s, output: 27.99 toks/s]
Processed prompts:  89%| | 454/512 [00:16<00:02, 27.69it/s, est. speed input: 28650.19 toks/s, output: 27.98 toks/s]
Processed prompts:  89%| | 458/512 [00:16<00:01, 27.57it/s, est. speed input: 28643.98 toks/s, output: 27.97 toks/s]
Processed prompts:  90%| | 462/512 [00:16<00:01, 27.34it/s, est. speed input: 28633.09 toks/s, output: 27.96 toks/s]
Processed prompts:  91%| | 466/512 [00:16<00:01, 27.17it/s, est. speed input: 28622.25 toks/s, output: 27.95 toks/s]
Processed prompts:  92%|| 470/512 [00:16<00:01, 27.13it/s, est. speed input: 28614.18 toks/s, output: 27.94 toks/s]
Processed prompts:  93%|| 474/512 [00:16<00:01, 26.73it/s, est. speed input: 28594.41 toks/s, output: 27.92 toks/s]
Processed prompts:  93%|| 478/512 [00:17<00:01, 26.76it/s, est. speed input: 28584.69 toks/s, output: 27.91 toks/s]
Processed prompts:  94%|| 482/512 [00:17<00:01, 26.83it/s, est. speed input: 28576.55 toks/s, output: 27.91 toks/s]
Processed prompts:  95%|| 486/512 [00:17<00:00, 26.97it/s, est. speed input: 28571.37 toks/s, output: 27.90 toks/s]
Processed prompts:  96%|| 490/512 [00:17<00:00, 26.98it/s, est. speed input: 28563.57 toks/s, output: 27.89 toks/s]
Processed prompts:  96%|| 494/512 [00:17<00:00, 26.89it/s, est. speed input: 28553.12 toks/s, output: 27.88 toks/s]
Processed prompts:  97%|| 498/512 [00:17<00:00, 26.90it/s, est. speed input: 28544.96 toks/s, output: 27.88 toks/s]
Processed prompts:  98%|| 502/512 [00:18<00:00, 26.48it/s, est. speed input: 28524.37 toks/s, output: 27.86 toks/s]
Processed prompts:  99%|| 506/512 [00:18<00:00, 26.63it/s, est. speed input: 28517.06 toks/s, output: 27.85 toks/s]
Processed prompts: 100%|| 510/512 [00:18<00:00, 28.36it/s, est. speed input: 28554.31 toks/s, output: 27.89 toks/s]
Processed prompts: 100%|| 512/512 [00:18<00:00, 28.36it/s, est. speed input: 28666.02 toks/s, output: 27.99 toks/s]
Processed prompts: 100%|| 512/512 [00:18<00:00, 27.99it/s, est. speed input: 28666.02 toks/s, output: 27.99 toks/s]
[rank0]:[W126 03:42:18.796042019 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 03:42:20
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:42:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:42:27 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=817527) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=817527) WARNING 01-26 03:42:49 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 26.40 requests/s, 27064.59 total tokens/s, 26.40 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 03:42:27] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:42:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:42:27] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:42:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:42:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:42:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:42:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:42:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:42:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:42:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:42:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:42:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:42:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:42:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:42:30] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:42:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:42:30] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:42:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:42:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:42:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:42:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:42:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:42:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:42:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:42:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:42:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:42:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:42:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=817527) [2026-01-26 03:42:31] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=817527) [2026-01-26 03:42:31] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=817527) [2026-01-26 03:42:31] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=817527) [2026-01-26 03:42:31] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=817527) [2026-01-26 03:42:31] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=817527) [2026-01-26 03:42:31] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=817527) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=817527) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.91s/it]
(EngineCore_DP0 pid=817527) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.91s/it]
(EngineCore_DP0 pid=817527) 
(EngineCore_DP0 pid=817527) [2026-01-26 03:42:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=817527) [2026-01-26 03:42:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=817527) [2026-01-26 03:42:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=817527) [2026-01-26 03:42:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=817527) [2026-01-26 03:42:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=817527) [2026-01-26 03:42:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=817527) [2026-01-26 03:42:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=817527) [2026-01-26 03:42:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=817527) 2026-01-26 03:42:48,423 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=817527) 2026-01-26 03:42:48,473 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   6%|         | 66/1024 [00:00<00:01, 652.18it/s]
Adding requests:  13%|        | 132/1024 [00:00<00:01, 609.74it/s]
Adding requests:  19%|        | 194/1024 [00:00<00:01, 559.38it/s]
Adding requests:  25%|       | 251/1024 [00:00<00:01, 553.86it/s]
Adding requests:  30%|       | 307/1024 [00:00<00:01, 542.58it/s]
Adding requests:  35%|      | 363/1024 [00:00<00:01, 546.28it/s]
Adding requests:  41%|      | 419/1024 [00:00<00:01, 547.82it/s]
Adding requests:  46%|     | 474/1024 [00:00<00:01, 541.70it/s]
Adding requests:  52%|    | 529/1024 [00:00<00:00, 530.33it/s]
Adding requests:  57%|    | 584/1024 [00:01<00:00, 533.64it/s]
Adding requests:  62%|   | 638/1024 [00:01<00:00, 522.13it/s]
Adding requests:  68%|   | 694/1024 [00:01<00:00, 530.06it/s]
Adding requests:  73%|  | 748/1024 [00:01<00:00, 528.15it/s]
Adding requests:  78%|  | 801/1024 [00:01<00:00, 524.17it/s]
Adding requests:  83%| | 854/1024 [00:01<00:00, 518.62it/s]
Adding requests:  89%| | 910/1024 [00:01<00:00, 529.01it/s]
Adding requests:  94%|| 963/1024 [00:01<00:00, 525.17it/s]
Adding requests:  99%|| 1018/1024 [00:01<00:00, 530.95it/s]
Adding requests: 100%|| 1024/1024 [00:01<00:00, 537.84it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 50/1024 [00:00<00:07, 133.65it/s, est. speed input: 136863.64 toks/s, output: 133.65 toks/s]
Processed prompts:   6%|         | 64/1024 [00:00<00:11, 86.65it/s, est. speed input: 96697.36 toks/s, output: 94.43 toks/s]   
Processed prompts:   7%|         | 73/1024 [00:00<00:15, 62.33it/s, est. speed input: 76544.46 toks/s, output: 74.75 toks/s]
Processed prompts:   8%|         | 79/1024 [00:01<00:20, 46.37it/s, est. speed input: 63529.45 toks/s, output: 62.04 toks/s]
Processed prompts:   8%|         | 84/1024 [00:01<00:26, 35.64it/s, est. speed input: 54486.07 toks/s, output: 53.21 toks/s]
Processed prompts:   9%|         | 90/1024 [00:01<00:30, 30.37it/s, est. speed input: 49028.10 toks/s, output: 47.88 toks/s]
Processed prompts:  10%|         | 98/1024 [00:02<00:31, 29.14it/s, est. speed input: 46012.33 toks/s, output: 44.93 toks/s]
Processed prompts:  10%|         | 106/1024 [00:02<00:32, 28.19it/s, est. speed input: 43653.43 toks/s, output: 42.63 toks/s]
Processed prompts:  11%|         | 114/1024 [00:02<00:32, 27.64it/s, est. speed input: 41849.79 toks/s, output: 40.87 toks/s]
Processed prompts:  12%|        | 122/1024 [00:03<00:32, 27.37it/s, est. speed input: 40451.71 toks/s, output: 39.50 toks/s]
Processed prompts:  13%|        | 130/1024 [00:03<00:32, 27.14it/s, est. speed input: 39281.35 toks/s, output: 38.36 toks/s]
Processed prompts:  13%|        | 138/1024 [00:03<00:33, 26.84it/s, est. speed input: 38247.26 toks/s, output: 37.35 toks/s]
Processed prompts:  14%|        | 146/1024 [00:03<00:32, 26.78it/s, est. speed input: 37423.01 toks/s, output: 36.55 toks/s]
Processed prompts:  15%|        | 154/1024 [00:04<00:32, 26.76it/s, est. speed input: 36721.41 toks/s, output: 35.86 toks/s]
Processed prompts:  16%|        | 162/1024 [00:04<00:32, 26.67it/s, est. speed input: 36087.89 toks/s, output: 35.24 toks/s]
Processed prompts:  17%|        | 170/1024 [00:04<00:32, 26.67it/s, est. speed input: 35549.81 toks/s, output: 34.72 toks/s]
Processed prompts:  17%|        | 178/1024 [00:05<00:31, 26.66it/s, est. speed input: 35071.13 toks/s, output: 34.25 toks/s]
Processed prompts:  18%|        | 186/1024 [00:05<00:31, 26.60it/s, est. speed input: 34632.95 toks/s, output: 33.82 toks/s]
Processed prompts:  19%|        | 194/1024 [00:05<00:31, 26.42it/s, est. speed input: 34209.29 toks/s, output: 33.41 toks/s]
Processed prompts:  20%|        | 202/1024 [00:06<00:31, 26.50it/s, est. speed input: 33872.06 toks/s, output: 33.08 toks/s]
Processed prompts:  21%|        | 210/1024 [00:06<00:30, 26.54it/s, est. speed input: 33562.70 toks/s, output: 32.78 toks/s]
Processed prompts:  21%|       | 218/1024 [00:06<00:30, 26.43it/s, est. speed input: 33255.03 toks/s, output: 32.48 toks/s]
Processed prompts:  22%|       | 226/1024 [00:07<00:30, 26.49it/s, est. speed input: 32998.38 toks/s, output: 32.22 toks/s]
Processed prompts:  23%|       | 234/1024 [00:07<00:29, 26.54it/s, est. speed input: 32764.99 toks/s, output: 32.00 toks/s]
Processed prompts:  24%|       | 242/1024 [00:07<00:29, 26.54it/s, est. speed input: 32544.05 toks/s, output: 31.78 toks/s]
Processed prompts:  24%|       | 250/1024 [00:07<00:29, 26.44it/s, est. speed input: 32323.42 toks/s, output: 31.57 toks/s]
Processed prompts:  25%|       | 258/1024 [00:08<00:28, 26.49it/s, est. speed input: 32137.95 toks/s, output: 31.38 toks/s]
Processed prompts:  26%|       | 266/1024 [00:08<00:28, 26.60it/s, est. speed input: 31976.26 toks/s, output: 31.23 toks/s]
Processed prompts:  27%|       | 274/1024 [00:08<00:28, 26.47it/s, est. speed input: 31796.98 toks/s, output: 31.05 toks/s]
Processed prompts:  28%|       | 282/1024 [00:09<00:27, 26.53it/s, est. speed input: 31649.71 toks/s, output: 30.91 toks/s]
Processed prompts:  28%|       | 290/1024 [00:09<00:27, 26.56it/s, est. speed input: 31509.72 toks/s, output: 30.77 toks/s]
Processed prompts:  29%|       | 298/1024 [00:09<00:27, 26.60it/s, est. speed input: 31381.38 toks/s, output: 30.65 toks/s]
Processed prompts:  30%|       | 306/1024 [00:10<00:27, 26.50it/s, est. speed input: 31245.61 toks/s, output: 30.51 toks/s]
Processed prompts:  31%|       | 314/1024 [00:10<00:26, 26.52it/s, est. speed input: 31127.12 toks/s, output: 30.40 toks/s]
Processed prompts:  31%|      | 322/1024 [00:10<00:26, 26.53it/s, est. speed input: 31015.61 toks/s, output: 30.29 toks/s]
Processed prompts:  32%|      | 330/1024 [00:10<00:26, 26.46it/s, est. speed input: 30902.59 toks/s, output: 30.18 toks/s]
Processed prompts:  33%|      | 338/1024 [00:11<00:25, 26.90it/s, est. speed input: 30845.40 toks/s, output: 30.12 toks/s]
Processed prompts:  34%|      | 346/1024 [00:11<00:25, 26.84it/s, est. speed input: 30754.14 toks/s, output: 30.03 toks/s]
Processed prompts:  35%|      | 354/1024 [00:11<00:25, 26.73it/s, est. speed input: 30661.39 toks/s, output: 29.94 toks/s]
Processed prompts:  35%|      | 362/1024 [00:12<00:24, 26.63it/s, est. speed input: 30570.52 toks/s, output: 29.85 toks/s]
Processed prompts:  36%|      | 370/1024 [00:12<00:24, 26.67it/s, est. speed input: 30494.05 toks/s, output: 29.78 toks/s]
Processed prompts:  37%|      | 378/1024 [00:12<00:24, 26.58it/s, est. speed input: 30411.28 toks/s, output: 29.70 toks/s]
Processed prompts:  38%|      | 386/1024 [00:13<00:24, 26.55it/s, est. speed input: 30334.75 toks/s, output: 29.62 toks/s]
Processed prompts:  38%|      | 394/1024 [00:13<00:23, 26.64it/s, est. speed input: 30270.92 toks/s, output: 29.56 toks/s]
Processed prompts:  39%|      | 402/1024 [00:13<00:23, 26.64it/s, est. speed input: 30205.30 toks/s, output: 29.50 toks/s]
Processed prompts:  40%|      | 410/1024 [00:13<00:23, 26.66it/s, est. speed input: 30144.01 toks/s, output: 29.44 toks/s]
Processed prompts:  41%|      | 418/1024 [00:14<00:22, 26.54it/s, est. speed input: 30074.20 toks/s, output: 29.37 toks/s]
Processed prompts:  42%|     | 426/1024 [00:14<00:22, 26.65it/s, est. speed input: 30022.90 toks/s, output: 29.32 toks/s]
Processed prompts:  42%|     | 434/1024 [00:14<00:22, 26.62it/s, est. speed input: 29965.03 toks/s, output: 29.26 toks/s]
Processed prompts:  43%|     | 442/1024 [00:15<00:21, 26.58it/s, est. speed input: 29908.30 toks/s, output: 29.21 toks/s]
Processed prompts:  44%|     | 450/1024 [00:15<00:21, 26.86it/s, est. speed input: 29876.39 toks/s, output: 29.18 toks/s]
Processed prompts:  45%|     | 458/1024 [00:15<00:21, 26.74it/s, est. speed input: 29822.86 toks/s, output: 29.12 toks/s]
Processed prompts:  46%|     | 466/1024 [00:16<00:20, 26.69it/s, est. speed input: 29774.02 toks/s, output: 29.08 toks/s]
Processed prompts:  46%|     | 474/1024 [00:16<00:20, 26.56it/s, est. speed input: 29720.18 toks/s, output: 29.02 toks/s]
Processed prompts:  47%|     | 482/1024 [00:16<00:20, 26.56it/s, est. speed input: 29674.17 toks/s, output: 28.98 toks/s]
Processed prompts:  48%|     | 490/1024 [00:16<00:20, 26.62it/s, est. speed input: 29634.36 toks/s, output: 28.94 toks/s]
Processed prompts:  49%|     | 498/1024 [00:17<00:19, 26.64it/s, est. speed input: 29593.82 toks/s, output: 28.90 toks/s]
Processed prompts:  49%|     | 506/1024 [00:17<00:19, 26.52it/s, est. speed input: 29546.62 toks/s, output: 28.85 toks/s]
Processed prompts:  50%|     | 514/1024 [00:17<00:19, 26.53it/s, est. speed input: 29506.85 toks/s, output: 28.82 toks/s]
Processed prompts:  51%|     | 522/1024 [00:18<00:18, 26.63it/s, est. speed input: 29473.90 toks/s, output: 28.78 toks/s]
Processed prompts:  52%|    | 530/1024 [00:18<00:18, 26.48it/s, est. speed input: 29429.06 toks/s, output: 28.74 toks/s]
Processed prompts:  53%|    | 538/1024 [00:18<00:18, 26.53it/s, est. speed input: 29394.89 toks/s, output: 28.71 toks/s]
Processed prompts:  53%|    | 546/1024 [00:19<00:17, 26.56it/s, est. speed input: 29361.47 toks/s, output: 28.67 toks/s]
Processed prompts:  54%|    | 554/1024 [00:19<00:17, 26.58it/s, est. speed input: 29328.60 toks/s, output: 28.64 toks/s]
Processed prompts:  55%|    | 562/1024 [00:19<00:17, 26.46it/s, est. speed input: 29289.47 toks/s, output: 28.60 toks/s]
Processed prompts:  56%|    | 570/1024 [00:19<00:17, 26.56it/s, est. speed input: 29261.72 toks/s, output: 28.58 toks/s]
Processed prompts:  56%|    | 578/1024 [00:20<00:16, 26.61it/s, est. speed input: 29234.00 toks/s, output: 28.55 toks/s]
Processed prompts:  57%|    | 586/1024 [00:20<00:16, 26.51it/s, est. speed input: 29199.26 toks/s, output: 28.51 toks/s]
Processed prompts:  58%|    | 594/1024 [00:20<00:16, 26.53it/s, est. speed input: 29170.75 toks/s, output: 28.49 toks/s]
Processed prompts:  59%|    | 602/1024 [00:21<00:15, 26.54it/s, est. speed input: 29142.88 toks/s, output: 28.46 toks/s]
Processed prompts:  60%|    | 610/1024 [00:21<00:15, 26.58it/s, est. speed input: 29116.99 toks/s, output: 28.43 toks/s]
Processed prompts:  60%|    | 618/1024 [00:21<00:15, 26.45it/s, est. speed input: 29084.01 toks/s, output: 28.40 toks/s]
Processed prompts:  61%|    | 626/1024 [00:22<00:14, 26.60it/s, est. speed input: 29064.08 toks/s, output: 28.38 toks/s]
Processed prompts:  62%|   | 634/1024 [00:22<00:14, 26.59it/s, est. speed input: 29039.16 toks/s, output: 28.36 toks/s]
Processed prompts:  63%|   | 642/1024 [00:22<00:14, 26.54it/s, est. speed input: 29012.56 toks/s, output: 28.33 toks/s]
Processed prompts:  63%|   | 650/1024 [00:22<00:14, 26.59it/s, est. speed input: 28990.99 toks/s, output: 28.31 toks/s]
Processed prompts:  64%|   | 658/1024 [00:23<00:13, 26.58it/s, est. speed input: 28967.89 toks/s, output: 28.29 toks/s]
Processed prompts:  65%|   | 666/1024 [00:23<00:13, 26.57it/s, est. speed input: 28945.04 toks/s, output: 28.27 toks/s]
Processed prompts:  66%|   | 674/1024 [00:23<00:13, 26.47it/s, est. speed input: 28918.34 toks/s, output: 28.24 toks/s]
Processed prompts:  67%|   | 682/1024 [00:24<00:12, 26.51it/s, est. speed input: 28897.73 toks/s, output: 28.22 toks/s]
Processed prompts:  67%|   | 690/1024 [00:24<00:12, 26.57it/s, est. speed input: 28878.85 toks/s, output: 28.20 toks/s]
Processed prompts:  68%|   | 698/1024 [00:24<00:12, 26.43it/s, est. speed input: 28852.32 toks/s, output: 28.18 toks/s]
Processed prompts:  69%|   | 706/1024 [00:25<00:11, 26.55it/s, est. speed input: 28836.03 toks/s, output: 28.16 toks/s]
Processed prompts:  70%|   | 714/1024 [00:25<00:11, 26.66it/s, est. speed input: 28821.28 toks/s, output: 28.15 toks/s]
Processed prompts:  71%|   | 722/1024 [00:25<00:11, 26.58it/s, est. speed input: 28800.17 toks/s, output: 28.13 toks/s]
Processed prompts:  71%|  | 730/1024 [00:25<00:11, 26.44it/s, est. speed input: 28775.81 toks/s, output: 28.10 toks/s]
Processed prompts:  72%|  | 738/1024 [00:26<00:10, 26.57it/s, est. speed input: 28761.60 toks/s, output: 28.09 toks/s]
Processed prompts:  73%|  | 746/1024 [00:26<00:10, 26.60it/s, est. speed input: 28745.31 toks/s, output: 28.07 toks/s]
Processed prompts:  74%|  | 754/1024 [00:26<00:10, 26.45it/s, est. speed input: 28722.28 toks/s, output: 28.05 toks/s]
Processed prompts:  74%|  | 762/1024 [00:27<00:09, 26.45it/s, est. speed input: 28704.14 toks/s, output: 28.03 toks/s]
Processed prompts:  75%|  | 770/1024 [00:27<00:09, 26.51it/s, est. speed input: 28688.55 toks/s, output: 28.02 toks/s]
Processed prompts:  76%|  | 778/1024 [00:27<00:09, 26.57it/s, est. speed input: 28674.21 toks/s, output: 28.00 toks/s]
Processed prompts:  77%|  | 786/1024 [00:28<00:08, 26.46it/s, est. speed input: 28654.17 toks/s, output: 27.98 toks/s]
Processed prompts:  78%|  | 794/1024 [00:28<00:08, 26.45it/s, est. speed input: 28637.37 toks/s, output: 27.97 toks/s]
Processed prompts:  78%|  | 802/1024 [00:28<00:08, 26.45it/s, est. speed input: 28621.07 toks/s, output: 27.95 toks/s]
Processed prompts:  79%|  | 810/1024 [00:28<00:08, 26.43it/s, est. speed input: 28604.05 toks/s, output: 27.93 toks/s]
Processed prompts:  80%|  | 818/1024 [00:29<00:07, 26.44it/s, est. speed input: 28588.63 toks/s, output: 27.92 toks/s]
Processed prompts:  81%|  | 826/1024 [00:29<00:07, 26.50it/s, est. speed input: 28575.40 toks/s, output: 27.91 toks/s]
Processed prompts:  81%| | 834/1024 [00:29<00:07, 26.47it/s, est. speed input: 28559.69 toks/s, output: 27.89 toks/s]
Processed prompts:  82%| | 842/1024 [00:30<00:06, 26.40it/s, est. speed input: 28542.67 toks/s, output: 27.87 toks/s]
Processed prompts:  83%| | 850/1024 [00:30<00:06, 26.51it/s, est. speed input: 28531.69 toks/s, output: 27.86 toks/s]
Processed prompts:  84%| | 858/1024 [00:30<00:06, 26.58it/s, est. speed input: 28520.50 toks/s, output: 27.85 toks/s]
Processed prompts:  85%| | 866/1024 [00:31<00:06, 24.16it/s, est. speed input: 28415.96 toks/s, output: 27.75 toks/s]
Processed prompts:  85%| | 874/1024 [00:31<00:06, 24.88it/s, est. speed input: 28406.30 toks/s, output: 27.74 toks/s]
Processed prompts:  86%| | 882/1024 [00:31<00:05, 25.01it/s, est. speed input: 28381.61 toks/s, output: 27.72 toks/s]
Processed prompts:  87%| | 890/1024 [00:32<00:05, 25.35it/s, est. speed input: 28366.60 toks/s, output: 27.70 toks/s]
Processed prompts:  88%| | 898/1024 [00:32<00:04, 25.66it/s, est. speed input: 28354.38 toks/s, output: 27.69 toks/s]
Processed prompts:  88%| | 906/1024 [00:32<00:04, 25.87it/s, est. speed input: 28341.77 toks/s, output: 27.68 toks/s]
Processed prompts:  89%| | 914/1024 [00:33<00:04, 26.17it/s, est. speed input: 28334.67 toks/s, output: 27.67 toks/s]
Processed prompts:  90%| | 922/1024 [00:33<00:03, 26.18it/s, est. speed input: 28320.83 toks/s, output: 27.66 toks/s]
Processed prompts:  91%| | 930/1024 [00:33<00:03, 26.27it/s, est. speed input: 28310.02 toks/s, output: 27.65 toks/s]
Processed prompts:  92%|| 938/1024 [00:33<00:03, 27.16it/s, est. speed input: 28325.29 toks/s, output: 27.66 toks/s]
Processed prompts:  92%|| 946/1024 [00:34<00:02, 26.97it/s, est. speed input: 28315.05 toks/s, output: 27.65 toks/s]
Processed prompts:  93%|| 954/1024 [00:34<00:02, 26.82it/s, est. speed input: 28304.62 toks/s, output: 27.64 toks/s]
Processed prompts:  94%|| 962/1024 [00:34<00:02, 26.78it/s, est. speed input: 28296.07 toks/s, output: 27.63 toks/s]
Processed prompts:  95%|| 970/1024 [00:35<00:02, 26.68it/s, est. speed input: 28285.82 toks/s, output: 27.62 toks/s]
Processed prompts:  96%|| 978/1024 [00:35<00:01, 26.52it/s, est. speed input: 28272.66 toks/s, output: 27.61 toks/s]
Processed prompts:  96%|| 986/1024 [00:35<00:01, 27.37it/s, est. speed input: 28288.01 toks/s, output: 27.62 toks/s]
Processed prompts:  97%|| 994/1024 [00:35<00:01, 27.11it/s, est. speed input: 28278.62 toks/s, output: 27.62 toks/s]
Processed prompts:  98%|| 1002/1024 [00:36<00:00, 27.00it/s, est. speed input: 28271.21 toks/s, output: 27.61 toks/s]
Processed prompts:  99%|| 1010/1024 [00:36<00:00, 26.71it/s, est. speed input: 28257.74 toks/s, output: 27.60 toks/s]
Processed prompts:  99%|| 1018/1024 [00:36<00:00, 27.37it/s, est. speed input: 28268.97 toks/s, output: 27.61 toks/s]
Processed prompts: 100%|| 1024/1024 [00:36<00:00, 27.37it/s, est. speed input: 28435.49 toks/s, output: 27.77 toks/s]
Processed prompts: 100%|| 1024/1024 [00:36<00:00, 27.77it/s, est. speed input: 28435.49 toks/s, output: 27.77 toks/s]
[rank0]:[W126 03:43:28.414294366 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 03:43:30
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:43:39 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:43:39 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=818736) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=818736) WARNING 01-26 03:44:02 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 26.71 requests/s, 27373.26 total tokens/s, 26.71 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 03:43:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:43:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:43:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:43:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:43:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:43:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:43:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:43:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:43:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:43:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:43:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:43:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:43:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:43:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:43:42] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:43:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:43:42] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:43:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:43:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:43:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:43:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:43:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:43:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:43:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:43:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:43:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:43:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:43:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=818736) [2026-01-26 03:43:43] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=818736) [2026-01-26 03:43:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=818736) [2026-01-26 03:43:43] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=818736) [2026-01-26 03:43:43] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=818736) [2026-01-26 03:43:43] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=818736) [2026-01-26 03:43:43] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=818736) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=818736) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 11.00s/it]
(EngineCore_DP0 pid=818736) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 11.00s/it]
(EngineCore_DP0 pid=818736) 
(EngineCore_DP0 pid=818736) [2026-01-26 03:43:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=818736) [2026-01-26 03:43:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=818736) [2026-01-26 03:43:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=818736) [2026-01-26 03:43:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=818736) [2026-01-26 03:43:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=818736) [2026-01-26 03:43:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=818736) [2026-01-26 03:43:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=818736) [2026-01-26 03:43:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=818736) 2026-01-26 03:44:01,214 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=818736) 2026-01-26 03:44:01,348 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|         | 45/2048 [00:00<00:04, 447.90it/s]
Adding requests:   5%|         | 103/2048 [00:00<00:03, 524.70it/s]
Adding requests:   8%|         | 156/2048 [00:00<00:03, 525.25it/s]
Adding requests:  10%|         | 209/2048 [00:00<00:03, 523.00it/s]
Adding requests:  13%|        | 263/2048 [00:00<00:03, 528.66it/s]
Adding requests:  15%|        | 317/2048 [00:00<00:03, 528.49it/s]
Adding requests:  18%|        | 372/2048 [00:00<00:03, 535.17it/s]
Adding requests:  21%|        | 426/2048 [00:00<00:03, 528.80it/s]
Adding requests:  23%|       | 479/2048 [00:00<00:02, 527.84it/s]
Adding requests:  26%|       | 532/2048 [00:01<00:02, 519.19it/s]
Adding requests:  29%|       | 588/2048 [00:01<00:02, 530.30it/s]
Adding requests:  31%|      | 642/2048 [00:01<00:02, 530.83it/s]
Adding requests:  34%|      | 696/2048 [00:01<00:02, 528.69it/s]
Adding requests:  37%|      | 749/2048 [00:01<00:02, 527.30it/s]
Adding requests:  39%|      | 802/2048 [00:01<00:02, 503.95it/s]
Adding requests:  42%|     | 853/2048 [00:02<00:05, 203.19it/s]
Adding requests:  44%|     | 902/2048 [00:02<00:04, 243.05it/s]
Adding requests:  47%|     | 954/2048 [00:02<00:03, 288.77it/s]
Adding requests:  49%|     | 1010/2048 [00:02<00:03, 340.75it/s]
Adding requests:  52%|    | 1063/2048 [00:02<00:02, 381.18it/s]
Adding requests:  54%|    | 1114/2048 [00:02<00:02, 410.55it/s]
Adding requests:  57%|    | 1169/2048 [00:02<00:01, 443.19it/s]
Adding requests:  60%|    | 1225/2048 [00:02<00:01, 471.77it/s]
Adding requests:  62%|   | 1278/2048 [00:02<00:01, 476.90it/s]
Adding requests:  65%|   | 1332/2048 [00:03<00:01, 493.25it/s]
Adding requests:  68%|   | 1387/2048 [00:03<00:01, 508.54it/s]
Adding requests:  70%|   | 1440/2048 [00:03<00:01, 506.16it/s]
Adding requests:  73%|  | 1495/2048 [00:03<00:01, 518.21it/s]
Adding requests:  76%|  | 1549/2048 [00:03<00:00, 522.13it/s]
Adding requests:  78%|  | 1607/2048 [00:03<00:00, 538.08it/s]
Adding requests:  81%|  | 1662/2048 [00:03<00:00, 533.81it/s]
Adding requests:  84%| | 1716/2048 [00:03<00:00, 527.44it/s]
Adding requests:  86%| | 1770/2048 [00:03<00:00, 526.97it/s]
Adding requests:  89%| | 1825/2048 [00:03<00:00, 533.27it/s]
Adding requests:  92%|| 1879/2048 [00:04<00:00, 533.31it/s]
Adding requests:  94%|| 1933/2048 [00:04<00:00, 532.29it/s]
Adding requests:  97%|| 1987/2048 [00:04<00:00, 532.10it/s]
Adding requests: 100%|| 2041/2048 [00:04<00:00, 499.07it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 461.20it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 114/2048 [00:00<00:08, 218.85it/s, est. speed input: 224121.97 toks/s, output: 218.86 toks/s]
Processed prompts:   7%|         | 136/2048 [00:01<00:18, 105.44it/s, est. speed input: 124153.37 toks/s, output: 121.24 toks/s]
Processed prompts:   7%|         | 148/2048 [00:01<00:29, 65.30it/s, est. speed input: 88063.56 toks/s, output: 86.00 toks/s]   
Processed prompts:   8%|         | 162/2048 [00:02<00:38, 48.43it/s, est. speed input: 71475.39 toks/s, output: 69.80 toks/s]
Processed prompts:   9%|         | 178/2048 [00:02<00:46, 40.36it/s, est. speed input: 62286.74 toks/s, output: 60.83 toks/s]
Processed prompts:   9%|         | 194/2048 [00:03<00:51, 35.72it/s, est. speed input: 56368.22 toks/s, output: 55.05 toks/s]
Processed prompts:  10%|         | 210/2048 [00:04<00:56, 32.69it/s, est. speed input: 52098.77 toks/s, output: 50.88 toks/s]
Processed prompts:  11%|         | 226/2048 [00:04<00:59, 30.81it/s, est. speed input: 48981.26 toks/s, output: 47.83 toks/s]
Processed prompts:  12%|        | 242/2048 [00:05<01:01, 29.45it/s, est. speed input: 46505.09 toks/s, output: 45.41 toks/s]
Processed prompts:  13%|        | 258/2048 [00:05<01:02, 28.62it/s, est. speed input: 44577.20 toks/s, output: 43.53 toks/s]
Processed prompts:  13%|        | 274/2048 [00:06<01:03, 27.99it/s, est. speed input: 42973.78 toks/s, output: 41.97 toks/s]
Processed prompts:  14%|        | 290/2048 [00:07<01:03, 27.52it/s, est. speed input: 41628.22 toks/s, output: 40.65 toks/s]
Processed prompts:  15%|        | 306/2048 [00:07<01:03, 27.29it/s, est. speed input: 40527.53 toks/s, output: 39.58 toks/s]
Processed prompts:  16%|        | 322/2048 [00:08<01:03, 27.10it/s, est. speed input: 39574.50 toks/s, output: 38.65 toks/s]
Processed prompts:  17%|        | 338/2048 [00:08<01:02, 27.26it/s, est. speed input: 38842.68 toks/s, output: 37.93 toks/s]
Processed prompts:  17%|        | 354/2048 [00:09<01:02, 27.04it/s, est. speed input: 38101.92 toks/s, output: 37.21 toks/s]
Processed prompts:  18%|        | 370/2048 [00:10<01:02, 26.94it/s, est. speed input: 37466.69 toks/s, output: 36.59 toks/s]
Processed prompts:  19%|        | 386/2048 [00:10<01:01, 26.86it/s, est. speed input: 36897.61 toks/s, output: 36.03 toks/s]
Processed prompts:  20%|        | 402/2048 [00:11<01:01, 26.77it/s, est. speed input: 36380.86 toks/s, output: 35.53 toks/s]
Processed prompts:  20%|        | 418/2048 [00:11<01:00, 26.79it/s, est. speed input: 35935.69 toks/s, output: 35.09 toks/s]
Processed prompts:  21%|        | 434/2048 [00:12<01:00, 26.68it/s, est. speed input: 35505.45 toks/s, output: 34.67 toks/s]
Processed prompts:  22%|       | 450/2048 [00:13<00:58, 27.10it/s, est. speed input: 35215.03 toks/s, output: 34.39 toks/s]
Processed prompts:  23%|       | 466/2048 [00:13<00:58, 26.91it/s, est. speed input: 34856.48 toks/s, output: 34.04 toks/s]
Processed prompts:  24%|       | 482/2048 [00:14<00:58, 26.86it/s, est. speed input: 34544.76 toks/s, output: 33.74 toks/s]
Processed prompts:  24%|       | 498/2048 [00:14<00:57, 26.78it/s, est. speed input: 34248.83 toks/s, output: 33.45 toks/s]
Processed prompts:  25%|       | 514/2048 [00:15<00:57, 26.80it/s, est. speed input: 33989.53 toks/s, output: 33.19 toks/s]
Processed prompts:  26%|       | 530/2048 [00:16<00:56, 26.71it/s, est. speed input: 33731.90 toks/s, output: 32.94 toks/s]
Processed prompts:  27%|       | 546/2048 [00:16<00:56, 26.66it/s, est. speed input: 33495.70 toks/s, output: 32.71 toks/s]
Processed prompts:  27%|       | 562/2048 [00:17<00:55, 26.69it/s, est. speed input: 33284.53 toks/s, output: 32.50 toks/s]
Processed prompts:  28%|       | 578/2048 [00:17<00:55, 26.61it/s, est. speed input: 33073.74 toks/s, output: 32.30 toks/s]
Processed prompts:  29%|       | 594/2048 [00:18<00:54, 26.65it/s, est. speed input: 32889.52 toks/s, output: 32.12 toks/s]
Processed prompts:  30%|       | 610/2048 [00:19<00:54, 26.61it/s, est. speed input: 32708.31 toks/s, output: 31.94 toks/s]
Processed prompts:  31%|       | 626/2048 [00:19<00:53, 26.68it/s, est. speed input: 32550.11 toks/s, output: 31.79 toks/s]
Processed prompts:  31%|      | 642/2048 [00:20<00:52, 26.68it/s, est. speed input: 32395.68 toks/s, output: 31.64 toks/s]
Processed prompts:  32%|      | 658/2048 [00:20<00:52, 26.62it/s, est. speed input: 32243.63 toks/s, output: 31.49 toks/s]
Processed prompts:  33%|      | 674/2048 [00:21<00:51, 26.65it/s, est. speed input: 32106.93 toks/s, output: 31.35 toks/s]
Processed prompts:  34%|      | 690/2048 [00:22<00:51, 26.60it/s, est. speed input: 31971.08 toks/s, output: 31.22 toks/s]
Processed prompts:  34%|      | 706/2048 [00:22<00:50, 26.66it/s, est. speed input: 31851.62 toks/s, output: 31.11 toks/s]
Processed prompts:  35%|      | 722/2048 [00:23<00:49, 26.63it/s, est. speed input: 31731.45 toks/s, output: 30.99 toks/s]
Processed prompts:  36%|      | 738/2048 [00:23<00:49, 26.70it/s, est. speed input: 31625.80 toks/s, output: 30.88 toks/s]
Processed prompts:  37%|      | 754/2048 [00:24<00:48, 26.60it/s, est. speed input: 31511.33 toks/s, output: 30.77 toks/s]
Processed prompts:  38%|      | 770/2048 [00:25<00:48, 26.61it/s, est. speed input: 31410.34 toks/s, output: 30.67 toks/s]
Processed prompts:  38%|      | 786/2048 [00:25<00:47, 26.66it/s, est. speed input: 31317.39 toks/s, output: 30.58 toks/s]
Processed prompts:  39%|      | 802/2048 [00:26<00:46, 26.62it/s, est. speed input: 31222.37 toks/s, output: 30.49 toks/s]
Processed prompts:  40%|      | 818/2048 [00:26<00:46, 26.68it/s, est. speed input: 31138.86 toks/s, output: 30.41 toks/s]
Processed prompts:  41%|      | 834/2048 [00:27<00:46, 25.96it/s, est. speed input: 30992.70 toks/s, output: 30.27 toks/s]
Processed prompts:  42%|     | 850/2048 [00:28<00:45, 26.16it/s, est. speed input: 30913.66 toks/s, output: 30.19 toks/s]
Processed prompts:  42%|     | 866/2048 [00:28<00:45, 26.26it/s, est. speed input: 30834.57 toks/s, output: 30.11 toks/s]
Processed prompts:  43%|     | 882/2048 [00:29<00:44, 26.39it/s, est. speed input: 30763.10 toks/s, output: 30.04 toks/s]
Processed prompts:  44%|     | 898/2048 [00:29<00:43, 26.45it/s, est. speed input: 30691.84 toks/s, output: 29.97 toks/s]
Processed prompts:  45%|     | 914/2048 [00:30<00:42, 26.43it/s, est. speed input: 30619.15 toks/s, output: 29.90 toks/s]
Processed prompts:  45%|     | 930/2048 [00:31<00:41, 26.98it/s, est. speed input: 30590.20 toks/s, output: 29.87 toks/s]
Processed prompts:  46%|     | 946/2048 [00:31<00:41, 26.87it/s, est. speed input: 30527.29 toks/s, output: 29.81 toks/s]
Processed prompts:  47%|     | 962/2048 [00:32<00:40, 26.87it/s, est. speed input: 30471.47 toks/s, output: 29.76 toks/s]
Processed prompts:  48%|     | 978/2048 [00:32<00:39, 27.23it/s, est. speed input: 30442.70 toks/s, output: 29.73 toks/s]
Processed prompts:  49%|     | 994/2048 [00:33<00:38, 27.09it/s, est. speed input: 30388.40 toks/s, output: 29.68 toks/s]
Processed prompts:  49%|     | 1010/2048 [00:34<00:38, 26.93it/s, est. speed input: 30331.86 toks/s, output: 29.62 toks/s]
Processed prompts:  50%|     | 1026/2048 [00:34<00:38, 26.82it/s, est. speed input: 30278.02 toks/s, output: 29.57 toks/s]
Processed prompts:  51%|     | 1042/2048 [00:35<00:37, 26.80it/s, est. speed input: 30229.12 toks/s, output: 29.52 toks/s]
Processed prompts:  52%|    | 1058/2048 [00:35<00:37, 26.69it/s, est. speed input: 30175.77 toks/s, output: 29.47 toks/s]
Processed prompts:  52%|    | 1074/2048 [00:36<00:36, 26.70it/s, est. speed input: 30129.55 toks/s, output: 29.42 toks/s]
Processed prompts:  53%|    | 1090/2048 [00:37<00:35, 26.63it/s, est. speed input: 30080.07 toks/s, output: 29.38 toks/s]
Processed prompts:  54%|    | 1106/2048 [00:37<00:35, 26.65it/s, est. speed input: 30036.84 toks/s, output: 29.33 toks/s]
Processed prompts:  55%|    | 1122/2048 [00:38<00:34, 26.56it/s, est. speed input: 29988.09 toks/s, output: 29.29 toks/s]
Processed prompts:  56%|    | 1138/2048 [00:38<00:34, 26.61it/s, est. speed input: 29948.00 toks/s, output: 29.25 toks/s]
Processed prompts:  56%|    | 1154/2048 [00:39<00:33, 27.08it/s, est. speed input: 29933.09 toks/s, output: 29.23 toks/s]
Processed prompts:  57%|    | 1170/2048 [00:40<00:32, 26.93it/s, est. speed input: 29892.63 toks/s, output: 29.19 toks/s]
Processed prompts:  58%|    | 1186/2048 [00:40<00:32, 26.87it/s, est. speed input: 29855.38 toks/s, output: 29.16 toks/s]
Processed prompts:  59%|    | 1202/2048 [00:41<00:31, 26.74it/s, est. speed input: 29814.73 toks/s, output: 29.12 toks/s]
Processed prompts:  59%|    | 1218/2048 [00:41<00:31, 26.72it/s, est. speed input: 29778.92 toks/s, output: 29.08 toks/s]
Processed prompts:  60%|    | 1234/2048 [00:42<00:30, 26.65it/s, est. speed input: 29741.35 toks/s, output: 29.04 toks/s]
Processed prompts:  61%|    | 1250/2048 [00:43<00:29, 26.67it/s, est. speed input: 29708.33 toks/s, output: 29.01 toks/s]
Processed prompts:  62%|   | 1266/2048 [00:43<00:28, 27.09it/s, est. speed input: 29696.53 toks/s, output: 29.00 toks/s]
Processed prompts:  63%|   | 1282/2048 [00:44<00:28, 26.98it/s, est. speed input: 29664.77 toks/s, output: 28.97 toks/s]
Processed prompts:  63%|   | 1298/2048 [00:44<00:27, 27.28it/s, est. speed input: 29652.19 toks/s, output: 28.96 toks/s]
Processed prompts:  64%|   | 1314/2048 [00:45<00:27, 27.05it/s, est. speed input: 29619.24 toks/s, output: 28.93 toks/s]
Processed prompts:  65%|   | 1330/2048 [00:46<00:26, 26.92it/s, est. speed input: 29588.49 toks/s, output: 28.89 toks/s]
Processed prompts:  66%|   | 1346/2048 [00:46<00:26, 26.79it/s, est. speed input: 29556.47 toks/s, output: 28.86 toks/s]
Processed prompts:  67%|   | 1362/2048 [00:47<00:25, 26.81it/s, est. speed input: 29530.71 toks/s, output: 28.84 toks/s]
Processed prompts:  67%|   | 1378/2048 [00:47<00:25, 26.80it/s, est. speed input: 29504.13 toks/s, output: 28.81 toks/s]
Processed prompts:  68%|   | 1394/2048 [00:48<00:24, 26.77it/s, est. speed input: 29477.53 toks/s, output: 28.79 toks/s]
Processed prompts:  69%|   | 1410/2048 [00:49<00:23, 26.71it/s, est. speed input: 29449.73 toks/s, output: 28.76 toks/s]
Processed prompts:  70%|   | 1426/2048 [00:49<00:23, 26.66it/s, est. speed input: 29422.10 toks/s, output: 28.73 toks/s]
Processed prompts:  70%|   | 1442/2048 [00:50<00:22, 26.66it/s, est. speed input: 29396.91 toks/s, output: 28.71 toks/s]
Processed prompts:  71%|   | 1458/2048 [00:50<00:22, 26.63it/s, est. speed input: 29370.64 toks/s, output: 28.68 toks/s]
Processed prompts:  72%|  | 1474/2048 [00:51<00:21, 26.62it/s, est. speed input: 29345.61 toks/s, output: 28.66 toks/s]
Processed prompts:  73%|  | 1490/2048 [00:52<00:21, 26.52it/s, est. speed input: 29317.34 toks/s, output: 28.63 toks/s]
Processed prompts:  74%|  | 1506/2048 [00:52<00:20, 26.58it/s, est. speed input: 29295.24 toks/s, output: 28.61 toks/s]
Processed prompts:  74%|  | 1522/2048 [00:53<00:19, 26.53it/s, est. speed input: 29269.41 toks/s, output: 28.58 toks/s]
Processed prompts:  75%|  | 1538/2048 [00:53<00:19, 26.50it/s, est. speed input: 29244.69 toks/s, output: 28.56 toks/s]
Processed prompts:  76%|  | 1554/2048 [00:54<00:18, 26.59it/s, est. speed input: 29225.17 toks/s, output: 28.54 toks/s]
Processed prompts:  77%|  | 1570/2048 [00:55<00:18, 26.53it/s, est. speed input: 29200.93 toks/s, output: 28.52 toks/s]
Processed prompts:  77%|  | 1586/2048 [00:55<00:17, 27.06it/s, est. speed input: 29199.53 toks/s, output: 28.52 toks/s]
Processed prompts:  78%|  | 1602/2048 [00:56<00:16, 26.88it/s, est. speed input: 29177.03 toks/s, output: 28.49 toks/s]
Processed prompts:  79%|  | 1618/2048 [00:56<00:16, 26.87it/s, est. speed input: 29159.37 toks/s, output: 28.48 toks/s]
Processed prompts:  80%|  | 1634/2048 [00:57<00:15, 26.72it/s, est. speed input: 29136.52 toks/s, output: 28.45 toks/s]
Processed prompts:  81%|  | 1650/2048 [00:57<00:14, 27.22it/s, est. speed input: 29136.67 toks/s, output: 28.45 toks/s]
Processed prompts:  81%| | 1666/2048 [00:58<00:14, 26.97it/s, est. speed input: 29114.80 toks/s, output: 28.43 toks/s]
Processed prompts:  82%| | 1682/2048 [00:59<00:13, 26.84it/s, est. speed input: 29095.15 toks/s, output: 28.41 toks/s]
Processed prompts:  83%| | 1698/2048 [00:59<00:13, 26.71it/s, est. speed input: 29074.28 toks/s, output: 28.39 toks/s]
Processed prompts:  84%| | 1714/2048 [01:00<00:12, 26.63it/s, est. speed input: 29054.53 toks/s, output: 28.37 toks/s]
Processed prompts:  84%| | 1730/2048 [01:01<00:11, 26.64it/s, est. speed input: 29037.39 toks/s, output: 28.36 toks/s]
Processed prompts:  85%| | 1746/2048 [01:01<00:11, 26.63it/s, est. speed input: 29019.71 toks/s, output: 28.34 toks/s]
Processed prompts:  86%| | 1762/2048 [01:02<00:10, 26.66it/s, est. speed input: 29003.84 toks/s, output: 28.32 toks/s]
Processed prompts:  87%| | 1778/2048 [01:02<00:10, 26.60it/s, est. speed input: 28985.61 toks/s, output: 28.31 toks/s]
Processed prompts:  88%| | 1794/2048 [01:03<00:09, 26.59it/s, est. speed input: 28968.62 toks/s, output: 28.29 toks/s]
Processed prompts:  88%| | 1810/2048 [01:04<00:08, 26.66it/s, est. speed input: 28954.67 toks/s, output: 28.28 toks/s]
Processed prompts:  89%| | 1826/2048 [01:04<00:08, 26.59it/s, est. speed input: 28937.04 toks/s, output: 28.26 toks/s]
Processed prompts:  90%| | 1842/2048 [01:05<00:07, 26.62it/s, est. speed input: 28922.20 toks/s, output: 28.24 toks/s]
Processed prompts:  91%| | 1858/2048 [01:05<00:07, 26.60it/s, est. speed input: 28906.37 toks/s, output: 28.23 toks/s]
Processed prompts:  92%|| 1874/2048 [01:06<00:06, 27.13it/s, est. speed input: 28908.27 toks/s, output: 28.23 toks/s]
Processed prompts:  92%|| 1890/2048 [01:06<00:05, 26.93it/s, est. speed input: 28892.20 toks/s, output: 28.22 toks/s]
Processed prompts:  93%|| 1906/2048 [01:07<00:05, 26.88it/s, est. speed input: 28878.85 toks/s, output: 28.20 toks/s]
Processed prompts:  94%|| 1922/2048 [01:08<00:04, 26.75it/s, est. speed input: 28862.89 toks/s, output: 28.19 toks/s]
Processed prompts:  95%|| 1938/2048 [01:08<00:04, 26.66it/s, est. speed input: 28847.24 toks/s, output: 28.17 toks/s]
Processed prompts:  95%|| 1954/2048 [01:09<00:03, 27.12it/s, est. speed input: 28848.14 toks/s, output: 28.17 toks/s]
Processed prompts:  96%|| 1970/2048 [01:09<00:02, 26.93it/s, est. speed input: 28833.26 toks/s, output: 28.16 toks/s]
Processed prompts:  97%|| 1986/2048 [01:10<00:02, 27.30it/s, est. speed input: 28833.63 toks/s, output: 28.16 toks/s]
Processed prompts:  98%|| 2002/2048 [01:11<00:01, 27.87it/s, est. speed input: 28842.56 toks/s, output: 28.17 toks/s]
Processed prompts:  99%|| 2018/2048 [01:11<00:01, 27.51it/s, est. speed input: 28830.00 toks/s, output: 28.15 toks/s]
Processed prompts:  99%|| 2034/2048 [01:12<00:00, 27.69it/s, est. speed input: 28829.63 toks/s, output: 28.15 toks/s]
Processed prompts: 100%|| 2048/2048 [01:12<00:00, 27.69it/s, est. speed input: 29028.00 toks/s, output: 28.35 toks/s]
Processed prompts: 100%|| 2048/2048 [01:12<00:00, 28.35it/s, est. speed input: 29028.00 toks/s, output: 28.35 toks/s]
[rank0]:[W126 03:45:19.497278998 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 03:45:21
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:45:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:45:36 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=820532) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=820532) WARNING 01-26 03:46:01 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 26.76 requests/s, 27424.38 total tokens/s, 26.76 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 03:45:36] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:45:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:45:36] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:45:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:45:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:45:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:45:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:45:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:45:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:45:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:45:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:45:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:45:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:45:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:45:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:45:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:45:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:45:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:45:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:45:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:45:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:45:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:45:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:45:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:45:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:45:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:45:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:45:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=820532) [2026-01-26 03:45:40] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=820532) [2026-01-26 03:45:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=820532) [2026-01-26 03:45:40] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=820532) [2026-01-26 03:45:40] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=820532) [2026-01-26 03:45:40] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=820532) [2026-01-26 03:45:40] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=820532) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=820532) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.63s/it]
(EngineCore_DP0 pid=820532) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.63s/it]
(EngineCore_DP0 pid=820532) 
(EngineCore_DP0 pid=820532) [2026-01-26 03:45:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=820532) [2026-01-26 03:45:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=820532) [2026-01-26 03:45:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=820532) [2026-01-26 03:45:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=820532) [2026-01-26 03:45:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=820532) [2026-01-26 03:45:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=820532) [2026-01-26 03:45:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=820532) [2026-01-26 03:45:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=820532) 2026-01-26 03:45:58,484 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=820532) 2026-01-26 03:45:59,028 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   2%|         | 66/4096 [00:00<00:06, 652.55it/s]
Adding requests:   3%|         | 133/4096 [00:00<00:06, 659.77it/s]
Adding requests:   5%|         | 199/4096 [00:00<00:06, 578.84it/s]
Adding requests:   6%|         | 258/4096 [00:00<00:06, 570.27it/s]
Adding requests:   8%|         | 316/4096 [00:00<00:06, 556.17it/s]
Adding requests:   9%|         | 372/4096 [00:00<00:06, 554.79it/s]
Adding requests:  10%|         | 428/4096 [00:00<00:06, 545.92it/s]
Adding requests:  12%|        | 483/4096 [00:00<00:06, 545.19it/s]
Adding requests:  13%|        | 538/4096 [00:00<00:06, 527.12it/s]
Adding requests:  14%|        | 593/4096 [00:01<00:06, 529.64it/s]
Adding requests:  16%|        | 647/4096 [00:01<00:06, 529.89it/s]
Adding requests:  17%|        | 701/4096 [00:01<00:06, 529.98it/s]
Adding requests:  18%|        | 755/4096 [00:01<00:06, 528.90it/s]
Adding requests:  20%|        | 808/4096 [00:01<00:06, 524.40it/s]
Adding requests:  21%|        | 861/4096 [00:01<00:06, 518.01it/s]
Adding requests:  22%|       | 916/4096 [00:01<00:06, 525.57it/s]
Adding requests:  24%|       | 974/4096 [00:01<00:05, 537.91it/s]
Adding requests:  25%|       | 1028/4096 [00:01<00:05, 527.07it/s]
Adding requests:  26%|       | 1082/4096 [00:01<00:05, 528.85it/s]
Adding requests:  28%|       | 1135/4096 [00:02<00:05, 522.31it/s]
Adding requests:  29%|       | 1188/4096 [00:02<00:05, 510.27it/s]
Adding requests:  30%|       | 1240/4096 [00:02<00:05, 509.23it/s]
Adding requests:  32%|      | 1292/4096 [00:02<00:05, 510.26it/s]
Adding requests:  33%|      | 1347/4096 [00:02<00:05, 519.78it/s]
Adding requests:  34%|      | 1403/4096 [00:02<00:05, 528.78it/s]
Adding requests:  36%|      | 1456/4096 [00:02<00:05, 523.07it/s]
Adding requests:  37%|      | 1512/4096 [00:02<00:04, 533.80it/s]
Adding requests:  38%|      | 1568/4096 [00:02<00:04, 541.35it/s]
Adding requests:  40%|      | 1623/4096 [00:03<00:04, 535.74it/s]
Adding requests:  41%|      | 1677/4096 [00:03<00:04, 530.99it/s]
Adding requests:  42%|     | 1732/4096 [00:03<00:04, 535.95it/s]
Adding requests:  44%|     | 1786/4096 [00:03<00:04, 534.21it/s]
Adding requests:  45%|     | 1842/4096 [00:03<00:04, 541.65it/s]
Adding requests:  46%|     | 1897/4096 [00:03<00:04, 537.23it/s]
Adding requests:  48%|     | 1952/4096 [00:03<00:03, 538.59it/s]
Adding requests:  49%|     | 2008/4096 [00:03<00:03, 544.01it/s]
Adding requests:  50%|     | 2063/4096 [00:03<00:03, 539.65it/s]
Adding requests:  52%|    | 2117/4096 [00:03<00:03, 528.98it/s]
Adding requests:  53%|    | 2170/4096 [00:04<00:03, 527.10it/s]
Adding requests:  54%|    | 2223/4096 [00:04<00:03, 521.27it/s]
Adding requests:  56%|    | 2277/4096 [00:04<00:03, 525.50it/s]
Adding requests:  57%|    | 2331/4096 [00:04<00:03, 529.33it/s]
Adding requests:  58%|    | 2384/4096 [00:04<00:03, 528.06it/s]
Adding requests:  59%|    | 2437/4096 [00:04<00:03, 497.73it/s]
Adding requests:  61%|    | 2488/4096 [00:04<00:03, 500.07it/s]
Adding requests:  62%|   | 2541/4096 [00:04<00:03, 506.42it/s]
Adding requests:  63%|   | 2596/4096 [00:04<00:02, 515.51it/s]
Adding requests:  65%|   | 2649/4096 [00:04<00:02, 518.33it/s]
Adding requests:  66%|   | 2702/4096 [00:05<00:02, 520.75it/s]
Adding requests:  67%|   | 2756/4096 [00:05<00:02, 524.53it/s]
Adding requests:  69%|   | 2809/4096 [00:05<00:02, 524.38it/s]
Adding requests:  70%|   | 2864/4096 [00:05<00:02, 531.93it/s]
Adding requests:  71%|  | 2919/4096 [00:05<00:02, 536.04it/s]
Adding requests:  73%|  | 2973/4096 [00:05<00:02, 533.85it/s]
Adding requests:  74%|  | 3027/4096 [00:05<00:02, 529.28it/s]
Adding requests:  75%|  | 3081/4096 [00:05<00:01, 531.79it/s]
Adding requests:  77%|  | 3135/4096 [00:05<00:01, 528.25it/s]
Adding requests:  78%|  | 3191/4096 [00:06<00:01, 536.89it/s]
Adding requests:  79%|  | 3247/4096 [00:06<00:01, 541.15it/s]
Adding requests:  81%|  | 3302/4096 [00:06<00:01, 537.48it/s]
Adding requests:  82%| | 3356/4096 [00:06<00:01, 532.79it/s]
Adding requests:  83%| | 3411/4096 [00:06<00:01, 534.76it/s]
Adding requests:  85%| | 3465/4096 [00:06<00:01, 519.49it/s]
Adding requests:  86%| | 3520/4096 [00:06<00:01, 528.04it/s]
Adding requests:  87%| | 3573/4096 [00:06<00:01, 518.94it/s]
Adding requests:  89%| | 3626/4096 [00:06<00:00, 521.21it/s]
Adding requests:  90%| | 3683/4096 [00:06<00:00, 531.47it/s]
Adding requests:  91%|| 3738/4096 [00:07<00:00, 535.05it/s]
Adding requests:  93%|| 3792/4096 [00:07<00:00, 524.90it/s]
Adding requests:  94%|| 3845/4096 [00:07<00:00, 524.09it/s]
Adding requests:  95%|| 3898/4096 [00:07<00:00, 523.26it/s]
Adding requests:  96%|| 3952/4096 [00:07<00:00, 527.28it/s]
Adding requests:  98%|| 4005/4096 [00:07<00:00, 524.31it/s]
Adding requests:  99%|| 4059/4096 [00:07<00:00, 525.96it/s]
Adding requests: 100%|| 4096/4096 [00:07<00:00, 530.83it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 194/4096 [00:00<00:18, 210.77it/s, est. speed input: 215836.84 toks/s, output: 210.78 toks/s]
Processed prompts:   6%|         | 226/4096 [00:02<00:44, 86.09it/s, est. speed input: 103997.43 toks/s, output: 101.56 toks/s] 
Processed prompts:   6%|         | 258/4096 [00:03<01:05, 58.20it/s, est. speed input: 77053.04 toks/s, output: 75.25 toks/s]  
Processed prompts:   7%|         | 290/4096 [00:04<01:25, 44.34it/s, est. speed input: 63013.52 toks/s, output: 61.54 toks/s]
Processed prompts:   8%|         | 322/4096 [00:05<01:39, 38.06it/s, est. speed input: 55798.99 toks/s, output: 54.49 toks/s]
Processed prompts:   9%|         | 354/4096 [00:07<01:49, 34.24it/s, est. speed input: 51016.67 toks/s, output: 49.82 toks/s]
Processed prompts:   9%|         | 386/4096 [00:08<01:56, 31.73it/s, est. speed input: 47560.19 toks/s, output: 46.45 toks/s]
Processed prompts:  10%|         | 418/4096 [00:09<02:02, 30.11it/s, est. speed input: 44997.87 toks/s, output: 43.94 toks/s]
Processed prompts:  11%|         | 450/4096 [00:10<02:05, 29.13it/s, est. speed input: 43066.17 toks/s, output: 42.06 toks/s]
Processed prompts:  12%|        | 482/4096 [00:11<02:07, 28.33it/s, est. speed input: 41460.89 toks/s, output: 40.49 toks/s]
Processed prompts:  13%|        | 514/4096 [00:13<02:08, 27.80it/s, est. speed input: 40153.37 toks/s, output: 39.21 toks/s]
Processed prompts:  13%|        | 546/4096 [00:14<02:09, 27.37it/s, est. speed input: 39044.09 toks/s, output: 38.13 toks/s]
Processed prompts:  14%|        | 578/4096 [00:15<02:09, 27.11it/s, est. speed input: 38118.06 toks/s, output: 37.22 toks/s]
Processed prompts:  15%|        | 610/4096 [00:16<02:09, 26.99it/s, est. speed input: 37347.78 toks/s, output: 36.47 toks/s]
Processed prompts:  16%|        | 642/4096 [00:17<02:08, 26.86it/s, est. speed input: 36666.55 toks/s, output: 35.81 toks/s]
Processed prompts:  16%|        | 674/4096 [00:19<02:07, 26.79it/s, est. speed input: 36074.44 toks/s, output: 35.23 toks/s]
Processed prompts:  17%|        | 706/4096 [00:20<02:06, 26.73it/s, est. speed input: 35551.13 toks/s, output: 34.72 toks/s]
Processed prompts:  18%|        | 738/4096 [00:21<02:05, 26.68it/s, est. speed input: 35084.93 toks/s, output: 34.26 toks/s]
Processed prompts:  19%|        | 770/4096 [00:22<02:05, 26.61it/s, est. speed input: 34658.31 toks/s, output: 33.85 toks/s]
Processed prompts:  20%|        | 802/4096 [00:23<02:04, 26.55it/s, est. speed input: 34273.91 toks/s, output: 33.47 toks/s]
Processed prompts:  20%|        | 834/4096 [00:25<02:02, 26.55it/s, est. speed input: 33934.02 toks/s, output: 33.14 toks/s]
Processed prompts:  21%|        | 866/4096 [00:26<02:01, 26.54it/s, est. speed input: 33623.04 toks/s, output: 32.83 toks/s]
Processed prompts:  22%|       | 898/4096 [00:27<02:00, 26.52it/s, est. speed input: 33338.48 toks/s, output: 32.56 toks/s]
Processed prompts:  23%|       | 930/4096 [00:28<01:58, 26.65it/s, est. speed input: 33102.58 toks/s, output: 32.33 toks/s]
Processed prompts:  23%|       | 962/4096 [00:29<01:57, 26.77it/s, est. speed input: 32888.28 toks/s, output: 32.12 toks/s]
Processed prompts:  24%|       | 994/4096 [00:31<01:56, 26.69it/s, est. speed input: 32666.07 toks/s, output: 31.90 toks/s]
Processed prompts:  25%|       | 1026/4096 [00:32<01:55, 26.60it/s, est. speed input: 32455.54 toks/s, output: 31.69 toks/s]
Processed prompts:  26%|       | 1058/4096 [00:33<01:54, 26.59it/s, est. speed input: 32265.98 toks/s, output: 31.51 toks/s]
Processed prompts:  27%|       | 1090/4096 [00:34<01:52, 26.60it/s, est. speed input: 32094.07 toks/s, output: 31.34 toks/s]
Processed prompts:  27%|       | 1122/4096 [00:35<01:51, 26.58it/s, est. speed input: 31928.90 toks/s, output: 31.18 toks/s]
Processed prompts:  28%|       | 1154/4096 [00:37<01:50, 26.72it/s, est. speed input: 31794.24 toks/s, output: 31.05 toks/s]
Processed prompts:  29%|       | 1186/4096 [00:38<01:49, 26.64it/s, est. speed input: 31645.73 toks/s, output: 30.90 toks/s]
Processed prompts:  30%|       | 1218/4096 [00:39<01:48, 26.59it/s, est. speed input: 31507.59 toks/s, output: 30.77 toks/s]
Processed prompts:  31%|       | 1250/4096 [00:40<01:46, 26.72it/s, est. speed input: 31396.33 toks/s, output: 30.66 toks/s]
Processed prompts:  31%|      | 1282/4096 [00:41<01:44, 26.81it/s, est. speed input: 31290.60 toks/s, output: 30.56 toks/s]
Processed prompts:  32%|      | 1314/4096 [00:43<01:44, 26.73it/s, est. speed input: 31176.02 toks/s, output: 30.45 toks/s]
Processed prompts:  33%|      | 1346/4096 [00:44<01:43, 26.64it/s, est. speed input: 31064.38 toks/s, output: 30.34 toks/s]
Processed prompts:  34%|      | 1378/4096 [00:45<01:42, 26.61it/s, est. speed input: 30960.77 toks/s, output: 30.24 toks/s]
Processed prompts:  34%|      | 1410/4096 [00:46<01:41, 26.58it/s, est. speed input: 30862.90 toks/s, output: 30.14 toks/s]
Processed prompts:  35%|      | 1442/4096 [00:47<01:39, 26.56it/s, est. speed input: 30769.36 toks/s, output: 30.05 toks/s]
Processed prompts:  36%|      | 1474/4096 [00:49<01:38, 26.54it/s, est. speed input: 30679.71 toks/s, output: 29.96 toks/s]
Processed prompts:  37%|      | 1506/4096 [00:50<01:37, 26.52it/s, est. speed input: 30594.42 toks/s, output: 29.88 toks/s]
Processed prompts:  38%|      | 1538/4096 [00:51<01:36, 26.53it/s, est. speed input: 30514.92 toks/s, output: 29.80 toks/s]
Processed prompts:  38%|      | 1570/4096 [00:52<01:34, 26.67it/s, est. speed input: 30450.91 toks/s, output: 29.74 toks/s]
Processed prompts:  39%|      | 1602/4096 [00:54<01:33, 26.61it/s, est. speed input: 30376.13 toks/s, output: 29.66 toks/s]
Processed prompts:  40%|      | 1634/4096 [00:55<01:32, 26.74it/s, est. speed input: 30318.59 toks/s, output: 29.61 toks/s]
Processed prompts:  41%|      | 1666/4096 [00:56<01:31, 26.67it/s, est. speed input: 30250.33 toks/s, output: 29.54 toks/s]
Processed prompts:  41%|     | 1698/4096 [00:57<01:30, 26.62it/s, est. speed input: 30184.99 toks/s, output: 29.48 toks/s]
Processed prompts:  42%|     | 1730/4096 [00:58<01:29, 26.56it/s, est. speed input: 30120.83 toks/s, output: 29.41 toks/s]
Processed prompts:  43%|     | 1762/4096 [01:00<01:28, 26.51it/s, est. speed input: 30058.26 toks/s, output: 29.35 toks/s]
Processed prompts:  44%|     | 1794/4096 [01:01<01:26, 26.53it/s, est. speed input: 30002.09 toks/s, output: 29.30 toks/s]
Processed prompts:  45%|     | 1826/4096 [01:02<01:25, 26.52it/s, est. speed input: 29946.58 toks/s, output: 29.24 toks/s]
Processed prompts:  45%|     | 1858/4096 [01:03<01:23, 26.70it/s, est. speed input: 29906.49 toks/s, output: 29.21 toks/s]
Processed prompts:  46%|     | 1890/4096 [01:04<01:22, 26.65it/s, est. speed input: 29855.75 toks/s, output: 29.16 toks/s]
Processed prompts:  47%|     | 1922/4096 [01:06<01:21, 26.58it/s, est. speed input: 29804.24 toks/s, output: 29.11 toks/s]
Processed prompts:  48%|     | 1954/4096 [01:07<01:20, 26.69it/s, est. speed input: 29765.13 toks/s, output: 29.07 toks/s]
Processed prompts:  48%|     | 1986/4096 [01:08<01:17, 27.22it/s, est. speed input: 29756.24 toks/s, output: 29.06 toks/s]
Processed prompts:  49%|     | 2018/4096 [01:09<01:17, 26.95it/s, est. speed input: 29707.92 toks/s, output: 29.01 toks/s]
Processed prompts:  50%|     | 2050/4096 [01:10<01:15, 27.15it/s, est. speed input: 29684.41 toks/s, output: 28.99 toks/s]
Processed prompts:  51%|     | 2082/4096 [01:11<01:14, 27.10it/s, est. speed input: 29650.73 toks/s, output: 28.96 toks/s]
Processed prompts:  52%|    | 2114/4096 [01:13<01:13, 26.92it/s, est. speed input: 29609.58 toks/s, output: 28.92 toks/s]
Processed prompts:  52%|    | 2146/4096 [01:14<01:12, 26.78it/s, est. speed input: 29568.52 toks/s, output: 28.88 toks/s]
Processed prompts:  53%|    | 2178/4096 [01:15<01:10, 27.07it/s, est. speed input: 29550.96 toks/s, output: 28.86 toks/s]
Processed prompts:  54%|    | 2210/4096 [01:16<01:09, 27.33it/s, est. speed input: 29537.43 toks/s, output: 28.85 toks/s]
Processed prompts:  55%|    | 2242/4096 [01:17<01:08, 27.07it/s, est. speed input: 29499.58 toks/s, output: 28.81 toks/s]
Processed prompts:  56%|    | 2274/4096 [01:19<01:07, 27.06it/s, est. speed input: 29472.35 toks/s, output: 28.78 toks/s]
Processed prompts:  56%|    | 2306/4096 [01:20<01:06, 27.05it/s, est. speed input: 29445.75 toks/s, output: 28.76 toks/s]
Processed prompts:  57%|    | 2338/4096 [01:21<01:05, 27.02it/s, est. speed input: 29419.12 toks/s, output: 28.73 toks/s]
Processed prompts:  58%|    | 2370/4096 [01:22<01:02, 27.54it/s, est. speed input: 29420.37 toks/s, output: 28.73 toks/s]
Processed prompts:  59%|    | 2402/4096 [01:23<01:01, 27.40it/s, est. speed input: 29396.27 toks/s, output: 28.71 toks/s]
Processed prompts:  59%|    | 2434/4096 [01:24<01:00, 27.27it/s, est. speed input: 29371.53 toks/s, output: 28.68 toks/s]
Processed prompts:  60%|    | 2466/4096 [01:26<00:59, 27.18it/s, est. speed input: 29347.49 toks/s, output: 28.66 toks/s]
Processed prompts:  61%|    | 2498/4096 [01:27<00:58, 27.15it/s, est. speed input: 29325.75 toks/s, output: 28.64 toks/s]
Processed prompts:  62%|   | 2530/4096 [01:28<00:58, 26.96it/s, est. speed input: 29296.26 toks/s, output: 28.61 toks/s]
Processed prompts:  63%|   | 2562/4096 [01:29<00:56, 26.99it/s, est. speed input: 29275.45 toks/s, output: 28.59 toks/s]
Processed prompts:  63%|   | 2594/4096 [01:30<00:55, 26.97it/s, est. speed input: 29252.96 toks/s, output: 28.57 toks/s]
Processed prompts:  64%|   | 2626/4096 [01:32<00:54, 26.81it/s, est. speed input: 29224.27 toks/s, output: 28.54 toks/s]
Processed prompts:  65%|   | 2658/4096 [01:33<00:53, 26.73it/s, est. speed input: 29197.90 toks/s, output: 28.51 toks/s]
Processed prompts:  66%|   | 2690/4096 [01:34<00:51, 27.06it/s, est. speed input: 29189.66 toks/s, output: 28.51 toks/s]
Processed prompts:  66%|   | 2722/4096 [01:35<00:51, 26.86it/s, est. speed input: 29162.54 toks/s, output: 28.48 toks/s]
Processed prompts:  67%|   | 2754/4096 [01:36<00:49, 26.93it/s, est. speed input: 29145.36 toks/s, output: 28.46 toks/s]
Processed prompts:  68%|   | 2786/4096 [01:37<00:48, 26.84it/s, est. speed input: 29122.48 toks/s, output: 28.44 toks/s]
Processed prompts:  69%|   | 2818/4096 [01:39<00:47, 27.12it/s, est. speed input: 29114.71 toks/s, output: 28.43 toks/s]
Processed prompts:  70%|   | 2850/4096 [01:40<00:45, 27.11it/s, est. speed input: 29098.44 toks/s, output: 28.42 toks/s]
Processed prompts:  70%|   | 2882/4096 [01:41<00:45, 26.89it/s, est. speed input: 29073.52 toks/s, output: 28.39 toks/s]
Processed prompts:  71%|   | 2914/4096 [01:42<00:44, 26.76it/s, est. speed input: 29050.44 toks/s, output: 28.37 toks/s]
Processed prompts:  72%|  | 2946/4096 [01:43<00:42, 26.83it/s, est. speed input: 29034.33 toks/s, output: 28.35 toks/s]
Processed prompts:  73%|  | 2978/4096 [01:45<00:41, 26.73it/s, est. speed input: 29012.35 toks/s, output: 28.33 toks/s]
Processed prompts:  73%|  | 3010/4096 [01:46<00:40, 27.04it/s, est. speed input: 29006.57 toks/s, output: 28.33 toks/s]
Processed prompts:  74%|  | 3042/4096 [01:47<00:39, 27.03it/s, est. speed input: 28991.40 toks/s, output: 28.31 toks/s]
Processed prompts:  75%|  | 3074/4096 [01:48<00:38, 26.87it/s, est. speed input: 28970.89 toks/s, output: 28.29 toks/s]
Processed prompts:  76%|  | 3106/4096 [01:49<00:36, 27.40it/s, est. speed input: 28975.36 toks/s, output: 28.30 toks/s]
Processed prompts:  77%|  | 3138/4096 [01:50<00:34, 27.56it/s, est. speed input: 28971.58 toks/s, output: 28.29 toks/s]
Processed prompts:  77%|  | 3170/4096 [01:52<00:34, 27.19it/s, est. speed input: 28950.25 toks/s, output: 28.27 toks/s]
Processed prompts:  78%|  | 3202/4096 [01:53<00:32, 27.42it/s, est. speed input: 28947.19 toks/s, output: 28.27 toks/s]
Processed prompts:  79%|  | 3234/4096 [01:54<00:31, 27.28it/s, est. speed input: 28933.10 toks/s, output: 28.25 toks/s]
Processed prompts:  80%|  | 3266/4096 [01:55<00:30, 27.04it/s, est. speed input: 28914.43 toks/s, output: 28.24 toks/s]
Processed prompts:  81%|  | 3298/4096 [01:56<00:29, 27.07it/s, est. speed input: 28902.90 toks/s, output: 28.23 toks/s]
Processed prompts:  81%| | 3330/4096 [01:57<00:28, 27.28it/s, est. speed input: 28898.67 toks/s, output: 28.22 toks/s]
Processed prompts:  82%| | 3362/4096 [01:59<00:27, 27.03it/s, est. speed input: 28880.32 toks/s, output: 28.20 toks/s]
Processed prompts:  83%| | 3394/4096 [02:00<00:26, 26.87it/s, est. speed input: 28863.06 toks/s, output: 28.19 toks/s]
Processed prompts:  84%| | 3426/4096 [02:01<00:24, 26.91it/s, est. speed input: 28851.26 toks/s, output: 28.18 toks/s]
Processed prompts:  84%| | 3458/4096 [02:02<00:23, 26.92it/s, est. speed input: 28839.04 toks/s, output: 28.16 toks/s]
Processed prompts:  85%| | 3490/4096 [02:03<00:22, 27.21it/s, est. speed input: 28836.53 toks/s, output: 28.16 toks/s]
Processed prompts:  86%| | 3522/4096 [02:05<00:21, 27.02it/s, est. speed input: 28820.99 toks/s, output: 28.15 toks/s]
Processed prompts:  87%| | 3554/4096 [02:06<00:20, 26.86it/s, est. speed input: 28804.95 toks/s, output: 28.13 toks/s]
Processed prompts:  88%| | 3586/4096 [02:07<00:19, 26.75it/s, est. speed input: 28789.22 toks/s, output: 28.11 toks/s]
Processed prompts:  88%| | 3618/4096 [02:08<00:17, 26.67it/s, est. speed input: 28773.32 toks/s, output: 28.10 toks/s]
Processed prompts:  89%| | 3650/4096 [02:09<00:16, 26.74it/s, est. speed input: 28762.26 toks/s, output: 28.09 toks/s]
Processed prompts:  90%| | 3682/4096 [02:11<00:15, 26.86it/s, est. speed input: 28753.41 toks/s, output: 28.08 toks/s]
Processed prompts:  91%| | 3714/4096 [02:12<00:14, 26.94it/s, est. speed input: 28744.70 toks/s, output: 28.07 toks/s]
Processed prompts:  91%|| 3746/4096 [02:13<00:13, 26.76it/s, est. speed input: 28728.76 toks/s, output: 28.06 toks/s]
Processed prompts:  92%|| 3778/4096 [02:14<00:11, 26.68it/s, est. speed input: 28714.49 toks/s, output: 28.04 toks/s]
Processed prompts:  93%|| 3810/4096 [02:15<00:10, 26.80it/s, est. speed input: 28705.83 toks/s, output: 28.03 toks/s]
Processed prompts:  94%|| 3842/4096 [02:17<00:09, 27.10it/s, est. speed input: 28704.15 toks/s, output: 28.03 toks/s]
Processed prompts:  95%|| 3874/4096 [02:18<00:08, 26.94it/s, est. speed input: 28691.22 toks/s, output: 28.02 toks/s]
Processed prompts:  95%|| 3906/4096 [02:19<00:07, 26.79it/s, est. speed input: 28677.17 toks/s, output: 28.01 toks/s]
Processed prompts:  96%|| 3938/4096 [02:20<00:05, 26.86it/s, est. speed input: 28668.73 toks/s, output: 28.00 toks/s]
Processed prompts:  97%|| 3970/4096 [02:21<00:04, 26.77it/s, est. speed input: 28656.12 toks/s, output: 27.98 toks/s]
Processed prompts:  98%|| 4002/4096 [02:23<00:03, 26.65it/s, est. speed input: 28642.18 toks/s, output: 27.97 toks/s]
Processed prompts:  98%|| 4034/4096 [02:24<00:02, 27.26it/s, est. speed input: 28648.84 toks/s, output: 27.98 toks/s]
Processed prompts:  99%|| 4066/4096 [02:25<00:01, 27.20it/s, est. speed input: 28641.06 toks/s, output: 27.97 toks/s]
Processed prompts: 100%|| 4096/4096 [02:25<00:00, 27.20it/s, est. speed input: 28852.33 toks/s, output: 28.18 toks/s]
Processed prompts: 100%|| 4096/4096 [02:25<00:00, 28.18it/s, est. speed input: 28852.33 toks/s, output: 28.18 toks/s]
[rank0]:[W126 03:48:34.877052621 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 03:48:37
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:49:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:49:03 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=823565) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=823565) WARNING 01-26 03:49:29 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 26.73 requests/s, 27397.68 total tokens/s, 26.73 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 03:49:02] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:49:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:49:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:49:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:49:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:49:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:49:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:49:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:49:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:49:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:49:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:49:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:49:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:49:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:49:06] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:49:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:49:06] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:49:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:49:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:49:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:49:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:49:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:49:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:49:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:49:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:49:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:49:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:49:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=823565) [2026-01-26 03:49:07] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=823565) [2026-01-26 03:49:07] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=823565) [2026-01-26 03:49:07] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=823565) [2026-01-26 03:49:07] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=823565) [2026-01-26 03:49:07] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=823565) [2026-01-26 03:49:07] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=823565) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=823565) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 11.00s/it]
(EngineCore_DP0 pid=823565) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 11.00s/it]
(EngineCore_DP0 pid=823565) 
(EngineCore_DP0 pid=823565) [2026-01-26 03:49:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=823565) [2026-01-26 03:49:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=823565) [2026-01-26 03:49:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=823565) [2026-01-26 03:49:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=823565) [2026-01-26 03:49:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=823565) [2026-01-26 03:49:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=823565) [2026-01-26 03:49:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=823565) [2026-01-26 03:49:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=823565) 2026-01-26 03:49:26,536 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=823565) 2026-01-26 03:49:26,789 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 68/8192 [00:00<00:12, 666.47it/s]
Adding requests:   2%|         | 135/8192 [00:00<00:14, 543.82it/s]
Adding requests:   2%|         | 193/8192 [00:00<00:14, 557.06it/s]
Adding requests:   3%|         | 255/8192 [00:00<00:13, 578.98it/s]
Adding requests:   4%|         | 314/8192 [00:00<00:13, 577.67it/s]
Adding requests:   5%|         | 379/8192 [00:00<00:13, 600.31it/s]
Adding requests:   5%|         | 443/8192 [00:00<00:12, 612.32it/s]
Adding requests:   6%|         | 505/8192 [00:00<00:12, 614.57it/s]
Adding requests:   7%|         | 569/8192 [00:00<00:12, 619.66it/s]
Adding requests:   8%|         | 633/8192 [00:01<00:12, 624.93it/s]
Adding requests:   9%|         | 700/8192 [00:01<00:11, 637.17it/s]
Adding requests:   9%|         | 766/8192 [00:01<00:11, 643.79it/s]
Adding requests:  10%|         | 831/8192 [00:01<00:11, 633.26it/s]
Adding requests:  11%|         | 895/8192 [00:01<00:11, 632.70it/s]
Adding requests:  12%|        | 959/8192 [00:01<00:12, 594.78it/s]
Adding requests:  12%|        | 1019/8192 [00:01<00:12, 567.47it/s]
Adding requests:  13%|        | 1077/8192 [00:01<00:12, 555.44it/s]
Adding requests:  14%|        | 1133/8192 [00:01<00:13, 536.37it/s]
Adding requests:  14%|        | 1187/8192 [00:02<00:13, 536.74it/s]
Adding requests:  15%|        | 1245/8192 [00:02<00:12, 547.04it/s]
Adding requests:  16%|        | 1300/8192 [00:02<00:12, 546.23it/s]
Adding requests:  17%|        | 1363/8192 [00:02<00:11, 570.48it/s]
Adding requests:  18%|        | 1434/8192 [00:02<00:11, 609.28it/s]
Adding requests:  18%|        | 1507/8192 [00:02<00:10, 644.53it/s]
Adding requests:  19%|        | 1572/8192 [00:02<00:10, 631.42it/s]
Adding requests:  20%|        | 1638/8192 [00:02<00:10, 639.11it/s]
Adding requests:  21%|        | 1708/8192 [00:02<00:09, 656.68it/s]
Adding requests:  22%|       | 1774/8192 [00:02<00:09, 655.92it/s]
Adding requests:  22%|       | 1840/8192 [00:03<00:10, 629.13it/s]
Adding requests:  23%|       | 1904/8192 [00:03<00:10, 621.71it/s]
Adding requests:  24%|       | 1967/8192 [00:03<00:11, 561.60it/s]
Adding requests:  25%|       | 2034/8192 [00:03<00:10, 590.47it/s]
Adding requests:  26%|       | 2095/8192 [00:03<00:10, 585.29it/s]
Adding requests:  26%|       | 2155/8192 [00:03<00:10, 559.43it/s]
Adding requests:  27%|       | 2224/8192 [00:03<00:10, 593.23it/s]
Adding requests:  28%|       | 2285/8192 [00:03<00:10, 559.57it/s]
Adding requests:  29%|       | 2346/8192 [00:03<00:10, 571.31it/s]
Adding requests:  29%|       | 2404/8192 [00:04<00:10, 555.34it/s]
Adding requests:  30%|       | 2461/8192 [00:04<00:10, 546.23it/s]
Adding requests:  31%|       | 2518/8192 [00:04<00:10, 549.54it/s]
Adding requests:  31%|      | 2574/8192 [00:04<00:10, 539.50it/s]
Adding requests:  32%|      | 2629/8192 [00:04<00:10, 538.66it/s]
Adding requests:  33%|      | 2685/8192 [00:04<00:10, 542.48it/s]
Adding requests:  33%|      | 2740/8192 [00:04<00:10, 540.02it/s]
Adding requests:  34%|      | 2795/8192 [00:04<00:10, 532.21it/s]
Adding requests:  35%|      | 2849/8192 [00:04<00:10, 513.39it/s]
Adding requests:  35%|      | 2902/8192 [00:05<00:10, 515.80it/s]
Adding requests:  36%|      | 2954/8192 [00:05<00:10, 513.46it/s]
Adding requests:  37%|      | 3006/8192 [00:05<00:10, 509.74it/s]
Adding requests:  37%|      | 3061/8192 [00:05<00:09, 520.28it/s]
Adding requests:  38%|      | 3114/8192 [00:05<00:09, 512.70it/s]
Adding requests:  39%|      | 3166/8192 [00:05<00:09, 510.49it/s]
Adding requests:  39%|      | 3218/8192 [00:05<00:09, 506.23it/s]
Adding requests:  40%|      | 3269/8192 [00:05<00:09, 497.78it/s]
Adding requests:  41%|      | 3323/8192 [00:05<00:09, 509.98it/s]
Adding requests:  41%|      | 3378/8192 [00:05<00:09, 518.38it/s]
Adding requests:  42%|     | 3430/8192 [00:06<00:09, 513.07it/s]
Adding requests:  43%|     | 3482/8192 [00:06<00:09, 503.18it/s]
Adding requests:  43%|     | 3536/8192 [00:06<00:09, 509.96it/s]
Adding requests:  44%|     | 3589/8192 [00:06<00:08, 514.07it/s]
Adding requests:  44%|     | 3641/8192 [00:06<00:08, 509.66it/s]
Adding requests:  45%|     | 3694/8192 [00:06<00:08, 513.56it/s]
Adding requests:  46%|     | 3748/8192 [00:06<00:08, 520.61it/s]
Adding requests:  46%|     | 3801/8192 [00:06<00:08, 520.50it/s]
Adding requests:  47%|     | 3855/8192 [00:06<00:08, 524.64it/s]
Adding requests:  48%|     | 3908/8192 [00:06<00:08, 523.53it/s]
Adding requests:  48%|     | 3961/8192 [00:07<00:08, 515.12it/s]
Adding requests:  49%|     | 4014/8192 [00:07<00:08, 517.15it/s]
Adding requests:  50%|     | 4066/8192 [00:07<00:08, 511.48it/s]
Adding requests:  50%|     | 4118/8192 [00:07<00:08, 505.96it/s]
Adding requests:  51%|     | 4171/8192 [00:07<00:07, 511.40it/s]
Adding requests:  52%|    | 4228/8192 [00:07<00:07, 528.47it/s]
Adding requests:  52%|    | 4281/8192 [00:07<00:07, 519.40it/s]
Adding requests:  53%|    | 4338/8192 [00:07<00:07, 533.20it/s]
Adding requests:  54%|    | 4396/8192 [00:07<00:06, 543.73it/s]
Adding requests:  54%|    | 4451/8192 [00:08<00:07, 532.28it/s]
Adding requests:  55%|    | 4505/8192 [00:08<00:06, 533.52it/s]
Adding requests:  56%|    | 4559/8192 [00:08<00:06, 531.83it/s]
Adding requests:  56%|    | 4613/8192 [00:08<00:06, 511.80it/s]
Adding requests:  57%|    | 4665/8192 [00:08<00:06, 511.38it/s]
Adding requests:  58%|    | 4720/8192 [00:08<00:06, 519.72it/s]
Adding requests:  58%|    | 4777/8192 [00:08<00:06, 534.18it/s]
Adding requests:  59%|    | 4831/8192 [00:08<00:06, 530.08it/s]
Adding requests:  60%|    | 4885/8192 [00:08<00:06, 524.07it/s]
Adding requests:  60%|    | 4942/8192 [00:08<00:06, 535.16it/s]
Adding requests:  61%|    | 4996/8192 [00:09<00:06, 522.39it/s]
Adding requests:  62%|   | 5052/8192 [00:09<00:05, 532.78it/s]
Adding requests:  62%|   | 5110/8192 [00:09<00:05, 546.45it/s]
Adding requests:  63%|   | 5165/8192 [00:09<00:05, 541.01it/s]
Adding requests:  64%|   | 5220/8192 [00:09<00:05, 540.31it/s]
Adding requests:  64%|   | 5275/8192 [00:09<00:05, 538.72it/s]
Adding requests:  65%|   | 5330/8192 [00:09<00:05, 537.57it/s]
Adding requests:  66%|   | 5385/8192 [00:09<00:05, 539.52it/s]
Adding requests:  66%|   | 5441/8192 [00:09<00:05, 543.58it/s]
Adding requests:  67%|   | 5496/8192 [00:09<00:04, 541.46it/s]
Adding requests:  68%|   | 5551/8192 [00:10<00:05, 518.18it/s]
Adding requests:  68%|   | 5607/8192 [00:10<00:04, 527.74it/s]
Adding requests:  69%|   | 5662/8192 [00:10<00:04, 533.98it/s]
Adding requests:  70%|   | 5717/8192 [00:10<00:04, 538.22it/s]
Adding requests:  70%|   | 5774/8192 [00:10<00:04, 544.17it/s]
Adding requests:  71%|   | 5831/8192 [00:10<00:04, 550.45it/s]
Adding requests:  72%|  | 5887/8192 [00:10<00:04, 544.30it/s]
Adding requests:  73%|  | 5943/8192 [00:10<00:04, 548.80it/s]
Adding requests:  73%|  | 5998/8192 [00:10<00:04, 515.72it/s]
Adding requests:  74%|  | 6055/8192 [00:11<00:04, 529.04it/s]
Adding requests:  75%|  | 6112/8192 [00:11<00:03, 536.35it/s]
Adding requests:  75%|  | 6170/8192 [00:11<00:03, 546.02it/s]
Adding requests:  76%|  | 6230/8192 [00:11<00:03, 559.10it/s]
Adding requests:  77%|  | 6287/8192 [00:11<00:03, 561.54it/s]
Adding requests:  77%|  | 6345/8192 [00:11<00:03, 566.84it/s]
Adding requests:  78%|  | 6405/8192 [00:11<00:03, 575.15it/s]
Adding requests:  79%|  | 6463/8192 [00:11<00:03, 563.55it/s]
Adding requests:  80%|  | 6522/8192 [00:11<00:02, 570.62it/s]
Adding requests:  80%|  | 6581/8192 [00:11<00:02, 572.11it/s]
Adding requests:  81%|  | 6639/8192 [00:12<00:02, 551.26it/s]
Adding requests:  82%| | 6695/8192 [00:12<00:02, 552.01it/s]
Adding requests:  82%| | 6752/8192 [00:12<00:02, 554.96it/s]
Adding requests:  83%| | 6808/8192 [00:12<00:02, 550.78it/s]
Adding requests:  84%| | 6864/8192 [00:12<00:02, 551.49it/s]
Adding requests:  85%| | 6926/8192 [00:12<00:02, 569.87it/s]
Adding requests:  85%| | 6984/8192 [00:12<00:02, 555.28it/s]
Adding requests:  86%| | 7040/8192 [00:12<00:02, 554.53it/s]
Adding requests:  87%| | 7096/8192 [00:12<00:01, 551.46it/s]
Adding requests:  87%| | 7152/8192 [00:12<00:01, 549.19it/s]
Adding requests:  88%| | 7209/8192 [00:13<00:01, 552.76it/s]
Adding requests:  89%| | 7266/8192 [00:13<00:01, 555.95it/s]
Adding requests:  89%| | 7322/8192 [00:13<00:01, 539.50it/s]
Adding requests:  90%| | 7377/8192 [00:13<00:01, 528.48it/s]
Adding requests:  91%| | 7436/8192 [00:13<00:01, 544.76it/s]
Adding requests:  91%|| 7495/8192 [00:13<00:01, 556.14it/s]
Adding requests:  92%|| 7551/8192 [00:13<00:01, 547.21it/s]
Adding requests:  93%|| 7606/8192 [00:13<00:01, 542.94it/s]
Adding requests:  94%|| 7666/8192 [00:13<00:00, 557.16it/s]
Adding requests:  94%|| 7722/8192 [00:14<00:00, 548.79it/s]
Adding requests:  95%|| 7779/8192 [00:14<00:00, 553.91it/s]
Adding requests:  96%|| 7837/8192 [00:14<00:00, 559.03it/s]
Adding requests:  96%|| 7893/8192 [00:14<00:00, 555.90it/s]
Adding requests:  97%|| 7949/8192 [00:14<00:00, 550.21it/s]
Adding requests:  98%|| 8005/8192 [00:14<00:00, 550.50it/s]
Adding requests:  98%|| 8061/8192 [00:14<00:00, 538.87it/s]
Adding requests:  99%|| 8119/8192 [00:14<00:00, 548.06it/s]
Adding requests: 100%|| 8176/8192 [00:14<00:00, 551.25it/s]
Adding requests: 100%|| 8192/8192 [00:14<00:00, 550.75it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|         | 322/8192 [00:01<00:47, 166.15it/s, est. speed input: 170143.98 toks/s, output: 166.15 toks/s]
Processed prompts:   5%|         | 386/8192 [00:04<01:41, 77.02it/s, est. speed input: 91100.11 toks/s, output: 88.96 toks/s]   
Processed prompts:   5%|         | 450/8192 [00:06<02:25, 53.07it/s, est. speed input: 68449.75 toks/s, output: 66.85 toks/s]
Processed prompts:   6%|         | 514/8192 [00:09<03:01, 42.39it/s, est. speed input: 57664.73 toks/s, output: 56.31 toks/s]
Processed prompts:   7%|         | 578/8192 [00:11<03:27, 36.63it/s, est. speed input: 51351.40 toks/s, output: 50.15 toks/s]
Processed prompts:   8%|         | 642/8192 [00:13<03:47, 33.18it/s, est. speed input: 47192.00 toks/s, output: 46.09 toks/s]
Processed prompts:   9%|         | 706/8192 [00:16<04:01, 30.96it/s, est. speed input: 44220.93 toks/s, output: 43.18 toks/s]
Processed prompts:   9%|         | 770/8192 [00:18<04:10, 29.60it/s, est. speed input: 42066.12 toks/s, output: 41.08 toks/s]
Processed prompts:  10%|         | 834/8192 [00:21<04:16, 28.68it/s, est. speed input: 40389.01 toks/s, output: 39.44 toks/s]
Processed prompts:  11%|         | 898/8192 [00:23<04:19, 28.12it/s, est. speed input: 39083.23 toks/s, output: 38.17 toks/s]
Processed prompts:  12%|        | 962/8192 [00:25<04:20, 27.73it/s, est. speed input: 38016.25 toks/s, output: 37.13 toks/s]
Processed prompts:  13%|        | 1026/8192 [00:28<04:21, 27.40it/s, est. speed input: 37105.42 toks/s, output: 36.24 toks/s]
Processed prompts:  13%|        | 1090/8192 [00:30<04:21, 27.16it/s, est. speed input: 36333.16 toks/s, output: 35.48 toks/s]
Processed prompts:  14%|        | 1154/8192 [00:33<04:20, 27.06it/s, est. speed input: 35696.57 toks/s, output: 34.86 toks/s]
Processed prompts:  15%|        | 1218/8192 [00:35<04:18, 27.01it/s, est. speed input: 35148.24 toks/s, output: 34.32 toks/s]
Processed prompts:  16%|        | 1282/8192 [00:37<04:16, 26.94it/s, est. speed input: 34662.05 toks/s, output: 33.85 toks/s]
Processed prompts:  16%|        | 1346/8192 [00:40<04:14, 26.86it/s, est. speed input: 34224.60 toks/s, output: 33.42 toks/s]
Processed prompts:  17%|        | 1410/8192 [00:42<04:13, 26.79it/s, est. speed input: 33830.94 toks/s, output: 33.04 toks/s]
Processed prompts:  18%|        | 1474/8192 [00:45<04:11, 26.74it/s, est. speed input: 33481.51 toks/s, output: 32.70 toks/s]
Processed prompts:  19%|        | 1538/8192 [00:47<04:08, 26.74it/s, est. speed input: 33174.99 toks/s, output: 32.40 toks/s]
Processed prompts:  20%|        | 1602/8192 [00:49<04:06, 26.76it/s, est. speed input: 32900.43 toks/s, output: 32.13 toks/s]
Processed prompts:  20%|        | 1666/8192 [00:52<04:04, 26.69it/s, est. speed input: 32635.72 toks/s, output: 31.87 toks/s]
Processed prompts:  21%|        | 1730/8192 [00:54<04:02, 26.70it/s, est. speed input: 32403.84 toks/s, output: 31.64 toks/s]
Processed prompts:  22%|       | 1794/8192 [00:57<03:59, 26.67it/s, est. speed input: 32186.50 toks/s, output: 31.43 toks/s]
Processed prompts:  23%|       | 1858/8192 [00:59<03:57, 26.71it/s, est. speed input: 31996.80 toks/s, output: 31.25 toks/s]
Processed prompts:  23%|       | 1922/8192 [01:01<03:54, 26.72it/s, est. speed input: 31818.45 toks/s, output: 31.07 toks/s]
Processed prompts:  24%|       | 1986/8192 [01:04<03:50, 26.98it/s, est. speed input: 31689.61 toks/s, output: 30.95 toks/s]
Processed prompts:  25%|       | 2050/8192 [01:06<03:46, 27.14it/s, est. speed input: 31567.84 toks/s, output: 30.83 toks/s]
Processed prompts:  26%|       | 2114/8192 [01:08<03:45, 26.99it/s, est. speed input: 31417.44 toks/s, output: 30.68 toks/s]
Processed prompts:  27%|       | 2178/8192 [01:11<03:40, 27.28it/s, est. speed input: 31328.75 toks/s, output: 30.59 toks/s]
Processed prompts:  27%|       | 2242/8192 [01:13<03:39, 27.14it/s, est. speed input: 31203.25 toks/s, output: 30.47 toks/s]
Processed prompts:  28%|       | 2306/8192 [01:15<03:36, 27.13it/s, est. speed input: 31096.05 toks/s, output: 30.37 toks/s]
Processed prompts:  29%|       | 2370/8192 [01:18<03:32, 27.39it/s, est. speed input: 31025.68 toks/s, output: 30.30 toks/s]
Processed prompts:  30%|       | 2434/8192 [01:20<03:30, 27.31it/s, est. speed input: 30931.10 toks/s, output: 30.21 toks/s]
Processed prompts:  30%|       | 2498/8192 [01:22<03:29, 27.13it/s, est. speed input: 30827.98 toks/s, output: 30.11 toks/s]
Processed prompts:  31%|      | 2562/8192 [01:25<03:27, 27.13it/s, est. speed input: 30743.49 toks/s, output: 30.02 toks/s]
Processed prompts:  32%|      | 2626/8192 [01:27<03:26, 26.96it/s, est. speed input: 30646.51 toks/s, output: 29.93 toks/s]
Processed prompts:  33%|      | 2690/8192 [01:30<03:23, 27.02it/s, est. speed input: 30572.24 toks/s, output: 29.86 toks/s]
Processed prompts:  34%|      | 2754/8192 [01:32<03:21, 26.97it/s, est. speed input: 30492.89 toks/s, output: 29.78 toks/s]
Processed prompts:  34%|      | 2818/8192 [01:34<03:17, 27.15it/s, est. speed input: 30438.39 toks/s, output: 29.72 toks/s]
Processed prompts:  35%|      | 2882/8192 [01:37<03:16, 26.96it/s, est. speed input: 30356.86 toks/s, output: 29.65 toks/s]
Processed prompts:  36%|      | 2946/8192 [01:39<03:14, 26.91it/s, est. speed input: 30287.12 toks/s, output: 29.58 toks/s]
Processed prompts:  37%|      | 3010/8192 [01:41<03:10, 27.14it/s, est. speed input: 30242.82 toks/s, output: 29.53 toks/s]
Processed prompts:  38%|      | 3074/8192 [01:44<03:07, 27.26it/s, est. speed input: 30197.42 toks/s, output: 29.49 toks/s]
Processed prompts:  38%|      | 3138/8192 [01:46<03:05, 27.23it/s, est. speed input: 30144.84 toks/s, output: 29.44 toks/s]
Processed prompts:  39%|      | 3202/8192 [01:48<03:02, 27.29it/s, est. speed input: 30100.71 toks/s, output: 29.40 toks/s]
Processed prompts:  40%|      | 3266/8192 [01:51<03:01, 27.14it/s, est. speed input: 30043.79 toks/s, output: 29.34 toks/s]
Processed prompts:  41%|      | 3330/8192 [01:53<02:59, 27.15it/s, est. speed input: 29998.05 toks/s, output: 29.29 toks/s]
Processed prompts:  41%|     | 3394/8192 [01:56<02:57, 27.04it/s, est. speed input: 29944.93 toks/s, output: 29.24 toks/s]
Processed prompts:  42%|     | 3458/8192 [01:58<02:54, 27.18it/s, est. speed input: 29910.46 toks/s, output: 29.21 toks/s]
Processed prompts:  43%|     | 3522/8192 [02:00<02:52, 27.03it/s, est. speed input: 29859.14 toks/s, output: 29.16 toks/s]
Processed prompts:  44%|     | 3586/8192 [02:03<02:51, 26.90it/s, est. speed input: 29807.70 toks/s, output: 29.11 toks/s]
Processed prompts:  45%|     | 3650/8192 [02:05<02:48, 26.96it/s, est. speed input: 29769.44 toks/s, output: 29.07 toks/s]
Processed prompts:  45%|     | 3714/8192 [02:07<02:46, 26.88it/s, est. speed input: 29723.77 toks/s, output: 29.03 toks/s]
Processed prompts:  46%|     | 3778/8192 [02:10<02:44, 26.85it/s, est. speed input: 29681.80 toks/s, output: 28.99 toks/s]
Processed prompts:  47%|     | 3842/8192 [02:12<02:41, 26.94it/s, est. speed input: 29648.46 toks/s, output: 28.95 toks/s]
Processed prompts:  48%|     | 3906/8192 [02:15<02:39, 26.89it/s, est. speed input: 29608.49 toks/s, output: 28.91 toks/s]
Processed prompts:  48%|     | 3970/8192 [02:17<02:37, 26.77it/s, est. speed input: 29565.04 toks/s, output: 28.87 toks/s]
Processed prompts:  49%|     | 4034/8192 [02:19<02:34, 27.00it/s, est. speed input: 29542.49 toks/s, output: 28.85 toks/s]
Processed prompts:  50%|     | 4098/8192 [02:22<02:32, 26.92it/s, est. speed input: 29506.01 toks/s, output: 28.81 toks/s]
Processed prompts:  51%|     | 4162/8192 [02:24<02:28, 27.10it/s, est. speed input: 29484.99 toks/s, output: 28.79 toks/s]
Processed prompts:  52%|    | 4226/8192 [02:26<02:26, 27.11it/s, est. speed input: 29457.76 toks/s, output: 28.77 toks/s]
Processed prompts:  52%|    | 4290/8192 [02:29<02:24, 26.99it/s, est. speed input: 29423.76 toks/s, output: 28.73 toks/s]
Processed prompts:  53%|    | 4354/8192 [02:31<02:22, 26.88it/s, est. speed input: 29389.93 toks/s, output: 28.70 toks/s]
Processed prompts:  54%|    | 4418/8192 [02:34<02:19, 26.99it/s, est. speed input: 29367.04 toks/s, output: 28.68 toks/s]
Processed prompts:  55%|    | 4482/8192 [02:36<02:17, 26.89it/s, est. speed input: 29335.29 toks/s, output: 28.65 toks/s]
Processed prompts:  55%|    | 4546/8192 [02:38<02:14, 27.08it/s, est. speed input: 29318.70 toks/s, output: 28.63 toks/s]
Processed prompts:  56%|    | 4610/8192 [02:41<02:12, 27.00it/s, est. speed input: 29291.16 toks/s, output: 28.60 toks/s]
Processed prompts:  57%|    | 4674/8192 [02:43<02:10, 26.87it/s, est. speed input: 29260.23 toks/s, output: 28.57 toks/s]
Processed prompts:  58%|    | 4738/8192 [02:45<02:08, 26.96it/s, est. speed input: 29239.98 toks/s, output: 28.55 toks/s]
Processed prompts:  59%|    | 4802/8192 [02:48<02:05, 26.92it/s, est. speed input: 29215.18 toks/s, output: 28.53 toks/s]
Processed prompts:  59%|    | 4866/8192 [02:50<02:03, 26.89it/s, est. speed input: 29190.75 toks/s, output: 28.51 toks/s]
Processed prompts:  60%|    | 4930/8192 [02:53<02:01, 26.86it/s, est. speed input: 29166.47 toks/s, output: 28.48 toks/s]
Processed prompts:  61%|    | 4994/8192 [02:55<01:58, 26.95it/s, est. speed input: 29148.38 toks/s, output: 28.47 toks/s]
Processed prompts:  62%|   | 5058/8192 [02:57<01:55, 27.16it/s, est. speed input: 29137.54 toks/s, output: 28.45 toks/s]
Processed prompts:  63%|   | 5122/8192 [03:00<01:53, 26.97it/s, est. speed input: 29111.37 toks/s, output: 28.43 toks/s]
Processed prompts:  63%|   | 5186/8192 [03:02<01:50, 27.16it/s, est. speed input: 29100.60 toks/s, output: 28.42 toks/s]
Processed prompts:  64%|   | 5250/8192 [03:04<01:47, 27.28it/s, est. speed input: 29089.49 toks/s, output: 28.41 toks/s]
Processed prompts:  65%|   | 5314/8192 [03:07<01:45, 27.35it/s, est. speed input: 29078.46 toks/s, output: 28.40 toks/s]
Processed prompts:  66%|   | 5378/8192 [03:09<01:43, 27.19it/s, est. speed input: 29058.17 toks/s, output: 28.38 toks/s]
Processed prompts:  66%|   | 5442/8192 [03:11<01:41, 27.15it/s, est. speed input: 29041.60 toks/s, output: 28.36 toks/s]
Processed prompts:  67%|   | 5506/8192 [03:14<01:39, 27.06it/s, est. speed input: 29022.38 toks/s, output: 28.34 toks/s]
Processed prompts:  68%|   | 5570/8192 [03:16<01:37, 26.92it/s, est. speed input: 29000.67 toks/s, output: 28.32 toks/s]
Processed prompts:  69%|   | 5634/8192 [03:19<01:34, 26.98it/s, est. speed input: 28985.99 toks/s, output: 28.31 toks/s]
Processed prompts:  70%|   | 5698/8192 [03:21<01:32, 27.05it/s, est. speed input: 28972.94 toks/s, output: 28.29 toks/s]
Processed prompts:  70%|   | 5762/8192 [03:23<01:30, 26.96it/s, est. speed input: 28954.55 toks/s, output: 28.28 toks/s]
Processed prompts:  71%|   | 5826/8192 [03:26<01:27, 26.94it/s, est. speed input: 28938.04 toks/s, output: 28.26 toks/s]
Processed prompts:  72%|  | 5890/8192 [03:28<01:25, 27.01it/s, est. speed input: 28925.64 toks/s, output: 28.25 toks/s]
Processed prompts:  73%|  | 5954/8192 [03:30<01:23, 26.91it/s, est. speed input: 28907.15 toks/s, output: 28.23 toks/s]
Processed prompts:  73%|  | 6018/8192 [03:33<01:20, 26.85it/s, est. speed input: 28889.75 toks/s, output: 28.21 toks/s]
Processed prompts:  74%|  | 6082/8192 [03:35<01:18, 26.78it/s, est. speed input: 28871.63 toks/s, output: 28.19 toks/s]
Processed prompts:  75%|  | 6146/8192 [03:38<01:15, 27.01it/s, est. speed input: 28864.65 toks/s, output: 28.19 toks/s]
Processed prompts:  76%|  | 6210/8192 [03:40<01:13, 26.97it/s, est. speed input: 28850.30 toks/s, output: 28.17 toks/s]
Processed prompts:  77%|  | 6274/8192 [03:42<01:11, 26.83it/s, est. speed input: 28831.84 toks/s, output: 28.16 toks/s]
Processed prompts:  77%|  | 6338/8192 [03:45<01:08, 26.94it/s, est. speed input: 28821.62 toks/s, output: 28.15 toks/s]
Processed prompts:  78%|  | 6402/8192 [03:47<01:06, 26.88it/s, est. speed input: 28806.42 toks/s, output: 28.13 toks/s]
Processed prompts:  79%|  | 6466/8192 [03:49<01:04, 26.77it/s, est. speed input: 28789.20 toks/s, output: 28.11 toks/s]
Processed prompts:  80%|  | 6530/8192 [03:52<01:01, 26.87it/s, est. speed input: 28778.59 toks/s, output: 28.10 toks/s]
Processed prompts:  80%|  | 6594/8192 [03:54<00:59, 26.84it/s, est. speed input: 28764.62 toks/s, output: 28.09 toks/s]
Processed prompts:  81%| | 6658/8192 [03:57<00:56, 26.94it/s, est. speed input: 28755.56 toks/s, output: 28.08 toks/s]
Processed prompts:  82%| | 6722/8192 [03:59<00:54, 26.84it/s, est. speed input: 28740.18 toks/s, output: 28.07 toks/s]
Processed prompts:  83%| | 6786/8192 [04:01<00:52, 26.80it/s, est. speed input: 28726.43 toks/s, output: 28.05 toks/s]
Processed prompts:  84%| | 6850/8192 [04:04<00:50, 26.80it/s, est. speed input: 28714.00 toks/s, output: 28.04 toks/s]
Processed prompts:  84%| | 6914/8192 [04:06<00:47, 26.82it/s, est. speed input: 28702.36 toks/s, output: 28.03 toks/s]
Processed prompts:  85%| | 6978/8192 [04:09<00:45, 26.92it/s, est. speed input: 28693.86 toks/s, output: 28.02 toks/s]
Processed prompts:  86%| | 7042/8192 [04:11<00:42, 26.89it/s, est. speed input: 28682.23 toks/s, output: 28.01 toks/s]
Processed prompts:  87%| | 7106/8192 [04:13<00:39, 27.22it/s, est. speed input: 28682.48 toks/s, output: 28.01 toks/s]
Processed prompts:  88%| | 7170/8192 [04:16<00:37, 27.09it/s, est. speed input: 28670.72 toks/s, output: 28.00 toks/s]
Processed prompts:  88%| | 7234/8192 [04:18<00:35, 27.12it/s, est. speed input: 28663.12 toks/s, output: 27.99 toks/s]
Processed prompts:  89%| | 7298/8192 [04:20<00:33, 27.00it/s, est. speed input: 28651.36 toks/s, output: 27.98 toks/s]
Processed prompts:  90%| | 7362/8192 [04:23<00:30, 27.03it/s, est. speed input: 28643.16 toks/s, output: 27.97 toks/s]
Processed prompts:  91%| | 7426/8192 [04:25<00:28, 26.95it/s, est. speed input: 28632.14 toks/s, output: 27.96 toks/s]
Processed prompts:  91%|| 7490/8192 [04:27<00:25, 27.13it/s, est. speed input: 28628.64 toks/s, output: 27.96 toks/s]
Processed prompts:  92%|| 7554/8192 [04:30<00:23, 27.27it/s, est. speed input: 28625.54 toks/s, output: 27.95 toks/s]
Processed prompts:  93%|| 7618/8192 [04:32<00:20, 27.51it/s, est. speed input: 28626.60 toks/s, output: 27.96 toks/s]
Processed prompts:  94%|| 7682/8192 [04:34<00:18, 27.26it/s, est. speed input: 28615.39 toks/s, output: 27.94 toks/s]
Processed prompts:  95%|| 7746/8192 [04:37<00:16, 27.13it/s, est. speed input: 28605.51 toks/s, output: 27.94 toks/s]
Processed prompts:  95%|| 7810/8192 [04:39<00:14, 26.97it/s, est. speed input: 28593.71 toks/s, output: 27.92 toks/s]
Processed prompts:  96%|| 7874/8192 [04:42<00:11, 26.87it/s, est. speed input: 28582.48 toks/s, output: 27.91 toks/s]
Processed prompts:  97%|| 7938/8192 [04:44<00:09, 26.83it/s, est. speed input: 28572.38 toks/s, output: 27.90 toks/s]
Processed prompts:  98%|| 8002/8192 [04:46<00:07, 26.81it/s, est. speed input: 28562.78 toks/s, output: 27.89 toks/s]
Processed prompts:  98%|| 8066/8192 [04:49<00:04, 26.95it/s, est. speed input: 28557.66 toks/s, output: 27.89 toks/s]
Processed prompts:  99%|| 8130/8192 [04:51<00:02, 26.98it/s, est. speed input: 28550.55 toks/s, output: 27.88 toks/s]
Processed prompts: 100%|| 8192/8192 [04:51<00:00, 26.98it/s, est. speed input: 28768.23 toks/s, output: 28.09 toks/s]
Processed prompts: 100%|| 8192/8192 [04:51<00:00, 28.09it/s, est. speed input: 28768.23 toks/s, output: 28.09 toks/s]
[rank0]:[W126 03:54:36.629716568 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 07:33:58
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:34:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:34:02 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1023697) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1023697) WARNING 01-26 07:34:23 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 46.41 requests/s, 23807.59 total tokens/s, 46.41 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 07:34:02] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:34:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:34:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:34:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:34:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:34:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:34:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:34:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:34:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:34:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:34:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:34:05] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:34:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:34:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:34:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:34:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:34:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:34:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1023697) [2026-01-26 07:34:06] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1023697) [2026-01-26 07:34:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1023697) [2026-01-26 07:34:06] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1023697) [2026-01-26 07:34:06] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1023697) [2026-01-26 07:34:06] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1023697) [2026-01-26 07:34:06] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1023697) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1023697) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.76s/it]
(EngineCore_DP0 pid=1023697) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.76s/it]
(EngineCore_DP0 pid=1023697) 
(EngineCore_DP0 pid=1023697) [2026-01-26 07:34:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1023697) [2026-01-26 07:34:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=1023697) [2026-01-26 07:34:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1023697) [2026-01-26 07:34:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=1023697) [2026-01-26 07:34:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1023697) [2026-01-26 07:34:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=1023697) [2026-01-26 07:34:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1023697) [2026-01-26 07:34:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=1023697) 2026-01-26 07:34:23,277 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1023697) 2026-01-26 07:34:23,284 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  98%|| 125/128 [00:00<00:00, 1236.87it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1235.04it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 6/128 [00:00<00:02, 54.41it/s, est. speed input: 27866.78 toks/s, output: 54.42 toks/s]
Processed prompts:   9%|         | 12/128 [00:00<00:02, 49.82it/s, est. speed input: 25838.69 toks/s, output: 50.46 toks/s]
Processed prompts:  14%|        | 18/128 [00:00<00:02, 48.96it/s, est. speed input: 25398.03 toks/s, output: 49.60 toks/s]
Processed prompts:  18%|        | 23/128 [00:00<00:02, 48.39it/s, est. speed input: 25141.42 toks/s, output: 49.10 toks/s]
Processed prompts:  22%|       | 28/128 [00:00<00:02, 48.50it/s, est. speed input: 25104.54 toks/s, output: 49.03 toks/s]
Processed prompts:  26%|       | 33/128 [00:00<00:02, 47.18it/s, est. speed input: 24735.31 toks/s, output: 48.31 toks/s]
Processed prompts:  30%|       | 38/128 [00:00<00:01, 47.55it/s, est. speed input: 24739.98 toks/s, output: 48.32 toks/s]
Processed prompts:  34%|      | 43/128 [00:00<00:01, 47.78it/s, est. speed input: 24738.65 toks/s, output: 48.32 toks/s]
Processed prompts:  38%|      | 48/128 [00:00<00:01, 48.05it/s, est. speed input: 24757.85 toks/s, output: 48.35 toks/s]
Processed prompts:  41%|     | 53/128 [00:01<00:01, 48.02it/s, est. speed input: 24737.07 toks/s, output: 48.31 toks/s]
Processed prompts:  45%|     | 58/128 [00:01<00:01, 48.13it/s, est. speed input: 24740.85 toks/s, output: 48.32 toks/s]
Processed prompts:  49%|     | 63/128 [00:01<00:01, 48.12it/s, est. speed input: 24730.75 toks/s, output: 48.30 toks/s]
Processed prompts:  53%|    | 68/128 [00:01<00:01, 48.23it/s, est. speed input: 24737.40 toks/s, output: 48.31 toks/s]
Processed prompts:  57%|    | 73/128 [00:01<00:01, 48.34it/s, est. speed input: 24747.78 toks/s, output: 48.33 toks/s]
Processed prompts:  61%|    | 78/128 [00:01<00:01, 48.48it/s, est. speed input: 24763.00 toks/s, output: 48.36 toks/s]
Processed prompts:  65%|   | 83/128 [00:01<00:00, 47.49it/s, est. speed input: 24664.08 toks/s, output: 48.17 toks/s]
Processed prompts:  69%|   | 88/128 [00:01<00:00, 47.74it/s, est. speed input: 24668.78 toks/s, output: 48.18 toks/s]
Processed prompts:  73%|  | 93/128 [00:01<00:00, 47.94it/s, est. speed input: 24674.87 toks/s, output: 48.19 toks/s]
Processed prompts:  77%|  | 98/128 [00:02<00:00, 48.15it/s, est. speed input: 24686.77 toks/s, output: 48.22 toks/s]
Processed prompts:  80%|  | 103/128 [00:02<00:00, 48.23it/s, est. speed input: 24691.55 toks/s, output: 48.23 toks/s]
Processed prompts:  84%| | 108/128 [00:02<00:00, 48.24it/s, est. speed input: 24692.53 toks/s, output: 48.23 toks/s]
Processed prompts:  88%| | 113/128 [00:02<00:00, 48.28it/s, est. speed input: 24696.43 toks/s, output: 48.23 toks/s]
Processed prompts:  92%|| 118/128 [00:02<00:00, 48.35it/s, est. speed input: 24701.51 toks/s, output: 48.24 toks/s]
Processed prompts:  96%|| 123/128 [00:02<00:00, 48.11it/s, est. speed input: 24687.11 toks/s, output: 48.22 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 48.30it/s, est. speed input: 24697.67 toks/s, output: 48.24 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 48.30it/s, est. speed input: 24697.67 toks/s, output: 48.24 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 48.23it/s, est. speed input: 24697.67 toks/s, output: 48.24 toks/s]
[rank0]:[W126 07:34:26.996979217 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 07:34:29
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:34:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:34:32 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1024305) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1024305) WARNING 01-26 07:34:54 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 25.88 requests/s, 26529.18 total tokens/s, 25.88 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 07:34:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:34:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:34:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:34:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:34:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:34:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:34:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:34:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:34:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:34:36] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:34:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:34:36] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:34:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:34:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:34:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:34:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:34:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:34:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:34:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1024305) [2026-01-26 07:34:37] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1024305) [2026-01-26 07:34:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1024305) [2026-01-26 07:34:37] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1024305) [2026-01-26 07:34:37] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1024305) [2026-01-26 07:34:37] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1024305) [2026-01-26 07:34:37] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1024305) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1024305) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.67s/it]
(EngineCore_DP0 pid=1024305) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.67s/it]
(EngineCore_DP0 pid=1024305) 
(EngineCore_DP0 pid=1024305) [2026-01-26 07:34:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1024305) [2026-01-26 07:34:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=1024305) [2026-01-26 07:34:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1024305) [2026-01-26 07:34:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=1024305) [2026-01-26 07:34:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1024305) [2026-01-26 07:34:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=1024305) [2026-01-26 07:34:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1024305) [2026-01-26 07:34:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=1024305) 2026-01-26 07:34:53,816 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1024305) 2026-01-26 07:34:53,823 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  48%|     | 62/128 [00:00<00:00, 610.05it/s]
Adding requests:  97%|| 124/128 [00:00<00:00, 575.92it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 579.77it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:02, 59.78it/s, est. speed input: 61224.23 toks/s, output: 59.78 toks/s]
Processed prompts:  10%|         | 13/128 [00:00<00:03, 35.33it/s, est. speed input: 38744.36 toks/s, output: 37.83 toks/s]
Processed prompts:  14%|        | 18/128 [00:00<00:03, 30.60it/s, est. speed input: 34110.38 toks/s, output: 33.31 toks/s]
Processed prompts:  17%|        | 22/128 [00:00<00:03, 28.92it/s, est. speed input: 32391.02 toks/s, output: 31.63 toks/s]
Processed prompts:  20%|        | 26/128 [00:00<00:03, 28.05it/s, est. speed input: 31403.88 toks/s, output: 30.67 toks/s]
Processed prompts:  23%|       | 29/128 [00:00<00:03, 27.73it/s, est. speed input: 30944.83 toks/s, output: 30.22 toks/s]
Processed prompts:  25%|       | 32/128 [00:01<00:03, 27.51it/s, est. speed input: 30591.76 toks/s, output: 29.87 toks/s]
Processed prompts:  27%|       | 35/128 [00:01<00:03, 27.24it/s, est. speed input: 30266.52 toks/s, output: 29.56 toks/s]
Processed prompts:  30%|       | 38/128 [00:01<00:03, 27.11it/s, est. speed input: 30018.65 toks/s, output: 29.31 toks/s]
Processed prompts:  32%|      | 41/128 [00:01<00:03, 26.98it/s, est. speed input: 29803.71 toks/s, output: 29.10 toks/s]
Processed prompts:  34%|      | 44/128 [00:01<00:03, 26.74it/s, est. speed input: 29575.72 toks/s, output: 28.88 toks/s]
Processed prompts:  37%|      | 47/128 [00:01<00:03, 26.25it/s, est. speed input: 29298.82 toks/s, output: 28.61 toks/s]
Processed prompts:  39%|      | 50/128 [00:01<00:02, 26.37it/s, est. speed input: 29169.90 toks/s, output: 28.49 toks/s]
Processed prompts:  41%|     | 53/128 [00:01<00:02, 26.47it/s, est. speed input: 29060.26 toks/s, output: 28.38 toks/s]
Processed prompts:  44%|     | 56/128 [00:01<00:02, 26.44it/s, est. speed input: 28942.04 toks/s, output: 28.26 toks/s]
Processed prompts:  46%|     | 59/128 [00:02<00:02, 26.26it/s, est. speed input: 28805.60 toks/s, output: 28.13 toks/s]
Processed prompts:  48%|     | 62/128 [00:02<00:02, 26.40it/s, est. speed input: 28732.95 toks/s, output: 28.06 toks/s]
Processed prompts:  51%|     | 65/128 [00:02<00:02, 26.49it/s, est. speed input: 28665.24 toks/s, output: 27.99 toks/s]
Processed prompts:  53%|    | 68/128 [00:02<00:02, 26.40it/s, est. speed input: 28578.87 toks/s, output: 27.91 toks/s]
Processed prompts:  55%|    | 71/128 [00:02<00:02, 26.42it/s, est. speed input: 28512.81 toks/s, output: 27.84 toks/s]
Processed prompts:  58%|    | 74/128 [00:02<00:02, 26.03it/s, est. speed input: 28390.31 toks/s, output: 27.72 toks/s]
Processed prompts:  60%|    | 77/128 [00:02<00:01, 26.32it/s, est. speed input: 28362.41 toks/s, output: 27.70 toks/s]
Processed prompts:  62%|   | 80/128 [00:02<00:01, 26.41it/s, est. speed input: 28318.59 toks/s, output: 27.65 toks/s]
Processed prompts:  65%|   | 83/128 [00:03<00:01, 26.38it/s, est. speed input: 28266.72 toks/s, output: 27.60 toks/s]
Processed prompts:  67%|   | 86/128 [00:03<00:01, 26.33it/s, est. speed input: 28213.98 toks/s, output: 27.55 toks/s]
Processed prompts:  70%|   | 89/128 [00:03<00:01, 26.24it/s, est. speed input: 28158.79 toks/s, output: 27.50 toks/s]
Processed prompts:  72%|  | 92/128 [00:03<00:01, 26.43it/s, est. speed input: 28138.30 toks/s, output: 27.48 toks/s]
Processed prompts:  74%|  | 95/128 [00:03<00:01, 26.38it/s, est. speed input: 28096.44 toks/s, output: 27.44 toks/s]
Processed prompts:  77%|  | 98/128 [00:03<00:01, 26.44it/s, est. speed input: 28068.97 toks/s, output: 27.41 toks/s]
Processed prompts:  79%|  | 101/128 [00:03<00:01, 25.98it/s, est. speed input: 27987.18 toks/s, output: 27.33 toks/s]
Processed prompts:  81%| | 104/128 [00:03<00:00, 26.03it/s, est. speed input: 27950.80 toks/s, output: 27.30 toks/s]
Processed prompts:  84%| | 107/128 [00:03<00:00, 26.25it/s, est. speed input: 27935.31 toks/s, output: 27.28 toks/s]
Processed prompts:  86%| | 110/128 [00:04<00:00, 26.42it/s, est. speed input: 27923.12 toks/s, output: 27.27 toks/s]
Processed prompts:  88%| | 113/128 [00:04<00:00, 26.31it/s, est. speed input: 27888.60 toks/s, output: 27.23 toks/s]
Processed prompts:  91%| | 116/128 [00:04<00:00, 26.40it/s, est. speed input: 27871.77 toks/s, output: 27.22 toks/s]
Processed prompts:  93%|| 119/128 [00:04<00:00, 26.29it/s, est. speed input: 27839.58 toks/s, output: 27.19 toks/s]
Processed prompts:  95%|| 122/128 [00:04<00:00, 26.32it/s, est. speed input: 27818.64 toks/s, output: 27.17 toks/s]
Processed prompts:  98%|| 125/128 [00:04<00:00, 26.31it/s, est. speed input: 27796.94 toks/s, output: 27.15 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 25.98it/s, est. speed input: 27748.02 toks/s, output: 27.10 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 25.98it/s, est. speed input: 27748.02 toks/s, output: 27.10 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 27.10it/s, est. speed input: 27748.02 toks/s, output: 27.10 toks/s]
[rank0]:[W126 07:34:59.706613160 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 07:35:01
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:35:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:35:05 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1024972) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1024972) WARNING 01-26 07:35:27 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 27.15 requests/s, 27830.26 total tokens/s, 27.15 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 07:35:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:35:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:35:05] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:35:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:35:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:35:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:35:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:35:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:35:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:35:09] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:35:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:35:09] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:35:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:35:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:35:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:35:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:35:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:35:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1024972) [2026-01-26 07:35:10] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1024972) [2026-01-26 07:35:10] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1024972) [2026-01-26 07:35:10] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1024972) [2026-01-26 07:35:10] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1024972) [2026-01-26 07:35:10] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1024972) [2026-01-26 07:35:10] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1024972) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1024972) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.91s/it]
(EngineCore_DP0 pid=1024972) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.91s/it]
(EngineCore_DP0 pid=1024972) 
(EngineCore_DP0 pid=1024972) [2026-01-26 07:35:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1024972) [2026-01-26 07:35:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=1024972) [2026-01-26 07:35:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1024972) [2026-01-26 07:35:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=1024972) [2026-01-26 07:35:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1024972) [2026-01-26 07:35:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=1024972) [2026-01-26 07:35:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1024972) [2026-01-26 07:35:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=1024972) 2026-01-26 07:35:26,979 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1024972) 2026-01-26 07:35:26,986 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  23%|       | 60/256 [00:00<00:00, 589.50it/s]
Adding requests:  46%|     | 119/256 [00:00<00:00, 583.02it/s]
Adding requests:  70%|   | 178/256 [00:00<00:00, 571.52it/s]
Adding requests:  92%|| 236/256 [00:00<00:00, 570.68it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 571.17it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 12/256 [00:00<00:03, 80.13it/s, est. speed input: 82064.34 toks/s, output: 80.13 toks/s]
Processed prompts:   8%|         | 21/256 [00:00<00:05, 43.91it/s, est. speed input: 48742.83 toks/s, output: 47.60 toks/s]
Processed prompts:  11%|         | 27/256 [00:00<00:06, 36.43it/s, est. speed input: 41713.95 toks/s, output: 40.74 toks/s]
Processed prompts:  12%|        | 32/256 [00:00<00:07, 31.30it/s, est. speed input: 37241.70 toks/s, output: 36.37 toks/s]
Processed prompts:  14%|        | 36/256 [00:01<00:07, 30.38it/s, est. speed input: 36019.61 toks/s, output: 35.17 toks/s]
Processed prompts:  16%|        | 40/256 [00:01<00:07, 29.63it/s, est. speed input: 35067.58 toks/s, output: 34.25 toks/s]
Processed prompts:  17%|        | 44/256 [00:01<00:07, 29.07it/s, est. speed input: 34323.44 toks/s, output: 33.52 toks/s]
Processed prompts:  19%|        | 48/256 [00:01<00:07, 28.66it/s, est. speed input: 33725.86 toks/s, output: 32.93 toks/s]
Processed prompts:  20%|        | 52/256 [00:01<00:07, 28.34it/s, est. speed input: 33226.28 toks/s, output: 32.45 toks/s]
Processed prompts:  22%|       | 56/256 [00:01<00:07, 27.72it/s, est. speed input: 32683.16 toks/s, output: 31.92 toks/s]
Processed prompts:  23%|       | 60/256 [00:01<00:07, 27.69it/s, est. speed input: 32347.43 toks/s, output: 31.59 toks/s]
Processed prompts:  25%|       | 64/256 [00:02<00:06, 27.73it/s, est. speed input: 32075.55 toks/s, output: 31.32 toks/s]
Processed prompts:  27%|       | 68/256 [00:02<00:06, 27.83it/s, est. speed input: 31858.71 toks/s, output: 31.11 toks/s]
Processed prompts:  28%|       | 72/256 [00:02<00:06, 27.73it/s, est. speed input: 31628.81 toks/s, output: 30.89 toks/s]
Processed prompts:  30%|       | 76/256 [00:02<00:06, 27.67it/s, est. speed input: 31425.71 toks/s, output: 30.69 toks/s]
Processed prompts:  31%|      | 80/256 [00:02<00:06, 27.73it/s, est. speed input: 31268.20 toks/s, output: 30.54 toks/s]
Processed prompts:  33%|      | 84/256 [00:02<00:06, 27.33it/s, est. speed input: 31038.91 toks/s, output: 30.31 toks/s]
Processed prompts:  34%|      | 88/256 [00:02<00:06, 27.37it/s, est. speed input: 30893.34 toks/s, output: 30.17 toks/s]
Processed prompts:  36%|      | 92/256 [00:03<00:05, 27.54it/s, est. speed input: 30786.23 toks/s, output: 30.06 toks/s]
Processed prompts:  38%|      | 96/256 [00:03<00:05, 27.65it/s, est. speed input: 30688.08 toks/s, output: 29.97 toks/s]
Processed prompts:  39%|      | 100/256 [00:03<00:05, 27.64it/s, est. speed input: 30583.10 toks/s, output: 29.87 toks/s]
Processed prompts:  41%|      | 104/256 [00:03<00:05, 27.61it/s, est. speed input: 30483.84 toks/s, output: 29.77 toks/s]
Processed prompts:  42%|     | 108/256 [00:03<00:05, 27.58it/s, est. speed input: 30391.75 toks/s, output: 29.68 toks/s]
Processed prompts:  44%|     | 112/256 [00:03<00:05, 27.39it/s, est. speed input: 30282.33 toks/s, output: 29.57 toks/s]
Processed prompts:  45%|     | 116/256 [00:03<00:05, 27.26it/s, est. speed input: 30182.35 toks/s, output: 29.47 toks/s]
Processed prompts:  47%|     | 120/256 [00:04<00:04, 27.42it/s, est. speed input: 30121.29 toks/s, output: 29.42 toks/s]
Processed prompts:  48%|     | 124/256 [00:04<00:04, 27.39it/s, est. speed input: 30046.64 toks/s, output: 29.34 toks/s]
Processed prompts:  50%|     | 128/256 [00:04<00:04, 27.51it/s, est. speed input: 29995.06 toks/s, output: 29.29 toks/s]
Processed prompts:  52%|    | 132/256 [00:04<00:04, 27.73it/s, est. speed input: 29961.53 toks/s, output: 29.26 toks/s]
Processed prompts:  53%|    | 136/256 [00:04<00:04, 27.75it/s, est. speed input: 29914.89 toks/s, output: 29.21 toks/s]
Processed prompts:  55%|    | 140/256 [00:04<00:04, 27.66it/s, est. speed input: 29860.61 toks/s, output: 29.16 toks/s]
Processed prompts:  56%|    | 144/256 [00:04<00:04, 27.49it/s, est. speed input: 29798.04 toks/s, output: 29.10 toks/s]
Processed prompts:  58%|    | 148/256 [00:05<00:03, 27.56it/s, est. speed input: 29757.93 toks/s, output: 29.06 toks/s]
Processed prompts:  59%|    | 152/256 [00:05<00:03, 27.52it/s, est. speed input: 29711.48 toks/s, output: 29.02 toks/s]
Processed prompts:  61%|    | 156/256 [00:05<00:03, 27.57it/s, est. speed input: 29674.78 toks/s, output: 28.98 toks/s]
Processed prompts:  62%|   | 160/256 [00:05<00:03, 27.60it/s, est. speed input: 29639.35 toks/s, output: 28.94 toks/s]
Processed prompts:  64%|   | 164/256 [00:05<00:03, 27.70it/s, est. speed input: 29613.66 toks/s, output: 28.92 toks/s]
Processed prompts:  66%|   | 168/256 [00:05<00:03, 27.70it/s, est. speed input: 29582.94 toks/s, output: 28.89 toks/s]
Processed prompts:  67%|   | 172/256 [00:05<00:03, 27.23it/s, est. speed input: 29512.08 toks/s, output: 28.82 toks/s]
Processed prompts:  69%|   | 176/256 [00:06<00:02, 27.37it/s, est. speed input: 29484.92 toks/s, output: 28.79 toks/s]
Processed prompts:  70%|   | 180/256 [00:06<00:02, 27.47it/s, est. speed input: 29459.27 toks/s, output: 28.77 toks/s]
Processed prompts:  72%|  | 184/256 [00:06<00:02, 27.48it/s, est. speed input: 29429.73 toks/s, output: 28.74 toks/s]
Processed prompts:  73%|  | 188/256 [00:06<00:02, 27.57it/s, est. speed input: 29408.24 toks/s, output: 28.72 toks/s]
Processed prompts:  75%|  | 192/256 [00:06<00:02, 27.59it/s, est. speed input: 29384.52 toks/s, output: 28.70 toks/s]
Processed prompts:  77%|  | 196/256 [00:06<00:02, 27.61it/s, est. speed input: 29361.80 toks/s, output: 28.67 toks/s]
Processed prompts:  78%|  | 200/256 [00:06<00:02, 27.24it/s, est. speed input: 29311.79 toks/s, output: 28.62 toks/s]
Processed prompts:  80%|  | 204/256 [00:07<00:01, 27.47it/s, est. speed input: 29299.71 toks/s, output: 28.61 toks/s]
Processed prompts:  81%| | 208/256 [00:07<00:01, 27.57it/s, est. speed input: 29282.82 toks/s, output: 28.60 toks/s]
Processed prompts:  83%| | 212/256 [00:07<00:01, 27.74it/s, est. speed input: 29274.15 toks/s, output: 28.59 toks/s]
Processed prompts:  84%| | 216/256 [00:07<00:01, 27.85it/s, est. speed input: 29264.86 toks/s, output: 28.58 toks/s]
Processed prompts:  86%| | 220/256 [00:07<00:01, 27.84it/s, est. speed input: 29250.21 toks/s, output: 28.56 toks/s]
Processed prompts:  88%| | 224/256 [00:07<00:01, 27.90it/s, est. speed input: 29240.80 toks/s, output: 28.56 toks/s]
Processed prompts:  89%| | 228/256 [00:07<00:01, 27.41it/s, est. speed input: 29197.48 toks/s, output: 28.51 toks/s]
Processed prompts:  91%| | 232/256 [00:08<00:00, 27.35it/s, est. speed input: 29173.17 toks/s, output: 28.49 toks/s]
Processed prompts:  92%|| 236/256 [00:08<00:00, 27.24it/s, est. speed input: 29145.96 toks/s, output: 28.46 toks/s]
Processed prompts:  94%|| 240/256 [00:08<00:00, 27.35it/s, est. speed input: 29130.66 toks/s, output: 28.45 toks/s]
Processed prompts:  95%|| 244/256 [00:08<00:00, 27.38it/s, est. speed input: 29113.16 toks/s, output: 28.43 toks/s]
Processed prompts:  97%|| 248/256 [00:08<00:00, 27.47it/s, est. speed input: 29100.84 toks/s, output: 28.42 toks/s]
Processed prompts:  98%|| 252/256 [00:08<00:00, 27.57it/s, est. speed input: 29090.38 toks/s, output: 28.41 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 29.81it/s, est. speed input: 29194.42 toks/s, output: 28.51 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 29.81it/s, est. speed input: 29194.42 toks/s, output: 28.51 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 28.51it/s, est. speed input: 29194.42 toks/s, output: 28.51 toks/s]
[rank0]:[W126 07:35:37.391331555 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 07:35:39
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:35:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:35:44 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1025732) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1025732) WARNING 01-26 07:36:06 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 26.70 requests/s, 27369.25 total tokens/s, 26.70 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 07:35:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:35:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:35:44] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:35:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:35:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:35:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:35:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:35:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:35:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:35:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:35:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:35:47] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:35:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:35:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:35:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:35:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:35:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:35:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:35:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1025732) [2026-01-26 07:35:48] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1025732) [2026-01-26 07:35:48] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1025732) [2026-01-26 07:35:48] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1025732) [2026-01-26 07:35:48] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1025732) [2026-01-26 07:35:48] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1025732) [2026-01-26 07:35:48] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1025732) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1025732) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.85s/it]
(EngineCore_DP0 pid=1025732) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.85s/it]
(EngineCore_DP0 pid=1025732) 
(EngineCore_DP0 pid=1025732) [2026-01-26 07:36:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1025732) [2026-01-26 07:36:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=1025732) [2026-01-26 07:36:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1025732) [2026-01-26 07:36:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=1025732) [2026-01-26 07:36:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1025732) [2026-01-26 07:36:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=1025732) [2026-01-26 07:36:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1025732) [2026-01-26 07:36:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=1025732) 2026-01-26 07:36:05,493 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1025732) 2026-01-26 07:36:05,501 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  12%|        | 61/512 [00:00<00:00, 609.06it/s]
Adding requests:  24%|       | 122/512 [00:00<00:00, 594.40it/s]
Adding requests:  36%|      | 182/512 [00:00<00:00, 574.76it/s]
Adding requests:  47%|     | 240/512 [00:00<00:00, 572.02it/s]
Adding requests:  58%|    | 298/512 [00:00<00:00, 563.72it/s]
Adding requests:  69%|   | 355/512 [00:00<00:00, 559.45it/s]
Adding requests:  80%|  | 411/512 [00:00<00:00, 554.99it/s]
Adding requests:  92%|| 469/512 [00:00<00:00, 560.11it/s]
Adding requests: 100%|| 512/512 [00:00<00:00, 563.60it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|         | 22/512 [00:00<00:03, 144.32it/s, est. speed input: 147827.06 toks/s, output: 144.34 toks/s]
Processed prompts:   7%|         | 37/512 [00:00<00:08, 54.87it/s, est. speed input: 63175.37 toks/s, output: 61.69 toks/s]   
Processed prompts:   9%|         | 45/512 [00:00<00:11, 42.33it/s, est. speed input: 50989.61 toks/s, output: 49.79 toks/s]
Processed prompts:  10%|         | 51/512 [00:01<00:13, 33.93it/s, est. speed input: 43506.57 toks/s, output: 42.49 toks/s]
Processed prompts:  11%|         | 56/512 [00:01<00:13, 33.90it/s, est. speed input: 42526.46 toks/s, output: 41.53 toks/s]
Processed prompts:  12%|        | 60/512 [00:01<00:13, 32.34it/s, est. speed input: 41080.51 toks/s, output: 40.12 toks/s]
Processed prompts:  12%|        | 64/512 [00:01<00:14, 30.85it/s, est. speed input: 39798.36 toks/s, output: 38.87 toks/s]
Processed prompts:  13%|        | 68/512 [00:01<00:14, 29.92it/s, est. speed input: 38829.93 toks/s, output: 37.92 toks/s]
Processed prompts:  14%|        | 72/512 [00:01<00:15, 28.81it/s, est. speed input: 37862.27 toks/s, output: 36.97 toks/s]
Processed prompts:  15%|        | 75/512 [00:02<00:16, 26.43it/s, est. speed input: 36654.06 toks/s, output: 35.79 toks/s]
Processed prompts:  15%|        | 78/512 [00:02<00:17, 24.62it/s, est. speed input: 35587.13 toks/s, output: 34.75 toks/s]
Processed prompts:  16%|        | 82/512 [00:02<00:16, 25.33it/s, est. speed input: 35101.51 toks/s, output: 34.28 toks/s]
Processed prompts:  17%|        | 86/512 [00:02<00:16, 25.88it/s, est. speed input: 34684.18 toks/s, output: 33.87 toks/s]
Processed prompts:  18%|        | 90/512 [00:02<00:16, 26.06it/s, est. speed input: 34258.18 toks/s, output: 33.46 toks/s]
Processed prompts:  18%|        | 94/512 [00:02<00:15, 26.37it/s, est. speed input: 33921.47 toks/s, output: 33.13 toks/s]
Processed prompts:  19%|        | 98/512 [00:02<00:15, 26.29it/s, est. speed input: 33552.26 toks/s, output: 32.77 toks/s]
Processed prompts:  20%|        | 102/512 [00:03<00:15, 26.48it/s, est. speed input: 33270.80 toks/s, output: 32.49 toks/s]
Processed prompts:  21%|        | 106/512 [00:03<00:15, 26.61it/s, est. speed input: 33011.83 toks/s, output: 32.24 toks/s]
Processed prompts:  21%|       | 110/512 [00:03<00:15, 26.79it/s, est. speed input: 32792.06 toks/s, output: 32.02 toks/s]
Processed prompts:  22%|       | 114/512 [00:03<00:14, 26.86it/s, est. speed input: 32580.04 toks/s, output: 31.82 toks/s]
Processed prompts:  23%|       | 118/512 [00:03<00:14, 26.90it/s, est. speed input: 32383.55 toks/s, output: 31.62 toks/s]
Processed prompts:  24%|       | 122/512 [00:03<00:14, 26.95it/s, est. speed input: 32206.23 toks/s, output: 31.45 toks/s]
Processed prompts:  25%|       | 126/512 [00:04<00:14, 26.67it/s, est. speed input: 31995.23 toks/s, output: 31.25 toks/s]
Processed prompts:  25%|       | 130/512 [00:04<00:14, 26.75it/s, est. speed input: 31838.42 toks/s, output: 31.09 toks/s]
Processed prompts:  26%|       | 134/512 [00:04<00:14, 26.82it/s, est. speed input: 31694.75 toks/s, output: 30.95 toks/s]
Processed prompts:  27%|       | 138/512 [00:04<00:13, 26.89it/s, est. speed input: 31562.26 toks/s, output: 30.82 toks/s]
Processed prompts:  28%|       | 142/512 [00:04<00:13, 27.00it/s, est. speed input: 31446.45 toks/s, output: 30.71 toks/s]
Processed prompts:  29%|       | 146/512 [00:04<00:13, 27.04it/s, est. speed input: 31333.82 toks/s, output: 30.60 toks/s]
Processed prompts:  29%|       | 150/512 [00:04<00:13, 26.99it/s, est. speed input: 31218.75 toks/s, output: 30.49 toks/s]
Processed prompts:  30%|       | 154/512 [00:05<00:13, 26.65it/s, est. speed input: 31074.84 toks/s, output: 30.35 toks/s]
Processed prompts:  31%|       | 158/512 [00:05<00:13, 26.73it/s, est. speed input: 30975.22 toks/s, output: 30.25 toks/s]
Processed prompts:  32%|      | 162/512 [00:05<00:12, 27.08it/s, est. speed input: 30911.70 toks/s, output: 30.19 toks/s]
Processed prompts:  32%|      | 166/512 [00:05<00:12, 27.14it/s, est. speed input: 30832.56 toks/s, output: 30.11 toks/s]
Processed prompts:  33%|      | 170/512 [00:05<00:12, 27.07it/s, est. speed input: 30746.35 toks/s, output: 30.03 toks/s]
Processed prompts:  34%|      | 174/512 [00:05<00:12, 27.02it/s, est. speed input: 30664.90 toks/s, output: 29.95 toks/s]
Processed prompts:  35%|      | 178/512 [00:05<00:12, 26.96it/s, est. speed input: 30584.94 toks/s, output: 29.87 toks/s]
Processed prompts:  36%|      | 182/512 [00:06<00:12, 26.68it/s, est. speed input: 30486.93 toks/s, output: 29.77 toks/s]
Processed prompts:  36%|      | 186/512 [00:06<00:12, 26.80it/s, est. speed input: 30421.32 toks/s, output: 29.71 toks/s]
Processed prompts:  37%|      | 190/512 [00:06<00:11, 27.06it/s, est. speed input: 30375.15 toks/s, output: 29.66 toks/s]
Processed prompts:  38%|      | 194/512 [00:06<00:11, 27.16it/s, est. speed input: 30323.04 toks/s, output: 29.61 toks/s]
Processed prompts:  39%|      | 198/512 [00:06<00:11, 27.00it/s, est. speed input: 30255.09 toks/s, output: 29.55 toks/s]
Processed prompts:  39%|      | 202/512 [00:06<00:11, 27.07it/s, est. speed input: 30204.07 toks/s, output: 29.50 toks/s]
Processed prompts:  40%|      | 206/512 [00:06<00:11, 27.10it/s, est. speed input: 30154.09 toks/s, output: 29.45 toks/s]
Processed prompts:  41%|      | 210/512 [00:07<00:11, 26.72it/s, est. speed input: 30075.12 toks/s, output: 29.37 toks/s]
Processed prompts:  42%|     | 214/512 [00:07<00:11, 26.84it/s, est. speed input: 30028.58 toks/s, output: 29.32 toks/s]
Processed prompts:  43%|     | 218/512 [00:07<00:10, 26.92it/s, est. speed input: 29983.38 toks/s, output: 29.28 toks/s]
Processed prompts:  43%|     | 222/512 [00:07<00:10, 27.07it/s, est. speed input: 29947.27 toks/s, output: 29.25 toks/s]
Processed prompts:  44%|     | 226/512 [00:07<00:10, 27.00it/s, est. speed input: 29899.81 toks/s, output: 29.20 toks/s]
Processed prompts:  45%|     | 230/512 [00:07<00:10, 26.94it/s, est. speed input: 29853.35 toks/s, output: 29.15 toks/s]
Processed prompts:  46%|     | 234/512 [00:08<00:10, 27.03it/s, est. speed input: 29817.70 toks/s, output: 29.12 toks/s]
Processed prompts:  46%|     | 238/512 [00:08<00:10, 26.78it/s, est. speed input: 29762.26 toks/s, output: 29.06 toks/s]
Processed prompts:  47%|     | 242/512 [00:08<00:10, 26.64it/s, est. speed input: 29711.03 toks/s, output: 29.01 toks/s]
Processed prompts:  48%|     | 246/512 [00:08<00:09, 26.87it/s, est. speed input: 29683.20 toks/s, output: 28.99 toks/s]
Processed prompts:  49%|     | 250/512 [00:08<00:09, 27.04it/s, est. speed input: 29656.43 toks/s, output: 28.96 toks/s]
Processed prompts:  50%|     | 254/512 [00:08<00:09, 27.03it/s, est. speed input: 29622.86 toks/s, output: 28.93 toks/s]
Processed prompts:  50%|     | 258/512 [00:08<00:09, 27.02it/s, est. speed input: 29590.08 toks/s, output: 28.90 toks/s]
Processed prompts:  51%|     | 262/512 [00:09<00:09, 26.94it/s, est. speed input: 29553.81 toks/s, output: 28.86 toks/s]
Processed prompts:  52%|    | 266/512 [00:09<00:09, 26.96it/s, est. speed input: 29523.19 toks/s, output: 28.83 toks/s]
Processed prompts:  53%|    | 270/512 [00:09<00:09, 26.66it/s, est. speed input: 29475.59 toks/s, output: 28.78 toks/s]
Processed prompts:  54%|    | 274/512 [00:09<00:08, 26.91it/s, est. speed input: 29455.81 toks/s, output: 28.77 toks/s]
Processed prompts:  54%|    | 278/512 [00:09<00:08, 27.02it/s, est. speed input: 29432.75 toks/s, output: 28.74 toks/s]
Processed prompts:  55%|    | 282/512 [00:09<00:08, 26.93it/s, est. speed input: 29401.04 toks/s, output: 28.71 toks/s]
Processed prompts:  56%|    | 286/512 [00:09<00:08, 26.86it/s, est. speed input: 29370.12 toks/s, output: 28.68 toks/s]
Processed prompts:  57%|    | 290/512 [00:10<00:08, 26.86it/s, est. speed input: 29342.42 toks/s, output: 28.65 toks/s]
Processed prompts:  57%|    | 294/512 [00:10<00:08, 26.83it/s, est. speed input: 29314.16 toks/s, output: 28.63 toks/s]
Processed prompts:  58%|    | 298/512 [00:10<00:08, 26.55it/s, est. speed input: 29273.26 toks/s, output: 28.59 toks/s]
Processed prompts:  59%|    | 302/512 [00:10<00:07, 26.73it/s, est. speed input: 29252.72 toks/s, output: 28.57 toks/s]
Processed prompts:  60%|    | 306/512 [00:10<00:07, 26.81it/s, est. speed input: 29230.92 toks/s, output: 28.55 toks/s]
Processed prompts:  61%|    | 310/512 [00:10<00:07, 26.80it/s, est. speed input: 29205.81 toks/s, output: 28.52 toks/s]
Processed prompts:  61%|   | 314/512 [00:11<00:07, 26.98it/s, est. speed input: 29190.69 toks/s, output: 28.51 toks/s]
Processed prompts:  62%|   | 318/512 [00:11<00:07, 26.92it/s, est. speed input: 29167.17 toks/s, output: 28.48 toks/s]
Processed prompts:  63%|   | 322/512 [00:11<00:07, 26.97it/s, est. speed input: 29148.29 toks/s, output: 28.47 toks/s]
Processed prompts:  64%|   | 326/512 [00:11<00:06, 26.67it/s, est. speed input: 29114.44 toks/s, output: 28.43 toks/s]
Processed prompts:  64%|   | 330/512 [00:11<00:06, 26.73it/s, est. speed input: 29094.09 toks/s, output: 28.41 toks/s]
Processed prompts:  65%|   | 334/512 [00:11<00:06, 26.83it/s, est. speed input: 29076.80 toks/s, output: 28.40 toks/s]
Processed prompts:  66%|   | 338/512 [00:11<00:06, 27.04it/s, est. speed input: 29066.15 toks/s, output: 28.38 toks/s]
Processed prompts:  67%|   | 342/512 [00:12<00:06, 27.96it/s, est. speed input: 29088.25 toks/s, output: 28.41 toks/s]
Processed prompts:  68%|   | 346/512 [00:12<00:06, 27.55it/s, est. speed input: 29066.15 toks/s, output: 28.38 toks/s]
Processed prompts:  68%|   | 350/512 [00:12<00:05, 27.34it/s, est. speed input: 29047.15 toks/s, output: 28.37 toks/s]
Processed prompts:  69%|   | 354/512 [00:12<00:05, 26.94it/s, est. speed input: 29017.83 toks/s, output: 28.34 toks/s]
Processed prompts:  70%|   | 358/512 [00:12<00:05, 26.96it/s, est. speed input: 29001.82 toks/s, output: 28.32 toks/s]
Processed prompts:  71%|   | 362/512 [00:12<00:05, 27.02it/s, est. speed input: 28988.11 toks/s, output: 28.31 toks/s]
Processed prompts:  71%|  | 366/512 [00:12<00:05, 27.01it/s, est. speed input: 28972.74 toks/s, output: 28.29 toks/s]
Processed prompts:  72%|  | 370/512 [00:13<00:05, 26.95it/s, est. speed input: 28955.55 toks/s, output: 28.28 toks/s]
Processed prompts:  73%|  | 374/512 [00:13<00:05, 27.01it/s, est. speed input: 28942.47 toks/s, output: 28.26 toks/s]
Processed prompts:  74%|  | 378/512 [00:13<00:04, 27.04it/s, est. speed input: 28929.43 toks/s, output: 28.25 toks/s]
Processed prompts:  75%|  | 382/512 [00:13<00:04, 26.68it/s, est. speed input: 28901.69 toks/s, output: 28.22 toks/s]
Processed prompts:  75%|  | 386/512 [00:13<00:04, 26.72it/s, est. speed input: 28885.91 toks/s, output: 28.21 toks/s]
Processed prompts:  76%|  | 390/512 [00:13<00:04, 26.74it/s, est. speed input: 28870.24 toks/s, output: 28.19 toks/s]
Processed prompts:  77%|  | 394/512 [00:13<00:04, 26.83it/s, est. speed input: 28857.78 toks/s, output: 28.18 toks/s]
Processed prompts:  78%|  | 398/512 [00:14<00:04, 26.78it/s, est. speed input: 28841.29 toks/s, output: 28.17 toks/s]
Processed prompts:  79%|  | 402/512 [00:14<00:04, 26.86it/s, est. speed input: 28829.37 toks/s, output: 28.15 toks/s]
Processed prompts:  79%|  | 406/512 [00:14<00:03, 26.90it/s, est. speed input: 28817.20 toks/s, output: 28.14 toks/s]
Processed prompts:  80%|  | 410/512 [00:14<00:03, 26.79it/s, est. speed input: 28800.10 toks/s, output: 28.13 toks/s]
Processed prompts:  81%|  | 414/512 [00:14<00:03, 26.90it/s, est. speed input: 28790.29 toks/s, output: 28.12 toks/s]
Processed prompts:  82%| | 418/512 [00:14<00:03, 26.96it/s, est. speed input: 28780.07 toks/s, output: 28.11 toks/s]
Processed prompts:  82%| | 422/512 [00:15<00:03, 26.86it/s, est. speed input: 28764.79 toks/s, output: 28.09 toks/s]
Processed prompts:  83%| | 426/512 [00:15<00:03, 26.89it/s, est. speed input: 28753.67 toks/s, output: 28.08 toks/s]
Processed prompts:  84%| | 430/512 [00:15<00:03, 26.93it/s, est. speed input: 28743.30 toks/s, output: 28.07 toks/s]
Processed prompts:  85%| | 434/512 [00:15<00:02, 27.03it/s, est. speed input: 28735.28 toks/s, output: 28.06 toks/s]
Processed prompts:  86%| | 438/512 [00:15<00:02, 26.78it/s, est. speed input: 28716.69 toks/s, output: 28.04 toks/s]
Processed prompts:  86%| | 442/512 [00:15<00:02, 26.76it/s, est. speed input: 28704.03 toks/s, output: 28.03 toks/s]
Processed prompts:  87%| | 446/512 [00:15<00:02, 26.88it/s, est. speed input: 28695.66 toks/s, output: 28.02 toks/s]
Processed prompts:  88%| | 450/512 [00:16<00:02, 28.00it/s, est. speed input: 28720.36 toks/s, output: 28.05 toks/s]
Processed prompts:  89%| | 454/512 [00:16<00:02, 27.59it/s, est. speed input: 28707.36 toks/s, output: 28.03 toks/s]
Processed prompts:  89%| | 458/512 [00:16<00:01, 27.36it/s, est. speed input: 28696.31 toks/s, output: 28.02 toks/s]
Processed prompts:  90%| | 462/512 [00:16<00:01, 27.29it/s, est. speed input: 28688.04 toks/s, output: 28.02 toks/s]
Processed prompts:  91%| | 466/512 [00:16<00:01, 26.96it/s, est. speed input: 28671.21 toks/s, output: 28.00 toks/s]
Processed prompts:  92%|| 470/512 [00:16<00:01, 26.69it/s, est. speed input: 28653.25 toks/s, output: 27.98 toks/s]
Processed prompts:  93%|| 474/512 [00:16<00:01, 26.63it/s, est. speed input: 28639.63 toks/s, output: 27.97 toks/s]
Processed prompts:  93%|| 478/512 [00:17<00:01, 26.70it/s, est. speed input: 28629.85 toks/s, output: 27.96 toks/s]
Processed prompts:  94%|| 482/512 [00:17<00:01, 26.67it/s, est. speed input: 28617.73 toks/s, output: 27.95 toks/s]
Processed prompts:  95%|| 486/512 [00:17<00:00, 26.74it/s, est. speed input: 28608.67 toks/s, output: 27.94 toks/s]
Processed prompts:  96%|| 490/512 [00:17<00:00, 26.77it/s, est. speed input: 28598.97 toks/s, output: 27.93 toks/s]
Processed prompts:  96%|| 494/512 [00:17<00:00, 26.76it/s, est. speed input: 28588.73 toks/s, output: 27.92 toks/s]
Processed prompts:  97%|| 498/512 [00:17<00:00, 26.56it/s, est. speed input: 28572.82 toks/s, output: 27.90 toks/s]
Processed prompts:  98%|| 502/512 [00:17<00:00, 26.70it/s, est. speed input: 28565.50 toks/s, output: 27.90 toks/s]
Processed prompts:  99%|| 506/512 [00:18<00:00, 26.75it/s, est. speed input: 28556.78 toks/s, output: 27.89 toks/s]
Processed prompts: 100%|| 510/512 [00:18<00:00, 28.38it/s, est. speed input: 28591.89 toks/s, output: 27.92 toks/s]
Processed prompts: 100%|| 512/512 [00:18<00:00, 28.38it/s, est. speed input: 28703.86 toks/s, output: 28.03 toks/s]
Processed prompts: 100%|| 512/512 [00:18<00:00, 28.03it/s, est. speed input: 28703.86 toks/s, output: 28.03 toks/s]
[rank0]:[W126 07:36:25.722864562 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 07:36:27
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:36:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:36:34 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1026605) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1026605) WARNING 01-26 07:36:55 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 26.34 requests/s, 26996.62 total tokens/s, 26.34 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 07:36:34] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:36:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:36:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:36:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:36:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:36:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:36:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:36:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:36:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:36:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:36:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:36:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:36:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:36:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:36:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:36:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:36:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:36:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:36:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1026605) [2026-01-26 07:36:38] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1026605) [2026-01-26 07:36:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1026605) [2026-01-26 07:36:38] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1026605) [2026-01-26 07:36:38] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1026605) [2026-01-26 07:36:38] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1026605) [2026-01-26 07:36:38] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1026605) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1026605) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.60s/it]
(EngineCore_DP0 pid=1026605) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.60s/it]
(EngineCore_DP0 pid=1026605) 
(EngineCore_DP0 pid=1026605) [2026-01-26 07:36:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1026605) [2026-01-26 07:36:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=1026605) [2026-01-26 07:36:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1026605) [2026-01-26 07:36:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=1026605) [2026-01-26 07:36:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1026605) [2026-01-26 07:36:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=1026605) [2026-01-26 07:36:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1026605) [2026-01-26 07:36:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=1026605) 2026-01-26 07:36:55,134 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1026605) 2026-01-26 07:36:55,182 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   6%|         | 59/1024 [00:00<00:01, 587.11it/s]
Adding requests:  12%|        | 118/1024 [00:00<00:01, 583.76it/s]
Adding requests:  17%|        | 177/1024 [00:00<00:01, 556.42it/s]
Adding requests:  23%|       | 235/1024 [00:00<00:01, 563.49it/s]
Adding requests:  29%|       | 292/1024 [00:00<00:01, 549.93it/s]
Adding requests:  34%|      | 348/1024 [00:00<00:01, 547.70it/s]
Adding requests:  40%|      | 405/1024 [00:00<00:01, 554.26it/s]
Adding requests:  45%|     | 461/1024 [00:00<00:01, 552.18it/s]
Adding requests:  50%|     | 517/1024 [00:00<00:00, 545.16it/s]
Adding requests:  56%|    | 572/1024 [00:01<00:00, 522.50it/s]
Adding requests:  61%|   | 628/1024 [00:01<00:00, 529.54it/s]
Adding requests:  67%|   | 684/1024 [00:01<00:00, 537.49it/s]
Adding requests:  72%|  | 740/1024 [00:01<00:00, 541.18it/s]
Adding requests:  78%|  | 795/1024 [00:01<00:00, 535.17it/s]
Adding requests:  83%| | 849/1024 [00:01<00:00, 531.21it/s]
Adding requests:  89%| | 907/1024 [00:01<00:00, 544.06it/s]
Adding requests:  94%|| 962/1024 [00:01<00:00, 540.41it/s]
Adding requests:  99%|| 1018/1024 [00:01<00:00, 542.81it/s]
Adding requests: 100%|| 1024/1024 [00:01<00:00, 544.35it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|         | 42/1024 [00:00<00:02, 386.01it/s, est. speed input: 395346.34 toks/s, output: 386.04 toks/s]
Processed prompts:   8%|         | 81/1024 [00:01<00:17, 53.15it/s, est. speed input: 62852.99 toks/s, output: 61.38 toks/s]   
Processed prompts:  10%|         | 99/1024 [00:02<00:25, 36.40it/s, est. speed input: 45485.60 toks/s, output: 44.42 toks/s]
Processed prompts:  11%|         | 110/1024 [00:02<00:25, 36.44it/s, est. speed input: 44540.09 toks/s, output: 43.50 toks/s]
Processed prompts:  12%|        | 118/1024 [00:02<00:26, 34.18it/s, est. speed input: 42610.33 toks/s, output: 41.61 toks/s]
Processed prompts:  12%|        | 124/1024 [00:03<00:29, 30.80it/s, est. speed input: 40457.51 toks/s, output: 39.51 toks/s]
Processed prompts:  13%|        | 130/1024 [00:03<00:31, 28.10it/s, est. speed input: 38716.43 toks/s, output: 37.81 toks/s]
Processed prompts:  13%|        | 138/1024 [00:03<00:32, 27.53it/s, est. speed input: 37718.49 toks/s, output: 36.83 toks/s]
Processed prompts:  14%|        | 146/1024 [00:04<00:32, 27.22it/s, est. speed input: 36919.90 toks/s, output: 36.05 toks/s]
Processed prompts:  15%|        | 154/1024 [00:04<00:32, 27.08it/s, est. speed input: 36261.91 toks/s, output: 35.41 toks/s]
Processed prompts:  16%|        | 162/1024 [00:04<00:32, 26.92it/s, est. speed input: 35669.86 toks/s, output: 34.83 toks/s]
Processed prompts:  17%|        | 170/1024 [00:04<00:32, 26.66it/s, est. speed input: 35112.33 toks/s, output: 34.29 toks/s]
Processed prompts:  17%|        | 178/1024 [00:05<00:31, 26.67it/s, est. speed input: 34669.03 toks/s, output: 33.86 toks/s]
Processed prompts:  18%|        | 186/1024 [00:05<00:31, 26.65it/s, est. speed input: 34266.92 toks/s, output: 33.46 toks/s]
Processed prompts:  19%|        | 194/1024 [00:05<00:31, 26.53it/s, est. speed input: 33882.46 toks/s, output: 33.09 toks/s]
Processed prompts:  20%|        | 202/1024 [00:06<00:30, 26.55it/s, est. speed input: 33559.25 toks/s, output: 32.77 toks/s]
Processed prompts:  21%|        | 210/1024 [00:06<00:30, 26.55it/s, est. speed input: 33261.15 toks/s, output: 32.48 toks/s]
Processed prompts:  21%|       | 218/1024 [00:06<00:30, 26.53it/s, est. speed input: 32987.34 toks/s, output: 32.21 toks/s]
Processed prompts:  22%|       | 226/1024 [00:07<00:30, 26.35it/s, est. speed input: 32707.30 toks/s, output: 31.94 toks/s]
Processed prompts:  23%|       | 234/1024 [00:07<00:29, 26.38it/s, est. speed input: 32476.87 toks/s, output: 31.72 toks/s]
Processed prompts:  24%|       | 242/1024 [00:07<00:29, 26.42it/s, est. speed input: 32267.56 toks/s, output: 31.51 toks/s]
Processed prompts:  24%|       | 250/1024 [00:07<00:29, 26.32it/s, est. speed input: 32054.69 toks/s, output: 31.30 toks/s]
Processed prompts:  25%|       | 258/1024 [00:08<00:28, 26.48it/s, est. speed input: 31890.53 toks/s, output: 31.14 toks/s]
Processed prompts:  26%|       | 266/1024 [00:08<00:28, 26.49it/s, est. speed input: 31723.67 toks/s, output: 30.98 toks/s]
Processed prompts:  27%|       | 274/1024 [00:08<00:28, 26.44it/s, est. speed input: 31561.20 toks/s, output: 30.82 toks/s]
Processed prompts:  28%|       | 282/1024 [00:09<00:28, 26.31it/s, est. speed input: 31395.86 toks/s, output: 30.66 toks/s]
Processed prompts:  28%|       | 290/1024 [00:09<00:27, 26.34it/s, est. speed input: 31257.16 toks/s, output: 30.52 toks/s]
Processed prompts:  29%|       | 298/1024 [00:09<00:27, 26.44it/s, est. speed input: 31136.25 toks/s, output: 30.41 toks/s]
Processed prompts:  30%|       | 306/1024 [00:10<00:27, 26.39it/s, est. speed input: 31009.63 toks/s, output: 30.28 toks/s]
Processed prompts:  31%|       | 314/1024 [00:10<00:26, 26.38it/s, est. speed input: 30891.55 toks/s, output: 30.17 toks/s]
Processed prompts:  31%|      | 322/1024 [00:10<00:26, 26.43it/s, est. speed input: 30787.91 toks/s, output: 30.07 toks/s]
Processed prompts:  32%|      | 330/1024 [00:11<00:26, 26.49it/s, est. speed input: 30692.08 toks/s, output: 29.97 toks/s]
Processed prompts:  33%|      | 338/1024 [00:11<00:25, 26.78it/s, est. speed input: 30626.05 toks/s, output: 29.91 toks/s]
Processed prompts:  34%|      | 346/1024 [00:11<00:25, 26.63it/s, est. speed input: 30528.86 toks/s, output: 29.81 toks/s]
Processed prompts:  35%|      | 354/1024 [00:11<00:25, 26.53it/s, est. speed input: 30437.03 toks/s, output: 29.72 toks/s]
Processed prompts:  35%|      | 362/1024 [00:12<00:25, 26.30it/s, est. speed input: 30334.68 toks/s, output: 29.62 toks/s]
Processed prompts:  36%|      | 370/1024 [00:12<00:24, 26.38it/s, est. speed input: 30259.62 toks/s, output: 29.55 toks/s]
Processed prompts:  37%|      | 378/1024 [00:12<00:24, 26.38it/s, est. speed input: 30182.34 toks/s, output: 29.47 toks/s]
Processed prompts:  38%|      | 386/1024 [00:13<00:24, 26.38it/s, est. speed input: 30109.37 toks/s, output: 29.40 toks/s]
Processed prompts:  38%|      | 394/1024 [00:13<00:23, 26.26it/s, est. speed input: 30028.93 toks/s, output: 29.33 toks/s]
Processed prompts:  39%|      | 402/1024 [00:13<00:23, 26.33it/s, est. speed input: 29965.48 toks/s, output: 29.26 toks/s]
Processed prompts:  40%|      | 410/1024 [00:14<00:23, 26.41it/s, est. speed input: 29906.61 toks/s, output: 29.21 toks/s]
Processed prompts:  41%|      | 418/1024 [00:14<00:23, 26.27it/s, est. speed input: 29835.23 toks/s, output: 29.14 toks/s]
Processed prompts:  42%|     | 426/1024 [00:14<00:22, 26.33it/s, est. speed input: 29779.22 toks/s, output: 29.08 toks/s]
Processed prompts:  42%|     | 434/1024 [00:14<00:22, 26.30it/s, est. speed input: 29719.34 toks/s, output: 29.02 toks/s]
Processed prompts:  43%|     | 442/1024 [00:15<00:21, 26.46it/s, est. speed input: 29675.94 toks/s, output: 28.98 toks/s]
Processed prompts:  44%|     | 450/1024 [00:15<00:21, 26.91it/s, est. speed input: 29657.40 toks/s, output: 28.96 toks/s]
Processed prompts:  45%|     | 458/1024 [00:15<00:21, 26.81it/s, est. speed input: 29611.30 toks/s, output: 28.92 toks/s]
Processed prompts:  46%|     | 466/1024 [00:16<00:20, 26.70it/s, est. speed input: 29563.80 toks/s, output: 28.87 toks/s]
Processed prompts:  46%|     | 474/1024 [00:16<00:20, 26.54it/s, est. speed input: 29512.63 toks/s, output: 28.82 toks/s]
Processed prompts:  47%|     | 482/1024 [00:16<00:20, 26.49it/s, est. speed input: 29466.86 toks/s, output: 28.78 toks/s]
Processed prompts:  48%|     | 490/1024 [00:17<00:20, 26.55it/s, est. speed input: 29429.67 toks/s, output: 28.74 toks/s]
Processed prompts:  49%|     | 498/1024 [00:17<00:19, 26.59it/s, est. speed input: 29393.12 toks/s, output: 28.70 toks/s]
Processed prompts:  49%|     | 506/1024 [00:17<00:19, 26.45it/s, est. speed input: 29347.34 toks/s, output: 28.66 toks/s]
Processed prompts:  50%|     | 514/1024 [00:17<00:19, 26.54it/s, est. speed input: 29314.83 toks/s, output: 28.63 toks/s]
Processed prompts:  51%|     | 522/1024 [00:18<00:18, 26.63it/s, est. speed input: 29285.12 toks/s, output: 28.60 toks/s]
Processed prompts:  52%|    | 530/1024 [00:18<00:18, 26.45it/s, est. speed input: 29241.74 toks/s, output: 28.56 toks/s]
Processed prompts:  53%|    | 538/1024 [00:18<00:18, 26.39it/s, est. speed input: 29203.72 toks/s, output: 28.52 toks/s]
Processed prompts:  53%|    | 546/1024 [00:19<00:18, 26.32it/s, est. speed input: 29165.17 toks/s, output: 28.48 toks/s]
Processed prompts:  54%|    | 554/1024 [00:19<00:17, 26.38it/s, est. speed input: 29134.03 toks/s, output: 28.45 toks/s]
Processed prompts:  55%|    | 562/1024 [00:19<00:17, 26.29it/s, est. speed input: 29096.59 toks/s, output: 28.41 toks/s]
Processed prompts:  56%|    | 570/1024 [00:20<00:17, 26.44it/s, est. speed input: 29071.59 toks/s, output: 28.39 toks/s]
Processed prompts:  56%|    | 578/1024 [00:20<00:16, 26.50it/s, est. speed input: 29045.14 toks/s, output: 28.36 toks/s]
Processed prompts:  57%|    | 586/1024 [00:20<00:16, 26.42it/s, est. speed input: 29013.26 toks/s, output: 28.33 toks/s]
Processed prompts:  58%|    | 594/1024 [00:20<00:16, 26.43it/s, est. speed input: 28985.37 toks/s, output: 28.31 toks/s]
Processed prompts:  59%|    | 602/1024 [00:21<00:15, 26.38it/s, est. speed input: 28955.46 toks/s, output: 28.28 toks/s]
Processed prompts:  60%|    | 610/1024 [00:21<00:15, 26.41it/s, est. speed input: 28929.86 toks/s, output: 28.25 toks/s]
Processed prompts:  60%|    | 618/1024 [00:21<00:15, 26.30it/s, est. speed input: 28898.15 toks/s, output: 28.22 toks/s]
Processed prompts:  61%|    | 626/1024 [00:22<00:15, 26.38it/s, est. speed input: 28874.95 toks/s, output: 28.20 toks/s]
Processed prompts:  62%|   | 634/1024 [00:22<00:14, 26.40it/s, est. speed input: 28850.79 toks/s, output: 28.17 toks/s]
Processed prompts:  63%|   | 642/1024 [00:22<00:14, 26.29it/s, est. speed input: 28821.53 toks/s, output: 28.15 toks/s]
Processed prompts:  63%|   | 650/1024 [00:23<00:14, 26.30it/s, est. speed input: 28796.85 toks/s, output: 28.12 toks/s]
Processed prompts:  64%|   | 658/1024 [00:23<00:13, 26.34it/s, est. speed input: 28774.61 toks/s, output: 28.10 toks/s]
Processed prompts:  65%|   | 666/1024 [00:23<00:13, 26.42it/s, est. speed input: 28755.36 toks/s, output: 28.08 toks/s]
Processed prompts:  66%|   | 674/1024 [00:24<00:13, 26.25it/s, est. speed input: 28726.07 toks/s, output: 28.05 toks/s]
Processed prompts:  67%|   | 682/1024 [00:24<00:12, 26.41it/s, est. speed input: 28709.93 toks/s, output: 28.04 toks/s]
Processed prompts:  67%|   | 690/1024 [00:24<00:12, 26.52it/s, est. speed input: 28694.26 toks/s, output: 28.02 toks/s]
Processed prompts:  68%|   | 698/1024 [00:24<00:12, 26.37it/s, est. speed input: 28669.00 toks/s, output: 28.00 toks/s]
Processed prompts:  69%|   | 706/1024 [00:25<00:12, 26.42it/s, est. speed input: 28651.38 toks/s, output: 27.98 toks/s]
Processed prompts:  70%|   | 714/1024 [00:25<00:11, 26.46it/s, est. speed input: 28634.02 toks/s, output: 27.96 toks/s]
Processed prompts:  71%|   | 722/1024 [00:25<00:11, 26.46it/s, est. speed input: 28616.06 toks/s, output: 27.95 toks/s]
Processed prompts:  71%|  | 730/1024 [00:26<00:11, 26.29it/s, est. speed input: 28591.55 toks/s, output: 27.92 toks/s]
Processed prompts:  72%|  | 738/1024 [00:26<00:10, 26.36it/s, est. speed input: 28574.95 toks/s, output: 27.91 toks/s]
Processed prompts:  73%|  | 746/1024 [00:26<00:10, 26.42it/s, est. speed input: 28559.46 toks/s, output: 27.89 toks/s]
Processed prompts:  74%|  | 754/1024 [00:27<00:10, 26.27it/s, est. speed input: 28536.48 toks/s, output: 27.87 toks/s]
Processed prompts:  74%|  | 762/1024 [00:27<00:09, 26.34it/s, est. speed input: 28521.25 toks/s, output: 27.85 toks/s]
Processed prompts:  75%|  | 770/1024 [00:27<00:09, 26.38it/s, est. speed input: 28505.71 toks/s, output: 27.84 toks/s]
Processed prompts:  76%|  | 778/1024 [00:27<00:09, 26.39it/s, est. speed input: 28489.93 toks/s, output: 27.82 toks/s]
Processed prompts:  77%|  | 786/1024 [00:28<00:09, 26.22it/s, est. speed input: 28467.56 toks/s, output: 27.80 toks/s]
Processed prompts:  78%|  | 794/1024 [00:28<00:08, 26.33it/s, est. speed input: 28454.54 toks/s, output: 27.79 toks/s]
Processed prompts:  78%|  | 802/1024 [00:28<00:08, 26.37it/s, est. speed input: 28440.50 toks/s, output: 27.77 toks/s]
Processed prompts:  79%|  | 810/1024 [00:29<00:08, 26.27it/s, est. speed input: 28421.59 toks/s, output: 27.76 toks/s]
Processed prompts:  80%|  | 818/1024 [00:29<00:07, 26.32it/s, est. speed input: 28407.82 toks/s, output: 27.74 toks/s]
Processed prompts:  81%|  | 826/1024 [00:29<00:07, 26.34it/s, est. speed input: 28393.66 toks/s, output: 27.73 toks/s]
Processed prompts:  81%| | 834/1024 [00:30<00:07, 26.39it/s, est. speed input: 28381.13 toks/s, output: 27.72 toks/s]
Processed prompts:  82%| | 842/1024 [00:30<00:06, 26.26it/s, est. speed input: 28362.83 toks/s, output: 27.70 toks/s]
Processed prompts:  83%| | 850/1024 [00:30<00:06, 26.33it/s, est. speed input: 28350.92 toks/s, output: 27.69 toks/s]
Processed prompts:  84%| | 858/1024 [00:31<00:06, 26.42it/s, est. speed input: 28340.45 toks/s, output: 27.68 toks/s]
Processed prompts:  85%| | 866/1024 [00:31<00:06, 26.30it/s, est. speed input: 28323.75 toks/s, output: 27.66 toks/s]
Processed prompts:  85%| | 874/1024 [00:31<00:05, 26.34it/s, est. speed input: 28311.82 toks/s, output: 27.65 toks/s]
Processed prompts:  86%| | 882/1024 [00:31<00:05, 26.33it/s, est. speed input: 28298.78 toks/s, output: 27.64 toks/s]
Processed prompts:  87%| | 890/1024 [00:32<00:05, 26.35it/s, est. speed input: 28286.68 toks/s, output: 27.62 toks/s]
Processed prompts:  88%| | 898/1024 [00:32<00:04, 26.18it/s, est. speed input: 28269.03 toks/s, output: 27.61 toks/s]
Processed prompts:  88%| | 906/1024 [00:32<00:04, 26.29it/s, est. speed input: 28259.01 toks/s, output: 27.60 toks/s]
Processed prompts:  89%| | 914/1024 [00:33<00:04, 26.30it/s, est. speed input: 28246.90 toks/s, output: 27.58 toks/s]
Processed prompts:  90%| | 922/1024 [00:33<00:03, 26.18it/s, est. speed input: 28231.15 toks/s, output: 27.57 toks/s]
Processed prompts:  91%| | 930/1024 [00:33<00:03, 26.28it/s, est. speed input: 28221.42 toks/s, output: 27.56 toks/s]
Processed prompts:  92%|| 938/1024 [00:34<00:03, 27.17it/s, est. speed input: 28237.42 toks/s, output: 27.58 toks/s]
Processed prompts:  92%|| 946/1024 [00:34<00:02, 26.95it/s, est. speed input: 28227.14 toks/s, output: 27.57 toks/s]
Processed prompts:  93%|| 954/1024 [00:34<00:02, 26.62it/s, est. speed input: 28211.85 toks/s, output: 27.55 toks/s]
Processed prompts:  94%|| 962/1024 [00:34<00:02, 26.69it/s, est. speed input: 28205.70 toks/s, output: 27.54 toks/s]
Processed prompts:  95%|| 970/1024 [00:35<00:02, 26.54it/s, est. speed input: 28193.85 toks/s, output: 27.53 toks/s]
Processed prompts:  96%|| 978/1024 [00:35<00:01, 26.32it/s, est. speed input: 28178.49 toks/s, output: 27.52 toks/s]
Processed prompts:  96%|| 986/1024 [00:35<00:01, 27.24it/s, est. speed input: 28195.05 toks/s, output: 27.53 toks/s]
Processed prompts:  97%|| 994/1024 [00:36<00:01, 26.94it/s, est. speed input: 28184.09 toks/s, output: 27.52 toks/s]
Processed prompts:  98%|| 1002/1024 [00:36<00:00, 26.80it/s, est. speed input: 28175.16 toks/s, output: 27.51 toks/s]
Processed prompts:  99%|| 1010/1024 [00:36<00:00, 26.54it/s, est. speed input: 28161.67 toks/s, output: 27.50 toks/s]
Processed prompts:  99%|| 1018/1024 [00:36<00:00, 27.35it/s, est. speed input: 28176.34 toks/s, output: 27.52 toks/s]
Processed prompts: 100%|| 1024/1024 [00:36<00:00, 27.35it/s, est. speed input: 28342.31 toks/s, output: 27.68 toks/s]
Processed prompts: 100%|| 1024/1024 [00:36<00:00, 27.68it/s, est. speed input: 28342.31 toks/s, output: 27.68 toks/s]
[rank0]:[W126 07:37:35.231941643 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 07:37:37
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:37:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:37:46 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1027798) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1027798) WARNING 01-26 07:38:09 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 26.68 requests/s, 27341.95 total tokens/s, 26.68 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 07:37:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:37:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:37:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:37:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:37:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:37:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:37:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:37:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:37:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:37:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:37:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:37:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:37:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:37:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:37:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:37:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:37:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:37:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:37:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:37:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:37:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:37:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:37:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:37:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:37:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:37:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:37:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:37:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1027798) [2026-01-26 07:37:50] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1027798) [2026-01-26 07:37:50] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1027798) [2026-01-26 07:37:50] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1027798) [2026-01-26 07:37:50] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1027798) [2026-01-26 07:37:50] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1027798) [2026-01-26 07:37:50] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1027798) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1027798) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.77s/it]
(EngineCore_DP0 pid=1027798) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.77s/it]
(EngineCore_DP0 pid=1027798) 
(EngineCore_DP0 pid=1027798) [2026-01-26 07:38:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1027798) [2026-01-26 07:38:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=1027798) [2026-01-26 07:38:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1027798) [2026-01-26 07:38:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=1027798) [2026-01-26 07:38:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1027798) [2026-01-26 07:38:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=1027798) [2026-01-26 07:38:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1027798) [2026-01-26 07:38:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=1027798) 2026-01-26 07:38:07,818 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1027798) 2026-01-26 07:38:07,941 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 60/2048 [00:00<00:03, 593.08it/s]
Adding requests:   6%|         | 120/2048 [00:00<00:03, 572.30it/s]
Adding requests:   9%|         | 178/2048 [00:00<00:03, 538.81it/s]
Adding requests:  11%|        | 235/2048 [00:00<00:03, 548.63it/s]
Adding requests:  14%|        | 291/2048 [00:00<00:03, 537.59it/s]
Adding requests:  17%|        | 345/2048 [00:00<00:03, 536.96it/s]
Adding requests:  20%|        | 401/2048 [00:00<00:03, 541.60it/s]
Adding requests:  22%|       | 456/2048 [00:00<00:02, 536.22it/s]
Adding requests:  25%|       | 510/2048 [00:00<00:02, 524.98it/s]
Adding requests:  27%|       | 563/2048 [00:01<00:02, 520.63it/s]
Adding requests:  30%|       | 618/2048 [00:01<00:02, 527.92it/s]
Adding requests:  33%|      | 673/2048 [00:01<00:02, 533.43it/s]
Adding requests:  36%|      | 728/2048 [00:01<00:02, 536.71it/s]
Adding requests:  38%|      | 782/2048 [00:01<00:02, 510.76it/s]
Adding requests:  41%|      | 834/2048 [00:01<00:02, 506.42it/s]
Adding requests:  43%|     | 885/2048 [00:02<00:05, 206.57it/s]
Adding requests:  46%|     | 939/2048 [00:02<00:04, 253.68it/s]
Adding requests:  48%|     | 993/2048 [00:02<00:03, 301.94it/s]
Adding requests:  51%|     | 1047/2048 [00:02<00:02, 347.69it/s]
Adding requests:  54%|    | 1100/2048 [00:02<00:02, 386.10it/s]
Adding requests:  56%|    | 1153/2048 [00:02<00:02, 419.12it/s]
Adding requests:  59%|    | 1209/2048 [00:02<00:01, 453.86it/s]
Adding requests:  62%|   | 1261/2048 [00:02<00:01, 471.07it/s]
Adding requests:  64%|   | 1316/2048 [00:02<00:01, 491.19it/s]
Adding requests:  67%|   | 1369/2048 [00:03<00:01, 497.21it/s]
Adding requests:  69%|   | 1422/2048 [00:03<00:01, 505.29it/s]
Adding requests:  72%|  | 1476/2048 [00:03<00:01, 514.40it/s]
Adding requests:  75%|  | 1530/2048 [00:03<00:00, 520.96it/s]
Adding requests:  77%|  | 1586/2048 [00:03<00:00, 530.56it/s]
Adding requests:  80%|  | 1642/2048 [00:03<00:00, 537.58it/s]
Adding requests:  83%| | 1697/2048 [00:03<00:00, 537.89it/s]
Adding requests:  86%| | 1752/2048 [00:03<00:00, 535.94it/s]
Adding requests:  88%| | 1806/2048 [00:03<00:00, 529.73it/s]
Adding requests:  91%| | 1861/2048 [00:04<00:00, 535.06it/s]
Adding requests:  94%|| 1915/2048 [00:04<00:00, 534.39it/s]
Adding requests:  96%|| 1969/2048 [00:04<00:00, 530.23it/s]
Adding requests:  99%|| 2023/2048 [00:04<00:00, 513.98it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 468.09it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 114/2048 [00:00<00:10, 192.77it/s, est. speed input: 197400.74 toks/s, output: 192.77 toks/s]
Processed prompts:   7%|         | 134/2048 [00:01<00:19, 97.95it/s, est. speed input: 114698.40 toks/s, output: 112.01 toks/s] 
Processed prompts:   7%|         | 146/2048 [00:01<00:30, 62.29it/s, est. speed input: 83189.34 toks/s, output: 81.24 toks/s]  
Processed prompts:   8%|         | 162/2048 [00:02<00:39, 48.32it/s, est. speed input: 69286.23 toks/s, output: 67.66 toks/s]
Processed prompts:   9%|         | 178/2048 [00:02<00:46, 40.51it/s, est. speed input: 60879.02 toks/s, output: 59.45 toks/s]
Processed prompts:   9%|         | 194/2048 [00:03<00:51, 35.87it/s, est. speed input: 55325.29 toks/s, output: 54.03 toks/s]
Processed prompts:  10%|         | 210/2048 [00:04<00:55, 32.87it/s, est. speed input: 51326.42 toks/s, output: 50.12 toks/s]
Processed prompts:  11%|         | 226/2048 [00:04<00:58, 30.98it/s, est. speed input: 48371.64 toks/s, output: 47.24 toks/s]
Processed prompts:  12%|        | 242/2048 [00:05<01:01, 29.58it/s, est. speed input: 45997.46 toks/s, output: 44.92 toks/s]
Processed prompts:  13%|        | 258/2048 [00:05<01:02, 28.69it/s, est. speed input: 44127.84 toks/s, output: 43.09 toks/s]
Processed prompts:  13%|        | 274/2048 [00:06<01:03, 28.11it/s, est. speed input: 42614.86 toks/s, output: 41.62 toks/s]
Processed prompts:  14%|        | 290/2048 [00:07<01:03, 27.63it/s, est. speed input: 41319.36 toks/s, output: 40.35 toks/s]
Processed prompts:  15%|        | 306/2048 [00:07<01:03, 27.40it/s, est. speed input: 40262.53 toks/s, output: 39.32 toks/s]
Processed prompts:  16%|        | 322/2048 [00:08<01:03, 27.17it/s, est. speed input: 39332.73 toks/s, output: 38.41 toks/s]
Processed prompts:  17%|        | 338/2048 [00:08<01:02, 27.40it/s, est. speed input: 38647.85 toks/s, output: 37.74 toks/s]
Processed prompts:  17%|        | 354/2048 [00:09<01:02, 27.17it/s, est. speed input: 37933.13 toks/s, output: 37.04 toks/s]
Processed prompts:  18%|        | 370/2048 [00:10<01:02, 27.06it/s, est. speed input: 37316.28 toks/s, output: 36.44 toks/s]
Processed prompts:  19%|        | 386/2048 [00:10<01:01, 26.92it/s, est. speed input: 36752.41 toks/s, output: 35.89 toks/s]
Processed prompts:  20%|        | 402/2048 [00:11<01:01, 26.83it/s, est. speed input: 36249.78 toks/s, output: 35.40 toks/s]
Processed prompts:  20%|        | 418/2048 [00:11<01:00, 26.76it/s, est. speed input: 35796.00 toks/s, output: 34.96 toks/s]
Processed prompts:  21%|        | 434/2048 [00:12<01:00, 26.66it/s, est. speed input: 35376.81 toks/s, output: 34.55 toks/s]
Processed prompts:  22%|       | 450/2048 [00:13<00:59, 27.08it/s, est. speed input: 35090.27 toks/s, output: 34.27 toks/s]
Processed prompts:  23%|       | 466/2048 [00:13<00:58, 26.91it/s, est. speed input: 34742.09 toks/s, output: 33.93 toks/s]
Processed prompts:  24%|       | 482/2048 [00:14<00:58, 26.88it/s, est. speed input: 34438.20 toks/s, output: 33.63 toks/s]
Processed prompts:  24%|       | 498/2048 [00:14<00:57, 26.75it/s, est. speed input: 34141.16 toks/s, output: 33.34 toks/s]
Processed prompts:  25%|       | 514/2048 [00:15<00:57, 26.68it/s, est. speed input: 33870.03 toks/s, output: 33.08 toks/s]
Processed prompts:  26%|       | 530/2048 [00:16<00:56, 26.67it/s, est. speed input: 33624.95 toks/s, output: 32.84 toks/s]
Processed prompts:  27%|       | 546/2048 [00:16<00:56, 26.67it/s, est. speed input: 33398.31 toks/s, output: 32.62 toks/s]
Processed prompts:  27%|       | 562/2048 [00:17<00:55, 26.71it/s, est. speed input: 33193.41 toks/s, output: 32.42 toks/s]
Processed prompts:  28%|       | 578/2048 [00:17<00:55, 26.67it/s, est. speed input: 32993.05 toks/s, output: 32.22 toks/s]
Processed prompts:  29%|       | 594/2048 [00:18<00:54, 26.71it/s, est. speed input: 32814.10 toks/s, output: 32.04 toks/s]
Processed prompts:  30%|       | 610/2048 [00:19<00:53, 26.68it/s, est. speed input: 32639.86 toks/s, output: 31.87 toks/s]
Processed prompts:  31%|       | 626/2048 [00:19<00:53, 26.71it/s, est. speed input: 32481.72 toks/s, output: 31.72 toks/s]
Processed prompts:  31%|      | 642/2048 [00:20<00:52, 26.67it/s, est. speed input: 32325.39 toks/s, output: 31.57 toks/s]
Processed prompts:  32%|      | 658/2048 [00:20<00:52, 26.63it/s, est. speed input: 32177.70 toks/s, output: 31.42 toks/s]
Processed prompts:  33%|      | 674/2048 [00:21<00:51, 26.69it/s, est. speed input: 32046.78 toks/s, output: 31.30 toks/s]
Processed prompts:  34%|      | 690/2048 [00:22<00:50, 26.67it/s, est. speed input: 31916.82 toks/s, output: 31.17 toks/s]
Processed prompts:  34%|      | 706/2048 [00:22<00:50, 26.71it/s, est. speed input: 31799.89 toks/s, output: 31.05 toks/s]
Processed prompts:  35%|      | 722/2048 [00:23<00:49, 26.68it/s, est. speed input: 31682.67 toks/s, output: 30.94 toks/s]
Processed prompts:  36%|      | 738/2048 [00:23<00:49, 26.68it/s, est. speed input: 31572.82 toks/s, output: 30.83 toks/s]
Processed prompts:  37%|      | 754/2048 [00:24<00:48, 26.63it/s, est. speed input: 31464.06 toks/s, output: 30.73 toks/s]
Processed prompts:  38%|      | 770/2048 [00:25<00:48, 26.59it/s, est. speed input: 31359.97 toks/s, output: 30.62 toks/s]
Processed prompts:  38%|      | 786/2048 [00:25<00:47, 26.66it/s, est. speed input: 31269.56 toks/s, output: 30.54 toks/s]
Processed prompts:  39%|      | 802/2048 [00:26<00:46, 26.60it/s, est. speed input: 31173.76 toks/s, output: 30.44 toks/s]
Processed prompts:  40%|      | 818/2048 [00:26<00:46, 26.69it/s, est. speed input: 31093.84 toks/s, output: 30.37 toks/s]
Processed prompts:  41%|      | 834/2048 [00:27<00:45, 26.70it/s, est. speed input: 31012.78 toks/s, output: 30.29 toks/s]
Processed prompts:  42%|     | 850/2048 [00:28<00:44, 26.69it/s, est. speed input: 30933.69 toks/s, output: 30.21 toks/s]
Processed prompts:  42%|     | 866/2048 [00:28<00:48, 24.49it/s, est. speed input: 30666.74 toks/s, output: 29.95 toks/s]
Processed prompts:  43%|     | 882/2048 [00:29<00:46, 24.92it/s, est. speed input: 30582.06 toks/s, output: 29.87 toks/s]
Processed prompts:  44%|     | 898/2048 [00:30<00:45, 25.45it/s, est. speed input: 30519.85 toks/s, output: 29.80 toks/s]
Processed prompts:  45%|     | 914/2048 [00:30<00:43, 25.78it/s, est. speed input: 30454.77 toks/s, output: 29.74 toks/s]
Processed prompts:  45%|     | 930/2048 [00:31<00:42, 26.52it/s, est. speed input: 30430.36 toks/s, output: 29.72 toks/s]
Processed prompts:  46%|     | 946/2048 [00:31<00:41, 26.50it/s, est. speed input: 30367.51 toks/s, output: 29.66 toks/s]
Processed prompts:  47%|     | 962/2048 [00:32<00:40, 26.63it/s, est. speed input: 30316.42 toks/s, output: 29.61 toks/s]
Processed prompts:  48%|     | 978/2048 [00:33<00:39, 27.04it/s, est. speed input: 30288.87 toks/s, output: 29.58 toks/s]
Processed prompts:  49%|     | 994/2048 [00:33<00:39, 26.89it/s, est. speed input: 30233.21 toks/s, output: 29.52 toks/s]
Processed prompts:  49%|     | 1010/2048 [00:34<00:38, 26.87it/s, est. speed input: 30185.00 toks/s, output: 29.48 toks/s]
Processed prompts:  50%|     | 1026/2048 [00:34<00:38, 26.78it/s, est. speed input: 30133.63 toks/s, output: 29.43 toks/s]
Processed prompts:  51%|     | 1042/2048 [00:35<00:37, 26.71it/s, est. speed input: 30083.66 toks/s, output: 29.38 toks/s]
Processed prompts:  52%|    | 1058/2048 [00:36<00:37, 26.69it/s, est. speed input: 30037.21 toks/s, output: 29.33 toks/s]
Processed prompts:  52%|    | 1074/2048 [00:36<00:36, 26.70it/s, est. speed input: 29993.54 toks/s, output: 29.29 toks/s]
Processed prompts:  53%|    | 1090/2048 [00:37<00:35, 26.64it/s, est. speed input: 29947.05 toks/s, output: 29.25 toks/s]
Processed prompts:  54%|    | 1106/2048 [00:37<00:35, 26.60it/s, est. speed input: 29902.43 toks/s, output: 29.20 toks/s]
Processed prompts:  55%|    | 1122/2048 [00:38<00:34, 26.62it/s, est. speed input: 29861.94 toks/s, output: 29.16 toks/s]
Processed prompts:  56%|    | 1138/2048 [00:39<00:34, 26.56it/s, est. speed input: 29818.44 toks/s, output: 29.12 toks/s]
Processed prompts:  56%|    | 1154/2048 [00:39<00:33, 27.04it/s, est. speed input: 29805.58 toks/s, output: 29.11 toks/s]
Processed prompts:  57%|    | 1170/2048 [00:40<00:32, 26.86it/s, est. speed input: 29764.65 toks/s, output: 29.07 toks/s]
Processed prompts:  58%|    | 1186/2048 [00:40<00:32, 26.85it/s, est. speed input: 29731.32 toks/s, output: 29.03 toks/s]
Processed prompts:  59%|    | 1202/2048 [00:41<00:31, 26.73it/s, est. speed input: 29692.53 toks/s, output: 29.00 toks/s]
Processed prompts:  59%|    | 1218/2048 [00:42<00:31, 26.75it/s, est. speed input: 29660.76 toks/s, output: 28.97 toks/s]
Processed prompts:  60%|    | 1234/2048 [00:42<00:30, 26.67it/s, est. speed input: 29624.58 toks/s, output: 28.93 toks/s]
Processed prompts:  61%|    | 1250/2048 [00:43<00:29, 26.61it/s, est. speed input: 29589.24 toks/s, output: 28.90 toks/s]
Processed prompts:  62%|   | 1266/2048 [00:43<00:28, 27.14it/s, est. speed input: 29583.86 toks/s, output: 28.89 toks/s]
Processed prompts:  63%|   | 1282/2048 [00:44<00:28, 26.94it/s, est. speed input: 29550.39 toks/s, output: 28.86 toks/s]
Processed prompts:  63%|   | 1298/2048 [00:44<00:27, 27.43it/s, est. speed input: 29547.71 toks/s, output: 28.86 toks/s]
Processed prompts:  64%|   | 1314/2048 [00:45<00:27, 27.18it/s, est. speed input: 29517.16 toks/s, output: 28.83 toks/s]
Processed prompts:  65%|   | 1330/2048 [00:46<00:26, 27.08it/s, est. speed input: 29490.99 toks/s, output: 28.80 toks/s]
Processed prompts:  66%|   | 1346/2048 [00:46<00:26, 26.84it/s, est. speed input: 29457.86 toks/s, output: 28.77 toks/s]
Processed prompts:  67%|   | 1362/2048 [00:47<00:25, 26.80it/s, est. speed input: 29431.35 toks/s, output: 28.74 toks/s]
Processed prompts:  67%|   | 1378/2048 [00:47<00:25, 26.72it/s, est. speed input: 29402.63 toks/s, output: 28.71 toks/s]
Processed prompts:  68%|   | 1394/2048 [00:48<00:24, 26.65it/s, est. speed input: 29374.24 toks/s, output: 28.69 toks/s]
Processed prompts:  69%|   | 1410/2048 [00:49<00:23, 26.64it/s, est. speed input: 29348.33 toks/s, output: 28.66 toks/s]
Processed prompts:  70%|   | 1426/2048 [00:49<00:23, 26.60it/s, est. speed input: 29321.74 toks/s, output: 28.63 toks/s]
Processed prompts:  70%|   | 1442/2048 [00:50<00:22, 26.60it/s, est. speed input: 29296.88 toks/s, output: 28.61 toks/s]
Processed prompts:  71%|   | 1458/2048 [00:51<00:22, 26.60it/s, est. speed input: 29272.69 toks/s, output: 28.59 toks/s]
Processed prompts:  72%|  | 1474/2048 [00:51<00:21, 26.65it/s, est. speed input: 29251.03 toks/s, output: 28.57 toks/s]
Processed prompts:  73%|  | 1490/2048 [00:52<00:20, 26.62it/s, est. speed input: 29227.14 toks/s, output: 28.54 toks/s]
Processed prompts:  74%|  | 1506/2048 [00:52<00:20, 26.60it/s, est. speed input: 29203.93 toks/s, output: 28.52 toks/s]
Processed prompts:  74%|  | 1522/2048 [00:53<00:19, 26.68it/s, est. speed input: 29184.88 toks/s, output: 28.50 toks/s]
Processed prompts:  75%|  | 1538/2048 [00:54<00:19, 26.61it/s, est. speed input: 29161.56 toks/s, output: 28.48 toks/s]
Processed prompts:  76%|  | 1554/2048 [00:54<00:18, 26.67it/s, est. speed input: 29142.74 toks/s, output: 28.46 toks/s]
Processed prompts:  77%|  | 1570/2048 [00:55<00:17, 26.63it/s, est. speed input: 29121.51 toks/s, output: 28.44 toks/s]
Processed prompts:  77%|  | 1586/2048 [00:55<00:17, 27.14it/s, est. speed input: 29121.18 toks/s, output: 28.44 toks/s]
Processed prompts:  78%|  | 1602/2048 [00:56<00:16, 26.94it/s, est. speed input: 29099.78 toks/s, output: 28.42 toks/s]
Processed prompts:  79%|  | 1618/2048 [00:56<00:16, 26.87it/s, est. speed input: 29081.31 toks/s, output: 28.40 toks/s]
Processed prompts:  80%|  | 1634/2048 [00:57<00:15, 26.76it/s, est. speed input: 29060.81 toks/s, output: 28.38 toks/s]
Processed prompts:  81%|  | 1650/2048 [00:58<00:14, 27.15it/s, est. speed input: 29058.30 toks/s, output: 28.38 toks/s]
Processed prompts:  81%| | 1666/2048 [00:58<00:14, 27.05it/s, est. speed input: 29041.93 toks/s, output: 28.36 toks/s]
Processed prompts:  82%| | 1682/2048 [00:59<00:13, 26.88it/s, est. speed input: 29022.59 toks/s, output: 28.34 toks/s]
Processed prompts:  83%| | 1698/2048 [00:59<00:13, 26.85it/s, est. speed input: 29006.62 toks/s, output: 28.33 toks/s]
Processed prompts:  84%| | 1714/2048 [01:00<00:12, 26.76it/s, est. speed input: 28988.39 toks/s, output: 28.31 toks/s]
Processed prompts:  84%| | 1730/2048 [01:01<00:11, 26.77it/s, est. speed input: 28973.28 toks/s, output: 28.29 toks/s]
Processed prompts:  85%| | 1746/2048 [01:01<00:11, 26.33it/s, est. speed input: 28942.69 toks/s, output: 28.26 toks/s]
Processed prompts:  86%| | 1762/2048 [01:02<00:10, 26.25it/s, est. speed input: 28920.42 toks/s, output: 28.24 toks/s]
Processed prompts:  87%| | 1778/2048 [01:02<00:10, 26.37it/s, est. speed input: 28904.80 toks/s, output: 28.23 toks/s]
Processed prompts:  88%| | 1794/2048 [01:03<00:09, 26.43it/s, est. speed input: 28888.92 toks/s, output: 28.21 toks/s]
Processed prompts:  88%| | 1810/2048 [01:04<00:08, 26.51it/s, est. speed input: 28874.34 toks/s, output: 28.20 toks/s]
Processed prompts:  89%| | 1826/2048 [01:04<00:08, 26.54it/s, est. speed input: 28859.19 toks/s, output: 28.18 toks/s]
Processed prompts:  90%| | 1842/2048 [01:05<00:07, 26.56it/s, est. speed input: 28844.51 toks/s, output: 28.17 toks/s]
Processed prompts:  91%| | 1858/2048 [01:05<00:07, 26.58it/s, est. speed input: 28830.08 toks/s, output: 28.15 toks/s]
Processed prompts:  92%|| 1874/2048 [01:06<00:06, 27.07it/s, est. speed input: 28831.34 toks/s, output: 28.16 toks/s]
Processed prompts:  92%|| 1890/2048 [01:07<00:05, 26.95it/s, est. speed input: 28817.75 toks/s, output: 28.14 toks/s]
Processed prompts:  93%|| 1906/2048 [01:07<00:05, 26.86it/s, est. speed input: 28804.15 toks/s, output: 28.13 toks/s]
Processed prompts:  94%|| 1922/2048 [01:08<00:04, 26.82it/s, est. speed input: 28791.50 toks/s, output: 28.12 toks/s]
Processed prompts:  95%|| 1938/2048 [01:08<00:04, 26.72it/s, est. speed input: 28777.12 toks/s, output: 28.10 toks/s]
Processed prompts:  95%|| 1954/2048 [01:09<00:03, 27.25it/s, est. speed input: 28781.02 toks/s, output: 28.11 toks/s]
Processed prompts:  96%|| 1970/2048 [01:10<00:02, 27.01it/s, est. speed input: 28766.45 toks/s, output: 28.09 toks/s]
Processed prompts:  97%|| 1986/2048 [01:10<00:02, 27.41it/s, est. speed input: 28768.82 toks/s, output: 28.09 toks/s]
Processed prompts:  98%|| 2002/2048 [01:11<00:01, 27.98it/s, est. speed input: 28779.10 toks/s, output: 28.10 toks/s]
Processed prompts:  99%|| 2018/2048 [01:11<00:01, 27.63it/s, est. speed input: 28768.42 toks/s, output: 28.09 toks/s]
Processed prompts:  99%|| 2034/2048 [01:12<00:00, 27.78it/s, est. speed input: 28768.71 toks/s, output: 28.09 toks/s]
Processed prompts: 100%|| 2048/2048 [01:12<00:00, 27.78it/s, est. speed input: 28966.64 toks/s, output: 28.29 toks/s]
Processed prompts: 100%|| 2048/2048 [01:12<00:00, 28.29it/s, est. speed input: 28966.64 toks/s, output: 28.29 toks/s]
[rank0]:[W126 07:39:26.248122571 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 07:39:28
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:39:43 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:39:43 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1029587) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1029587) WARNING 01-26 07:40:07 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 26.98 requests/s, 27652.21 total tokens/s, 26.98 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 07:39:43] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:39:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:39:43] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:39:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:39:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:39:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:39:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:39:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:39:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:39:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:39:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:39:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:39:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:39:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:39:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:39:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:39:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:39:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:39:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1029587) [2026-01-26 07:39:47] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1029587) [2026-01-26 07:39:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1029587) [2026-01-26 07:39:47] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1029587) [2026-01-26 07:39:47] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1029587) [2026-01-26 07:39:47] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1029587) [2026-01-26 07:39:47] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1029587) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1029587) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.64s/it]
(EngineCore_DP0 pid=1029587) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.64s/it]
(EngineCore_DP0 pid=1029587) 
(EngineCore_DP0 pid=1029587) [2026-01-26 07:39:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1029587) [2026-01-26 07:39:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=1029587) [2026-01-26 07:39:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1029587) [2026-01-26 07:39:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=1029587) [2026-01-26 07:39:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1029587) [2026-01-26 07:39:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=1029587) [2026-01-26 07:39:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1029587) [2026-01-26 07:39:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=1029587) 2026-01-26 07:40:05,211 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1029587) 2026-01-26 07:40:05,435 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   2%|         | 65/4096 [00:00<00:06, 639.86it/s]
Adding requests:   3%|         | 129/4096 [00:00<00:06, 622.67it/s]
Adding requests:   5%|         | 192/4096 [00:00<00:06, 562.70it/s]
Adding requests:   6%|         | 249/4096 [00:00<00:06, 555.33it/s]
Adding requests:   7%|         | 305/4096 [00:00<00:07, 540.87it/s]
Adding requests:   9%|         | 360/4096 [00:00<00:06, 542.23it/s]
Adding requests:  10%|         | 415/4096 [00:00<00:06, 530.78it/s]
Adding requests:  11%|        | 469/4096 [00:00<00:06, 530.27it/s]
Adding requests:  13%|        | 523/4096 [00:00<00:06, 518.12it/s]
Adding requests:  14%|        | 576/4096 [00:01<00:06, 520.26it/s]
Adding requests:  15%|        | 630/4096 [00:01<00:06, 525.96it/s]
Adding requests:  17%|        | 683/4096 [00:01<00:06, 526.10it/s]
Adding requests:  18%|        | 736/4096 [00:01<00:06, 524.64it/s]
Adding requests:  19%|        | 789/4096 [00:01<00:06, 511.79it/s]
Adding requests:  21%|        | 841/4096 [00:01<00:06, 499.56it/s]
Adding requests:  22%|       | 896/4096 [00:01<00:06, 512.91it/s]
Adding requests:  23%|       | 949/4096 [00:01<00:06, 517.78it/s]
Adding requests:  24%|       | 1002/4096 [00:01<00:05, 519.79it/s]
Adding requests:  26%|       | 1058/4096 [00:01<00:05, 529.45it/s]
Adding requests:  27%|       | 1112/4096 [00:02<00:05, 520.81it/s]
Adding requests:  28%|       | 1167/4096 [00:02<00:05, 527.90it/s]
Adding requests:  30%|       | 1220/4096 [00:02<00:05, 495.11it/s]
Adding requests:  31%|       | 1270/4096 [00:02<00:05, 496.05it/s]
Adding requests:  32%|      | 1323/4096 [00:02<00:05, 503.60it/s]
Adding requests:  34%|      | 1374/4096 [00:02<00:05, 498.36it/s]
Adding requests:  35%|      | 1427/4096 [00:02<00:05, 506.11it/s]
Adding requests:  36%|      | 1482/4096 [00:02<00:05, 515.57it/s]
Adding requests:  38%|      | 1536/4096 [00:02<00:04, 520.54it/s]
Adding requests:  39%|      | 1592/4096 [00:03<00:04, 530.75it/s]
Adding requests:  40%|      | 1647/4096 [00:03<00:04, 533.01it/s]
Adding requests:  42%|     | 1701/4096 [00:03<00:04, 524.49it/s]
Adding requests:  43%|     | 1758/4096 [00:03<00:04, 536.34it/s]
Adding requests:  44%|     | 1812/4096 [00:03<00:04, 528.35it/s]
Adding requests:  46%|     | 1866/4096 [00:03<00:04, 531.32it/s]
Adding requests:  47%|     | 1922/4096 [00:03<00:04, 538.53it/s]
Adding requests:  48%|     | 1976/4096 [00:03<00:04, 522.92it/s]
Adding requests:  50%|     | 2029/4096 [00:03<00:03, 521.67it/s]
Adding requests:  51%|     | 2082/4096 [00:03<00:03, 522.69it/s]
Adding requests:  52%|    | 2135/4096 [00:04<00:03, 513.09it/s]
Adding requests:  53%|    | 2187/4096 [00:04<00:03, 506.52it/s]
Adding requests:  55%|    | 2241/4096 [00:04<00:03, 515.32it/s]
Adding requests:  56%|    | 2293/4096 [00:04<00:03, 514.12it/s]
Adding requests:  57%|    | 2348/4096 [00:04<00:03, 520.49it/s]
Adding requests:  59%|    | 2401/4096 [00:04<00:03, 522.46it/s]
Adding requests:  60%|    | 2454/4096 [00:04<00:03, 506.92it/s]
Adding requests:  61%|    | 2505/4096 [00:04<00:03, 505.35it/s]
Adding requests:  62%|   | 2558/4096 [00:04<00:03, 509.25it/s]
Adding requests:  64%|   | 2611/4096 [00:05<00:02, 515.05it/s]
Adding requests:  65%|   | 2663/4096 [00:05<00:02, 513.12it/s]
Adding requests:  66%|   | 2715/4096 [00:05<00:02, 511.47it/s]
Adding requests:  68%|   | 2768/4096 [00:05<00:02, 516.46it/s]
Adding requests:  69%|   | 2820/4096 [00:05<00:02, 510.43it/s]
Adding requests:  70%|   | 2875/4096 [00:05<00:02, 521.32it/s]
Adding requests:  71%|  | 2928/4096 [00:05<00:02, 516.63it/s]
Adding requests:  73%|  | 2980/4096 [00:05<00:02, 517.06it/s]
Adding requests:  74%|  | 3032/4096 [00:05<00:02, 515.76it/s]
Adding requests:  75%|  | 3084/4096 [00:05<00:01, 510.45it/s]
Adding requests:  77%|  | 3136/4096 [00:06<00:01, 511.44it/s]
Adding requests:  78%|  | 3192/4096 [00:06<00:01, 523.49it/s]
Adding requests:  79%|  | 3245/4096 [00:06<00:01, 524.89it/s]
Adding requests:  81%|  | 3299/4096 [00:06<00:01, 525.50it/s]
Adding requests:  82%| | 3352/4096 [00:06<00:01, 523.36it/s]
Adding requests:  83%| | 3405/4096 [00:06<00:01, 522.87it/s]
Adding requests:  84%| | 3458/4096 [00:06<00:01, 523.15it/s]
Adding requests:  86%| | 3512/4096 [00:06<00:01, 526.04it/s]
Adding requests:  87%| | 3565/4096 [00:06<00:01, 518.10it/s]
Adding requests:  88%| | 3619/4096 [00:06<00:00, 521.43it/s]
Adding requests:  90%| | 3673/4096 [00:07<00:00, 525.73it/s]
Adding requests:  91%| | 3729/4096 [00:07<00:00, 532.99it/s]
Adding requests:  92%|| 3783/4096 [00:07<00:00, 513.43it/s]
Adding requests:  94%|| 3836/4096 [00:07<00:00, 514.46it/s]
Adding requests:  95%|| 3888/4096 [00:07<00:00, 513.50it/s]
Adding requests:  96%|| 3940/4096 [00:07<00:00, 511.34it/s]
Adding requests:  98%|| 3994/4096 [00:07<00:00, 518.82it/s]
Adding requests:  99%|| 4048/4096 [00:07<00:00, 523.74it/s]
Adding requests: 100%|| 4096/4096 [00:07<00:00, 521.34it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 194/4096 [00:00<00:13, 278.94it/s, est. speed input: 285638.16 toks/s, output: 278.94 toks/s]
Processed prompts:   6%|         | 226/4096 [00:01<00:38, 99.77it/s, est. speed input: 122419.03 toks/s, output: 119.55 toks/s] 
Processed prompts:   6%|         | 258/4096 [00:03<01:01, 62.90it/s, est. speed input: 85522.98 toks/s, output: 83.52 toks/s]  
Processed prompts:   7%|         | 290/4096 [00:04<01:19, 47.71it/s, est. speed input: 69229.40 toks/s, output: 67.61 toks/s]
Processed prompts:   8%|         | 322/4096 [00:05<01:34, 39.99it/s, est. speed input: 60208.74 toks/s, output: 58.80 toks/s]
Processed prompts:   9%|         | 354/4096 [00:06<01:45, 35.40it/s, est. speed input: 54344.42 toks/s, output: 53.07 toks/s]
Processed prompts:   9%|         | 386/4096 [00:07<01:54, 32.50it/s, est. speed input: 50231.38 toks/s, output: 49.05 toks/s]
Processed prompts:  10%|         | 418/4096 [00:09<01:59, 30.67it/s, est. speed input: 47230.14 toks/s, output: 46.12 toks/s]
Processed prompts:  11%|         | 450/4096 [00:10<02:03, 29.53it/s, est. speed input: 44973.44 toks/s, output: 43.92 toks/s]
Processed prompts:  12%|        | 482/4096 [00:11<02:06, 28.67it/s, est. speed input: 43138.21 toks/s, output: 42.13 toks/s]
Processed prompts:  13%|        | 514/4096 [00:12<02:07, 28.03it/s, est. speed input: 41623.93 toks/s, output: 40.65 toks/s]
Processed prompts:  13%|        | 546/4096 [00:13<02:08, 27.67it/s, est. speed input: 40406.42 toks/s, output: 39.46 toks/s]
Processed prompts:  14%|        | 578/4096 [00:15<02:08, 27.36it/s, est. speed input: 39360.50 toks/s, output: 38.44 toks/s]
Processed prompts:  15%|        | 610/4096 [00:16<02:08, 27.21it/s, est. speed input: 38488.47 toks/s, output: 37.59 toks/s]
Processed prompts:  16%|        | 642/4096 [00:17<02:07, 27.07it/s, est. speed input: 37725.70 toks/s, output: 36.84 toks/s]
Processed prompts:  16%|        | 674/4096 [00:18<02:06, 26.99it/s, est. speed input: 37066.57 toks/s, output: 36.20 toks/s]
Processed prompts:  17%|        | 706/4096 [00:19<02:05, 26.93it/s, est. speed input: 36487.30 toks/s, output: 35.63 toks/s]
Processed prompts:  18%|        | 738/4096 [00:21<02:04, 26.87it/s, est. speed input: 35966.57 toks/s, output: 35.12 toks/s]
Processed prompts:  19%|        | 770/4096 [00:22<02:03, 26.83it/s, est. speed input: 35503.73 toks/s, output: 34.67 toks/s]
Processed prompts:  20%|        | 802/4096 [00:23<02:02, 26.80it/s, est. speed input: 35088.02 toks/s, output: 34.27 toks/s]
Processed prompts:  20%|        | 834/4096 [00:24<02:01, 26.74it/s, est. speed input: 34704.93 toks/s, output: 33.89 toks/s]
Processed prompts:  21%|        | 866/4096 [00:25<02:00, 26.73it/s, est. speed input: 34363.95 toks/s, output: 33.56 toks/s]
Processed prompts:  22%|       | 898/4096 [00:27<01:59, 26.74it/s, est. speed input: 34056.08 toks/s, output: 33.26 toks/s]
Processed prompts:  23%|       | 930/4096 [00:28<01:57, 26.85it/s, est. speed input: 33791.96 toks/s, output: 33.00 toks/s]
Processed prompts:  23%|       | 962/4096 [00:29<01:56, 26.95it/s, est. speed input: 33553.81 toks/s, output: 32.77 toks/s]
Processed prompts:  24%|       | 994/4096 [00:30<01:55, 26.92it/s, est. speed input: 33317.08 toks/s, output: 32.54 toks/s]
Processed prompts:  25%|       | 1026/4096 [00:31<01:54, 26.84it/s, est. speed input: 33089.06 toks/s, output: 32.31 toks/s]
Processed prompts:  26%|       | 1058/4096 [00:32<01:53, 26.78it/s, est. speed input: 32877.68 toks/s, output: 32.11 toks/s]
Processed prompts:  27%|       | 1090/4096 [00:34<01:52, 26.78it/s, est. speed input: 32686.40 toks/s, output: 31.92 toks/s]
Processed prompts:  27%|       | 1122/4096 [00:35<01:51, 26.75it/s, est. speed input: 32504.34 toks/s, output: 31.74 toks/s]
Processed prompts:  28%|       | 1154/4096 [00:36<01:49, 26.91it/s, est. speed input: 32357.90 toks/s, output: 31.60 toks/s]
Processed prompts:  29%|       | 1186/4096 [00:37<01:48, 26.88it/s, est. speed input: 32203.30 toks/s, output: 31.45 toks/s]
Processed prompts:  30%|       | 1218/4096 [00:38<01:47, 26.85it/s, est. speed input: 32056.61 toks/s, output: 31.31 toks/s]
Processed prompts:  31%|       | 1250/4096 [00:40<01:45, 26.98it/s, est. speed input: 31936.14 toks/s, output: 31.19 toks/s]
Processed prompts:  31%|      | 1282/4096 [00:41<01:44, 27.02it/s, est. speed input: 31816.86 toks/s, output: 31.07 toks/s]
Processed prompts:  32%|      | 1314/4096 [00:42<01:43, 26.91it/s, est. speed input: 31688.58 toks/s, output: 30.95 toks/s]
Processed prompts:  33%|      | 1346/4096 [00:43<01:42, 26.86it/s, est. speed input: 31571.14 toks/s, output: 30.83 toks/s]
Processed prompts:  34%|      | 1378/4096 [00:44<01:41, 26.82it/s, est. speed input: 31458.63 toks/s, output: 30.72 toks/s]
Processed prompts:  34%|      | 1410/4096 [00:46<01:40, 26.79it/s, est. speed input: 31352.68 toks/s, output: 30.62 toks/s]
Processed prompts:  35%|      | 1442/4096 [00:47<01:39, 26.81it/s, est. speed input: 31254.81 toks/s, output: 30.52 toks/s]
Processed prompts:  36%|      | 1474/4096 [00:48<01:37, 26.76it/s, est. speed input: 31156.89 toks/s, output: 30.43 toks/s]
Processed prompts:  37%|      | 1506/4096 [00:49<01:36, 26.77it/s, est. speed input: 31067.28 toks/s, output: 30.34 toks/s]
Processed prompts:  38%|      | 1538/4096 [00:50<01:35, 26.76it/s, est. speed input: 30980.48 toks/s, output: 30.25 toks/s]
Processed prompts:  38%|      | 1570/4096 [00:52<01:34, 26.84it/s, est. speed input: 30905.07 toks/s, output: 30.18 toks/s]
Processed prompts:  39%|      | 1602/4096 [00:53<01:33, 26.80it/s, est. speed input: 30825.02 toks/s, output: 30.10 toks/s]
Processed prompts:  40%|      | 1634/4096 [00:54<01:31, 26.94it/s, est. speed input: 30762.93 toks/s, output: 30.04 toks/s]
Processed prompts:  41%|      | 1666/4096 [00:55<01:30, 26.88it/s, est. speed input: 30689.59 toks/s, output: 29.97 toks/s]
Processed prompts:  41%|     | 1698/4096 [00:56<01:29, 26.76it/s, est. speed input: 30614.07 toks/s, output: 29.90 toks/s]
Processed prompts:  42%|     | 1730/4096 [00:57<01:28, 26.75it/s, est. speed input: 30546.67 toks/s, output: 29.83 toks/s]
Processed prompts:  43%|     | 1762/4096 [00:59<01:27, 26.73it/s, est. speed input: 30481.34 toks/s, output: 29.77 toks/s]
Processed prompts:  44%|     | 1794/4096 [01:00<01:26, 26.71it/s, est. speed input: 30418.54 toks/s, output: 29.71 toks/s]
Processed prompts:  45%|     | 1826/4096 [01:01<01:24, 26.71it/s, est. speed input: 30358.57 toks/s, output: 29.65 toks/s]
Processed prompts:  45%|     | 1858/4096 [01:02<01:23, 26.84it/s, est. speed input: 30310.82 toks/s, output: 29.60 toks/s]
Processed prompts:  46%|     | 1890/4096 [01:03<01:22, 26.80it/s, est. speed input: 30255.18 toks/s, output: 29.55 toks/s]
Processed prompts:  47%|     | 1922/4096 [01:05<01:21, 26.78it/s, est. speed input: 30202.44 toks/s, output: 29.49 toks/s]
Processed prompts:  48%|     | 1954/4096 [01:06<01:19, 26.86it/s, est. speed input: 30157.90 toks/s, output: 29.45 toks/s]
Processed prompts:  48%|     | 1986/4096 [01:07<01:16, 27.41it/s, est. speed input: 30146.65 toks/s, output: 29.44 toks/s]
Processed prompts:  49%|     | 2018/4096 [01:08<01:16, 27.20it/s, est. speed input: 30098.05 toks/s, output: 29.39 toks/s]
Processed prompts:  50%|     | 2050/4096 [01:09<01:14, 27.39it/s, est. speed input: 30071.85 toks/s, output: 29.37 toks/s]
Processed prompts:  51%|     | 2082/4096 [01:10<01:13, 27.34it/s, est. speed input: 30035.49 toks/s, output: 29.33 toks/s]
Processed prompts:  52%|    | 2114/4096 [01:12<01:13, 27.10it/s, est. speed input: 29987.97 toks/s, output: 29.29 toks/s]
Processed prompts:  52%|    | 2146/4096 [01:13<01:12, 26.99it/s, est. speed input: 29945.49 toks/s, output: 29.24 toks/s]
Processed prompts:  53%|    | 2178/4096 [01:14<01:10, 27.30it/s, est. speed input: 29926.99 toks/s, output: 29.23 toks/s]
Processed prompts:  54%|    | 2210/4096 [01:15<01:08, 27.52it/s, est. speed input: 29908.61 toks/s, output: 29.21 toks/s]
Processed prompts:  55%|    | 2242/4096 [01:16<01:07, 27.29it/s, est. speed input: 29869.60 toks/s, output: 29.17 toks/s]
Processed prompts:  56%|    | 2274/4096 [01:18<01:06, 27.24it/s, est. speed input: 29838.17 toks/s, output: 29.14 toks/s]
Processed prompts:  56%|    | 2306/4096 [01:19<01:05, 27.24it/s, est. speed input: 29809.46 toks/s, output: 29.11 toks/s]
Processed prompts:  57%|    | 2338/4096 [01:20<01:04, 27.22it/s, est. speed input: 29780.28 toks/s, output: 29.08 toks/s]
Processed prompts:  58%|    | 2370/4096 [01:21<01:02, 27.73it/s, est. speed input: 29778.85 toks/s, output: 29.08 toks/s]
Processed prompts:  59%|    | 2402/4096 [01:22<01:01, 27.59it/s, est. speed input: 29752.47 toks/s, output: 29.06 toks/s]
Processed prompts:  59%|    | 2434/4096 [01:23<01:00, 27.41it/s, est. speed input: 29722.73 toks/s, output: 29.03 toks/s]
Processed prompts:  60%|    | 2466/4096 [01:25<00:59, 27.37it/s, est. speed input: 29697.92 toks/s, output: 29.00 toks/s]
Processed prompts:  61%|    | 2498/4096 [01:26<00:58, 27.33it/s, est. speed input: 29673.56 toks/s, output: 28.98 toks/s]
Processed prompts:  62%|   | 2530/4096 [01:27<00:57, 27.15it/s, est. speed input: 29642.24 toks/s, output: 28.95 toks/s]
Processed prompts:  63%|   | 2562/4096 [01:28<00:56, 27.11it/s, est. speed input: 29615.78 toks/s, output: 28.92 toks/s]
Processed prompts:  63%|   | 2594/4096 [01:29<00:55, 27.10it/s, est. speed input: 29590.81 toks/s, output: 28.90 toks/s]
Processed prompts:  64%|   | 2626/4096 [01:30<00:54, 26.98it/s, est. speed input: 29561.17 toks/s, output: 28.87 toks/s]
Processed prompts:  65%|   | 2658/4096 [01:32<00:53, 26.94it/s, est. speed input: 29534.51 toks/s, output: 28.84 toks/s]
Processed prompts:  66%|   | 2690/4096 [01:33<00:51, 27.22it/s, est. speed input: 29522.48 toks/s, output: 28.83 toks/s]
Processed prompts:  66%|   | 2722/4096 [01:34<00:50, 27.05it/s, est. speed input: 29494.12 toks/s, output: 28.80 toks/s]
Processed prompts:  67%|   | 2754/4096 [01:35<00:49, 27.09it/s, est. speed input: 29473.85 toks/s, output: 28.78 toks/s]
Processed prompts:  68%|   | 2786/4096 [01:36<00:48, 26.91it/s, est. speed input: 29444.82 toks/s, output: 28.75 toks/s]
Processed prompts:  69%|   | 2818/4096 [01:38<00:46, 27.25it/s, est. speed input: 29436.66 toks/s, output: 28.75 toks/s]
Processed prompts:  70%|   | 2850/4096 [01:39<00:45, 27.24it/s, est. speed input: 29418.05 toks/s, output: 28.73 toks/s]
Processed prompts:  70%|   | 2882/4096 [01:40<00:44, 27.06it/s, est. speed input: 29392.75 toks/s, output: 28.70 toks/s]
Processed prompts:  71%|   | 2914/4096 [01:41<00:43, 26.97it/s, est. speed input: 29369.07 toks/s, output: 28.68 toks/s]
Processed prompts:  72%|  | 2946/4096 [01:42<00:42, 27.05it/s, est. speed input: 29352.37 toks/s, output: 28.66 toks/s]
Processed prompts:  73%|  | 2978/4096 [01:43<00:41, 26.92it/s, est. speed input: 29328.32 toks/s, output: 28.64 toks/s]
Processed prompts:  73%|  | 3010/4096 [01:45<00:39, 27.26it/s, est. speed input: 29322.13 toks/s, output: 28.63 toks/s]
Processed prompts:  74%|  | 3042/4096 [01:46<00:38, 27.22it/s, est. speed input: 29304.80 toks/s, output: 28.62 toks/s]
Processed prompts:  75%|  | 3074/4096 [01:47<00:37, 27.04it/s, est. speed input: 29282.16 toks/s, output: 28.60 toks/s]
Processed prompts:  76%|  | 3106/4096 [01:48<00:35, 27.58it/s, est. speed input: 29285.78 toks/s, output: 28.60 toks/s]
Processed prompts:  77%|  | 3138/4096 [01:49<00:34, 27.73it/s, est. speed input: 29280.34 toks/s, output: 28.59 toks/s]
Processed prompts:  77%|  | 3170/4096 [01:50<00:33, 27.43it/s, est. speed input: 29259.78 toks/s, output: 28.57 toks/s]
Processed prompts:  78%|  | 3202/4096 [01:52<00:32, 27.61it/s, est. speed input: 29254.24 toks/s, output: 28.57 toks/s]
Processed prompts:  79%|  | 3234/4096 [01:53<00:31, 27.48it/s, est. speed input: 29239.43 toks/s, output: 28.55 toks/s]
Processed prompts:  80%|  | 3266/4096 [01:54<00:30, 27.26it/s, est. speed input: 29220.27 toks/s, output: 28.54 toks/s]
Processed prompts:  81%|  | 3298/4096 [01:55<00:29, 27.23it/s, est. speed input: 29206.00 toks/s, output: 28.52 toks/s]
Processed prompts:  81%| | 3330/4096 [01:56<00:27, 27.48it/s, est. speed input: 29201.43 toks/s, output: 28.52 toks/s]
Processed prompts:  82%| | 3362/4096 [01:57<00:26, 27.22it/s, est. speed input: 29181.76 toks/s, output: 28.50 toks/s]
Processed prompts:  83%| | 3394/4096 [01:59<00:25, 27.07it/s, est. speed input: 29163.43 toks/s, output: 28.48 toks/s]
Processed prompts:  84%| | 3426/4096 [02:00<00:24, 27.09it/s, est. speed input: 29150.07 toks/s, output: 28.47 toks/s]
Processed prompts:  84%| | 3458/4096 [02:01<00:23, 27.10it/s, est. speed input: 29136.58 toks/s, output: 28.45 toks/s]
Processed prompts:  85%| | 3490/4096 [02:02<00:22, 27.38it/s, est. speed input: 29132.91 toks/s, output: 28.45 toks/s]
Processed prompts:  86%| | 3522/4096 [02:03<00:21, 27.19it/s, est. speed input: 29116.16 toks/s, output: 28.43 toks/s]
Processed prompts:  87%| | 3554/4096 [02:05<00:20, 27.03it/s, est. speed input: 29098.68 toks/s, output: 28.42 toks/s]
Processed prompts:  88%| | 3586/4096 [02:06<00:18, 26.93it/s, est. speed input: 29082.04 toks/s, output: 28.40 toks/s]
Processed prompts:  88%| | 3618/4096 [02:07<00:17, 26.86it/s, est. speed input: 29065.49 toks/s, output: 28.38 toks/s]
Processed prompts:  89%| | 3650/4096 [02:08<00:16, 26.92it/s, est. speed input: 29053.30 toks/s, output: 28.37 toks/s]
Processed prompts:  90%| | 3682/4096 [02:09<00:15, 27.00it/s, est. speed input: 29042.36 toks/s, output: 28.36 toks/s]
Processed prompts:  91%| | 3714/4096 [02:11<00:14, 27.05it/s, est. speed input: 29031.22 toks/s, output: 28.35 toks/s]
Processed prompts:  91%|| 3746/4096 [02:12<00:12, 26.97it/s, est. speed input: 29016.80 toks/s, output: 28.34 toks/s]
Processed prompts:  92%|| 3778/4096 [02:13<00:11, 26.88it/s, est. speed input: 29001.49 toks/s, output: 28.32 toks/s]
Processed prompts:  93%|| 3810/4096 [02:14<00:10, 26.98it/s, est. speed input: 28991.49 toks/s, output: 28.31 toks/s]
Processed prompts:  94%|| 3842/4096 [02:15<00:09, 27.28it/s, est. speed input: 28988.87 toks/s, output: 28.31 toks/s]
Processed prompts:  95%|| 3874/4096 [02:16<00:08, 27.10it/s, est. speed input: 28974.50 toks/s, output: 28.30 toks/s]
Processed prompts:  95%|| 3906/4096 [02:18<00:07, 27.00it/s, est. speed input: 28960.91 toks/s, output: 28.28 toks/s]
Processed prompts:  96%|| 3938/4096 [02:19<00:05, 27.02it/s, est. speed input: 28950.24 toks/s, output: 28.27 toks/s]
Processed prompts:  97%|| 3970/4096 [02:20<00:04, 26.90it/s, est. speed input: 28935.85 toks/s, output: 28.26 toks/s]
Processed prompts:  98%|| 4002/4096 [02:21<00:03, 26.86it/s, est. speed input: 28922.95 toks/s, output: 28.25 toks/s]
Processed prompts:  98%|| 4034/4096 [02:22<00:02, 27.46it/s, est. speed input: 28928.80 toks/s, output: 28.25 toks/s]
Processed prompts:  99%|| 4066/4096 [02:23<00:01, 27.39it/s, est. speed input: 28920.10 toks/s, output: 28.24 toks/s]
Processed prompts: 100%|| 4096/4096 [02:23<00:00, 27.39it/s, est. speed input: 29133.38 toks/s, output: 28.45 toks/s]
Processed prompts: 100%|| 4096/4096 [02:23<00:00, 28.45it/s, est. speed input: 29133.38 toks/s, output: 28.45 toks/s]
[rank0]:[W126 07:42:39.512610028 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 07:42:41
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:43:07 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:43:07 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1032598) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1032598) WARNING 01-26 07:43:33 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 26.63 requests/s, 27293.39 total tokens/s, 26.63 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 07:43:07] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:43:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:43:07] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:43:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:43:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:43:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:43:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:43:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:43:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:43:10] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:43:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:43:10] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:43:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:43:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:43:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:43:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:43:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:43:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:43:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1032598) [2026-01-26 07:43:11] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1032598) [2026-01-26 07:43:11] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1032598) [2026-01-26 07:43:11] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1032598) [2026-01-26 07:43:11] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1032598) [2026-01-26 07:43:11] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1032598) [2026-01-26 07:43:11] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1032598) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1032598) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.57s/it]
(EngineCore_DP0 pid=1032598) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.57s/it]
(EngineCore_DP0 pid=1032598) 
(EngineCore_DP0 pid=1032598) [2026-01-26 07:43:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1032598) [2026-01-26 07:43:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=1032598) [2026-01-26 07:43:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1032598) [2026-01-26 07:43:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=1032598) [2026-01-26 07:43:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1032598) [2026-01-26 07:43:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=1032598) [2026-01-26 07:43:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1032598) [2026-01-26 07:43:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=1032598) 2026-01-26 07:43:30,580 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1032598) 2026-01-26 07:43:30,822 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 66/8192 [00:00<00:12, 655.36it/s]
Adding requests:   2%|         | 132/8192 [00:00<00:14, 561.78it/s]
Adding requests:   2%|         | 192/8192 [00:00<00:13, 575.44it/s]
Adding requests:   3%|         | 252/8192 [00:00<00:13, 583.44it/s]
Adding requests:   4%|         | 316/8192 [00:00<00:13, 602.27it/s]
Adding requests:   5%|         | 383/8192 [00:00<00:12, 623.47it/s]
Adding requests:   5%|         | 450/8192 [00:00<00:12, 637.94it/s]
Adding requests:   6%|         | 514/8192 [00:00<00:12, 631.65it/s]
Adding requests:   7%|         | 578/8192 [00:00<00:12, 612.28it/s]
Adding requests:   8%|         | 640/8192 [00:01<00:12, 607.21it/s]
Adding requests:   9%|         | 701/8192 [00:01<00:13, 565.25it/s]
Adding requests:   9%|         | 759/8192 [00:01<00:13, 548.29it/s]
Adding requests:  10%|         | 815/8192 [00:01<00:14, 526.78it/s]
Adding requests:  11%|         | 871/8192 [00:01<00:13, 533.92it/s]
Adding requests:  11%|        | 925/8192 [00:01<00:13, 527.31it/s]
Adding requests:  12%|        | 986/8192 [00:01<00:13, 548.98it/s]
Adding requests:  13%|        | 1051/8192 [00:01<00:12, 576.52it/s]
Adding requests:  14%|        | 1109/8192 [00:01<00:12, 565.05it/s]
Adding requests:  14%|        | 1176/8192 [00:02<00:11, 593.42it/s]
Adding requests:  15%|        | 1241/8192 [00:02<00:11, 609.55it/s]
Adding requests:  16%|        | 1303/8192 [00:02<00:11, 575.97it/s]
Adding requests:  17%|        | 1366/8192 [00:02<00:11, 590.89it/s]
Adding requests:  18%|        | 1437/8192 [00:02<00:10, 623.11it/s]
Adding requests:  18%|        | 1500/8192 [00:02<00:10, 616.92it/s]
Adding requests:  19%|        | 1562/8192 [00:02<00:10, 604.69it/s]
Adding requests:  20%|        | 1630/8192 [00:02<00:10, 624.76it/s]
Adding requests:  21%|        | 1693/8192 [00:02<00:11, 570.63it/s]
Adding requests:  21%|       | 1754/8192 [00:02<00:11, 580.53it/s]
Adding requests:  22%|       | 1818/8192 [00:03<00:10, 594.76it/s]
Adding requests:  23%|       | 1879/8192 [00:03<00:11, 557.00it/s]
Adding requests:  24%|       | 1943/8192 [00:03<00:10, 579.48it/s]
Adding requests:  24%|       | 2002/8192 [00:03<00:10, 573.49it/s]
Adding requests:  25%|       | 2060/8192 [00:03<00:10, 566.72it/s]
Adding requests:  26%|       | 2124/8192 [00:03<00:10, 586.53it/s]
Adding requests:  27%|       | 2183/8192 [00:03<00:10, 557.98it/s]
Adding requests:  27%|       | 2240/8192 [00:03<00:10, 550.66it/s]
Adding requests:  28%|       | 2297/8192 [00:03<00:10, 554.18it/s]
Adding requests:  29%|       | 2353/8192 [00:04<00:10, 539.14it/s]
Adding requests:  29%|       | 2408/8192 [00:04<00:10, 533.99it/s]
Adding requests:  30%|       | 2463/8192 [00:04<00:10, 536.74it/s]
Adding requests:  31%|       | 2517/8192 [00:04<00:10, 527.73it/s]
Adding requests:  32%|      | 2585/8192 [00:04<00:09, 570.79it/s]
Adding requests:  32%|      | 2660/8192 [00:04<00:08, 621.85it/s]
Adding requests:  33%|      | 2723/8192 [00:04<00:09, 603.81it/s]
Adding requests:  34%|      | 2788/8192 [00:04<00:08, 613.08it/s]
Adding requests:  35%|      | 2850/8192 [00:04<00:09, 579.90it/s]
Adding requests:  36%|      | 2909/8192 [00:05<00:09, 559.07it/s]
Adding requests:  36%|      | 2966/8192 [00:05<00:09, 549.17it/s]
Adding requests:  37%|      | 3025/8192 [00:05<00:09, 557.32it/s]
Adding requests:  38%|      | 3081/8192 [00:05<00:09, 543.69it/s]
Adding requests:  38%|      | 3136/8192 [00:05<00:09, 540.28it/s]
Adding requests:  39%|      | 3193/8192 [00:05<00:09, 546.53it/s]
Adding requests:  40%|      | 3248/8192 [00:05<00:09, 509.81it/s]
Adding requests:  40%|      | 3300/8192 [00:05<00:09, 506.11it/s]
Adding requests:  41%|      | 3354/8192 [00:05<00:09, 513.19it/s]
Adding requests:  42%|     | 3411/8192 [00:05<00:09, 528.49it/s]
Adding requests:  42%|     | 3465/8192 [00:06<00:09, 516.65it/s]
Adding requests:  43%|     | 3519/8192 [00:06<00:08, 521.78it/s]
Adding requests:  44%|     | 3572/8192 [00:06<00:08, 517.68it/s]
Adding requests:  44%|     | 3624/8192 [00:06<00:08, 512.50it/s]
Adding requests:  45%|     | 3682/8192 [00:06<00:08, 527.12it/s]
Adding requests:  46%|     | 3736/8192 [00:06<00:08, 528.73it/s]
Adding requests:  46%|     | 3794/8192 [00:06<00:08, 541.18it/s]
Adding requests:  47%|     | 3849/8192 [00:06<00:08, 535.84it/s]
Adding requests:  48%|     | 3904/8192 [00:06<00:07, 537.62it/s]
Adding requests:  48%|     | 3961/8192 [00:07<00:07, 546.00it/s]
Adding requests:  49%|     | 4016/8192 [00:07<00:07, 534.08it/s]
Adding requests:  50%|     | 4070/8192 [00:07<00:07, 519.41it/s]
Adding requests:  50%|     | 4129/8192 [00:07<00:07, 539.39it/s]
Adding requests:  51%|     | 4184/8192 [00:07<00:07, 532.98it/s]
Adding requests:  52%|    | 4239/8192 [00:07<00:07, 536.37it/s]
Adding requests:  52%|    | 4295/8192 [00:07<00:07, 541.33it/s]
Adding requests:  53%|    | 4350/8192 [00:07<00:07, 536.42it/s]
Adding requests:  54%|    | 4405/8192 [00:07<00:07, 540.38it/s]
Adding requests:  54%|    | 4461/8192 [00:07<00:06, 543.30it/s]
Adding requests:  55%|    | 4516/8192 [00:08<00:06, 536.21it/s]
Adding requests:  56%|    | 4570/8192 [00:08<00:06, 536.14it/s]
Adding requests:  56%|    | 4624/8192 [00:08<00:07, 503.59it/s]
Adding requests:  57%|    | 4681/8192 [00:08<00:06, 520.34it/s]
Adding requests:  58%|    | 4734/8192 [00:08<00:06, 517.44it/s]
Adding requests:  58%|    | 4790/8192 [00:08<00:06, 528.39it/s]
Adding requests:  59%|    | 4847/8192 [00:08<00:06, 539.50it/s]
Adding requests:  60%|    | 4902/8192 [00:08<00:06, 527.14it/s]
Adding requests:  60%|    | 4955/8192 [00:08<00:06, 525.58it/s]
Adding requests:  61%|    | 5011/8192 [00:09<00:05, 533.67it/s]
Adding requests:  62%|   | 5066/8192 [00:09<00:05, 538.44it/s]
Adding requests:  63%|   | 5122/8192 [00:09<00:05, 544.23it/s]
Adding requests:  63%|   | 5177/8192 [00:09<00:05, 540.17it/s]
Adding requests:  64%|   | 5234/8192 [00:09<00:05, 547.33it/s]
Adding requests:  65%|   | 5289/8192 [00:09<00:05, 537.97it/s]
Adding requests:  65%|   | 5345/8192 [00:09<00:05, 542.48it/s]
Adding requests:  66%|   | 5401/8192 [00:09<00:05, 547.15it/s]
Adding requests:  67%|   | 5456/8192 [00:09<00:05, 541.97it/s]
Adding requests:  67%|   | 5511/8192 [00:09<00:05, 532.50it/s]
Adding requests:  68%|   | 5567/8192 [00:10<00:04, 538.24it/s]
Adding requests:  69%|   | 5621/8192 [00:10<00:04, 535.52it/s]
Adding requests:  69%|   | 5675/8192 [00:10<00:04, 534.57it/s]
Adding requests:  70%|   | 5734/8192 [00:10<00:04, 549.54it/s]
Adding requests:  71%|   | 5789/8192 [00:10<00:04, 546.08it/s]
Adding requests:  71%|  | 5845/8192 [00:10<00:04, 547.13it/s]
Adding requests:  72%|  | 5906/8192 [00:10<00:04, 565.35it/s]
Adding requests:  73%|  | 5963/8192 [00:10<00:04, 534.03it/s]
Adding requests:  73%|  | 6018/8192 [00:10<00:04, 537.04it/s]
Adding requests:  74%|  | 6073/8192 [00:10<00:03, 537.50it/s]
Adding requests:  75%|  | 6130/8192 [00:11<00:03, 544.96it/s]
Adding requests:  76%|  | 6185/8192 [00:11<00:03, 542.38it/s]
Adding requests:  76%|  | 6243/8192 [00:11<00:03, 551.91it/s]
Adding requests:  77%|  | 6304/8192 [00:11<00:03, 568.62it/s]
Adding requests:  78%|  | 6361/8192 [00:11<00:03, 567.24it/s]
Adding requests:  78%|  | 6419/8192 [00:11<00:03, 569.97it/s]
Adding requests:  79%|  | 6481/8192 [00:11<00:02, 583.60it/s]
Adding requests:  80%|  | 6540/8192 [00:11<00:02, 572.95it/s]
Adding requests:  81%|  | 6598/8192 [00:11<00:02, 564.43it/s]
Adding requests:  81%|  | 6655/8192 [00:11<00:02, 559.57it/s]
Adding requests:  82%| | 6712/8192 [00:12<00:02, 550.60it/s]
Adding requests:  83%| | 6768/8192 [00:12<00:02, 549.87it/s]
Adding requests:  83%| | 6827/8192 [00:12<00:02, 559.78it/s]
Adding requests:  84%| | 6884/8192 [00:12<00:02, 558.29it/s]
Adding requests:  85%| | 6945/8192 [00:12<00:02, 571.90it/s]
Adding requests:  85%| | 7003/8192 [00:12<00:02, 563.72it/s]
Adding requests:  86%| | 7060/8192 [00:12<00:02, 560.11it/s]
Adding requests:  87%| | 7118/8192 [00:12<00:01, 564.52it/s]
Adding requests:  88%| | 7176/8192 [00:12<00:01, 567.03it/s]
Adding requests:  88%| | 7233/8192 [00:13<00:01, 566.34it/s]
Adding requests:  89%| | 7291/8192 [00:13<00:01, 566.54it/s]
Adding requests:  90%| | 7348/8192 [00:13<00:01, 544.88it/s]
Adding requests:  90%| | 7407/8192 [00:13<00:01, 557.88it/s]
Adding requests:  91%| | 7463/8192 [00:13<00:01, 556.96it/s]
Adding requests:  92%|| 7519/8192 [00:13<00:01, 556.26it/s]
Adding requests:  93%|| 7578/8192 [00:13<00:01, 565.02it/s]
Adding requests:  93%|| 7635/8192 [00:13<00:01, 556.03it/s]
Adding requests:  94%|| 7692/8192 [00:13<00:00, 559.41it/s]
Adding requests:  95%|| 7750/8192 [00:13<00:00, 562.60it/s]
Adding requests:  95%|| 7807/8192 [00:14<00:00, 546.80it/s]
Adding requests:  96%|| 7865/8192 [00:14<00:00, 555.31it/s]
Adding requests:  97%|| 7921/8192 [00:14<00:00, 550.00it/s]
Adding requests:  97%|| 7978/8192 [00:14<00:00, 553.65it/s]
Adding requests:  98%|| 8034/8192 [00:14<00:00, 541.36it/s]
Adding requests:  99%|| 8092/8192 [00:14<00:00, 551.39it/s]
Adding requests:  99%|| 8148/8192 [00:14<00:00, 544.83it/s]
Adding requests: 100%|| 8192/8192 [00:14<00:00, 554.99it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|         | 322/8192 [00:01<00:47, 165.41it/s, est. speed input: 169390.03 toks/s, output: 165.42 toks/s]
Processed prompts:   5%|         | 386/8192 [00:04<01:41, 76.87it/s, est. speed input: 90891.84 toks/s, output: 88.76 toks/s]   
Processed prompts:   5%|         | 450/8192 [00:06<02:25, 53.14it/s, est. speed input: 68472.30 toks/s, output: 66.87 toks/s]
Processed prompts:   6%|         | 514/8192 [00:09<03:00, 42.42it/s, est. speed input: 57675.79 toks/s, output: 56.32 toks/s]
Processed prompts:   7%|         | 578/8192 [00:11<03:27, 36.65it/s, est. speed input: 51359.97 toks/s, output: 50.16 toks/s]
Processed prompts:   8%|         | 642/8192 [00:13<03:47, 33.22it/s, est. speed input: 47217.67 toks/s, output: 46.11 toks/s]
Processed prompts:   9%|         | 706/8192 [00:16<04:01, 31.00it/s, est. speed input: 44250.74 toks/s, output: 43.21 toks/s]
Processed prompts:   9%|         | 770/8192 [00:18<04:10, 29.64it/s, est. speed input: 42094.21 toks/s, output: 41.11 toks/s]
Processed prompts:  10%|         | 834/8192 [00:21<04:16, 28.74it/s, est. speed input: 40432.60 toks/s, output: 39.48 toks/s]
Processed prompts:  11%|         | 898/8192 [00:24<04:37, 26.28it/s, est. speed input: 38221.97 toks/s, output: 37.33 toks/s]
Processed prompts:  12%|        | 962/8192 [00:26<04:33, 26.46it/s, est. speed input: 37261.39 toks/s, output: 36.39 toks/s]
Processed prompts:  13%|        | 1026/8192 [00:28<04:30, 26.52it/s, est. speed input: 36431.69 toks/s, output: 35.58 toks/s]
Processed prompts:  13%|        | 1090/8192 [00:31<04:27, 26.53it/s, est. speed input: 35719.72 toks/s, output: 34.88 toks/s]
Processed prompts:  14%|        | 1154/8192 [00:33<04:24, 26.66it/s, est. speed input: 35146.94 toks/s, output: 34.32 toks/s]
Processed prompts:  15%|        | 1218/8192 [00:36<04:20, 26.72it/s, est. speed input: 34643.06 toks/s, output: 33.83 toks/s]
Processed prompts:  16%|        | 1282/8192 [00:38<04:17, 26.79it/s, est. speed input: 34206.96 toks/s, output: 33.41 toks/s]
Processed prompts:  16%|        | 1346/8192 [00:40<04:15, 26.76it/s, est. speed input: 33801.74 toks/s, output: 33.01 toks/s]
Processed prompts:  17%|        | 1410/8192 [00:43<04:13, 26.71it/s, est. speed input: 33436.17 toks/s, output: 32.65 toks/s]
Processed prompts:  18%|        | 1474/8192 [00:45<04:11, 26.68it/s, est. speed input: 33108.98 toks/s, output: 32.33 toks/s]
Processed prompts:  19%|        | 1538/8192 [00:47<04:09, 26.70it/s, est. speed input: 32824.74 toks/s, output: 32.06 toks/s]
Processed prompts:  20%|        | 1602/8192 [00:50<04:06, 26.76it/s, est. speed input: 32574.03 toks/s, output: 31.81 toks/s]
Processed prompts:  20%|        | 1666/8192 [00:52<04:04, 26.70it/s, est. speed input: 32330.02 toks/s, output: 31.57 toks/s]
Processed prompts:  21%|        | 1730/8192 [00:55<04:02, 26.68it/s, est. speed input: 32110.07 toks/s, output: 31.36 toks/s]
Processed prompts:  22%|       | 1794/8192 [00:57<04:04, 26.16it/s, est. speed input: 31822.00 toks/s, output: 31.08 toks/s]
Processed prompts:  23%|       | 1858/8192 [01:00<04:00, 26.36it/s, est. speed input: 31649.16 toks/s, output: 30.91 toks/s]
Processed prompts:  23%|       | 1922/8192 [01:02<03:56, 26.55it/s, est. speed input: 31497.34 toks/s, output: 30.76 toks/s]
Processed prompts:  24%|       | 1986/8192 [01:04<03:51, 26.84it/s, est. speed input: 31379.74 toks/s, output: 30.64 toks/s]
Processed prompts:  25%|       | 2050/8192 [01:07<03:47, 27.03it/s, est. speed input: 31267.80 toks/s, output: 30.53 toks/s]
Processed prompts:  26%|       | 2114/8192 [01:09<03:45, 26.90it/s, est. speed input: 31128.02 toks/s, output: 30.40 toks/s]
Processed prompts:  27%|       | 2178/8192 [01:11<03:41, 27.20it/s, est. speed input: 31047.71 toks/s, output: 30.32 toks/s]
Processed prompts:  27%|       | 2242/8192 [01:14<03:39, 27.13it/s, est. speed input: 30937.42 toks/s, output: 30.21 toks/s]
Processed prompts:  28%|       | 2306/8192 [01:16<03:37, 27.12it/s, est. speed input: 30838.78 toks/s, output: 30.12 toks/s]
Processed prompts:  29%|       | 2370/8192 [01:18<03:32, 27.38it/s, est. speed input: 30776.75 toks/s, output: 30.06 toks/s]
Processed prompts:  30%|       | 2434/8192 [01:21<03:30, 27.29it/s, est. speed input: 30688.23 toks/s, output: 29.97 toks/s]
Processed prompts:  30%|       | 2498/8192 [01:23<03:29, 27.15it/s, est. speed input: 30596.21 toks/s, output: 29.88 toks/s]
Processed prompts:  31%|      | 2562/8192 [01:25<03:27, 27.15it/s, est. speed input: 30519.35 toks/s, output: 29.80 toks/s]
Processed prompts:  32%|      | 2626/8192 [01:28<03:25, 27.02it/s, est. speed input: 30434.29 toks/s, output: 29.72 toks/s]
Processed prompts:  33%|      | 2690/8192 [01:30<03:26, 26.69it/s, est. speed input: 30329.13 toks/s, output: 29.62 toks/s]
Processed prompts:  34%|      | 2754/8192 [01:33<03:23, 26.76it/s, est. speed input: 30258.61 toks/s, output: 29.55 toks/s]
Processed prompts:  34%|      | 2818/8192 [01:35<03:19, 26.99it/s, est. speed input: 30208.77 toks/s, output: 29.50 toks/s]
Processed prompts:  35%|      | 2882/8192 [01:37<03:17, 26.88it/s, est. speed input: 30136.28 toks/s, output: 29.43 toks/s]
Processed prompts:  36%|      | 2946/8192 [01:40<03:15, 26.87it/s, est. speed input: 30073.26 toks/s, output: 29.37 toks/s]
Processed prompts:  37%|      | 3010/8192 [01:42<03:11, 27.09it/s, est. speed input: 30032.90 toks/s, output: 29.33 toks/s]
Processed prompts:  38%|      | 3074/8192 [01:44<03:08, 27.21it/s, est. speed input: 29991.44 toks/s, output: 29.29 toks/s]
Processed prompts:  38%|      | 3138/8192 [01:47<03:05, 27.22it/s, est. speed input: 29945.33 toks/s, output: 29.24 toks/s]
Processed prompts:  39%|      | 3202/8192 [01:49<03:02, 27.32it/s, est. speed input: 29909.21 toks/s, output: 29.21 toks/s]
Processed prompts:  40%|      | 3266/8192 [01:52<03:01, 27.16it/s, est. speed input: 29856.20 toks/s, output: 29.16 toks/s]
Processed prompts:  41%|      | 3330/8192 [01:54<02:58, 27.17it/s, est. speed input: 29815.06 toks/s, output: 29.12 toks/s]
Processed prompts:  41%|     | 3394/8192 [01:56<02:57, 27.09it/s, est. speed input: 29768.92 toks/s, output: 29.07 toks/s]
Processed prompts:  42%|     | 3458/8192 [01:59<02:53, 27.21it/s, est. speed input: 29737.17 toks/s, output: 29.04 toks/s]
Processed prompts:  43%|     | 3522/8192 [02:01<02:55, 26.63it/s, est. speed input: 29659.50 toks/s, output: 28.96 toks/s]
Processed prompts:  44%|     | 3586/8192 [02:04<02:52, 26.63it/s, est. speed input: 29612.69 toks/s, output: 28.92 toks/s]
Processed prompts:  45%|     | 3650/8192 [02:06<02:49, 26.77it/s, est. speed input: 29578.01 toks/s, output: 28.88 toks/s]
Processed prompts:  45%|     | 3714/8192 [02:08<02:47, 26.79it/s, est. speed input: 29539.17 toks/s, output: 28.85 toks/s]
Processed prompts:  46%|     | 3778/8192 [02:11<02:44, 26.81it/s, est. speed input: 29502.40 toks/s, output: 28.81 toks/s]
Processed prompts:  47%|     | 3842/8192 [02:13<02:41, 26.92it/s, est. speed input: 29472.64 toks/s, output: 28.78 toks/s]
Processed prompts:  48%|     | 3906/8192 [02:15<02:39, 26.91it/s, est. speed input: 29438.75 toks/s, output: 28.75 toks/s]
Processed prompts:  48%|     | 3970/8192 [02:18<02:37, 26.84it/s, est. speed input: 29401.78 toks/s, output: 28.71 toks/s]
Processed prompts:  49%|     | 4034/8192 [02:20<02:33, 27.03it/s, est. speed input: 29380.85 toks/s, output: 28.69 toks/s]
Processed prompts:  50%|     | 4098/8192 [02:23<02:32, 26.89it/s, est. speed input: 29344.64 toks/s, output: 28.66 toks/s]
Processed prompts:  51%|     | 4162/8192 [02:25<02:28, 27.05it/s, est. speed input: 29324.38 toks/s, output: 28.64 toks/s]
Processed prompts:  52%|    | 4226/8192 [02:27<02:26, 27.09it/s, est. speed input: 29300.76 toks/s, output: 28.61 toks/s]
Processed prompts:  52%|    | 4290/8192 [02:30<02:24, 27.00it/s, est. speed input: 29270.78 toks/s, output: 28.58 toks/s]
Processed prompts:  53%|    | 4354/8192 [02:32<02:22, 26.88it/s, est. speed input: 29239.17 toks/s, output: 28.55 toks/s]
Processed prompts:  54%|    | 4418/8192 [02:34<02:22, 26.55it/s, est. speed input: 29194.32 toks/s, output: 28.51 toks/s]
Processed prompts:  55%|    | 4482/8192 [02:37<02:19, 26.58it/s, est. speed input: 29165.08 toks/s, output: 28.48 toks/s]
Processed prompts:  55%|    | 4546/8192 [02:39<02:15, 26.85it/s, est. speed input: 29150.53 toks/s, output: 28.47 toks/s]
Processed prompts:  56%|    | 4610/8192 [02:42<02:13, 26.86it/s, est. speed input: 29126.53 toks/s, output: 28.44 toks/s]
Processed prompts:  57%|    | 4674/8192 [02:44<02:11, 26.78it/s, est. speed input: 29099.05 toks/s, output: 28.42 toks/s]
Processed prompts:  58%|    | 4738/8192 [02:46<02:08, 26.88it/s, est. speed input: 29080.15 toks/s, output: 28.40 toks/s]
Processed prompts:  59%|    | 4802/8192 [02:49<02:05, 26.91it/s, est. speed input: 29059.99 toks/s, output: 28.38 toks/s]
Processed prompts:  59%|    | 4866/8192 [02:51<02:03, 26.91it/s, est. speed input: 29039.20 toks/s, output: 28.36 toks/s]
Processed prompts:  60%|    | 4930/8192 [02:53<02:01, 26.89it/s, est. speed input: 29017.93 toks/s, output: 28.34 toks/s]
Processed prompts:  61%|    | 4994/8192 [02:56<01:58, 27.01it/s, est. speed input: 29003.47 toks/s, output: 28.32 toks/s]
Processed prompts:  62%|   | 5058/8192 [02:58<01:55, 27.16it/s, est. speed input: 28992.57 toks/s, output: 28.31 toks/s]
Processed prompts:  63%|   | 5122/8192 [03:01<01:53, 26.96it/s, est. speed input: 28967.94 toks/s, output: 28.29 toks/s]
Processed prompts:  63%|   | 5186/8192 [03:03<01:50, 27.14it/s, est. speed input: 28958.48 toks/s, output: 28.28 toks/s]
Processed prompts:  64%|   | 5250/8192 [03:05<01:47, 27.26it/s, est. speed input: 28949.17 toks/s, output: 28.27 toks/s]
Processed prompts:  65%|   | 5314/8192 [03:08<01:46, 26.95it/s, est. speed input: 28922.28 toks/s, output: 28.24 toks/s]
Processed prompts:  66%|   | 5378/8192 [03:10<01:44, 26.88it/s, est. speed input: 28902.71 toks/s, output: 28.23 toks/s]
Processed prompts:  66%|   | 5442/8192 [03:12<01:41, 26.96it/s, est. speed input: 28889.36 toks/s, output: 28.21 toks/s]
Processed prompts:  67%|   | 5506/8192 [03:15<01:39, 26.96it/s, est. speed input: 28873.59 toks/s, output: 28.20 toks/s]
Processed prompts:  68%|   | 5570/8192 [03:17<01:37, 26.86it/s, est. speed input: 28854.23 toks/s, output: 28.18 toks/s]
Processed prompts:  69%|   | 5634/8192 [03:20<01:34, 26.97it/s, est. speed input: 28842.92 toks/s, output: 28.17 toks/s]
Processed prompts:  70%|   | 5698/8192 [03:22<01:32, 27.01it/s, est. speed input: 28830.06 toks/s, output: 28.15 toks/s]
Processed prompts:  70%|   | 5762/8192 [03:24<01:30, 26.99it/s, est. speed input: 28815.84 toks/s, output: 28.14 toks/s]
Processed prompts:  71%|   | 5826/8192 [03:27<01:27, 26.97it/s, est. speed input: 28801.31 toks/s, output: 28.13 toks/s]
Processed prompts:  72%|  | 5890/8192 [03:29<01:25, 27.05it/s, est. speed input: 28791.17 toks/s, output: 28.12 toks/s]
Processed prompts:  73%|  | 5954/8192 [03:31<01:23, 26.88it/s, est. speed input: 28772.38 toks/s, output: 28.10 toks/s]
Processed prompts:  73%|  | 6018/8192 [03:34<01:20, 26.92it/s, est. speed input: 28759.95 toks/s, output: 28.09 toks/s]
Processed prompts:  74%|  | 6082/8192 [03:36<01:18, 26.84it/s, est. speed input: 28743.68 toks/s, output: 28.07 toks/s]
Processed prompts:  75%|  | 6146/8192 [03:38<01:15, 27.05it/s, est. speed input: 28738.21 toks/s, output: 28.06 toks/s]
Processed prompts:  76%|  | 6210/8192 [03:41<01:14, 26.59it/s, est. speed input: 28709.18 toks/s, output: 28.04 toks/s]
Processed prompts:  77%|  | 6274/8192 [03:43<01:12, 26.60it/s, est. speed input: 28693.61 toks/s, output: 28.02 toks/s]
Processed prompts:  77%|  | 6338/8192 [03:46<01:09, 26.76it/s, est. speed input: 28684.28 toks/s, output: 28.01 toks/s]
Processed prompts:  78%|  | 6402/8192 [03:48<01:06, 26.77it/s, est. speed input: 28671.37 toks/s, output: 28.00 toks/s]
Processed prompts:  79%|  | 6466/8192 [03:51<01:04, 26.71it/s, est. speed input: 28655.98 toks/s, output: 27.98 toks/s]
Processed prompts:  80%|  | 6530/8192 [03:53<01:01, 26.83it/s, est. speed input: 28647.11 toks/s, output: 27.98 toks/s]
Processed prompts:  80%|  | 6594/8192 [03:55<00:59, 26.85it/s, est. speed input: 28635.91 toks/s, output: 27.96 toks/s]
Processed prompts:  81%| | 6658/8192 [03:58<00:56, 26.95it/s, est. speed input: 28628.03 toks/s, output: 27.96 toks/s]
Processed prompts:  82%| | 6722/8192 [04:00<00:54, 26.84it/s, est. speed input: 28613.95 toks/s, output: 27.94 toks/s]
Processed prompts:  83%| | 6786/8192 [04:02<00:52, 26.86it/s, est. speed input: 28603.58 toks/s, output: 27.93 toks/s]
Processed prompts:  84%| | 6850/8192 [04:05<00:49, 26.89it/s, est. speed input: 28593.83 toks/s, output: 27.92 toks/s]
Processed prompts:  84%| | 6914/8192 [04:07<00:47, 26.87it/s, est. speed input: 28582.98 toks/s, output: 27.91 toks/s]
Processed prompts:  85%| | 6978/8192 [04:10<00:45, 26.96it/s, est. speed input: 28575.82 toks/s, output: 27.91 toks/s]
Processed prompts:  86%| | 7042/8192 [04:12<00:43, 26.40it/s, est. speed input: 28547.69 toks/s, output: 27.88 toks/s]
Processed prompts:  87%| | 7106/8192 [04:14<00:40, 26.88it/s, est. speed input: 28549.66 toks/s, output: 27.88 toks/s]
Processed prompts:  88%| | 7170/8192 [04:17<00:38, 26.89it/s, est. speed input: 28540.28 toks/s, output: 27.87 toks/s]
Processed prompts:  88%| | 7234/8192 [04:19<00:35, 26.94it/s, est. speed input: 28532.89 toks/s, output: 27.86 toks/s]
Processed prompts:  89%| | 7298/8192 [04:22<00:33, 26.91it/s, est. speed input: 28523.29 toks/s, output: 27.85 toks/s]
Processed prompts:  90%| | 7362/8192 [04:24<00:30, 26.98it/s, est. speed input: 28516.77 toks/s, output: 27.85 toks/s]
Processed prompts:  91%| | 7426/8192 [04:26<00:28, 26.93it/s, est. speed input: 28507.36 toks/s, output: 27.84 toks/s]
Processed prompts:  91%|| 7490/8192 [04:29<00:25, 27.13it/s, est. speed input: 28505.22 toks/s, output: 27.84 toks/s]
Processed prompts:  92%|| 7554/8192 [04:31<00:23, 27.22it/s, est. speed input: 28501.58 toks/s, output: 27.83 toks/s]
Processed prompts:  93%|| 7618/8192 [04:33<00:20, 27.44it/s, est. speed input: 28502.70 toks/s, output: 27.83 toks/s]
Processed prompts:  94%|| 7682/8192 [04:36<00:18, 27.28it/s, est. speed input: 28494.72 toks/s, output: 27.83 toks/s]
Processed prompts:  95%|| 7746/8192 [04:38<00:16, 27.15it/s, est. speed input: 28486.00 toks/s, output: 27.82 toks/s]
Processed prompts:  95%|| 7810/8192 [04:40<00:14, 27.00it/s, est. speed input: 28475.77 toks/s, output: 27.81 toks/s]
Processed prompts:  96%|| 7874/8192 [04:43<00:11, 26.88it/s, est. speed input: 28465.47 toks/s, output: 27.80 toks/s]
Processed prompts:  97%|| 7938/8192 [04:45<00:09, 26.35it/s, est. speed input: 28441.57 toks/s, output: 27.77 toks/s]
Processed prompts:  98%|| 8002/8192 [04:48<00:07, 26.52it/s, est. speed input: 28434.60 toks/s, output: 27.77 toks/s]
Processed prompts:  98%|| 8066/8192 [04:50<00:04, 26.69it/s, est. speed input: 28429.01 toks/s, output: 27.76 toks/s]
Processed prompts:  99%|| 8130/8192 [04:52<00:02, 26.85it/s, est. speed input: 28424.45 toks/s, output: 27.76 toks/s]
Processed prompts: 100%|| 8192/8192 [04:52<00:00, 26.85it/s, est. speed input: 28641.17 toks/s, output: 27.97 toks/s]
Processed prompts: 100%|| 8192/8192 [04:52<00:00, 27.97it/s, est. speed input: 28641.17 toks/s, output: 27.97 toks/s]
[rank0]:[W126 07:48:41.840475233 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 11:02:38
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:02:41 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:02:41 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1211640) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1211640) WARNING 01-26 11:03:23 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 20.88 requests/s, 10711.08 total tokens/s, 20.88 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 11:02:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 11:02:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 11:02:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 11:02:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:02:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:02:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:02:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:02:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:02:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 11:02:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:02:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:02:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:02:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:02:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:02:45] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 11:02:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 11:02:45] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 11:02:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:02:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:02:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:02:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:02:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:02:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 11:02:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:02:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:02:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:02:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:02:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1211640) [2026-01-26 11:02:46] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1211640) [2026-01-26 11:02:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1211640) [2026-01-26 11:02:46] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1211640) [2026-01-26 11:02:46] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1211640) [2026-01-26 11:02:46] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1211640) [2026-01-26 11:02:46] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1211640) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1211640) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29<00:00, 29.20s/it]
(EngineCore_DP0 pid=1211640) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29<00:00, 29.20s/it]
(EngineCore_DP0 pid=1211640) 
(EngineCore_DP0 pid=1211640) [2026-01-26 11:03:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1211640) [2026-01-26 11:03:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=1211640) [2026-01-26 11:03:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1211640) [2026-01-26 11:03:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=1211640) [2026-01-26 11:03:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1211640) [2026-01-26 11:03:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=1211640) [2026-01-26 11:03:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1211640) [2026-01-26 11:03:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=1211640) 2026-01-26 11:03:22,599 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1211640) 2026-01-26 11:03:22,611 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1367.75it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:15,  8.29it/s, est. speed input: 4245.93 toks/s, output: 8.29 toks/s]
Processed prompts:   3%|         | 4/128 [00:00<00:07, 16.11it/s, est. speed input: 7703.61 toks/s, output: 15.05 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:06, 18.55it/s, est. speed input: 8817.86 toks/s, output: 17.22 toks/s]
Processed prompts:   8%|         | 10/128 [00:00<00:06, 19.62it/s, est. speed input: 9344.52 toks/s, output: 18.25 toks/s]
Processed prompts:  10%|         | 13/128 [00:00<00:05, 20.34it/s, est. speed input: 9692.75 toks/s, output: 18.93 toks/s]
Processed prompts:  12%|        | 16/128 [00:00<00:05, 20.82it/s, est. speed input: 9935.76 toks/s, output: 19.41 toks/s]
Processed prompts:  15%|        | 19/128 [00:00<00:05, 21.08it/s, est. speed input: 10099.44 toks/s, output: 19.73 toks/s]
Processed prompts:  17%|        | 22/128 [00:01<00:04, 21.29it/s, est. speed input: 10228.63 toks/s, output: 19.98 toks/s]
Processed prompts:  20%|        | 25/128 [00:01<00:04, 21.44it/s, est. speed input: 10330.22 toks/s, output: 20.18 toks/s]
Processed prompts:  22%|       | 28/128 [00:01<00:04, 21.16it/s, est. speed input: 10350.88 toks/s, output: 20.22 toks/s]
Processed prompts:  24%|       | 31/128 [00:01<00:04, 21.21it/s, est. speed input: 10403.32 toks/s, output: 20.32 toks/s]
Processed prompts:  27%|       | 34/128 [00:01<00:04, 21.37it/s, est. speed input: 10463.38 toks/s, output: 20.44 toks/s]
Processed prompts:  29%|       | 37/128 [00:01<00:04, 21.51it/s, est. speed input: 10517.99 toks/s, output: 20.54 toks/s]
Processed prompts:  31%|      | 40/128 [00:01<00:04, 21.52it/s, est. speed input: 10555.19 toks/s, output: 20.62 toks/s]
Processed prompts:  34%|      | 43/128 [00:02<00:03, 21.49it/s, est. speed input: 10582.77 toks/s, output: 20.67 toks/s]
Processed prompts:  36%|      | 46/128 [00:02<00:03, 21.49it/s, est. speed input: 10608.80 toks/s, output: 20.72 toks/s]
Processed prompts:  38%|      | 49/128 [00:02<00:03, 21.40it/s, est. speed input: 10623.71 toks/s, output: 20.75 toks/s]
Processed prompts:  41%|      | 52/128 [00:02<00:03, 21.39it/s, est. speed input: 10641.75 toks/s, output: 20.78 toks/s]
Processed prompts:  43%|     | 55/128 [00:02<00:03, 21.52it/s, est. speed input: 10669.72 toks/s, output: 20.84 toks/s]
Processed prompts:  45%|     | 58/128 [00:02<00:03, 21.63it/s, est. speed input: 10696.23 toks/s, output: 20.89 toks/s]
Processed prompts:  48%|     | 61/128 [00:02<00:03, 21.68it/s, est. speed input: 10718.37 toks/s, output: 20.93 toks/s]
Processed prompts:  50%|     | 64/128 [00:03<00:02, 21.60it/s, est. speed input: 10729.53 toks/s, output: 20.96 toks/s]
Processed prompts:  52%|    | 67/128 [00:03<00:02, 21.76it/s, est. speed input: 10755.08 toks/s, output: 21.01 toks/s]
Processed prompts:  55%|    | 70/128 [00:03<00:02, 21.62it/s, est. speed input: 10761.28 toks/s, output: 21.02 toks/s]
Processed prompts:  57%|    | 73/128 [00:03<00:02, 21.34it/s, est. speed input: 10754.88 toks/s, output: 21.01 toks/s]
Processed prompts:  59%|    | 76/128 [00:03<00:02, 21.39it/s, est. speed input: 10765.09 toks/s, output: 21.03 toks/s]
Processed prompts:  62%|   | 79/128 [00:03<00:02, 21.35it/s, est. speed input: 10769.23 toks/s, output: 21.03 toks/s]
Processed prompts:  64%|   | 82/128 [00:03<00:02, 21.42it/s, est. speed input: 10779.49 toks/s, output: 21.05 toks/s]
Processed prompts:  66%|   | 85/128 [00:04<00:02, 21.38it/s, est. speed input: 10783.73 toks/s, output: 21.06 toks/s]
Processed prompts:  69%|   | 88/128 [00:04<00:01, 21.38it/s, est. speed input: 10789.38 toks/s, output: 21.07 toks/s]
Processed prompts:  71%|   | 91/128 [00:04<00:01, 21.51it/s, est. speed input: 10801.54 toks/s, output: 21.10 toks/s]
Processed prompts:  73%|  | 94/128 [00:04<00:01, 21.29it/s, est. speed input: 10796.53 toks/s, output: 21.09 toks/s]
Processed prompts:  76%|  | 97/128 [00:04<00:01, 21.32it/s, est. speed input: 10801.27 toks/s, output: 21.10 toks/s]
Processed prompts:  78%|  | 100/128 [00:04<00:01, 21.43it/s, est. speed input: 10810.13 toks/s, output: 21.11 toks/s]
Processed prompts:  80%|  | 103/128 [00:04<00:01, 21.59it/s, est. speed input: 10822.63 toks/s, output: 21.14 toks/s]
Processed prompts:  83%| | 106/128 [00:05<00:01, 21.54it/s, est. speed input: 10826.54 toks/s, output: 21.15 toks/s]
Processed prompts:  85%| | 109/128 [00:05<00:00, 21.59it/s, est. speed input: 10834.50 toks/s, output: 21.16 toks/s]
Processed prompts:  88%| | 112/128 [00:05<00:00, 21.66it/s, est. speed input: 10843.40 toks/s, output: 21.18 toks/s]
Processed prompts:  90%| | 115/128 [00:05<00:00, 21.57it/s, est. speed input: 10845.77 toks/s, output: 21.18 toks/s]
Processed prompts:  92%|| 118/128 [00:05<00:00, 21.27it/s, est. speed input: 10837.79 toks/s, output: 21.17 toks/s]
Processed prompts:  95%|| 121/128 [00:05<00:00, 21.31it/s, est. speed input: 10840.69 toks/s, output: 21.17 toks/s]
Processed prompts:  97%|| 124/128 [00:05<00:00, 21.56it/s, est. speed input: 10852.53 toks/s, output: 21.20 toks/s]
Processed prompts:  99%|| 127/128 [00:05<00:00, 21.56it/s, est. speed input: 10856.79 toks/s, output: 21.20 toks/s]
Processed prompts: 100%|| 128/128 [00:06<00:00, 21.56it/s, est. speed input: 10857.71 toks/s, output: 21.21 toks/s]
Processed prompts: 100%|| 128/128 [00:06<00:00, 21.21it/s, est. speed input: 10857.71 toks/s, output: 21.21 toks/s]
[rank0]:[W126 11:03:29.790726098 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 11:03:31
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:03:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:03:35 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1212591) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1212591) WARNING 01-26 11:04:15 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.97 requests/s, 12264.98 total tokens/s, 11.97 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 11:03:35] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 11:03:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 11:03:35] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 11:03:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:03:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:03:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:03:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:03:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:03:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 11:03:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:03:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:03:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:03:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:03:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:03:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 11:03:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 11:03:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 11:03:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:03:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:03:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:03:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:03:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:03:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 11:03:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:03:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:03:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:03:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:03:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1212591) [2026-01-26 11:03:40] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1212591) [2026-01-26 11:03:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1212591) [2026-01-26 11:03:40] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1212591) [2026-01-26 11:03:40] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1212591) [2026-01-26 11:03:40] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1212591) [2026-01-26 11:03:40] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1212591) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1212591) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:28<00:00, 28.38s/it]
(EngineCore_DP0 pid=1212591) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:28<00:00, 28.38s/it]
(EngineCore_DP0 pid=1212591) 
(EngineCore_DP0 pid=1212591) [2026-01-26 11:04:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1212591) [2026-01-26 11:04:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=1212591) [2026-01-26 11:04:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1212591) [2026-01-26 11:04:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=1212591) [2026-01-26 11:04:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1212591) [2026-01-26 11:04:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=1212591) [2026-01-26 11:04:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1212591) [2026-01-26 11:04:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=1212591) 2026-01-26 11:04:15,417 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1212591) 2026-01-26 11:04:15,428 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  49%|     | 63/128 [00:00<00:00, 626.41it/s]
Adding requests:  98%|| 126/128 [00:00<00:00, 610.87it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 612.00it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 3/128 [00:00<00:04, 28.72it/s, est. speed input: 29415.70 toks/s, output: 28.72 toks/s]
Processed prompts:   5%|         | 6/128 [00:00<00:07, 16.03it/s, est. speed input: 17582.15 toks/s, output: 17.17 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:08, 14.37it/s, est. speed input: 15927.12 toks/s, output: 15.55 toks/s]
Processed prompts:   8%|         | 10/128 [00:00<00:08, 13.51it/s, est. speed input: 15065.84 toks/s, output: 14.71 toks/s]
Processed prompts:   9%|         | 12/128 [00:00<00:08, 12.89it/s, est. speed input: 14464.19 toks/s, output: 14.12 toks/s]
Processed prompts:  11%|         | 14/128 [00:01<00:08, 12.69it/s, est. speed input: 14159.91 toks/s, output: 13.83 toks/s]
Processed prompts:  12%|        | 16/128 [00:01<00:08, 12.50it/s, est. speed input: 13912.52 toks/s, output: 13.59 toks/s]
Processed prompts:  14%|        | 18/128 [00:01<00:08, 12.38it/s, est. speed input: 13728.94 toks/s, output: 13.41 toks/s]
Processed prompts:  16%|        | 20/128 [00:01<00:08, 12.30it/s, est. speed input: 13583.39 toks/s, output: 13.26 toks/s]
Processed prompts:  17%|        | 22/128 [00:01<00:08, 12.24it/s, est. speed input: 13467.05 toks/s, output: 13.15 toks/s]
Processed prompts:  19%|        | 24/128 [00:01<00:08, 12.02it/s, est. speed input: 13313.13 toks/s, output: 13.00 toks/s]
Processed prompts:  20%|        | 26/128 [00:02<00:08, 12.09it/s, est. speed input: 13251.47 toks/s, output: 12.94 toks/s]
Processed prompts:  22%|       | 28/128 [00:02<00:08, 12.10it/s, est. speed input: 13187.00 toks/s, output: 12.88 toks/s]
Processed prompts:  23%|       | 30/128 [00:02<00:08, 12.09it/s, est. speed input: 13127.17 toks/s, output: 12.82 toks/s]
Processed prompts:  25%|       | 32/128 [00:02<00:07, 12.06it/s, est. speed input: 13071.80 toks/s, output: 12.77 toks/s]
Processed prompts:  27%|       | 34/128 [00:02<00:07, 12.06it/s, est. speed input: 13025.83 toks/s, output: 12.72 toks/s]
Processed prompts:  28%|       | 36/128 [00:02<00:07, 11.88it/s, est. speed input: 12949.36 toks/s, output: 12.65 toks/s]
Processed prompts:  30%|       | 38/128 [00:03<00:07, 12.02it/s, est. speed input: 12932.48 toks/s, output: 12.63 toks/s]
Processed prompts:  31%|      | 40/128 [00:03<00:07, 12.06it/s, est. speed input: 12907.12 toks/s, output: 12.60 toks/s]
Processed prompts:  33%|      | 42/128 [00:03<00:07, 12.07it/s, est. speed input: 12881.83 toks/s, output: 12.58 toks/s]
Processed prompts:  34%|      | 44/128 [00:03<00:06, 12.15it/s, est. speed input: 12869.61 toks/s, output: 12.57 toks/s]
Processed prompts:  36%|      | 46/128 [00:03<00:06, 12.12it/s, est. speed input: 12846.58 toks/s, output: 12.55 toks/s]
Processed prompts:  38%|      | 48/128 [00:03<00:06, 12.09it/s, est. speed input: 12822.50 toks/s, output: 12.52 toks/s]
Processed prompts:  39%|      | 50/128 [00:04<00:06, 11.94it/s, est. speed input: 12783.01 toks/s, output: 12.48 toks/s]
Processed prompts:  41%|      | 52/128 [00:04<00:06, 12.03it/s, est. speed input: 12773.52 toks/s, output: 12.47 toks/s]
Processed prompts:  42%|     | 54/128 [00:04<00:06, 12.05it/s, est. speed input: 12758.54 toks/s, output: 12.46 toks/s]
Processed prompts:  44%|     | 56/128 [00:04<00:05, 12.05it/s, est. speed input: 12743.07 toks/s, output: 12.44 toks/s]
Processed prompts:  45%|     | 58/128 [00:04<00:05, 12.08it/s, est. speed input: 12732.00 toks/s, output: 12.43 toks/s]
Processed prompts:  47%|     | 60/128 [00:04<00:05, 12.10it/s, est. speed input: 12722.29 toks/s, output: 12.42 toks/s]
Processed prompts:  48%|     | 62/128 [00:05<00:05, 11.96it/s, est. speed input: 12694.34 toks/s, output: 12.40 toks/s]
Processed prompts:  50%|     | 64/128 [00:05<00:05, 12.01it/s, est. speed input: 12686.42 toks/s, output: 12.39 toks/s]
Processed prompts:  52%|    | 66/128 [00:05<00:05, 12.00it/s, est. speed input: 12672.75 toks/s, output: 12.38 toks/s]
Processed prompts:  53%|    | 68/128 [00:05<00:04, 12.03it/s, est. speed input: 12664.25 toks/s, output: 12.37 toks/s]
Processed prompts:  55%|    | 70/128 [00:05<00:04, 12.04it/s, est. speed input: 12655.02 toks/s, output: 12.36 toks/s]
Processed prompts:  56%|    | 72/128 [00:05<00:04, 12.06it/s, est. speed input: 12648.24 toks/s, output: 12.35 toks/s]
Processed prompts:  58%|    | 74/128 [00:06<00:04, 11.90it/s, est. speed input: 12624.21 toks/s, output: 12.33 toks/s]
Processed prompts:  59%|    | 76/128 [00:06<00:04, 11.98it/s, est. speed input: 12619.98 toks/s, output: 12.32 toks/s]
Processed prompts:  61%|    | 78/128 [00:06<00:04, 12.10it/s, est. speed input: 12621.14 toks/s, output: 12.33 toks/s]
Processed prompts:  62%|   | 80/128 [00:06<00:03, 12.08it/s, est. speed input: 12613.80 toks/s, output: 12.32 toks/s]
Processed prompts:  64%|   | 82/128 [00:06<00:03, 12.03it/s, est. speed input: 12603.72 toks/s, output: 12.31 toks/s]
Processed prompts:  66%|   | 84/128 [00:06<00:03, 12.07it/s, est. speed input: 12599.94 toks/s, output: 12.30 toks/s]
Processed prompts:  67%|   | 86/128 [00:06<00:03, 12.02it/s, est. speed input: 12589.71 toks/s, output: 12.29 toks/s]
Processed prompts:  69%|   | 88/128 [00:07<00:03, 11.94it/s, est. speed input: 12577.23 toks/s, output: 12.28 toks/s]
Processed prompts:  70%|   | 90/128 [00:07<00:03, 12.02it/s, est. speed input: 12575.20 toks/s, output: 12.28 toks/s]
Processed prompts:  72%|  | 92/128 [00:07<00:02, 12.07it/s, est. speed input: 12573.50 toks/s, output: 12.28 toks/s]
Processed prompts:  73%|  | 94/128 [00:07<00:02, 12.06it/s, est. speed input: 12568.31 toks/s, output: 12.27 toks/s]
Processed prompts:  75%|  | 96/128 [00:07<00:02, 12.06it/s, est. speed input: 12563.78 toks/s, output: 12.27 toks/s]
Processed prompts:  77%|  | 98/128 [00:07<00:02, 12.06it/s, est. speed input: 12559.29 toks/s, output: 12.26 toks/s]
Processed prompts:  78%|  | 100/128 [00:08<00:02, 11.91it/s, est. speed input: 12544.07 toks/s, output: 12.25 toks/s]
Processed prompts:  80%|  | 102/128 [00:08<00:02, 12.02it/s, est. speed input: 12544.63 toks/s, output: 12.25 toks/s]
Processed prompts:  81%| | 104/128 [00:08<00:01, 12.04it/s, est. speed input: 12541.47 toks/s, output: 12.25 toks/s]
Processed prompts:  83%| | 106/128 [00:08<00:01, 12.05it/s, est. speed input: 12538.06 toks/s, output: 12.24 toks/s]
Processed prompts:  84%| | 108/128 [00:08<00:01, 12.05it/s, est. speed input: 12534.46 toks/s, output: 12.24 toks/s]
Processed prompts:  86%| | 110/128 [00:08<00:01, 12.07it/s, est. speed input: 12532.04 toks/s, output: 12.24 toks/s]
Processed prompts:  88%| | 112/128 [00:09<00:01, 11.93it/s, est. speed input: 12519.93 toks/s, output: 12.23 toks/s]
Processed prompts:  89%| | 114/128 [00:09<00:01, 12.00it/s, est. speed input: 12518.82 toks/s, output: 12.23 toks/s]
Processed prompts:  91%| | 116/128 [00:09<00:00, 12.11it/s, est. speed input: 12521.73 toks/s, output: 12.23 toks/s]
Processed prompts:  92%|| 118/128 [00:09<00:00, 12.10it/s, est. speed input: 12519.11 toks/s, output: 12.23 toks/s]
Processed prompts:  94%|| 120/128 [00:09<00:00, 12.09it/s, est. speed input: 12516.27 toks/s, output: 12.22 toks/s]
Processed prompts:  95%|| 122/128 [00:09<00:00, 12.07it/s, est. speed input: 12512.66 toks/s, output: 12.22 toks/s]
Processed prompts:  97%|| 124/128 [00:10<00:00, 12.02it/s, est. speed input: 12507.42 toks/s, output: 12.21 toks/s]
Processed prompts:  98%|| 126/128 [00:10<00:00, 11.94it/s, est. speed input: 12499.46 toks/s, output: 12.21 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 12.00it/s, est. speed input: 12498.55 toks/s, output: 12.21 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 12.00it/s, est. speed input: 12498.55 toks/s, output: 12.21 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 12.21it/s, est. speed input: 12498.55 toks/s, output: 12.21 toks/s]
[rank0]:[W126 11:04:26.062435620 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 11:04:29
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:04:33 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:04:33 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1213564) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1213564) WARNING 01-26 11:05:13 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 12.24 requests/s, 12546.11 total tokens/s, 12.24 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 11:04:33] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 11:04:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 11:04:33] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 11:04:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:04:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:04:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:04:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:04:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:04:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 11:04:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:04:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:04:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:04:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:04:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:04:36] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 11:04:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 11:04:36] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 11:04:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:04:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:04:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:04:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:04:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:04:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 11:04:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:04:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:04:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:04:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:04:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1213564) [2026-01-26 11:04:37] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1213564) [2026-01-26 11:04:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1213564) [2026-01-26 11:04:37] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1213564) [2026-01-26 11:04:37] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1213564) [2026-01-26 11:04:37] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1213564) [2026-01-26 11:04:37] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1213564) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1213564) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:28<00:00, 28.57s/it]
(EngineCore_DP0 pid=1213564) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:28<00:00, 28.57s/it]
(EngineCore_DP0 pid=1213564) 
(EngineCore_DP0 pid=1213564) [2026-01-26 11:05:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1213564) [2026-01-26 11:05:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=1213564) [2026-01-26 11:05:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1213564) [2026-01-26 11:05:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=1213564) [2026-01-26 11:05:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1213564) [2026-01-26 11:05:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=1213564) [2026-01-26 11:05:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1213564) [2026-01-26 11:05:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=1213564) 2026-01-26 11:05:13,191 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1213564) 2026-01-26 11:05:13,202 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  16%|        | 41/256 [00:00<00:00, 403.99it/s]
Adding requests:  38%|      | 97/256 [00:00<00:00, 493.37it/s]
Adding requests:  57%|    | 147/256 [00:00<00:00, 486.27it/s]
Adding requests:  78%|  | 200/256 [00:00<00:00, 499.98it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 507.90it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 6/256 [00:00<00:07, 35.53it/s, est. speed input: 36382.10 toks/s, output: 35.53 toks/s]
Processed prompts:   4%|         | 10/256 [00:00<00:13, 18.71it/s, est. speed input: 20941.89 toks/s, output: 20.45 toks/s]
Processed prompts:   5%|         | 13/256 [00:00<00:12, 18.70it/s, est. speed input: 20498.29 toks/s, output: 20.02 toks/s]
Processed prompts:   6%|         | 16/256 [00:00<00:17, 14.06it/s, est. speed input: 16876.52 toks/s, output: 16.48 toks/s]
Processed prompts:   7%|         | 18/256 [00:01<00:17, 13.54it/s, est. speed input: 16226.85 toks/s, output: 15.85 toks/s]
Processed prompts:   8%|         | 20/256 [00:01<00:17, 13.25it/s, est. speed input: 15797.98 toks/s, output: 15.43 toks/s]
Processed prompts:   9%|         | 22/256 [00:01<00:17, 13.03it/s, est. speed input: 15463.63 toks/s, output: 15.10 toks/s]
Processed prompts:   9%|         | 24/256 [00:01<00:18, 12.88it/s, est. speed input: 15200.68 toks/s, output: 14.84 toks/s]
Processed prompts:  10%|         | 26/256 [00:01<00:18, 12.71it/s, est. speed input: 14961.38 toks/s, output: 14.61 toks/s]
Processed prompts:  11%|         | 28/256 [00:01<00:17, 12.69it/s, est. speed input: 14795.70 toks/s, output: 14.45 toks/s]
Processed prompts:  12%|        | 30/256 [00:02<00:18, 12.44it/s, est. speed input: 14584.73 toks/s, output: 14.24 toks/s]
Processed prompts:  12%|        | 32/256 [00:02<00:17, 12.48it/s, est. speed input: 14466.19 toks/s, output: 14.13 toks/s]
Processed prompts:  13%|        | 34/256 [00:02<00:17, 12.46it/s, est. speed input: 14350.05 toks/s, output: 14.01 toks/s]
Processed prompts:  14%|        | 36/256 [00:02<00:17, 12.45it/s, est. speed input: 14249.04 toks/s, output: 13.91 toks/s]
Processed prompts:  15%|        | 38/256 [00:02<00:17, 12.46it/s, est. speed input: 14163.58 toks/s, output: 13.83 toks/s]
Processed prompts:  16%|        | 40/256 [00:02<00:17, 12.44it/s, est. speed input: 14082.48 toks/s, output: 13.75 toks/s]
Processed prompts:  16%|        | 42/256 [00:03<00:17, 12.45it/s, est. speed input: 14014.22 toks/s, output: 13.69 toks/s]
Processed prompts:  17%|        | 44/256 [00:03<00:17, 12.30it/s, est. speed input: 13921.81 toks/s, output: 13.60 toks/s]
Processed prompts:  18%|        | 46/256 [00:03<00:17, 12.31it/s, est. speed input: 13860.02 toks/s, output: 13.54 toks/s]
Processed prompts:  19%|        | 48/256 [00:03<00:16, 12.30it/s, est. speed input: 13801.05 toks/s, output: 13.48 toks/s]
Processed prompts:  20%|        | 50/256 [00:03<00:16, 12.30it/s, est. speed input: 13748.69 toks/s, output: 13.43 toks/s]
Processed prompts:  20%|        | 52/256 [00:03<00:16, 12.38it/s, est. speed input: 13712.22 toks/s, output: 13.39 toks/s]
Processed prompts:  21%|        | 54/256 [00:04<00:16, 12.35it/s, est. speed input: 13667.29 toks/s, output: 13.35 toks/s]
Processed prompts:  22%|       | 56/256 [00:04<00:16, 12.21it/s, est. speed input: 13608.25 toks/s, output: 13.29 toks/s]
Processed prompts:  23%|       | 58/256 [00:04<00:16, 12.20it/s, est. speed input: 13564.73 toks/s, output: 13.25 toks/s]
Processed prompts:  23%|       | 60/256 [00:04<00:15, 12.25it/s, est. speed input: 13532.93 toks/s, output: 13.22 toks/s]
Processed prompts:  24%|       | 62/256 [00:04<00:15, 12.29it/s, est. speed input: 13503.13 toks/s, output: 13.19 toks/s]
Processed prompts:  25%|       | 64/256 [00:04<00:15, 12.35it/s, est. speed input: 13480.40 toks/s, output: 13.16 toks/s]
Processed prompts:  26%|       | 66/256 [00:05<00:15, 12.38it/s, est. speed input: 13456.35 toks/s, output: 13.14 toks/s]
Processed prompts:  27%|       | 68/256 [00:05<00:15, 12.33it/s, est. speed input: 13426.26 toks/s, output: 13.11 toks/s]
Processed prompts:  27%|       | 70/256 [00:05<00:15, 12.24it/s, est. speed input: 13392.36 toks/s, output: 13.08 toks/s]
Processed prompts:  28%|       | 72/256 [00:05<00:15, 12.25it/s, est. speed input: 13367.51 toks/s, output: 13.05 toks/s]
Processed prompts:  29%|       | 74/256 [00:05<00:14, 12.34it/s, est. speed input: 13353.11 toks/s, output: 13.04 toks/s]
Processed prompts:  30%|       | 76/256 [00:05<00:14, 12.31it/s, est. speed input: 13330.56 toks/s, output: 13.02 toks/s]
Processed prompts:  30%|       | 78/256 [00:05<00:14, 12.34it/s, est. speed input: 13313.75 toks/s, output: 13.00 toks/s]
Processed prompts:  31%|      | 80/256 [00:06<00:14, 12.33it/s, est. speed input: 13294.83 toks/s, output: 12.98 toks/s]
Processed prompts:  32%|      | 82/256 [00:06<00:14, 12.16it/s, est. speed input: 13261.70 toks/s, output: 12.95 toks/s]
Processed prompts:  33%|      | 84/256 [00:06<00:14, 12.19it/s, est. speed input: 13244.03 toks/s, output: 12.93 toks/s]
Processed prompts:  34%|      | 86/256 [00:06<00:13, 12.22it/s, est. speed input: 13228.33 toks/s, output: 12.92 toks/s]
Processed prompts:  34%|      | 88/256 [00:06<00:13, 12.25it/s, est. speed input: 13213.78 toks/s, output: 12.90 toks/s]
Processed prompts:  35%|      | 90/256 [00:06<00:13, 12.30it/s, est. speed input: 13202.01 toks/s, output: 12.89 toks/s]
Processed prompts:  36%|      | 92/256 [00:07<00:13, 12.34it/s, est. speed input: 13191.64 toks/s, output: 12.88 toks/s]
Processed prompts:  37%|      | 94/256 [00:07<00:13, 12.22it/s, est. speed input: 13170.05 toks/s, output: 12.86 toks/s]
Processed prompts:  38%|      | 96/256 [00:07<00:13, 12.16it/s, est. speed input: 13150.97 toks/s, output: 12.84 toks/s]
Processed prompts:  38%|      | 98/256 [00:07<00:12, 12.19it/s, est. speed input: 13138.15 toks/s, output: 12.83 toks/s]
Processed prompts:  39%|      | 100/256 [00:07<00:12, 12.23it/s, est. speed input: 13127.00 toks/s, output: 12.82 toks/s]
Processed prompts:  40%|      | 102/256 [00:07<00:12, 12.32it/s, est. speed input: 13121.09 toks/s, output: 12.81 toks/s]
Processed prompts:  41%|      | 104/256 [00:08<00:12, 12.30it/s, est. speed input: 13109.57 toks/s, output: 12.80 toks/s]
Processed prompts:  41%|     | 106/256 [00:08<00:12, 12.33it/s, est. speed input: 13101.64 toks/s, output: 12.79 toks/s]
Processed prompts:  42%|     | 108/256 [00:08<00:12, 12.19it/s, est. speed input: 13082.77 toks/s, output: 12.78 toks/s]
Processed prompts:  43%|     | 110/256 [00:08<00:11, 12.21it/s, est. speed input: 13072.80 toks/s, output: 12.77 toks/s]
Processed prompts:  44%|     | 112/256 [00:08<00:11, 12.29it/s, est. speed input: 13067.38 toks/s, output: 12.76 toks/s]
Processed prompts:  45%|     | 114/256 [00:08<00:11, 12.32it/s, est. speed input: 13060.58 toks/s, output: 12.75 toks/s]
Processed prompts:  45%|     | 116/256 [00:09<00:11, 12.32it/s, est. speed input: 13052.83 toks/s, output: 12.75 toks/s]
Processed prompts:  46%|     | 118/256 [00:09<00:11, 12.33it/s, est. speed input: 13045.95 toks/s, output: 12.74 toks/s]
Processed prompts:  47%|     | 120/256 [00:09<00:11, 12.19it/s, est. speed input: 13029.97 toks/s, output: 12.72 toks/s]
Processed prompts:  48%|     | 122/256 [00:09<00:10, 12.23it/s, est. speed input: 13023.11 toks/s, output: 12.72 toks/s]
Processed prompts:  48%|     | 124/256 [00:09<00:10, 12.24it/s, est. speed input: 13015.34 toks/s, output: 12.71 toks/s]
Processed prompts:  49%|     | 126/256 [00:09<00:10, 12.28it/s, est. speed input: 13009.89 toks/s, output: 12.70 toks/s]
Processed prompts:  50%|     | 128/256 [00:10<00:10, 12.31it/s, est. speed input: 13004.66 toks/s, output: 12.70 toks/s]
Processed prompts:  51%|     | 130/256 [00:10<00:10, 12.34it/s, est. speed input: 13000.06 toks/s, output: 12.70 toks/s]
Processed prompts:  52%|    | 132/256 [00:10<00:10, 12.35it/s, est. speed input: 12994.51 toks/s, output: 12.69 toks/s]
Processed prompts:  52%|    | 134/256 [00:10<00:10, 12.16it/s, est. speed input: 12979.02 toks/s, output: 12.67 toks/s]
Processed prompts:  53%|    | 136/256 [00:10<00:09, 12.24it/s, est. speed input: 12975.35 toks/s, output: 12.67 toks/s]
Processed prompts:  54%|    | 138/256 [00:10<00:09, 12.28it/s, est. speed input: 12970.65 toks/s, output: 12.67 toks/s]
Processed prompts:  55%|    | 140/256 [00:11<00:09, 12.28it/s, est. speed input: 12965.12 toks/s, output: 12.66 toks/s]
Processed prompts:  55%|    | 142/256 [00:11<00:09, 12.33it/s, est. speed input: 12961.84 toks/s, output: 12.66 toks/s]
Processed prompts:  56%|    | 144/256 [00:11<00:09, 12.33it/s, est. speed input: 12957.09 toks/s, output: 12.65 toks/s]
Processed prompts:  57%|    | 146/256 [00:11<00:09, 12.18it/s, est. speed input: 12944.88 toks/s, output: 12.64 toks/s]
Processed prompts:  58%|    | 148/256 [00:11<00:08, 12.17it/s, est. speed input: 12938.02 toks/s, output: 12.63 toks/s]
Processed prompts:  59%|    | 150/256 [00:11<00:08, 12.18it/s, est. speed input: 12931.87 toks/s, output: 12.63 toks/s]
Processed prompts:  59%|    | 152/256 [00:12<00:08, 12.22it/s, est. speed input: 12927.27 toks/s, output: 12.62 toks/s]
Processed prompts:  60%|    | 154/256 [00:12<00:08, 12.28it/s, est. speed input: 12924.76 toks/s, output: 12.62 toks/s]
Processed prompts:  61%|    | 156/256 [00:12<00:08, 12.33it/s, est. speed input: 12922.16 toks/s, output: 12.62 toks/s]
Processed prompts:  62%|   | 158/256 [00:12<00:07, 12.32it/s, est. speed input: 12917.93 toks/s, output: 12.62 toks/s]
Processed prompts:  62%|   | 160/256 [00:12<00:07, 12.21it/s, est. speed input: 12909.13 toks/s, output: 12.61 toks/s]
Processed prompts:  63%|   | 162/256 [00:12<00:07, 12.31it/s, est. speed input: 12908.63 toks/s, output: 12.61 toks/s]
Processed prompts:  64%|   | 164/256 [00:13<00:07, 12.30it/s, est. speed input: 12904.39 toks/s, output: 12.60 toks/s]
Processed prompts:  65%|   | 166/256 [00:13<00:07, 12.35it/s, est. speed input: 12902.63 toks/s, output: 12.60 toks/s]
Processed prompts:  66%|   | 168/256 [00:13<00:07, 12.40it/s, est. speed input: 12901.64 toks/s, output: 12.60 toks/s]
Processed prompts:  66%|   | 170/256 [00:13<00:06, 12.37it/s, est. speed input: 12897.77 toks/s, output: 12.60 toks/s]
Processed prompts:  67%|   | 172/256 [00:13<00:06, 12.23it/s, est. speed input: 12889.31 toks/s, output: 12.59 toks/s]
Processed prompts:  68%|   | 174/256 [00:13<00:06, 12.29it/s, est. speed input: 12887.39 toks/s, output: 12.59 toks/s]
Processed prompts:  69%|   | 176/256 [00:13<00:06, 12.27it/s, est. speed input: 12883.27 toks/s, output: 12.58 toks/s]
Processed prompts:  70%|   | 178/256 [00:14<00:06, 12.25it/s, est. speed input: 12878.63 toks/s, output: 12.58 toks/s]
Processed prompts:  70%|   | 180/256 [00:14<00:06, 12.29it/s, est. speed input: 12876.35 toks/s, output: 12.57 toks/s]
Processed prompts:  71%|   | 182/256 [00:14<00:05, 12.35it/s, est. speed input: 12875.31 toks/s, output: 12.57 toks/s]
Processed prompts:  72%|  | 184/256 [00:14<00:05, 12.37it/s, est. speed input: 12873.69 toks/s, output: 12.57 toks/s]
Processed prompts:  73%|  | 186/256 [00:14<00:05, 12.20it/s, est. speed input: 12865.05 toks/s, output: 12.56 toks/s]
Processed prompts:  73%|  | 188/256 [00:14<00:05, 12.26it/s, est. speed input: 12863.23 toks/s, output: 12.56 toks/s]
Processed prompts:  74%|  | 190/256 [00:15<00:05, 12.26it/s, est. speed input: 12859.75 toks/s, output: 12.56 toks/s]
Processed prompts:  75%|  | 192/256 [00:15<00:05, 12.27it/s, est. speed input: 12856.81 toks/s, output: 12.56 toks/s]
Processed prompts:  76%|  | 194/256 [00:15<00:05, 12.27it/s, est. speed input: 12853.97 toks/s, output: 12.55 toks/s]
Processed prompts:  77%|  | 196/256 [00:15<00:04, 12.31it/s, est. speed input: 12852.24 toks/s, output: 12.55 toks/s]
Processed prompts:  77%|  | 198/256 [00:15<00:04, 12.19it/s, est. speed input: 12845.48 toks/s, output: 12.54 toks/s]
Processed prompts:  78%|  | 200/256 [00:15<00:04, 12.28it/s, est. speed input: 12844.95 toks/s, output: 12.54 toks/s]
Processed prompts:  79%|  | 202/256 [00:16<00:04, 12.25it/s, est. speed input: 12841.24 toks/s, output: 12.54 toks/s]
Processed prompts:  80%|  | 204/256 [00:16<00:04, 12.24it/s, est. speed input: 12837.65 toks/s, output: 12.54 toks/s]
Processed prompts:  80%|  | 206/256 [00:16<00:04, 12.26it/s, est. speed input: 12835.60 toks/s, output: 12.53 toks/s]
Processed prompts:  81%| | 208/256 [00:16<00:03, 12.33it/s, est. speed input: 12835.01 toks/s, output: 12.53 toks/s]
Processed prompts:  82%| | 210/256 [00:16<00:03, 12.31it/s, est. speed input: 12832.52 toks/s, output: 12.53 toks/s]
Processed prompts:  83%| | 212/256 [00:16<00:03, 12.22it/s, est. speed input: 12827.05 toks/s, output: 12.53 toks/s]
Processed prompts:  84%| | 214/256 [00:17<00:03, 12.30it/s, est. speed input: 12826.81 toks/s, output: 12.53 toks/s]
Processed prompts:  84%| | 216/256 [00:17<00:03, 12.31it/s, est. speed input: 12825.03 toks/s, output: 12.52 toks/s]
Processed prompts:  85%| | 218/256 [00:17<00:03, 12.32it/s, est. speed input: 12823.22 toks/s, output: 12.52 toks/s]
Processed prompts:  86%| | 220/256 [00:17<00:02, 12.40it/s, est. speed input: 12823.79 toks/s, output: 12.52 toks/s]
Processed prompts:  87%| | 222/256 [00:17<00:02, 12.42it/s, est. speed input: 12823.36 toks/s, output: 12.52 toks/s]
Processed prompts:  88%| | 224/256 [00:17<00:02, 12.22it/s, est. speed input: 12816.14 toks/s, output: 12.52 toks/s]
Processed prompts:  88%| | 226/256 [00:18<00:02, 12.26it/s, est. speed input: 12814.51 toks/s, output: 12.51 toks/s]
Processed prompts:  89%| | 228/256 [00:18<00:02, 12.30it/s, est. speed input: 12813.54 toks/s, output: 12.51 toks/s]
Processed prompts:  90%| | 230/256 [00:18<00:02, 12.39it/s, est. speed input: 12814.36 toks/s, output: 12.51 toks/s]
Processed prompts:  91%| | 232/256 [00:18<00:01, 12.33it/s, est. speed input: 12811.55 toks/s, output: 12.51 toks/s]
Processed prompts:  91%|| 234/256 [00:18<00:01, 12.34it/s, est. speed input: 12810.15 toks/s, output: 12.51 toks/s]
Processed prompts:  92%|| 236/256 [00:18<00:01, 12.33it/s, est. speed input: 12808.22 toks/s, output: 12.51 toks/s]
Processed prompts:  93%|| 238/256 [00:19<00:01, 12.19it/s, est. speed input: 12802.74 toks/s, output: 12.50 toks/s]
Processed prompts:  94%|| 240/256 [00:19<00:01, 12.34it/s, est. speed input: 12804.20 toks/s, output: 12.50 toks/s]
Processed prompts:  95%|| 242/256 [00:19<00:01, 12.44it/s, est. speed input: 12805.73 toks/s, output: 12.51 toks/s]
Processed prompts:  95%|| 244/256 [00:19<00:00, 12.38it/s, est. speed input: 12803.61 toks/s, output: 12.50 toks/s]
Processed prompts:  96%|| 246/256 [00:19<00:00, 12.43it/s, est. speed input: 12803.98 toks/s, output: 12.50 toks/s]
Processed prompts:  97%|| 248/256 [00:19<00:00, 12.43it/s, est. speed input: 12803.20 toks/s, output: 12.50 toks/s]
Processed prompts:  98%|| 250/256 [00:20<00:00, 12.29it/s, est. speed input: 12798.71 toks/s, output: 12.50 toks/s]
Processed prompts:  98%|| 252/256 [00:20<00:00, 12.34it/s, est. speed input: 12798.46 toks/s, output: 12.50 toks/s]
Processed prompts:  99%|| 254/256 [00:20<00:00, 12.31it/s, est. speed input: 12796.29 toks/s, output: 12.50 toks/s]
Processed prompts: 100%|| 256/256 [00:20<00:00, 12.31it/s, est. speed input: 12844.34 toks/s, output: 12.54 toks/s]
Processed prompts: 100%|| 256/256 [00:20<00:00, 12.54it/s, est. speed input: 12844.34 toks/s, output: 12.54 toks/s]
[rank0]:[W126 11:05:35.203095629 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 11:05:37
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:05:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:05:42 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1214715) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1214715) WARNING 01-26 11:06:23 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.70 requests/s, 11987.86 total tokens/s, 11.70 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 11:05:42] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 11:05:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 11:05:42] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 11:05:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:05:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:05:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:05:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:05:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:05:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 11:05:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:05:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:05:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:05:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:05:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:05:45] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 11:05:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 11:05:45] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 11:05:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:05:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:05:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:05:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:05:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:05:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 11:05:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:05:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:05:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:05:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:05:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1214715) [2026-01-26 11:05:46] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1214715) [2026-01-26 11:05:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1214715) [2026-01-26 11:05:46] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1214715) [2026-01-26 11:05:46] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1214715) [2026-01-26 11:05:46] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1214715) [2026-01-26 11:05:46] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1214715) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1214715) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:28<00:00, 28.83s/it]
(EngineCore_DP0 pid=1214715) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:28<00:00, 28.83s/it]
(EngineCore_DP0 pid=1214715) 
(EngineCore_DP0 pid=1214715) [2026-01-26 11:06:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1214715) [2026-01-26 11:06:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=1214715) [2026-01-26 11:06:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1214715) [2026-01-26 11:06:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=1214715) [2026-01-26 11:06:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1214715) [2026-01-26 11:06:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=1214715) [2026-01-26 11:06:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1214715) [2026-01-26 11:06:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=1214715) 2026-01-26 11:06:22,182 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1214715) 2026-01-26 11:06:22,192 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  12%|        | 61/512 [00:00<00:00, 604.82it/s]
Adding requests:  24%|       | 122/512 [00:00<00:00, 563.59it/s]
Adding requests:  35%|      | 179/512 [00:00<00:00, 550.83it/s]
Adding requests:  46%|     | 237/512 [00:00<00:00, 559.64it/s]
Adding requests:  57%|    | 294/512 [00:00<00:00, 559.50it/s]
Adding requests:  69%|   | 351/512 [00:00<00:00, 556.93it/s]
Adding requests:  80%|  | 408/512 [00:00<00:00, 559.79it/s]
Adding requests:  91%| | 465/512 [00:00<00:00, 559.92it/s]
Adding requests: 100%|| 512/512 [00:00<00:00, 556.83it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 10/512 [00:00<00:14, 34.57it/s, est. speed input: 35398.50 toks/s, output: 34.57 toks/s]
Processed prompts:   3%|         | 14/512 [00:00<00:24, 20.12it/s, est. speed input: 22631.66 toks/s, output: 22.10 toks/s]
Processed prompts:   4%|         | 18/512 [00:00<00:30, 16.16it/s, est. speed input: 18906.66 toks/s, output: 18.46 toks/s]
Processed prompts:   4%|         | 22/512 [00:01<00:33, 14.43it/s, est. speed input: 17161.07 toks/s, output: 16.76 toks/s]
Processed prompts:   5%|         | 26/512 [00:01<00:36, 13.47it/s, est. speed input: 16115.28 toks/s, output: 15.74 toks/s]
Processed prompts:   6%|         | 30/512 [00:01<00:37, 12.84it/s, est. speed input: 15395.83 toks/s, output: 15.03 toks/s]
Processed prompts:   7%|         | 34/512 [00:02<00:38, 12.50it/s, est. speed input: 14915.08 toks/s, output: 14.57 toks/s]
Processed prompts:   7%|         | 38/512 [00:02<00:38, 12.26it/s, est. speed input: 14548.07 toks/s, output: 14.21 toks/s]
Processed prompts:   8%|         | 42/512 [00:03<00:39, 12.05it/s, est. speed input: 14242.60 toks/s, output: 13.91 toks/s]
Processed prompts:   9%|         | 46/512 [00:03<00:38, 12.01it/s, est. speed input: 14036.83 toks/s, output: 13.71 toks/s]
Processed prompts:  10%|         | 50/512 [00:03<00:38, 11.91it/s, est. speed input: 13847.47 toks/s, output: 13.52 toks/s]
Processed prompts:  11%|         | 54/512 [00:04<00:38, 11.81it/s, est. speed input: 13677.21 toks/s, output: 13.36 toks/s]
Processed prompts:  11%|        | 58/512 [00:04<00:38, 11.83it/s, est. speed input: 13559.51 toks/s, output: 13.24 toks/s]
Processed prompts:  12%|        | 62/512 [00:04<00:38, 11.83it/s, est. speed input: 13457.57 toks/s, output: 13.14 toks/s]
Processed prompts:  13%|        | 66/512 [00:05<00:37, 11.74it/s, est. speed input: 13344.94 toks/s, output: 13.03 toks/s]
Processed prompts:  14%|        | 70/512 [00:05<00:37, 11.77it/s, est. speed input: 13268.28 toks/s, output: 12.96 toks/s]
Processed prompts:  14%|        | 74/512 [00:05<00:37, 11.75it/s, est. speed input: 13192.26 toks/s, output: 12.88 toks/s]
Processed prompts:  15%|        | 78/512 [00:06<00:36, 11.73it/s, est. speed input: 13122.92 toks/s, output: 12.82 toks/s]
Processed prompts:  16%|        | 82/512 [00:06<00:36, 11.76it/s, est. speed input: 13069.94 toks/s, output: 12.76 toks/s]
Processed prompts:  17%|        | 86/512 [00:06<00:36, 11.79it/s, est. speed input: 13023.43 toks/s, output: 12.72 toks/s]
Processed prompts:  18%|        | 90/512 [00:07<00:35, 11.74it/s, est. speed input: 12970.14 toks/s, output: 12.67 toks/s]
Processed prompts:  18%|        | 94/512 [00:07<00:35, 11.77it/s, est. speed input: 12930.98 toks/s, output: 12.63 toks/s]
Processed prompts:  19%|        | 98/512 [00:07<00:35, 11.79it/s, est. speed input: 12896.03 toks/s, output: 12.59 toks/s]
Processed prompts:  20%|        | 102/512 [00:08<00:34, 11.73it/s, est. speed input: 12851.73 toks/s, output: 12.55 toks/s]
Processed prompts:  21%|        | 106/512 [00:08<00:34, 11.72it/s, est. speed input: 12816.80 toks/s, output: 12.52 toks/s]
Processed prompts:  21%|       | 110/512 [00:08<00:34, 11.76it/s, est. speed input: 12791.36 toks/s, output: 12.49 toks/s]
Processed prompts:  22%|       | 114/512 [00:09<00:33, 11.71it/s, est. speed input: 12755.99 toks/s, output: 12.46 toks/s]
Processed prompts:  23%|       | 118/512 [00:09<00:33, 11.72it/s, est. speed input: 12730.08 toks/s, output: 12.43 toks/s]
Processed prompts:  24%|       | 122/512 [00:09<00:33, 11.73it/s, est. speed input: 12705.89 toks/s, output: 12.41 toks/s]
Processed prompts:  25%|       | 126/512 [00:10<00:32, 11.70it/s, est. speed input: 12678.84 toks/s, output: 12.38 toks/s]
Processed prompts:  25%|       | 130/512 [00:10<00:32, 11.73it/s, est. speed input: 12660.31 toks/s, output: 12.36 toks/s]
Processed prompts:  26%|       | 134/512 [00:10<00:32, 11.80it/s, est. speed input: 12646.90 toks/s, output: 12.35 toks/s]
Processed prompts:  27%|       | 138/512 [00:11<00:31, 11.79it/s, est. speed input: 12628.85 toks/s, output: 12.33 toks/s]
Processed prompts:  28%|       | 142/512 [00:11<00:31, 11.72it/s, est. speed input: 12605.10 toks/s, output: 12.31 toks/s]
Processed prompts:  29%|       | 146/512 [00:11<00:31, 11.75it/s, est. speed input: 12590.70 toks/s, output: 12.30 toks/s]
Processed prompts:  29%|       | 150/512 [00:12<00:30, 11.73it/s, est. speed input: 12573.73 toks/s, output: 12.28 toks/s]
Processed prompts:  30%|       | 154/512 [00:12<00:30, 11.69it/s, est. speed input: 12554.18 toks/s, output: 12.26 toks/s]
Processed prompts:  31%|       | 158/512 [00:12<00:30, 11.71it/s, est. speed input: 12541.03 toks/s, output: 12.25 toks/s]
Processed prompts:  32%|      | 162/512 [00:13<00:29, 11.72it/s, est. speed input: 12527.49 toks/s, output: 12.23 toks/s]
Processed prompts:  32%|      | 166/512 [00:13<00:29, 11.70it/s, est. speed input: 12512.93 toks/s, output: 12.22 toks/s]
Processed prompts:  33%|      | 170/512 [00:13<00:29, 11.72it/s, est. speed input: 12501.35 toks/s, output: 12.21 toks/s]
Processed prompts:  34%|      | 174/512 [00:14<00:28, 11.76it/s, est. speed input: 12492.49 toks/s, output: 12.20 toks/s]
Processed prompts:  35%|      | 178/512 [00:14<00:28, 11.68it/s, est. speed input: 12475.55 toks/s, output: 12.18 toks/s]
Processed prompts:  36%|      | 182/512 [00:14<00:28, 11.69it/s, est. speed input: 12464.82 toks/s, output: 12.17 toks/s]
Processed prompts:  36%|      | 186/512 [00:15<00:27, 11.71it/s, est. speed input: 12454.95 toks/s, output: 12.16 toks/s]
Processed prompts:  37%|      | 190/512 [00:15<00:27, 11.66it/s, est. speed input: 12441.09 toks/s, output: 12.15 toks/s]
Processed prompts:  38%|      | 194/512 [00:15<00:27, 11.71it/s, est. speed input: 12433.96 toks/s, output: 12.14 toks/s]
Processed prompts:  39%|      | 198/512 [00:16<00:26, 11.75it/s, est. speed input: 12427.60 toks/s, output: 12.14 toks/s]
Processed prompts:  39%|      | 202/512 [00:16<00:26, 11.66it/s, est. speed input: 12413.31 toks/s, output: 12.12 toks/s]
Processed prompts:  40%|      | 206/512 [00:17<00:26, 11.71it/s, est. speed input: 12407.39 toks/s, output: 12.12 toks/s]
Processed prompts:  41%|      | 210/512 [00:17<00:25, 11.75it/s, est. speed input: 12401.69 toks/s, output: 12.11 toks/s]
Processed prompts:  42%|     | 214/512 [00:17<00:25, 11.69it/s, est. speed input: 12390.78 toks/s, output: 12.10 toks/s]
Processed prompts:  43%|     | 218/512 [00:18<00:25, 11.75it/s, est. speed input: 12386.97 toks/s, output: 12.10 toks/s]
Processed prompts:  43%|     | 222/512 [00:18<00:24, 11.74it/s, est. speed input: 12379.43 toks/s, output: 12.09 toks/s]
Processed prompts:  44%|     | 226/512 [00:18<00:24, 11.68it/s, est. speed input: 12368.88 toks/s, output: 12.08 toks/s]
Processed prompts:  45%|     | 230/512 [00:19<00:24, 11.71it/s, est. speed input: 12363.72 toks/s, output: 12.07 toks/s]
Processed prompts:  46%|     | 234/512 [00:19<00:23, 11.78it/s, est. speed input: 12361.31 toks/s, output: 12.07 toks/s]
Processed prompts:  46%|     | 238/512 [00:19<00:23, 11.73it/s, est. speed input: 12353.11 toks/s, output: 12.06 toks/s]
Processed prompts:  47%|     | 242/512 [00:20<00:22, 11.75it/s, est. speed input: 12348.79 toks/s, output: 12.06 toks/s]
Processed prompts:  48%|     | 246/512 [00:20<00:22, 11.75it/s, est. speed input: 12343.20 toks/s, output: 12.05 toks/s]
Processed prompts:  49%|     | 250/512 [00:20<00:22, 11.73it/s, est. speed input: 12337.22 toks/s, output: 12.05 toks/s]
Processed prompts:  50%|     | 254/512 [00:21<00:22, 11.72it/s, est. speed input: 12331.28 toks/s, output: 12.04 toks/s]
Processed prompts:  50%|     | 258/512 [00:21<00:21, 11.74it/s, est. speed input: 12327.39 toks/s, output: 12.04 toks/s]
Processed prompts:  51%|     | 262/512 [00:21<00:21, 11.78it/s, est. speed input: 12324.78 toks/s, output: 12.04 toks/s]
Processed prompts:  52%|    | 266/512 [00:22<00:21, 11.71it/s, est. speed input: 12316.78 toks/s, output: 12.03 toks/s]
Processed prompts:  53%|    | 270/512 [00:22<00:20, 11.75it/s, est. speed input: 12314.27 toks/s, output: 12.03 toks/s]
Processed prompts:  54%|    | 274/512 [00:22<00:20, 11.77it/s, est. speed input: 12310.76 toks/s, output: 12.02 toks/s]
Processed prompts:  54%|    | 278/512 [00:23<00:19, 11.74it/s, est. speed input: 12305.75 toks/s, output: 12.02 toks/s]
Processed prompts:  55%|    | 282/512 [00:23<00:19, 11.76it/s, est. speed input: 12302.65 toks/s, output: 12.01 toks/s]
Processed prompts:  56%|    | 286/512 [00:23<00:19, 11.77it/s, est. speed input: 12299.40 toks/s, output: 12.01 toks/s]
Processed prompts:  57%|    | 290/512 [00:24<00:18, 11.73it/s, est. speed input: 12293.93 toks/s, output: 12.01 toks/s]
Processed prompts:  57%|    | 294/512 [00:24<00:18, 11.79it/s, est. speed input: 12292.76 toks/s, output: 12.00 toks/s]
Processed prompts:  58%|    | 298/512 [00:24<00:18, 11.80it/s, est. speed input: 12290.18 toks/s, output: 12.00 toks/s]
Processed prompts:  59%|    | 302/512 [00:25<00:17, 11.73it/s, est. speed input: 12284.09 toks/s, output: 12.00 toks/s]
Processed prompts:  60%|    | 306/512 [00:25<00:17, 11.72it/s, est. speed input: 12280.19 toks/s, output: 11.99 toks/s]
Processed prompts:  61%|    | 310/512 [00:25<00:17, 11.74it/s, est. speed input: 12277.33 toks/s, output: 11.99 toks/s]
Processed prompts:  61%|   | 314/512 [00:26<00:16, 11.67it/s, est. speed input: 12270.91 toks/s, output: 11.98 toks/s]
Processed prompts:  62%|   | 318/512 [00:26<00:16, 11.71it/s, est. speed input: 12268.46 toks/s, output: 11.98 toks/s]
Processed prompts:  63%|   | 322/512 [00:26<00:16, 11.79it/s, est. speed input: 12268.34 toks/s, output: 11.98 toks/s]
Processed prompts:  64%|   | 326/512 [00:27<00:15, 11.71it/s, est. speed input: 12262.33 toks/s, output: 11.97 toks/s]
Processed prompts:  64%|   | 330/512 [00:27<00:15, 11.71it/s, est. speed input: 12259.13 toks/s, output: 11.97 toks/s]
Processed prompts:  65%|   | 334/512 [00:27<00:15, 11.74it/s, est. speed input: 12257.20 toks/s, output: 11.97 toks/s]
Processed prompts:  66%|   | 338/512 [00:28<00:14, 11.72it/s, est. speed input: 12253.38 toks/s, output: 11.97 toks/s]
Processed prompts:  67%|   | 342/512 [00:28<00:13, 12.26it/s, est. speed input: 12271.87 toks/s, output: 11.98 toks/s]
Processed prompts:  68%|   | 346/512 [00:28<00:13, 12.11it/s, est. speed input: 12269.40 toks/s, output: 11.98 toks/s]
Processed prompts:  68%|   | 350/512 [00:29<00:13, 12.03it/s, est. speed input: 12267.80 toks/s, output: 11.98 toks/s]
Processed prompts:  69%|   | 354/512 [00:29<00:13, 11.91it/s, est. speed input: 12263.57 toks/s, output: 11.98 toks/s]
Processed prompts:  70%|   | 358/512 [00:29<00:12, 11.87it/s, est. speed input: 12261.27 toks/s, output: 11.97 toks/s]
Processed prompts:  71%|   | 362/512 [00:30<00:12, 11.81it/s, est. speed input: 12257.81 toks/s, output: 11.97 toks/s]
Processed prompts:  71%|  | 366/512 [00:30<00:12, 11.75it/s, est. speed input: 12253.86 toks/s, output: 11.97 toks/s]
Processed prompts:  72%|  | 370/512 [00:30<00:12, 11.76it/s, est. speed input: 12251.69 toks/s, output: 11.96 toks/s]
Processed prompts:  73%|  | 374/512 [00:31<00:11, 11.76it/s, est. speed input: 12249.56 toks/s, output: 11.96 toks/s]
Processed prompts:  74%|  | 378/512 [00:31<00:12, 10.71it/s, est. speed input: 12204.24 toks/s, output: 11.92 toks/s]
Processed prompts:  75%|  | 382/512 [00:32<00:11, 10.98it/s, est. speed input: 12201.42 toks/s, output: 11.92 toks/s]
Processed prompts:  75%|  | 386/512 [00:32<00:11, 11.20it/s, est. speed input: 12199.71 toks/s, output: 11.91 toks/s]
Processed prompts:  76%|  | 390/512 [00:32<00:10, 11.33it/s, est. speed input: 12196.70 toks/s, output: 11.91 toks/s]
Processed prompts:  77%|  | 394/512 [00:33<00:10, 11.45it/s, est. speed input: 12195.08 toks/s, output: 11.91 toks/s]
Processed prompts:  78%|  | 398/512 [00:33<00:09, 11.53it/s, est. speed input: 12192.87 toks/s, output: 11.91 toks/s]
Processed prompts:  79%|  | 402/512 [00:33<00:09, 11.54it/s, est. speed input: 12189.44 toks/s, output: 11.90 toks/s]
Processed prompts:  79%|  | 406/512 [00:34<00:09, 11.58it/s, est. speed input: 12186.99 toks/s, output: 11.90 toks/s]
Processed prompts:  80%|  | 410/512 [00:34<00:08, 11.63it/s, est. speed input: 12185.55 toks/s, output: 11.90 toks/s]
Processed prompts:  81%|  | 414/512 [00:34<00:08, 11.62it/s, est. speed input: 12182.45 toks/s, output: 11.90 toks/s]
Processed prompts:  82%| | 418/512 [00:35<00:08, 11.65it/s, est. speed input: 12180.75 toks/s, output: 11.90 toks/s]
Processed prompts:  82%| | 422/512 [00:35<00:07, 11.69it/s, est. speed input: 12179.75 toks/s, output: 11.89 toks/s]
Processed prompts:  83%| | 426/512 [00:35<00:07, 11.63it/s, est. speed input: 12175.67 toks/s, output: 11.89 toks/s]
Processed prompts:  84%| | 430/512 [00:36<00:07, 11.66it/s, est. speed input: 12174.21 toks/s, output: 11.89 toks/s]
Processed prompts:  85%| | 434/512 [00:36<00:06, 11.73it/s, est. speed input: 12174.09 toks/s, output: 11.89 toks/s]
Processed prompts:  86%| | 438/512 [00:36<00:06, 11.71it/s, est. speed input: 12172.01 toks/s, output: 11.89 toks/s]
Processed prompts:  86%| | 442/512 [00:37<00:05, 11.77it/s, est. speed input: 12172.15 toks/s, output: 11.89 toks/s]
Processed prompts:  87%| | 446/512 [00:37<00:05, 11.77it/s, est. speed input: 12171.11 toks/s, output: 11.89 toks/s]
Processed prompts:  88%| | 450/512 [00:37<00:05, 12.33it/s, est. speed input: 12186.74 toks/s, output: 11.90 toks/s]
Processed prompts:  89%| | 454/512 [00:38<00:04, 12.12it/s, est. speed input: 12184.47 toks/s, output: 11.90 toks/s]
Processed prompts:  89%| | 458/512 [00:38<00:04, 12.00it/s, est. speed input: 12182.78 toks/s, output: 11.90 toks/s]
Processed prompts:  90%| | 462/512 [00:38<00:04, 11.90it/s, est. speed input: 12180.94 toks/s, output: 11.90 toks/s]
Processed prompts:  91%| | 466/512 [00:39<00:03, 11.87it/s, est. speed input: 12179.95 toks/s, output: 11.89 toks/s]
Processed prompts:  92%|| 470/512 [00:39<00:03, 11.84it/s, est. speed input: 12178.87 toks/s, output: 11.89 toks/s]
Processed prompts:  93%|| 474/512 [00:39<00:03, 11.77it/s, est. speed input: 12176.27 toks/s, output: 11.89 toks/s]
Processed prompts:  93%|| 478/512 [00:40<00:02, 11.76it/s, est. speed input: 12174.89 toks/s, output: 11.89 toks/s]
Processed prompts:  94%|| 482/512 [00:40<00:02, 11.76it/s, est. speed input: 12173.83 toks/s, output: 11.89 toks/s]
Processed prompts:  95%|| 486/512 [00:40<00:02, 11.70it/s, est. speed input: 12170.95 toks/s, output: 11.89 toks/s]
Processed prompts:  96%|| 490/512 [00:41<00:01, 11.65it/s, est. speed input: 12167.93 toks/s, output: 11.88 toks/s]
Processed prompts:  96%|| 494/512 [00:41<00:01, 11.72it/s, est. speed input: 12168.00 toks/s, output: 11.88 toks/s]
Processed prompts:  97%|| 498/512 [00:41<00:01, 11.75it/s, est. speed input: 12167.37 toks/s, output: 11.88 toks/s]
Processed prompts:  98%|| 502/512 [00:42<00:00, 11.72it/s, est. speed input: 12165.59 toks/s, output: 11.88 toks/s]
Processed prompts:  99%|| 506/512 [00:42<00:00, 11.78it/s, est. speed input: 12165.79 toks/s, output: 11.88 toks/s]
Processed prompts: 100%|| 510/512 [00:42<00:00, 12.59it/s, est. speed input: 12185.75 toks/s, output: 11.90 toks/s]
Processed prompts: 100%|| 512/512 [00:42<00:00, 12.59it/s, est. speed input: 12233.51 toks/s, output: 11.95 toks/s]
Processed prompts: 100%|| 512/512 [00:42<00:00, 11.95it/s, est. speed input: 12233.51 toks/s, output: 11.95 toks/s]
[rank0]:[W126 11:07:07.218660815 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 11:07:09
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:07:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:07:15 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1216214) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1216214) WARNING 01-26 11:07:57 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.64 requests/s, 11934.51 total tokens/s, 11.64 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 11:07:15] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 11:07:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 11:07:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 11:07:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:07:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:07:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:07:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:07:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:07:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 11:07:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:07:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:07:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:07:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:07:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:07:18] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 11:07:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 11:07:18] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 11:07:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:07:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:07:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:07:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:07:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:07:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 11:07:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:07:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:07:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:07:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:07:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1216214) [2026-01-26 11:07:19] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1216214) [2026-01-26 11:07:19] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1216214) [2026-01-26 11:07:19] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1216214) [2026-01-26 11:07:19] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1216214) [2026-01-26 11:07:19] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1216214) [2026-01-26 11:07:19] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1216214) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1216214) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29<00:00, 29.10s/it]
(EngineCore_DP0 pid=1216214) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29<00:00, 29.10s/it]
(EngineCore_DP0 pid=1216214) 
(EngineCore_DP0 pid=1216214) [2026-01-26 11:07:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1216214) [2026-01-26 11:07:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=1216214) [2026-01-26 11:07:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1216214) [2026-01-26 11:07:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=1216214) [2026-01-26 11:07:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1216214) [2026-01-26 11:07:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=1216214) [2026-01-26 11:07:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1216214) [2026-01-26 11:07:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=1216214) 2026-01-26 11:07:56,079 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1216214) 2026-01-26 11:07:56,136 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   6%|         | 61/1024 [00:00<00:01, 605.92it/s]
Adding requests:  12%|        | 122/1024 [00:00<00:01, 570.57it/s]
Adding requests:  18%|        | 180/1024 [00:00<00:01, 542.69it/s]
Adding requests:  23%|       | 236/1024 [00:00<00:01, 548.07it/s]
Adding requests:  28%|       | 291/1024 [00:00<00:01, 538.63it/s]
Adding requests:  34%|      | 345/1024 [00:00<00:01, 532.35it/s]
Adding requests:  39%|      | 400/1024 [00:00<00:01, 535.36it/s]
Adding requests:  44%|     | 454/1024 [00:00<00:01, 526.50it/s]
Adding requests:  50%|     | 507/1024 [00:00<00:00, 526.42it/s]
Adding requests:  55%|    | 560/1024 [00:01<00:00, 511.34it/s]
Adding requests:  60%|    | 613/1024 [00:01<00:00, 516.40it/s]
Adding requests:  65%|   | 667/1024 [00:01<00:00, 520.86it/s]
Adding requests:  71%|   | 725/1024 [00:01<00:00, 537.36it/s]
Adding requests:  76%|  | 779/1024 [00:01<00:00, 532.03it/s]
Adding requests:  81%| | 833/1024 [00:01<00:00, 518.43it/s]
Adding requests:  87%| | 888/1024 [00:01<00:00, 525.27it/s]
Adding requests:  92%|| 942/1024 [00:01<00:00, 527.39it/s]
Adding requests:  97%|| 997/1024 [00:01<00:00, 533.25it/s]
Adding requests: 100%|| 1024/1024 [00:01<00:00, 532.62it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 18/1024 [00:00<00:17, 56.82it/s, est. speed input: 58186.53 toks/s, output: 56.82 toks/s]
Processed prompts:   3%|         | 26/1024 [00:00<00:43, 22.80it/s, est. speed input: 26665.39 toks/s, output: 26.04 toks/s]
Processed prompts:   3%|         | 34/1024 [00:01<00:58, 17.04it/s, est. speed input: 20705.03 toks/s, output: 20.22 toks/s]
Processed prompts:   4%|         | 42/1024 [00:02<01:06, 14.71it/s, est. speed input: 18133.55 toks/s, output: 17.71 toks/s]
Processed prompts:   5%|         | 50/1024 [00:03<01:11, 13.58it/s, est. speed input: 16763.04 toks/s, output: 16.37 toks/s]
Processed prompts:   6%|         | 58/1024 [00:03<01:14, 12.89it/s, est. speed input: 15867.49 toks/s, output: 15.50 toks/s]
Processed prompts:   6%|         | 66/1024 [00:04<01:16, 12.49it/s, est. speed input: 15267.00 toks/s, output: 14.91 toks/s]
Processed prompts:   7%|         | 74/1024 [00:05<01:17, 12.23it/s, est. speed input: 14821.25 toks/s, output: 14.47 toks/s]
Processed prompts:   8%|         | 82/1024 [00:05<01:18, 12.04it/s, est. speed input: 14477.32 toks/s, output: 14.14 toks/s]
Processed prompts:   9%|         | 90/1024 [00:06<01:18, 11.94it/s, est. speed input: 14217.53 toks/s, output: 13.88 toks/s]
Processed prompts:  10%|         | 98/1024 [00:07<01:18, 11.84it/s, est. speed input: 13992.28 toks/s, output: 13.66 toks/s]
Processed prompts:  10%|         | 106/1024 [00:07<01:18, 11.75it/s, est. speed input: 13803.12 toks/s, output: 13.48 toks/s]
Processed prompts:  11%|         | 114/1024 [00:08<01:17, 11.72it/s, est. speed input: 13651.82 toks/s, output: 13.33 toks/s]
Processed prompts:  12%|        | 122/1024 [00:09<01:17, 11.67it/s, est. speed input: 13516.98 toks/s, output: 13.20 toks/s]
Processed prompts:  13%|        | 130/1024 [00:09<01:16, 11.65it/s, est. speed input: 13403.48 toks/s, output: 13.09 toks/s]
Processed prompts:  13%|        | 138/1024 [00:10<01:15, 11.67it/s, est. speed input: 13312.24 toks/s, output: 13.00 toks/s]
Processed prompts:  14%|        | 146/1024 [00:11<01:15, 11.65it/s, est. speed input: 13224.74 toks/s, output: 12.91 toks/s]
Processed prompts:  15%|        | 154/1024 [00:11<01:14, 11.64it/s, est. speed input: 13148.53 toks/s, output: 12.84 toks/s]
Processed prompts:  16%|        | 162/1024 [00:12<01:14, 11.65it/s, est. speed input: 13083.33 toks/s, output: 12.78 toks/s]
Processed prompts:  17%|        | 170/1024 [00:13<01:13, 11.62it/s, est. speed input: 13018.50 toks/s, output: 12.71 toks/s]
Processed prompts:  17%|        | 178/1024 [00:14<01:12, 11.60it/s, est. speed input: 12960.08 toks/s, output: 12.66 toks/s]
Processed prompts:  18%|        | 186/1024 [00:14<01:11, 11.66it/s, est. speed input: 12919.60 toks/s, output: 12.62 toks/s]
Processed prompts:  19%|        | 194/1024 [00:15<01:11, 11.63it/s, est. speed input: 12871.12 toks/s, output: 12.57 toks/s]
Processed prompts:  20%|        | 202/1024 [00:16<01:10, 11.62it/s, est. speed input: 12829.25 toks/s, output: 12.53 toks/s]
Processed prompts:  21%|        | 210/1024 [00:16<01:09, 11.64it/s, est. speed input: 12793.62 toks/s, output: 12.49 toks/s]
Processed prompts:  21%|       | 218/1024 [00:17<01:09, 11.62it/s, est. speed input: 12756.22 toks/s, output: 12.46 toks/s]
Processed prompts:  22%|       | 226/1024 [00:18<01:08, 11.65it/s, est. speed input: 12727.97 toks/s, output: 12.43 toks/s]
Processed prompts:  23%|       | 234/1024 [00:18<01:07, 11.63it/s, est. speed input: 12696.62 toks/s, output: 12.40 toks/s]
Processed prompts:  24%|       | 242/1024 [00:19<01:07, 11.61it/s, est. speed input: 12665.97 toks/s, output: 12.37 toks/s]
Processed prompts:  24%|       | 250/1024 [00:20<01:06, 11.62it/s, est. speed input: 12640.62 toks/s, output: 12.34 toks/s]
Processed prompts:  25%|       | 258/1024 [00:20<01:05, 11.62it/s, est. speed input: 12616.67 toks/s, output: 12.32 toks/s]
Processed prompts:  26%|       | 266/1024 [00:21<01:05, 11.63it/s, est. speed input: 12595.04 toks/s, output: 12.30 toks/s]
Processed prompts:  27%|       | 274/1024 [00:22<01:04, 11.66it/s, est. speed input: 12577.03 toks/s, output: 12.28 toks/s]
Processed prompts:  28%|       | 282/1024 [00:22<01:03, 11.65it/s, est. speed input: 12556.99 toks/s, output: 12.26 toks/s]
Processed prompts:  28%|       | 290/1024 [00:23<01:03, 11.64it/s, est. speed input: 12537.32 toks/s, output: 12.24 toks/s]
Processed prompts:  29%|       | 298/1024 [00:24<01:02, 11.65it/s, est. speed input: 12521.45 toks/s, output: 12.23 toks/s]
Processed prompts:  30%|       | 306/1024 [00:25<01:01, 11.66it/s, est. speed input: 12506.31 toks/s, output: 12.21 toks/s]
Processed prompts:  31%|       | 314/1024 [00:25<01:01, 11.63it/s, est. speed input: 12488.19 toks/s, output: 12.20 toks/s]
Processed prompts:  31%|      | 322/1024 [00:26<01:00, 11.63it/s, est. speed input: 12473.42 toks/s, output: 12.18 toks/s]
Processed prompts:  32%|      | 330/1024 [00:27<00:59, 11.61it/s, est. speed input: 12457.28 toks/s, output: 12.17 toks/s]
Processed prompts:  33%|      | 338/1024 [00:27<00:57, 11.92it/s, est. speed input: 12469.87 toks/s, output: 12.18 toks/s]
Processed prompts:  34%|      | 346/1024 [00:28<00:57, 11.85it/s, est. speed input: 12458.23 toks/s, output: 12.17 toks/s]
Processed prompts:  35%|      | 354/1024 [00:29<00:56, 11.77it/s, est. speed input: 12444.30 toks/s, output: 12.15 toks/s]
Processed prompts:  35%|      | 362/1024 [00:29<00:56, 11.75it/s, est. speed input: 12433.32 toks/s, output: 12.14 toks/s]
Processed prompts:  36%|      | 370/1024 [00:30<00:55, 11.70it/s, est. speed input: 12420.43 toks/s, output: 12.13 toks/s]
Processed prompts:  37%|      | 378/1024 [00:31<00:55, 11.66it/s, est. speed input: 12407.84 toks/s, output: 12.12 toks/s]
Processed prompts:  38%|      | 386/1024 [00:31<00:54, 11.66it/s, est. speed input: 12397.38 toks/s, output: 12.11 toks/s]
Processed prompts:  38%|      | 394/1024 [00:32<00:54, 11.65it/s, est. speed input: 12386.93 toks/s, output: 12.10 toks/s]
Processed prompts:  39%|      | 402/1024 [00:33<00:53, 11.62it/s, est. speed input: 12375.66 toks/s, output: 12.09 toks/s]
Processed prompts:  40%|      | 410/1024 [00:33<00:52, 11.63it/s, est. speed input: 12366.80 toks/s, output: 12.08 toks/s]
Processed prompts:  41%|      | 418/1024 [00:34<00:52, 11.64it/s, est. speed input: 12358.16 toks/s, output: 12.07 toks/s]
Processed prompts:  42%|     | 426/1024 [00:35<00:51, 11.62it/s, est. speed input: 12348.54 toks/s, output: 12.06 toks/s]
Processed prompts:  42%|     | 434/1024 [00:36<00:50, 11.64it/s, est. speed input: 12341.48 toks/s, output: 12.05 toks/s]
Processed prompts:  43%|     | 442/1024 [00:36<00:50, 11.63it/s, est. speed input: 12332.92 toks/s, output: 12.04 toks/s]
Processed prompts:  44%|     | 450/1024 [00:37<00:47, 11.96it/s, est. speed input: 12346.13 toks/s, output: 12.06 toks/s]
Processed prompts:  45%|     | 458/1024 [00:38<00:47, 11.86it/s, est. speed input: 12338.21 toks/s, output: 12.05 toks/s]
Processed prompts:  46%|     | 466/1024 [00:38<00:47, 11.78it/s, est. speed input: 12329.99 toks/s, output: 12.04 toks/s]
Processed prompts:  46%|     | 474/1024 [00:39<00:46, 11.74it/s, est. speed input: 12323.03 toks/s, output: 12.03 toks/s]
Processed prompts:  47%|     | 482/1024 [00:40<00:46, 11.69it/s, est. speed input: 12314.79 toks/s, output: 12.03 toks/s]
Processed prompts:  48%|     | 490/1024 [00:40<00:45, 11.64it/s, est. speed input: 12306.17 toks/s, output: 12.02 toks/s]
Processed prompts:  49%|     | 498/1024 [00:41<00:45, 11.64it/s, est. speed input: 12299.76 toks/s, output: 12.01 toks/s]
Processed prompts:  49%|     | 506/1024 [00:42<00:44, 11.63it/s, est. speed input: 12292.94 toks/s, output: 12.00 toks/s]
Processed prompts:  50%|     | 514/1024 [00:42<00:43, 11.60it/s, est. speed input: 12285.35 toks/s, output: 12.00 toks/s]
Processed prompts:  51%|     | 522/1024 [00:43<00:43, 11.63it/s, est. speed input: 12280.21 toks/s, output: 11.99 toks/s]
Processed prompts:  52%|    | 530/1024 [00:44<00:42, 11.62it/s, est. speed input: 12274.26 toks/s, output: 11.99 toks/s]
Processed prompts:  53%|    | 538/1024 [00:44<00:41, 11.61it/s, est. speed input: 12267.79 toks/s, output: 11.98 toks/s]
Processed prompts:  53%|    | 546/1024 [00:45<00:41, 11.63it/s, est. speed input: 12263.00 toks/s, output: 11.98 toks/s]
Processed prompts:  54%|    | 554/1024 [00:46<00:40, 11.61it/s, est. speed input: 12256.92 toks/s, output: 11.97 toks/s]
Processed prompts:  55%|    | 562/1024 [00:46<00:39, 11.61it/s, est. speed input: 12251.52 toks/s, output: 11.96 toks/s]
Processed prompts:  56%|    | 570/1024 [00:47<00:39, 11.61it/s, est. speed input: 12246.07 toks/s, output: 11.96 toks/s]
Processed prompts:  56%|    | 578/1024 [00:48<00:38, 11.60it/s, est. speed input: 12240.49 toks/s, output: 11.95 toks/s]
Processed prompts:  57%|    | 586/1024 [00:49<00:37, 11.58it/s, est. speed input: 12234.61 toks/s, output: 11.95 toks/s]
Processed prompts:  58%|    | 594/1024 [00:49<00:36, 11.63it/s, est. speed input: 12231.60 toks/s, output: 11.94 toks/s]
Processed prompts:  59%|    | 602/1024 [00:50<00:36, 11.61it/s, est. speed input: 12226.20 toks/s, output: 11.94 toks/s]
Processed prompts:  60%|    | 610/1024 [00:51<00:35, 11.59it/s, est. speed input: 12220.71 toks/s, output: 11.93 toks/s]
Processed prompts:  60%|    | 618/1024 [00:51<00:34, 11.61it/s, est. speed input: 12216.78 toks/s, output: 11.93 toks/s]
Processed prompts:  61%|    | 626/1024 [00:52<00:34, 11.60it/s, est. speed input: 12212.35 toks/s, output: 11.93 toks/s]
Processed prompts:  62%|   | 634/1024 [00:53<00:33, 11.64it/s, est. speed input: 12209.67 toks/s, output: 11.92 toks/s]
Processed prompts:  63%|   | 642/1024 [00:53<00:32, 11.63it/s, est. speed input: 12205.66 toks/s, output: 11.92 toks/s]
Processed prompts:  63%|   | 650/1024 [00:54<00:32, 11.61it/s, est. speed input: 12201.07 toks/s, output: 11.92 toks/s]
Processed prompts:  64%|   | 658/1024 [00:55<00:31, 11.64it/s, est. speed input: 12198.26 toks/s, output: 11.91 toks/s]
Processed prompts:  65%|   | 666/1024 [00:55<00:30, 11.62it/s, est. speed input: 12194.13 toks/s, output: 11.91 toks/s]
Processed prompts:  66%|   | 674/1024 [00:56<00:30, 11.62it/s, est. speed input: 12190.37 toks/s, output: 11.90 toks/s]
Processed prompts:  67%|   | 682/1024 [00:57<00:29, 11.63it/s, est. speed input: 12187.21 toks/s, output: 11.90 toks/s]
Processed prompts:  67%|   | 690/1024 [00:57<00:28, 11.61it/s, est. speed input: 12183.32 toks/s, output: 11.90 toks/s]
Processed prompts:  68%|   | 698/1024 [00:58<00:28, 11.62it/s, est. speed input: 12180.11 toks/s, output: 11.89 toks/s]
Processed prompts:  69%|   | 706/1024 [00:59<00:27, 11.63it/s, est. speed input: 12177.42 toks/s, output: 11.89 toks/s]
Processed prompts:  70%|   | 714/1024 [01:00<00:26, 11.62it/s, est. speed input: 12173.81 toks/s, output: 11.89 toks/s]
Processed prompts:  71%|   | 722/1024 [01:00<00:26, 11.59it/s, est. speed input: 12169.68 toks/s, output: 11.88 toks/s]
Processed prompts:  71%|  | 730/1024 [01:01<00:25, 11.63it/s, est. speed input: 12167.63 toks/s, output: 11.88 toks/s]
Processed prompts:  72%|  | 738/1024 [01:02<00:24, 11.58it/s, est. speed input: 12163.10 toks/s, output: 11.88 toks/s]
Processed prompts:  73%|  | 746/1024 [01:02<00:23, 11.60it/s, est. speed input: 12160.30 toks/s, output: 11.88 toks/s]
Processed prompts:  74%|  | 754/1024 [01:03<00:23, 11.61it/s, est. speed input: 12157.84 toks/s, output: 11.87 toks/s]
Processed prompts:  74%|  | 762/1024 [01:04<00:22, 11.60it/s, est. speed input: 12154.46 toks/s, output: 11.87 toks/s]
Processed prompts:  75%|  | 770/1024 [01:04<00:21, 11.59it/s, est. speed input: 12151.20 toks/s, output: 11.87 toks/s]
Processed prompts:  76%|  | 778/1024 [01:05<00:21, 11.60it/s, est. speed input: 12148.59 toks/s, output: 11.86 toks/s]
Processed prompts:  77%|  | 786/1024 [01:06<00:20, 11.60it/s, est. speed input: 12145.63 toks/s, output: 11.86 toks/s]
Processed prompts:  78%|  | 794/1024 [01:06<00:19, 11.62it/s, est. speed input: 12143.81 toks/s, output: 11.86 toks/s]
Processed prompts:  78%|  | 802/1024 [01:07<00:19, 11.59it/s, est. speed input: 12140.26 toks/s, output: 11.86 toks/s]
Processed prompts:  79%|  | 810/1024 [01:08<00:18, 11.58it/s, est. speed input: 12137.07 toks/s, output: 11.85 toks/s]
Processed prompts:  80%|  | 818/1024 [01:09<00:17, 11.58it/s, est. speed input: 12134.42 toks/s, output: 11.85 toks/s]
Processed prompts:  81%|  | 826/1024 [01:09<00:17, 11.59it/s, est. speed input: 12131.79 toks/s, output: 11.85 toks/s]
Processed prompts:  81%| | 834/1024 [01:10<00:16, 11.58it/s, est. speed input: 12128.82 toks/s, output: 11.84 toks/s]
Processed prompts:  82%| | 842/1024 [01:11<00:15, 11.59it/s, est. speed input: 12126.76 toks/s, output: 11.84 toks/s]
Processed prompts:  83%| | 850/1024 [01:11<00:14, 11.61it/s, est. speed input: 12124.74 toks/s, output: 11.84 toks/s]
Processed prompts:  84%| | 858/1024 [01:12<00:14, 11.60it/s, est. speed input: 12122.32 toks/s, output: 11.84 toks/s]
Processed prompts:  85%| | 866/1024 [01:13<00:13, 11.63it/s, est. speed input: 12120.79 toks/s, output: 11.84 toks/s]
Processed prompts:  85%| | 874/1024 [01:13<00:12, 11.60it/s, est. speed input: 12117.82 toks/s, output: 11.83 toks/s]
Processed prompts:  86%| | 882/1024 [01:14<00:12, 11.59it/s, est. speed input: 12115.46 toks/s, output: 11.83 toks/s]
Processed prompts:  87%| | 890/1024 [01:15<00:11, 11.62it/s, est. speed input: 12114.13 toks/s, output: 11.83 toks/s]
Processed prompts:  88%| | 898/1024 [01:15<00:10, 11.61it/s, est. speed input: 12111.81 toks/s, output: 11.83 toks/s]
Processed prompts:  88%| | 906/1024 [01:16<00:10, 11.62it/s, est. speed input: 12110.17 toks/s, output: 11.83 toks/s]
Processed prompts:  89%| | 914/1024 [01:17<00:09, 11.64it/s, est. speed input: 12108.86 toks/s, output: 11.83 toks/s]
Processed prompts:  90%| | 922/1024 [01:17<00:08, 11.63it/s, est. speed input: 12106.77 toks/s, output: 11.82 toks/s]
Processed prompts:  91%| | 930/1024 [01:18<00:08, 11.60it/s, est. speed input: 12104.22 toks/s, output: 11.82 toks/s]
Processed prompts:  92%|| 938/1024 [01:19<00:07, 11.99it/s, est. speed input: 12113.60 toks/s, output: 11.83 toks/s]
Processed prompts:  92%|| 946/1024 [01:19<00:06, 11.86it/s, est. speed input: 12111.34 toks/s, output: 11.83 toks/s]
Processed prompts:  93%|| 954/1024 [01:20<00:05, 11.78it/s, est. speed input: 12109.39 toks/s, output: 11.83 toks/s]
Processed prompts:  94%|| 962/1024 [01:21<00:05, 11.72it/s, est. speed input: 12107.16 toks/s, output: 11.82 toks/s]
Processed prompts:  95%|| 970/1024 [01:22<00:04, 11.68it/s, est. speed input: 12105.10 toks/s, output: 11.82 toks/s]
Processed prompts:  96%|| 978/1024 [01:22<00:03, 11.67it/s, est. speed input: 12103.79 toks/s, output: 11.82 toks/s]
Processed prompts:  96%|| 986/1024 [01:23<00:03, 12.05it/s, est. speed input: 12112.92 toks/s, output: 11.83 toks/s]
Processed prompts:  97%|| 994/1024 [01:24<00:02, 11.89it/s, est. speed input: 12110.43 toks/s, output: 11.83 toks/s]
Processed prompts:  98%|| 1002/1024 [01:24<00:01, 11.82it/s, est. speed input: 12108.94 toks/s, output: 11.83 toks/s]
Processed prompts:  99%|| 1010/1024 [01:25<00:01, 11.73it/s, est. speed input: 12106.39 toks/s, output: 11.82 toks/s]
Processed prompts:  99%|| 1018/1024 [01:26<00:00, 12.20it/s, est. speed input: 12118.07 toks/s, output: 11.83 toks/s]
Processed prompts: 100%|| 1024/1024 [01:26<00:00, 12.20it/s, est. speed input: 12189.48 toks/s, output: 11.90 toks/s]
Processed prompts: 100%|| 1024/1024 [01:26<00:00, 11.90it/s, est. speed input: 12189.48 toks/s, output: 11.90 toks/s]
[rank0]:[W126 11:09:25.647143283 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 11:09:27
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:09:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:09:36 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1218345) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1218345) WARNING 01-26 11:10:19 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.83 requests/s, 12121.38 total tokens/s, 11.83 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 11:09:36] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 11:09:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 11:09:36] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 11:09:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:09:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:09:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:09:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:09:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:09:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 11:09:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:09:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:09:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:09:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:09:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:09:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 11:09:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 11:09:40] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 11:09:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:09:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:09:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:09:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:09:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:09:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 11:09:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:09:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:09:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:09:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:09:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1218345) [2026-01-26 11:09:41] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1218345) [2026-01-26 11:09:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1218345) [2026-01-26 11:09:41] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1218345) [2026-01-26 11:09:41] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1218345) [2026-01-26 11:09:41] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1218345) [2026-01-26 11:09:41] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1218345) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1218345) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:28<00:00, 28.42s/it]
(EngineCore_DP0 pid=1218345) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:28<00:00, 28.42s/it]
(EngineCore_DP0 pid=1218345) 
(EngineCore_DP0 pid=1218345) [2026-01-26 11:10:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1218345) [2026-01-26 11:10:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=1218345) [2026-01-26 11:10:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1218345) [2026-01-26 11:10:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=1218345) [2026-01-26 11:10:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1218345) [2026-01-26 11:10:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=1218345) [2026-01-26 11:10:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1218345) [2026-01-26 11:10:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=1218345) 2026-01-26 11:10:17,416 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1218345) 2026-01-26 11:10:17,534 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 59/2048 [00:00<00:03, 583.17it/s]
Adding requests:   6%|         | 118/2048 [00:00<00:03, 553.20it/s]
Adding requests:   8%|         | 174/2048 [00:00<00:03, 530.04it/s]
Adding requests:  11%|         | 229/2048 [00:00<00:03, 535.31it/s]
Adding requests:  14%|        | 283/2048 [00:00<00:03, 535.72it/s]
Adding requests:  17%|        | 338/2048 [00:00<00:03, 537.91it/s]
Adding requests:  19%|        | 392/2048 [00:00<00:03, 537.02it/s]
Adding requests:  22%|       | 446/2048 [00:00<00:02, 534.39it/s]
Adding requests:  24%|       | 500/2048 [00:00<00:02, 520.55it/s]
Adding requests:  27%|       | 553/2048 [00:01<00:02, 514.09it/s]
Adding requests:  30%|       | 605/2048 [00:01<00:02, 514.95it/s]
Adding requests:  32%|      | 661/2048 [00:01<00:02, 526.72it/s]
Adding requests:  35%|      | 716/2048 [00:01<00:02, 531.80it/s]
Adding requests:  38%|      | 770/2048 [00:01<00:02, 511.39it/s]
Adding requests:  40%|      | 822/2048 [00:01<00:02, 500.89it/s]
Adding requests:  43%|     | 873/2048 [00:02<00:05, 206.60it/s]
Adding requests:  45%|     | 925/2048 [00:02<00:04, 251.05it/s]
Adding requests:  48%|     | 978/2048 [00:02<00:03, 298.51it/s]
Adding requests:  50%|     | 1032/2048 [00:02<00:02, 345.49it/s]
Adding requests:  53%|    | 1083/2048 [00:02<00:02, 380.24it/s]
Adding requests:  55%|    | 1134/2048 [00:02<00:02, 409.27it/s]
Adding requests:  58%|    | 1190/2048 [00:02<00:01, 447.01it/s]
Adding requests:  61%|    | 1242/2048 [00:02<00:01, 462.55it/s]
Adding requests:  63%|   | 1293/2048 [00:02<00:01, 470.29it/s]
Adding requests:  66%|   | 1346/2048 [00:03<00:01, 486.32it/s]
Adding requests:  68%|   | 1400/2048 [00:03<00:01, 501.30it/s]
Adding requests:  71%|   | 1452/2048 [00:03<00:01, 500.65it/s]
Adding requests:  74%|  | 1508/2048 [00:03<00:01, 516.82it/s]
Adding requests:  76%|  | 1562/2048 [00:03<00:00, 521.84it/s]
Adding requests:  79%|  | 1618/2048 [00:03<00:00, 529.05it/s]
Adding requests:  82%| | 1672/2048 [00:03<00:00, 519.47it/s]
Adding requests:  84%| | 1727/2048 [00:03<00:00, 526.98it/s]
Adding requests:  87%| | 1780/2048 [00:03<00:00, 520.98it/s]
Adding requests:  90%| | 1833/2048 [00:04<00:00, 522.72it/s]
Adding requests:  92%|| 1886/2048 [00:04<00:00, 522.64it/s]
Adding requests:  95%|| 1939/2048 [00:04<00:00, 520.89it/s]
Adding requests:  97%|| 1992/2048 [00:04<00:00, 515.09it/s]
Adding requests: 100%|| 2044/2048 [00:04<00:00, 494.99it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 461.17it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 50/2048 [00:01<00:46, 43.25it/s, est. speed input: 44295.55 toks/s, output: 43.26 toks/s]
Processed prompts:   3%|         | 66/2048 [00:02<01:23, 23.60it/s, est. speed input: 26945.93 toks/s, output: 26.31 toks/s]
Processed prompts:   4%|         | 82/2048 [00:03<01:49, 18.01it/s, est. speed input: 21721.94 toks/s, output: 21.21 toks/s]
Processed prompts:   5%|         | 98/2048 [00:05<02:05, 15.53it/s, est. speed input: 19234.94 toks/s, output: 18.78 toks/s]
Processed prompts:   6%|         | 114/2048 [00:06<02:16, 14.19it/s, est. speed input: 17777.93 toks/s, output: 17.36 toks/s]
Processed prompts:   6%|         | 130/2048 [00:07<02:23, 13.36it/s, est. speed input: 16798.58 toks/s, output: 16.40 toks/s]
Processed prompts:   7%|         | 146/2048 [00:09<02:28, 12.85it/s, est. speed input: 16111.07 toks/s, output: 15.73 toks/s]
Processed prompts:   8%|         | 162/2048 [00:10<02:30, 12.53it/s, est. speed input: 15604.36 toks/s, output: 15.24 toks/s]
Processed prompts:   9%|         | 178/2048 [00:11<02:31, 12.31it/s, est. speed input: 15209.48 toks/s, output: 14.85 toks/s]
Processed prompts:   9%|         | 194/2048 [00:13<02:32, 12.15it/s, est. speed input: 14892.80 toks/s, output: 14.54 toks/s]
Processed prompts:  10%|         | 210/2048 [00:14<02:32, 12.05it/s, est. speed input: 14636.62 toks/s, output: 14.29 toks/s]
Processed prompts:  11%|         | 226/2048 [00:16<02:32, 11.98it/s, est. speed input: 14422.20 toks/s, output: 14.08 toks/s]
Processed prompts:  12%|        | 242/2048 [00:17<02:31, 11.96it/s, est. speed input: 14249.21 toks/s, output: 13.92 toks/s]
Processed prompts:  13%|        | 258/2048 [00:18<02:30, 11.90it/s, est. speed input: 14090.36 toks/s, output: 13.76 toks/s]
Processed prompts:  13%|        | 274/2048 [00:20<02:29, 11.88it/s, est. speed input: 13958.44 toks/s, output: 13.63 toks/s]
Processed prompts:  14%|        | 290/2048 [00:21<02:28, 11.86it/s, est. speed input: 13841.49 toks/s, output: 13.52 toks/s]
Processed prompts:  15%|        | 306/2048 [00:22<02:27, 11.83it/s, est. speed input: 13733.69 toks/s, output: 13.41 toks/s]
Processed prompts:  16%|        | 322/2048 [00:24<02:25, 11.84it/s, est. speed input: 13644.07 toks/s, output: 13.32 toks/s]
Processed prompts:  17%|        | 338/2048 [00:25<02:22, 11.96it/s, est. speed input: 13589.24 toks/s, output: 13.27 toks/s]
Processed prompts:  17%|        | 354/2048 [00:26<02:22, 11.91it/s, est. speed input: 13512.12 toks/s, output: 13.20 toks/s]
Processed prompts:  18%|        | 370/2048 [00:28<02:21, 11.86it/s, est. speed input: 13440.22 toks/s, output: 13.13 toks/s]
Processed prompts:  19%|        | 386/2048 [00:29<02:20, 11.85it/s, est. speed input: 13379.55 toks/s, output: 13.07 toks/s]
Processed prompts:  20%|        | 402/2048 [00:30<02:18, 11.85it/s, est. speed input: 13324.78 toks/s, output: 13.01 toks/s]
Processed prompts:  20%|        | 418/2048 [00:32<02:17, 11.85it/s, est. speed input: 13274.91 toks/s, output: 12.96 toks/s]
Processed prompts:  21%|        | 434/2048 [00:33<02:16, 11.81it/s, est. speed input: 13223.78 toks/s, output: 12.91 toks/s]
Processed prompts:  22%|       | 450/2048 [00:34<02:13, 11.98it/s, est. speed input: 13203.83 toks/s, output: 12.89 toks/s]
Processed prompts:  23%|       | 466/2048 [00:36<02:12, 11.93it/s, est. speed input: 13162.31 toks/s, output: 12.85 toks/s]
Processed prompts:  24%|       | 482/2048 [00:37<02:11, 11.88it/s, est. speed input: 13121.69 toks/s, output: 12.81 toks/s]
Processed prompts:  24%|       | 498/2048 [00:38<02:10, 11.87it/s, est. speed input: 13087.13 toks/s, output: 12.78 toks/s]
Processed prompts:  25%|       | 514/2048 [00:40<02:09, 11.86it/s, est. speed input: 13054.63 toks/s, output: 12.75 toks/s]
Processed prompts:  26%|       | 530/2048 [00:41<02:08, 11.84it/s, est. speed input: 13022.83 toks/s, output: 12.72 toks/s]
Processed prompts:  27%|       | 546/2048 [00:43<02:07, 11.81it/s, est. speed input: 12991.13 toks/s, output: 12.69 toks/s]
Processed prompts:  27%|       | 562/2048 [00:44<02:05, 11.81it/s, est. speed input: 12963.66 toks/s, output: 12.66 toks/s]
Processed prompts:  28%|       | 578/2048 [00:45<02:04, 11.81it/s, est. speed input: 12937.78 toks/s, output: 12.63 toks/s]
Processed prompts:  29%|       | 594/2048 [00:47<02:03, 11.81it/s, est. speed input: 12913.98 toks/s, output: 12.61 toks/s]
Processed prompts:  30%|       | 610/2048 [00:48<02:01, 11.80it/s, est. speed input: 12890.01 toks/s, output: 12.59 toks/s]
Processed prompts:  31%|       | 626/2048 [00:49<02:00, 11.80it/s, est. speed input: 12868.28 toks/s, output: 12.57 toks/s]
Processed prompts:  31%|      | 642/2048 [00:51<01:59, 11.80it/s, est. speed input: 12847.06 toks/s, output: 12.55 toks/s]
Processed prompts:  32%|      | 658/2048 [00:52<01:57, 11.79it/s, est. speed input: 12826.25 toks/s, output: 12.53 toks/s]
Processed prompts:  33%|      | 674/2048 [00:53<01:56, 11.80it/s, est. speed input: 12808.56 toks/s, output: 12.51 toks/s]
Processed prompts:  34%|      | 690/2048 [00:55<01:55, 11.81it/s, est. speed input: 12791.16 toks/s, output: 12.49 toks/s]
Processed prompts:  34%|      | 706/2048 [00:56<01:53, 11.80it/s, est. speed input: 12773.67 toks/s, output: 12.47 toks/s]
Processed prompts:  35%|      | 722/2048 [00:57<01:52, 11.78it/s, est. speed input: 12755.52 toks/s, output: 12.46 toks/s]
Processed prompts:  36%|      | 738/2048 [00:59<01:51, 11.72it/s, est. speed input: 12734.87 toks/s, output: 12.44 toks/s]
Processed prompts:  37%|      | 754/2048 [01:00<01:50, 11.75it/s, est. speed input: 12721.09 toks/s, output: 12.42 toks/s]
Processed prompts:  38%|      | 770/2048 [01:02<01:48, 11.75it/s, est. speed input: 12705.71 toks/s, output: 12.41 toks/s]
Processed prompts:  38%|      | 786/2048 [01:03<01:47, 11.76it/s, est. speed input: 12691.82 toks/s, output: 12.39 toks/s]
Processed prompts:  39%|      | 802/2048 [01:04<01:45, 11.77it/s, est. speed input: 12679.26 toks/s, output: 12.38 toks/s]
Processed prompts:  40%|      | 818/2048 [01:06<01:44, 11.79it/s, est. speed input: 12667.50 toks/s, output: 12.37 toks/s]
Processed prompts:  41%|      | 834/2048 [01:07<01:43, 11.77it/s, est. speed input: 12654.50 toks/s, output: 12.36 toks/s]
Processed prompts:  42%|     | 850/2048 [01:08<01:41, 11.78it/s, est. speed input: 12642.92 toks/s, output: 12.35 toks/s]
Processed prompts:  42%|     | 866/2048 [01:10<01:40, 11.79it/s, est. speed input: 12632.79 toks/s, output: 12.34 toks/s]
Processed prompts:  43%|     | 882/2048 [01:11<01:38, 11.79it/s, est. speed input: 12622.22 toks/s, output: 12.33 toks/s]
Processed prompts:  44%|     | 898/2048 [01:12<01:37, 11.77it/s, est. speed input: 12610.58 toks/s, output: 12.32 toks/s]
Processed prompts:  45%|     | 914/2048 [01:14<01:36, 11.77it/s, est. speed input: 12600.16 toks/s, output: 12.30 toks/s]
Processed prompts:  45%|     | 930/2048 [01:15<01:33, 11.96it/s, est. speed input: 12602.71 toks/s, output: 12.31 toks/s]
Processed prompts:  46%|     | 946/2048 [01:16<01:32, 11.91it/s, est. speed input: 12593.34 toks/s, output: 12.30 toks/s]
Processed prompts:  47%|     | 962/2048 [01:18<01:31, 11.87it/s, est. speed input: 12583.76 toks/s, output: 12.29 toks/s]
Processed prompts:  48%|     | 978/2048 [01:19<01:28, 12.04it/s, est. speed input: 12586.49 toks/s, output: 12.29 toks/s]
Processed prompts:  49%|     | 994/2048 [01:20<01:28, 11.97it/s, est. speed input: 12578.34 toks/s, output: 12.28 toks/s]
Processed prompts:  49%|     | 1010/2048 [01:22<01:27, 11.90it/s, est. speed input: 12569.44 toks/s, output: 12.27 toks/s]
Processed prompts:  50%|     | 1026/2048 [01:23<01:26, 11.88it/s, est. speed input: 12561.93 toks/s, output: 12.27 toks/s]
Processed prompts:  51%|     | 1042/2048 [01:24<01:24, 11.86it/s, est. speed input: 12554.31 toks/s, output: 12.26 toks/s]
Processed prompts:  52%|    | 1058/2048 [01:26<01:23, 11.84it/s, est. speed input: 12547.21 toks/s, output: 12.25 toks/s]
Processed prompts:  52%|    | 1074/2048 [01:27<01:22, 11.81it/s, est. speed input: 12539.05 toks/s, output: 12.25 toks/s]
Processed prompts:  53%|    | 1090/2048 [01:29<01:21, 11.81it/s, est. speed input: 12532.34 toks/s, output: 12.24 toks/s]
Processed prompts:  54%|    | 1106/2048 [01:30<01:19, 11.81it/s, est. speed input: 12525.59 toks/s, output: 12.23 toks/s]
Processed prompts:  55%|    | 1122/2048 [01:31<01:18, 11.77it/s, est. speed input: 12517.00 toks/s, output: 12.22 toks/s]
Processed prompts:  56%|    | 1138/2048 [01:33<01:17, 11.77it/s, est. speed input: 12510.30 toks/s, output: 12.22 toks/s]
Processed prompts:  56%|    | 1154/2048 [01:34<01:14, 11.94it/s, est. speed input: 12512.21 toks/s, output: 12.22 toks/s]
Processed prompts:  57%|    | 1170/2048 [01:35<01:13, 11.92it/s, est. speed input: 12507.07 toks/s, output: 12.21 toks/s]
Processed prompts:  58%|    | 1186/2048 [01:37<01:12, 11.87it/s, est. speed input: 12500.73 toks/s, output: 12.21 toks/s]
Processed prompts:  59%|    | 1202/2048 [01:38<01:11, 11.84it/s, est. speed input: 12494.69 toks/s, output: 12.20 toks/s]
Processed prompts:  59%|    | 1218/2048 [01:39<01:10, 11.84it/s, est. speed input: 12489.40 toks/s, output: 12.20 toks/s]
Processed prompts:  60%|    | 1234/2048 [01:41<01:08, 11.83it/s, est. speed input: 12484.09 toks/s, output: 12.19 toks/s]
Processed prompts:  61%|    | 1250/2048 [01:42<01:07, 11.81it/s, est. speed input: 12478.44 toks/s, output: 12.19 toks/s]
Processed prompts:  62%|   | 1266/2048 [01:43<01:05, 11.99it/s, est. speed input: 12481.25 toks/s, output: 12.19 toks/s]
Processed prompts:  63%|   | 1282/2048 [01:45<01:04, 11.93it/s, est. speed input: 12476.13 toks/s, output: 12.18 toks/s]
Processed prompts:  63%|   | 1298/2048 [01:46<01:03, 11.90it/s, est. speed input: 12471.40 toks/s, output: 12.18 toks/s]
Processed prompts:  64%|   | 1314/2048 [01:47<01:01, 11.85it/s, est. speed input: 12465.74 toks/s, output: 12.17 toks/s]
Processed prompts:  65%|   | 1330/2048 [01:49<01:00, 11.84it/s, est. speed input: 12461.08 toks/s, output: 12.17 toks/s]
Processed prompts:  66%|   | 1346/2048 [01:50<00:59, 11.84it/s, est. speed input: 12456.92 toks/s, output: 12.16 toks/s]
Processed prompts:  67%|   | 1362/2048 [01:52<00:58, 11.82it/s, est. speed input: 12452.06 toks/s, output: 12.16 toks/s]
Processed prompts:  67%|   | 1378/2048 [01:53<00:56, 11.80it/s, est. speed input: 12447.14 toks/s, output: 12.16 toks/s]
Processed prompts:  68%|   | 1394/2048 [01:54<00:55, 11.79it/s, est. speed input: 12442.51 toks/s, output: 12.15 toks/s]
Processed prompts:  69%|   | 1410/2048 [01:56<00:54, 11.80it/s, est. speed input: 12438.44 toks/s, output: 12.15 toks/s]
Processed prompts:  70%|   | 1426/2048 [01:57<00:52, 11.78it/s, est. speed input: 12433.64 toks/s, output: 12.14 toks/s]
Processed prompts:  70%|   | 1442/2048 [01:58<00:51, 11.77it/s, est. speed input: 12429.15 toks/s, output: 12.14 toks/s]
Processed prompts:  71%|   | 1458/2048 [02:00<00:50, 11.79it/s, est. speed input: 12425.42 toks/s, output: 12.13 toks/s]
Processed prompts:  72%|  | 1474/2048 [02:01<00:48, 11.80it/s, est. speed input: 12421.96 toks/s, output: 12.13 toks/s]
Processed prompts:  73%|  | 1490/2048 [02:02<00:47, 11.78it/s, est. speed input: 12417.52 toks/s, output: 12.13 toks/s]
Processed prompts:  74%|  | 1506/2048 [02:04<00:45, 11.78it/s, est. speed input: 12413.74 toks/s, output: 12.12 toks/s]
Processed prompts:  74%|  | 1522/2048 [02:05<00:44, 11.80it/s, est. speed input: 12410.50 toks/s, output: 12.12 toks/s]
Processed prompts:  75%|  | 1538/2048 [02:06<00:43, 11.79it/s, est. speed input: 12406.69 toks/s, output: 12.12 toks/s]
Processed prompts:  76%|  | 1554/2048 [02:08<00:41, 11.79it/s, est. speed input: 12403.30 toks/s, output: 12.11 toks/s]
Processed prompts:  77%|  | 1570/2048 [02:09<00:40, 11.79it/s, est. speed input: 12399.82 toks/s, output: 12.11 toks/s]
Processed prompts:  77%|  | 1586/2048 [02:10<00:38, 11.98it/s, est. speed input: 12403.28 toks/s, output: 12.11 toks/s]
Processed prompts:  78%|  | 1602/2048 [02:12<00:37, 11.91it/s, est. speed input: 12399.33 toks/s, output: 12.11 toks/s]
Processed prompts:  79%|  | 1618/2048 [02:13<00:36, 11.87it/s, est. speed input: 12395.95 toks/s, output: 12.11 toks/s]
Processed prompts:  80%|  | 1634/2048 [02:15<00:34, 11.86it/s, est. speed input: 12393.19 toks/s, output: 12.10 toks/s]
Processed prompts:  81%|  | 1650/2048 [02:16<00:33, 11.84it/s, est. speed input: 12390.00 toks/s, output: 12.10 toks/s]
Processed prompts:  81%| | 1666/2048 [02:17<00:32, 11.81it/s, est. speed input: 12386.29 toks/s, output: 12.10 toks/s]
Processed prompts:  82%| | 1682/2048 [02:19<00:30, 11.81it/s, est. speed input: 12383.49 toks/s, output: 12.09 toks/s]
Processed prompts:  83%| | 1698/2048 [02:20<00:29, 11.80it/s, est. speed input: 12380.37 toks/s, output: 12.09 toks/s]
Processed prompts:  84%| | 1714/2048 [02:21<00:28, 11.78it/s, est. speed input: 12376.88 toks/s, output: 12.09 toks/s]
Processed prompts:  84%| | 1730/2048 [02:23<00:26, 11.79it/s, est. speed input: 12374.25 toks/s, output: 12.08 toks/s]
Processed prompts:  85%| | 1746/2048 [02:24<00:25, 11.81it/s, est. speed input: 12371.93 toks/s, output: 12.08 toks/s]
Processed prompts:  86%| | 1762/2048 [02:25<00:24, 11.80it/s, est. speed input: 12369.13 toks/s, output: 12.08 toks/s]
Processed prompts:  87%| | 1778/2048 [02:27<00:22, 11.79it/s, est. speed input: 12366.18 toks/s, output: 12.08 toks/s]
Processed prompts:  88%| | 1794/2048 [02:28<00:21, 11.80it/s, est. speed input: 12363.67 toks/s, output: 12.07 toks/s]
Processed prompts:  88%| | 1810/2048 [02:29<00:20, 11.80it/s, est. speed input: 12361.30 toks/s, output: 12.07 toks/s]
Processed prompts:  89%| | 1826/2048 [02:31<00:18, 11.81it/s, est. speed input: 12359.05 toks/s, output: 12.07 toks/s]
Processed prompts:  90%| | 1842/2048 [02:32<00:17, 11.79it/s, est. speed input: 12356.19 toks/s, output: 12.07 toks/s]
Processed prompts:  91%| | 1858/2048 [02:34<00:16, 11.79it/s, est. speed input: 12353.63 toks/s, output: 12.06 toks/s]
Processed prompts:  92%|| 1874/2048 [02:35<00:14, 11.97it/s, est. speed input: 12356.51 toks/s, output: 12.07 toks/s]
Processed prompts:  92%|| 1890/2048 [02:36<00:13, 11.89it/s, est. speed input: 12353.46 toks/s, output: 12.06 toks/s]
Processed prompts:  93%|| 1906/2048 [02:38<00:11, 11.86it/s, est. speed input: 12350.87 toks/s, output: 12.06 toks/s]
Processed prompts:  94%|| 1922/2048 [02:39<00:10, 11.84it/s, est. speed input: 12348.53 toks/s, output: 12.06 toks/s]
Processed prompts:  95%|| 1938/2048 [02:40<00:09, 11.82it/s, est. speed input: 12346.00 toks/s, output: 12.06 toks/s]
Processed prompts:  95%|| 1954/2048 [02:42<00:07, 11.98it/s, est. speed input: 12348.56 toks/s, output: 12.06 toks/s]
Processed prompts:  96%|| 1970/2048 [02:43<00:06, 11.92it/s, est. speed input: 12346.30 toks/s, output: 12.06 toks/s]
Processed prompts:  97%|| 1986/2048 [02:44<00:05, 11.89it/s, est. speed input: 12344.19 toks/s, output: 12.05 toks/s]
Processed prompts:  98%|| 2002/2048 [02:46<00:03, 11.86it/s, est. speed input: 12342.15 toks/s, output: 12.05 toks/s]
Processed prompts:  99%|| 2018/2048 [02:47<00:02, 11.83it/s, est. speed input: 12339.51 toks/s, output: 12.05 toks/s]
Processed prompts:  99%|| 2034/2048 [02:48<00:01, 12.03it/s, est. speed input: 12343.39 toks/s, output: 12.05 toks/s]
Processed prompts: 100%|| 2048/2048 [02:48<00:00, 12.03it/s, est. speed input: 12428.34 toks/s, output: 12.14 toks/s]
Processed prompts: 100%|| 2048/2048 [02:48<00:00, 12.14it/s, est. speed input: 12428.34 toks/s, output: 12.14 toks/s]
[rank0]:[W126 11:13:12.918103411 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 11:13:14
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:13:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:13:29 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1221748) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1221748) WARNING 01-26 11:14:17 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.78 requests/s, 12072.89 total tokens/s, 11.78 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 11:13:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 11:13:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 11:13:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 11:13:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:13:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:13:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:13:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:13:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:13:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 11:13:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:13:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:13:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:13:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:13:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:13:33] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 11:13:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 11:13:33] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 11:13:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:13:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:13:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:13:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:13:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:13:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 11:13:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:13:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:13:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:13:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:13:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1221748) [2026-01-26 11:13:34] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1221748) [2026-01-26 11:13:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1221748) [2026-01-26 11:13:34] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1221748) [2026-01-26 11:13:34] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1221748) [2026-01-26 11:13:34] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1221748) [2026-01-26 11:13:34] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1221748) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1221748) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:28<00:00, 28.75s/it]
(EngineCore_DP0 pid=1221748) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:28<00:00, 28.75s/it]
(EngineCore_DP0 pid=1221748) 
(EngineCore_DP0 pid=1221748) [2026-01-26 11:14:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1221748) [2026-01-26 11:14:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=1221748) [2026-01-26 11:14:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1221748) [2026-01-26 11:14:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=1221748) [2026-01-26 11:14:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1221748) [2026-01-26 11:14:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=1221748) [2026-01-26 11:14:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1221748) [2026-01-26 11:14:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=1221748) 2026-01-26 11:14:11,819 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1221748) 2026-01-26 11:14:12,400 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|         | 59/4096 [00:00<00:06, 588.07it/s]
Adding requests:   3%|         | 118/4096 [00:00<00:07, 546.11it/s]
Adding requests:   4%|         | 173/4096 [00:00<00:07, 531.10it/s]
Adding requests:   6%|         | 227/4096 [00:00<00:07, 524.66it/s]
Adding requests:   7%|         | 280/4096 [00:00<00:07, 518.46it/s]
Adding requests:   8%|         | 332/4096 [00:00<00:07, 508.06it/s]
Adding requests:   9%|         | 383/4096 [00:00<00:07, 500.68it/s]
Adding requests:  11%|         | 434/4096 [00:00<00:07, 498.68it/s]
Adding requests:  12%|        | 484/4096 [00:00<00:07, 495.59it/s]
Adding requests:  13%|        | 534/4096 [00:01<00:07, 485.93it/s]
Adding requests:  14%|        | 587/4096 [00:01<00:07, 498.34it/s]
Adding requests:  16%|        | 639/4096 [00:01<00:06, 503.05it/s]
Adding requests:  17%|        | 692/4096 [00:01<00:06, 510.46it/s]
Adding requests:  18%|        | 744/4096 [00:01<00:06, 506.56it/s]
Adding requests:  19%|        | 795/4096 [00:01<00:06, 499.17it/s]
Adding requests:  21%|        | 845/4096 [00:01<00:06, 486.11it/s]
Adding requests:  22%|       | 899/4096 [00:01<00:06, 500.14it/s]
Adding requests:  23%|       | 951/4096 [00:01<00:06, 505.94it/s]
Adding requests:  25%|       | 1004/4096 [00:01<00:06, 510.98it/s]
Adding requests:  26%|       | 1057/4096 [00:02<00:05, 513.35it/s]
Adding requests:  27%|       | 1109/4096 [00:02<00:05, 502.21it/s]
Adding requests:  28%|       | 1160/4096 [00:02<00:05, 504.37it/s]
Adding requests:  30%|       | 1211/4096 [00:02<00:05, 486.97it/s]
Adding requests:  31%|       | 1263/4096 [00:02<00:05, 495.10it/s]
Adding requests:  32%|      | 1315/4096 [00:02<00:05, 498.60it/s]
Adding requests:  33%|      | 1369/4096 [00:02<00:05, 510.60it/s]
Adding requests:  35%|      | 1423/4096 [00:02<00:05, 515.54it/s]
Adding requests:  36%|      | 1475/4096 [00:02<00:05, 513.07it/s]
Adding requests:  37%|      | 1528/4096 [00:03<00:04, 515.63it/s]
Adding requests:  39%|      | 1581/4096 [00:03<00:04, 518.99it/s]
Adding requests:  40%|      | 1635/4096 [00:03<00:04, 523.80it/s]
Adding requests:  41%|      | 1688/4096 [00:03<00:04, 522.50it/s]
Adding requests:  43%|     | 1741/4096 [00:03<00:04, 523.37it/s]
Adding requests:  44%|     | 1794/4096 [00:03<00:04, 518.84it/s]
Adding requests:  45%|     | 1846/4096 [00:03<00:04, 516.08it/s]
Adding requests:  46%|     | 1898/4096 [00:03<00:04, 509.79it/s]
Adding requests:  48%|     | 1949/4096 [00:03<00:04, 508.13it/s]
Adding requests:  49%|     | 2000/4096 [00:03<00:04, 507.02it/s]
Adding requests:  50%|     | 2052/4096 [00:04<00:04, 510.36it/s]
Adding requests:  51%|    | 2104/4096 [00:04<00:04, 495.97it/s]
Adding requests:  53%|    | 2154/4096 [00:04<00:03, 495.33it/s]
Adding requests:  54%|    | 2204/4096 [00:04<00:03, 492.02it/s]
Adding requests:  55%|    | 2257/4096 [00:04<00:03, 500.93it/s]
Adding requests:  56%|    | 2309/4096 [00:04<00:03, 505.39it/s]
Adding requests:  58%|    | 2360/4096 [00:04<00:03, 505.51it/s]
Adding requests:  59%|    | 2411/4096 [00:04<00:03, 501.18it/s]
Adding requests:  60%|    | 2462/4096 [00:04<00:03, 476.58it/s]
Adding requests:  61%|   | 2512/4096 [00:04<00:03, 481.05it/s]
Adding requests:  63%|   | 2562/4096 [00:05<00:03, 484.48it/s]
Adding requests:  64%|   | 2614/4096 [00:05<00:03, 493.86it/s]
Adding requests:  65%|   | 2667/4096 [00:05<00:02, 503.49it/s]
Adding requests:  66%|   | 2718/4096 [00:05<00:02, 504.21it/s]
Adding requests:  68%|   | 2771/4096 [00:05<00:02, 510.20it/s]
Adding requests:  69%|   | 2823/4096 [00:05<00:02, 511.44it/s]
Adding requests:  70%|   | 2875/4096 [00:05<00:02, 509.41it/s]
Adding requests:  71%|  | 2926/4096 [00:05<00:02, 506.03it/s]
Adding requests:  73%|  | 2978/4096 [00:05<00:02, 508.52it/s]
Adding requests:  74%|  | 3029/4096 [00:05<00:02, 504.95it/s]
Adding requests:  75%|  | 3080/4096 [00:06<00:02, 501.90it/s]
Adding requests:  76%|  | 3131/4096 [00:06<00:01, 503.97it/s]
Adding requests:  78%|  | 3183/4096 [00:06<00:01, 507.10it/s]
Adding requests:  79%|  | 3236/4096 [00:06<00:01, 512.01it/s]
Adding requests:  80%|  | 3290/4096 [00:06<00:01, 519.32it/s]
Adding requests:  82%| | 3343/4096 [00:06<00:01, 519.38it/s]
Adding requests:  83%| | 3395/4096 [00:06<00:01, 517.25it/s]
Adding requests:  84%| | 3447/4096 [00:06<00:01, 516.74it/s]
Adding requests:  85%| | 3499/4096 [00:06<00:01, 502.85it/s]
Adding requests:  87%| | 3551/4096 [00:07<00:01, 504.05it/s]
Adding requests:  88%| | 3602/4096 [00:07<00:00, 502.96it/s]
Adding requests:  89%| | 3653/4096 [00:07<00:00, 503.80it/s]
Adding requests:  90%| | 3706/4096 [00:07<00:00, 508.81it/s]
Adding requests:  92%|| 3759/4096 [00:07<00:00, 513.09it/s]
Adding requests:  93%|| 3811/4096 [00:07<00:00, 492.49it/s]
Adding requests:  94%|| 3863/4096 [00:07<00:00, 499.95it/s]
Adding requests:  96%|| 3914/4096 [00:07<00:00, 500.77it/s]
Adding requests:  97%|| 3967/4096 [00:07<00:00, 505.67it/s]
Adding requests:  98%|| 4018/4096 [00:07<00:00, 504.33it/s]
Adding requests:  99%|| 4069/4096 [00:08<00:00, 498.27it/s]
Adding requests: 100%|| 4096/4096 [00:08<00:00, 505.79it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 66/4096 [00:00<00:16, 247.35it/s, est. speed input: 253334.01 toks/s, output: 247.37 toks/s]
Processed prompts:   2%|         | 98/4096 [00:02<02:29, 26.81it/s, est. speed input: 33488.16 toks/s, output: 32.70 toks/s]   
Processed prompts:   3%|         | 130/4096 [00:05<03:37, 18.23it/s, est. speed input: 23305.98 toks/s, output: 22.76 toks/s]
Processed prompts:   4%|         | 162/4096 [00:08<04:16, 15.31it/s, est. speed input: 19659.19 toks/s, output: 19.20 toks/s]
Processed prompts:   5%|         | 194/4096 [00:11<04:40, 13.93it/s, est. speed input: 17805.50 toks/s, output: 17.39 toks/s]
Processed prompts:   6%|         | 226/4096 [00:13<04:54, 13.14it/s, est. speed input: 16670.01 toks/s, output: 16.28 toks/s]
Processed prompts:   6%|         | 258/4096 [00:16<05:02, 12.68it/s, est. speed input: 15912.54 toks/s, output: 15.54 toks/s]
Processed prompts:   7%|         | 290/4096 [00:19<05:07, 12.37it/s, est. speed input: 15362.28 toks/s, output: 15.00 toks/s]
Processed prompts:   8%|         | 322/4096 [00:22<05:08, 12.25it/s, est. speed input: 14987.45 toks/s, output: 14.64 toks/s]
Processed prompts:   9%|         | 354/4096 [00:24<05:09, 12.09it/s, est. speed input: 14659.76 toks/s, output: 14.32 toks/s]
Processed prompts:   9%|         | 386/4096 [00:27<05:09, 11.98it/s, est. speed input: 14398.64 toks/s, output: 14.06 toks/s]
Processed prompts:  10%|         | 418/4096 [00:30<05:08, 11.92it/s, est. speed input: 14187.48 toks/s, output: 13.85 toks/s]
Processed prompts:  11%|         | 450/4096 [00:32<05:05, 11.94it/s, est. speed input: 14032.44 toks/s, output: 13.70 toks/s]
Processed prompts:  12%|        | 482/4096 [00:35<05:03, 11.89it/s, est. speed input: 13881.09 toks/s, output: 13.56 toks/s]
Processed prompts:  13%|        | 514/4096 [00:38<05:02, 11.84it/s, est. speed input: 13746.86 toks/s, output: 13.42 toks/s]
Processed prompts:  13%|        | 546/4096 [00:41<05:00, 11.81it/s, est. speed input: 13633.18 toks/s, output: 13.31 toks/s]
Processed prompts:  14%|        | 578/4096 [00:43<04:58, 11.78it/s, est. speed input: 13530.16 toks/s, output: 13.21 toks/s]
Processed prompts:  15%|        | 610/4096 [00:46<04:56, 11.77it/s, est. speed input: 13443.18 toks/s, output: 13.13 toks/s]
Processed prompts:  16%|        | 642/4096 [00:49<04:53, 11.76it/s, est. speed input: 13362.92 toks/s, output: 13.05 toks/s]
Processed prompts:  16%|        | 674/4096 [00:51<04:51, 11.74it/s, est. speed input: 13289.95 toks/s, output: 12.98 toks/s]
Processed prompts:  17%|        | 706/4096 [00:54<04:48, 11.74it/s, est. speed input: 13227.64 toks/s, output: 12.92 toks/s]
Processed prompts:  18%|        | 738/4096 [00:57<04:46, 11.73it/s, est. speed input: 13168.48 toks/s, output: 12.86 toks/s]
Processed prompts:  19%|        | 770/4096 [01:00<04:43, 11.74it/s, est. speed input: 13116.68 toks/s, output: 12.81 toks/s]
Processed prompts:  20%|        | 802/4096 [01:02<04:40, 11.73it/s, est. speed input: 13068.73 toks/s, output: 12.76 toks/s]
Processed prompts:  20%|        | 834/4096 [01:05<04:38, 11.73it/s, est. speed input: 13024.15 toks/s, output: 12.72 toks/s]
Processed prompts:  21%|        | 866/4096 [01:08<04:35, 11.74it/s, est. speed input: 12984.55 toks/s, output: 12.68 toks/s]
Processed prompts:  22%|       | 898/4096 [01:11<04:32, 11.73it/s, est. speed input: 12947.11 toks/s, output: 12.64 toks/s]
Processed prompts:  23%|       | 930/4096 [01:13<04:27, 11.83it/s, est. speed input: 12925.29 toks/s, output: 12.62 toks/s]
Processed prompts:  23%|       | 962/4096 [01:16<04:23, 11.89it/s, est. speed input: 12904.07 toks/s, output: 12.60 toks/s]
Processed prompts:  24%|       | 994/4096 [01:19<04:21, 11.85it/s, est. speed input: 12874.08 toks/s, output: 12.57 toks/s]
Processed prompts:  25%|       | 1026/4096 [01:21<04:19, 11.81it/s, est. speed input: 12845.52 toks/s, output: 12.54 toks/s]
Processed prompts:  26%|       | 1058/4096 [01:24<04:17, 11.79it/s, est. speed input: 12818.40 toks/s, output: 12.52 toks/s]
Processed prompts:  27%|       | 1090/4096 [01:27<04:15, 11.77it/s, est. speed input: 12793.42 toks/s, output: 12.49 toks/s]
Processed prompts:  27%|       | 1122/4096 [01:29<04:12, 11.76it/s, est. speed input: 12770.10 toks/s, output: 12.47 toks/s]
Processed prompts:  28%|       | 1154/4096 [01:32<04:08, 11.85it/s, est. speed input: 12757.52 toks/s, output: 12.46 toks/s]
Processed prompts:  29%|       | 1186/4096 [01:35<04:06, 11.82it/s, est. speed input: 12736.98 toks/s, output: 12.44 toks/s]
Processed prompts:  30%|       | 1218/4096 [01:38<04:04, 11.79it/s, est. speed input: 12717.00 toks/s, output: 12.42 toks/s]
Processed prompts:  31%|       | 1250/4096 [01:40<03:59, 11.87it/s, est. speed input: 12706.93 toks/s, output: 12.41 toks/s]
Processed prompts:  31%|      | 1282/4096 [01:43<03:58, 11.82it/s, est. speed input: 12688.04 toks/s, output: 12.39 toks/s]
Processed prompts:  32%|      | 1314/4096 [01:46<03:55, 11.79it/s, est. speed input: 12670.73 toks/s, output: 12.37 toks/s]
Processed prompts:  33%|      | 1346/4096 [01:48<03:53, 11.78it/s, est. speed input: 12654.67 toks/s, output: 12.36 toks/s]
Processed prompts:  34%|      | 1378/4096 [01:51<03:51, 11.76it/s, est. speed input: 12638.61 toks/s, output: 12.34 toks/s]
Processed prompts:  34%|      | 1410/4096 [01:54<03:48, 11.76it/s, est. speed input: 12624.15 toks/s, output: 12.33 toks/s]
Processed prompts:  35%|      | 1442/4096 [01:57<03:45, 11.75it/s, est. speed input: 12609.68 toks/s, output: 12.31 toks/s]
Processed prompts:  36%|      | 1474/4096 [01:59<03:43, 11.74it/s, est. speed input: 12596.09 toks/s, output: 12.30 toks/s]
Processed prompts:  37%|      | 1506/4096 [02:02<03:40, 11.73it/s, est. speed input: 12582.61 toks/s, output: 12.29 toks/s]
Processed prompts:  38%|      | 1538/4096 [02:05<03:37, 11.74it/s, est. speed input: 12570.64 toks/s, output: 12.28 toks/s]
Processed prompts:  38%|      | 1570/4096 [02:07<03:33, 11.82it/s, est. speed input: 12564.99 toks/s, output: 12.27 toks/s]
Processed prompts:  39%|      | 1602/4096 [02:10<03:31, 11.79it/s, est. speed input: 12553.53 toks/s, output: 12.26 toks/s]
Processed prompts:  40%|      | 1634/4096 [02:13<03:29, 11.77it/s, est. speed input: 12542.41 toks/s, output: 12.25 toks/s]
Processed prompts:  41%|      | 1666/4096 [02:16<03:26, 11.76it/s, est. speed input: 12531.86 toks/s, output: 12.24 toks/s]
Processed prompts:  41%|     | 1698/4096 [02:18<03:24, 11.75it/s, est. speed input: 12521.61 toks/s, output: 12.23 toks/s]
Processed prompts:  42%|     | 1730/4096 [02:21<03:21, 11.74it/s, est. speed input: 12511.16 toks/s, output: 12.22 toks/s]
Processed prompts:  43%|     | 1762/4096 [02:24<03:18, 11.74it/s, est. speed input: 12502.41 toks/s, output: 12.21 toks/s]
Processed prompts:  44%|     | 1794/4096 [02:27<03:16, 11.73it/s, est. speed input: 12492.83 toks/s, output: 12.20 toks/s]
Processed prompts:  45%|     | 1826/4096 [02:29<03:13, 11.73it/s, est. speed input: 12483.88 toks/s, output: 12.19 toks/s]
Processed prompts:  45%|     | 1858/4096 [02:32<03:09, 11.82it/s, est. speed input: 12480.95 toks/s, output: 12.19 toks/s]
Processed prompts:  46%|     | 1890/4096 [02:35<03:07, 11.79it/s, est. speed input: 12472.55 toks/s, output: 12.18 toks/s]
Processed prompts:  47%|     | 1922/4096 [02:37<03:04, 11.78it/s, est. speed input: 12465.07 toks/s, output: 12.17 toks/s]
Processed prompts:  48%|     | 1954/4096 [02:40<03:00, 11.85it/s, est. speed input: 12462.20 toks/s, output: 12.17 toks/s]
Processed prompts:  48%|     | 1986/4096 [02:43<02:58, 11.82it/s, est. speed input: 12455.02 toks/s, output: 12.16 toks/s]
Processed prompts:  49%|     | 2018/4096 [02:46<02:56, 11.78it/s, est. speed input: 12447.35 toks/s, output: 12.16 toks/s]
Processed prompts:  50%|     | 2050/4096 [02:48<02:53, 11.77it/s, est. speed input: 12440.39 toks/s, output: 12.15 toks/s]
Processed prompts:  51%|     | 2082/4096 [02:51<02:51, 11.76it/s, est. speed input: 12433.62 toks/s, output: 12.14 toks/s]
Processed prompts:  52%|    | 2114/4096 [02:54<02:48, 11.75it/s, est. speed input: 12427.13 toks/s, output: 12.14 toks/s]
Processed prompts:  52%|    | 2146/4096 [02:56<02:46, 11.74it/s, est. speed input: 12420.66 toks/s, output: 12.13 toks/s]
Processed prompts:  53%|    | 2178/4096 [02:59<02:43, 11.73it/s, est. speed input: 12413.85 toks/s, output: 12.12 toks/s]
Processed prompts:  54%|    | 2210/4096 [03:02<02:38, 11.92it/s, est. speed input: 12417.66 toks/s, output: 12.13 toks/s]
Processed prompts:  55%|    | 2242/4096 [03:04<02:36, 11.86it/s, est. speed input: 12411.41 toks/s, output: 12.12 toks/s]
Processed prompts:  56%|    | 2274/4096 [03:07<02:33, 11.91it/s, est. speed input: 12410.04 toks/s, output: 12.12 toks/s]
Processed prompts:  56%|    | 2306/4096 [03:10<02:31, 11.85it/s, est. speed input: 12404.26 toks/s, output: 12.11 toks/s]
Processed prompts:  57%|    | 2338/4096 [03:13<02:27, 11.90it/s, est. speed input: 12403.10 toks/s, output: 12.11 toks/s]
Processed prompts:  58%|    | 2370/4096 [03:15<02:23, 12.05it/s, est. speed input: 12406.84 toks/s, output: 12.12 toks/s]
Processed prompts:  59%|    | 2402/4096 [03:18<02:21, 11.96it/s, est. speed input: 12401.92 toks/s, output: 12.11 toks/s]
Processed prompts:  59%|    | 2434/4096 [03:21<02:19, 11.88it/s, est. speed input: 12396.26 toks/s, output: 12.11 toks/s]
Processed prompts:  60%|    | 2466/4096 [03:23<02:17, 11.84it/s, est. speed input: 12391.15 toks/s, output: 12.10 toks/s]
Processed prompts:  61%|    | 2498/4096 [03:26<02:14, 11.89it/s, est. speed input: 12389.96 toks/s, output: 12.10 toks/s]
Processed prompts:  62%|   | 2530/4096 [03:29<02:12, 11.84it/s, est. speed input: 12385.20 toks/s, output: 12.09 toks/s]
Processed prompts:  63%|   | 2562/4096 [03:31<02:08, 11.90it/s, est. speed input: 12384.30 toks/s, output: 12.09 toks/s]
Processed prompts:  63%|   | 2594/4096 [03:34<02:06, 11.85it/s, est. speed input: 12379.67 toks/s, output: 12.09 toks/s]
Processed prompts:  64%|   | 2626/4096 [03:37<02:04, 11.81it/s, est. speed input: 12374.92 toks/s, output: 12.08 toks/s]
Processed prompts:  65%|   | 2658/4096 [03:40<02:02, 11.78it/s, est. speed input: 12370.05 toks/s, output: 12.08 toks/s]
Processed prompts:  66%|   | 2690/4096 [03:42<01:59, 11.77it/s, est. speed input: 12365.78 toks/s, output: 12.08 toks/s]
Processed prompts:  66%|   | 2722/4096 [03:45<01:56, 11.75it/s, est. speed input: 12361.23 toks/s, output: 12.07 toks/s]
Processed prompts:  67%|   | 2754/4096 [03:48<01:54, 11.75it/s, est. speed input: 12357.44 toks/s, output: 12.07 toks/s]
Processed prompts:  68%|   | 2786/4096 [03:50<01:51, 11.74it/s, est. speed input: 12353.14 toks/s, output: 12.06 toks/s]
Processed prompts:  69%|   | 2818/4096 [03:53<01:48, 11.74it/s, est. speed input: 12349.18 toks/s, output: 12.06 toks/s]
Processed prompts:  70%|   | 2850/4096 [03:56<01:46, 11.73it/s, est. speed input: 12345.09 toks/s, output: 12.06 toks/s]
Processed prompts:  70%|   | 2882/4096 [03:59<01:43, 11.73it/s, est. speed input: 12341.10 toks/s, output: 12.05 toks/s]
Processed prompts:  71%|   | 2914/4096 [04:01<01:40, 11.73it/s, est. speed input: 12337.57 toks/s, output: 12.05 toks/s]
Processed prompts:  72%|  | 2946/4096 [04:04<01:38, 11.73it/s, est. speed input: 12333.75 toks/s, output: 12.04 toks/s]
Processed prompts:  73%|  | 2978/4096 [04:07<01:35, 11.74it/s, est. speed input: 12330.55 toks/s, output: 12.04 toks/s]
Processed prompts:  73%|  | 3010/4096 [04:10<01:32, 11.73it/s, est. speed input: 12326.78 toks/s, output: 12.04 toks/s]
Processed prompts:  74%|  | 3042/4096 [04:12<01:29, 11.74it/s, est. speed input: 12323.69 toks/s, output: 12.03 toks/s]
Processed prompts:  75%|  | 3074/4096 [04:15<01:27, 11.73it/s, est. speed input: 12320.07 toks/s, output: 12.03 toks/s]
Processed prompts:  76%|  | 3106/4096 [04:18<01:24, 11.73it/s, est. speed input: 12316.72 toks/s, output: 12.03 toks/s]
Processed prompts:  77%|  | 3138/4096 [04:20<01:21, 11.82it/s, est. speed input: 12316.75 toks/s, output: 12.03 toks/s]
Processed prompts:  77%|  | 3170/4096 [04:23<01:18, 11.78it/s, est. speed input: 12313.25 toks/s, output: 12.02 toks/s]
Processed prompts:  78%|  | 3202/4096 [04:26<01:15, 11.77it/s, est. speed input: 12310.38 toks/s, output: 12.02 toks/s]
Processed prompts:  79%|  | 3234/4096 [04:29<01:13, 11.76it/s, est. speed input: 12307.38 toks/s, output: 12.02 toks/s]
Processed prompts:  80%|  | 3266/4096 [04:31<01:10, 11.75it/s, est. speed input: 12304.52 toks/s, output: 12.02 toks/s]
Processed prompts:  81%|  | 3298/4096 [04:34<01:07, 11.74it/s, est. speed input: 12301.49 toks/s, output: 12.01 toks/s]
Processed prompts:  81%| | 3330/4096 [04:37<01:05, 11.74it/s, est. speed input: 12298.75 toks/s, output: 12.01 toks/s]
Processed prompts:  82%| | 3362/4096 [04:39<01:02, 11.74it/s, est. speed input: 12295.97 toks/s, output: 12.01 toks/s]
Processed prompts:  83%| | 3394/4096 [04:42<00:59, 11.74it/s, est. speed input: 12293.32 toks/s, output: 12.01 toks/s]
Processed prompts:  84%| | 3426/4096 [04:45<00:57, 11.73it/s, est. speed input: 12290.41 toks/s, output: 12.00 toks/s]
Processed prompts:  84%| | 3458/4096 [04:48<00:54, 11.73it/s, est. speed input: 12287.71 toks/s, output: 12.00 toks/s]
Processed prompts:  85%| | 3490/4096 [04:50<00:50, 11.93it/s, est. speed input: 12291.57 toks/s, output: 12.00 toks/s]
Processed prompts:  86%| | 3522/4096 [04:53<00:48, 11.87it/s, est. speed input: 12288.85 toks/s, output: 12.00 toks/s]
Processed prompts:  87%| | 3554/4096 [04:56<00:45, 11.82it/s, est. speed input: 12286.20 toks/s, output: 12.00 toks/s]
Processed prompts:  88%| | 3586/4096 [04:58<00:43, 11.79it/s, est. speed input: 12283.68 toks/s, output: 12.00 toks/s]
Processed prompts:  88%| | 3618/4096 [05:01<00:40, 11.77it/s, est. speed input: 12281.18 toks/s, output: 11.99 toks/s]
Processed prompts:  89%| | 3650/4096 [05:04<00:37, 11.76it/s, est. speed input: 12278.73 toks/s, output: 11.99 toks/s]
Processed prompts:  90%| | 3682/4096 [05:07<00:35, 11.75it/s, est. speed input: 12276.36 toks/s, output: 11.99 toks/s]
Processed prompts:  91%| | 3714/4096 [05:09<00:32, 11.83it/s, est. speed input: 12276.54 toks/s, output: 11.99 toks/s]
Processed prompts:  91%|| 3746/4096 [05:12<00:29, 11.80it/s, est. speed input: 12274.21 toks/s, output: 11.99 toks/s]
Processed prompts:  92%|| 3778/4096 [05:15<00:27, 11.77it/s, est. speed input: 12271.86 toks/s, output: 11.98 toks/s]
Processed prompts:  93%|| 3810/4096 [05:17<00:24, 11.75it/s, est. speed input: 12269.44 toks/s, output: 11.98 toks/s]
Processed prompts:  94%|| 3842/4096 [05:20<00:21, 11.83it/s, est. speed input: 12269.72 toks/s, output: 11.98 toks/s]
Processed prompts:  95%|| 3874/4096 [05:23<00:18, 11.74it/s, est. speed input: 12265.81 toks/s, output: 11.98 toks/s]
Processed prompts:  95%|| 3906/4096 [05:26<00:16, 11.71it/s, est. speed input: 12262.91 toks/s, output: 11.98 toks/s]
Processed prompts:  96%|| 3938/4096 [05:28<00:13, 11.72it/s, est. speed input: 12260.79 toks/s, output: 11.97 toks/s]
Processed prompts:  97%|| 3970/4096 [05:31<00:10, 11.73it/s, est. speed input: 12258.98 toks/s, output: 11.97 toks/s]
Processed prompts:  98%|| 4002/4096 [05:34<00:08, 11.73it/s, est. speed input: 12257.07 toks/s, output: 11.97 toks/s]
Processed prompts:  98%|| 4034/4096 [05:36<00:05, 11.82it/s, est. speed input: 12257.68 toks/s, output: 11.97 toks/s]
Processed prompts:  99%|| 4066/4096 [05:39<00:02, 11.89it/s, est. speed input: 12258.36 toks/s, output: 11.97 toks/s]
Processed prompts: 100%|| 4096/4096 [05:39<00:00, 11.89it/s, est. speed input: 12348.79 toks/s, output: 12.06 toks/s]
Processed prompts: 100%|| 4096/4096 [05:39<00:00, 12.06it/s, est. speed input: 12348.79 toks/s, output: 12.06 toks/s]
[rank0]:[W126 11:20:05.929751508 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 11:20:08
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:20:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:20:34 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1227865) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1227865) WARNING 01-26 11:21:26 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.75 requests/s, 12047.79 total tokens/s, 11.75 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 11:20:34] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 11:20:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 11:20:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 11:20:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:20:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:20:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:20:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:20:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:20:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 11:20:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:20:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:20:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:20:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:20:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:20:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 11:20:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 11:20:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 11:20:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:20:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:20:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:20:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:20:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 11:20:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 11:20:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:20:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:20:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:20:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:20:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1227865) [2026-01-26 11:20:38] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1227865) [2026-01-26 11:20:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1227865) [2026-01-26 11:20:38] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1227865) [2026-01-26 11:20:38] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1227865) [2026-01-26 11:20:38] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1227865) [2026-01-26 11:20:38] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1227865) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1227865) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:28<00:00, 28.93s/it]
(EngineCore_DP0 pid=1227865) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:28<00:00, 28.93s/it]
(EngineCore_DP0 pid=1227865) 
(EngineCore_DP0 pid=1227865) [2026-01-26 11:21:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1227865) [2026-01-26 11:21:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=1227865) [2026-01-26 11:21:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1227865) [2026-01-26 11:21:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=1227865) [2026-01-26 11:21:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1227865) [2026-01-26 11:21:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=1227865) [2026-01-26 11:21:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1227865) [2026-01-26 11:21:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=1227865) 2026-01-26 11:21:19,175 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1227865) 2026-01-26 11:21:19,492 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 64/8192 [00:00<00:12, 637.31it/s]
Adding requests:   2%|         | 128/8192 [00:00<00:14, 570.33it/s]
Adding requests:   2%|         | 186/8192 [00:00<00:14, 547.51it/s]
Adding requests:   3%|         | 241/8192 [00:00<00:14, 534.06it/s]
Adding requests:   4%|         | 295/8192 [00:00<00:15, 522.09it/s]
Adding requests:   4%|         | 348/8192 [00:00<00:15, 514.06it/s]
Adding requests:   5%|         | 402/8192 [00:00<00:14, 520.32it/s]
Adding requests:   6%|         | 455/8192 [00:00<00:15, 514.68it/s]
Adding requests:   6%|         | 507/8192 [00:00<00:15, 511.82it/s]
Adding requests:   7%|         | 559/8192 [00:01<00:14, 512.57it/s]
Adding requests:   7%|         | 611/8192 [00:01<00:14, 510.18it/s]
Adding requests:   8%|         | 667/8192 [00:01<00:14, 523.74it/s]
Adding requests:   9%|         | 720/8192 [00:01<00:15, 494.68it/s]
Adding requests:   9%|         | 772/8192 [00:01<00:14, 499.38it/s]
Adding requests:  10%|         | 823/8192 [00:01<00:15, 489.40it/s]
Adding requests:  11%|         | 873/8192 [00:01<00:14, 492.20it/s]
Adding requests:  11%|        | 927/8192 [00:01<00:14, 504.83it/s]
Adding requests:  12%|        | 980/8192 [00:01<00:14, 509.18it/s]
Adding requests:  13%|        | 1032/8192 [00:02<00:14, 510.51it/s]
Adding requests:  13%|        | 1085/8192 [00:02<00:13, 513.63it/s]
Adding requests:  14%|        | 1137/8192 [00:02<00:13, 506.76it/s]
Adding requests:  15%|        | 1192/8192 [00:02<00:13, 517.05it/s]
Adding requests:  15%|        | 1244/8192 [00:02<00:13, 509.17it/s]
Adding requests:  16%|        | 1295/8192 [00:02<00:13, 501.15it/s]
Adding requests:  16%|        | 1350/8192 [00:02<00:13, 514.05it/s]
Adding requests:  17%|        | 1402/8192 [00:02<00:13, 506.63it/s]
Adding requests:  18%|        | 1455/8192 [00:02<00:13, 512.91it/s]
Adding requests:  18%|        | 1507/8192 [00:02<00:13, 513.46it/s]
Adding requests:  19%|        | 1562/8192 [00:03<00:12, 524.15it/s]
Adding requests:  20%|        | 1615/8192 [00:03<00:12, 522.83it/s]
Adding requests:  20%|        | 1672/8192 [00:03<00:12, 535.86it/s]
Adding requests:  21%|        | 1728/8192 [00:03<00:11, 540.64it/s]
Adding requests:  22%|       | 1783/8192 [00:03<00:11, 539.20it/s]
Adding requests:  22%|       | 1837/8192 [00:03<00:11, 536.04it/s]
Adding requests:  23%|       | 1891/8192 [00:03<00:12, 512.88it/s]
Adding requests:  24%|       | 1944/8192 [00:03<00:12, 512.44it/s]
Adding requests:  24%|       | 1996/8192 [00:03<00:12, 512.90it/s]
Adding requests:  25%|       | 2050/8192 [00:03<00:11, 519.82it/s]
Adding requests:  26%|       | 2104/8192 [00:04<00:11, 524.82it/s]
Adding requests:  26%|       | 2157/8192 [00:04<00:11, 515.64it/s]
Adding requests:  27%|       | 2211/8192 [00:04<00:11, 521.05it/s]
Adding requests:  28%|       | 2264/8192 [00:04<00:11, 523.02it/s]
Adding requests:  28%|       | 2320/8192 [00:04<00:11, 530.32it/s]
Adding requests:  29%|       | 2374/8192 [00:04<00:10, 530.42it/s]
Adding requests:  30%|       | 2428/8192 [00:04<00:10, 528.12it/s]
Adding requests:  30%|       | 2484/8192 [00:04<00:10, 536.45it/s]
Adding requests:  31%|       | 2538/8192 [00:04<00:10, 530.22it/s]
Adding requests:  32%|      | 2592/8192 [00:04<00:10, 519.45it/s]
Adding requests:  32%|      | 2645/8192 [00:05<00:10, 518.36it/s]
Adding requests:  33%|      | 2700/8192 [00:05<00:10, 527.14it/s]
Adding requests:  34%|      | 2753/8192 [00:05<00:10, 521.20it/s]
Adding requests:  34%|      | 2806/8192 [00:05<00:10, 520.02it/s]
Adding requests:  35%|      | 2860/8192 [00:05<00:10, 525.82it/s]
Adding requests:  36%|      | 2914/8192 [00:05<00:09, 529.57it/s]
Adding requests:  36%|      | 2967/8192 [00:05<00:10, 521.39it/s]
Adding requests:  37%|      | 3020/8192 [00:05<00:09, 520.26it/s]
Adding requests:  38%|      | 3073/8192 [00:05<00:09, 519.22it/s]
Adding requests:  38%|      | 3127/8192 [00:06<00:09, 521.87it/s]
Adding requests:  39%|      | 3182/8192 [00:06<00:09, 525.23it/s]
Adding requests:  39%|      | 3235/8192 [00:06<00:10, 488.04it/s]
Adding requests:  40%|      | 3289/8192 [00:06<00:09, 501.83it/s]
Adding requests:  41%|      | 3342/8192 [00:06<00:09, 508.90it/s]
Adding requests:  41%|     | 3398/8192 [00:06<00:09, 521.14it/s]
Adding requests:  42%|     | 3451/8192 [00:06<00:09, 520.15it/s]
Adding requests:  43%|     | 3507/8192 [00:06<00:08, 530.72it/s]
Adding requests:  43%|     | 3561/8192 [00:06<00:08, 528.69it/s]
Adding requests:  44%|     | 3615/8192 [00:06<00:08, 530.24it/s]
Adding requests:  45%|     | 3669/8192 [00:07<00:08, 518.89it/s]
Adding requests:  45%|     | 3723/8192 [00:07<00:08, 524.21it/s]
Adding requests:  46%|     | 3780/8192 [00:07<00:08, 536.96it/s]
Adding requests:  47%|     | 3835/8192 [00:07<00:08, 537.72it/s]
Adding requests:  47%|     | 3890/8192 [00:07<00:07, 541.20it/s]
Adding requests:  48%|     | 3946/8192 [00:07<00:07, 546.58it/s]
Adding requests:  49%|     | 4002/8192 [00:07<00:07, 548.76it/s]
Adding requests:  50%|     | 4057/8192 [00:07<00:07, 540.52it/s]
Adding requests:  50%|     | 4112/8192 [00:07<00:07, 536.90it/s]
Adding requests:  51%|     | 4170/8192 [00:07<00:07, 548.20it/s]
Adding requests:  52%|    | 4225/8192 [00:08<00:07, 548.25it/s]
Adding requests:  52%|    | 4282/8192 [00:08<00:07, 552.63it/s]
Adding requests:  53%|    | 4339/8192 [00:08<00:06, 555.22it/s]
Adding requests:  54%|    | 4397/8192 [00:08<00:06, 558.78it/s]
Adding requests:  54%|    | 4454/8192 [00:08<00:06, 561.66it/s]
Adding requests:  55%|    | 4511/8192 [00:08<00:06, 553.40it/s]
Adding requests:  56%|    | 4570/8192 [00:08<00:06, 561.88it/s]
Adding requests:  56%|    | 4627/8192 [00:08<00:06, 519.87it/s]
Adding requests:  57%|    | 4682/8192 [00:08<00:06, 526.70it/s]
Adding requests:  58%|    | 4736/8192 [00:09<00:06, 526.87it/s]
Adding requests:  58%|    | 4791/8192 [00:09<00:06, 533.01it/s]
Adding requests:  59%|    | 4847/8192 [00:09<00:06, 538.83it/s]
Adding requests:  60%|    | 4902/8192 [00:09<00:06, 537.40it/s]
Adding requests:  60%|    | 4956/8192 [00:09<00:06, 536.01it/s]
Adding requests:  61%|    | 5014/8192 [00:09<00:05, 547.99it/s]
Adding requests:  62%|   | 5070/8192 [00:09<00:05, 550.20it/s]
Adding requests:  63%|   | 5132/8192 [00:09<00:05, 568.62it/s]
Adding requests:  63%|   | 5189/8192 [00:09<00:05, 557.19it/s]
Adding requests:  64%|   | 5246/8192 [00:09<00:05, 559.87it/s]
Adding requests:  65%|   | 5303/8192 [00:10<00:05, 556.45it/s]
Adding requests:  65%|   | 5359/8192 [00:10<00:05, 548.67it/s]
Adding requests:  66%|   | 5416/8192 [00:10<00:05, 553.92it/s]
Adding requests:  67%|   | 5472/8192 [00:10<00:05, 541.80it/s]
Adding requests:  67%|   | 5527/8192 [00:10<00:04, 539.49it/s]
Adding requests:  68%|   | 5581/8192 [00:10<00:04, 529.63it/s]
Adding requests:  69%|   | 5635/8192 [00:10<00:04, 530.68it/s]
Adding requests:  69%|   | 5689/8192 [00:10<00:04, 525.05it/s]
Adding requests:  70%|   | 5746/8192 [00:10<00:04, 535.26it/s]
Adding requests:  71%|   | 5801/8192 [00:10<00:04, 537.07it/s]
Adding requests:  71%|  | 5855/8192 [00:11<00:04, 530.67it/s]
Adding requests:  72%|  | 5909/8192 [00:11<00:04, 530.51it/s]
Adding requests:  73%|  | 5964/8192 [00:11<00:04, 534.12it/s]
Adding requests:  73%|  | 6018/8192 [00:11<00:04, 501.97it/s]
Adding requests:  74%|  | 6078/8192 [00:11<00:03, 529.26it/s]
Adding requests:  75%|  | 6132/8192 [00:11<00:03, 531.05it/s]
Adding requests:  76%|  | 6192/8192 [00:11<00:03, 548.90it/s]
Adding requests:  76%|  | 6249/8192 [00:11<00:03, 553.41it/s]
Adding requests:  77%|  | 6311/8192 [00:11<00:03, 572.05it/s]
Adding requests:  78%|  | 6369/8192 [00:12<00:03, 570.13it/s]
Adding requests:  78%|  | 6427/8192 [00:12<00:03, 572.77it/s]
Adding requests:  79%|  | 6485/8192 [00:12<00:02, 571.81it/s]
Adding requests:  80%|  | 6543/8192 [00:12<00:02, 571.75it/s]
Adding requests:  81%|  | 6601/8192 [00:12<00:02, 570.42it/s]
Adding requests:  81%| | 6659/8192 [00:12<00:02, 569.38it/s]
Adding requests:  82%| | 6718/8192 [00:12<00:02, 575.21it/s]
Adding requests:  83%| | 6776/8192 [00:12<00:02, 565.78it/s]
Adding requests:  83%| | 6833/8192 [00:12<00:02, 561.48it/s]
Adding requests:  84%| | 6890/8192 [00:12<00:02, 555.99it/s]
Adding requests:  85%| | 6950/8192 [00:13<00:02, 566.66it/s]
Adding requests:  86%| | 7007/8192 [00:13<00:02, 559.54it/s]
Adding requests:  86%| | 7064/8192 [00:13<00:02, 560.32it/s]
Adding requests:  87%| | 7122/8192 [00:13<00:01, 564.92it/s]
Adding requests:  88%| | 7179/8192 [00:13<00:01, 558.67it/s]
Adding requests:  88%| | 7235/8192 [00:13<00:01, 557.76it/s]
Adding requests:  89%| | 7295/8192 [00:13<00:01, 568.72it/s]
Adding requests:  90%| | 7352/8192 [00:13<00:01, 538.36it/s]
Adding requests:  90%| | 7409/8192 [00:13<00:01, 546.00it/s]
Adding requests:  91%| | 7470/8192 [00:13<00:01, 562.84it/s]
Adding requests:  92%|| 7527/8192 [00:14<00:01, 555.76it/s]
Adding requests:  93%|| 7587/8192 [00:14<00:01, 566.70it/s]
Adding requests:  93%|| 7644/8192 [00:14<00:00, 561.27it/s]
Adding requests:  94%|| 7703/8192 [00:14<00:00, 568.79it/s]
Adding requests:  95%|| 7760/8192 [00:14<00:00, 555.69it/s]
Adding requests:  95%|| 7819/8192 [00:14<00:00, 562.92it/s]
Adding requests:  96%|| 7876/8192 [00:14<00:00, 558.78it/s]
Adding requests:  97%|| 7932/8192 [00:14<00:00, 556.75it/s]
Adding requests:  98%|| 7988/8192 [00:14<00:00, 552.56it/s]
Adding requests:  98%|| 8044/8192 [00:15<00:00, 552.62it/s]
Adding requests:  99%|| 8103/8192 [00:15<00:00, 560.75it/s]
Adding requests: 100%|| 8161/8192 [00:15<00:00, 563.16it/s]
Adding requests: 100%|| 8192/8192 [00:15<00:00, 536.55it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 130/8192 [00:01<01:23, 96.61it/s, est. speed input: 98925.96 toks/s, output: 96.61 toks/s]
Processed prompts:   2%|         | 194/8192 [00:06<05:30, 24.21it/s, est. speed input: 29192.89 toks/s, output: 28.51 toks/s]
Processed prompts:   3%|         | 258/8192 [00:12<07:36, 17.36it/s, est. speed input: 21552.52 toks/s, output: 21.05 toks/s]
Processed prompts:   4%|         | 322/8192 [00:17<08:46, 14.95it/s, est. speed input: 18670.90 toks/s, output: 18.23 toks/s]
Processed prompts:   5%|         | 386/8192 [00:23<09:29, 13.70it/s, est. speed input: 17095.56 toks/s, output: 16.69 toks/s]
Processed prompts:   5%|         | 450/8192 [00:28<09:53, 13.06it/s, est. speed input: 16161.76 toks/s, output: 15.78 toks/s]
Processed prompts:   6%|         | 514/8192 [00:33<10:09, 12.59it/s, est. speed input: 15485.13 toks/s, output: 15.12 toks/s]
Processed prompts:   7%|         | 578/8192 [00:39<10:19, 12.30it/s, est. speed input: 14999.42 toks/s, output: 14.65 toks/s]
Processed prompts:   8%|         | 642/8192 [00:44<10:23, 12.11it/s, est. speed input: 14632.40 toks/s, output: 14.29 toks/s]
Processed prompts:   9%|         | 706/8192 [00:50<10:24, 11.98it/s, est. speed input: 14345.11 toks/s, output: 14.01 toks/s]
Processed prompts:   9%|         | 770/8192 [00:55<10:23, 11.90it/s, est. speed input: 14114.46 toks/s, output: 13.78 toks/s]
Processed prompts:  10%|         | 834/8192 [01:01<10:21, 11.84it/s, est. speed input: 13924.30 toks/s, output: 13.60 toks/s]
Processed prompts:  11%|         | 898/8192 [01:06<10:15, 11.85it/s, est. speed input: 13780.61 toks/s, output: 13.46 toks/s]
Processed prompts:  12%|        | 962/8192 [01:12<10:10, 11.85it/s, est. speed input: 13658.90 toks/s, output: 13.34 toks/s]
Processed prompts:  13%|        | 1026/8192 [01:17<10:07, 11.80it/s, est. speed input: 13538.80 toks/s, output: 13.22 toks/s]
Processed prompts:  13%|        | 1090/8192 [01:23<10:03, 11.77it/s, est. speed input: 13436.44 toks/s, output: 13.12 toks/s]
Processed prompts:  14%|        | 1154/8192 [01:28<09:56, 11.80it/s, est. speed input: 13357.82 toks/s, output: 13.04 toks/s]
Processed prompts:  15%|        | 1218/8192 [01:33<09:50, 11.82it/s, est. speed input: 13288.29 toks/s, output: 12.98 toks/s]
Processed prompts:  16%|        | 1282/8192 [01:39<09:46, 11.79it/s, est. speed input: 13216.92 toks/s, output: 12.91 toks/s]
Processed prompts:  16%|        | 1346/8192 [01:44<09:42, 11.76it/s, est. speed input: 13152.82 toks/s, output: 12.84 toks/s]
Processed prompts:  17%|        | 1410/8192 [01:50<09:37, 11.75it/s, est. speed input: 13095.19 toks/s, output: 12.79 toks/s]
Processed prompts:  18%|        | 1474/8192 [01:55<09:32, 11.73it/s, est. speed input: 13042.49 toks/s, output: 12.74 toks/s]
Processed prompts:  19%|        | 1538/8192 [02:01<09:25, 11.77it/s, est. speed input: 13002.92 toks/s, output: 12.70 toks/s]
Processed prompts:  20%|        | 1602/8192 [02:06<09:20, 11.75it/s, est. speed input: 12959.03 toks/s, output: 12.66 toks/s]
Processed prompts:  20%|        | 1666/8192 [02:12<09:15, 11.74it/s, est. speed input: 12919.21 toks/s, output: 12.62 toks/s]
Processed prompts:  21%|        | 1730/8192 [02:17<09:11, 11.73it/s, est. speed input: 12881.34 toks/s, output: 12.58 toks/s]
Processed prompts:  22%|       | 1794/8192 [02:23<09:06, 11.71it/s, est. speed input: 12845.98 toks/s, output: 12.54 toks/s]
Processed prompts:  23%|       | 1858/8192 [02:28<08:58, 11.76it/s, est. speed input: 12820.86 toks/s, output: 12.52 toks/s]
Processed prompts:  23%|       | 1922/8192 [02:33<08:51, 11.79it/s, est. speed input: 12797.39 toks/s, output: 12.50 toks/s]
Processed prompts:  24%|       | 1986/8192 [02:39<08:47, 11.76it/s, est. speed input: 12768.50 toks/s, output: 12.47 toks/s]
Processed prompts:  25%|       | 2050/8192 [02:44<08:43, 11.74it/s, est. speed input: 12742.60 toks/s, output: 12.44 toks/s]
Processed prompts:  26%|       | 2114/8192 [02:50<08:38, 11.73it/s, est. speed input: 12717.88 toks/s, output: 12.42 toks/s]
Processed prompts:  27%|       | 2178/8192 [02:55<08:28, 11.83it/s, est. speed input: 12706.91 toks/s, output: 12.41 toks/s]
Processed prompts:  27%|       | 2242/8192 [03:00<08:22, 11.84it/s, est. speed input: 12690.73 toks/s, output: 12.39 toks/s]
Processed prompts:  28%|       | 2306/8192 [03:06<08:16, 11.85it/s, est. speed input: 12674.89 toks/s, output: 12.38 toks/s]
Processed prompts:  29%|       | 2370/8192 [03:11<08:08, 11.91it/s, est. speed input: 12665.87 toks/s, output: 12.37 toks/s]
Processed prompts:  30%|       | 2434/8192 [03:17<08:06, 11.85it/s, est. speed input: 12646.87 toks/s, output: 12.35 toks/s]
Processed prompts:  30%|       | 2498/8192 [03:22<08:00, 11.85it/s, est. speed input: 12633.10 toks/s, output: 12.34 toks/s]
Processed prompts:  31%|      | 2562/8192 [03:27<07:55, 11.85it/s, est. speed input: 12620.00 toks/s, output: 12.32 toks/s]
Processed prompts:  32%|      | 2626/8192 [03:33<07:51, 11.80it/s, est. speed input: 12603.31 toks/s, output: 12.31 toks/s]
Processed prompts:  33%|      | 2690/8192 [03:38<07:47, 11.77it/s, est. speed input: 12587.65 toks/s, output: 12.29 toks/s]
Processed prompts:  34%|      | 2754/8192 [03:44<07:42, 11.75it/s, est. speed input: 12572.86 toks/s, output: 12.28 toks/s]
Processed prompts:  34%|      | 2818/8192 [03:49<07:38, 11.73it/s, est. speed input: 12558.66 toks/s, output: 12.26 toks/s]
Processed prompts:  35%|      | 2882/8192 [03:55<07:32, 11.73it/s, est. speed input: 12545.52 toks/s, output: 12.25 toks/s]
Processed prompts:  36%|      | 2946/8192 [04:00<07:27, 11.72it/s, est. speed input: 12532.56 toks/s, output: 12.24 toks/s]
Processed prompts:  37%|      | 3010/8192 [04:06<07:22, 11.71it/s, est. speed input: 12520.46 toks/s, output: 12.23 toks/s]
Processed prompts:  38%|      | 3074/8192 [04:11<07:17, 11.71it/s, est. speed input: 12508.53 toks/s, output: 12.22 toks/s]
Processed prompts:  38%|      | 3138/8192 [04:17<07:09, 11.76it/s, est. speed input: 12501.13 toks/s, output: 12.21 toks/s]
Processed prompts:  39%|      | 3202/8192 [04:22<07:05, 11.74it/s, est. speed input: 12490.12 toks/s, output: 12.20 toks/s]
Processed prompts:  40%|      | 3266/8192 [04:27<07:00, 11.72it/s, est. speed input: 12479.64 toks/s, output: 12.19 toks/s]
Processed prompts:  41%|      | 3330/8192 [04:33<06:55, 11.71it/s, est. speed input: 12469.24 toks/s, output: 12.18 toks/s]
Processed prompts:  41%|     | 3394/8192 [04:38<06:49, 11.71it/s, est. speed input: 12459.52 toks/s, output: 12.17 toks/s]
Processed prompts:  42%|     | 3458/8192 [04:44<06:40, 11.81it/s, est. speed input: 12457.48 toks/s, output: 12.17 toks/s]
Processed prompts:  43%|     | 3522/8192 [04:49<06:36, 11.77it/s, est. speed input: 12448.25 toks/s, output: 12.16 toks/s]
Processed prompts:  44%|     | 3586/8192 [04:55<06:32, 11.75it/s, est. speed input: 12439.35 toks/s, output: 12.15 toks/s]
Processed prompts:  45%|     | 3650/8192 [05:00<06:27, 11.73it/s, est. speed input: 12430.74 toks/s, output: 12.14 toks/s]
Processed prompts:  45%|     | 3714/8192 [05:06<06:20, 11.77it/s, est. speed input: 12425.81 toks/s, output: 12.13 toks/s]
Processed prompts:  46%|     | 3778/8192 [05:11<06:15, 11.75it/s, est. speed input: 12418.01 toks/s, output: 12.13 toks/s]
Processed prompts:  47%|     | 3842/8192 [05:17<06:10, 11.73it/s, est. speed input: 12410.32 toks/s, output: 12.12 toks/s]
Processed prompts:  48%|     | 3906/8192 [05:22<06:05, 11.72it/s, est. speed input: 12402.86 toks/s, output: 12.11 toks/s]
Processed prompts:  48%|     | 3970/8192 [05:27<06:00, 11.71it/s, est. speed input: 12395.59 toks/s, output: 12.11 toks/s]
Processed prompts:  49%|     | 4034/8192 [05:33<05:53, 11.75it/s, est. speed input: 12391.46 toks/s, output: 12.10 toks/s]
Processed prompts:  50%|     | 4098/8192 [05:38<05:48, 11.73it/s, est. speed input: 12384.58 toks/s, output: 12.09 toks/s]
Processed prompts:  51%|     | 4162/8192 [05:44<05:43, 11.73it/s, est. speed input: 12378.41 toks/s, output: 12.09 toks/s]
Processed prompts:  52%|    | 4226/8192 [05:49<05:35, 11.82it/s, est. speed input: 12377.83 toks/s, output: 12.09 toks/s]
Processed prompts:  52%|    | 4290/8192 [05:55<05:29, 11.83it/s, est. speed input: 12374.12 toks/s, output: 12.08 toks/s]
Processed prompts:  53%|    | 4354/8192 [06:00<05:25, 11.79it/s, est. speed input: 12368.21 toks/s, output: 12.08 toks/s]
Processed prompts:  54%|    | 4418/8192 [06:05<05:20, 11.76it/s, est. speed input: 12362.09 toks/s, output: 12.07 toks/s]
Processed prompts:  55%|    | 4482/8192 [06:11<05:16, 11.74it/s, est. speed input: 12356.42 toks/s, output: 12.07 toks/s]
Processed prompts:  55%|    | 4546/8192 [06:16<05:10, 11.73it/s, est. speed input: 12351.12 toks/s, output: 12.06 toks/s]
Processed prompts:  56%|    | 4610/8192 [06:22<05:05, 11.72it/s, est. speed input: 12345.81 toks/s, output: 12.06 toks/s]
Processed prompts:  57%|    | 4674/8192 [06:27<05:00, 11.71it/s, est. speed input: 12340.56 toks/s, output: 12.05 toks/s]
Processed prompts:  58%|    | 4738/8192 [06:33<04:53, 11.76it/s, est. speed input: 12337.93 toks/s, output: 12.05 toks/s]
Processed prompts:  59%|    | 4802/8192 [06:38<04:47, 11.79it/s, est. speed input: 12335.52 toks/s, output: 12.05 toks/s]
Processed prompts:  59%|    | 4866/8192 [06:44<04:42, 11.76it/s, est. speed input: 12330.53 toks/s, output: 12.04 toks/s]
Processed prompts:  60%|    | 4930/8192 [06:49<04:37, 11.75it/s, est. speed input: 12326.02 toks/s, output: 12.04 toks/s]
Processed prompts:  61%|    | 4994/8192 [06:54<04:30, 11.84it/s, est. speed input: 12326.31 toks/s, output: 12.04 toks/s]
Processed prompts:  62%|   | 5058/8192 [07:00<04:25, 11.79it/s, est. speed input: 12321.68 toks/s, output: 12.03 toks/s]
Processed prompts:  63%|   | 5122/8192 [07:05<04:21, 11.76it/s, est. speed input: 12317.17 toks/s, output: 12.03 toks/s]
Processed prompts:  63%|   | 5186/8192 [07:11<04:15, 11.78it/s, est. speed input: 12314.67 toks/s, output: 12.03 toks/s]
Processed prompts:  64%|   | 5250/8192 [07:16<04:10, 11.76it/s, est. speed input: 12310.64 toks/s, output: 12.02 toks/s]
Processed prompts:  65%|   | 5314/8192 [07:22<04:04, 11.79it/s, est. speed input: 12308.68 toks/s, output: 12.02 toks/s]
Processed prompts:  66%|   | 5378/8192 [07:27<03:58, 11.81it/s, est. speed input: 12306.79 toks/s, output: 12.02 toks/s]
Processed prompts:  66%|   | 5442/8192 [07:32<03:53, 11.78it/s, est. speed input: 12302.95 toks/s, output: 12.01 toks/s]
Processed prompts:  67%|   | 5506/8192 [07:38<03:47, 11.81it/s, est. speed input: 12301.20 toks/s, output: 12.01 toks/s]
Processed prompts:  68%|   | 5570/8192 [07:43<03:42, 11.77it/s, est. speed input: 12297.15 toks/s, output: 12.01 toks/s]
Processed prompts:  69%|   | 5634/8192 [07:49<03:36, 11.80it/s, est. speed input: 12295.66 toks/s, output: 12.01 toks/s]
Processed prompts:  70%|   | 5698/8192 [07:54<03:31, 11.77it/s, est. speed input: 12291.89 toks/s, output: 12.00 toks/s]
Processed prompts:  70%|   | 5762/8192 [08:00<03:26, 11.74it/s, est. speed input: 12288.18 toks/s, output: 12.00 toks/s]
Processed prompts:  71%|   | 5826/8192 [08:05<03:21, 11.73it/s, est. speed input: 12284.69 toks/s, output: 12.00 toks/s]
Processed prompts:  72%|  | 5890/8192 [08:11<03:16, 11.71it/s, est. speed input: 12281.06 toks/s, output: 11.99 toks/s]
Processed prompts:  73%|  | 5954/8192 [08:16<03:11, 11.71it/s, est. speed input: 12277.73 toks/s, output: 11.99 toks/s]
Processed prompts:  73%|  | 6018/8192 [08:22<03:05, 11.70it/s, est. speed input: 12274.17 toks/s, output: 11.99 toks/s]
Processed prompts:  74%|  | 6082/8192 [08:27<03:00, 11.70it/s, est. speed input: 12271.15 toks/s, output: 11.98 toks/s]
Processed prompts:  75%|  | 6146/8192 [08:33<02:54, 11.70it/s, est. speed input: 12267.94 toks/s, output: 11.98 toks/s]
Processed prompts:  76%|  | 6210/8192 [08:38<02:49, 11.69it/s, est. speed input: 12264.69 toks/s, output: 11.98 toks/s]
Processed prompts:  77%|  | 6274/8192 [08:43<02:44, 11.69it/s, est. speed input: 12261.59 toks/s, output: 11.97 toks/s]
Processed prompts:  77%|  | 6338/8192 [08:49<02:38, 11.69it/s, est. speed input: 12258.59 toks/s, output: 11.97 toks/s]
Processed prompts:  78%|  | 6402/8192 [08:54<02:33, 11.69it/s, est. speed input: 12255.60 toks/s, output: 11.97 toks/s]
Processed prompts:  79%|  | 6466/8192 [09:00<02:27, 11.69it/s, est. speed input: 12252.81 toks/s, output: 11.97 toks/s]
Processed prompts:  80%|  | 6530/8192 [09:05<02:22, 11.69it/s, est. speed input: 12250.00 toks/s, output: 11.96 toks/s]
Processed prompts:  80%|  | 6594/8192 [09:11<02:16, 11.74it/s, est. speed input: 12249.01 toks/s, output: 11.96 toks/s]
Processed prompts:  81%| | 6658/8192 [09:16<02:10, 11.78it/s, est. speed input: 12247.96 toks/s, output: 11.96 toks/s]
Processed prompts:  82%| | 6722/8192 [09:22<02:05, 11.75it/s, est. speed input: 12245.27 toks/s, output: 11.96 toks/s]
Processed prompts:  83%| | 6786/8192 [09:27<01:59, 11.74it/s, est. speed input: 12242.71 toks/s, output: 11.96 toks/s]
Processed prompts:  84%| | 6850/8192 [09:33<01:54, 11.73it/s, est. speed input: 12240.25 toks/s, output: 11.95 toks/s]
Processed prompts:  84%| | 6914/8192 [09:38<01:49, 11.71it/s, est. speed input: 12237.68 toks/s, output: 11.95 toks/s]
Processed prompts:  85%| | 6978/8192 [09:44<01:43, 11.71it/s, est. speed input: 12235.29 toks/s, output: 11.95 toks/s]
Processed prompts:  86%| | 7042/8192 [09:49<01:38, 11.71it/s, est. speed input: 12232.87 toks/s, output: 11.95 toks/s]
Processed prompts:  87%| | 7106/8192 [09:54<01:32, 11.76it/s, est. speed input: 12232.24 toks/s, output: 11.95 toks/s]
Processed prompts:  88%| | 7170/8192 [10:00<01:27, 11.74it/s, est. speed input: 12229.99 toks/s, output: 11.94 toks/s]
Processed prompts:  88%| | 7234/8192 [10:05<01:21, 11.78it/s, est. speed input: 12229.32 toks/s, output: 11.94 toks/s]
Processed prompts:  89%| | 7298/8192 [10:11<01:16, 11.75it/s, est. speed input: 12226.95 toks/s, output: 11.94 toks/s]
Processed prompts:  90%| | 7362/8192 [10:16<01:10, 11.73it/s, est. speed input: 12224.72 toks/s, output: 11.94 toks/s]
Processed prompts:  91%| | 7426/8192 [10:22<01:05, 11.78it/s, est. speed input: 12224.21 toks/s, output: 11.94 toks/s]
Processed prompts:  91%|| 7490/8192 [10:27<00:59, 11.75it/s, est. speed input: 12222.02 toks/s, output: 11.94 toks/s]
Processed prompts:  92%|| 7554/8192 [10:32<00:53, 11.85it/s, est. speed input: 12223.21 toks/s, output: 11.94 toks/s]
Processed prompts:  93%|| 7618/8192 [10:38<00:48, 11.80it/s, est. speed input: 12220.96 toks/s, output: 11.93 toks/s]
Processed prompts:  94%|| 7682/8192 [10:43<00:43, 11.82it/s, est. speed input: 12220.36 toks/s, output: 11.93 toks/s]
Processed prompts:  95%|| 7746/8192 [10:49<00:37, 11.78it/s, est. speed input: 12218.33 toks/s, output: 11.93 toks/s]
Processed prompts:  95%|| 7810/8192 [10:54<00:32, 11.76it/s, est. speed input: 12216.54 toks/s, output: 11.93 toks/s]
Processed prompts:  96%|| 7874/8192 [11:00<00:27, 11.74it/s, est. speed input: 12214.56 toks/s, output: 11.93 toks/s]
Processed prompts:  97%|| 7938/8192 [11:05<00:21, 11.78it/s, est. speed input: 12214.07 toks/s, output: 11.93 toks/s]
Processed prompts:  98%|| 8002/8192 [11:10<00:16, 11.75it/s, est. speed input: 12212.09 toks/s, output: 11.93 toks/s]
Processed prompts:  98%|| 8066/8192 [11:16<00:10, 11.79it/s, est. speed input: 12211.55 toks/s, output: 11.93 toks/s]
Processed prompts:  99%|| 8130/8192 [11:21<00:05, 11.86it/s, est. speed input: 12212.53 toks/s, output: 11.93 toks/s]
Processed prompts: 100%|| 8192/8192 [11:21<00:00, 11.86it/s, est. speed input: 12305.66 toks/s, output: 12.02 toks/s]
Processed prompts: 100%|| 8192/8192 [11:21<00:00, 12.02it/s, est. speed input: 12305.66 toks/s, output: 12.02 toks/s]
[rank0]:[W126 11:33:03.091553924 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 16:28:26
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 16:28:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 16:28:30 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1496168) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1496168) WARNING 01-26 16:30:02 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 9.43 requests/s, 4836.08 total tokens/s, 9.43 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 16:28:30] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:28:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:28:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:28:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:28:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:28:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:28:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:28:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:28:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:28:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:28:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:28:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:28:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:28:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 16:28:33] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:28:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:28:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:28:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:28:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:28:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:28:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:28:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:28:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:28:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:28:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:28:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:28:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:28:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1496168) [2026-01-26 16:28:34] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1496168) [2026-01-26 16:28:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1496168) [2026-01-26 16:28:34] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1496168) [2026-01-26 16:28:34] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1496168) [2026-01-26 16:28:34] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1496168) [2026-01-26 16:28:34] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1496168) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1496168) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.24s/it]
(EngineCore_DP0 pid=1496168) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:05<00:00, 33.44s/it]
(EngineCore_DP0 pid=1496168) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:05<00:00, 32.66s/it]
(EngineCore_DP0 pid=1496168) 
(EngineCore_DP0 pid=1496168) [2026-01-26 16:29:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1496168) [2026-01-26 16:29:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=1496168) [2026-01-26 16:29:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1496168) [2026-01-26 16:29:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=1496168) [2026-01-26 16:29:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1496168) [2026-01-26 16:29:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=1496168) [2026-01-26 16:29:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1496168) [2026-01-26 16:29:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=1496168) 2026-01-26 16:29:51,856 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1496168) 2026-01-26 16:29:52,261 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:   1%|          | 1/128 [00:00<01:59,  1.06it/s]
Adding requests:   2%|         | 2/128 [00:01<01:15,  1.68it/s]
Adding requests:   2%|         | 3/128 [00:01<00:54,  2.30it/s]
Adding requests:   3%|         | 4/128 [00:01<00:41,  3.02it/s]
Adding requests:   4%|         | 5/128 [00:01<00:32,  3.82it/s]
Adding requests:   5%|         | 7/128 [00:01<00:20,  6.05it/s]
Adding requests:   7%|         | 9/128 [00:02<00:14,  8.14it/s]
Adding requests:   9%|         | 12/128 [00:02<00:09, 11.92it/s]
Adding requests:  12%|        | 16/128 [00:02<00:06, 17.63it/s]
Adding requests:  16%|        | 20/128 [00:02<00:05, 20.92it/s]
Adding requests:  21%|        | 27/128 [00:02<00:03, 30.67it/s]
Adding requests:  29%|       | 37/128 [00:02<00:01, 47.06it/s]
Adding requests:  50%|     | 64/128 [00:02<00:00, 103.43it/s]
Adding requests:  73%|  | 93/128 [00:02<00:00, 152.66it/s]
Adding requests: 100%|| 128/128 [00:03<00:00, 42.54it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|        | 18/128 [00:00<00:01, 109.42it/s, est. speed input: 56032.28 toks/s, output: 109.43 toks/s]
Processed prompts:  23%|       | 29/128 [00:01<00:04, 20.58it/s, est. speed input: 12414.60 toks/s, output: 24.25 toks/s]  
Processed prompts:  27%|       | 35/128 [00:01<00:05, 16.51it/s, est. speed input: 10197.67 toks/s, output: 19.92 toks/s]
Processed prompts:  30%|       | 39/128 [00:02<00:05, 14.88it/s, est. speed input: 9371.16 toks/s, output: 18.30 toks/s] 
Processed prompts:  33%|      | 42/128 [00:02<00:06, 13.86it/s, est. speed input: 8900.55 toks/s, output: 17.38 toks/s]
Processed prompts:  34%|      | 44/128 [00:02<00:06, 13.33it/s, est. speed input: 8666.65 toks/s, output: 16.93 toks/s]
Processed prompts:  36%|      | 46/128 [00:02<00:06, 12.82it/s, est. speed input: 8457.82 toks/s, output: 16.52 toks/s]
Processed prompts:  38%|      | 48/128 [00:02<00:06, 12.33it/s, est. speed input: 8269.77 toks/s, output: 16.15 toks/s]
Processed prompts:  39%|      | 50/128 [00:03<00:06, 11.92it/s, est. speed input: 8103.02 toks/s, output: 15.83 toks/s]
Processed prompts:  41%|      | 52/128 [00:03<00:06, 11.53it/s, est. speed input: 7944.43 toks/s, output: 15.52 toks/s]
Processed prompts:  42%|     | 54/128 [00:03<00:06, 11.26it/s, est. speed input: 7808.31 toks/s, output: 15.25 toks/s]
Processed prompts:  44%|     | 56/128 [00:03<00:06, 11.12it/s, est. speed input: 7692.91 toks/s, output: 15.03 toks/s]
Processed prompts:  45%|     | 58/128 [00:03<00:06, 11.05it/s, est. speed input: 7592.65 toks/s, output: 14.83 toks/s]
Processed prompts:  47%|     | 60/128 [00:04<00:06, 11.01it/s, est. speed input: 7503.41 toks/s, output: 14.66 toks/s]
Processed prompts:  48%|     | 62/128 [00:04<00:06, 10.93it/s, est. speed input: 7415.50 toks/s, output: 14.48 toks/s]
Processed prompts:  50%|     | 64/128 [00:04<00:05, 10.78it/s, est. speed input: 7327.17 toks/s, output: 14.31 toks/s]
Processed prompts:  52%|    | 66/128 [00:04<00:05, 10.75it/s, est. speed input: 7251.88 toks/s, output: 14.16 toks/s]
Processed prompts:  53%|    | 68/128 [00:04<00:05, 10.73it/s, est. speed input: 7183.50 toks/s, output: 14.03 toks/s]
Processed prompts:  55%|    | 70/128 [00:05<00:05, 10.72it/s, est. speed input: 7120.18 toks/s, output: 13.91 toks/s]
Processed prompts:  56%|    | 72/128 [00:05<00:05, 10.69it/s, est. speed input: 7059.29 toks/s, output: 13.79 toks/s]
Processed prompts:  58%|    | 74/128 [00:05<00:05, 10.62it/s, est. speed input: 6999.13 toks/s, output: 13.67 toks/s]
Processed prompts:  59%|    | 76/128 [00:05<00:04, 10.66it/s, est. speed input: 6949.20 toks/s, output: 13.57 toks/s]
Processed prompts:  61%|    | 78/128 [00:05<00:04, 10.70it/s, est. speed input: 6903.67 toks/s, output: 13.48 toks/s]
Processed prompts:  62%|   | 80/128 [00:05<00:04, 10.71it/s, est. speed input: 6859.54 toks/s, output: 13.40 toks/s]
Processed prompts:  64%|   | 82/128 [00:06<00:04, 10.73it/s, est. speed input: 6819.27 toks/s, output: 13.32 toks/s]
Processed prompts:  66%|   | 84/128 [00:06<00:04, 10.76it/s, est. speed input: 6782.16 toks/s, output: 13.25 toks/s]
Processed prompts:  67%|   | 86/128 [00:06<00:03, 10.66it/s, est. speed input: 6739.76 toks/s, output: 13.16 toks/s]
Processed prompts:  69%|   | 88/128 [00:06<00:03, 10.67it/s, est. speed input: 6704.82 toks/s, output: 13.10 toks/s]
Processed prompts:  70%|   | 90/128 [00:06<00:03, 10.66it/s, est. speed input: 6670.48 toks/s, output: 13.03 toks/s]
Processed prompts:  72%|  | 92/128 [00:07<00:03, 10.72it/s, est. speed input: 6641.41 toks/s, output: 12.97 toks/s]
Processed prompts:  73%|  | 94/128 [00:07<00:03, 10.72it/s, est. speed input: 6611.87 toks/s, output: 12.91 toks/s]
Processed prompts:  75%|  | 96/128 [00:07<00:03, 10.66it/s, est. speed input: 6580.92 toks/s, output: 12.85 toks/s]
Processed prompts:  77%|  | 98/128 [00:07<00:02, 10.65it/s, est. speed input: 6552.66 toks/s, output: 12.80 toks/s]
Processed prompts:  78%|  | 100/128 [00:07<00:02, 10.64it/s, est. speed input: 6525.88 toks/s, output: 12.75 toks/s]
Processed prompts:  80%|  | 102/128 [00:08<00:02, 10.73it/s, est. speed input: 6504.81 toks/s, output: 12.70 toks/s]
Processed prompts:  81%| | 104/128 [00:08<00:02, 10.71it/s, est. speed input: 6481.23 toks/s, output: 12.66 toks/s]
Processed prompts:  83%| | 106/128 [00:08<00:02, 10.70it/s, est. speed input: 6458.68 toks/s, output: 12.61 toks/s]
Processed prompts:  84%| | 108/128 [00:08<00:01, 10.61it/s, est. speed input: 6433.46 toks/s, output: 12.57 toks/s]
Processed prompts:  86%| | 110/128 [00:08<00:01, 10.67it/s, est. speed input: 6414.42 toks/s, output: 12.53 toks/s]
Processed prompts:  88%| | 112/128 [00:08<00:01, 10.73it/s, est. speed input: 6397.11 toks/s, output: 12.49 toks/s]
Processed prompts:  89%| | 114/128 [00:09<00:01, 10.75it/s, est. speed input: 6379.35 toks/s, output: 12.46 toks/s]
Processed prompts:  91%| | 116/128 [00:09<00:01, 10.71it/s, est. speed input: 6360.45 toks/s, output: 12.42 toks/s]
Processed prompts:  92%|| 118/128 [00:09<00:00, 10.70it/s, est. speed input: 6342.69 toks/s, output: 12.39 toks/s]
Processed prompts:  94%|| 120/128 [00:09<00:00, 10.59it/s, est. speed input: 6322.07 toks/s, output: 12.35 toks/s]
Processed prompts:  95%|| 122/128 [00:09<00:00, 10.66it/s, est. speed input: 6307.58 toks/s, output: 12.32 toks/s]
Processed prompts:  97%|| 124/128 [00:10<00:00, 10.69it/s, est. speed input: 6292.66 toks/s, output: 12.29 toks/s]
Processed prompts:  98%|| 126/128 [00:10<00:00, 10.74it/s, est. speed input: 6279.73 toks/s, output: 12.27 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 10.74it/s, est. speed input: 6265.77 toks/s, output: 12.24 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 10.74it/s, est. speed input: 6265.77 toks/s, output: 12.24 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 12.24it/s, est. speed input: 6265.77 toks/s, output: 12.24 toks/s]
[rank0]:[W126 16:30:17.281023416 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 16:30:34
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 16:30:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 16:30:40 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1498155) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1498155) WARNING 01-26 16:31:59 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.59 requests/s, 5729.43 total tokens/s, 5.59 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 16:30:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:30:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:30:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:30:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:30:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:30:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:30:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:30:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:30:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:30:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:30:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:30:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:30:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:30:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 16:30:43] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:30:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:30:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:30:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:30:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:30:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:30:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:30:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:30:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:30:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:30:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:30:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:30:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:30:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1498155) [2026-01-26 16:30:44] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1498155) [2026-01-26 16:30:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1498155) [2026-01-26 16:30:44] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1498155) [2026-01-26 16:30:44] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1498155) [2026-01-26 16:30:44] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1498155) [2026-01-26 16:30:44] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1498155) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1498155) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.81s/it]
(EngineCore_DP0 pid=1498155) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:05<00:00, 33.20s/it]
(EngineCore_DP0 pid=1498155) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:05<00:00, 32.54s/it]
(EngineCore_DP0 pid=1498155) 
(EngineCore_DP0 pid=1498155) [2026-01-26 16:31:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1498155) [2026-01-26 16:31:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=1498155) [2026-01-26 16:31:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1498155) [2026-01-26 16:31:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=1498155) [2026-01-26 16:31:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1498155) [2026-01-26 16:31:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=1498155) [2026-01-26 16:31:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1498155) [2026-01-26 16:31:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=1498155) 2026-01-26 16:31:58,961 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1498155) 2026-01-26 16:31:58,998 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  24%|       | 31/128 [00:00<00:00, 309.04it/s]
Adding requests:  58%|    | 74/128 [00:00<00:00, 377.53it/s]
Adding requests:  92%|| 118/128 [00:00<00:00, 405.90it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 391.76it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 2/128 [00:00<00:20,  6.07it/s, est. speed input: 6212.16 toks/s, output: 6.07 toks/s]
Processed prompts:   2%|         | 3/128 [00:00<00:26,  4.65it/s, est. speed input: 4991.92 toks/s, output: 4.87 toks/s]
Processed prompts:   3%|         | 4/128 [00:00<00:30,  4.11it/s, est. speed input: 4520.64 toks/s, output: 4.41 toks/s]
Processed prompts:   4%|         | 5/128 [00:01<00:31,  3.85it/s, est. speed input: 4276.71 toks/s, output: 4.18 toks/s]
Processed prompts:   5%|         | 6/128 [00:01<00:32,  3.70it/s, est. speed input: 4130.80 toks/s, output: 4.03 toks/s]
Processed prompts:   5%|         | 7/128 [00:01<00:33,  3.58it/s, est. speed input: 4012.40 toks/s, output: 3.92 toks/s]
Processed prompts:   6%|         | 8/128 [00:02<00:32,  3.68it/s, est. speed input: 4013.90 toks/s, output: 3.92 toks/s]
Processed prompts:   7%|         | 9/128 [00:02<00:28,  4.16it/s, est. speed input: 4167.59 toks/s, output: 4.07 toks/s]
Processed prompts:   8%|         | 10/128 [00:02<00:25,  4.59it/s, est. speed input: 4305.09 toks/s, output: 4.20 toks/s]
Processed prompts:   9%|         | 11/128 [00:02<00:23,  4.93it/s, est. speed input: 4421.09 toks/s, output: 4.32 toks/s]
Processed prompts:   9%|         | 12/128 [00:02<00:22,  5.18it/s, est. speed input: 4520.36 toks/s, output: 4.41 toks/s]
Processed prompts:  10%|         | 13/128 [00:02<00:21,  5.33it/s, est. speed input: 4601.23 toks/s, output: 4.49 toks/s]
Processed prompts:  11%|         | 14/128 [00:03<00:20,  5.50it/s, est. speed input: 4683.22 toks/s, output: 4.57 toks/s]
Processed prompts:  12%|        | 15/128 [00:03<00:20,  5.63it/s, est. speed input: 4755.61 toks/s, output: 4.64 toks/s]
Processed prompts:  12%|        | 16/128 [00:03<00:19,  5.71it/s, est. speed input: 4820.04 toks/s, output: 4.71 toks/s]
Processed prompts:  13%|        | 17/128 [00:03<00:19,  5.79it/s, est. speed input: 4881.38 toks/s, output: 4.77 toks/s]
Processed prompts:  14%|        | 18/128 [00:03<00:18,  5.80it/s, est. speed input: 4930.82 toks/s, output: 4.82 toks/s]
Processed prompts:  15%|        | 19/128 [00:03<00:18,  5.75it/s, est. speed input: 4969.78 toks/s, output: 4.85 toks/s]
Processed prompts:  16%|        | 20/128 [00:04<00:18,  5.79it/s, est. speed input: 5013.00 toks/s, output: 4.90 toks/s]
Processed prompts:  16%|        | 21/128 [00:04<00:18,  5.83it/s, est. speed input: 5055.06 toks/s, output: 4.94 toks/s]
Processed prompts:  17%|        | 22/128 [00:04<00:18,  5.84it/s, est. speed input: 5091.95 toks/s, output: 4.97 toks/s]
Processed prompts:  18%|        | 23/128 [00:04<00:17,  5.86it/s, est. speed input: 5127.30 toks/s, output: 5.01 toks/s]
Processed prompts:  19%|        | 24/128 [00:04<00:17,  5.90it/s, est. speed input: 5162.79 toks/s, output: 5.04 toks/s]
Processed prompts:  20%|        | 25/128 [00:04<00:17,  5.85it/s, est. speed input: 5188.08 toks/s, output: 5.07 toks/s]
Processed prompts:  20%|        | 26/128 [00:05<00:17,  5.87it/s, est. speed input: 5216.93 toks/s, output: 5.09 toks/s]
Processed prompts:  21%|        | 27/128 [00:05<00:17,  5.89it/s, est. speed input: 5244.39 toks/s, output: 5.12 toks/s]
Processed prompts:  22%|       | 28/128 [00:05<00:17,  5.88it/s, est. speed input: 5268.05 toks/s, output: 5.14 toks/s]
Processed prompts:  23%|       | 29/128 [00:05<00:16,  5.89it/s, est. speed input: 5292.07 toks/s, output: 5.17 toks/s]
Processed prompts:  23%|       | 30/128 [00:05<00:16,  5.92it/s, est. speed input: 5315.90 toks/s, output: 5.19 toks/s]
Processed prompts:  24%|       | 31/128 [00:05<00:16,  5.88it/s, est. speed input: 5334.18 toks/s, output: 5.21 toks/s]
Processed prompts:  25%|       | 32/128 [00:06<00:16,  5.88it/s, est. speed input: 5353.22 toks/s, output: 5.23 toks/s]
Processed prompts:  26%|       | 33/128 [00:06<00:16,  5.88it/s, est. speed input: 5371.09 toks/s, output: 5.25 toks/s]
Processed prompts:  27%|       | 34/128 [00:06<00:15,  5.90it/s, est. speed input: 5389.94 toks/s, output: 5.26 toks/s]
Processed prompts:  27%|       | 35/128 [00:06<00:15,  5.86it/s, est. speed input: 5403.72 toks/s, output: 5.28 toks/s]
Processed prompts:  28%|       | 36/128 [00:06<00:15,  5.89it/s, est. speed input: 5420.49 toks/s, output: 5.29 toks/s]
Processed prompts:  29%|       | 37/128 [00:06<00:15,  5.85it/s, est. speed input: 5432.56 toks/s, output: 5.31 toks/s]
Processed prompts:  30%|       | 38/128 [00:07<00:15,  5.87it/s, est. speed input: 5447.44 toks/s, output: 5.32 toks/s]
Processed prompts:  30%|       | 39/128 [00:07<00:15,  5.90it/s, est. speed input: 5462.88 toks/s, output: 5.33 toks/s]
Processed prompts:  31%|      | 40/128 [00:07<00:14,  5.91it/s, est. speed input: 5476.30 toks/s, output: 5.35 toks/s]
Processed prompts:  32%|      | 41/128 [00:07<00:14,  5.92it/s, est. speed input: 5490.20 toks/s, output: 5.36 toks/s]
Processed prompts:  33%|      | 42/128 [00:07<00:14,  5.92it/s, est. speed input: 5502.52 toks/s, output: 5.37 toks/s]
Processed prompts:  34%|      | 43/128 [00:07<00:14,  5.90it/s, est. speed input: 5513.11 toks/s, output: 5.38 toks/s]
Processed prompts:  34%|      | 44/128 [00:08<00:14,  5.83it/s, est. speed input: 5519.27 toks/s, output: 5.39 toks/s]
Processed prompts:  35%|      | 45/128 [00:08<00:14,  5.86it/s, est. speed input: 5530.61 toks/s, output: 5.40 toks/s]
Processed prompts:  36%|      | 46/128 [00:08<00:13,  5.87it/s, est. speed input: 5540.33 toks/s, output: 5.41 toks/s]
Processed prompts:  37%|      | 47/128 [00:08<00:13,  5.84it/s, est. speed input: 5547.97 toks/s, output: 5.42 toks/s]
Processed prompts:  38%|      | 48/128 [00:08<00:13,  5.84it/s, est. speed input: 5556.21 toks/s, output: 5.43 toks/s]
Processed prompts:  38%|      | 49/128 [00:09<00:13,  5.83it/s, est. speed input: 5563.89 toks/s, output: 5.43 toks/s]
Processed prompts:  39%|      | 50/128 [00:09<00:13,  5.80it/s, est. speed input: 5569.58 toks/s, output: 5.44 toks/s]
Processed prompts:  40%|      | 51/128 [00:09<00:13,  5.83it/s, est. speed input: 5577.92 toks/s, output: 5.45 toks/s]
Processed prompts:  41%|      | 52/128 [00:09<00:13,  5.82it/s, est. speed input: 5584.65 toks/s, output: 5.45 toks/s]
Processed prompts:  41%|     | 53/128 [00:09<00:12,  5.83it/s, est. speed input: 5591.90 toks/s, output: 5.46 toks/s]
Processed prompts:  42%|     | 54/128 [00:09<00:12,  5.88it/s, est. speed input: 5601.12 toks/s, output: 5.47 toks/s]
Processed prompts:  43%|     | 55/128 [00:10<00:12,  5.87it/s, est. speed input: 5607.45 toks/s, output: 5.48 toks/s]
Processed prompts:  44%|     | 56/128 [00:10<00:12,  5.81it/s, est. speed input: 5610.94 toks/s, output: 5.48 toks/s]
Processed prompts:  45%|     | 57/128 [00:10<00:12,  5.83it/s, est. speed input: 5617.67 toks/s, output: 5.49 toks/s]
Processed prompts:  45%|     | 58/128 [00:10<00:11,  5.86it/s, est. speed input: 5624.82 toks/s, output: 5.49 toks/s]
Processed prompts:  46%|     | 59/128 [00:10<00:11,  5.85it/s, est. speed input: 5630.50 toks/s, output: 5.50 toks/s]
Processed prompts:  47%|     | 60/128 [00:10<00:11,  5.90it/s, est. speed input: 5638.45 toks/s, output: 5.51 toks/s]
Processed prompts:  48%|     | 61/128 [00:11<00:11,  5.87it/s, est. speed input: 5643.02 toks/s, output: 5.51 toks/s]
Processed prompts:  48%|     | 62/128 [00:11<00:11,  5.80it/s, est. speed input: 5645.46 toks/s, output: 5.51 toks/s]
Processed prompts:  49%|     | 63/128 [00:11<00:11,  5.81it/s, est. speed input: 5650.07 toks/s, output: 5.52 toks/s]
Processed prompts:  50%|     | 64/128 [00:11<00:11,  5.81it/s, est. speed input: 5654.47 toks/s, output: 5.52 toks/s]
Processed prompts:  51%|     | 65/128 [00:11<00:10,  5.83it/s, est. speed input: 5659.69 toks/s, output: 5.53 toks/s]
Processed prompts:  52%|    | 66/128 [00:11<00:10,  5.84it/s, est. speed input: 5664.78 toks/s, output: 5.53 toks/s]
Processed prompts:  52%|    | 67/128 [00:12<00:10,  5.84it/s, est. speed input: 5669.15 toks/s, output: 5.54 toks/s]
Processed prompts:  53%|    | 68/128 [00:12<00:10,  5.82it/s, est. speed input: 5672.51 toks/s, output: 5.54 toks/s]
Processed prompts:  54%|    | 69/128 [00:12<00:10,  5.85it/s, est. speed input: 5677.82 toks/s, output: 5.54 toks/s]
Processed prompts:  55%|    | 70/128 [00:12<00:09,  5.89it/s, est. speed input: 5683.73 toks/s, output: 5.55 toks/s]
Processed prompts:  55%|    | 71/128 [00:12<00:09,  5.91it/s, est. speed input: 5689.20 toks/s, output: 5.56 toks/s]
Processed prompts:  56%|    | 72/128 [00:12<00:09,  5.89it/s, est. speed input: 5693.02 toks/s, output: 5.56 toks/s]
Processed prompts:  57%|    | 73/128 [00:13<00:09,  5.88it/s, est. speed input: 5697.01 toks/s, output: 5.56 toks/s]
Processed prompts:  58%|    | 74/128 [00:13<00:09,  5.82it/s, est. speed input: 5698.57 toks/s, output: 5.57 toks/s]
Processed prompts:  59%|    | 75/128 [00:13<00:09,  5.81it/s, est. speed input: 5701.58 toks/s, output: 5.57 toks/s]
Processed prompts:  59%|    | 76/128 [00:13<00:08,  5.82it/s, est. speed input: 5705.08 toks/s, output: 5.57 toks/s]
Processed prompts:  60%|    | 77/128 [00:13<00:08,  5.81it/s, est. speed input: 5707.70 toks/s, output: 5.57 toks/s]
Processed prompts:  61%|    | 78/128 [00:13<00:08,  5.80it/s, est. speed input: 5710.39 toks/s, output: 5.58 toks/s]
Processed prompts:  62%|   | 79/128 [00:14<00:08,  5.85it/s, est. speed input: 5715.12 toks/s, output: 5.58 toks/s]
Processed prompts:  62%|   | 80/128 [00:14<00:08,  5.79it/s, est. speed input: 5715.97 toks/s, output: 5.58 toks/s]
Processed prompts:  63%|   | 81/128 [00:14<00:08,  5.81it/s, est. speed input: 5719.49 toks/s, output: 5.59 toks/s]
Processed prompts:  64%|   | 82/128 [00:14<00:07,  5.84it/s, est. speed input: 5723.33 toks/s, output: 5.59 toks/s]
Processed prompts:  65%|   | 83/128 [00:14<00:07,  5.86it/s, est. speed input: 5726.96 toks/s, output: 5.59 toks/s]
Processed prompts:  66%|   | 84/128 [00:15<00:07,  5.87it/s, est. speed input: 5730.57 toks/s, output: 5.60 toks/s]
Processed prompts:  66%|   | 85/128 [00:15<00:07,  5.84it/s, est. speed input: 5732.59 toks/s, output: 5.60 toks/s]
Processed prompts:  67%|   | 86/128 [00:15<00:07,  5.81it/s, est. speed input: 5734.18 toks/s, output: 5.60 toks/s]
Processed prompts:  68%|   | 87/128 [00:15<00:07,  5.78it/s, est. speed input: 5735.44 toks/s, output: 5.60 toks/s]
Processed prompts:  69%|   | 88/128 [00:15<00:06,  5.80it/s, est. speed input: 5738.07 toks/s, output: 5.60 toks/s]
Processed prompts:  70%|   | 89/128 [00:15<00:06,  5.81it/s, est. speed input: 5740.59 toks/s, output: 5.61 toks/s]
Processed prompts:  70%|   | 90/128 [00:16<00:06,  5.82it/s, est. speed input: 5743.24 toks/s, output: 5.61 toks/s]
Processed prompts:  71%|   | 91/128 [00:16<00:06,  5.83it/s, est. speed input: 5745.92 toks/s, output: 5.61 toks/s]
Processed prompts:  72%|  | 92/128 [00:16<00:06,  5.88it/s, est. speed input: 5749.81 toks/s, output: 5.62 toks/s]
Processed prompts:  73%|  | 93/128 [00:16<00:06,  5.78it/s, est. speed input: 5749.41 toks/s, output: 5.61 toks/s]
Processed prompts:  73%|  | 94/128 [00:16<00:05,  5.81it/s, est. speed input: 5752.06 toks/s, output: 5.62 toks/s]
Processed prompts:  74%|  | 95/128 [00:16<00:05,  5.82it/s, est. speed input: 5754.34 toks/s, output: 5.62 toks/s]
Processed prompts:  75%|  | 96/128 [00:17<00:05,  5.81it/s, est. speed input: 5756.28 toks/s, output: 5.62 toks/s]
Processed prompts:  76%|  | 97/128 [00:17<00:05,  5.82it/s, est. speed input: 5758.29 toks/s, output: 5.62 toks/s]
Processed prompts:  77%|  | 98/128 [00:17<00:05,  5.83it/s, est. speed input: 5760.86 toks/s, output: 5.63 toks/s]
Processed prompts:  77%|  | 99/128 [00:17<00:05,  5.77it/s, est. speed input: 5760.89 toks/s, output: 5.63 toks/s]
Processed prompts:  78%|  | 100/128 [00:17<00:04,  5.78it/s, est. speed input: 5762.72 toks/s, output: 5.63 toks/s]
Processed prompts:  79%|  | 101/128 [00:17<00:04,  5.80it/s, est. speed input: 5764.95 toks/s, output: 5.63 toks/s]
Processed prompts:  80%|  | 102/128 [00:18<00:04,  5.82it/s, est. speed input: 5767.09 toks/s, output: 5.63 toks/s]
Processed prompts:  80%|  | 103/128 [00:18<00:04,  5.85it/s, est. speed input: 5769.91 toks/s, output: 5.63 toks/s]
Processed prompts:  81%| | 104/128 [00:18<00:04,  5.85it/s, est. speed input: 5771.99 toks/s, output: 5.64 toks/s]
Processed prompts:  82%| | 105/128 [00:18<00:03,  5.84it/s, est. speed input: 5773.63 toks/s, output: 5.64 toks/s]
Processed prompts:  83%| | 106/128 [00:18<00:03,  5.85it/s, est. speed input: 5775.84 toks/s, output: 5.64 toks/s]
Processed prompts:  84%| | 107/128 [00:18<00:03,  5.85it/s, est. speed input: 5777.81 toks/s, output: 5.64 toks/s]
Processed prompts:  84%| | 108/128 [00:19<00:03,  5.82it/s, est. speed input: 5778.80 toks/s, output: 5.64 toks/s]
Processed prompts:  85%| | 109/128 [00:19<00:03,  5.85it/s, est. speed input: 5781.29 toks/s, output: 5.65 toks/s]
Processed prompts:  86%| | 110/128 [00:19<00:03,  5.83it/s, est. speed input: 5782.60 toks/s, output: 5.65 toks/s]
Processed prompts:  87%| | 111/128 [00:19<00:02,  5.76it/s, est. speed input: 5782.27 toks/s, output: 5.65 toks/s]
Processed prompts:  88%| | 112/128 [00:19<00:02,  5.77it/s, est. speed input: 5783.50 toks/s, output: 5.65 toks/s]
Processed prompts:  88%| | 113/128 [00:20<00:02,  5.78it/s, est. speed input: 5784.74 toks/s, output: 5.65 toks/s]
Processed prompts:  89%| | 114/128 [00:20<00:02,  5.81it/s, est. speed input: 5786.83 toks/s, output: 5.65 toks/s]
Processed prompts:  90%| | 115/128 [00:20<00:02,  5.86it/s, est. speed input: 5789.53 toks/s, output: 5.65 toks/s]
Processed prompts:  91%| | 116/128 [00:20<00:02,  5.86it/s, est. speed input: 5791.45 toks/s, output: 5.66 toks/s]
Processed prompts:  91%|| 117/128 [00:20<00:01,  5.82it/s, est. speed input: 5792.00 toks/s, output: 5.66 toks/s]
Processed prompts:  92%|| 118/128 [00:20<00:01,  5.81it/s, est. speed input: 5792.99 toks/s, output: 5.66 toks/s]
Processed prompts:  93%|| 119/128 [00:21<00:01,  5.81it/s, est. speed input: 5794.31 toks/s, output: 5.66 toks/s]
Processed prompts:  94%|| 120/128 [00:21<00:01,  5.83it/s, est. speed input: 5796.17 toks/s, output: 5.66 toks/s]
Processed prompts:  95%|| 121/128 [00:21<00:01,  5.84it/s, est. speed input: 5797.80 toks/s, output: 5.66 toks/s]
Processed prompts:  95%|| 122/128 [00:21<00:01,  5.82it/s, est. speed input: 5798.68 toks/s, output: 5.66 toks/s]
Processed prompts:  96%|| 123/128 [00:21<00:00,  5.77it/s, est. speed input: 5798.73 toks/s, output: 5.66 toks/s]
Processed prompts:  97%|| 124/128 [00:21<00:00,  5.83it/s, est. speed input: 5801.19 toks/s, output: 5.67 toks/s]
Processed prompts:  98%|| 125/128 [00:22<00:00,  5.84it/s, est. speed input: 5802.71 toks/s, output: 5.67 toks/s]
Processed prompts:  98%|| 126/128 [00:22<00:00,  5.83it/s, est. speed input: 5803.70 toks/s, output: 5.67 toks/s]
Processed prompts:  99%|| 127/128 [00:22<00:00,  5.86it/s, est. speed input: 5805.70 toks/s, output: 5.67 toks/s]
Processed prompts: 100%|| 128/128 [00:22<00:00,  5.85it/s, est. speed input: 5807.01 toks/s, output: 5.67 toks/s]
Processed prompts: 100%|| 128/128 [00:22<00:00,  5.85it/s, est. speed input: 5807.01 toks/s, output: 5.67 toks/s]
Processed prompts: 100%|| 128/128 [00:22<00:00,  5.67it/s, est. speed input: 5807.01 toks/s, output: 5.67 toks/s]
[rank0]:[W126 16:32:22.126137982 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 16:32:25
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 16:32:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 16:32:31 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1499882) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1499882) WARNING 01-26 16:33:52 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.89 requests/s, 6032.60 total tokens/s, 5.89 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 16:32:31] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:32:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:32:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:32:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:32:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:32:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:32:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:32:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:32:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:32:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:32:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:32:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:32:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:32:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 16:32:35] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:32:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:32:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:32:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:32:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:32:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:32:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:32:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:32:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:32:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:32:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:32:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:32:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:32:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1499882) [2026-01-26 16:32:36] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1499882) [2026-01-26 16:32:36] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1499882) [2026-01-26 16:32:36] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1499882) [2026-01-26 16:32:36] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1499882) [2026-01-26 16:32:36] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1499882) [2026-01-26 16:32:36] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1499882) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1499882) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.91s/it]
(EngineCore_DP0 pid=1499882) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:05<00:00, 33.62s/it]
(EngineCore_DP0 pid=1499882) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:05<00:00, 32.92s/it]
(EngineCore_DP0 pid=1499882) 
(EngineCore_DP0 pid=1499882) [2026-01-26 16:33:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1499882) [2026-01-26 16:33:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=1499882) [2026-01-26 16:33:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1499882) [2026-01-26 16:33:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=1499882) [2026-01-26 16:33:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1499882) [2026-01-26 16:33:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=1499882) [2026-01-26 16:33:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1499882) [2026-01-26 16:33:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=1499882) 2026-01-26 16:33:51,125 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1499882) 2026-01-26 16:33:51,163 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  12%|        | 32/256 [00:00<00:00, 318.94it/s]
Adding requests:  27%|       | 70/256 [00:00<00:00, 353.00it/s]
Adding requests:  44%|     | 112/256 [00:00<00:00, 378.44it/s]
Adding requests:  60%|    | 153/256 [00:00<00:00, 389.94it/s]
Adding requests:  78%|  | 199/256 [00:00<00:00, 413.93it/s]
Adding requests:  95%|| 242/256 [00:00<00:00, 414.62it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 398.12it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 4/256 [00:00<00:19, 12.67it/s, est. speed input: 12971.55 toks/s, output: 12.67 toks/s]
Processed prompts:   2%|         | 6/256 [00:00<00:29,  8.62it/s, est. speed input: 9425.88 toks/s, output: 9.20 toks/s]  
Processed prompts:   3%|         | 8/256 [00:00<00:33,  7.36it/s, est. speed input: 8271.96 toks/s, output: 8.08 toks/s]
Processed prompts:   4%|         | 10/256 [00:01<00:36,  6.79it/s, est. speed input: 7712.49 toks/s, output: 7.53 toks/s]
Processed prompts:   5%|         | 12/256 [00:01<00:37,  6.46it/s, est. speed input: 7369.43 toks/s, output: 7.20 toks/s]
Processed prompts:   5%|         | 14/256 [00:02<00:38,  6.29it/s, est. speed input: 7158.76 toks/s, output: 6.99 toks/s]
Processed prompts:   6%|         | 16/256 [00:02<00:38,  6.19it/s, est. speed input: 7011.61 toks/s, output: 6.85 toks/s]
Processed prompts:   7%|         | 18/256 [00:02<00:39,  6.08it/s, est. speed input: 6882.25 toks/s, output: 6.72 toks/s]
Processed prompts:   8%|         | 20/256 [00:03<00:39,  6.04it/s, est. speed input: 6791.94 toks/s, output: 6.63 toks/s]
Processed prompts:   9%|         | 22/256 [00:03<00:38,  6.01it/s, est. speed input: 6721.20 toks/s, output: 6.56 toks/s]
Processed prompts:   9%|         | 24/256 [00:03<00:38,  5.96it/s, est. speed input: 6655.30 toks/s, output: 6.50 toks/s]
Processed prompts:  10%|         | 26/256 [00:04<00:38,  5.96it/s, est. speed input: 6608.10 toks/s, output: 6.45 toks/s]
Processed prompts:  11%|         | 28/256 [00:04<00:38,  5.95it/s, est. speed input: 6566.19 toks/s, output: 6.41 toks/s]
Processed prompts:  12%|        | 30/256 [00:04<00:38,  5.90it/s, est. speed input: 6519.82 toks/s, output: 6.37 toks/s]
Processed prompts:  12%|        | 32/256 [00:05<00:37,  5.90it/s, est. speed input: 6488.25 toks/s, output: 6.34 toks/s]
Processed prompts:  13%|        | 34/256 [00:05<00:37,  5.91it/s, est. speed input: 6461.17 toks/s, output: 6.31 toks/s]
Processed prompts:  14%|        | 36/256 [00:05<00:37,  5.88it/s, est. speed input: 6431.35 toks/s, output: 6.28 toks/s]
Processed prompts:  15%|        | 38/256 [00:06<00:37,  5.89it/s, est. speed input: 6410.18 toks/s, output: 6.26 toks/s]
Processed prompts:  16%|        | 40/256 [00:06<00:36,  5.91it/s, est. speed input: 6393.26 toks/s, output: 6.24 toks/s]
Processed prompts:  16%|        | 42/256 [00:06<00:36,  5.88it/s, est. speed input: 6371.76 toks/s, output: 6.22 toks/s]
Processed prompts:  17%|        | 44/256 [00:07<00:35,  5.90it/s, est. speed input: 6358.14 toks/s, output: 6.21 toks/s]
Processed prompts:  18%|        | 46/256 [00:07<00:35,  5.90it/s, est. speed input: 6343.82 toks/s, output: 6.20 toks/s]
Processed prompts:  19%|        | 48/256 [00:07<00:35,  5.87it/s, est. speed input: 6325.63 toks/s, output: 6.18 toks/s]
Processed prompts:  20%|        | 50/256 [00:08<00:34,  5.89it/s, est. speed input: 6315.32 toks/s, output: 6.17 toks/s]
Processed prompts:  20%|        | 52/256 [00:08<00:34,  5.91it/s, est. speed input: 6306.55 toks/s, output: 6.16 toks/s]
Processed prompts:  21%|        | 54/256 [00:08<00:34,  5.89it/s, est. speed input: 6293.97 toks/s, output: 6.15 toks/s]
Processed prompts:  22%|       | 56/256 [00:09<00:33,  5.91it/s, est. speed input: 6287.01 toks/s, output: 6.14 toks/s]
Processed prompts:  23%|       | 58/256 [00:09<00:33,  5.90it/s, est. speed input: 6277.50 toks/s, output: 6.13 toks/s]
Processed prompts:  23%|       | 60/256 [00:09<00:33,  5.89it/s, est. speed input: 6268.55 toks/s, output: 6.12 toks/s]
Processed prompts:  24%|       | 62/256 [00:10<00:32,  5.90it/s, est. speed input: 6261.88 toks/s, output: 6.12 toks/s]
Processed prompts:  25%|       | 64/256 [00:10<00:32,  5.90it/s, est. speed input: 6254.53 toks/s, output: 6.11 toks/s]
Processed prompts:  26%|       | 66/256 [00:10<00:32,  5.88it/s, est. speed input: 6245.63 toks/s, output: 6.10 toks/s]
Processed prompts:  27%|       | 68/256 [00:11<00:31,  5.89it/s, est. speed input: 6240.22 toks/s, output: 6.09 toks/s]
Processed prompts:  27%|       | 70/256 [00:11<00:31,  5.91it/s, est. speed input: 6236.13 toks/s, output: 6.09 toks/s]
Processed prompts:  28%|       | 72/256 [00:11<00:31,  5.90it/s, est. speed input: 6230.07 toks/s, output: 6.08 toks/s]
Processed prompts:  29%|       | 74/256 [00:12<00:30,  5.88it/s, est. speed input: 6222.84 toks/s, output: 6.08 toks/s]
Processed prompts:  30%|       | 76/256 [00:12<00:30,  5.89it/s, est. speed input: 6217.93 toks/s, output: 6.07 toks/s]
Processed prompts:  30%|       | 78/256 [00:12<00:30,  5.89it/s, est. speed input: 6213.14 toks/s, output: 6.07 toks/s]
Processed prompts:  31%|      | 80/256 [00:13<00:29,  5.87it/s, est. speed input: 6206.90 toks/s, output: 6.06 toks/s]
Processed prompts:  32%|      | 82/256 [00:13<00:29,  5.88it/s, est. speed input: 6202.50 toks/s, output: 6.06 toks/s]
Processed prompts:  33%|      | 84/256 [00:13<00:29,  5.89it/s, est. speed input: 6199.00 toks/s, output: 6.05 toks/s]
Processed prompts:  34%|      | 86/256 [00:14<00:28,  5.87it/s, est. speed input: 6193.17 toks/s, output: 6.05 toks/s]
Processed prompts:  34%|      | 88/256 [00:14<00:28,  5.88it/s, est. speed input: 6190.14 toks/s, output: 6.05 toks/s]
Processed prompts:  35%|      | 90/256 [00:14<00:28,  5.90it/s, est. speed input: 6187.93 toks/s, output: 6.04 toks/s]
Processed prompts:  36%|      | 92/256 [00:15<00:27,  5.87it/s, est. speed input: 6182.05 toks/s, output: 6.04 toks/s]
Processed prompts:  37%|      | 94/256 [00:15<00:27,  5.88it/s, est. speed input: 6179.03 toks/s, output: 6.03 toks/s]
Processed prompts:  38%|      | 96/256 [00:15<00:27,  5.89it/s, est. speed input: 6176.32 toks/s, output: 6.03 toks/s]
Processed prompts:  38%|      | 98/256 [00:16<00:26,  5.86it/s, est. speed input: 6170.94 toks/s, output: 6.03 toks/s]
Processed prompts:  39%|      | 100/256 [00:16<00:26,  5.86it/s, est. speed input: 6167.34 toks/s, output: 6.02 toks/s]
Processed prompts:  40%|      | 102/256 [00:16<00:26,  5.87it/s, est. speed input: 6165.10 toks/s, output: 6.02 toks/s]
Processed prompts:  41%|      | 104/256 [00:17<00:25,  5.86it/s, est. speed input: 6161.23 toks/s, output: 6.02 toks/s]
Processed prompts:  41%|     | 106/256 [00:17<00:25,  5.88it/s, est. speed input: 6159.33 toks/s, output: 6.01 toks/s]
Processed prompts:  42%|     | 108/256 [00:17<00:25,  5.89it/s, est. speed input: 6157.37 toks/s, output: 6.01 toks/s]
Processed prompts:  43%|     | 110/256 [00:18<00:24,  5.86it/s, est. speed input: 6153.28 toks/s, output: 6.01 toks/s]
Processed prompts:  44%|     | 112/256 [00:18<00:24,  5.88it/s, est. speed input: 6151.54 toks/s, output: 6.01 toks/s]
Processed prompts:  45%|     | 114/256 [00:18<00:24,  5.89it/s, est. speed input: 6149.70 toks/s, output: 6.01 toks/s]
Processed prompts:  45%|     | 116/256 [00:19<00:23,  5.86it/s, est. speed input: 6146.08 toks/s, output: 6.00 toks/s]
Processed prompts:  46%|     | 118/256 [00:19<00:23,  5.88it/s, est. speed input: 6144.50 toks/s, output: 6.00 toks/s]
Processed prompts:  47%|     | 120/256 [00:20<00:23,  5.88it/s, est. speed input: 6142.27 toks/s, output: 6.00 toks/s]
Processed prompts:  48%|     | 122/256 [00:20<00:22,  5.87it/s, est. speed input: 6139.62 toks/s, output: 6.00 toks/s]
Processed prompts:  48%|     | 124/256 [00:20<00:22,  5.87it/s, est. speed input: 6137.58 toks/s, output: 5.99 toks/s]
Processed prompts:  49%|     | 126/256 [00:21<00:22,  5.88it/s, est. speed input: 6136.13 toks/s, output: 5.99 toks/s]
Processed prompts:  50%|     | 128/256 [00:21<00:21,  5.88it/s, est. speed input: 6134.49 toks/s, output: 5.99 toks/s]
Processed prompts:  51%|     | 130/256 [00:21<00:21,  5.89it/s, est. speed input: 6132.96 toks/s, output: 5.99 toks/s]
Processed prompts:  52%|    | 132/256 [00:22<00:21,  5.89it/s, est. speed input: 6131.49 toks/s, output: 5.99 toks/s]
Processed prompts:  52%|    | 134/256 [00:22<00:20,  5.90it/s, est. speed input: 6130.70 toks/s, output: 5.99 toks/s]
Processed prompts:  53%|    | 136/256 [00:22<00:20,  5.88it/s, est. speed input: 6128.03 toks/s, output: 5.98 toks/s]
Processed prompts:  54%|    | 138/256 [00:23<00:20,  5.88it/s, est. speed input: 6126.38 toks/s, output: 5.98 toks/s]
Processed prompts:  55%|    | 140/256 [00:23<00:19,  5.90it/s, est. speed input: 6126.08 toks/s, output: 5.98 toks/s]
Processed prompts:  55%|    | 142/256 [00:23<00:19,  5.88it/s, est. speed input: 6123.91 toks/s, output: 5.98 toks/s]
Processed prompts:  56%|    | 144/256 [00:24<00:19,  5.89it/s, est. speed input: 6122.90 toks/s, output: 5.98 toks/s]
Processed prompts:  57%|    | 146/256 [00:24<00:18,  5.89it/s, est. speed input: 6121.43 toks/s, output: 5.98 toks/s]
Processed prompts:  58%|    | 148/256 [00:24<00:18,  5.88it/s, est. speed input: 6119.74 toks/s, output: 5.98 toks/s]
Processed prompts:  59%|    | 150/256 [00:25<00:18,  5.87it/s, est. speed input: 6118.12 toks/s, output: 5.97 toks/s]
Processed prompts:  59%|    | 152/256 [00:25<00:17,  5.88it/s, est. speed input: 6117.19 toks/s, output: 5.97 toks/s]
Processed prompts:  60%|    | 154/256 [00:25<00:17,  5.86it/s, est. speed input: 6114.95 toks/s, output: 5.97 toks/s]
Processed prompts:  61%|    | 156/256 [00:26<00:17,  5.86it/s, est. speed input: 6113.57 toks/s, output: 5.97 toks/s]
Processed prompts:  62%|   | 158/256 [00:26<00:16,  5.87it/s, est. speed input: 6112.38 toks/s, output: 5.97 toks/s]
Processed prompts:  62%|   | 160/256 [00:26<00:16,  5.86it/s, est. speed input: 6110.80 toks/s, output: 5.97 toks/s]
Processed prompts:  63%|   | 162/256 [00:27<00:16,  5.87it/s, est. speed input: 6109.75 toks/s, output: 5.97 toks/s]
Processed prompts:  64%|   | 164/256 [00:27<00:15,  5.87it/s, est. speed input: 6108.74 toks/s, output: 5.97 toks/s]
Processed prompts:  65%|   | 166/256 [00:27<00:15,  5.86it/s, est. speed input: 6106.91 toks/s, output: 5.96 toks/s]
Processed prompts:  66%|   | 168/256 [00:28<00:15,  5.85it/s, est. speed input: 6105.39 toks/s, output: 5.96 toks/s]
Processed prompts:  66%|   | 170/256 [00:28<00:14,  5.87it/s, est. speed input: 6104.64 toks/s, output: 5.96 toks/s]
Processed prompts:  67%|   | 172/256 [00:28<00:14,  5.85it/s, est. speed input: 6102.73 toks/s, output: 5.96 toks/s]
Processed prompts:  68%|   | 174/256 [00:29<00:13,  5.86it/s, est. speed input: 6101.84 toks/s, output: 5.96 toks/s]
Processed prompts:  69%|   | 176/256 [00:29<00:13,  5.89it/s, est. speed input: 6101.83 toks/s, output: 5.96 toks/s]
Processed prompts:  70%|   | 178/256 [00:29<00:13,  5.87it/s, est. speed input: 6100.21 toks/s, output: 5.96 toks/s]
Processed prompts:  70%|   | 180/256 [00:30<00:12,  5.88it/s, est. speed input: 6099.69 toks/s, output: 5.96 toks/s]
Processed prompts:  71%|   | 182/256 [00:30<00:12,  5.90it/s, est. speed input: 6099.67 toks/s, output: 5.96 toks/s]
Processed prompts:  72%|  | 184/256 [00:30<00:12,  5.88it/s, est. speed input: 6098.31 toks/s, output: 5.96 toks/s]
Processed prompts:  73%|  | 186/256 [00:31<00:11,  5.88it/s, est. speed input: 6097.39 toks/s, output: 5.95 toks/s]
Processed prompts:  73%|  | 188/256 [00:31<00:11,  5.89it/s, est. speed input: 6097.04 toks/s, output: 5.95 toks/s]
Processed prompts:  74%|  | 190/256 [00:31<00:11,  5.87it/s, est. speed input: 6095.62 toks/s, output: 5.95 toks/s]
Processed prompts:  75%|  | 192/256 [00:32<00:10,  5.88it/s, est. speed input: 6095.10 toks/s, output: 5.95 toks/s]
Processed prompts:  76%|  | 194/256 [00:32<00:10,  5.88it/s, est. speed input: 6094.19 toks/s, output: 5.95 toks/s]
Processed prompts:  77%|  | 196/256 [00:32<00:10,  5.87it/s, est. speed input: 6092.99 toks/s, output: 5.95 toks/s]
Processed prompts:  77%|  | 198/256 [00:33<00:09,  5.85it/s, est. speed input: 6091.38 toks/s, output: 5.95 toks/s]
Processed prompts:  78%|  | 200/256 [00:33<00:09,  5.87it/s, est. speed input: 6091.16 toks/s, output: 5.95 toks/s]
Processed prompts:  79%|  | 202/256 [00:33<00:08,  6.66it/s, est. speed input: 6114.68 toks/s, output: 5.97 toks/s]
Processed prompts:  80%|  | 204/256 [00:34<00:08,  6.39it/s, est. speed input: 6113.14 toks/s, output: 5.97 toks/s]
Processed prompts:  80%|  | 206/256 [00:34<00:08,  6.22it/s, est. speed input: 6112.18 toks/s, output: 5.97 toks/s]
Processed prompts:  81%| | 208/256 [00:34<00:07,  6.13it/s, est. speed input: 6111.64 toks/s, output: 5.97 toks/s]
Processed prompts:  82%| | 210/256 [00:35<00:07,  6.01it/s, est. speed input: 6109.55 toks/s, output: 5.97 toks/s]
Processed prompts:  83%| | 212/256 [00:35<00:07,  5.98it/s, est. speed input: 6108.90 toks/s, output: 5.97 toks/s]
Processed prompts:  84%| | 214/256 [00:35<00:07,  5.96it/s, est. speed input: 6108.58 toks/s, output: 5.97 toks/s]
Processed prompts:  84%| | 216/256 [00:36<00:06,  5.91it/s, est. speed input: 6106.83 toks/s, output: 5.96 toks/s]
Processed prompts:  85%| | 218/256 [00:36<00:06,  5.91it/s, est. speed input: 6106.28 toks/s, output: 5.96 toks/s]
Processed prompts:  86%| | 220/256 [00:36<00:06,  5.91it/s, est. speed input: 6105.96 toks/s, output: 5.96 toks/s]
Processed prompts:  87%| | 222/256 [00:37<00:05,  5.88it/s, est. speed input: 6104.53 toks/s, output: 5.96 toks/s]
Processed prompts:  88%| | 224/256 [00:37<00:05,  5.91it/s, est. speed input: 6104.58 toks/s, output: 5.96 toks/s]
Processed prompts:  88%| | 226/256 [00:37<00:05,  5.91it/s, est. speed input: 6104.09 toks/s, output: 5.96 toks/s]
Processed prompts:  89%| | 228/256 [00:38<00:04,  5.89it/s, est. speed input: 6102.91 toks/s, output: 5.96 toks/s]
Processed prompts:  90%| | 230/256 [00:38<00:04,  5.89it/s, est. speed input: 6102.35 toks/s, output: 5.96 toks/s]
Processed prompts:  91%| | 232/256 [00:38<00:04,  5.90it/s, est. speed input: 6101.95 toks/s, output: 5.96 toks/s]
Processed prompts:  91%|| 234/256 [00:39<00:03,  5.88it/s, est. speed input: 6100.90 toks/s, output: 5.96 toks/s]
Processed prompts:  92%|| 236/256 [00:39<00:03,  5.87it/s, est. speed input: 6099.90 toks/s, output: 5.96 toks/s]
Processed prompts:  93%|| 238/256 [00:39<00:03,  5.89it/s, est. speed input: 6099.71 toks/s, output: 5.96 toks/s]
Processed prompts:  94%|| 240/256 [00:40<00:02,  5.91it/s, est. speed input: 6099.68 toks/s, output: 5.96 toks/s]
Processed prompts:  95%|| 242/256 [00:40<00:02,  5.88it/s, est. speed input: 6098.49 toks/s, output: 5.96 toks/s]
Processed prompts:  95%|| 244/256 [00:40<00:02,  5.89it/s, est. speed input: 6098.16 toks/s, output: 5.96 toks/s]
Processed prompts:  96%|| 246/256 [00:41<00:01,  5.89it/s, est. speed input: 6097.45 toks/s, output: 5.95 toks/s]
Processed prompts:  97%|| 248/256 [00:41<00:01,  5.85it/s, est. speed input: 6095.88 toks/s, output: 5.95 toks/s]
Processed prompts:  98%|| 250/256 [00:41<00:01,  5.86it/s, est. speed input: 6095.40 toks/s, output: 5.95 toks/s]
Processed prompts:  98%|| 252/256 [00:42<00:00,  5.88it/s, est. speed input: 6095.13 toks/s, output: 5.95 toks/s]
Processed prompts:  99%|| 254/256 [00:42<00:00,  5.85it/s, est. speed input: 6093.69 toks/s, output: 5.95 toks/s]
Processed prompts: 100%|| 256/256 [00:42<00:00,  6.89it/s, est. speed input: 6117.37 toks/s, output: 5.97 toks/s]
Processed prompts: 100%|| 256/256 [00:42<00:00,  6.89it/s, est. speed input: 6117.37 toks/s, output: 5.97 toks/s]
Processed prompts: 100%|| 256/256 [00:42<00:00,  5.97it/s, est. speed input: 6117.37 toks/s, output: 5.97 toks/s]
[rank0]:[W126 16:34:35.966481665 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 16:34:38
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 16:34:45 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 16:34:46 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1501943) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1501943) WARNING 01-26 16:36:07 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.78 requests/s, 5926.08 total tokens/s, 5.78 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 16:34:45] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:34:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:34:45] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:34:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:34:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:34:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:34:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:34:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:34:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:34:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:34:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:34:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:34:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:34:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 16:34:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:34:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:34:49] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:34:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:34:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:34:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:34:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:34:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:34:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:34:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:34:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:34:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:34:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:34:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1501943) [2026-01-26 16:34:50] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1501943) [2026-01-26 16:34:50] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1501943) [2026-01-26 16:34:50] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1501943) [2026-01-26 16:34:50] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1501943) [2026-01-26 16:34:50] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1501943) [2026-01-26 16:34:50] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1501943) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1501943) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.68s/it]
(EngineCore_DP0 pid=1501943) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:06<00:00, 34.21s/it]
(EngineCore_DP0 pid=1501943) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:06<00:00, 33.38s/it]
(EngineCore_DP0 pid=1501943) 
(EngineCore_DP0 pid=1501943) [2026-01-26 16:35:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1501943) [2026-01-26 16:35:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=1501943) [2026-01-26 16:35:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1501943) [2026-01-26 16:35:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=1501943) [2026-01-26 16:35:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1501943) [2026-01-26 16:35:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=1501943) [2026-01-26 16:35:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1501943) [2026-01-26 16:35:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=1501943) 2026-01-26 16:36:06,431 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1501943) 2026-01-26 16:36:06,516 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   9%|         | 44/512 [00:00<00:01, 432.08it/s]
Adding requests:  17%|        | 88/512 [00:00<00:01, 408.47it/s]
Adding requests:  26%|       | 131/512 [00:00<00:00, 417.00it/s]
Adding requests:  34%|      | 176/512 [00:00<00:00, 426.70it/s]
Adding requests:  44%|     | 223/512 [00:00<00:00, 439.46it/s]
Adding requests:  52%|    | 268/512 [00:00<00:00, 435.49it/s]
Adding requests:  61%|    | 313/512 [00:00<00:00, 437.29it/s]
Adding requests:  70%|   | 357/512 [00:00<00:00, 436.44it/s]
Adding requests:  79%|  | 402/512 [00:00<00:00, 439.01it/s]
Adding requests:  87%| | 446/512 [00:01<00:00, 438.36it/s]
Adding requests:  96%|| 491/512 [00:01<00:00, 440.25it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 435.30it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 6/512 [00:00<00:40, 12.49it/s, est. speed input: 12790.31 toks/s, output: 12.49 toks/s]
Processed prompts:   2%|         | 10/512 [00:01<01:02,  8.06it/s, est. speed input: 8821.10 toks/s, output: 8.61 toks/s] 
Processed prompts:   3%|         | 14/512 [00:01<01:11,  6.92it/s, est. speed input: 7722.99 toks/s, output: 7.54 toks/s]
Processed prompts:   4%|         | 18/512 [00:02<01:16,  6.46it/s, est. speed input: 7240.43 toks/s, output: 7.07 toks/s]
Processed prompts:   4%|         | 22/512 [00:03<01:18,  6.21it/s, est. speed input: 6956.68 toks/s, output: 6.79 toks/s]
Processed prompts:   5%|         | 26/512 [00:03<01:20,  6.06it/s, est. speed input: 6772.51 toks/s, output: 6.61 toks/s]
Processed prompts:   6%|         | 30/512 [00:04<01:20,  5.97it/s, est. speed input: 6646.57 toks/s, output: 6.49 toks/s]
Processed prompts:   7%|         | 34/512 [00:05<01:20,  5.93it/s, est. speed input: 6559.87 toks/s, output: 6.41 toks/s]
Processed prompts:   7%|         | 38/512 [00:05<01:20,  5.89it/s, est. speed input: 6488.52 toks/s, output: 6.34 toks/s]
Processed prompts:   8%|         | 42/512 [00:06<01:20,  5.85it/s, est. speed input: 6427.41 toks/s, output: 6.28 toks/s]
Processed prompts:   9%|         | 46/512 [00:07<01:19,  5.86it/s, est. speed input: 6389.82 toks/s, output: 6.24 toks/s]
Processed prompts:  10%|         | 50/512 [00:08<01:19,  5.83it/s, est. speed input: 6348.34 toks/s, output: 6.20 toks/s]
Processed prompts:  11%|         | 54/512 [00:08<01:18,  5.83it/s, est. speed input: 6318.80 toks/s, output: 6.17 toks/s]
Processed prompts:  11%|        | 58/512 [00:09<01:17,  5.83it/s, est. speed input: 6294.23 toks/s, output: 6.15 toks/s]
Processed prompts:  12%|        | 62/512 [00:10<01:17,  5.81it/s, est. speed input: 6265.72 toks/s, output: 6.12 toks/s]
Processed prompts:  13%|        | 66/512 [00:10<01:17,  5.79it/s, est. speed input: 6241.78 toks/s, output: 6.10 toks/s]
Processed prompts:  14%|        | 70/512 [00:11<01:16,  5.81it/s, est. speed input: 6227.58 toks/s, output: 6.08 toks/s]
Processed prompts:  14%|        | 74/512 [00:12<01:15,  5.82it/s, est. speed input: 6212.97 toks/s, output: 6.07 toks/s]
Processed prompts:  15%|        | 78/512 [00:12<01:14,  5.83it/s, est. speed input: 6201.46 toks/s, output: 6.06 toks/s]
Processed prompts:  16%|        | 82/512 [00:13<01:14,  5.80it/s, est. speed input: 6185.03 toks/s, output: 6.04 toks/s]
Processed prompts:  17%|        | 86/512 [00:14<01:13,  5.78it/s, est. speed input: 6170.20 toks/s, output: 6.03 toks/s]
Processed prompts:  18%|        | 90/512 [00:14<01:12,  5.79it/s, est. speed input: 6160.05 toks/s, output: 6.02 toks/s]
Processed prompts:  18%|        | 94/512 [00:15<01:12,  5.77it/s, est. speed input: 6146.98 toks/s, output: 6.00 toks/s]
Processed prompts:  19%|        | 98/512 [00:16<01:11,  5.77it/s, est. speed input: 6136.19 toks/s, output: 5.99 toks/s]
Processed prompts:  20%|        | 102/512 [00:17<01:10,  5.78it/s, est. speed input: 6128.28 toks/s, output: 5.98 toks/s]
Processed prompts:  21%|        | 106/512 [00:17<01:10,  5.77it/s, est. speed input: 6119.26 toks/s, output: 5.98 toks/s]
Processed prompts:  21%|       | 110/512 [00:18<01:09,  5.78it/s, est. speed input: 6111.87 toks/s, output: 5.97 toks/s]
Processed prompts:  22%|       | 114/512 [00:19<01:08,  5.79it/s, est. speed input: 6106.53 toks/s, output: 5.96 toks/s]
Processed prompts:  23%|       | 118/512 [00:19<01:08,  5.78it/s, est. speed input: 6098.96 toks/s, output: 5.96 toks/s]
Processed prompts:  24%|       | 122/512 [00:20<01:07,  5.77it/s, est. speed input: 6092.10 toks/s, output: 5.95 toks/s]
Processed prompts:  25%|       | 126/512 [00:21<01:06,  5.79it/s, est. speed input: 6087.80 toks/s, output: 5.95 toks/s]
Processed prompts:  25%|       | 130/512 [00:21<01:06,  5.78it/s, est. speed input: 6081.64 toks/s, output: 5.94 toks/s]
Processed prompts:  26%|       | 134/512 [00:22<01:05,  5.78it/s, est. speed input: 6076.41 toks/s, output: 5.93 toks/s]
Processed prompts:  27%|       | 138/512 [00:23<01:04,  5.79it/s, est. speed input: 6072.80 toks/s, output: 5.93 toks/s]
Processed prompts:  28%|       | 142/512 [00:23<01:03,  5.79it/s, est. speed input: 6068.51 toks/s, output: 5.93 toks/s]
Processed prompts:  29%|       | 146/512 [00:24<01:03,  5.77it/s, est. speed input: 6062.94 toks/s, output: 5.92 toks/s]
Processed prompts:  29%|       | 150/512 [00:25<01:02,  5.78it/s, est. speed input: 6059.85 toks/s, output: 5.92 toks/s]
Processed prompts:  30%|       | 154/512 [00:26<01:02,  5.77it/s, est. speed input: 6055.06 toks/s, output: 5.91 toks/s]
Processed prompts:  31%|       | 158/512 [00:26<01:01,  5.76it/s, est. speed input: 6050.49 toks/s, output: 5.91 toks/s]
Processed prompts:  32%|      | 162/512 [00:27<01:00,  5.78it/s, est. speed input: 6048.40 toks/s, output: 5.91 toks/s]
Processed prompts:  32%|      | 166/512 [00:28<01:00,  5.76it/s, est. speed input: 6043.56 toks/s, output: 5.90 toks/s]
Processed prompts:  33%|      | 170/512 [00:28<00:59,  5.76it/s, est. speed input: 6040.31 toks/s, output: 5.90 toks/s]
Processed prompts:  34%|      | 174/512 [00:29<00:58,  5.77it/s, est. speed input: 6037.72 toks/s, output: 5.90 toks/s]
Processed prompts:  35%|      | 178/512 [00:30<00:57,  5.77it/s, est. speed input: 6034.40 toks/s, output: 5.89 toks/s]
Processed prompts:  36%|      | 182/512 [00:30<00:57,  5.77it/s, est. speed input: 6031.68 toks/s, output: 5.89 toks/s]
Processed prompts:  36%|      | 186/512 [00:31<00:57,  5.67it/s, est. speed input: 6020.92 toks/s, output: 5.88 toks/s]
Processed prompts:  37%|      | 190/512 [00:32<00:56,  5.68it/s, est. speed input: 6017.58 toks/s, output: 5.88 toks/s]
Processed prompts:  38%|      | 194/512 [00:33<00:55,  5.70it/s, est. speed input: 6014.86 toks/s, output: 5.87 toks/s]
Processed prompts:  39%|      | 198/512 [00:33<00:54,  5.73it/s, est. speed input: 6013.39 toks/s, output: 5.87 toks/s]
Processed prompts:  39%|      | 202/512 [00:34<00:51,  6.03it/s, est. speed input: 6030.58 toks/s, output: 5.89 toks/s]
Processed prompts:  40%|      | 206/512 [00:34<00:51,  5.97it/s, est. speed input: 6029.31 toks/s, output: 5.89 toks/s]
Processed prompts:  41%|      | 210/512 [00:35<00:51,  5.91it/s, est. speed input: 6027.01 toks/s, output: 5.89 toks/s]
Processed prompts:  42%|     | 214/512 [00:36<00:50,  5.87it/s, est. speed input: 6024.82 toks/s, output: 5.88 toks/s]
Processed prompts:  43%|     | 218/512 [00:37<00:50,  5.85it/s, est. speed input: 6023.30 toks/s, output: 5.88 toks/s]
Processed prompts:  43%|     | 222/512 [00:37<00:49,  5.81it/s, est. speed input: 6020.33 toks/s, output: 5.88 toks/s]
Processed prompts:  44%|     | 226/512 [00:38<00:49,  5.79it/s, est. speed input: 6017.99 toks/s, output: 5.88 toks/s]
Processed prompts:  45%|     | 230/512 [00:39<00:48,  5.81it/s, est. speed input: 6017.25 toks/s, output: 5.88 toks/s]
Processed prompts:  46%|     | 234/512 [00:39<00:48,  5.78it/s, est. speed input: 6014.38 toks/s, output: 5.87 toks/s]
Processed prompts:  46%|     | 238/512 [00:40<00:47,  5.78it/s, est. speed input: 6012.59 toks/s, output: 5.87 toks/s]
Processed prompts:  47%|     | 242/512 [00:41<00:46,  5.78it/s, est. speed input: 6011.00 toks/s, output: 5.87 toks/s]
Processed prompts:  48%|     | 246/512 [00:41<00:46,  5.76it/s, est. speed input: 6008.27 toks/s, output: 5.87 toks/s]
Processed prompts:  49%|     | 250/512 [00:42<00:45,  5.75it/s, est. speed input: 6005.74 toks/s, output: 5.86 toks/s]
Processed prompts:  50%|     | 254/512 [00:43<00:44,  5.77it/s, est. speed input: 6004.97 toks/s, output: 5.86 toks/s]
Processed prompts:  50%|     | 258/512 [00:44<00:44,  5.77it/s, est. speed input: 6003.69 toks/s, output: 5.86 toks/s]
Processed prompts:  51%|     | 262/512 [00:44<00:43,  5.77it/s, est. speed input: 6001.90 toks/s, output: 5.86 toks/s]
Processed prompts:  52%|    | 266/512 [00:45<00:42,  5.78it/s, est. speed input: 6000.95 toks/s, output: 5.86 toks/s]
Processed prompts:  53%|    | 270/512 [00:46<00:41,  5.77it/s, est. speed input: 5999.21 toks/s, output: 5.86 toks/s]
Processed prompts:  54%|    | 274/512 [00:46<00:41,  5.77it/s, est. speed input: 5997.88 toks/s, output: 5.86 toks/s]
Processed prompts:  54%|    | 278/512 [00:47<00:40,  5.77it/s, est. speed input: 5996.88 toks/s, output: 5.86 toks/s]
Processed prompts:  55%|    | 282/512 [00:48<00:39,  5.77it/s, est. speed input: 5995.44 toks/s, output: 5.85 toks/s]
Processed prompts:  56%|    | 286/512 [00:48<00:39,  5.76it/s, est. speed input: 5993.81 toks/s, output: 5.85 toks/s]
Processed prompts:  57%|    | 290/512 [00:49<00:38,  5.76it/s, est. speed input: 5992.22 toks/s, output: 5.85 toks/s]
Processed prompts:  57%|    | 294/512 [00:50<00:37,  5.76it/s, est. speed input: 5991.00 toks/s, output: 5.85 toks/s]
Processed prompts:  58%|    | 298/512 [00:50<00:37,  5.77it/s, est. speed input: 5990.25 toks/s, output: 5.85 toks/s]
Processed prompts:  59%|    | 302/512 [00:51<00:36,  5.76it/s, est. speed input: 5988.86 toks/s, output: 5.85 toks/s]
Processed prompts:  60%|    | 306/512 [00:52<00:33,  6.11it/s, est. speed input: 6002.60 toks/s, output: 5.86 toks/s]
Processed prompts:  61%|    | 310/512 [00:52<00:33,  6.01it/s, est. speed input: 6001.70 toks/s, output: 5.86 toks/s]
Processed prompts:  61%|   | 314/512 [00:53<00:33,  5.93it/s, est. speed input: 6000.11 toks/s, output: 5.86 toks/s]
Processed prompts:  62%|   | 318/512 [00:54<00:33,  5.87it/s, est. speed input: 5998.63 toks/s, output: 5.86 toks/s]
Processed prompts:  63%|   | 322/512 [00:54<00:32,  5.84it/s, est. speed input: 5997.51 toks/s, output: 5.86 toks/s]
Processed prompts:  64%|   | 326/512 [00:55<00:32,  5.80it/s, est. speed input: 5995.73 toks/s, output: 5.86 toks/s]
Processed prompts:  64%|   | 330/512 [00:56<00:31,  5.79it/s, est. speed input: 5994.42 toks/s, output: 5.85 toks/s]
Processed prompts:  65%|   | 334/512 [00:57<00:30,  5.79it/s, est. speed input: 5993.79 toks/s, output: 5.85 toks/s]
Processed prompts:  66%|   | 338/512 [00:57<00:30,  5.78it/s, est. speed input: 5992.65 toks/s, output: 5.85 toks/s]
Processed prompts:  67%|   | 342/512 [00:58<00:29,  5.78it/s, est. speed input: 5991.62 toks/s, output: 5.85 toks/s]
Processed prompts:  68%|   | 346/512 [00:59<00:28,  5.78it/s, est. speed input: 5990.94 toks/s, output: 5.85 toks/s]
Processed prompts:  68%|   | 350/512 [00:59<00:28,  5.78it/s, est. speed input: 5989.88 toks/s, output: 5.85 toks/s]
Processed prompts:  69%|   | 354/512 [01:00<00:27,  5.78it/s, est. speed input: 5989.04 toks/s, output: 5.85 toks/s]
Processed prompts:  70%|   | 358/512 [01:01<00:26,  5.80it/s, est. speed input: 5989.14 toks/s, output: 5.85 toks/s]
Processed prompts:  71%|   | 362/512 [01:01<00:25,  5.78it/s, est. speed input: 5987.83 toks/s, output: 5.85 toks/s]
Processed prompts:  71%|  | 366/512 [01:02<00:25,  5.76it/s, est. speed input: 5986.31 toks/s, output: 5.85 toks/s]
Processed prompts:  72%|  | 370/512 [01:03<00:24,  5.76it/s, est. speed input: 5985.48 toks/s, output: 5.85 toks/s]
Processed prompts:  73%|  | 374/512 [01:03<00:23,  5.76it/s, est. speed input: 5984.49 toks/s, output: 5.84 toks/s]
Processed prompts:  74%|  | 378/512 [01:04<00:23,  5.78it/s, est. speed input: 5984.20 toks/s, output: 5.84 toks/s]
Processed prompts:  75%|  | 382/512 [01:05<00:22,  5.77it/s, est. speed input: 5983.17 toks/s, output: 5.84 toks/s]
Processed prompts:  75%|  | 386/512 [01:06<00:21,  5.77it/s, est. speed input: 5982.37 toks/s, output: 5.84 toks/s]
Processed prompts:  76%|  | 390/512 [01:06<00:21,  5.76it/s, est. speed input: 5981.35 toks/s, output: 5.84 toks/s]
Processed prompts:  77%|  | 394/512 [01:07<00:20,  5.76it/s, est. speed input: 5980.44 toks/s, output: 5.84 toks/s]
Processed prompts:  78%|  | 398/512 [01:08<00:19,  5.75it/s, est. speed input: 5979.27 toks/s, output: 5.84 toks/s]
Processed prompts:  79%|  | 402/512 [01:08<00:19,  5.75it/s, est. speed input: 5978.39 toks/s, output: 5.84 toks/s]
Processed prompts:  79%|  | 406/512 [01:09<00:18,  5.74it/s, est. speed input: 5977.10 toks/s, output: 5.84 toks/s]
Processed prompts:  80%|  | 410/512 [01:10<00:17,  5.74it/s, est. speed input: 5976.00 toks/s, output: 5.84 toks/s]
Processed prompts:  81%|  | 414/512 [01:10<00:17,  5.74it/s, est. speed input: 5975.11 toks/s, output: 5.84 toks/s]
Processed prompts:  82%| | 418/512 [01:11<00:16,  5.73it/s, est. speed input: 5973.89 toks/s, output: 5.83 toks/s]
Processed prompts:  82%| | 422/512 [01:12<00:15,  5.72it/s, est. speed input: 5972.66 toks/s, output: 5.83 toks/s]
Processed prompts:  83%| | 426/512 [01:13<00:14,  5.75it/s, est. speed input: 5972.32 toks/s, output: 5.83 toks/s]
Processed prompts:  84%| | 430/512 [01:13<00:14,  5.74it/s, est. speed input: 5971.31 toks/s, output: 5.83 toks/s]
Processed prompts:  85%| | 434/512 [01:14<00:12,  6.09it/s, est. speed input: 5981.01 toks/s, output: 5.84 toks/s]
Processed prompts:  86%| | 438/512 [01:14<00:12,  5.98it/s, est. speed input: 5980.21 toks/s, output: 5.84 toks/s]
Processed prompts:  86%| | 442/512 [01:15<00:11,  5.89it/s, est. speed input: 5978.85 toks/s, output: 5.84 toks/s]
Processed prompts:  87%| | 446/512 [01:16<00:11,  5.84it/s, est. speed input: 5977.80 toks/s, output: 5.84 toks/s]
Processed prompts:  88%| | 450/512 [01:17<00:10,  5.83it/s, est. speed input: 5977.39 toks/s, output: 5.84 toks/s]
Processed prompts:  89%| | 454/512 [01:17<00:10,  5.80it/s, est. speed input: 5976.43 toks/s, output: 5.84 toks/s]
Processed prompts:  89%| | 458/512 [01:18<00:09,  5.77it/s, est. speed input: 5975.23 toks/s, output: 5.84 toks/s]
Processed prompts:  90%| | 462/512 [01:19<00:08,  5.78it/s, est. speed input: 5975.04 toks/s, output: 5.83 toks/s]
Processed prompts:  91%| | 466/512 [01:19<00:07,  5.76it/s, est. speed input: 5973.75 toks/s, output: 5.83 toks/s]
Processed prompts:  92%|| 470/512 [01:20<00:07,  5.75it/s, est. speed input: 5972.97 toks/s, output: 5.83 toks/s]
Processed prompts:  93%|| 474/512 [01:21<00:06,  5.77it/s, est. speed input: 5972.65 toks/s, output: 5.83 toks/s]
Processed prompts:  93%|| 478/512 [01:21<00:05,  5.76it/s, est. speed input: 5972.01 toks/s, output: 5.83 toks/s]
Processed prompts:  94%|| 482/512 [01:22<00:05,  5.77it/s, est. speed input: 5971.47 toks/s, output: 5.83 toks/s]
Processed prompts:  95%|| 486/512 [01:23<00:04,  5.76it/s, est. speed input: 5970.64 toks/s, output: 5.83 toks/s]
Processed prompts:  96%|| 490/512 [01:24<00:03,  5.74it/s, est. speed input: 5969.55 toks/s, output: 5.83 toks/s]
Processed prompts:  96%|| 494/512 [01:24<00:03,  5.75it/s, est. speed input: 5969.09 toks/s, output: 5.83 toks/s]
Processed prompts:  97%|| 498/512 [01:25<00:02,  5.74it/s, est. speed input: 5968.19 toks/s, output: 5.83 toks/s]
Processed prompts:  98%|| 502/512 [01:26<00:01,  5.74it/s, est. speed input: 5967.45 toks/s, output: 5.83 toks/s]
Processed prompts:  99%|| 506/512 [01:26<00:01,  5.75it/s, est. speed input: 5967.04 toks/s, output: 5.83 toks/s]
Processed prompts: 100%|| 510/512 [01:27<00:00,  6.15it/s, est. speed input: 5976.63 toks/s, output: 5.84 toks/s]
Processed prompts: 100%|| 512/512 [01:27<00:00,  6.15it/s, est. speed input: 6000.06 toks/s, output: 5.86 toks/s]
Processed prompts: 100%|| 512/512 [01:27<00:00,  5.86it/s, est. speed input: 6000.06 toks/s, output: 5.86 toks/s]
[rank0]:[W126 16:37:36.958319200 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 16:37:39
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 16:37:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 16:37:48 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1504638) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1504638) WARNING 01-26 16:39:10 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.61 requests/s, 5748.82 total tokens/s, 5.61 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 16:37:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:37:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:37:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:37:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:37:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:37:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:37:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:37:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:37:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:37:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:37:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:37:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:37:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:37:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 16:37:51] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:37:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:37:51] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:37:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:37:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:37:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:37:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:37:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:37:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:37:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:37:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:37:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:37:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:37:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1504638) [2026-01-26 16:37:52] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1504638) [2026-01-26 16:37:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1504638) [2026-01-26 16:37:52] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1504638) [2026-01-26 16:37:52] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1504638) [2026-01-26 16:37:52] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1504638) [2026-01-26 16:37:52] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1504638) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1504638) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.31s/it]
(EngineCore_DP0 pid=1504638) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:05<00:00, 33.64s/it]
(EngineCore_DP0 pid=1504638) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:05<00:00, 32.84s/it]
(EngineCore_DP0 pid=1504638) 
(EngineCore_DP0 pid=1504638) [2026-01-26 16:38:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1504638) [2026-01-26 16:38:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=1504638) [2026-01-26 16:38:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1504638) [2026-01-26 16:38:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=1504638) [2026-01-26 16:38:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1504638) [2026-01-26 16:38:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=1504638) [2026-01-26 16:38:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1504638) [2026-01-26 16:38:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=1504638) 2026-01-26 16:39:08,121 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1504638) 2026-01-26 16:39:08,687 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|         | 34/1024 [00:00<00:02, 333.50it/s]
Adding requests:   7%|         | 72/1024 [00:00<00:02, 355.60it/s]
Adding requests:  12%|        | 119/1024 [00:00<00:02, 404.69it/s]
Adding requests:  16%|        | 162/1024 [00:00<00:02, 412.06it/s]
Adding requests:  20%|        | 208/1024 [00:00<00:01, 428.99it/s]
Adding requests:  25%|       | 252/1024 [00:00<00:01, 432.63it/s]
Adding requests:  29%|       | 299/1024 [00:00<00:01, 442.02it/s]
Adding requests:  34%|      | 344/1024 [00:00<00:01, 435.03it/s]
Adding requests:  38%|      | 389/1024 [00:00<00:01, 437.33it/s]
Adding requests:  42%|     | 435/1024 [00:01<00:01, 441.04it/s]
Adding requests:  47%|     | 482/1024 [00:01<00:01, 447.42it/s]
Adding requests:  52%|    | 534/1024 [00:01<00:01, 462.32it/s]
Adding requests:  57%|    | 581/1024 [00:01<00:00, 450.69it/s]
Adding requests:  61%|   | 628/1024 [00:01<00:00, 453.34it/s]
Adding requests:  66%|   | 674/1024 [00:01<00:00, 444.84it/s]
Adding requests:  70%|   | 720/1024 [00:01<00:00, 447.91it/s]
Adding requests:  75%|  | 765/1024 [00:01<00:00, 439.31it/s]
Adding requests:  79%|  | 811/1024 [00:01<00:00, 442.69it/s]
Adding requests:  84%| | 858/1024 [00:01<00:00, 449.81it/s]
Adding requests:  89%| | 907/1024 [00:02<00:00, 457.18it/s]
Adding requests:  93%|| 953/1024 [00:02<00:00, 446.55it/s]
Adding requests:  97%|| 998/1024 [00:02<00:00, 447.06it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 439.36it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 10/1024 [00:00<01:22, 12.23it/s, est. speed input: 12525.52 toks/s, output: 12.23 toks/s]
Processed prompts:   2%|         | 18/1024 [00:02<02:14,  7.47it/s, est. speed input: 8183.15 toks/s, output: 7.99 toks/s]  
Processed prompts:   3%|         | 26/1024 [00:03<02:32,  6.54it/s, est. speed input: 7241.41 toks/s, output: 7.07 toks/s]
Processed prompts:   3%|         | 34/1024 [00:05<02:40,  6.17it/s, est. speed input: 6835.36 toks/s, output: 6.68 toks/s]
Processed prompts:   4%|         | 42/1024 [00:06<02:45,  5.95it/s, est. speed input: 6591.93 toks/s, output: 6.44 toks/s]
Processed prompts:   5%|         | 50/1024 [00:07<02:46,  5.84it/s, est. speed input: 6446.17 toks/s, output: 6.30 toks/s]
Processed prompts:   6%|         | 58/1024 [00:09<02:47,  5.77it/s, est. speed input: 6340.21 toks/s, output: 6.19 toks/s]
Processed prompts:   6%|         | 66/1024 [00:10<02:47,  5.70it/s, est. speed input: 6255.64 toks/s, output: 6.11 toks/s]
Processed prompts:   7%|         | 74/1024 [00:12<02:47,  5.68it/s, est. speed input: 6200.33 toks/s, output: 6.05 toks/s]
Processed prompts:   8%|         | 82/1024 [00:13<02:46,  5.67it/s, est. speed input: 6154.53 toks/s, output: 6.01 toks/s]
Processed prompts:   9%|         | 90/1024 [00:15<02:45,  5.65it/s, est. speed input: 6117.64 toks/s, output: 5.97 toks/s]
Processed prompts:  10%|         | 98/1024 [00:16<02:43,  5.65it/s, est. speed input: 6089.27 toks/s, output: 5.95 toks/s]
Processed prompts:  10%|         | 106/1024 [00:17<02:42,  5.64it/s, est. speed input: 6060.37 toks/s, output: 5.92 toks/s]
Processed prompts:  11%|         | 114/1024 [00:19<02:41,  5.62it/s, est. speed input: 6036.35 toks/s, output: 5.89 toks/s]
Processed prompts:  12%|        | 122/1024 [00:20<02:40,  5.62it/s, est. speed input: 6016.27 toks/s, output: 5.88 toks/s]
Processed prompts:  13%|        | 130/1024 [00:22<02:39,  5.62it/s, est. speed input: 5998.94 toks/s, output: 5.86 toks/s]
Processed prompts:  13%|        | 138/1024 [00:23<02:38,  5.60it/s, est. speed input: 5981.31 toks/s, output: 5.84 toks/s]
Processed prompts:  14%|        | 146/1024 [00:25<02:36,  5.61it/s, est. speed input: 5967.99 toks/s, output: 5.83 toks/s]
Processed prompts:  15%|        | 154/1024 [00:26<02:35,  5.60it/s, est. speed input: 5954.62 toks/s, output: 5.82 toks/s]
Processed prompts:  16%|        | 162/1024 [00:27<02:33,  5.61it/s, est. speed input: 5944.25 toks/s, output: 5.80 toks/s]
Processed prompts:  17%|        | 170/1024 [00:29<02:32,  5.61it/s, est. speed input: 5935.81 toks/s, output: 5.80 toks/s]
Processed prompts:  17%|        | 178/1024 [00:30<02:31,  5.60it/s, est. speed input: 5924.82 toks/s, output: 5.79 toks/s]
Processed prompts:  18%|        | 186/1024 [00:32<02:30,  5.59it/s, est. speed input: 5914.14 toks/s, output: 5.78 toks/s]
Processed prompts:  19%|        | 194/1024 [00:33<02:28,  5.60it/s, est. speed input: 5908.17 toks/s, output: 5.77 toks/s]
Processed prompts:  20%|        | 202/1024 [00:34<02:22,  5.79it/s, est. speed input: 5926.77 toks/s, output: 5.79 toks/s]
Processed prompts:  21%|        | 210/1024 [00:36<02:21,  5.74it/s, est. speed input: 5920.48 toks/s, output: 5.78 toks/s]
Processed prompts:  21%|       | 218/1024 [00:37<02:21,  5.70it/s, est. speed input: 5914.04 toks/s, output: 5.78 toks/s]
Processed prompts:  22%|       | 226/1024 [00:39<02:20,  5.67it/s, est. speed input: 5907.19 toks/s, output: 5.77 toks/s]
Processed prompts:  23%|       | 234/1024 [00:40<02:19,  5.65it/s, est. speed input: 5901.53 toks/s, output: 5.76 toks/s]
Processed prompts:  24%|       | 242/1024 [00:42<02:18,  5.64it/s, est. speed input: 5896.21 toks/s, output: 5.76 toks/s]
Processed prompts:  24%|       | 250/1024 [00:43<02:17,  5.62it/s, est. speed input: 5890.58 toks/s, output: 5.75 toks/s]
Processed prompts:  25%|       | 258/1024 [00:44<02:16,  5.62it/s, est. speed input: 5885.66 toks/s, output: 5.75 toks/s]
Processed prompts:  26%|       | 266/1024 [00:46<02:15,  5.61it/s, est. speed input: 5881.17 toks/s, output: 5.74 toks/s]
Processed prompts:  27%|       | 274/1024 [00:47<02:13,  5.61it/s, est. speed input: 5876.71 toks/s, output: 5.74 toks/s]
Processed prompts:  28%|       | 282/1024 [00:49<02:12,  5.61it/s, est. speed input: 5873.34 toks/s, output: 5.74 toks/s]
Processed prompts:  28%|       | 290/1024 [00:50<02:10,  5.61it/s, est. speed input: 5869.93 toks/s, output: 5.73 toks/s]
Processed prompts:  29%|       | 298/1024 [00:52<02:09,  5.61it/s, est. speed input: 5865.97 toks/s, output: 5.73 toks/s]
Processed prompts:  30%|       | 306/1024 [00:53<02:03,  5.79it/s, est. speed input: 5879.16 toks/s, output: 5.74 toks/s]
Processed prompts:  31%|       | 314/1024 [00:54<02:03,  5.74it/s, est. speed input: 5876.29 toks/s, output: 5.74 toks/s]
Processed prompts:  31%|      | 322/1024 [00:56<02:02,  5.71it/s, est. speed input: 5873.74 toks/s, output: 5.74 toks/s]
Processed prompts:  32%|      | 330/1024 [00:57<02:02,  5.68it/s, est. speed input: 5870.21 toks/s, output: 5.73 toks/s]
Processed prompts:  33%|      | 338/1024 [00:58<02:01,  5.65it/s, est. speed input: 5866.43 toks/s, output: 5.73 toks/s]
Processed prompts:  34%|      | 346/1024 [01:00<02:00,  5.64it/s, est. speed input: 5864.09 toks/s, output: 5.73 toks/s]
Processed prompts:  35%|      | 354/1024 [01:01<01:58,  5.63it/s, est. speed input: 5861.28 toks/s, output: 5.72 toks/s]
Processed prompts:  35%|      | 362/1024 [01:03<01:57,  5.62it/s, est. speed input: 5858.20 toks/s, output: 5.72 toks/s]
Processed prompts:  36%|      | 370/1024 [01:04<01:56,  5.61it/s, est. speed input: 5855.02 toks/s, output: 5.72 toks/s]
Processed prompts:  37%|      | 378/1024 [01:06<01:55,  5.61it/s, est. speed input: 5852.71 toks/s, output: 5.72 toks/s]
Processed prompts:  38%|      | 386/1024 [01:07<01:53,  5.61it/s, est. speed input: 5850.13 toks/s, output: 5.71 toks/s]
Processed prompts:  38%|      | 394/1024 [01:09<01:52,  5.60it/s, est. speed input: 5847.10 toks/s, output: 5.71 toks/s]
Processed prompts:  39%|      | 402/1024 [01:10<01:51,  5.60it/s, est. speed input: 5844.75 toks/s, output: 5.71 toks/s]
Processed prompts:  40%|      | 410/1024 [01:11<01:49,  5.59it/s, est. speed input: 5842.02 toks/s, output: 5.71 toks/s]
Processed prompts:  41%|      | 418/1024 [01:13<01:48,  5.59it/s, est. speed input: 5839.86 toks/s, output: 5.70 toks/s]
Processed prompts:  42%|     | 426/1024 [01:14<01:46,  5.60it/s, est. speed input: 5837.98 toks/s, output: 5.70 toks/s]
Processed prompts:  42%|     | 434/1024 [01:15<01:41,  5.80it/s, est. speed input: 5848.57 toks/s, output: 5.71 toks/s]
Processed prompts:  43%|     | 442/1024 [01:17<01:41,  5.73it/s, est. speed input: 5845.91 toks/s, output: 5.71 toks/s]
Processed prompts:  44%|     | 450/1024 [01:18<01:40,  5.70it/s, est. speed input: 5844.38 toks/s, output: 5.71 toks/s]
Processed prompts:  45%|     | 458/1024 [01:20<01:39,  5.66it/s, est. speed input: 5842.06 toks/s, output: 5.71 toks/s]
Processed prompts:  46%|     | 466/1024 [01:21<01:39,  5.62it/s, est. speed input: 5839.06 toks/s, output: 5.70 toks/s]
Processed prompts:  46%|     | 474/1024 [01:23<01:37,  5.62it/s, est. speed input: 5837.25 toks/s, output: 5.70 toks/s]
Processed prompts:  47%|     | 482/1024 [01:24<01:36,  5.60it/s, est. speed input: 5835.12 toks/s, output: 5.70 toks/s]
Processed prompts:  48%|     | 490/1024 [01:26<01:35,  5.61it/s, est. speed input: 5833.90 toks/s, output: 5.70 toks/s]
Processed prompts:  49%|     | 498/1024 [01:27<01:33,  5.60it/s, est. speed input: 5831.73 toks/s, output: 5.70 toks/s]
Processed prompts:  49%|     | 506/1024 [01:28<01:32,  5.59it/s, est. speed input: 5829.83 toks/s, output: 5.69 toks/s]
Processed prompts:  50%|     | 514/1024 [01:30<01:31,  5.59it/s, est. speed input: 5827.96 toks/s, output: 5.69 toks/s]
Processed prompts:  51%|     | 522/1024 [01:31<01:29,  5.59it/s, est. speed input: 5826.55 toks/s, output: 5.69 toks/s]
Processed prompts:  52%|    | 530/1024 [01:33<01:28,  5.60it/s, est. speed input: 5825.31 toks/s, output: 5.69 toks/s]
Processed prompts:  53%|    | 538/1024 [01:34<01:26,  5.59it/s, est. speed input: 5823.35 toks/s, output: 5.69 toks/s]
Processed prompts:  53%|    | 546/1024 [01:36<01:25,  5.60it/s, est. speed input: 5822.55 toks/s, output: 5.69 toks/s]
Processed prompts:  54%|    | 554/1024 [01:37<01:23,  5.60it/s, est. speed input: 5821.22 toks/s, output: 5.68 toks/s]
Processed prompts:  55%|    | 562/1024 [01:38<01:22,  5.59it/s, est. speed input: 5819.64 toks/s, output: 5.68 toks/s]
Processed prompts:  56%|    | 570/1024 [01:40<01:21,  5.59it/s, est. speed input: 5818.27 toks/s, output: 5.68 toks/s]
Processed prompts:  56%|    | 578/1024 [01:41<01:19,  5.59it/s, est. speed input: 5816.96 toks/s, output: 5.68 toks/s]
Processed prompts:  57%|    | 586/1024 [01:43<01:18,  5.59it/s, est. speed input: 5815.81 toks/s, output: 5.68 toks/s]
Processed prompts:  58%|    | 594/1024 [01:44<01:16,  5.60it/s, est. speed input: 5814.77 toks/s, output: 5.68 toks/s]
Processed prompts:  59%|    | 602/1024 [01:46<01:15,  5.59it/s, est. speed input: 5813.09 toks/s, output: 5.68 toks/s]
Processed prompts:  60%|    | 610/1024 [01:47<01:14,  5.58it/s, est. speed input: 5811.42 toks/s, output: 5.68 toks/s]
Processed prompts:  60%|    | 618/1024 [01:48<01:12,  5.57it/s, est. speed input: 5809.91 toks/s, output: 5.67 toks/s]
Processed prompts:  61%|    | 626/1024 [01:50<01:11,  5.57it/s, est. speed input: 5808.40 toks/s, output: 5.67 toks/s]
Processed prompts:  62%|   | 634/1024 [01:51<01:10,  5.57it/s, est. speed input: 5806.91 toks/s, output: 5.67 toks/s]
Processed prompts:  63%|   | 642/1024 [01:53<01:08,  5.57it/s, est. speed input: 5805.91 toks/s, output: 5.67 toks/s]
Processed prompts:  63%|   | 650/1024 [01:54<01:07,  5.57it/s, est. speed input: 5804.49 toks/s, output: 5.67 toks/s]
Processed prompts:  64%|   | 658/1024 [01:56<01:05,  5.56it/s, est. speed input: 5802.97 toks/s, output: 5.67 toks/s]
Processed prompts:  65%|   | 666/1024 [01:57<01:04,  5.57it/s, est. speed input: 5801.85 toks/s, output: 5.67 toks/s]
Processed prompts:  66%|   | 674/1024 [01:58<01:02,  5.57it/s, est. speed input: 5800.92 toks/s, output: 5.66 toks/s]
Processed prompts:  67%|   | 682/1024 [02:00<01:01,  5.59it/s, est. speed input: 5800.33 toks/s, output: 5.66 toks/s]
Processed prompts:  67%|   | 690/1024 [02:01<00:59,  5.58it/s, est. speed input: 5799.28 toks/s, output: 5.66 toks/s]
Processed prompts:  68%|   | 698/1024 [02:03<00:58,  5.58it/s, est. speed input: 5798.23 toks/s, output: 5.66 toks/s]
Processed prompts:  69%|   | 706/1024 [02:04<00:56,  5.59it/s, est. speed input: 5797.49 toks/s, output: 5.66 toks/s]
Processed prompts:  70%|   | 714/1024 [02:06<00:55,  5.58it/s, est. speed input: 5796.28 toks/s, output: 5.66 toks/s]
Processed prompts:  71%|   | 722/1024 [02:07<00:54,  5.58it/s, est. speed input: 5795.37 toks/s, output: 5.66 toks/s]
Processed prompts:  71%|  | 730/1024 [02:08<00:52,  5.59it/s, est. speed input: 5794.88 toks/s, output: 5.66 toks/s]
Processed prompts:  72%|  | 738/1024 [02:10<00:51,  5.58it/s, est. speed input: 5793.60 toks/s, output: 5.66 toks/s]
Processed prompts:  73%|  | 746/1024 [02:11<00:49,  5.57it/s, est. speed input: 5792.54 toks/s, output: 5.66 toks/s]
Processed prompts:  74%|  | 754/1024 [02:13<00:48,  5.59it/s, est. speed input: 5792.13 toks/s, output: 5.66 toks/s]
Processed prompts:  74%|  | 762/1024 [02:14<00:47,  5.57it/s, est. speed input: 5790.89 toks/s, output: 5.66 toks/s]
Processed prompts:  75%|  | 770/1024 [02:16<00:45,  5.57it/s, est. speed input: 5789.94 toks/s, output: 5.65 toks/s]
Processed prompts:  76%|  | 778/1024 [02:17<00:44,  5.57it/s, est. speed input: 5789.10 toks/s, output: 5.65 toks/s]
Processed prompts:  77%|  | 786/1024 [02:18<00:41,  5.76it/s, est. speed input: 5794.88 toks/s, output: 5.66 toks/s]
Processed prompts:  78%|  | 794/1024 [02:20<00:40,  5.72it/s, est. speed input: 5794.53 toks/s, output: 5.66 toks/s]
Processed prompts:  78%|  | 802/1024 [02:21<00:39,  5.69it/s, est. speed input: 5794.12 toks/s, output: 5.66 toks/s]
Processed prompts:  79%|  | 810/1024 [02:23<00:37,  5.65it/s, est. speed input: 5792.96 toks/s, output: 5.66 toks/s]
Processed prompts:  80%|  | 818/1024 [02:24<00:36,  5.63it/s, est. speed input: 5792.41 toks/s, output: 5.66 toks/s]
Processed prompts:  81%|  | 826/1024 [02:26<00:35,  5.64it/s, est. speed input: 5792.27 toks/s, output: 5.66 toks/s]
Processed prompts:  81%| | 834/1024 [02:27<00:33,  5.62it/s, est. speed input: 5791.52 toks/s, output: 5.66 toks/s]
Processed prompts:  82%| | 842/1024 [02:28<00:32,  5.60it/s, est. speed input: 5790.41 toks/s, output: 5.65 toks/s]
Processed prompts:  83%| | 850/1024 [02:30<00:31,  5.59it/s, est. speed input: 5789.51 toks/s, output: 5.65 toks/s]
Processed prompts:  84%| | 858/1024 [02:31<00:29,  5.58it/s, est. speed input: 5788.66 toks/s, output: 5.65 toks/s]
Processed prompts:  85%| | 866/1024 [02:33<00:28,  5.59it/s, est. speed input: 5788.26 toks/s, output: 5.65 toks/s]
Processed prompts:  85%| | 874/1024 [02:34<00:26,  5.58it/s, est. speed input: 5787.34 toks/s, output: 5.65 toks/s]
Processed prompts:  86%| | 882/1024 [02:36<00:25,  5.58it/s, est. speed input: 5786.70 toks/s, output: 5.65 toks/s]
Processed prompts:  87%| | 890/1024 [02:37<00:23,  5.59it/s, est. speed input: 5786.43 toks/s, output: 5.65 toks/s]
Processed prompts:  88%| | 898/1024 [02:38<00:22,  5.59it/s, est. speed input: 5785.85 toks/s, output: 5.65 toks/s]
Processed prompts:  88%| | 906/1024 [02:40<00:21,  5.59it/s, est. speed input: 5785.25 toks/s, output: 5.65 toks/s]
Processed prompts:  89%| | 914/1024 [02:41<00:19,  5.58it/s, est. speed input: 5784.51 toks/s, output: 5.65 toks/s]
Processed prompts:  90%| | 922/1024 [02:43<00:18,  5.58it/s, est. speed input: 5783.70 toks/s, output: 5.65 toks/s]
Processed prompts:  91%| | 930/1024 [02:44<00:16,  5.58it/s, est. speed input: 5783.21 toks/s, output: 5.65 toks/s]
Processed prompts:  92%|| 938/1024 [02:46<00:15,  5.58it/s, est. speed input: 5782.68 toks/s, output: 5.65 toks/s]
Processed prompts:  92%|| 946/1024 [02:47<00:13,  5.59it/s, est. speed input: 5782.25 toks/s, output: 5.65 toks/s]
Processed prompts:  93%|| 954/1024 [02:48<00:12,  5.59it/s, est. speed input: 5781.82 toks/s, output: 5.65 toks/s]
Processed prompts:  94%|| 962/1024 [02:50<00:11,  5.59it/s, est. speed input: 5781.44 toks/s, output: 5.65 toks/s]
Processed prompts:  95%|| 970/1024 [02:51<00:09,  5.59it/s, est. speed input: 5780.87 toks/s, output: 5.65 toks/s]
Processed prompts:  96%|| 978/1024 [02:53<00:08,  5.59it/s, est. speed input: 5780.40 toks/s, output: 5.64 toks/s]
Processed prompts:  96%|| 986/1024 [02:54<00:06,  5.59it/s, est. speed input: 5779.90 toks/s, output: 5.64 toks/s]
Processed prompts:  97%|| 994/1024 [02:56<00:05,  5.58it/s, est. speed input: 5779.12 toks/s, output: 5.64 toks/s]
Processed prompts:  98%|| 1002/1024 [02:57<00:03,  5.57it/s, est. speed input: 5778.37 toks/s, output: 5.64 toks/s]
Processed prompts:  99%|| 1010/1024 [02:58<00:02,  5.58it/s, est. speed input: 5778.00 toks/s, output: 5.64 toks/s]
Processed prompts:  99%|| 1018/1024 [03:00<00:01,  5.81it/s, est. speed input: 5783.48 toks/s, output: 5.65 toks/s]
Processed prompts: 100%|| 1024/1024 [03:00<00:00,  5.81it/s, est. speed input: 5817.56 toks/s, output: 5.68 toks/s]
Processed prompts: 100%|| 1024/1024 [03:00<00:00,  5.68it/s, est. speed input: 5817.56 toks/s, output: 5.68 toks/s]
[rank0]:[W126 16:42:13.917423871 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 16:42:17
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 16:42:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 16:42:31 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1508722) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1508722) WARNING 01-26 16:44:08 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 0.76 requests/s, 779.92 total tokens/s, 0.76 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 16:42:30] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:42:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:42:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:42:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:42:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:42:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:42:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:42:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:42:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:42:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:42:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:42:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:42:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:42:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 16:42:34] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:42:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:42:34] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:42:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:42:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:42:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:42:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:42:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:42:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:42:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:42:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:42:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:42:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:42:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1508722) [2026-01-26 16:42:35] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1508722) [2026-01-26 16:42:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1508722) [2026-01-26 16:42:35] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1508722) [2026-01-26 16:42:35] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1508722) [2026-01-26 16:42:35] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1508722) [2026-01-26 16:42:35] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1508722) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1508722) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.78s/it]
(EngineCore_DP0 pid=1508722) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:06<00:00, 34.14s/it]
(EngineCore_DP0 pid=1508722) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:06<00:00, 33.33s/it]
(EngineCore_DP0 pid=1508722) 
(EngineCore_DP0 pid=1508722) [2026-01-26 16:43:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1508722) [2026-01-26 16:43:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=1508722) [2026-01-26 16:43:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1508722) [2026-01-26 16:43:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=1508722) [2026-01-26 16:43:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1508722) [2026-01-26 16:43:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=1508722) [2026-01-26 16:43:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1508722) [2026-01-26 16:43:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=1508722) 2026-01-26 16:43:53,318 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1508722) 2026-01-26 16:43:54,112 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|         | 43/2048 [00:00<00:04, 422.39it/s]
Adding requests:   4%|         | 86/2048 [00:00<00:05, 390.99it/s]
Adding requests:   6%|         | 131/2048 [00:00<00:04, 413.73it/s]
Adding requests:   9%|         | 184/2048 [00:00<00:04, 457.94it/s]
Adding requests:  11%|        | 231/2048 [00:00<00:03, 460.27it/s]
Adding requests:  14%|        | 284/2048 [00:00<00:03, 481.34it/s]
Adding requests:  17%|        | 343/2048 [00:00<00:03, 514.02it/s]
Adding requests:  20%|        | 403/2048 [00:00<00:03, 539.93it/s]
Adding requests:  22%|       | 458/2048 [00:00<00:02, 531.17it/s]
Adding requests:  25%|       | 516/2048 [00:01<00:02, 543.94it/s]
Adding requests:  28%|       | 576/2048 [00:01<00:02, 558.29it/s]
Adding requests:  31%|       | 632/2048 [00:01<00:02, 552.44it/s]
Adding requests:  34%|      | 688/2048 [00:01<00:02, 551.06it/s]
Adding requests:  36%|      | 744/2048 [00:01<00:02, 546.57it/s]
Adding requests:  39%|      | 799/2048 [00:01<00:02, 545.80it/s]
Adding requests:  42%|     | 854/2048 [00:01<00:02, 522.09it/s]
Adding requests:  44%|     | 910/2048 [00:01<00:02, 530.80it/s]
Adding requests:  47%|     | 964/2048 [00:02<00:02, 381.19it/s]
Adding requests:  49%|     | 1009/2048 [00:02<00:02, 391.53it/s]
Adding requests:  52%|    | 1064/2048 [00:02<00:02, 429.46it/s]
Adding requests:  55%|    | 1120/2048 [00:02<00:02, 462.25it/s]
Adding requests:  58%|    | 1178/2048 [00:02<00:01, 491.99it/s]
Adding requests:  60%|    | 1236/2048 [00:02<00:01, 515.95it/s]
Adding requests:  63%|   | 1291/2048 [00:02<00:01, 523.95it/s]
Adding requests:  66%|   | 1348/2048 [00:02<00:01, 536.75it/s]
Adding requests:  69%|   | 1405/2048 [00:02<00:01, 543.41it/s]
Adding requests:  71%|  | 1463/2048 [00:02<00:01, 550.97it/s]
Adding requests:  74%|  | 1519/2048 [00:03<00:00, 536.33it/s]
Adding requests:  77%|  | 1574/2048 [00:03<00:00, 536.80it/s]
Adding requests:  79%|  | 1628/2048 [00:03<00:00, 537.35it/s]
Adding requests:  82%| | 1682/2048 [00:03<00:00, 534.25it/s]
Adding requests:  85%| | 1736/2048 [00:03<00:00, 533.48it/s]
Adding requests:  87%| | 1790/2048 [00:03<00:00, 528.89it/s]
Adding requests:  90%| | 1847/2048 [00:03<00:00, 539.11it/s]
Adding requests:  93%|| 1904/2048 [00:03<00:00, 546.76it/s]
Adding requests:  96%|| 1963/2048 [00:03<00:00, 558.44it/s]
Adding requests:  99%|| 2019/2048 [00:03<00:00, 550.27it/s]
Adding requests: 100%|| 2048/2048 [00:03<00:00, 512.49it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 2/2048 [00:15<4:27:46,  7.85s/it, est. speed input: 130.40 toks/s, output: 0.13 toks/s]
Processed prompts:   1%|          | 18/2048 [00:35<1:00:15,  1.78s/it, est. speed input: 516.31 toks/s, output: 0.50 toks/s]
Processed prompts:   2%|         | 34/2048 [00:55<49:41,  1.48s/it, est. speed input: 624.84 toks/s, output: 0.61 toks/s]  
Processed prompts:   2%|         | 50/2048 [01:15<45:50,  1.38s/it, est. speed input: 676.31 toks/s, output: 0.66 toks/s]
Processed prompts:   3%|         | 66/2048 [01:35<43:57,  1.33s/it, est. speed input: 705.07 toks/s, output: 0.69 toks/s]
Processed prompts:   4%|         | 82/2048 [01:55<42:39,  1.30s/it, est. speed input: 724.74 toks/s, output: 0.71 toks/s]
Processed prompts:   5%|         | 98/2048 [02:15<41:47,  1.29s/it, est. speed input: 738.25 toks/s, output: 0.72 toks/s]
Processed prompts:   6%|         | 114/2048 [02:35<41:04,  1.27s/it, est. speed input: 748.61 toks/s, output: 0.73 toks/s]
Processed prompts:   6%|         | 130/2048 [02:55<40:31,  1.27s/it, est. speed input: 756.43 toks/s, output: 0.74 toks/s]
Processed prompts:   7%|         | 146/2048 [03:15<40:01,  1.26s/it, est. speed input: 762.78 toks/s, output: 0.74 toks/s]
Processed prompts:   8%|         | 162/2048 [03:36<39:34,  1.26s/it, est. speed input: 767.94 toks/s, output: 0.75 toks/s]
Processed prompts:   9%|         | 178/2048 [03:56<39:09,  1.26s/it, est. speed input: 772.22 toks/s, output: 0.75 toks/s]
Processed prompts:   9%|         | 194/2048 [04:23<43:19,  1.40s/it, est. speed input: 753.07 toks/s, output: 0.74 toks/s]
Processed prompts:  10%|         | 210/2048 [04:43<41:32,  1.36s/it, est. speed input: 757.68 toks/s, output: 0.74 toks/s]
Processed prompts:  11%|         | 226/2048 [05:03<40:13,  1.32s/it, est. speed input: 761.70 toks/s, output: 0.74 toks/s]
Processed prompts:  12%|        | 242/2048 [05:23<39:11,  1.30s/it, est. speed input: 765.21 toks/s, output: 0.75 toks/s]
Processed prompts:  13%|        | 258/2048 [05:43<38:23,  1.29s/it, est. speed input: 768.31 toks/s, output: 0.75 toks/s]
Processed prompts:  13%|        | 274/2048 [06:03<37:43,  1.28s/it, est. speed input: 771.07 toks/s, output: 0.75 toks/s]
Processed prompts:  14%|        | 290/2048 [06:23<37:10,  1.27s/it, est. speed input: 773.53 toks/s, output: 0.76 toks/s]
Processed prompts:  15%|        | 306/2048 [06:51<40:54,  1.41s/it, est. speed input: 761.13 toks/s, output: 0.74 toks/s]
Processed prompts:  16%|        | 322/2048 [07:11<39:10,  1.36s/it, est. speed input: 763.80 toks/s, output: 0.75 toks/s]
Processed prompts:  17%|        | 338/2048 [07:31<37:52,  1.33s/it, est. speed input: 766.17 toks/s, output: 0.75 toks/s]
Processed prompts:  17%|        | 354/2048 [07:51<36:52,  1.31s/it, est. speed input: 768.37 toks/s, output: 0.75 toks/s]
Processed prompts:  18%|        | 370/2048 [08:11<36:03,  1.29s/it, est. speed input: 770.42 toks/s, output: 0.75 toks/s]
Processed prompts:  19%|        | 386/2048 [08:31<35:23,  1.28s/it, est. speed input: 772.29 toks/s, output: 0.75 toks/s]
Processed prompts:  20%|        | 402/2048 [08:51<34:50,  1.27s/it, est. speed input: 774.04 toks/s, output: 0.76 toks/s]
Processed prompts:  20%|        | 418/2048 [09:11<34:20,  1.26s/it, est. speed input: 775.65 toks/s, output: 0.76 toks/s]
Processed prompts:  21%|        | 434/2048 [09:39<37:47,  1.40s/it, est. speed input: 766.81 toks/s, output: 0.75 toks/s]
Processed prompts:  22%|       | 450/2048 [09:59<36:11,  1.36s/it, est. speed input: 768.52 toks/s, output: 0.75 toks/s]
Processed prompts:  23%|       | 466/2048 [10:19<34:58,  1.33s/it, est. speed input: 770.13 toks/s, output: 0.75 toks/s]
Processed prompts:  24%|       | 482/2048 [10:39<34:02,  1.30s/it, est. speed input: 771.62 toks/s, output: 0.75 toks/s]
Processed prompts:  24%|       | 498/2048 [10:59<33:17,  1.29s/it, est. speed input: 773.01 toks/s, output: 0.75 toks/s]
Processed prompts:  25%|       | 514/2048 [11:19<32:39,  1.28s/it, est. speed input: 774.34 toks/s, output: 0.76 toks/s]
Processed prompts:  26%|       | 530/2048 [11:39<32:07,  1.27s/it, est. speed input: 775.61 toks/s, output: 0.76 toks/s]
Processed prompts:  27%|       | 546/2048 [11:59<31:38,  1.26s/it, est. speed input: 776.81 toks/s, output: 0.76 toks/s]
Processed prompts:  27%|       | 562/2048 [12:19<31:13,  1.26s/it, est. speed input: 777.88 toks/s, output: 0.76 toks/s]
Processed prompts:  28%|       | 578/2048 [12:39<30:49,  1.26s/it, est. speed input: 778.96 toks/s, output: 0.76 toks/s]
Processed prompts:  29%|       | 594/2048 [12:59<30:26,  1.26s/it, est. speed input: 779.96 toks/s, output: 0.76 toks/s]
Processed prompts:  30%|       | 610/2048 [13:19<30:04,  1.25s/it, est. speed input: 780.93 toks/s, output: 0.76 toks/s]
Processed prompts:  31%|       | 626/2048 [13:39<29:42,  1.25s/it, est. speed input: 781.84 toks/s, output: 0.76 toks/s]
Processed prompts:  31%|      | 642/2048 [13:59<29:21,  1.25s/it, est. speed input: 782.71 toks/s, output: 0.76 toks/s]
Processed prompts:  32%|      | 658/2048 [14:19<29:01,  1.25s/it, est. speed input: 783.53 toks/s, output: 0.77 toks/s]
Processed prompts:  33%|      | 674/2048 [14:39<28:40,  1.25s/it, est. speed input: 784.32 toks/s, output: 0.77 toks/s]
Processed prompts:  34%|      | 690/2048 [15:00<28:20,  1.25s/it, est. speed input: 785.05 toks/s, output: 0.77 toks/s]
Processed prompts:  34%|      | 706/2048 [15:20<28:00,  1.25s/it, est. speed input: 785.78 toks/s, output: 0.77 toks/s]
Processed prompts:  35%|      | 722/2048 [15:40<27:40,  1.25s/it, est. speed input: 786.46 toks/s, output: 0.77 toks/s]
Processed prompts:  36%|      | 738/2048 [16:00<27:19,  1.25s/it, est. speed input: 787.13 toks/s, output: 0.77 toks/s]
Processed prompts:  37%|      | 754/2048 [16:20<27:00,  1.25s/it, est. speed input: 787.75 toks/s, output: 0.77 toks/s]
Processed prompts:  38%|      | 770/2048 [16:40<26:39,  1.25s/it, est. speed input: 788.38 toks/s, output: 0.77 toks/s]
Processed prompts:  38%|      | 786/2048 [17:07<29:22,  1.40s/it, est. speed input: 783.03 toks/s, output: 0.76 toks/s]
Processed prompts:  39%|      | 802/2048 [17:27<28:05,  1.35s/it, est. speed input: 783.72 toks/s, output: 0.77 toks/s]
Processed prompts:  40%|      | 818/2048 [17:47<27:06,  1.32s/it, est. speed input: 784.35 toks/s, output: 0.77 toks/s]
Processed prompts:  41%|      | 834/2048 [18:07<26:19,  1.30s/it, est. speed input: 784.98 toks/s, output: 0.77 toks/s]
Processed prompts:  42%|     | 850/2048 [18:27<25:41,  1.29s/it, est. speed input: 785.57 toks/s, output: 0.77 toks/s]
Processed prompts:  42%|     | 866/2048 [18:47<25:07,  1.28s/it, est. speed input: 786.17 toks/s, output: 0.77 toks/s]
Processed prompts:  43%|     | 882/2048 [19:08<24:39,  1.27s/it, est. speed input: 786.72 toks/s, output: 0.77 toks/s]
Processed prompts:  44%|     | 898/2048 [19:28<24:12,  1.26s/it, est. speed input: 787.28 toks/s, output: 0.77 toks/s]
Processed prompts:  45%|     | 914/2048 [19:48<23:47,  1.26s/it, est. speed input: 787.81 toks/s, output: 0.77 toks/s]
Processed prompts:  45%|     | 930/2048 [20:08<23:25,  1.26s/it, est. speed input: 788.31 toks/s, output: 0.77 toks/s]
Processed prompts:  46%|     | 946/2048 [20:28<23:03,  1.26s/it, est. speed input: 788.78 toks/s, output: 0.77 toks/s]
Processed prompts:  47%|     | 962/2048 [20:48<22:42,  1.25s/it, est. speed input: 789.25 toks/s, output: 0.77 toks/s]
Processed prompts:  48%|     | 978/2048 [21:08<22:21,  1.25s/it, est. speed input: 789.71 toks/s, output: 0.77 toks/s]
Processed prompts:  49%|     | 994/2048 [21:28<22:00,  1.25s/it, est. speed input: 790.16 toks/s, output: 0.77 toks/s]
Processed prompts:  49%|     | 1010/2048 [21:48<21:39,  1.25s/it, est. speed input: 790.59 toks/s, output: 0.77 toks/s]
Processed prompts:  50%|     | 1026/2048 [22:08<21:19,  1.25s/it, est. speed input: 791.02 toks/s, output: 0.77 toks/s]
Processed prompts:  51%|     | 1042/2048 [22:28<20:59,  1.25s/it, est. speed input: 791.42 toks/s, output: 0.77 toks/s]
Processed prompts:  52%|    | 1058/2048 [22:48<20:38,  1.25s/it, est. speed input: 791.83 toks/s, output: 0.77 toks/s]
Processed prompts:  52%|    | 1074/2048 [23:08<20:18,  1.25s/it, est. speed input: 792.22 toks/s, output: 0.77 toks/s]
Processed prompts:  53%|    | 1090/2048 [23:28<19:58,  1.25s/it, est. speed input: 792.60 toks/s, output: 0.77 toks/s]
Processed prompts:  54%|    | 1106/2048 [23:48<19:38,  1.25s/it, est. speed input: 792.96 toks/s, output: 0.77 toks/s]
Processed prompts:  55%|    | 1122/2048 [24:08<19:18,  1.25s/it, est. speed input: 793.31 toks/s, output: 0.77 toks/s]
Processed prompts:  56%|    | 1138/2048 [24:28<18:58,  1.25s/it, est. speed input: 793.67 toks/s, output: 0.78 toks/s]
Processed prompts:  56%|    | 1154/2048 [24:48<18:38,  1.25s/it, est. speed input: 794.00 toks/s, output: 0.78 toks/s]
Processed prompts:  57%|    | 1170/2048 [25:08<18:18,  1.25s/it, est. speed input: 794.31 toks/s, output: 0.78 toks/s]
Processed prompts:  58%|    | 1186/2048 [25:28<17:58,  1.25s/it, est. speed input: 794.64 toks/s, output: 0.78 toks/s]
Processed prompts:  59%|    | 1202/2048 [25:56<19:40,  1.40s/it, est. speed input: 791.00 toks/s, output: 0.77 toks/s]
Processed prompts:  59%|    | 1218/2048 [26:16<18:42,  1.35s/it, est. speed input: 791.35 toks/s, output: 0.77 toks/s]
Processed prompts:  60%|    | 1234/2048 [26:43<19:53,  1.47s/it, est. speed input: 787.88 toks/s, output: 0.77 toks/s]
Processed prompts:  61%|    | 1250/2048 [27:03<18:38,  1.40s/it, est. speed input: 788.27 toks/s, output: 0.77 toks/s]
Processed prompts:  62%|   | 1266/2048 [27:23<17:40,  1.36s/it, est. speed input: 788.64 toks/s, output: 0.77 toks/s]
Processed prompts:  63%|   | 1282/2048 [27:43<16:55,  1.33s/it, est. speed input: 788.98 toks/s, output: 0.77 toks/s]
Processed prompts:  63%|   | 1298/2048 [28:03<16:17,  1.30s/it, est. speed input: 789.33 toks/s, output: 0.77 toks/s]
Processed prompts:  64%|   | 1314/2048 [28:23<15:45,  1.29s/it, est. speed input: 789.67 toks/s, output: 0.77 toks/s]
Processed prompts:  65%|   | 1330/2048 [28:51<17:01,  1.42s/it, est. speed input: 786.46 toks/s, output: 0.77 toks/s]
Processed prompts:  66%|   | 1346/2048 [29:11<16:02,  1.37s/it, est. speed input: 786.83 toks/s, output: 0.77 toks/s]
Processed prompts:  67%|   | 1362/2048 [29:31<15:15,  1.34s/it, est. speed input: 787.18 toks/s, output: 0.77 toks/s]
Processed prompts:  67%|   | 1378/2048 [29:51<14:37,  1.31s/it, est. speed input: 787.53 toks/s, output: 0.77 toks/s]
Processed prompts:  68%|   | 1394/2048 [30:11<14:05,  1.29s/it, est. speed input: 787.87 toks/s, output: 0.77 toks/s]
Processed prompts:  69%|   | 1410/2048 [30:31<13:36,  1.28s/it, est. speed input: 788.21 toks/s, output: 0.77 toks/s]
Processed prompts:  70%|   | 1426/2048 [30:51<13:10,  1.27s/it, est. speed input: 788.54 toks/s, output: 0.77 toks/s]
Processed prompts:  70%|   | 1442/2048 [31:19<14:14,  1.41s/it, est. speed input: 785.62 toks/s, output: 0.77 toks/s]
Processed prompts:  71%|   | 1458/2048 [31:47<14:49,  1.51s/it, est. speed input: 782.79 toks/s, output: 0.76 toks/s]
Processed prompts:  72%|  | 1474/2048 [32:07<13:40,  1.43s/it, est. speed input: 783.17 toks/s, output: 0.76 toks/s]
Processed prompts:  73%|  | 1490/2048 [32:27<12:47,  1.38s/it, est. speed input: 783.53 toks/s, output: 0.77 toks/s]
Processed prompts:  74%|  | 1506/2048 [32:47<12:05,  1.34s/it, est. speed input: 783.88 toks/s, output: 0.77 toks/s]
Processed prompts:  74%|  | 1522/2048 [33:15<12:46,  1.46s/it, est. speed input: 781.19 toks/s, output: 0.76 toks/s]
Processed prompts:  75%|  | 1538/2048 [33:35<11:51,  1.40s/it, est. speed input: 781.56 toks/s, output: 0.76 toks/s]
Processed prompts:  76%|  | 1554/2048 [34:02<12:19,  1.50s/it, est. speed input: 778.97 toks/s, output: 0.76 toks/s]
Processed prompts:  77%|  | 1570/2048 [34:22<11:20,  1.42s/it, est. speed input: 779.35 toks/s, output: 0.76 toks/s]
Processed prompts:  77%|  | 1586/2048 [34:42<10:33,  1.37s/it, est. speed input: 779.75 toks/s, output: 0.76 toks/s]
Processed prompts:  78%|  | 1602/2048 [35:02<09:55,  1.33s/it, est. speed input: 780.12 toks/s, output: 0.76 toks/s]
Processed prompts:  79%|  | 1618/2048 [35:30<10:25,  1.45s/it, est. speed input: 777.66 toks/s, output: 0.76 toks/s]
Processed prompts:  80%|  | 1634/2048 [35:50<09:36,  1.39s/it, est. speed input: 778.05 toks/s, output: 0.76 toks/s]
Processed prompts:  81%|  | 1650/2048 [36:10<08:57,  1.35s/it, est. speed input: 778.42 toks/s, output: 0.76 toks/s]
Processed prompts:  81%| | 1666/2048 [36:30<08:24,  1.32s/it, est. speed input: 778.79 toks/s, output: 0.76 toks/s]
Processed prompts:  82%| | 1682/2048 [36:50<07:55,  1.30s/it, est. speed input: 779.14 toks/s, output: 0.76 toks/s]
Processed prompts:  83%| | 1698/2048 [37:10<07:29,  1.29s/it, est. speed input: 779.49 toks/s, output: 0.76 toks/s]
Processed prompts:  84%| | 1714/2048 [37:30<07:05,  1.27s/it, est. speed input: 779.84 toks/s, output: 0.76 toks/s]
Processed prompts:  84%| | 1730/2048 [37:58<07:29,  1.41s/it, est. speed input: 777.54 toks/s, output: 0.76 toks/s]
Processed prompts:  85%| | 1746/2048 [38:24<07:25,  1.47s/it, est. speed input: 775.91 toks/s, output: 0.76 toks/s]
Processed prompts:  86%| | 1762/2048 [38:44<06:42,  1.41s/it, est. speed input: 776.28 toks/s, output: 0.76 toks/s]
Processed prompts:  87%| | 1778/2048 [39:04<06:07,  1.36s/it, est. speed input: 776.64 toks/s, output: 0.76 toks/s]
Processed prompts:  88%| | 1794/2048 [39:24<05:37,  1.33s/it, est. speed input: 776.99 toks/s, output: 0.76 toks/s]
Processed prompts:  88%| | 1810/2048 [39:44<05:10,  1.31s/it, est. speed input: 777.33 toks/s, output: 0.76 toks/s]
Processed prompts:  89%| | 1826/2048 [40:04<04:46,  1.29s/it, est. speed input: 777.68 toks/s, output: 0.76 toks/s]
Processed prompts:  90%| | 1842/2048 [40:24<04:23,  1.28s/it, est. speed input: 778.02 toks/s, output: 0.76 toks/s]
Processed prompts:  91%| | 1858/2048 [40:44<04:01,  1.27s/it, est. speed input: 778.36 toks/s, output: 0.76 toks/s]
Processed prompts:  92%|| 1874/2048 [41:04<03:39,  1.26s/it, est. speed input: 778.69 toks/s, output: 0.76 toks/s]
Processed prompts:  92%|| 1890/2048 [41:32<03:41,  1.40s/it, est. speed input: 776.59 toks/s, output: 0.76 toks/s]
Processed prompts:  93%|| 1906/2048 [41:52<03:12,  1.36s/it, est. speed input: 776.93 toks/s, output: 0.76 toks/s]
Processed prompts:  94%|| 1922/2048 [42:12<02:47,  1.33s/it, est. speed input: 777.27 toks/s, output: 0.76 toks/s]
Processed prompts:  95%|| 1938/2048 [42:32<02:23,  1.30s/it, est. speed input: 777.59 toks/s, output: 0.76 toks/s]
Processed prompts:  95%|| 1954/2048 [42:52<02:01,  1.29s/it, est. speed input: 777.90 toks/s, output: 0.76 toks/s]
Processed prompts:  96%|| 1970/2048 [43:12<01:39,  1.28s/it, est. speed input: 778.22 toks/s, output: 0.76 toks/s]
Processed prompts:  97%|| 1986/2048 [43:39<01:27,  1.41s/it, est. speed input: 776.22 toks/s, output: 0.76 toks/s]
Processed prompts:  98%|| 2002/2048 [43:59<01:02,  1.37s/it, est. speed input: 776.54 toks/s, output: 0.76 toks/s]
Processed prompts:  99%|| 2018/2048 [44:19<00:39,  1.33s/it, est. speed input: 776.86 toks/s, output: 0.76 toks/s]
Processed prompts:  99%|| 2034/2048 [44:47<00:20,  1.45s/it, est. speed input: 774.98 toks/s, output: 0.76 toks/s]
Processed prompts: 100%|| 2048/2048 [44:47<00:00,  1.45s/it, est. speed input: 780.32 toks/s, output: 0.76 toks/s]
Processed prompts: 100%|| 2048/2048 [44:47<00:00,  1.31s/it, est. speed input: 780.32 toks/s, output: 0.76 toks/s]
[rank0]:[W126 17:29:00.263386354 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 17:29:02
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 17:29:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 17:29:22 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1547769) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1547769) WARNING 01-26 17:30:54 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.76 requests/s, 5901.61 total tokens/s, 5.76 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 17:29:21] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 17:29:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 17:29:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 17:29:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:29:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:29:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:29:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:29:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:29:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 17:29:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 17:29:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 17:29:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 17:29:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 17:29:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 17:29:25] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 17:29:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 17:29:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 17:29:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:29:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:29:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:29:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:29:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:29:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 17:29:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 17:29:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 17:29:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 17:29:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 17:29:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1547769) [2026-01-26 17:29:26] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1547769) [2026-01-26 17:29:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1547769) [2026-01-26 17:29:26] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1547769) [2026-01-26 17:29:26] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1547769) [2026-01-26 17:29:26] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1547769) [2026-01-26 17:29:26] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1547769) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1547769) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.07s/it]
(EngineCore_DP0 pid=1547769) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:06<00:00, 33.88s/it]
(EngineCore_DP0 pid=1547769) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:06<00:00, 33.00s/it]
(EngineCore_DP0 pid=1547769) 
(EngineCore_DP0 pid=1547769) [2026-01-26 17:30:33] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1547769) [2026-01-26 17:30:33] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=1547769) [2026-01-26 17:30:33] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1547769) [2026-01-26 17:30:33] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=1547769) [2026-01-26 17:30:33] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1547769) [2026-01-26 17:30:33] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=1547769) [2026-01-26 17:30:33] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1547769) [2026-01-26 17:30:33] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=1547769) 2026-01-26 17:30:45,733 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1547769) 2026-01-26 17:30:47,739 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/4096 [00:01<1:17:21,  1.13s/it]
Adding requests:   0%|          | 2/4096 [00:01<44:24,  1.54it/s]  
Adding requests:   0%|          | 3/4096 [00:01<29:37,  2.30it/s]
Adding requests:   0%|          | 4/4096 [00:01<20:57,  3.26it/s]
Adding requests:   0%|          | 6/4096 [00:01<12:28,  5.46it/s]
Adding requests:   0%|          | 9/4096 [00:02<07:40,  8.88it/s]
Adding requests:   0%|          | 12/4096 [00:02<05:31, 12.32it/s]
Adding requests:   0%|          | 17/4096 [00:02<03:30, 19.38it/s]
Adding requests:   1%|          | 30/4096 [00:02<01:34, 43.16it/s]
Adding requests:   1%|          | 45/4096 [00:02<00:59, 68.11it/s]
Adding requests:   2%|         | 64/4096 [00:02<00:41, 97.51it/s]
Adding requests:   2%|         | 81/4096 [00:02<00:34, 116.20it/s]
Adding requests:   3%|         | 111/4096 [00:02<00:24, 164.53it/s]
Adding requests:   3%|         | 140/4096 [00:02<00:19, 197.97it/s]
Adding requests:   4%|         | 177/4096 [00:02<00:15, 245.08it/s]
Adding requests:   5%|         | 216/4096 [00:03<00:13, 285.53it/s]
Adding requests:   6%|         | 259/4096 [00:03<00:11, 326.91it/s]
Adding requests:   7%|         | 299/4096 [00:03<00:10, 348.05it/s]
Adding requests:   8%|         | 344/4096 [00:03<00:09, 376.90it/s]
Adding requests:  10%|         | 391/4096 [00:03<00:09, 403.52it/s]
Adding requests:  11%|         | 440/4096 [00:03<00:08, 427.17it/s]
Adding requests:  12%|        | 486/4096 [00:03<00:08, 436.20it/s]
Adding requests:  13%|        | 535/4096 [00:03<00:07, 450.01it/s]
Adding requests:  14%|        | 581/4096 [00:03<00:08, 438.38it/s]
Adding requests:  15%|        | 625/4096 [00:04<00:07, 437.01it/s]
Adding requests:  16%|        | 669/4096 [00:04<00:08, 427.50it/s]
Adding requests:  17%|        | 712/4096 [00:04<00:08, 410.15it/s]
Adding requests:  18%|        | 754/4096 [00:04<00:08, 404.96it/s]
Adding requests:  20%|        | 799/4096 [00:04<00:07, 416.30it/s]
Adding requests:  21%|        | 846/4096 [00:04<00:07, 431.12it/s]
Adding requests:  22%|       | 890/4096 [00:04<00:07, 431.67it/s]
Adding requests:  23%|       | 934/4096 [00:04<00:07, 428.22it/s]
Adding requests:  24%|       | 979/4096 [00:04<00:07, 432.90it/s]
Adding requests:  25%|       | 1023/4096 [00:04<00:07, 433.99it/s]
Adding requests:  26%|       | 1067/4096 [00:05<00:07, 427.49it/s]
Adding requests:  27%|       | 1111/4096 [00:05<00:06, 429.85it/s]
Adding requests:  28%|       | 1155/4096 [00:05<00:06, 430.05it/s]
Adding requests:  29%|       | 1199/4096 [00:05<00:06, 427.00it/s]
Adding requests:  30%|       | 1242/4096 [00:05<00:06, 422.69it/s]
Adding requests:  31%|      | 1285/4096 [00:05<00:06, 418.45it/s]
Adding requests:  32%|      | 1327/4096 [00:05<00:07, 384.21it/s]
Adding requests:  33%|      | 1368/4096 [00:05<00:07, 387.78it/s]
Adding requests:  34%|      | 1410/4096 [00:05<00:06, 393.85it/s]
Adding requests:  35%|      | 1452/4096 [00:06<00:06, 399.02it/s]
Adding requests:  37%|      | 1497/4096 [00:06<00:06, 411.47it/s]
Adding requests:  38%|      | 1540/4096 [00:06<00:06, 415.90it/s]
Adding requests:  39%|      | 1583/4096 [00:06<00:06, 418.14it/s]
Adding requests:  40%|      | 1625/4096 [00:06<00:06, 408.80it/s]
Adding requests:  41%|      | 1667/4096 [00:06<00:05, 411.37it/s]
Adding requests:  42%|     | 1711/4096 [00:06<00:05, 418.33it/s]
Adding requests:  43%|     | 1756/4096 [00:06<00:05, 427.54it/s]
Adding requests:  44%|     | 1799/4096 [00:06<00:05, 419.88it/s]
Adding requests:  45%|     | 1842/4096 [00:06<00:05, 419.83it/s]
Adding requests:  46%|     | 1885/4096 [00:07<00:05, 421.37it/s]
Adding requests:  47%|     | 1930/4096 [00:07<00:05, 429.77it/s]
Adding requests:  48%|     | 1974/4096 [00:07<00:04, 428.49it/s]
Adding requests:  49%|     | 2017/4096 [00:07<00:04, 424.81it/s]
Adding requests:  50%|     | 2060/4096 [00:07<00:04, 420.01it/s]
Adding requests:  51%|    | 2104/4096 [00:07<00:04, 425.02it/s]
Adding requests:  52%|    | 2147/4096 [00:07<00:04, 422.40it/s]
Adding requests:  53%|    | 2190/4096 [00:07<00:04, 409.91it/s]
Adding requests:  54%|    | 2232/4096 [00:07<00:04, 402.01it/s]
Adding requests:  56%|    | 2276/4096 [00:07<00:04, 411.07it/s]
Adding requests:  57%|    | 2321/4096 [00:08<00:04, 421.36it/s]
Adding requests:  58%|    | 2369/4096 [00:08<00:03, 437.04it/s]
Adding requests:  59%|    | 2413/4096 [00:08<00:03, 430.82it/s]
Adding requests:  60%|    | 2457/4096 [00:08<00:03, 432.52it/s]
Adding requests:  61%|    | 2502/4096 [00:08<00:03, 435.01it/s]
Adding requests:  62%|   | 2546/4096 [00:08<00:03, 405.42it/s]
Adding requests:  63%|   | 2588/4096 [00:08<00:03, 409.35it/s]
Adding requests:  64%|   | 2632/4096 [00:08<00:03, 416.38it/s]
Adding requests:  65%|   | 2675/4096 [00:08<00:03, 418.85it/s]
Adding requests:  66%|   | 2718/4096 [00:09<00:03, 420.38it/s]
Adding requests:  67%|   | 2764/4096 [00:09<00:03, 431.81it/s]
Adding requests:  69%|   | 2808/4096 [00:09<00:02, 429.85it/s]
Adding requests:  70%|   | 2853/4096 [00:09<00:02, 433.12it/s]
Adding requests:  71%|   | 2897/4096 [00:09<00:02, 434.99it/s]
Adding requests:  72%|  | 2942/4096 [00:09<00:02, 437.70it/s]
Adding requests:  73%|  | 2987/4096 [00:09<00:02, 437.63it/s]
Adding requests:  74%|  | 3032/4096 [00:09<00:02, 439.68it/s]
Adding requests:  75%|  | 3077/4096 [00:09<00:02, 441.55it/s]
Adding requests:  76%|  | 3123/4096 [00:09<00:02, 445.64it/s]
Adding requests:  77%|  | 3168/4096 [00:10<00:02, 441.90it/s]
Adding requests:  78%|  | 3213/4096 [00:10<00:02, 435.85it/s]
Adding requests:  80%|  | 3258/4096 [00:10<00:01, 437.20it/s]
Adding requests:  81%|  | 3302/4096 [00:10<00:01, 430.48it/s]
Adding requests:  82%| | 3346/4096 [00:10<00:01, 430.76it/s]
Adding requests:  83%| | 3391/4096 [00:10<00:01, 434.81it/s]
Adding requests:  84%| | 3435/4096 [00:10<00:01, 427.47it/s]
Adding requests:  85%| | 3482/4096 [00:10<00:01, 439.64it/s]
Adding requests:  86%| | 3527/4096 [00:10<00:01, 434.63it/s]
Adding requests:  87%| | 3573/4096 [00:10<00:01, 438.85it/s]
Adding requests:  88%| | 3617/4096 [00:11<00:01, 427.67it/s]
Adding requests:  89%| | 3661/4096 [00:11<00:01, 428.61it/s]
Adding requests:  90%| | 3704/4096 [00:11<00:00, 426.41it/s]
Adding requests:  91%|| 3747/4096 [00:11<00:00, 426.79it/s]
Adding requests:  93%|| 3790/4096 [00:11<00:00, 414.05it/s]
Adding requests:  94%|| 3832/4096 [00:11<00:00, 401.56it/s]
Adding requests:  95%|| 3875/4096 [00:11<00:00, 407.47it/s]
Adding requests:  96%|| 3916/4096 [00:11<00:00, 406.03it/s]
Adding requests:  97%|| 3957/4096 [00:11<00:00, 394.30it/s]
Adding requests:  98%|| 3999/4096 [00:12<00:00, 399.97it/s]
Adding requests:  99%|| 4042/4096 [00:12<00:00, 408.36it/s]
Adding requests: 100%|| 4083/4096 [00:12<00:00, 404.58it/s]
Adding requests: 100%|| 4096/4096 [00:12<00:00, 334.26it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 40/4096 [00:01<02:20, 28.84it/s, est. speed input: 29533.93 toks/s, output: 28.84 toks/s]
Processed prompts:   2%|         | 72/4096 [00:06<07:17,  9.21it/s, est. speed input: 10633.27 toks/s, output: 10.38 toks/s]
Processed prompts:   3%|         | 104/4096 [00:12<09:05,  7.31it/s, est. speed input: 8525.77 toks/s, output: 8.33 toks/s] 
Processed prompts:   3%|         | 136/4096 [00:18<09:57,  6.63it/s, est. speed input: 7716.56 toks/s, output: 7.54 toks/s]
Processed prompts:   4%|         | 168/4096 [00:23<10:24,  6.29it/s, est. speed input: 7284.52 toks/s, output: 7.11 toks/s]
Processed prompts:   5%|         | 200/4096 [00:29<10:33,  6.15it/s, est. speed input: 7048.87 toks/s, output: 6.88 toks/s]
Processed prompts:   6%|         | 232/4096 [00:34<10:43,  6.01it/s, est. speed input: 6860.01 toks/s, output: 6.70 toks/s]
Processed prompts:   6%|         | 264/4096 [00:40<10:47,  5.92it/s, est. speed input: 6723.33 toks/s, output: 6.57 toks/s]
Processed prompts:   7%|         | 296/4096 [00:45<10:42,  5.91it/s, est. speed input: 6640.99 toks/s, output: 6.49 toks/s]
Processed prompts:   8%|         | 328/4096 [00:51<10:43,  5.85it/s, est. speed input: 6556.74 toks/s, output: 6.40 toks/s]
Processed prompts:   9%|         | 360/4096 [00:56<10:42,  5.81it/s, est. speed input: 6488.52 toks/s, output: 6.34 toks/s]
Processed prompts:  10%|         | 392/4096 [01:02<10:39,  5.79it/s, est. speed input: 6434.33 toks/s, output: 6.28 toks/s]
Processed prompts:  10%|         | 424/4096 [01:07<10:30,  5.82it/s, est. speed input: 6401.40 toks/s, output: 6.25 toks/s]
Processed prompts:  11%|         | 456/4096 [01:13<10:28,  5.79it/s, est. speed input: 6360.54 toks/s, output: 6.21 toks/s]
Processed prompts:  12%|        | 488/4096 [01:19<10:25,  5.77it/s, est. speed input: 6325.26 toks/s, output: 6.18 toks/s]
Processed prompts:  13%|        | 520/4096 [01:24<10:20,  5.76it/s, est. speed input: 6295.53 toks/s, output: 6.15 toks/s]
Processed prompts:  13%|        | 552/4096 [01:30<10:16,  5.75it/s, est. speed input: 6267.74 toks/s, output: 6.12 toks/s]
Processed prompts:  14%|        | 584/4096 [01:35<10:11,  5.74it/s, est. speed input: 6244.15 toks/s, output: 6.10 toks/s]
Processed prompts:  15%|        | 616/4096 [01:41<10:06,  5.74it/s, est. speed input: 6223.13 toks/s, output: 6.08 toks/s]
Processed prompts:  16%|        | 648/4096 [01:46<10:01,  5.73it/s, est. speed input: 6203.87 toks/s, output: 6.06 toks/s]
Processed prompts:  17%|        | 680/4096 [01:52<09:56,  5.73it/s, est. speed input: 6186.47 toks/s, output: 6.04 toks/s]
Processed prompts:  17%|        | 712/4096 [01:58<09:51,  5.72it/s, est. speed input: 6170.92 toks/s, output: 6.03 toks/s]
Processed prompts:  18%|        | 744/4096 [02:03<09:45,  5.72it/s, est. speed input: 6156.51 toks/s, output: 6.01 toks/s]
Processed prompts:  19%|        | 776/4096 [02:09<09:35,  5.77it/s, est. speed input: 6150.85 toks/s, output: 6.01 toks/s]
Processed prompts:  20%|        | 808/4096 [02:14<09:31,  5.75it/s, est. speed input: 6138.36 toks/s, output: 5.99 toks/s]
Processed prompts:  21%|        | 840/4096 [02:20<09:26,  5.74it/s, est. speed input: 6127.44 toks/s, output: 5.98 toks/s]
Processed prompts:  21%|       | 872/4096 [02:25<09:21,  5.74it/s, est. speed input: 6117.55 toks/s, output: 5.97 toks/s]
Processed prompts:  22%|       | 904/4096 [02:31<09:16,  5.73it/s, est. speed input: 6108.04 toks/s, output: 5.96 toks/s]
Processed prompts:  23%|       | 936/4096 [02:37<09:11,  5.73it/s, est. speed input: 6099.21 toks/s, output: 5.96 toks/s]
Processed prompts:  24%|       | 968/4096 [02:42<09:05,  5.73it/s, est. speed input: 6091.21 toks/s, output: 5.95 toks/s]
Processed prompts:  24%|       | 1000/4096 [02:48<09:00,  5.73it/s, est. speed input: 6083.40 toks/s, output: 5.94 toks/s]
Processed prompts:  25%|       | 1032/4096 [02:53<08:55,  5.72it/s, est. speed input: 6075.89 toks/s, output: 5.93 toks/s]
Processed prompts:  26%|       | 1064/4096 [02:59<08:49,  5.72it/s, est. speed input: 6069.37 toks/s, output: 5.93 toks/s]
Processed prompts:  27%|       | 1096/4096 [03:05<08:43,  5.73it/s, est. speed input: 6063.43 toks/s, output: 5.92 toks/s]
Processed prompts:  28%|       | 1128/4096 [03:10<08:38,  5.73it/s, est. speed input: 6057.50 toks/s, output: 5.92 toks/s]
Processed prompts:  28%|       | 1160/4096 [03:16<08:32,  5.72it/s, est. speed input: 6051.79 toks/s, output: 5.91 toks/s]
Processed prompts:  29%|       | 1192/4096 [03:21<08:23,  5.77it/s, est. speed input: 6050.98 toks/s, output: 5.91 toks/s]
Processed prompts:  30%|       | 1224/4096 [03:27<08:14,  5.80it/s, est. speed input: 6050.21 toks/s, output: 5.91 toks/s]
Processed prompts:  31%|       | 1256/4096 [03:32<08:11,  5.78it/s, est. speed input: 6045.48 toks/s, output: 5.90 toks/s]
Processed prompts:  31%|      | 1288/4096 [03:38<08:07,  5.77it/s, est. speed input: 6040.84 toks/s, output: 5.90 toks/s]
Processed prompts:  32%|      | 1320/4096 [03:43<07:58,  5.80it/s, est. speed input: 6040.21 toks/s, output: 5.90 toks/s]
Processed prompts:  33%|      | 1352/4096 [03:49<07:55,  5.78it/s, est. speed input: 6035.97 toks/s, output: 5.89 toks/s]
Processed prompts:  34%|      | 1384/4096 [03:54<07:50,  5.76it/s, est. speed input: 6031.83 toks/s, output: 5.89 toks/s]
Processed prompts:  35%|      | 1416/4096 [04:00<07:42,  5.80it/s, est. speed input: 6031.55 toks/s, output: 5.89 toks/s]
Processed prompts:  35%|      | 1448/4096 [04:05<07:34,  5.82it/s, est. speed input: 6031.37 toks/s, output: 5.89 toks/s]
Processed prompts:  36%|      | 1480/4096 [04:11<07:31,  5.79it/s, est. speed input: 6027.45 toks/s, output: 5.89 toks/s]
Processed prompts:  37%|      | 1512/4096 [04:16<07:24,  5.82it/s, est. speed input: 6027.42 toks/s, output: 5.89 toks/s]
Processed prompts:  38%|      | 1544/4096 [04:22<07:17,  5.83it/s, est. speed input: 6027.11 toks/s, output: 5.89 toks/s]
Processed prompts:  38%|      | 1576/4096 [04:27<07:14,  5.80it/s, est. speed input: 6023.56 toks/s, output: 5.88 toks/s]
Processed prompts:  39%|      | 1608/4096 [04:33<07:07,  5.82it/s, est. speed input: 6023.56 toks/s, output: 5.88 toks/s]
Processed prompts:  40%|      | 1640/4096 [04:38<07:03,  5.79it/s, est. speed input: 6020.24 toks/s, output: 5.88 toks/s]
Processed prompts:  41%|      | 1672/4096 [04:44<07:00,  5.77it/s, est. speed input: 6017.00 toks/s, output: 5.88 toks/s]
Processed prompts:  42%|     | 1704/4096 [04:50<06:55,  5.76it/s, est. speed input: 6014.17 toks/s, output: 5.87 toks/s]
Processed prompts:  42%|     | 1736/4096 [04:55<06:39,  5.90it/s, est. speed input: 6021.17 toks/s, output: 5.88 toks/s]
Processed prompts:  43%|     | 1768/4096 [05:00<06:38,  5.85it/s, est. speed input: 6018.19 toks/s, output: 5.88 toks/s]
Processed prompts:  44%|     | 1800/4096 [05:06<06:35,  5.81it/s, est. speed input: 6015.15 toks/s, output: 5.87 toks/s]
Processed prompts:  45%|     | 1832/4096 [05:12<06:31,  5.78it/s, est. speed input: 6012.51 toks/s, output: 5.87 toks/s]
Processed prompts:  46%|     | 1864/4096 [05:17<06:24,  5.81it/s, est. speed input: 6012.56 toks/s, output: 5.87 toks/s]
Processed prompts:  46%|     | 1896/4096 [05:23<06:20,  5.78it/s, est. speed input: 6009.86 toks/s, output: 5.87 toks/s]
Processed prompts:  47%|     | 1928/4096 [05:28<06:16,  5.76it/s, est. speed input: 6007.11 toks/s, output: 5.87 toks/s]
Processed prompts:  48%|     | 1960/4096 [05:34<06:08,  5.80it/s, est. speed input: 6007.30 toks/s, output: 5.87 toks/s]
Processed prompts:  49%|     | 1992/4096 [05:39<06:04,  5.78it/s, est. speed input: 6005.00 toks/s, output: 5.86 toks/s]
Processed prompts:  49%|     | 2024/4096 [05:45<05:59,  5.76it/s, est. speed input: 6002.53 toks/s, output: 5.86 toks/s]
Processed prompts:  50%|     | 2056/4096 [05:50<05:52,  5.79it/s, est. speed input: 6002.71 toks/s, output: 5.86 toks/s]
Processed prompts:  51%|     | 2088/4096 [05:56<05:47,  5.77it/s, est. speed input: 6000.54 toks/s, output: 5.86 toks/s]
Processed prompts:  52%|    | 2120/4096 [06:01<05:43,  5.76it/s, est. speed input: 5998.39 toks/s, output: 5.86 toks/s]
Processed prompts:  53%|    | 2152/4096 [06:07<05:38,  5.75it/s, est. speed input: 5996.34 toks/s, output: 5.86 toks/s]
Processed prompts:  53%|    | 2184/4096 [06:12<05:30,  5.79it/s, est. speed input: 5996.61 toks/s, output: 5.86 toks/s]
Processed prompts:  54%|    | 2216/4096 [06:18<05:26,  5.76it/s, est. speed input: 5994.52 toks/s, output: 5.85 toks/s]
Processed prompts:  55%|    | 2248/4096 [06:24<05:21,  5.75it/s, est. speed input: 5992.42 toks/s, output: 5.85 toks/s]
Processed prompts:  56%|    | 2280/4096 [06:29<05:16,  5.74it/s, est. speed input: 5990.61 toks/s, output: 5.85 toks/s]
Processed prompts:  56%|    | 2312/4096 [06:35<05:11,  5.73it/s, est. speed input: 5988.61 toks/s, output: 5.85 toks/s]
Processed prompts:  57%|    | 2344/4096 [06:40<05:03,  5.77it/s, est. speed input: 5988.86 toks/s, output: 5.85 toks/s]
Processed prompts:  58%|    | 2376/4096 [06:46<04:58,  5.75it/s, est. speed input: 5986.94 toks/s, output: 5.85 toks/s]
Processed prompts:  59%|    | 2408/4096 [06:51<04:53,  5.75it/s, est. speed input: 5985.29 toks/s, output: 5.85 toks/s]
Processed prompts:  60%|    | 2440/4096 [06:57<04:48,  5.73it/s, est. speed input: 5983.38 toks/s, output: 5.84 toks/s]
Processed prompts:  60%|    | 2472/4096 [07:03<04:43,  5.73it/s, est. speed input: 5981.80 toks/s, output: 5.84 toks/s]
Processed prompts:  61%|    | 2504/4096 [07:08<04:37,  5.73it/s, est. speed input: 5980.12 toks/s, output: 5.84 toks/s]
Processed prompts:  62%|   | 2536/4096 [07:14<04:30,  5.77it/s, est. speed input: 5980.53 toks/s, output: 5.84 toks/s]
Processed prompts:  63%|   | 2568/4096 [07:19<04:25,  5.75it/s, est. speed input: 5978.96 toks/s, output: 5.84 toks/s]
Processed prompts:  63%|   | 2600/4096 [07:25<04:18,  5.79it/s, est. speed input: 5979.46 toks/s, output: 5.84 toks/s]
Processed prompts:  64%|   | 2632/4096 [07:30<04:11,  5.82it/s, est. speed input: 5979.92 toks/s, output: 5.84 toks/s]
Processed prompts:  65%|   | 2664/4096 [07:36<04:07,  5.79it/s, est. speed input: 5978.41 toks/s, output: 5.84 toks/s]
Processed prompts:  66%|   | 2696/4096 [07:41<04:02,  5.77it/s, est. speed input: 5976.93 toks/s, output: 5.84 toks/s]
Processed prompts:  67%|   | 2728/4096 [07:47<03:55,  5.80it/s, est. speed input: 5977.33 toks/s, output: 5.84 toks/s]
Processed prompts:  67%|   | 2760/4096 [07:52<03:51,  5.77it/s, est. speed input: 5975.80 toks/s, output: 5.84 toks/s]
Processed prompts:  68%|   | 2792/4096 [07:58<03:46,  5.76it/s, est. speed input: 5974.50 toks/s, output: 5.83 toks/s]
Processed prompts:  69%|   | 2824/4096 [08:04<03:41,  5.75it/s, est. speed input: 5973.14 toks/s, output: 5.83 toks/s]
Processed prompts:  70%|   | 2856/4096 [08:09<03:36,  5.74it/s, est. speed input: 5971.74 toks/s, output: 5.83 toks/s]
Processed prompts:  71%|   | 2888/4096 [08:15<03:27,  5.83it/s, est. speed input: 5974.30 toks/s, output: 5.83 toks/s]
Processed prompts:  71%|  | 2920/4096 [08:20<03:21,  5.84it/s, est. speed input: 5974.67 toks/s, output: 5.83 toks/s]
Processed prompts:  72%|  | 2952/4096 [08:26<03:17,  5.80it/s, est. speed input: 5973.29 toks/s, output: 5.83 toks/s]
Processed prompts:  73%|  | 2984/4096 [08:31<03:11,  5.81it/s, est. speed input: 5973.23 toks/s, output: 5.83 toks/s]
Processed prompts:  74%|  | 3016/4096 [08:37<03:06,  5.78it/s, est. speed input: 5971.90 toks/s, output: 5.83 toks/s]
Processed prompts:  74%|  | 3048/4096 [08:42<03:01,  5.76it/s, est. speed input: 5970.69 toks/s, output: 5.83 toks/s]
Processed prompts:  75%|  | 3080/4096 [08:48<02:56,  5.75it/s, est. speed input: 5969.47 toks/s, output: 5.83 toks/s]
Processed prompts:  76%|  | 3112/4096 [08:53<02:51,  5.74it/s, est. speed input: 5968.24 toks/s, output: 5.83 toks/s]
Processed prompts:  77%|  | 3144/4096 [08:59<02:46,  5.73it/s, est. speed input: 5967.10 toks/s, output: 5.83 toks/s]
Processed prompts:  78%|  | 3176/4096 [09:04<02:39,  5.78it/s, est. speed input: 5967.59 toks/s, output: 5.83 toks/s]
Processed prompts:  78%|  | 3208/4096 [09:10<02:34,  5.76it/s, est. speed input: 5966.53 toks/s, output: 5.83 toks/s]
Processed prompts:  79%|  | 3240/4096 [09:16<02:28,  5.75it/s, est. speed input: 5965.43 toks/s, output: 5.83 toks/s]
Processed prompts:  80%|  | 3272/4096 [09:21<02:23,  5.74it/s, est. speed input: 5964.20 toks/s, output: 5.82 toks/s]
Processed prompts:  81%|  | 3304/4096 [09:27<02:18,  5.73it/s, est. speed input: 5963.22 toks/s, output: 5.82 toks/s]
Processed prompts:  81%| | 3336/4096 [09:32<02:12,  5.73it/s, est. speed input: 5962.11 toks/s, output: 5.82 toks/s]
Processed prompts:  82%| | 3368/4096 [09:38<02:07,  5.72it/s, est. speed input: 5961.09 toks/s, output: 5.82 toks/s]
Processed prompts:  83%| | 3400/4096 [09:44<02:00,  5.77it/s, est. speed input: 5961.49 toks/s, output: 5.82 toks/s]
Processed prompts:  84%| | 3432/4096 [09:49<01:55,  5.75it/s, est. speed input: 5960.47 toks/s, output: 5.82 toks/s]
Processed prompts:  85%| | 3464/4096 [09:55<01:50,  5.74it/s, est. speed input: 5959.45 toks/s, output: 5.82 toks/s]
Processed prompts:  85%| | 3496/4096 [10:00<01:44,  5.73it/s, est. speed input: 5958.47 toks/s, output: 5.82 toks/s]
Processed prompts:  86%| | 3528/4096 [10:06<01:39,  5.73it/s, est. speed input: 5957.59 toks/s, output: 5.82 toks/s]
Processed prompts:  87%| | 3560/4096 [10:11<01:32,  5.77it/s, est. speed input: 5958.14 toks/s, output: 5.82 toks/s]
Processed prompts:  88%| | 3592/4096 [10:17<01:27,  5.76it/s, est. speed input: 5957.20 toks/s, output: 5.82 toks/s]
Processed prompts:  88%| | 3624/4096 [10:23<01:22,  5.74it/s, est. speed input: 5956.23 toks/s, output: 5.82 toks/s]
Processed prompts:  89%| | 3656/4096 [10:28<01:16,  5.74it/s, est. speed input: 5955.34 toks/s, output: 5.82 toks/s]
Processed prompts:  90%| | 3688/4096 [10:33<01:09,  5.83it/s, est. speed input: 5957.50 toks/s, output: 5.82 toks/s]
Processed prompts:  91%| | 3720/4096 [10:39<01:04,  5.80it/s, est. speed input: 5956.59 toks/s, output: 5.82 toks/s]
Processed prompts:  92%|| 3752/4096 [10:45<00:59,  5.77it/s, est. speed input: 5955.70 toks/s, output: 5.82 toks/s]
Processed prompts:  92%|| 3784/4096 [10:50<00:54,  5.76it/s, est. speed input: 5954.83 toks/s, output: 5.82 toks/s]
Processed prompts:  93%|| 3816/4096 [10:56<00:48,  5.74it/s, est. speed input: 5953.97 toks/s, output: 5.81 toks/s]
Processed prompts:  94%|| 3848/4096 [11:01<00:43,  5.74it/s, est. speed input: 5953.21 toks/s, output: 5.81 toks/s]
Processed prompts:  95%|| 3880/4096 [11:07<00:37,  5.73it/s, est. speed input: 5952.29 toks/s, output: 5.81 toks/s]
Processed prompts:  96%|| 3912/4096 [11:12<00:31,  5.77it/s, est. speed input: 5952.73 toks/s, output: 5.81 toks/s]
Processed prompts:  96%|| 3944/4096 [11:18<00:26,  5.80it/s, est. speed input: 5953.23 toks/s, output: 5.81 toks/s]
Processed prompts:  97%|| 3976/4096 [11:23<00:20,  5.77it/s, est. speed input: 5952.39 toks/s, output: 5.81 toks/s]
Processed prompts:  98%|| 4008/4096 [11:29<00:15,  5.80it/s, est. speed input: 5952.82 toks/s, output: 5.81 toks/s]
Processed prompts:  99%|| 4040/4096 [11:34<00:09,  5.82it/s, est. speed input: 5953.32 toks/s, output: 5.81 toks/s]
Processed prompts:  99%|| 4072/4096 [11:39<00:03,  6.25it/s, est. speed input: 5964.07 toks/s, output: 5.82 toks/s]
Processed prompts: 100%|| 4096/4096 [11:39<00:00,  6.25it/s, est. speed input: 5999.22 toks/s, output: 5.86 toks/s]
Processed prompts: 100%|| 4096/4096 [11:39<00:00,  5.86it/s, est. speed input: 5999.22 toks/s, output: 5.86 toks/s]
[rank0]:[W126 17:42:56.364303827 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 17:43:02
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 17:43:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 17:43:35 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1559654) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 303, in forward
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     hidden_states = self.mlp(hidden_states)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 108, in forward
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     x, _ = self.down_proj(x)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1405, in forward
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     output_parallel = self.quant_method.apply(self, input_parallel, bias_)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 349, in quant_slide_int8_triton
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]     out = torch.zeros(M_padded, K_out_padded, dtype=torch.int8, device=x.device)
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866] Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=1559654) ERROR 01-26 17:44:50 [core.py:866] 

STDERR:
[2026-01-26 17:43:35] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 17:43:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 17:43:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 17:43:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:43:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:43:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:43:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:43:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:43:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 17:43:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 17:43:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 17:43:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 17:43:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 17:43:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 17:43:38] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 17:43:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 17:43:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 17:43:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:43:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:43:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:43:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:43:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 17:43:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 17:43:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 17:43:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 17:43:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 17:43:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 17:43:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1559654) [2026-01-26 17:43:39] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1559654) [2026-01-26 17:43:39] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1559654) [2026-01-26 17:43:39] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1559654) [2026-01-26 17:43:39] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1559654) [2026-01-26 17:43:39] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1559654) [2026-01-26 17:43:39] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1559654) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1559654) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.97s/it]
(EngineCore_DP0 pid=1559654) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:07<00:00, 34.42s/it]
(EngineCore_DP0 pid=1559654) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:07<00:00, 33.61s/it]
(EngineCore_DP0 pid=1559654) 
(EngineCore_DP0 pid=1559654) [2026-01-26 17:44:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1559654) [2026-01-26 17:44:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=1559654) [2026-01-26 17:44:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1559654) [2026-01-26 17:44:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=1559654) [2026-01-26 17:44:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1559654) [2026-01-26 17:44:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=1559654) [2026-01-26 17:44:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1559654) [2026-01-26 17:44:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=1559654) Process EngineCore_DP0:
(EngineCore_DP0 pid=1559654) Traceback (most recent call last):
(EngineCore_DP0 pid=1559654)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=1559654)     self.run()
(EngineCore_DP0 pid=1559654)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=1559654)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=1559654)     raise e
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1559654)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1559654)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1559654)     super().__init__(
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1559654)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1559654)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1559654)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1559654)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1559654)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1559654)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1559654)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1559654)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1559654)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1559654)     self.model_runner.profile_run()
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1559654)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1559654)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1559654)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1559654)     outputs = self.model(
(EngineCore_DP0 pid=1559654)               ^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1559654)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1559654)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1559654)     hidden_states = self.model(
(EngineCore_DP0 pid=1559654)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=1559654)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=1559654)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=1559654)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1559654)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1559654)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 303, in forward
(EngineCore_DP0 pid=1559654)     hidden_states = self.mlp(hidden_states)
(EngineCore_DP0 pid=1559654)                     ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1559654)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1559654)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 108, in forward
(EngineCore_DP0 pid=1559654)     x, _ = self.down_proj(x)
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1559654)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1559654)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1405, in forward
(EngineCore_DP0 pid=1559654)     output_parallel = self.quant_method.apply(self, input_parallel, bias_)
(EngineCore_DP0 pid=1559654)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=1559654)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=1559654)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=1559654)     return self._linear_fn(
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=1559654)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=1559654)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=1559654)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=1559654)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=1559654)     return fn(input, L)
(EngineCore_DP0 pid=1559654)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 349, in quant_slide_int8_triton
(EngineCore_DP0 pid=1559654)     out = torch.zeros(M_padded, K_out_padded, dtype=torch.int8, device=x.device)
(EngineCore_DP0 pid=1559654)           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1559654) torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=1559654) Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=1559654) CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=1559654) For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=1559654) Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=1559654) 
[rank0]:[W126 17:44:51.286741001 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-27 04:15:26
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 04:15:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 04:15:33 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2098367) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2098367) WARNING 01-27 04:17:57 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.60 requests/s, 2873.43 total tokens/s, 5.60 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-27 04:15:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 04:15:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:15:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 04:15:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:15:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:15:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:15:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:15:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:15:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:15:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 04:15:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 04:15:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 04:15:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 04:15:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 04:15:36] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 04:15:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:15:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 04:15:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:15:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:15:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:15:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:15:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:15:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:15:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 04:15:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 04:15:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 04:15:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 04:15:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2098367) [2026-01-27 04:15:37] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2098367) [2026-01-27 04:15:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2098367) [2026-01-27 04:15:37] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2098367) [2026-01-27 04:15:37] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=2098367) [2026-01-27 04:15:37] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=2098367) [2026-01-27 04:15:37] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=2098367) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2098367) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.52s/it]
(EngineCore_DP0 pid=2098367) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:40<00:44, 22.23s/it]
(EngineCore_DP0 pid=2098367) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:16<00:28, 28.42s/it]
(EngineCore_DP0 pid=2098367) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:57<00:00, 33.34s/it]
(EngineCore_DP0 pid=2098367) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:57<00:00, 29.25s/it]
(EngineCore_DP0 pid=2098367) 
(EngineCore_DP0 pid=2098367) [2026-01-27 04:17:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=2098367) [2026-01-27 04:17:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 44040192 bytes
(EngineCore_DP0 pid=2098367) [2026-01-27 04:17:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=2098367) [2026-01-27 04:17:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=2098367) [2026-01-27 04:17:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=2098367) [2026-01-27 04:17:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 169869312 bytes
(EngineCore_DP0 pid=2098367) [2026-01-27 04:17:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=2098367) [2026-01-27 04:17:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 85032960 bytes
(EngineCore_DP0 pid=2098367) 2026-01-27 04:17:49,405 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2098367) 2026-01-27 04:17:50,038 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:   1%|          | 1/128 [00:00<01:56,  1.09it/s]
Adding requests:   2%|         | 2/128 [00:01<01:07,  1.88it/s]
Adding requests:   2%|         | 3/128 [00:01<00:44,  2.82it/s]
Adding requests:   3%|         | 4/128 [00:01<00:31,  3.89it/s]
Adding requests:   5%|         | 6/128 [00:01<00:19,  6.12it/s]
Adding requests:   6%|         | 8/128 [00:01<00:14,  8.53it/s]
Adding requests:   9%|         | 11/128 [00:01<00:09, 12.17it/s]
Adding requests:  11%|         | 14/128 [00:01<00:07, 14.89it/s]
Adding requests:  15%|        | 19/128 [00:02<00:05, 21.71it/s]
Adding requests:  20%|        | 25/128 [00:02<00:03, 29.10it/s]
Adding requests:  25%|       | 32/128 [00:02<00:02, 38.17it/s]
Adding requests:  41%|     | 53/128 [00:02<00:00, 81.31it/s]
Adding requests:  69%|   | 88/128 [00:02<00:00, 152.19it/s]
Adding requests: 100%|| 128/128 [00:02<00:00, 48.79it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|         | 9/128 [00:00<00:03, 39.55it/s, est. speed input: 20251.30 toks/s, output: 39.55 toks/s]
Processed prompts:  10%|         | 13/128 [00:00<00:09, 12.55it/s, est. speed input: 7489.77 toks/s, output: 14.63 toks/s]
Processed prompts:  12%|        | 15/128 [00:01<00:11, 10.08it/s, est. speed input: 6253.52 toks/s, output: 12.21 toks/s]
Processed prompts:  13%|        | 17/128 [00:01<00:12,  8.72it/s, est. speed input: 5591.06 toks/s, output: 10.92 toks/s]
Processed prompts:  15%|        | 19/128 [00:01<00:13,  7.85it/s, est. speed input: 5154.35 toks/s, output: 10.07 toks/s]
Processed prompts:  16%|        | 20/128 [00:02<00:14,  7.50it/s, est. speed input: 4985.77 toks/s, output: 9.74 toks/s] 
Processed prompts:  16%|        | 21/128 [00:02<00:15,  7.11it/s, est. speed input: 4825.59 toks/s, output: 9.42 toks/s]
Processed prompts:  17%|        | 22/128 [00:02<00:15,  6.87it/s, est. speed input: 4707.17 toks/s, output: 9.19 toks/s]
Processed prompts:  18%|        | 23/128 [00:02<00:15,  6.68it/s, est. speed input: 4606.46 toks/s, output: 9.00 toks/s]
Processed prompts:  19%|        | 24/128 [00:02<00:16,  6.29it/s, est. speed input: 4477.24 toks/s, output: 8.74 toks/s]
Processed prompts:  20%|        | 25/128 [00:02<00:16,  6.23it/s, est. speed input: 4399.29 toks/s, output: 8.59 toks/s]
Processed prompts:  20%|        | 26/128 [00:03<00:16,  6.17it/s, est. speed input: 4327.87 toks/s, output: 8.45 toks/s]
Processed prompts:  21%|        | 27/128 [00:03<00:16,  6.07it/s, est. speed input: 4257.12 toks/s, output: 8.31 toks/s]
Processed prompts:  22%|       | 28/128 [00:03<00:16,  6.09it/s, est. speed input: 4203.25 toks/s, output: 8.21 toks/s]
Processed prompts:  23%|       | 29/128 [00:03<00:16,  6.11it/s, est. speed input: 4155.44 toks/s, output: 8.12 toks/s]
Processed prompts:  23%|       | 30/128 [00:03<00:16,  6.07it/s, est. speed input: 4106.77 toks/s, output: 8.02 toks/s]
Processed prompts:  24%|       | 31/128 [00:03<00:16,  6.06it/s, est. speed input: 4063.48 toks/s, output: 7.94 toks/s]
Processed prompts:  25%|       | 32/128 [00:04<00:15,  6.07it/s, est. speed input: 4025.94 toks/s, output: 7.86 toks/s]
Processed prompts:  26%|       | 33/128 [00:04<00:15,  5.99it/s, est. speed input: 3982.64 toks/s, output: 7.78 toks/s]
Processed prompts:  27%|       | 34/128 [00:04<00:15,  6.01it/s, est. speed input: 3949.59 toks/s, output: 7.71 toks/s]
Processed prompts:  27%|       | 35/128 [00:04<00:15,  6.02it/s, est. speed input: 3918.96 toks/s, output: 7.65 toks/s]
Processed prompts:  28%|       | 36/128 [00:04<00:15,  5.82it/s, est. speed input: 3874.27 toks/s, output: 7.57 toks/s]
Processed prompts:  29%|       | 37/128 [00:04<00:15,  5.87it/s, est. speed input: 3846.99 toks/s, output: 7.51 toks/s]
Processed prompts:  30%|       | 38/128 [00:05<00:15,  5.92it/s, est. speed input: 3822.31 toks/s, output: 7.47 toks/s]
Processed prompts:  30%|       | 39/128 [00:05<00:15,  5.87it/s, est. speed input: 3793.49 toks/s, output: 7.41 toks/s]
Processed prompts:  31%|      | 40/128 [00:05<00:14,  5.93it/s, est. speed input: 3772.97 toks/s, output: 7.37 toks/s]
Processed prompts:  32%|      | 41/128 [00:05<00:14,  5.97it/s, est. speed input: 3753.23 toks/s, output: 7.33 toks/s]
Processed prompts:  33%|      | 42/128 [00:05<00:14,  6.00it/s, est. speed input: 3734.68 toks/s, output: 7.29 toks/s]
Processed prompts:  34%|      | 43/128 [00:05<00:14,  6.04it/s, est. speed input: 3718.33 toks/s, output: 7.26 toks/s]
Processed prompts:  34%|      | 44/128 [00:06<00:13,  6.05it/s, est. speed input: 3701.70 toks/s, output: 7.23 toks/s]
Processed prompts:  35%|      | 45/128 [00:06<00:13,  6.02it/s, est. speed input: 3684.37 toks/s, output: 7.20 toks/s]
Processed prompts:  36%|      | 46/128 [00:06<00:13,  5.95it/s, est. speed input: 3665.25 toks/s, output: 7.16 toks/s]
Processed prompts:  37%|      | 47/128 [00:06<00:13,  5.97it/s, est. speed input: 3650.35 toks/s, output: 7.13 toks/s]
Processed prompts:  38%|      | 48/128 [00:06<00:13,  6.00it/s, est. speed input: 3637.21 toks/s, output: 7.10 toks/s]
Processed prompts:  38%|      | 49/128 [00:06<00:13,  6.03it/s, est. speed input: 3625.08 toks/s, output: 7.08 toks/s]
Processed prompts:  39%|      | 50/128 [00:07<00:13,  5.78it/s, est. speed input: 3600.19 toks/s, output: 7.03 toks/s]
Processed prompts:  40%|      | 51/128 [00:07<00:13,  5.85it/s, est. speed input: 3588.43 toks/s, output: 7.01 toks/s]
Processed prompts:  41%|      | 52/128 [00:07<00:13,  5.83it/s, est. speed input: 3573.97 toks/s, output: 6.98 toks/s]
Processed prompts:  41%|     | 53/128 [00:07<00:12,  5.88it/s, est. speed input: 3562.95 toks/s, output: 6.96 toks/s]
Processed prompts:  42%|     | 54/128 [00:07<00:12,  5.94it/s, est. speed input: 3553.65 toks/s, output: 6.94 toks/s]
Processed prompts:  43%|     | 55/128 [00:07<00:12,  5.99it/s, est. speed input: 3544.83 toks/s, output: 6.92 toks/s]
Processed prompts:  44%|     | 56/128 [00:08<00:11,  6.01it/s, est. speed input: 3535.68 toks/s, output: 6.91 toks/s]
Processed prompts:  45%|     | 57/128 [00:08<00:11,  6.00it/s, est. speed input: 3526.26 toks/s, output: 6.89 toks/s]
Processed prompts:  45%|     | 58/128 [00:08<00:11,  5.95it/s, est. speed input: 3515.25 toks/s, output: 6.87 toks/s]
Processed prompts:  46%|     | 59/128 [00:08<00:11,  5.97it/s, est. speed input: 3506.90 toks/s, output: 6.85 toks/s]
Processed prompts:  47%|     | 60/128 [00:08<00:11,  5.99it/s, est. speed input: 3499.10 toks/s, output: 6.83 toks/s]
Processed prompts:  48%|     | 61/128 [00:08<00:11,  6.02it/s, est. speed input: 3492.21 toks/s, output: 6.82 toks/s]
Processed prompts:  48%|     | 62/128 [00:09<00:10,  6.03it/s, est. speed input: 3484.92 toks/s, output: 6.81 toks/s]
Processed prompts:  49%|     | 63/128 [00:09<00:10,  6.00it/s, est. speed input: 3476.94 toks/s, output: 6.79 toks/s]
Processed prompts:  50%|     | 64/128 [00:09<00:10,  5.94it/s, est. speed input: 3467.74 toks/s, output: 6.77 toks/s]
Processed prompts:  51%|     | 65/128 [00:09<00:10,  5.97it/s, est. speed input: 3461.09 toks/s, output: 6.76 toks/s]
Processed prompts:  52%|    | 66/128 [00:09<00:10,  6.00it/s, est. speed input: 3455.41 toks/s, output: 6.75 toks/s]
Processed prompts:  52%|    | 67/128 [00:09<00:10,  6.01it/s, est. speed input: 3449.06 toks/s, output: 6.74 toks/s]
Processed prompts:  53%|    | 68/128 [00:10<00:09,  6.01it/s, est. speed input: 3442.88 toks/s, output: 6.72 toks/s]
Processed prompts:  54%|    | 69/128 [00:10<00:09,  6.00it/s, est. speed input: 3436.69 toks/s, output: 6.71 toks/s]
Processed prompts:  55%|    | 70/128 [00:10<00:09,  5.98it/s, est. speed input: 3430.21 toks/s, output: 6.70 toks/s]
Processed prompts:  55%|    | 71/128 [00:10<00:09,  5.95it/s, est. speed input: 3423.44 toks/s, output: 6.69 toks/s]
Processed prompts:  56%|    | 72/128 [00:10<00:09,  5.94it/s, est. speed input: 3417.36 toks/s, output: 6.67 toks/s]
Processed prompts:  57%|    | 73/128 [00:10<00:09,  5.98it/s, est. speed input: 3412.70 toks/s, output: 6.67 toks/s]
Processed prompts:  58%|    | 74/128 [00:11<00:09,  6.00it/s, est. speed input: 3407.95 toks/s, output: 6.66 toks/s]
Processed prompts:  59%|    | 75/128 [00:11<00:08,  6.00it/s, est. speed input: 3402.99 toks/s, output: 6.65 toks/s]
Processed prompts:  59%|    | 76/128 [00:11<00:08,  6.03it/s, est. speed input: 3398.90 toks/s, output: 6.64 toks/s]
Processed prompts:  60%|    | 77/128 [00:11<00:08,  5.95it/s, est. speed input: 3392.33 toks/s, output: 6.63 toks/s]
Processed prompts:  61%|    | 78/128 [00:11<00:08,  5.99it/s, est. speed input: 3388.59 toks/s, output: 6.62 toks/s]
Processed prompts:  62%|   | 79/128 [00:11<00:08,  6.02it/s, est. speed input: 3384.72 toks/s, output: 6.61 toks/s]
Processed prompts:  62%|   | 80/128 [00:12<00:07,  6.01it/s, est. speed input: 3380.50 toks/s, output: 6.60 toks/s]
Processed prompts:  63%|   | 81/128 [00:12<00:07,  6.03it/s, est. speed input: 3376.82 toks/s, output: 6.60 toks/s]
Processed prompts:  64%|   | 82/128 [00:12<00:07,  6.05it/s, est. speed input: 3373.49 toks/s, output: 6.59 toks/s]
Processed prompts:  65%|   | 83/128 [00:12<00:07,  6.00it/s, est. speed input: 3368.62 toks/s, output: 6.58 toks/s]
Processed prompts:  66%|   | 84/128 [00:12<00:07,  6.02it/s, est. speed input: 3365.20 toks/s, output: 6.57 toks/s]
Processed prompts:  66%|   | 85/128 [00:12<00:07,  6.04it/s, est. speed input: 3362.05 toks/s, output: 6.57 toks/s]
Processed prompts:  67%|   | 86/128 [00:13<00:06,  6.02it/s, est. speed input: 3358.28 toks/s, output: 6.56 toks/s]
Processed prompts:  68%|   | 87/128 [00:13<00:06,  6.03it/s, est. speed input: 3355.11 toks/s, output: 6.55 toks/s]
Processed prompts:  69%|   | 88/128 [00:13<00:06,  6.04it/s, est. speed input: 3351.87 toks/s, output: 6.55 toks/s]
Processed prompts:  70%|   | 89/128 [00:13<00:06,  5.98it/s, est. speed input: 3347.33 toks/s, output: 6.54 toks/s]
Processed prompts:  70%|   | 90/128 [00:13<00:06,  5.99it/s, est. speed input: 3344.14 toks/s, output: 6.53 toks/s]
Processed prompts:  71%|   | 91/128 [00:13<00:06,  6.00it/s, est. speed input: 3341.01 toks/s, output: 6.53 toks/s]
Processed prompts:  72%|  | 92/128 [00:14<00:05,  6.00it/s, est. speed input: 3337.88 toks/s, output: 6.52 toks/s]
Processed prompts:  73%|  | 93/128 [00:14<00:05,  6.00it/s, est. speed input: 3334.84 toks/s, output: 6.51 toks/s]
Processed prompts:  73%|  | 94/128 [00:14<00:05,  6.04it/s, est. speed input: 3332.63 toks/s, output: 6.51 toks/s]
Processed prompts:  74%|  | 95/128 [00:14<00:05,  6.04it/s, est. speed input: 3329.98 toks/s, output: 6.50 toks/s]
Processed prompts:  75%|  | 96/128 [00:14<00:05,  5.97it/s, est. speed input: 3325.75 toks/s, output: 6.50 toks/s]
Processed prompts:  76%|  | 97/128 [00:14<00:05,  6.01it/s, est. speed input: 3323.60 toks/s, output: 6.49 toks/s]
Processed prompts:  77%|  | 98/128 [00:15<00:05,  5.99it/s, est. speed input: 3320.43 toks/s, output: 6.49 toks/s]
Processed prompts:  77%|  | 99/128 [00:15<00:04,  5.99it/s, est. speed input: 3317.64 toks/s, output: 6.48 toks/s]
Processed prompts:  78%|  | 100/128 [00:15<00:04,  6.01it/s, est. speed input: 3315.44 toks/s, output: 6.48 toks/s]
Processed prompts:  79%|  | 101/128 [00:15<00:04,  6.02it/s, est. speed input: 3313.00 toks/s, output: 6.47 toks/s]
Processed prompts:  80%|  | 102/128 [00:15<00:04,  5.97it/s, est. speed input: 3309.55 toks/s, output: 6.46 toks/s]
Processed prompts:  80%|  | 103/128 [00:15<00:04,  6.02it/s, est. speed input: 3307.81 toks/s, output: 6.46 toks/s]
Processed prompts:  81%| | 104/128 [00:16<00:03,  6.01it/s, est. speed input: 3305.27 toks/s, output: 6.46 toks/s]
Processed prompts:  82%| | 105/128 [00:16<00:03,  6.03it/s, est. speed input: 3303.40 toks/s, output: 6.45 toks/s]
Processed prompts:  83%| | 106/128 [00:16<00:03,  6.01it/s, est. speed input: 3300.89 toks/s, output: 6.45 toks/s]
Processed prompts:  84%| | 107/128 [00:16<00:03,  5.99it/s, est. speed input: 3298.29 toks/s, output: 6.44 toks/s]
Processed prompts:  84%| | 108/128 [00:16<00:03,  5.95it/s, est. speed input: 3295.14 toks/s, output: 6.44 toks/s]
Processed prompts:  85%| | 109/128 [00:16<00:03,  5.98it/s, est. speed input: 3293.31 toks/s, output: 6.43 toks/s]
Processed prompts:  86%| | 110/128 [00:17<00:03,  5.99it/s, est. speed input: 3291.14 toks/s, output: 6.43 toks/s]
Processed prompts:  87%| | 111/128 [00:17<00:02,  5.98it/s, est. speed input: 3288.93 toks/s, output: 6.42 toks/s]
Processed prompts:  88%| | 112/128 [00:17<00:02,  5.99it/s, est. speed input: 3286.92 toks/s, output: 6.42 toks/s]
Processed prompts:  88%| | 113/128 [00:17<00:02,  6.00it/s, est. speed input: 3285.02 toks/s, output: 6.42 toks/s]
Processed prompts:  89%| | 114/128 [00:17<00:02,  5.95it/s, est. speed input: 3282.21 toks/s, output: 6.41 toks/s]
Processed prompts:  90%| | 115/128 [00:17<00:02,  5.94it/s, est. speed input: 3279.70 toks/s, output: 6.41 toks/s]
Processed prompts:  91%| | 116/128 [00:18<00:02,  5.99it/s, est. speed input: 3278.38 toks/s, output: 6.40 toks/s]
Processed prompts:  91%|| 117/128 [00:18<00:01,  6.00it/s, est. speed input: 3276.58 toks/s, output: 6.40 toks/s]
Processed prompts:  92%|| 118/128 [00:18<00:01,  6.00it/s, est. speed input: 3274.71 toks/s, output: 6.40 toks/s]
Processed prompts:  93%|| 119/128 [00:18<00:01,  6.01it/s, est. speed input: 3273.11 toks/s, output: 6.39 toks/s]
Processed prompts:  94%|| 120/128 [00:18<00:01,  6.02it/s, est. speed input: 3271.50 toks/s, output: 6.39 toks/s]
Processed prompts:  95%|| 121/128 [00:18<00:01,  5.96it/s, est. speed input: 3268.87 toks/s, output: 6.38 toks/s]
Processed prompts:  95%|| 122/128 [00:19<00:01,  5.99it/s, est. speed input: 3267.41 toks/s, output: 6.38 toks/s]
Processed prompts:  96%|| 123/128 [00:19<00:00,  6.02it/s, est. speed input: 3266.17 toks/s, output: 6.38 toks/s]
Processed prompts:  97%|| 124/128 [00:19<00:00,  6.03it/s, est. speed input: 3264.70 toks/s, output: 6.38 toks/s]
Processed prompts:  98%|| 125/128 [00:19<00:00,  6.02it/s, est. speed input: 3263.10 toks/s, output: 6.37 toks/s]
Processed prompts:  98%|| 126/128 [00:19<00:00,  6.00it/s, est. speed input: 3261.29 toks/s, output: 6.37 toks/s]
Processed prompts:  99%|| 127/128 [00:19<00:00,  5.95it/s, est. speed input: 3258.98 toks/s, output: 6.37 toks/s]
Processed prompts: 100%|| 128/128 [00:20<00:00,  5.97it/s, est. speed input: 3257.40 toks/s, output: 6.36 toks/s]
Processed prompts: 100%|| 128/128 [00:20<00:00,  5.97it/s, est. speed input: 3257.40 toks/s, output: 6.36 toks/s]
Processed prompts: 100%|| 128/128 [00:20<00:00,  6.36it/s, est. speed input: 3257.40 toks/s, output: 6.36 toks/s]
[rank0]:[W127 04:18:22.163408077 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-27 04:18:39
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 04:18:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 04:18:46 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2101211) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2101211) WARNING 01-27 04:21:02 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.26 requests/s, 3345.00 total tokens/s, 3.26 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-27 04:18:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 04:18:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:18:46] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 04:18:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:18:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:18:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:18:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:18:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:18:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:18:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 04:18:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 04:18:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 04:18:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 04:18:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 04:18:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 04:18:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:18:49] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 04:18:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:18:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:18:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:18:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:18:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:18:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:18:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 04:18:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 04:18:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 04:18:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 04:18:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2101211) [2026-01-27 04:18:50] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2101211) [2026-01-27 04:18:50] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2101211) [2026-01-27 04:18:50] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2101211) [2026-01-27 04:18:50] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=2101211) [2026-01-27 04:18:50] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=2101211) [2026-01-27 04:18:50] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=2101211) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2101211) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.51s/it]
(EngineCore_DP0 pid=2101211) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:41<00:45, 22.86s/it]
(EngineCore_DP0 pid=2101211) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:17<00:28, 28.85s/it]
(EngineCore_DP0 pid=2101211) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:59<00:00, 33.91s/it]
(EngineCore_DP0 pid=2101211) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:59<00:00, 29.77s/it]
(EngineCore_DP0 pid=2101211) 
(EngineCore_DP0 pid=2101211) [2026-01-27 04:20:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=2101211) [2026-01-27 04:20:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 44040192 bytes
(EngineCore_DP0 pid=2101211) [2026-01-27 04:20:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=2101211) [2026-01-27 04:20:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=2101211) [2026-01-27 04:20:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=2101211) [2026-01-27 04:20:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 169869312 bytes
(EngineCore_DP0 pid=2101211) [2026-01-27 04:20:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=2101211) [2026-01-27 04:20:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 85032960 bytes
(EngineCore_DP0 pid=2101211) 2026-01-27 04:21:01,587 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2101211) 2026-01-27 04:21:01,699 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:   5%|         | 6/128 [00:00<00:02, 58.07it/s]
Adding requests:  32%|      | 41/128 [00:00<00:00, 226.89it/s]
Adding requests:  67%|   | 86/128 [00:00<00:00, 327.04it/s]
Adding requests:  98%|| 125/128 [00:00<00:00, 351.25it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 309.16it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:18,  6.97it/s, est. speed input: 7133.41 toks/s, output: 6.97 toks/s]
Processed prompts:   2%|         | 2/128 [00:00<00:29,  4.26it/s, est. speed input: 4636.65 toks/s, output: 4.53 toks/s]
Processed prompts:   2%|         | 3/128 [00:00<00:32,  3.79it/s, est. speed input: 4151.56 toks/s, output: 4.05 toks/s]
Processed prompts:   3%|         | 4/128 [00:01<00:34,  3.57it/s, est. speed input: 3917.90 toks/s, output: 3.83 toks/s]
Processed prompts:   4%|         | 5/128 [00:01<00:35,  3.48it/s, est. speed input: 3803.29 toks/s, output: 3.71 toks/s]
Processed prompts:   5%|         | 6/128 [00:01<00:35,  3.45it/s, est. speed input: 3744.55 toks/s, output: 3.66 toks/s]
Processed prompts:   5%|         | 7/128 [00:01<00:35,  3.38it/s, est. speed input: 3679.18 toks/s, output: 3.59 toks/s]
Processed prompts:   6%|         | 8/128 [00:02<00:35,  3.38it/s, est. speed input: 3648.84 toks/s, output: 3.56 toks/s]
Processed prompts:   7%|         | 9/128 [00:02<00:35,  3.36it/s, est. speed input: 3620.33 toks/s, output: 3.54 toks/s]
Processed prompts:   8%|         | 10/128 [00:02<00:35,  3.35it/s, est. speed input: 3598.32 toks/s, output: 3.51 toks/s]
Processed prompts:   9%|         | 11/128 [00:03<00:35,  3.30it/s, est. speed input: 3566.22 toks/s, output: 3.48 toks/s]
Processed prompts:   9%|         | 12/128 [00:03<00:35,  3.31it/s, est. speed input: 3550.90 toks/s, output: 3.47 toks/s]
Processed prompts:  10%|         | 13/128 [00:03<00:34,  3.32it/s, est. speed input: 3540.98 toks/s, output: 3.46 toks/s]
Processed prompts:  11%|         | 14/128 [00:04<00:34,  3.30it/s, est. speed input: 3526.09 toks/s, output: 3.44 toks/s]
Processed prompts:  12%|        | 15/128 [00:04<00:34,  3.31it/s, est. speed input: 3517.04 toks/s, output: 3.43 toks/s]
Processed prompts:  12%|        | 16/128 [00:04<00:33,  3.31it/s, est. speed input: 3510.15 toks/s, output: 3.43 toks/s]
Processed prompts:  13%|        | 17/128 [00:04<00:33,  3.33it/s, est. speed input: 3505.98 toks/s, output: 3.42 toks/s]
Processed prompts:  14%|        | 18/128 [00:05<00:33,  3.30it/s, est. speed input: 3495.12 toks/s, output: 3.41 toks/s]
Processed prompts:  15%|        | 19/128 [00:05<00:32,  3.32it/s, est. speed input: 3492.06 toks/s, output: 3.41 toks/s]
Processed prompts:  16%|        | 20/128 [00:05<00:32,  3.32it/s, est. speed input: 3487.82 toks/s, output: 3.41 toks/s]
Processed prompts:  16%|        | 21/128 [00:06<00:32,  3.30it/s, est. speed input: 3480.19 toks/s, output: 3.40 toks/s]
Processed prompts:  17%|        | 22/128 [00:06<00:32,  3.31it/s, est. speed input: 3477.20 toks/s, output: 3.40 toks/s]
Processed prompts:  18%|        | 23/128 [00:06<00:31,  3.30it/s, est. speed input: 3472.17 toks/s, output: 3.39 toks/s]
Processed prompts:  19%|        | 24/128 [00:07<00:31,  3.32it/s, est. speed input: 3470.10 toks/s, output: 3.39 toks/s]
Processed prompts:  20%|        | 25/128 [00:07<00:31,  3.29it/s, est. speed input: 3463.35 toks/s, output: 3.38 toks/s]
Processed prompts:  20%|        | 26/128 [00:07<00:30,  3.31it/s, est. speed input: 3461.89 toks/s, output: 3.38 toks/s]
Processed prompts:  21%|        | 27/128 [00:07<00:30,  3.31it/s, est. speed input: 3459.50 toks/s, output: 3.38 toks/s]
Processed prompts:  22%|       | 28/128 [00:08<00:30,  3.28it/s, est. speed input: 3453.51 toks/s, output: 3.37 toks/s]
Processed prompts:  23%|       | 29/128 [00:08<00:30,  3.29it/s, est. speed input: 3451.67 toks/s, output: 3.37 toks/s]
Processed prompts:  23%|       | 30/128 [00:08<00:29,  3.30it/s, est. speed input: 3449.50 toks/s, output: 3.37 toks/s]
Processed prompts:  24%|       | 31/128 [00:09<00:29,  3.30it/s, est. speed input: 3447.36 toks/s, output: 3.37 toks/s]
Processed prompts:  25%|       | 32/128 [00:09<00:29,  3.29it/s, est. speed input: 3443.67 toks/s, output: 3.36 toks/s]
Processed prompts:  26%|       | 33/128 [00:09<00:28,  3.29it/s, est. speed input: 3441.77 toks/s, output: 3.36 toks/s]
Processed prompts:  27%|       | 34/128 [00:10<00:28,  3.30it/s, est. speed input: 3440.17 toks/s, output: 3.36 toks/s]
Processed prompts:  27%|       | 35/128 [00:10<00:28,  3.28it/s, est. speed input: 3436.68 toks/s, output: 3.36 toks/s]
Processed prompts:  28%|       | 36/128 [00:10<00:27,  3.29it/s, est. speed input: 3434.99 toks/s, output: 3.35 toks/s]
Processed prompts:  29%|       | 37/128 [00:11<00:27,  3.32it/s, est. speed input: 3436.49 toks/s, output: 3.36 toks/s]
Processed prompts:  30%|       | 38/128 [00:11<00:27,  3.32it/s, est. speed input: 3435.50 toks/s, output: 3.35 toks/s]
Processed prompts:  30%|       | 39/128 [00:11<00:26,  3.30it/s, est. speed input: 3432.89 toks/s, output: 3.35 toks/s]
Processed prompts:  31%|      | 40/128 [00:11<00:26,  3.31it/s, est. speed input: 3432.09 toks/s, output: 3.35 toks/s]
Processed prompts:  32%|      | 41/128 [00:12<00:26,  3.31it/s, est. speed input: 3430.85 toks/s, output: 3.35 toks/s]
Processed prompts:  33%|      | 42/128 [00:12<00:26,  3.29it/s, est. speed input: 3428.34 toks/s, output: 3.35 toks/s]
Processed prompts:  34%|      | 43/128 [00:12<00:25,  3.29it/s, est. speed input: 3426.87 toks/s, output: 3.35 toks/s]
Processed prompts:  34%|      | 44/128 [00:13<00:25,  3.30it/s, est. speed input: 3426.50 toks/s, output: 3.35 toks/s]
Processed prompts:  35%|      | 45/128 [00:13<00:25,  3.29it/s, est. speed input: 3424.33 toks/s, output: 3.34 toks/s]
Processed prompts:  36%|      | 46/128 [00:13<00:24,  3.30it/s, est. speed input: 3423.72 toks/s, output: 3.34 toks/s]
Processed prompts:  37%|      | 47/128 [00:14<00:24,  3.29it/s, est. speed input: 3422.49 toks/s, output: 3.34 toks/s]
Processed prompts:  38%|      | 48/128 [00:14<00:24,  3.29it/s, est. speed input: 3421.16 toks/s, output: 3.34 toks/s]
Processed prompts:  38%|      | 49/128 [00:14<00:24,  3.27it/s, est. speed input: 3418.74 toks/s, output: 3.34 toks/s]
Processed prompts:  39%|      | 50/128 [00:14<00:23,  3.29it/s, est. speed input: 3418.99 toks/s, output: 3.34 toks/s]
Processed prompts:  40%|      | 51/128 [00:15<00:23,  3.30it/s, est. speed input: 3418.28 toks/s, output: 3.34 toks/s]
Processed prompts:  41%|      | 52/128 [00:15<00:23,  3.28it/s, est. speed input: 3416.48 toks/s, output: 3.34 toks/s]
Processed prompts:  41%|     | 53/128 [00:15<00:22,  3.30it/s, est. speed input: 3416.46 toks/s, output: 3.34 toks/s]
Processed prompts:  42%|     | 54/128 [00:16<00:22,  3.30it/s, est. speed input: 3415.56 toks/s, output: 3.34 toks/s]
Processed prompts:  43%|     | 55/128 [00:16<00:22,  3.30it/s, est. speed input: 3415.01 toks/s, output: 3.33 toks/s]
Processed prompts:  44%|     | 56/128 [00:16<00:21,  3.28it/s, est. speed input: 3413.05 toks/s, output: 3.33 toks/s]
Processed prompts:  45%|     | 57/128 [00:17<00:21,  3.28it/s, est. speed input: 3411.94 toks/s, output: 3.33 toks/s]
Processed prompts:  45%|     | 58/128 [00:17<00:21,  3.30it/s, est. speed input: 3412.31 toks/s, output: 3.33 toks/s]
Processed prompts:  46%|     | 59/128 [00:17<00:21,  3.28it/s, est. speed input: 3410.77 toks/s, output: 3.33 toks/s]
Processed prompts:  47%|     | 60/128 [00:18<00:20,  3.29it/s, est. speed input: 3410.53 toks/s, output: 3.33 toks/s]
Processed prompts:  48%|     | 61/128 [00:18<00:20,  3.30it/s, est. speed input: 3410.10 toks/s, output: 3.33 toks/s]
Processed prompts:  48%|     | 62/128 [00:18<00:19,  3.30it/s, est. speed input: 3409.88 toks/s, output: 3.33 toks/s]
Processed prompts:  49%|     | 63/128 [00:18<00:19,  3.28it/s, est. speed input: 3408.19 toks/s, output: 3.33 toks/s]
Processed prompts:  50%|     | 64/128 [00:19<00:19,  3.27it/s, est. speed input: 3407.11 toks/s, output: 3.33 toks/s]
Processed prompts:  51%|     | 65/128 [00:19<00:19,  3.29it/s, est. speed input: 3407.05 toks/s, output: 3.33 toks/s]
Processed prompts:  52%|    | 66/128 [00:19<00:18,  3.27it/s, est. speed input: 3405.37 toks/s, output: 3.33 toks/s]
Processed prompts:  52%|    | 67/128 [00:20<00:18,  3.28it/s, est. speed input: 3405.13 toks/s, output: 3.33 toks/s]
Processed prompts:  53%|    | 68/128 [00:20<00:18,  3.28it/s, est. speed input: 3404.46 toks/s, output: 3.32 toks/s]
Processed prompts:  54%|    | 69/128 [00:20<00:17,  3.30it/s, est. speed input: 3404.57 toks/s, output: 3.32 toks/s]
Processed prompts:  55%|    | 70/128 [00:21<00:17,  3.28it/s, est. speed input: 3403.11 toks/s, output: 3.32 toks/s]
Processed prompts:  55%|    | 71/128 [00:21<00:17,  3.27it/s, est. speed input: 3402.37 toks/s, output: 3.32 toks/s]
Processed prompts:  56%|    | 72/128 [00:21<00:17,  3.28it/s, est. speed input: 3401.79 toks/s, output: 3.32 toks/s]
Processed prompts:  57%|    | 73/128 [00:21<00:16,  3.26it/s, est. speed input: 3400.37 toks/s, output: 3.32 toks/s]
Processed prompts:  58%|    | 74/128 [00:22<00:16,  3.27it/s, est. speed input: 3399.78 toks/s, output: 3.32 toks/s]
Processed prompts:  59%|    | 75/128 [00:22<00:16,  3.27it/s, est. speed input: 3399.39 toks/s, output: 3.32 toks/s]
Processed prompts:  59%|    | 76/128 [00:22<00:15,  3.27it/s, est. speed input: 3398.76 toks/s, output: 3.32 toks/s]
Processed prompts:  60%|    | 77/128 [00:23<00:15,  3.28it/s, est. speed input: 3398.42 toks/s, output: 3.32 toks/s]
Processed prompts:  61%|    | 78/128 [00:23<00:15,  3.28it/s, est. speed input: 3398.09 toks/s, output: 3.32 toks/s]
Processed prompts:  62%|   | 79/128 [00:23<00:14,  3.30it/s, est. speed input: 3398.15 toks/s, output: 3.32 toks/s]
Processed prompts:  62%|   | 80/128 [00:24<00:14,  3.28it/s, est. speed input: 3397.07 toks/s, output: 3.32 toks/s]
Processed prompts:  63%|   | 81/128 [00:24<00:14,  3.28it/s, est. speed input: 3396.66 toks/s, output: 3.32 toks/s]
Processed prompts:  64%|   | 82/128 [00:24<00:14,  3.28it/s, est. speed input: 3396.39 toks/s, output: 3.32 toks/s]
Processed prompts:  65%|   | 83/128 [00:25<00:13,  3.28it/s, est. speed input: 3395.86 toks/s, output: 3.32 toks/s]
Processed prompts:  66%|   | 84/128 [00:25<00:13,  3.29it/s, est. speed input: 3395.81 toks/s, output: 3.32 toks/s]
Processed prompts:  66%|   | 85/128 [00:25<00:13,  3.30it/s, est. speed input: 3395.83 toks/s, output: 3.32 toks/s]
Processed prompts:  67%|   | 86/128 [00:25<00:12,  3.29it/s, est. speed input: 3395.22 toks/s, output: 3.32 toks/s]
Processed prompts:  68%|   | 87/128 [00:26<00:12,  3.27it/s, est. speed input: 3394.04 toks/s, output: 3.31 toks/s]
Processed prompts:  69%|   | 88/128 [00:26<00:12,  3.28it/s, est. speed input: 3393.95 toks/s, output: 3.31 toks/s]
Processed prompts:  70%|   | 89/128 [00:26<00:11,  3.27it/s, est. speed input: 3393.31 toks/s, output: 3.31 toks/s]
Processed prompts:  70%|   | 90/128 [00:27<00:11,  3.26it/s, est. speed input: 3392.27 toks/s, output: 3.31 toks/s]
Processed prompts:  71%|   | 91/128 [00:27<00:11,  3.27it/s, est. speed input: 3392.25 toks/s, output: 3.31 toks/s]
Processed prompts:  72%|  | 92/128 [00:27<00:10,  3.28it/s, est. speed input: 3392.15 toks/s, output: 3.31 toks/s]
Processed prompts:  73%|  | 93/128 [00:28<00:10,  3.29it/s, est. speed input: 3392.06 toks/s, output: 3.31 toks/s]
Processed prompts:  73%|  | 94/128 [00:28<00:10,  3.29it/s, est. speed input: 3391.80 toks/s, output: 3.31 toks/s]
Processed prompts:  74%|  | 95/128 [00:28<00:10,  3.29it/s, est. speed input: 3391.51 toks/s, output: 3.31 toks/s]
Processed prompts:  75%|  | 96/128 [00:28<00:09,  3.30it/s, est. speed input: 3391.54 toks/s, output: 3.31 toks/s]
Processed prompts:  76%|  | 97/128 [00:29<00:09,  3.27it/s, est. speed input: 3390.59 toks/s, output: 3.31 toks/s]
Processed prompts:  77%|  | 98/128 [00:29<00:09,  3.29it/s, est. speed input: 3390.61 toks/s, output: 3.31 toks/s]
Processed prompts:  77%|  | 99/128 [00:29<00:08,  3.29it/s, est. speed input: 3390.40 toks/s, output: 3.31 toks/s]
Processed prompts:  78%|  | 100/128 [00:30<00:08,  3.29it/s, est. speed input: 3390.18 toks/s, output: 3.31 toks/s]
Processed prompts:  79%|  | 101/128 [00:30<00:08,  3.27it/s, est. speed input: 3389.38 toks/s, output: 3.31 toks/s]
Processed prompts:  80%|  | 102/128 [00:30<00:07,  3.28it/s, est. speed input: 3389.21 toks/s, output: 3.31 toks/s]
Processed prompts:  80%|  | 103/128 [00:31<00:07,  3.28it/s, est. speed input: 3388.91 toks/s, output: 3.31 toks/s]
Processed prompts:  81%| | 104/128 [00:31<00:07,  3.26it/s, est. speed input: 3388.09 toks/s, output: 3.31 toks/s]
Processed prompts:  82%| | 105/128 [00:31<00:07,  3.27it/s, est. speed input: 3388.00 toks/s, output: 3.31 toks/s]
Processed prompts:  83%| | 106/128 [00:32<00:06,  3.28it/s, est. speed input: 3387.88 toks/s, output: 3.31 toks/s]
Processed prompts:  84%| | 107/128 [00:32<00:06,  3.26it/s, est. speed input: 3386.99 toks/s, output: 3.31 toks/s]
Processed prompts:  84%| | 108/128 [00:32<00:06,  3.26it/s, est. speed input: 3386.45 toks/s, output: 3.31 toks/s]
Processed prompts:  85%| | 109/128 [00:32<00:05,  3.26it/s, est. speed input: 3386.18 toks/s, output: 3.31 toks/s]
Processed prompts:  86%| | 110/128 [00:33<00:05,  3.28it/s, est. speed input: 3386.19 toks/s, output: 3.31 toks/s]
Processed prompts:  87%| | 111/128 [00:33<00:05,  3.27it/s, est. speed input: 3385.58 toks/s, output: 3.31 toks/s]
Processed prompts:  88%| | 112/128 [00:33<00:04,  3.27it/s, est. speed input: 3385.22 toks/s, output: 3.31 toks/s]
Processed prompts:  88%| | 113/128 [00:34<00:04,  3.27it/s, est. speed input: 3385.09 toks/s, output: 3.31 toks/s]
Processed prompts:  89%| | 114/128 [00:34<00:04,  3.27it/s, est. speed input: 3384.55 toks/s, output: 3.31 toks/s]
Processed prompts:  90%| | 115/128 [00:34<00:03,  3.29it/s, est. speed input: 3384.78 toks/s, output: 3.31 toks/s]
Processed prompts:  91%| | 116/128 [00:35<00:03,  3.29it/s, est. speed input: 3384.70 toks/s, output: 3.31 toks/s]
Processed prompts:  91%|| 117/128 [00:35<00:03,  3.29it/s, est. speed input: 3384.57 toks/s, output: 3.31 toks/s]
Processed prompts:  92%|| 118/128 [00:35<00:03,  3.27it/s, est. speed input: 3383.88 toks/s, output: 3.30 toks/s]
Processed prompts:  93%|| 119/128 [00:36<00:02,  3.27it/s, est. speed input: 3383.54 toks/s, output: 3.30 toks/s]
Processed prompts:  94%|| 120/128 [00:36<00:02,  3.27it/s, est. speed input: 3383.34 toks/s, output: 3.30 toks/s]
Processed prompts:  95%|| 121/128 [00:36<00:02,  3.28it/s, est. speed input: 3383.20 toks/s, output: 3.30 toks/s]
Processed prompts:  95%|| 122/128 [00:36<00:01,  3.29it/s, est. speed input: 3383.35 toks/s, output: 3.30 toks/s]
Processed prompts:  96%|| 123/128 [00:37<00:01,  3.31it/s, est. speed input: 3383.69 toks/s, output: 3.30 toks/s]
Processed prompts:  97%|| 124/128 [00:37<00:01,  3.31it/s, est. speed input: 3383.89 toks/s, output: 3.30 toks/s]
Processed prompts:  98%|| 125/128 [00:37<00:00,  3.29it/s, est. speed input: 3383.33 toks/s, output: 3.30 toks/s]
Processed prompts:  98%|| 126/128 [00:38<00:00,  3.29it/s, est. speed input: 3383.15 toks/s, output: 3.30 toks/s]
Processed prompts:  99%|| 127/128 [00:38<00:00,  3.29it/s, est. speed input: 3383.14 toks/s, output: 3.30 toks/s]
Processed prompts: 100%|| 128/128 [00:38<00:00,  3.27it/s, est. speed input: 3382.34 toks/s, output: 3.30 toks/s]
Processed prompts: 100%|| 128/128 [00:38<00:00,  3.27it/s, est. speed input: 3382.34 toks/s, output: 3.30 toks/s]
Processed prompts: 100%|| 128/128 [00:38<00:00,  3.30it/s, est. speed input: 3382.34 toks/s, output: 3.30 toks/s]
[rank0]:[W127 04:21:41.977375098 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-27 04:21:49
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 04:21:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 04:21:56 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2104023) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2104023) WARNING 01-27 04:24:23 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.10 requests/s, 3180.46 total tokens/s, 3.10 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-27 04:21:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 04:21:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:21:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 04:21:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:21:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:21:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:21:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:21:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:21:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:21:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 04:21:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 04:21:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 04:21:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 04:21:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 04:21:59] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 04:21:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:21:59] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 04:21:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:21:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:21:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:21:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:21:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:21:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:21:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 04:21:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 04:21:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 04:21:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 04:21:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2104023) [2026-01-27 04:22:00] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2104023) [2026-01-27 04:22:00] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2104023) [2026-01-27 04:22:00] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2104023) [2026-01-27 04:22:00] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=2104023) [2026-01-27 04:22:00] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=2104023) [2026-01-27 04:22:00] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=2104023) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2104023) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.47s/it]
(EngineCore_DP0 pid=2104023) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:41<00:45, 22.66s/it]
(EngineCore_DP0 pid=2104023) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:17<00:28, 28.75s/it]
(EngineCore_DP0 pid=2104023) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:58<00:00, 33.70s/it]
(EngineCore_DP0 pid=2104023) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:58<00:00, 29.59s/it]
(EngineCore_DP0 pid=2104023) 
(EngineCore_DP0 pid=2104023) [2026-01-27 04:24:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=2104023) [2026-01-27 04:24:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 44040192 bytes
(EngineCore_DP0 pid=2104023) [2026-01-27 04:24:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=2104023) [2026-01-27 04:24:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=2104023) [2026-01-27 04:24:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=2104023) [2026-01-27 04:24:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 169869312 bytes
(EngineCore_DP0 pid=2104023) [2026-01-27 04:24:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=2104023) [2026-01-27 04:24:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 85032960 bytes
(EngineCore_DP0 pid=2104023) 2026-01-27 04:24:13,665 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2104023) 2026-01-27 04:24:14,148 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/256 [00:01<05:26,  1.28s/it]
Adding requests:   1%|          | 2/256 [00:01<02:56,  1.44it/s]
Adding requests:   1%|          | 3/256 [00:01<01:54,  2.21it/s]
Adding requests:   2%|         | 4/256 [00:01<01:20,  3.13it/s]
Adding requests:   2%|         | 5/256 [00:01<01:00,  4.15it/s]
Adding requests:   3%|         | 7/256 [00:02<00:38,  6.49it/s]
Adding requests:   4%|         | 9/256 [00:02<00:27,  8.85it/s]
Adding requests:   5%|         | 12/256 [00:02<00:19, 12.51it/s]
Adding requests:   6%|         | 16/256 [00:02<00:13, 18.35it/s]
Adding requests:  11%|         | 27/256 [00:02<00:05, 39.76it/s]
Adding requests:  16%|        | 42/256 [00:02<00:03, 66.57it/s]
Adding requests:  23%|       | 60/256 [00:02<00:02, 96.25it/s]
Adding requests:  32%|      | 82/256 [00:02<00:01, 129.31it/s]
Adding requests:  45%|     | 115/256 [00:02<00:00, 183.99it/s]
Adding requests:  59%|    | 150/256 [00:03<00:00, 229.86it/s]
Adding requests:  73%|  | 188/256 [00:03<00:00, 271.55it/s]
Adding requests:  89%| | 229/256 [00:03<00:00, 309.55it/s]
Adding requests: 100%|| 256/256 [00:03<00:00, 76.94it/s] 

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 6/256 [00:00<00:15, 16.17it/s, est. speed input: 16553.81 toks/s, output: 16.17 toks/s]
Processed prompts:   3%|         | 8/256 [00:00<00:35,  7.04it/s, est. speed input: 8259.46 toks/s, output: 8.07 toks/s]  
Processed prompts:   4%|         | 10/256 [00:01<00:48,  5.11it/s, est. speed input: 6337.58 toks/s, output: 6.19 toks/s]
Processed prompts:   5%|         | 12/256 [00:02<00:56,  4.30it/s, est. speed input: 5476.64 toks/s, output: 5.35 toks/s]
Processed prompts:   5%|         | 14/256 [00:02<01:02,  3.88it/s, est. speed input: 4988.46 toks/s, output: 4.87 toks/s]
Processed prompts:   6%|         | 16/256 [00:03<01:05,  3.65it/s, est. speed input: 4688.30 toks/s, output: 4.58 toks/s]
Processed prompts:   7%|         | 18/256 [00:04<01:07,  3.51it/s, est. speed input: 4480.79 toks/s, output: 4.38 toks/s]
Processed prompts:   8%|         | 20/256 [00:04<01:09,  3.40it/s, est. speed input: 4313.29 toks/s, output: 4.21 toks/s]
Processed prompts:   9%|         | 22/256 [00:05<01:10,  3.34it/s, est. speed input: 4193.92 toks/s, output: 4.10 toks/s]
Processed prompts:   9%|         | 24/256 [00:06<01:10,  3.28it/s, est. speed input: 4092.33 toks/s, output: 4.00 toks/s]
Processed prompts:  10%|         | 26/256 [00:06<01:10,  3.24it/s, est. speed input: 4009.69 toks/s, output: 3.92 toks/s]
Processed prompts:  11%|         | 28/256 [00:07<01:10,  3.23it/s, est. speed input: 3946.26 toks/s, output: 3.85 toks/s]
Processed prompts:  12%|        | 30/256 [00:07<01:10,  3.21it/s, est. speed input: 3889.17 toks/s, output: 3.80 toks/s]
Processed prompts:  12%|        | 32/256 [00:08<01:09,  3.20it/s, est. speed input: 3843.29 toks/s, output: 3.75 toks/s]
Processed prompts:  13%|        | 34/256 [00:09<01:09,  3.19it/s, est. speed input: 3801.91 toks/s, output: 3.71 toks/s]
Processed prompts:  14%|        | 36/256 [00:09<01:09,  3.18it/s, est. speed input: 3765.32 toks/s, output: 3.68 toks/s]
Processed prompts:  15%|        | 38/256 [00:10<01:08,  3.19it/s, est. speed input: 3735.97 toks/s, output: 3.65 toks/s]
Processed prompts:  16%|        | 40/256 [00:11<01:08,  3.18it/s, est. speed input: 3706.73 toks/s, output: 3.62 toks/s]
Processed prompts:  16%|        | 42/256 [00:11<01:07,  3.18it/s, est. speed input: 3683.62 toks/s, output: 3.60 toks/s]
Processed prompts:  17%|        | 44/256 [00:12<01:06,  3.17it/s, est. speed input: 3659.74 toks/s, output: 3.57 toks/s]
Processed prompts:  18%|        | 46/256 [00:12<01:06,  3.17it/s, est. speed input: 3638.59 toks/s, output: 3.55 toks/s]
Processed prompts:  19%|        | 48/256 [00:13<01:05,  3.18it/s, est. speed input: 3622.89 toks/s, output: 3.54 toks/s]
Processed prompts:  20%|        | 50/256 [00:14<01:04,  3.17it/s, est. speed input: 3604.76 toks/s, output: 3.52 toks/s]
Processed prompts:  20%|        | 52/256 [00:14<01:04,  3.17it/s, est. speed input: 3589.83 toks/s, output: 3.51 toks/s]
Processed prompts:  21%|        | 54/256 [00:15<01:03,  3.17it/s, est. speed input: 3575.03 toks/s, output: 3.49 toks/s]
Processed prompts:  22%|       | 56/256 [00:16<01:03,  3.17it/s, est. speed input: 3562.22 toks/s, output: 3.48 toks/s]
Processed prompts:  23%|       | 58/256 [00:16<01:02,  3.17it/s, est. speed input: 3550.31 toks/s, output: 3.47 toks/s]
Processed prompts:  23%|       | 60/256 [00:17<01:02,  3.16it/s, est. speed input: 3537.76 toks/s, output: 3.45 toks/s]
Processed prompts:  24%|       | 62/256 [00:17<01:01,  3.16it/s, est. speed input: 3527.84 toks/s, output: 3.45 toks/s]
Processed prompts:  25%|       | 64/256 [00:18<01:00,  3.17it/s, est. speed input: 3518.48 toks/s, output: 3.44 toks/s]
Processed prompts:  26%|       | 66/256 [00:19<01:00,  3.16it/s, est. speed input: 3508.74 toks/s, output: 3.43 toks/s]
Processed prompts:  27%|       | 68/256 [00:19<00:59,  3.17it/s, est. speed input: 3500.73 toks/s, output: 3.42 toks/s]
Processed prompts:  27%|       | 70/256 [00:20<00:58,  3.16it/s, est. speed input: 3492.59 toks/s, output: 3.41 toks/s]
Processed prompts:  28%|       | 72/256 [00:21<00:58,  3.17it/s, est. speed input: 3485.73 toks/s, output: 3.40 toks/s]
Processed prompts:  29%|       | 74/256 [00:21<00:57,  3.16it/s, est. speed input: 3477.76 toks/s, output: 3.40 toks/s]
Processed prompts:  30%|       | 76/256 [00:22<00:57,  3.16it/s, est. speed input: 3470.41 toks/s, output: 3.39 toks/s]
Processed prompts:  30%|       | 78/256 [00:23<00:56,  3.16it/s, est. speed input: 3464.34 toks/s, output: 3.38 toks/s]
Processed prompts:  31%|      | 80/256 [00:23<00:55,  3.15it/s, est. speed input: 3457.07 toks/s, output: 3.38 toks/s]
Processed prompts:  32%|      | 82/256 [00:24<00:55,  3.15it/s, est. speed input: 3451.40 toks/s, output: 3.37 toks/s]
Processed prompts:  33%|      | 84/256 [00:24<00:54,  3.15it/s, est. speed input: 3445.85 toks/s, output: 3.37 toks/s]
Processed prompts:  34%|      | 86/256 [00:25<00:53,  3.15it/s, est. speed input: 3440.11 toks/s, output: 3.36 toks/s]
Processed prompts:  34%|      | 88/256 [00:26<00:53,  3.15it/s, est. speed input: 3435.34 toks/s, output: 3.35 toks/s]
Processed prompts:  35%|      | 90/256 [00:26<00:52,  3.15it/s, est. speed input: 3430.07 toks/s, output: 3.35 toks/s]
Processed prompts:  36%|      | 92/256 [00:27<00:52,  3.14it/s, est. speed input: 3424.92 toks/s, output: 3.34 toks/s]
Processed prompts:  37%|      | 94/256 [00:28<00:51,  3.15it/s, est. speed input: 3420.75 toks/s, output: 3.34 toks/s]
Processed prompts:  38%|      | 96/256 [00:28<00:50,  3.15it/s, est. speed input: 3416.09 toks/s, output: 3.34 toks/s]
Processed prompts:  38%|      | 98/256 [00:29<00:50,  3.15it/s, est. speed input: 3412.30 toks/s, output: 3.33 toks/s]
Processed prompts:  39%|      | 100/256 [00:30<00:49,  3.15it/s, est. speed input: 3407.98 toks/s, output: 3.33 toks/s]
Processed prompts:  40%|      | 102/256 [00:30<00:48,  3.15it/s, est. speed input: 3404.05 toks/s, output: 3.32 toks/s]
Processed prompts:  41%|      | 104/256 [00:31<00:48,  3.16it/s, est. speed input: 3401.09 toks/s, output: 3.32 toks/s]
Processed prompts:  41%|     | 106/256 [00:31<00:47,  3.15it/s, est. speed input: 3397.29 toks/s, output: 3.32 toks/s]
Processed prompts:  42%|     | 108/256 [00:32<00:46,  3.16it/s, est. speed input: 3394.61 toks/s, output: 3.32 toks/s]
Processed prompts:  43%|     | 110/256 [00:33<00:46,  3.15it/s, est. speed input: 3391.22 toks/s, output: 3.31 toks/s]
Processed prompts:  44%|     | 112/256 [00:33<00:45,  3.15it/s, est. speed input: 3387.77 toks/s, output: 3.31 toks/s]
Processed prompts:  45%|     | 114/256 [00:34<00:45,  3.15it/s, est. speed input: 3384.94 toks/s, output: 3.31 toks/s]
Processed prompts:  45%|     | 116/256 [00:35<00:44,  3.15it/s, est. speed input: 3382.17 toks/s, output: 3.30 toks/s]
Processed prompts:  46%|     | 118/256 [00:35<00:43,  3.16it/s, est. speed input: 3379.71 toks/s, output: 3.30 toks/s]
Processed prompts:  47%|     | 120/256 [00:36<00:43,  3.16it/s, est. speed input: 3377.21 toks/s, output: 3.30 toks/s]
Processed prompts:  48%|     | 122/256 [00:37<00:42,  3.16it/s, est. speed input: 3374.83 toks/s, output: 3.30 toks/s]
Processed prompts:  48%|     | 124/256 [00:37<00:41,  3.17it/s, est. speed input: 3372.90 toks/s, output: 3.29 toks/s]
Processed prompts:  49%|     | 126/256 [00:38<00:41,  3.16it/s, est. speed input: 3370.37 toks/s, output: 3.29 toks/s]
Processed prompts:  50%|     | 128/256 [00:38<00:40,  3.16it/s, est. speed input: 3368.23 toks/s, output: 3.29 toks/s]
Processed prompts:  51%|     | 130/256 [00:39<00:39,  3.15it/s, est. speed input: 3365.63 toks/s, output: 3.29 toks/s]
Processed prompts:  52%|    | 132/256 [00:40<00:39,  3.15it/s, est. speed input: 3363.17 toks/s, output: 3.28 toks/s]
Processed prompts:  52%|    | 134/256 [00:40<00:38,  3.15it/s, est. speed input: 3360.99 toks/s, output: 3.28 toks/s]
Processed prompts:  53%|    | 136/256 [00:41<00:38,  3.14it/s, est. speed input: 3358.49 toks/s, output: 3.28 toks/s]
Processed prompts:  54%|    | 138/256 [00:42<00:37,  3.15it/s, est. speed input: 3356.79 toks/s, output: 3.28 toks/s]
Processed prompts:  55%|    | 140/256 [00:42<00:36,  3.15it/s, est. speed input: 3354.71 toks/s, output: 3.28 toks/s]
Processed prompts:  55%|    | 142/256 [00:43<00:36,  3.14it/s, est. speed input: 3352.53 toks/s, output: 3.27 toks/s]
Processed prompts:  56%|    | 144/256 [00:44<00:35,  3.15it/s, est. speed input: 3350.94 toks/s, output: 3.27 toks/s]
Processed prompts:  57%|    | 146/256 [00:44<00:34,  3.15it/s, est. speed input: 3349.05 toks/s, output: 3.27 toks/s]
Processed prompts:  58%|    | 148/256 [00:45<00:34,  3.15it/s, est. speed input: 3347.52 toks/s, output: 3.27 toks/s]
Processed prompts:  59%|    | 150/256 [00:45<00:33,  3.15it/s, est. speed input: 3345.65 toks/s, output: 3.27 toks/s]
Processed prompts:  59%|    | 152/256 [00:46<00:33,  3.14it/s, est. speed input: 3343.62 toks/s, output: 3.27 toks/s]
Processed prompts:  60%|    | 154/256 [00:47<00:32,  3.15it/s, est. speed input: 3342.42 toks/s, output: 3.26 toks/s]
Processed prompts:  61%|    | 156/256 [00:47<00:31,  3.14it/s, est. speed input: 3340.55 toks/s, output: 3.26 toks/s]
Processed prompts:  62%|   | 158/256 [00:48<00:31,  3.15it/s, est. speed input: 3339.24 toks/s, output: 3.26 toks/s]
Processed prompts:  62%|   | 160/256 [00:49<00:30,  3.15it/s, est. speed input: 3337.56 toks/s, output: 3.26 toks/s]
Processed prompts:  63%|   | 162/256 [00:49<00:29,  3.14it/s, est. speed input: 3335.96 toks/s, output: 3.26 toks/s]
Processed prompts:  64%|   | 164/256 [00:50<00:29,  3.15it/s, est. speed input: 3334.74 toks/s, output: 3.26 toks/s]
Processed prompts:  65%|   | 166/256 [00:50<00:28,  3.15it/s, est. speed input: 3333.29 toks/s, output: 3.26 toks/s]
Processed prompts:  66%|   | 168/256 [00:51<00:27,  3.16it/s, est. speed input: 3332.28 toks/s, output: 3.25 toks/s]
Processed prompts:  66%|   | 170/256 [00:52<00:27,  3.15it/s, est. speed input: 3330.94 toks/s, output: 3.25 toks/s]
Processed prompts:  67%|   | 172/256 [00:52<00:26,  3.15it/s, est. speed input: 3329.39 toks/s, output: 3.25 toks/s]
Processed prompts:  68%|   | 174/256 [00:53<00:26,  3.15it/s, est. speed input: 3328.37 toks/s, output: 3.25 toks/s]
Processed prompts:  69%|   | 176/256 [00:54<00:25,  3.15it/s, est. speed input: 3326.96 toks/s, output: 3.25 toks/s]
Processed prompts:  70%|   | 178/256 [00:54<00:24,  3.14it/s, est. speed input: 3325.64 toks/s, output: 3.25 toks/s]
Processed prompts:  70%|   | 180/256 [00:55<00:24,  3.16it/s, est. speed input: 3324.95 toks/s, output: 3.25 toks/s]
Processed prompts:  71%|   | 182/256 [00:56<00:23,  3.15it/s, est. speed input: 3323.63 toks/s, output: 3.25 toks/s]
Processed prompts:  72%|  | 184/256 [00:56<00:22,  3.15it/s, est. speed input: 3322.55 toks/s, output: 3.24 toks/s]
Processed prompts:  73%|  | 186/256 [00:57<00:22,  3.14it/s, est. speed input: 3321.23 toks/s, output: 3.24 toks/s]
Processed prompts:  73%|  | 188/256 [00:57<00:21,  3.14it/s, est. speed input: 3319.81 toks/s, output: 3.24 toks/s]
Processed prompts:  74%|  | 190/256 [00:58<00:21,  3.14it/s, est. speed input: 3318.66 toks/s, output: 3.24 toks/s]
Processed prompts:  75%|  | 192/256 [00:59<00:20,  3.14it/s, est. speed input: 3317.47 toks/s, output: 3.24 toks/s]
Processed prompts:  76%|  | 194/256 [00:59<00:19,  3.14it/s, est. speed input: 3316.63 toks/s, output: 3.24 toks/s]
Processed prompts:  77%|  | 196/256 [01:00<00:19,  3.14it/s, est. speed input: 3315.51 toks/s, output: 3.24 toks/s]
Processed prompts:  77%|  | 198/256 [01:01<00:18,  3.14it/s, est. speed input: 3314.53 toks/s, output: 3.24 toks/s]
Processed prompts:  78%|  | 200/256 [01:01<00:17,  3.15it/s, est. speed input: 3313.63 toks/s, output: 3.24 toks/s]
Processed prompts:  79%|  | 202/256 [01:02<00:15,  3.55it/s, est. speed input: 3325.63 toks/s, output: 3.25 toks/s]
Processed prompts:  80%|  | 204/256 [01:02<00:15,  3.42it/s, est. speed input: 3324.53 toks/s, output: 3.25 toks/s]
Processed prompts:  80%|  | 206/256 [01:03<00:15,  3.33it/s, est. speed input: 3323.49 toks/s, output: 3.25 toks/s]
Processed prompts:  81%| | 208/256 [01:04<00:14,  3.28it/s, est. speed input: 3322.59 toks/s, output: 3.24 toks/s]
Processed prompts:  82%| | 210/256 [01:04<00:14,  3.23it/s, est. speed input: 3321.43 toks/s, output: 3.24 toks/s]
Processed prompts:  83%| | 212/256 [01:05<00:13,  3.20it/s, est. speed input: 3320.23 toks/s, output: 3.24 toks/s]
Processed prompts:  84%| | 214/256 [01:06<00:13,  3.19it/s, est. speed input: 3319.60 toks/s, output: 3.24 toks/s]
Processed prompts:  84%| | 216/256 [01:06<00:12,  3.17it/s, est. speed input: 3318.49 toks/s, output: 3.24 toks/s]
Processed prompts:  85%| | 218/256 [01:07<00:12,  3.16it/s, est. speed input: 3317.44 toks/s, output: 3.24 toks/s]
Processed prompts:  86%| | 220/256 [01:07<00:11,  3.15it/s, est. speed input: 3316.36 toks/s, output: 3.24 toks/s]
Processed prompts:  87%| | 222/256 [01:08<00:10,  3.14it/s, est. speed input: 3315.33 toks/s, output: 3.24 toks/s]
Processed prompts:  88%| | 224/256 [01:09<00:10,  3.15it/s, est. speed input: 3314.52 toks/s, output: 3.24 toks/s]
Processed prompts:  88%| | 226/256 [01:09<00:09,  3.14it/s, est. speed input: 3313.58 toks/s, output: 3.24 toks/s]
Processed prompts:  89%| | 228/256 [01:10<00:08,  3.15it/s, est. speed input: 3312.90 toks/s, output: 3.24 toks/s]
Processed prompts:  90%| | 230/256 [01:11<00:08,  3.14it/s, est. speed input: 3311.90 toks/s, output: 3.23 toks/s]
Processed prompts:  91%| | 232/256 [01:11<00:07,  3.14it/s, est. speed input: 3310.86 toks/s, output: 3.23 toks/s]
Processed prompts:  91%|| 234/256 [01:12<00:07,  3.14it/s, est. speed input: 3310.09 toks/s, output: 3.23 toks/s]
Processed prompts:  92%|| 236/256 [01:13<00:06,  3.13it/s, est. speed input: 3309.09 toks/s, output: 3.23 toks/s]
Processed prompts:  93%|| 238/256 [01:13<00:05,  3.14it/s, est. speed input: 3308.49 toks/s, output: 3.23 toks/s]
Processed prompts:  94%|| 240/256 [01:14<00:05,  3.14it/s, est. speed input: 3307.68 toks/s, output: 3.23 toks/s]
Processed prompts:  95%|| 242/256 [01:14<00:04,  3.14it/s, est. speed input: 3306.81 toks/s, output: 3.23 toks/s]
Processed prompts:  95%|| 244/256 [01:15<00:03,  3.14it/s, est. speed input: 3306.14 toks/s, output: 3.23 toks/s]
Processed prompts:  96%|| 246/256 [01:16<00:03,  3.14it/s, est. speed input: 3305.41 toks/s, output: 3.23 toks/s]
Processed prompts:  97%|| 248/256 [01:16<00:02,  3.15it/s, est. speed input: 3304.89 toks/s, output: 3.23 toks/s]
Processed prompts:  98%|| 250/256 [01:17<00:01,  3.14it/s, est. speed input: 3303.95 toks/s, output: 3.23 toks/s]
Processed prompts:  98%|| 252/256 [01:18<00:01,  3.13it/s, est. speed input: 3303.06 toks/s, output: 3.23 toks/s]
Processed prompts:  99%|| 254/256 [01:18<00:00,  3.15it/s, est. speed input: 3302.73 toks/s, output: 3.23 toks/s]
Processed prompts: 100%|| 256/256 [01:19<00:00,  3.71it/s, est. speed input: 3315.50 toks/s, output: 3.24 toks/s]
Processed prompts: 100%|| 256/256 [01:19<00:00,  3.71it/s, est. speed input: 3315.50 toks/s, output: 3.24 toks/s]
Processed prompts: 100%|| 256/256 [01:19<00:00,  3.24it/s, est. speed input: 3315.50 toks/s, output: 3.24 toks/s]
[rank0]:[W127 04:25:47.945690780 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-27 04:26:05
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 04:26:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 04:26:13 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2107759) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2107759) WARNING 01-27 04:28:30 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.14 requests/s, 3216.62 total tokens/s, 3.14 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-27 04:26:12] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 04:26:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:26:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 04:26:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:26:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:26:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:26:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:26:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:26:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:26:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 04:26:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 04:26:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 04:26:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 04:26:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 04:26:16] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 04:26:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:26:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 04:26:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:26:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:26:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:26:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:26:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:26:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:26:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 04:26:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 04:26:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 04:26:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 04:26:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2107759) [2026-01-27 04:26:17] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2107759) [2026-01-27 04:26:17] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2107759) [2026-01-27 04:26:17] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2107759) [2026-01-27 04:26:17] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=2107759) [2026-01-27 04:26:17] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=2107759) [2026-01-27 04:26:17] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=2107759) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2107759) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.48s/it]
(EngineCore_DP0 pid=2107759) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:41<00:45, 22.63s/it]
(EngineCore_DP0 pid=2107759) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:16<00:28, 28.54s/it]
(EngineCore_DP0 pid=2107759) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:58<00:00, 33.64s/it]
(EngineCore_DP0 pid=2107759) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:58<00:00, 29.51s/it]
(EngineCore_DP0 pid=2107759) 
(EngineCore_DP0 pid=2107759) [2026-01-27 04:28:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=2107759) [2026-01-27 04:28:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 44040192 bytes
(EngineCore_DP0 pid=2107759) [2026-01-27 04:28:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=2107759) [2026-01-27 04:28:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=2107759) [2026-01-27 04:28:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=2107759) [2026-01-27 04:28:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 169869312 bytes
(EngineCore_DP0 pid=2107759) [2026-01-27 04:28:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=2107759) [2026-01-27 04:28:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 85032960 bytes
(EngineCore_DP0 pid=2107759) 2026-01-27 04:28:28,265 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2107759) 2026-01-27 04:28:28,704 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/512 [00:00<00:54,  9.37it/s]
Adding requests:   5%|         | 28/512 [00:00<00:03, 157.61it/s]
Adding requests:  14%|        | 70/512 [00:00<00:01, 271.36it/s]
Adding requests:  21%|        | 108/512 [00:00<00:01, 311.23it/s]
Adding requests:  29%|       | 150/512 [00:00<00:01, 348.60it/s]
Adding requests:  38%|      | 197/512 [00:00<00:00, 388.64it/s]
Adding requests:  47%|     | 242/512 [00:00<00:00, 406.78it/s]
Adding requests:  56%|    | 288/512 [00:00<00:00, 421.92it/s]
Adding requests:  65%|   | 335/512 [00:00<00:00, 435.60it/s]
Adding requests:  74%|  | 381/512 [00:01<00:00, 440.82it/s]
Adding requests:  84%| | 429/512 [00:01<00:00, 449.70it/s]
Adding requests:  93%|| 475/512 [00:01<00:00, 452.67it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 394.95it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 2/512 [00:00<02:16,  3.73it/s, est. speed input: 3822.31 toks/s, output: 3.73 toks/s]
Processed prompts:   1%|          | 6/512 [00:01<02:33,  3.31it/s, est. speed input: 3424.00 toks/s, output: 3.34 toks/s]
Processed prompts:   2%|         | 10/512 [00:03<02:35,  3.24it/s, est. speed input: 3351.08 toks/s, output: 3.27 toks/s]
Processed prompts:   3%|         | 14/512 [00:04<02:35,  3.20it/s, est. speed input: 3316.46 toks/s, output: 3.24 toks/s]
Processed prompts:   4%|         | 18/512 [00:05<02:34,  3.19it/s, est. speed input: 3299.75 toks/s, output: 3.22 toks/s]
Processed prompts:   4%|         | 22/512 [00:06<02:34,  3.17it/s, est. speed input: 3285.21 toks/s, output: 3.21 toks/s]
Processed prompts:   5%|         | 26/512 [00:08<02:33,  3.17it/s, est. speed input: 3276.37 toks/s, output: 3.20 toks/s]
Processed prompts:   6%|         | 30/512 [00:09<02:32,  3.16it/s, est. speed input: 3269.26 toks/s, output: 3.19 toks/s]
Processed prompts:   7%|         | 34/512 [00:10<02:31,  3.16it/s, est. speed input: 3264.51 toks/s, output: 3.19 toks/s]
Processed prompts:   7%|         | 38/512 [00:11<02:30,  3.15it/s, est. speed input: 3259.80 toks/s, output: 3.18 toks/s]
Processed prompts:   8%|         | 42/512 [00:13<02:29,  3.15it/s, est. speed input: 3254.85 toks/s, output: 3.18 toks/s]
Processed prompts:   9%|         | 46/512 [00:14<02:27,  3.15it/s, est. speed input: 3252.63 toks/s, output: 3.18 toks/s]
Processed prompts:  10%|         | 50/512 [00:15<02:26,  3.14it/s, est. speed input: 3248.83 toks/s, output: 3.17 toks/s]
Processed prompts:  11%|         | 54/512 [00:17<02:25,  3.14it/s, est. speed input: 3246.56 toks/s, output: 3.17 toks/s]
Processed prompts:  11%|        | 58/512 [00:18<02:24,  3.14it/s, est. speed input: 3243.67 toks/s, output: 3.17 toks/s]
Processed prompts:  12%|        | 62/512 [00:19<02:23,  3.14it/s, est. speed input: 3241.09 toks/s, output: 3.17 toks/s]
Processed prompts:  13%|        | 66/512 [00:20<02:22,  3.14it/s, est. speed input: 3239.74 toks/s, output: 3.16 toks/s]
Processed prompts:  14%|        | 70/512 [00:22<02:20,  3.14it/s, est. speed input: 3238.21 toks/s, output: 3.16 toks/s]
Processed prompts:  14%|        | 74/512 [00:23<02:19,  3.14it/s, est. speed input: 3236.90 toks/s, output: 3.16 toks/s]
Processed prompts:  15%|        | 78/512 [00:24<02:18,  3.14it/s, est. speed input: 3236.04 toks/s, output: 3.16 toks/s]
Processed prompts:  16%|        | 82/512 [00:25<02:17,  3.13it/s, est. speed input: 3234.14 toks/s, output: 3.16 toks/s]
Processed prompts:  17%|        | 86/512 [00:27<02:15,  3.14it/s, est. speed input: 3233.07 toks/s, output: 3.16 toks/s]
Processed prompts:  18%|        | 90/512 [00:28<02:14,  3.13it/s, est. speed input: 3231.66 toks/s, output: 3.16 toks/s]
Processed prompts:  18%|        | 94/512 [00:29<02:13,  3.13it/s, est. speed input: 3230.70 toks/s, output: 3.15 toks/s]
Processed prompts:  19%|        | 98/512 [00:31<02:12,  3.13it/s, est. speed input: 3229.65 toks/s, output: 3.15 toks/s]
Processed prompts:  20%|        | 102/512 [00:32<02:10,  3.13it/s, est. speed input: 3229.11 toks/s, output: 3.15 toks/s]
Processed prompts:  21%|        | 106/512 [00:33<02:09,  3.14it/s, est. speed input: 3228.73 toks/s, output: 3.15 toks/s]
Processed prompts:  21%|       | 110/512 [00:34<02:08,  3.14it/s, est. speed input: 3227.94 toks/s, output: 3.15 toks/s]
Processed prompts:  22%|       | 114/512 [00:36<02:06,  3.13it/s, est. speed input: 3227.23 toks/s, output: 3.15 toks/s]
Processed prompts:  23%|       | 118/512 [00:37<02:05,  3.13it/s, est. speed input: 3226.28 toks/s, output: 3.15 toks/s]
Processed prompts:  24%|       | 122/512 [00:38<02:04,  3.14it/s, est. speed input: 3226.29 toks/s, output: 3.15 toks/s]
Processed prompts:  25%|       | 126/512 [00:39<02:02,  3.14it/s, est. speed input: 3226.14 toks/s, output: 3.15 toks/s]
Processed prompts:  25%|       | 130/512 [00:41<02:01,  3.14it/s, est. speed input: 3225.49 toks/s, output: 3.15 toks/s]
Processed prompts:  26%|       | 134/512 [00:42<02:00,  3.13it/s, est. speed input: 3224.67 toks/s, output: 3.15 toks/s]
Processed prompts:  27%|       | 138/512 [00:43<01:59,  3.13it/s, est. speed input: 3223.93 toks/s, output: 3.15 toks/s]
Processed prompts:  28%|       | 142/512 [00:45<01:58,  3.13it/s, est. speed input: 3223.42 toks/s, output: 3.15 toks/s]
Processed prompts:  29%|       | 146/512 [00:46<01:56,  3.13it/s, est. speed input: 3222.97 toks/s, output: 3.15 toks/s]
Processed prompts:  29%|       | 150/512 [00:47<01:55,  3.13it/s, est. speed input: 3222.53 toks/s, output: 3.15 toks/s]
Processed prompts:  30%|       | 154/512 [00:48<01:54,  3.13it/s, est. speed input: 3222.15 toks/s, output: 3.15 toks/s]
Processed prompts:  31%|       | 158/512 [00:50<01:53,  3.13it/s, est. speed input: 3221.31 toks/s, output: 3.15 toks/s]
Processed prompts:  32%|      | 162/512 [00:51<01:51,  3.13it/s, est. speed input: 3220.78 toks/s, output: 3.15 toks/s]
Processed prompts:  32%|      | 166/512 [00:52<01:50,  3.13it/s, est. speed input: 3220.42 toks/s, output: 3.14 toks/s]
Processed prompts:  33%|      | 170/512 [00:54<01:49,  3.13it/s, est. speed input: 3220.00 toks/s, output: 3.14 toks/s]
Processed prompts:  34%|      | 174/512 [00:55<01:48,  3.12it/s, est. speed input: 3219.35 toks/s, output: 3.14 toks/s]
Processed prompts:  35%|      | 178/512 [00:56<01:46,  3.13it/s, est. speed input: 3219.08 toks/s, output: 3.14 toks/s]
Processed prompts:  36%|      | 182/512 [00:57<01:45,  3.12it/s, est. speed input: 3218.25 toks/s, output: 3.14 toks/s]
Processed prompts:  36%|      | 186/512 [00:59<01:44,  3.13it/s, est. speed input: 3218.66 toks/s, output: 3.14 toks/s]
Processed prompts:  37%|      | 190/512 [01:00<01:42,  3.13it/s, est. speed input: 3218.31 toks/s, output: 3.14 toks/s]
Processed prompts:  38%|      | 194/512 [01:01<01:41,  3.13it/s, est. speed input: 3217.75 toks/s, output: 3.14 toks/s]
Processed prompts:  39%|      | 198/512 [01:03<01:40,  3.13it/s, est. speed input: 3217.63 toks/s, output: 3.14 toks/s]
Processed prompts:  39%|      | 202/512 [01:04<01:32,  3.33it/s, est. speed input: 3230.55 toks/s, output: 3.15 toks/s]
Processed prompts:  40%|      | 206/512 [01:05<01:33,  3.27it/s, est. speed input: 3229.99 toks/s, output: 3.15 toks/s]
Processed prompts:  41%|      | 210/512 [01:06<01:33,  3.23it/s, est. speed input: 3229.54 toks/s, output: 3.15 toks/s]
Processed prompts:  42%|     | 214/512 [01:07<01:33,  3.19it/s, est. speed input: 3228.86 toks/s, output: 3.15 toks/s]
Processed prompts:  43%|     | 218/512 [01:09<01:32,  3.17it/s, est. speed input: 3228.26 toks/s, output: 3.15 toks/s]
Processed prompts:  43%|     | 222/512 [01:10<01:31,  3.16it/s, est. speed input: 3227.91 toks/s, output: 3.15 toks/s]
Processed prompts:  44%|     | 226/512 [01:11<01:30,  3.15it/s, est. speed input: 3227.38 toks/s, output: 3.15 toks/s]
Processed prompts:  45%|     | 230/512 [01:12<01:29,  3.14it/s, est. speed input: 3226.93 toks/s, output: 3.15 toks/s]
Processed prompts:  46%|     | 234/512 [01:14<01:28,  3.14it/s, est. speed input: 3226.35 toks/s, output: 3.15 toks/s]
Processed prompts:  46%|     | 238/512 [01:15<01:27,  3.13it/s, est. speed input: 3225.90 toks/s, output: 3.15 toks/s]
Processed prompts:  47%|     | 242/512 [01:16<01:26,  3.13it/s, est. speed input: 3225.52 toks/s, output: 3.15 toks/s]
Processed prompts:  48%|     | 246/512 [01:18<01:24,  3.13it/s, est. speed input: 3225.29 toks/s, output: 3.15 toks/s]
Processed prompts:  49%|     | 250/512 [01:19<01:23,  3.13it/s, est. speed input: 3224.79 toks/s, output: 3.15 toks/s]
Processed prompts:  50%|     | 254/512 [01:20<01:22,  3.12it/s, est. speed input: 3224.23 toks/s, output: 3.15 toks/s]
Processed prompts:  50%|     | 258/512 [01:21<01:21,  3.12it/s, est. speed input: 3223.82 toks/s, output: 3.15 toks/s]
Processed prompts:  51%|     | 262/512 [01:23<01:19,  3.13it/s, est. speed input: 3223.50 toks/s, output: 3.15 toks/s]
Processed prompts:  52%|    | 266/512 [01:24<01:18,  3.12it/s, est. speed input: 3223.05 toks/s, output: 3.15 toks/s]
Processed prompts:  53%|    | 270/512 [01:25<01:17,  3.12it/s, est. speed input: 3222.72 toks/s, output: 3.15 toks/s]
Processed prompts:  54%|    | 274/512 [01:27<01:16,  3.12it/s, est. speed input: 3222.06 toks/s, output: 3.15 toks/s]
Processed prompts:  54%|    | 278/512 [01:28<01:15,  3.12it/s, est. speed input: 3221.73 toks/s, output: 3.15 toks/s]
Processed prompts:  55%|    | 282/512 [01:29<01:13,  3.12it/s, est. speed input: 3221.48 toks/s, output: 3.15 toks/s]
Processed prompts:  56%|    | 286/512 [01:30<01:12,  3.12it/s, est. speed input: 3221.14 toks/s, output: 3.15 toks/s]
Processed prompts:  57%|    | 290/512 [01:32<01:11,  3.12it/s, est. speed input: 3220.81 toks/s, output: 3.15 toks/s]
Processed prompts:  57%|    | 294/512 [01:33<01:09,  3.12it/s, est. speed input: 3220.57 toks/s, output: 3.15 toks/s]
Processed prompts:  58%|    | 298/512 [01:34<01:08,  3.12it/s, est. speed input: 3220.23 toks/s, output: 3.14 toks/s]
Processed prompts:  59%|    | 302/512 [01:36<01:07,  3.13it/s, est. speed input: 3220.20 toks/s, output: 3.14 toks/s]
Processed prompts:  60%|    | 306/512 [01:37<01:01,  3.34it/s, est. speed input: 3228.74 toks/s, output: 3.15 toks/s]
Processed prompts:  61%|    | 310/512 [01:38<01:01,  3.27it/s, est. speed input: 3228.25 toks/s, output: 3.15 toks/s]
Processed prompts:  61%|   | 314/512 [01:39<01:01,  3.22it/s, est. speed input: 3227.68 toks/s, output: 3.15 toks/s]
Processed prompts:  62%|   | 318/512 [01:40<01:00,  3.19it/s, est. speed input: 3227.30 toks/s, output: 3.15 toks/s]
Processed prompts:  63%|   | 322/512 [01:42<00:59,  3.17it/s, est. speed input: 3226.90 toks/s, output: 3.15 toks/s]
Processed prompts:  64%|   | 326/512 [01:43<00:58,  3.16it/s, est. speed input: 3226.66 toks/s, output: 3.15 toks/s]
Processed prompts:  64%|   | 330/512 [01:44<00:57,  3.14it/s, est. speed input: 3226.21 toks/s, output: 3.15 toks/s]
Processed prompts:  65%|   | 334/512 [01:46<00:56,  3.14it/s, est. speed input: 3225.86 toks/s, output: 3.15 toks/s]
Processed prompts:  66%|   | 338/512 [01:47<00:55,  3.14it/s, est. speed input: 3225.68 toks/s, output: 3.15 toks/s]
Processed prompts:  67%|   | 342/512 [01:48<00:54,  3.13it/s, est. speed input: 3225.36 toks/s, output: 3.15 toks/s]
Processed prompts:  68%|   | 346/512 [01:49<00:53,  3.13it/s, est. speed input: 3225.01 toks/s, output: 3.15 toks/s]
Processed prompts:  68%|   | 350/512 [01:51<00:51,  3.12it/s, est. speed input: 3224.50 toks/s, output: 3.15 toks/s]
Processed prompts:  69%|   | 354/512 [01:52<00:50,  3.12it/s, est. speed input: 3224.15 toks/s, output: 3.15 toks/s]
Processed prompts:  70%|   | 358/512 [01:53<00:49,  3.12it/s, est. speed input: 3223.91 toks/s, output: 3.15 toks/s]
Processed prompts:  71%|   | 362/512 [01:54<00:48,  3.12it/s, est. speed input: 3223.67 toks/s, output: 3.15 toks/s]
Processed prompts:  71%|  | 366/512 [01:56<00:46,  3.12it/s, est. speed input: 3223.41 toks/s, output: 3.15 toks/s]
Processed prompts:  72%|  | 370/512 [01:57<00:45,  3.12it/s, est. speed input: 3223.09 toks/s, output: 3.15 toks/s]
Processed prompts:  73%|  | 374/512 [01:58<00:44,  3.12it/s, est. speed input: 3222.81 toks/s, output: 3.15 toks/s]
Processed prompts:  74%|  | 378/512 [02:00<00:42,  3.12it/s, est. speed input: 3222.58 toks/s, output: 3.15 toks/s]
Processed prompts:  75%|  | 382/512 [02:01<00:41,  3.12it/s, est. speed input: 3222.30 toks/s, output: 3.15 toks/s]
Processed prompts:  75%|  | 386/512 [02:02<00:40,  3.12it/s, est. speed input: 3222.09 toks/s, output: 3.15 toks/s]
Processed prompts:  76%|  | 390/512 [02:03<00:39,  3.12it/s, est. speed input: 3221.69 toks/s, output: 3.15 toks/s]
Processed prompts:  77%|  | 394/512 [02:05<00:37,  3.12it/s, est. speed input: 3221.44 toks/s, output: 3.15 toks/s]
Processed prompts:  78%|  | 398/512 [02:06<00:36,  3.13it/s, est. speed input: 3221.35 toks/s, output: 3.15 toks/s]
Processed prompts:  79%|  | 402/512 [02:07<00:35,  3.13it/s, est. speed input: 3221.25 toks/s, output: 3.15 toks/s]
Processed prompts:  79%|  | 406/512 [02:09<00:33,  3.13it/s, est. speed input: 3221.12 toks/s, output: 3.15 toks/s]
Processed prompts:  80%|  | 410/512 [02:10<00:32,  3.13it/s, est. speed input: 3220.85 toks/s, output: 3.15 toks/s]
Processed prompts:  81%|  | 414/512 [02:11<00:31,  3.13it/s, est. speed input: 3220.66 toks/s, output: 3.15 toks/s]
Processed prompts:  82%| | 418/512 [02:12<00:30,  3.13it/s, est. speed input: 3220.44 toks/s, output: 3.14 toks/s]
Processed prompts:  82%| | 422/512 [02:14<00:28,  3.13it/s, est. speed input: 3220.24 toks/s, output: 3.14 toks/s]
Processed prompts:  83%| | 426/512 [02:15<00:27,  3.12it/s, est. speed input: 3219.93 toks/s, output: 3.14 toks/s]
Processed prompts:  84%| | 430/512 [02:16<00:26,  3.12it/s, est. speed input: 3219.76 toks/s, output: 3.14 toks/s]
Processed prompts:  85%| | 434/512 [02:17<00:23,  3.33it/s, est. speed input: 3225.79 toks/s, output: 3.15 toks/s]
Processed prompts:  86%| | 438/512 [02:19<00:22,  3.27it/s, est. speed input: 3225.59 toks/s, output: 3.15 toks/s]
Processed prompts:  86%| | 442/512 [02:20<00:21,  3.22it/s, est. speed input: 3225.38 toks/s, output: 3.15 toks/s]
Processed prompts:  87%| | 446/512 [02:21<00:20,  3.20it/s, est. speed input: 3225.19 toks/s, output: 3.15 toks/s]
Processed prompts:  88%| | 450/512 [02:22<00:19,  3.17it/s, est. speed input: 3224.82 toks/s, output: 3.15 toks/s]
Processed prompts:  89%| | 454/512 [02:24<00:18,  3.15it/s, est. speed input: 3224.56 toks/s, output: 3.15 toks/s]
Processed prompts:  89%| | 458/512 [02:25<00:17,  3.14it/s, est. speed input: 3224.32 toks/s, output: 3.15 toks/s]
Processed prompts:  90%| | 462/512 [02:26<00:15,  3.14it/s, est. speed input: 3224.15 toks/s, output: 3.15 toks/s]
Processed prompts:  91%| | 466/512 [02:28<00:14,  3.14it/s, est. speed input: 3224.04 toks/s, output: 3.15 toks/s]
Processed prompts:  92%|| 470/512 [02:29<00:13,  3.13it/s, est. speed input: 3223.63 toks/s, output: 3.15 toks/s]
Processed prompts:  93%|| 474/512 [02:30<00:12,  3.13it/s, est. speed input: 3223.41 toks/s, output: 3.15 toks/s]
Processed prompts:  93%|| 478/512 [02:31<00:10,  3.13it/s, est. speed input: 3223.28 toks/s, output: 3.15 toks/s]
Processed prompts:  94%|| 482/512 [02:33<00:09,  3.13it/s, est. speed input: 3223.04 toks/s, output: 3.15 toks/s]
Processed prompts:  95%|| 486/512 [02:34<00:08,  3.12it/s, est. speed input: 3222.83 toks/s, output: 3.15 toks/s]
Processed prompts:  96%|| 490/512 [02:35<00:07,  3.12it/s, est. speed input: 3222.60 toks/s, output: 3.15 toks/s]
Processed prompts:  96%|| 494/512 [02:36<00:05,  3.12it/s, est. speed input: 3222.42 toks/s, output: 3.15 toks/s]
Processed prompts:  97%|| 498/512 [02:38<00:04,  3.12it/s, est. speed input: 3222.14 toks/s, output: 3.15 toks/s]
Processed prompts:  98%|| 502/512 [02:39<00:03,  3.12it/s, est. speed input: 3221.97 toks/s, output: 3.15 toks/s]
Processed prompts:  99%|| 506/512 [02:40<00:01,  3.12it/s, est. speed input: 3221.74 toks/s, output: 3.15 toks/s]
Processed prompts: 100%|| 510/512 [02:41<00:00,  3.37it/s, est. speed input: 3227.79 toks/s, output: 3.15 toks/s]
Processed prompts: 100%|| 512/512 [02:41<00:00,  3.37it/s, est. speed input: 3240.44 toks/s, output: 3.16 toks/s]
Processed prompts: 100%|| 512/512 [02:41<00:00,  3.16it/s, est. speed input: 3240.44 toks/s, output: 3.16 toks/s]
[rank0]:[W127 04:31:13.816834286 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-27 04:31:23
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 04:31:33 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 04:31:34 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2112370) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2112370) WARNING 01-27 04:34:03 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.13 requests/s, 3212.08 total tokens/s, 3.13 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-27 04:31:33] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 04:31:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:31:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 04:31:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:31:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:31:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:31:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:31:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:31:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:31:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 04:31:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 04:31:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 04:31:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 04:31:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 04:31:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 04:31:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:31:37] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 04:31:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:31:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:31:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:31:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:31:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:31:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:31:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 04:31:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 04:31:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 04:31:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 04:31:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2112370) [2026-01-27 04:31:38] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2112370) [2026-01-27 04:31:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2112370) [2026-01-27 04:31:38] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2112370) [2026-01-27 04:31:38] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=2112370) [2026-01-27 04:31:38] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=2112370) [2026-01-27 04:31:38] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=2112370) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2112370) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:26,  8.70s/it]
(EngineCore_DP0 pid=2112370) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:41<00:45, 22.95s/it]
(EngineCore_DP0 pid=2112370) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:17<00:29, 29.05s/it]
(EngineCore_DP0 pid=2112370) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:58<00:00, 33.76s/it]
(EngineCore_DP0 pid=2112370) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:58<00:00, 29.73s/it]
(EngineCore_DP0 pid=2112370) 
(EngineCore_DP0 pid=2112370) [2026-01-27 04:33:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=2112370) [2026-01-27 04:33:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 44040192 bytes
(EngineCore_DP0 pid=2112370) [2026-01-27 04:33:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=2112370) [2026-01-27 04:33:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=2112370) [2026-01-27 04:33:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=2112370) [2026-01-27 04:33:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 169869312 bytes
(EngineCore_DP0 pid=2112370) [2026-01-27 04:33:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=2112370) [2026-01-27 04:33:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 85032960 bytes
(EngineCore_DP0 pid=2112370) 2026-01-27 04:33:52,744 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2112370) 2026-01-27 04:33:53,949 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/1024 [00:01<17:45,  1.04s/it]
Adding requests:   0%|          | 2/1024 [00:01<09:33,  1.78it/s]
Adding requests:   0%|          | 3/1024 [00:01<06:12,  2.74it/s]
Adding requests:   0%|          | 5/1024 [00:01<03:34,  4.75it/s]
Adding requests:   1%|          | 7/1024 [00:01<02:22,  7.12it/s]
Adding requests:   1%|          | 10/1024 [00:01<01:30, 11.17it/s]
Adding requests:   1%|         | 13/1024 [00:01<01:08, 14.76it/s]
Adding requests:   2%|         | 21/1024 [00:02<00:34, 29.01it/s]
Adding requests:   4%|         | 44/1024 [00:02<00:12, 76.51it/s]
Adding requests:   7%|         | 72/1024 [00:02<00:07, 127.12it/s]
Adding requests:  10%|         | 104/1024 [00:02<00:05, 176.47it/s]
Adding requests:  14%|        | 144/1024 [00:02<00:03, 236.11it/s]
Adding requests:  18%|        | 186/1024 [00:02<00:02, 286.56it/s]
Adding requests:  22%|       | 229/1024 [00:02<00:02, 325.10it/s]
Adding requests:  26%|       | 270/1024 [00:02<00:02, 349.44it/s]
Adding requests:  30%|       | 309/1024 [00:02<00:01, 360.01it/s]
Adding requests:  34%|      | 350/1024 [00:02<00:01, 372.91it/s]
Adding requests:  39%|      | 395/1024 [00:03<00:01, 395.46it/s]
Adding requests:  43%|     | 440/1024 [00:03<00:01, 409.45it/s]
Adding requests:  48%|     | 487/1024 [00:03<00:01, 426.32it/s]
Adding requests:  52%|    | 534/1024 [00:03<00:01, 438.12it/s]
Adding requests:  56%|    | 578/1024 [00:03<00:01, 432.06it/s]
Adding requests:  61%|    | 623/1024 [00:03<00:00, 435.60it/s]
Adding requests:  65%|   | 667/1024 [00:03<00:00, 424.76it/s]
Adding requests:  69%|   | 711/1024 [00:03<00:00, 428.75it/s]
Adding requests:  74%|  | 754/1024 [00:03<00:00, 415.75it/s]
Adding requests:  78%|  | 798/1024 [00:03<00:00, 419.78it/s]
Adding requests:  82%| | 844/1024 [00:04<00:00, 431.22it/s]
Adding requests:  87%| | 890/1024 [00:04<00:00, 437.69it/s]
Adding requests:  91%| | 934/1024 [00:04<00:00, 432.97it/s]
Adding requests:  96%|| 978/1024 [00:04<00:00, 429.81it/s]
Adding requests: 100%|| 1022/1024 [00:04<00:00, 431.20it/s]
Adding requests: 100%|| 1024/1024 [00:04<00:00, 228.38it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 5/1024 [00:00<01:48,  9.37it/s, est. speed input: 9600.64 toks/s, output: 9.38 toks/s]
Processed prompts:   1%|         | 13/1024 [00:03<04:15,  3.96it/s, est. speed input: 4346.18 toks/s, output: 4.24 toks/s]
Processed prompts:   2%|         | 21/1024 [00:05<04:45,  3.51it/s, est. speed input: 3840.71 toks/s, output: 3.75 toks/s]
Processed prompts:   3%|         | 29/1024 [00:08<04:56,  3.36it/s, est. speed input: 3651.95 toks/s, output: 3.57 toks/s]
Processed prompts:   4%|         | 37/1024 [00:10<05:01,  3.28it/s, est. speed input: 3551.66 toks/s, output: 3.47 toks/s]
Processed prompts:   4%|         | 45/1024 [00:13<05:03,  3.23it/s, est. speed input: 3488.00 toks/s, output: 3.41 toks/s]
Processed prompts:   5%|         | 53/1024 [00:15<05:02,  3.21it/s, est. speed input: 3446.60 toks/s, output: 3.37 toks/s]
Processed prompts:   6%|         | 61/1024 [00:18<05:02,  3.19it/s, est. speed input: 3414.86 toks/s, output: 3.33 toks/s]
Processed prompts:   7%|         | 69/1024 [00:20<05:01,  3.17it/s, est. speed input: 3391.14 toks/s, output: 3.31 toks/s]
Processed prompts:   8%|         | 77/1024 [00:23<04:59,  3.17it/s, est. speed input: 3373.43 toks/s, output: 3.29 toks/s]
Processed prompts:   8%|         | 85/1024 [00:25<04:57,  3.16it/s, est. speed input: 3359.07 toks/s, output: 3.28 toks/s]
Processed prompts:   9%|         | 93/1024 [00:28<04:54,  3.16it/s, est. speed input: 3346.77 toks/s, output: 3.27 toks/s]
Processed prompts:  10%|         | 101/1024 [00:31<04:52,  3.15it/s, est. speed input: 3336.18 toks/s, output: 3.26 toks/s]
Processed prompts:  11%|         | 109/1024 [00:33<04:50,  3.15it/s, est. speed input: 3327.34 toks/s, output: 3.25 toks/s]
Processed prompts:  11%|        | 117/1024 [00:36<04:48,  3.15it/s, est. speed input: 3319.16 toks/s, output: 3.24 toks/s]
Processed prompts:  12%|        | 125/1024 [00:38<04:45,  3.14it/s, est. speed input: 3312.39 toks/s, output: 3.23 toks/s]
Processed prompts:  13%|        | 133/1024 [00:41<04:43,  3.14it/s, est. speed input: 3306.44 toks/s, output: 3.23 toks/s]
Processed prompts:  14%|        | 141/1024 [00:43<04:41,  3.14it/s, est. speed input: 3301.03 toks/s, output: 3.22 toks/s]
Processed prompts:  15%|        | 149/1024 [00:46<04:38,  3.14it/s, est. speed input: 3296.19 toks/s, output: 3.22 toks/s]
Processed prompts:  15%|        | 157/1024 [00:48<04:35,  3.14it/s, est. speed input: 3292.14 toks/s, output: 3.21 toks/s]
Processed prompts:  16%|        | 165/1024 [00:51<04:33,  3.14it/s, est. speed input: 3288.31 toks/s, output: 3.21 toks/s]
Processed prompts:  17%|        | 173/1024 [00:53<04:30,  3.14it/s, est. speed input: 3285.10 toks/s, output: 3.21 toks/s]
Processed prompts:  18%|        | 181/1024 [00:56<04:28,  3.14it/s, est. speed input: 3281.79 toks/s, output: 3.20 toks/s]
Processed prompts:  18%|        | 189/1024 [00:59<04:25,  3.14it/s, est. speed input: 3279.10 toks/s, output: 3.20 toks/s]
Processed prompts:  19%|        | 197/1024 [01:01<04:15,  3.24it/s, est. speed input: 3289.85 toks/s, output: 3.21 toks/s]
Processed prompts:  20%|        | 205/1024 [01:03<04:15,  3.21it/s, est. speed input: 3286.75 toks/s, output: 3.21 toks/s]
Processed prompts:  21%|        | 213/1024 [01:06<04:14,  3.18it/s, est. speed input: 3283.89 toks/s, output: 3.21 toks/s]
Processed prompts:  22%|       | 221/1024 [01:08<04:13,  3.17it/s, est. speed input: 3281.17 toks/s, output: 3.20 toks/s]
Processed prompts:  22%|       | 229/1024 [01:11<04:11,  3.16it/s, est. speed input: 3279.26 toks/s, output: 3.20 toks/s]
Processed prompts:  23%|       | 237/1024 [01:14<04:09,  3.15it/s, est. speed input: 3276.66 toks/s, output: 3.20 toks/s]
Processed prompts:  24%|       | 245/1024 [01:16<04:07,  3.15it/s, est. speed input: 3274.62 toks/s, output: 3.20 toks/s]
Processed prompts:  25%|       | 253/1024 [01:19<04:05,  3.15it/s, est. speed input: 3272.72 toks/s, output: 3.20 toks/s]
Processed prompts:  25%|       | 261/1024 [01:21<04:02,  3.15it/s, est. speed input: 3270.98 toks/s, output: 3.19 toks/s]
Processed prompts:  26%|       | 269/1024 [01:24<04:00,  3.14it/s, est. speed input: 3269.37 toks/s, output: 3.19 toks/s]
Processed prompts:  27%|       | 277/1024 [01:26<03:57,  3.14it/s, est. speed input: 3267.67 toks/s, output: 3.19 toks/s]
Processed prompts:  28%|       | 285/1024 [01:29<03:55,  3.14it/s, est. speed input: 3266.18 toks/s, output: 3.19 toks/s]
Processed prompts:  29%|       | 293/1024 [01:31<03:52,  3.14it/s, est. speed input: 3264.74 toks/s, output: 3.19 toks/s]
Processed prompts:  29%|       | 301/1024 [01:34<03:43,  3.23it/s, est. speed input: 3272.00 toks/s, output: 3.20 toks/s]
Processed prompts:  30%|       | 309/1024 [01:36<03:42,  3.21it/s, est. speed input: 3270.56 toks/s, output: 3.19 toks/s]
Processed prompts:  31%|       | 317/1024 [01:39<03:41,  3.19it/s, est. speed input: 3269.09 toks/s, output: 3.19 toks/s]
Processed prompts:  32%|      | 325/1024 [01:41<03:40,  3.17it/s, est. speed input: 3267.61 toks/s, output: 3.19 toks/s]
Processed prompts:  33%|      | 333/1024 [01:44<03:38,  3.16it/s, est. speed input: 3266.17 toks/s, output: 3.19 toks/s]
Processed prompts:  33%|      | 341/1024 [01:46<03:36,  3.15it/s, est. speed input: 3264.81 toks/s, output: 3.19 toks/s]
Processed prompts:  34%|      | 349/1024 [01:49<03:34,  3.15it/s, est. speed input: 3263.59 toks/s, output: 3.19 toks/s]
Processed prompts:  35%|      | 357/1024 [01:52<03:32,  3.14it/s, est. speed input: 3262.42 toks/s, output: 3.19 toks/s]
Processed prompts:  36%|      | 365/1024 [01:54<03:29,  3.14it/s, est. speed input: 3261.39 toks/s, output: 3.18 toks/s]
Processed prompts:  36%|      | 373/1024 [01:57<03:27,  3.14it/s, est. speed input: 3260.42 toks/s, output: 3.18 toks/s]
Processed prompts:  37%|      | 381/1024 [01:59<03:24,  3.14it/s, est. speed input: 3259.33 toks/s, output: 3.18 toks/s]
Processed prompts:  38%|      | 389/1024 [02:02<03:22,  3.14it/s, est. speed input: 3258.36 toks/s, output: 3.18 toks/s]
Processed prompts:  39%|      | 397/1024 [02:04<03:19,  3.14it/s, est. speed input: 3257.39 toks/s, output: 3.18 toks/s]
Processed prompts:  40%|      | 405/1024 [02:07<03:17,  3.14it/s, est. speed input: 3256.59 toks/s, output: 3.18 toks/s]
Processed prompts:  40%|      | 413/1024 [02:09<03:14,  3.14it/s, est. speed input: 3255.83 toks/s, output: 3.18 toks/s]
Processed prompts:  41%|      | 421/1024 [02:12<03:12,  3.14it/s, est. speed input: 3254.90 toks/s, output: 3.18 toks/s]
Processed prompts:  42%|     | 429/1024 [02:14<03:03,  3.24it/s, est. speed input: 3260.32 toks/s, output: 3.18 toks/s]
Processed prompts:  43%|     | 437/1024 [02:17<03:02,  3.21it/s, est. speed input: 3259.58 toks/s, output: 3.18 toks/s]
Processed prompts:  43%|     | 445/1024 [02:19<03:01,  3.19it/s, est. speed input: 3258.66 toks/s, output: 3.18 toks/s]
Processed prompts:  44%|     | 453/1024 [02:22<03:00,  3.17it/s, est. speed input: 3257.90 toks/s, output: 3.18 toks/s]
Processed prompts:  45%|     | 461/1024 [02:24<02:58,  3.16it/s, est. speed input: 3257.05 toks/s, output: 3.18 toks/s]
Processed prompts:  46%|     | 469/1024 [02:27<02:55,  3.15it/s, est. speed input: 3256.29 toks/s, output: 3.18 toks/s]
Processed prompts:  47%|     | 477/1024 [02:30<02:53,  3.15it/s, est. speed input: 3255.52 toks/s, output: 3.18 toks/s]
Processed prompts:  47%|     | 485/1024 [02:32<02:51,  3.15it/s, est. speed input: 3254.89 toks/s, output: 3.18 toks/s]
Processed prompts:  48%|     | 493/1024 [02:35<02:48,  3.15it/s, est. speed input: 3254.28 toks/s, output: 3.18 toks/s]
Processed prompts:  49%|     | 501/1024 [02:37<02:46,  3.14it/s, est. speed input: 3253.61 toks/s, output: 3.18 toks/s]
Processed prompts:  50%|     | 509/1024 [02:40<02:43,  3.14it/s, est. speed input: 3252.94 toks/s, output: 3.18 toks/s]
Processed prompts:  50%|     | 517/1024 [02:42<02:41,  3.14it/s, est. speed input: 3252.18 toks/s, output: 3.18 toks/s]
Processed prompts:  51%|    | 525/1024 [02:45<02:38,  3.14it/s, est. speed input: 3251.67 toks/s, output: 3.18 toks/s]
Processed prompts:  52%|    | 533/1024 [02:47<02:36,  3.14it/s, est. speed input: 3251.13 toks/s, output: 3.17 toks/s]
Processed prompts:  53%|    | 541/1024 [02:50<02:33,  3.14it/s, est. speed input: 3250.43 toks/s, output: 3.17 toks/s]
Processed prompts:  54%|    | 549/1024 [02:52<02:31,  3.14it/s, est. speed input: 3249.81 toks/s, output: 3.17 toks/s]
Processed prompts:  54%|    | 557/1024 [02:55<02:28,  3.14it/s, est. speed input: 3249.24 toks/s, output: 3.17 toks/s]
Processed prompts:  55%|    | 565/1024 [02:58<02:26,  3.14it/s, est. speed input: 3248.74 toks/s, output: 3.17 toks/s]
Processed prompts:  56%|    | 573/1024 [03:00<02:23,  3.14it/s, est. speed input: 3248.19 toks/s, output: 3.17 toks/s]
Processed prompts:  57%|    | 581/1024 [03:03<02:21,  3.14it/s, est. speed input: 3247.72 toks/s, output: 3.17 toks/s]
Processed prompts:  58%|    | 589/1024 [03:05<02:18,  3.14it/s, est. speed input: 3247.25 toks/s, output: 3.17 toks/s]
Processed prompts:  58%|    | 597/1024 [03:08<02:16,  3.14it/s, est. speed input: 3246.68 toks/s, output: 3.17 toks/s]
Processed prompts:  59%|    | 605/1024 [03:10<02:13,  3.14it/s, est. speed input: 3246.20 toks/s, output: 3.17 toks/s]
Processed prompts:  60%|    | 613/1024 [03:13<02:11,  3.14it/s, est. speed input: 3245.72 toks/s, output: 3.17 toks/s]
Processed prompts:  61%|    | 621/1024 [03:15<02:08,  3.13it/s, est. speed input: 3245.25 toks/s, output: 3.17 toks/s]
Processed prompts:  61%|   | 629/1024 [03:18<02:05,  3.14it/s, est. speed input: 3244.84 toks/s, output: 3.17 toks/s]
Processed prompts:  62%|   | 637/1024 [03:21<02:03,  3.13it/s, est. speed input: 3244.23 toks/s, output: 3.17 toks/s]
Processed prompts:  63%|   | 645/1024 [03:23<02:00,  3.13it/s, est. speed input: 3243.82 toks/s, output: 3.17 toks/s]
Processed prompts:  64%|   | 653/1024 [03:26<01:58,  3.13it/s, est. speed input: 3243.27 toks/s, output: 3.17 toks/s]
Processed prompts:  65%|   | 661/1024 [03:28<01:55,  3.13it/s, est. speed input: 3242.95 toks/s, output: 3.17 toks/s]
Processed prompts:  65%|   | 669/1024 [03:31<01:53,  3.13it/s, est. speed input: 3242.43 toks/s, output: 3.17 toks/s]
Processed prompts:  66%|   | 677/1024 [03:33<01:50,  3.13it/s, est. speed input: 3242.13 toks/s, output: 3.17 toks/s]
Processed prompts:  67%|   | 685/1024 [03:36<01:48,  3.14it/s, est. speed input: 3241.78 toks/s, output: 3.17 toks/s]
Processed prompts:  68%|   | 693/1024 [03:38<01:45,  3.13it/s, est. speed input: 3241.30 toks/s, output: 3.17 toks/s]
Processed prompts:  68%|   | 701/1024 [03:41<01:43,  3.13it/s, est. speed input: 3240.96 toks/s, output: 3.16 toks/s]
Processed prompts:  69%|   | 709/1024 [03:44<01:40,  3.13it/s, est. speed input: 3240.54 toks/s, output: 3.16 toks/s]
Processed prompts:  70%|   | 717/1024 [03:46<01:37,  3.13it/s, est. speed input: 3240.22 toks/s, output: 3.16 toks/s]
Processed prompts:  71%|   | 725/1024 [03:49<01:35,  3.13it/s, est. speed input: 3239.88 toks/s, output: 3.16 toks/s]
Processed prompts:  72%|  | 733/1024 [03:51<01:32,  3.13it/s, est. speed input: 3239.53 toks/s, output: 3.16 toks/s]
Processed prompts:  72%|  | 741/1024 [03:54<01:30,  3.13it/s, est. speed input: 3239.22 toks/s, output: 3.16 toks/s]
Processed prompts:  73%|  | 749/1024 [03:56<01:27,  3.13it/s, est. speed input: 3238.83 toks/s, output: 3.16 toks/s]
Processed prompts:  74%|  | 757/1024 [03:59<01:25,  3.13it/s, est. speed input: 3238.53 toks/s, output: 3.16 toks/s]
Processed prompts:  75%|  | 765/1024 [04:01<01:22,  3.13it/s, est. speed input: 3238.08 toks/s, output: 3.16 toks/s]
Processed prompts:  75%|  | 773/1024 [04:04<01:20,  3.13it/s, est. speed input: 3237.79 toks/s, output: 3.16 toks/s]
Processed prompts:  76%|  | 781/1024 [04:06<01:15,  3.23it/s, est. speed input: 3240.91 toks/s, output: 3.16 toks/s]
Processed prompts:  77%|  | 789/1024 [04:09<01:13,  3.20it/s, est. speed input: 3240.51 toks/s, output: 3.16 toks/s]
Processed prompts:  78%|  | 797/1024 [04:11<01:11,  3.18it/s, est. speed input: 3240.24 toks/s, output: 3.16 toks/s]
Processed prompts:  79%|  | 805/1024 [04:14<01:09,  3.17it/s, est. speed input: 3239.99 toks/s, output: 3.16 toks/s]
Processed prompts:  79%|  | 813/1024 [04:16<01:06,  3.16it/s, est. speed input: 3239.63 toks/s, output: 3.16 toks/s]
Processed prompts:  80%|  | 821/1024 [04:19<01:04,  3.15it/s, est. speed input: 3239.30 toks/s, output: 3.16 toks/s]
Processed prompts:  81%|  | 829/1024 [04:22<01:02,  3.14it/s, est. speed input: 3238.93 toks/s, output: 3.16 toks/s]
Processed prompts:  82%| | 837/1024 [04:24<00:59,  3.14it/s, est. speed input: 3238.56 toks/s, output: 3.16 toks/s]
Processed prompts:  83%| | 845/1024 [04:27<00:57,  3.14it/s, est. speed input: 3238.25 toks/s, output: 3.16 toks/s]
Processed prompts:  83%| | 853/1024 [04:29<00:54,  3.13it/s, est. speed input: 3237.95 toks/s, output: 3.16 toks/s]
Processed prompts:  84%| | 861/1024 [04:32<00:52,  3.13it/s, est. speed input: 3237.61 toks/s, output: 3.16 toks/s]
Processed prompts:  85%| | 869/1024 [04:34<00:49,  3.13it/s, est. speed input: 3237.29 toks/s, output: 3.16 toks/s]
Processed prompts:  86%| | 877/1024 [04:37<00:46,  3.13it/s, est. speed input: 3237.01 toks/s, output: 3.16 toks/s]
Processed prompts:  86%| | 885/1024 [04:39<00:44,  3.13it/s, est. speed input: 3236.71 toks/s, output: 3.16 toks/s]
Processed prompts:  87%| | 893/1024 [04:42<00:41,  3.13it/s, est. speed input: 3236.46 toks/s, output: 3.16 toks/s]
Processed prompts:  88%| | 901/1024 [04:45<00:39,  3.12it/s, est. speed input: 3235.99 toks/s, output: 3.16 toks/s]
Processed prompts:  89%| | 909/1024 [04:47<00:36,  3.13it/s, est. speed input: 3235.78 toks/s, output: 3.16 toks/s]
Processed prompts:  90%| | 917/1024 [04:50<00:34,  3.13it/s, est. speed input: 3235.55 toks/s, output: 3.16 toks/s]
Processed prompts:  90%| | 925/1024 [04:52<00:31,  3.13it/s, est. speed input: 3235.24 toks/s, output: 3.16 toks/s]
Processed prompts:  91%| | 933/1024 [04:55<00:29,  3.13it/s, est. speed input: 3234.99 toks/s, output: 3.16 toks/s]
Processed prompts:  92%|| 941/1024 [04:57<00:26,  3.13it/s, est. speed input: 3234.68 toks/s, output: 3.16 toks/s]
Processed prompts:  93%|| 949/1024 [05:00<00:23,  3.13it/s, est. speed input: 3234.44 toks/s, output: 3.16 toks/s]
Processed prompts:  93%|| 957/1024 [05:03<00:21,  3.13it/s, est. speed input: 3234.17 toks/s, output: 3.16 toks/s]
Processed prompts:  94%|| 965/1024 [05:05<00:18,  3.13it/s, est. speed input: 3233.93 toks/s, output: 3.16 toks/s]
Processed prompts:  95%|| 973/1024 [05:08<00:16,  3.13it/s, est. speed input: 3233.70 toks/s, output: 3.16 toks/s]
Processed prompts:  96%|| 981/1024 [05:10<00:13,  3.13it/s, est. speed input: 3233.46 toks/s, output: 3.16 toks/s]
Processed prompts:  97%|| 989/1024 [05:13<00:11,  3.13it/s, est. speed input: 3233.27 toks/s, output: 3.16 toks/s]
Processed prompts:  97%|| 997/1024 [05:15<00:08,  3.13it/s, est. speed input: 3233.02 toks/s, output: 3.16 toks/s]
Processed prompts:  98%|| 1005/1024 [05:18<00:06,  3.13it/s, est. speed input: 3232.87 toks/s, output: 3.16 toks/s]
Processed prompts:  99%|| 1013/1024 [05:20<00:03,  3.13it/s, est. speed input: 3232.64 toks/s, output: 3.16 toks/s]
Processed prompts: 100%|| 1021/1024 [05:22<00:00,  3.67it/s, est. speed input: 3244.98 toks/s, output: 3.17 toks/s]
Processed prompts: 100%|| 1024/1024 [05:22<00:00,  3.67it/s, est. speed input: 3254.52 toks/s, output: 3.18 toks/s]
Processed prompts: 100%|| 1024/1024 [05:22<00:00,  3.18it/s, est. speed input: 3254.52 toks/s, output: 3.18 toks/s]
[rank0]:[W127 04:39:31.934520611 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-27 04:39:46
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 04:40:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 04:40:00 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2119540) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2119540) WARNING 01-27 04:42:34 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.15 requests/s, 3231.82 total tokens/s, 3.15 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-27 04:40:00] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 04:40:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:40:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 04:40:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:40:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:40:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:40:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:40:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:40:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:40:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 04:40:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 04:40:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 04:40:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 04:40:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 04:40:04] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 04:40:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:40:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 04:40:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:40:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:40:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:40:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:40:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:40:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:40:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 04:40:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 04:40:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 04:40:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 04:40:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2119540) [2026-01-27 04:40:05] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2119540) [2026-01-27 04:40:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2119540) [2026-01-27 04:40:05] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2119540) [2026-01-27 04:40:05] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=2119540) [2026-01-27 04:40:05] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=2119540) [2026-01-27 04:40:05] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=2119540) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2119540) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.53s/it]
(EngineCore_DP0 pid=2119540) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:41<00:45, 22.77s/it]
(EngineCore_DP0 pid=2119540) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:17<00:28, 28.81s/it]
(EngineCore_DP0 pid=2119540) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:58<00:00, 33.89s/it]
(EngineCore_DP0 pid=2119540) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:58<00:00, 29.73s/it]
(EngineCore_DP0 pid=2119540) 
(EngineCore_DP0 pid=2119540) [2026-01-27 04:42:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=2119540) [2026-01-27 04:42:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 44040192 bytes
(EngineCore_DP0 pid=2119540) [2026-01-27 04:42:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=2119540) [2026-01-27 04:42:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=2119540) [2026-01-27 04:42:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=2119540) [2026-01-27 04:42:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 169869312 bytes
(EngineCore_DP0 pid=2119540) [2026-01-27 04:42:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=2119540) [2026-01-27 04:42:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 85032960 bytes
(EngineCore_DP0 pid=2119540) 2026-01-27 04:42:21,398 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2119540) 2026-01-27 04:42:23,682 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/2048 [00:00<31:39,  1.08it/s]
Adding requests:   0%|          | 2/2048 [00:01<17:45,  1.92it/s]
Adding requests:   0%|          | 3/2048 [00:01<11:44,  2.90it/s]
Adding requests:   0%|          | 5/2048 [00:01<06:48,  5.00it/s]
Adding requests:   0%|          | 7/2048 [00:01<04:34,  7.44it/s]
Adding requests:   1%|          | 11/2048 [00:01<02:36, 13.01it/s]
Adding requests:   1%|          | 15/2048 [00:01<01:52, 18.11it/s]
Adding requests:   1%|         | 30/2048 [00:01<00:42, 47.40it/s]
Adding requests:   2%|         | 49/2048 [00:02<00:24, 81.68it/s]
Adding requests:   3%|         | 70/2048 [00:02<00:17, 113.27it/s]
Adding requests:   5%|         | 107/2048 [00:02<00:10, 180.61it/s]
Adding requests:   7%|         | 147/2048 [00:02<00:07, 240.62it/s]
Adding requests:   9%|         | 194/2048 [00:02<00:06, 304.47it/s]
Adding requests:  12%|        | 237/2048 [00:02<00:05, 337.10it/s]
Adding requests:  14%|        | 279/2048 [00:02<00:04, 360.57it/s]
Adding requests:  16%|        | 323/2048 [00:02<00:04, 380.54it/s]
Adding requests:  18%|        | 368/2048 [00:02<00:04, 400.04it/s]
Adding requests:  20%|        | 415/2048 [00:02<00:03, 419.65it/s]
Adding requests:  23%|       | 461/2048 [00:03<00:03, 429.75it/s]
Adding requests:  25%|       | 510/2048 [00:03<00:03, 446.42it/s]
Adding requests:  27%|       | 557/2048 [00:03<00:03, 452.49it/s]
Adding requests:  29%|       | 603/2048 [00:03<00:03, 442.76it/s]
Adding requests:  32%|      | 648/2048 [00:03<00:03, 440.82it/s]
Adding requests:  34%|      | 693/2048 [00:03<00:03, 441.02it/s]
Adding requests:  36%|      | 738/2048 [00:03<00:03, 436.62it/s]
Adding requests:  38%|      | 782/2048 [00:03<00:02, 427.82it/s]
Adding requests:  41%|      | 831/2048 [00:03<00:02, 445.66it/s]
Adding requests:  43%|     | 876/2048 [00:11<00:57, 20.41it/s] 
Adding requests:  45%|     | 920/2048 [00:11<00:39, 28.26it/s]
Adding requests:  47%|     | 963/2048 [00:11<00:28, 38.72it/s]
Adding requests:  49%|     | 1004/2048 [00:11<00:20, 52.02it/s]
Adding requests:  51%|     | 1047/2048 [00:11<00:14, 70.44it/s]
Adding requests:  53%|    | 1090/2048 [00:11<00:10, 93.77it/s]
Adding requests:  56%|    | 1137/2048 [00:11<00:07, 125.75it/s]
Adding requests:  58%|    | 1180/2048 [00:11<00:05, 158.51it/s]
Adding requests:  60%|    | 1225/2048 [00:11<00:04, 197.36it/s]
Adding requests:  62%|   | 1269/2048 [00:12<00:03, 234.77it/s]
Adding requests:  64%|   | 1315/2048 [00:12<00:02, 275.67it/s]
Adding requests:  66%|   | 1359/2048 [00:12<00:02, 306.83it/s]
Adding requests:  69%|   | 1403/2048 [00:12<00:01, 333.62it/s]
Adding requests:  71%|   | 1446/2048 [00:12<00:01, 356.88it/s]
Adding requests:  73%|  | 1493/2048 [00:12<00:01, 385.24it/s]
Adding requests:  75%|  | 1539/2048 [00:12<00:01, 403.98it/s]
Adding requests:  77%|  | 1584/2048 [00:12<00:01, 412.79it/s]
Adding requests:  80%|  | 1629/2048 [00:12<00:01, 407.97it/s]
Adding requests:  82%| | 1672/2048 [00:12<00:00, 413.07it/s]
Adding requests:  84%| | 1717/2048 [00:13<00:00, 422.19it/s]
Adding requests:  86%| | 1762/2048 [00:13<00:00, 429.00it/s]
Adding requests:  88%| | 1808/2048 [00:13<00:00, 435.65it/s]
Adding requests:  90%| | 1853/2048 [00:13<00:00, 431.79it/s]
Adding requests:  93%|| 1897/2048 [00:13<00:00, 433.64it/s]
Adding requests:  95%|| 1943/2048 [00:13<00:00, 441.15it/s]
Adding requests:  97%|| 1988/2048 [00:13<00:00, 442.61it/s]
Adding requests:  99%|| 2033/2048 [00:13<00:00, 425.97it/s]
Adding requests: 100%|| 2048/2048 [00:13<00:00, 148.13it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 36/2048 [00:03<03:09, 10.63it/s, est. speed input: 10883.17 toks/s, output: 10.63 toks/s]
Processed prompts:   3%|         | 52/2048 [00:08<05:59,  5.55it/s, est. speed input: 6313.06 toks/s, output: 6.17 toks/s]  
Processed prompts:   3%|         | 68/2048 [00:13<07:32,  4.37it/s, est. speed input: 5158.94 toks/s, output: 5.04 toks/s]
Processed prompts:   4%|         | 84/2048 [00:18<08:27,  3.87it/s, est. speed input: 4634.48 toks/s, output: 4.53 toks/s]
Processed prompts:   5%|         | 100/2048 [00:23<09:00,  3.60it/s, est. speed input: 4333.26 toks/s, output: 4.23 toks/s]
Processed prompts:   6%|         | 116/2048 [00:28<09:20,  3.45it/s, est. speed input: 4138.27 toks/s, output: 4.04 toks/s]
Processed prompts:   6%|         | 132/2048 [00:33<09:31,  3.35it/s, est. speed input: 4001.83 toks/s, output: 3.91 toks/s]
Processed prompts:   7%|         | 148/2048 [00:38<09:38,  3.29it/s, est. speed input: 3900.37 toks/s, output: 3.81 toks/s]
Processed prompts:   8%|         | 164/2048 [00:43<09:40,  3.24it/s, est. speed input: 3822.24 toks/s, output: 3.73 toks/s]
Processed prompts:   9%|         | 180/2048 [00:49<09:41,  3.21it/s, est. speed input: 3760.38 toks/s, output: 3.67 toks/s]
Processed prompts:  10%|         | 196/2048 [00:53<09:31,  3.24it/s, est. speed input: 3726.32 toks/s, output: 3.64 toks/s]
Processed prompts:  10%|         | 212/2048 [00:58<09:31,  3.21it/s, est. speed input: 3682.99 toks/s, output: 3.60 toks/s]
Processed prompts:  11%|         | 228/2048 [01:04<09:29,  3.19it/s, est. speed input: 3646.74 toks/s, output: 3.56 toks/s]
Processed prompts:  12%|        | 244/2048 [01:09<09:27,  3.18it/s, est. speed input: 3615.40 toks/s, output: 3.53 toks/s]
Processed prompts:  13%|        | 260/2048 [01:14<09:24,  3.17it/s, est. speed input: 3588.23 toks/s, output: 3.50 toks/s]
Processed prompts:  13%|        | 276/2048 [01:19<09:20,  3.16it/s, est. speed input: 3564.70 toks/s, output: 3.48 toks/s]
Processed prompts:  14%|        | 292/2048 [01:24<09:07,  3.20it/s, est. speed input: 3554.63 toks/s, output: 3.47 toks/s]
Processed prompts:  15%|        | 308/2048 [01:29<09:06,  3.19it/s, est. speed input: 3535.58 toks/s, output: 3.45 toks/s]
Processed prompts:  16%|        | 324/2048 [01:34<09:02,  3.18it/s, est. speed input: 3518.86 toks/s, output: 3.44 toks/s]
Processed prompts:  17%|        | 340/2048 [01:39<08:59,  3.17it/s, est. speed input: 3503.77 toks/s, output: 3.42 toks/s]
Processed prompts:  17%|        | 356/2048 [01:44<08:55,  3.16it/s, est. speed input: 3490.08 toks/s, output: 3.41 toks/s]
Processed prompts:  18%|        | 372/2048 [01:49<08:51,  3.16it/s, est. speed input: 3477.52 toks/s, output: 3.40 toks/s]
Processed prompts:  19%|        | 388/2048 [01:54<08:46,  3.15it/s, est. speed input: 3466.17 toks/s, output: 3.38 toks/s]
Processed prompts:  20%|        | 404/2048 [01:59<08:41,  3.15it/s, est. speed input: 3455.59 toks/s, output: 3.37 toks/s]
Processed prompts:  21%|        | 420/2048 [02:04<08:36,  3.15it/s, est. speed input: 3446.16 toks/s, output: 3.37 toks/s]
Processed prompts:  21%|       | 436/2048 [02:09<08:24,  3.19it/s, est. speed input: 3443.86 toks/s, output: 3.36 toks/s]
Processed prompts:  22%|       | 452/2048 [02:14<08:21,  3.18it/s, est. speed input: 3435.50 toks/s, output: 3.35 toks/s]
Processed prompts:  23%|       | 468/2048 [02:19<08:18,  3.17it/s, est. speed input: 3427.67 toks/s, output: 3.35 toks/s]
Processed prompts:  24%|       | 484/2048 [02:24<08:14,  3.16it/s, est. speed input: 3420.45 toks/s, output: 3.34 toks/s]
Processed prompts:  24%|       | 500/2048 [02:29<08:10,  3.16it/s, est. speed input: 3413.71 toks/s, output: 3.33 toks/s]
Processed prompts:  25%|       | 516/2048 [02:35<08:05,  3.15it/s, est. speed input: 3407.32 toks/s, output: 3.33 toks/s]
Processed prompts:  26%|       | 532/2048 [02:40<08:01,  3.15it/s, est. speed input: 3401.29 toks/s, output: 3.32 toks/s]
Processed prompts:  27%|       | 548/2048 [02:45<07:56,  3.15it/s, est. speed input: 3395.62 toks/s, output: 3.32 toks/s]
Processed prompts:  28%|       | 564/2048 [02:50<07:51,  3.15it/s, est. speed input: 3390.45 toks/s, output: 3.31 toks/s]
Processed prompts:  28%|       | 580/2048 [02:55<07:46,  3.15it/s, est. speed input: 3385.53 toks/s, output: 3.31 toks/s]
Processed prompts:  29%|       | 596/2048 [03:00<07:41,  3.14it/s, est. speed input: 3380.72 toks/s, output: 3.30 toks/s]
Processed prompts:  30%|       | 612/2048 [03:05<07:36,  3.14it/s, est. speed input: 3376.32 toks/s, output: 3.30 toks/s]
Processed prompts:  31%|       | 628/2048 [03:10<07:31,  3.14it/s, est. speed input: 3372.13 toks/s, output: 3.29 toks/s]
Processed prompts:  31%|      | 644/2048 [03:15<07:26,  3.15it/s, est. speed input: 3368.28 toks/s, output: 3.29 toks/s]
Processed prompts:  32%|      | 660/2048 [03:20<07:21,  3.14it/s, est. speed input: 3364.46 toks/s, output: 3.29 toks/s]
Processed prompts:  33%|      | 676/2048 [03:25<07:16,  3.14it/s, est. speed input: 3360.83 toks/s, output: 3.28 toks/s]
Processed prompts:  34%|      | 692/2048 [03:31<07:11,  3.14it/s, est. speed input: 3357.31 toks/s, output: 3.28 toks/s]
Processed prompts:  35%|      | 708/2048 [03:36<07:06,  3.14it/s, est. speed input: 3353.98 toks/s, output: 3.28 toks/s]
Processed prompts:  35%|      | 724/2048 [03:41<07:01,  3.14it/s, est. speed input: 3350.92 toks/s, output: 3.27 toks/s]
Processed prompts:  36%|      | 740/2048 [03:46<06:56,  3.14it/s, est. speed input: 3347.93 toks/s, output: 3.27 toks/s]
Processed prompts:  37%|      | 756/2048 [03:51<06:50,  3.14it/s, est. speed input: 3345.13 toks/s, output: 3.27 toks/s]
Processed prompts:  38%|      | 772/2048 [03:56<06:40,  3.19it/s, est. speed input: 3345.89 toks/s, output: 3.27 toks/s]
Processed prompts:  38%|      | 788/2048 [04:01<06:36,  3.18it/s, est. speed input: 3343.21 toks/s, output: 3.26 toks/s]
Processed prompts:  39%|      | 804/2048 [04:06<06:32,  3.17it/s, est. speed input: 3340.74 toks/s, output: 3.26 toks/s]
Processed prompts:  40%|      | 820/2048 [04:11<06:28,  3.16it/s, est. speed input: 3338.27 toks/s, output: 3.26 toks/s]
Processed prompts:  41%|      | 836/2048 [04:16<06:24,  3.16it/s, est. speed input: 3335.91 toks/s, output: 3.26 toks/s]
Processed prompts:  42%|     | 852/2048 [04:21<06:19,  3.15it/s, est. speed input: 3333.59 toks/s, output: 3.26 toks/s]
Processed prompts:  42%|     | 868/2048 [04:26<06:14,  3.15it/s, est. speed input: 3331.32 toks/s, output: 3.25 toks/s]
Processed prompts:  43%|     | 884/2048 [04:31<06:09,  3.15it/s, est. speed input: 3329.24 toks/s, output: 3.25 toks/s]
Processed prompts:  44%|     | 900/2048 [04:36<06:04,  3.15it/s, est. speed input: 3327.18 toks/s, output: 3.25 toks/s]
Processed prompts:  45%|     | 916/2048 [04:42<06:00,  3.14it/s, est. speed input: 3325.19 toks/s, output: 3.25 toks/s]
Processed prompts:  46%|     | 932/2048 [04:47<05:54,  3.14it/s, est. speed input: 3323.34 toks/s, output: 3.25 toks/s]
Processed prompts:  46%|     | 948/2048 [04:52<05:49,  3.14it/s, est. speed input: 3321.56 toks/s, output: 3.24 toks/s]
Processed prompts:  47%|     | 964/2048 [04:57<05:44,  3.15it/s, est. speed input: 3319.90 toks/s, output: 3.24 toks/s]
Processed prompts:  48%|     | 980/2048 [05:02<05:39,  3.15it/s, est. speed input: 3318.22 toks/s, output: 3.24 toks/s]
Processed prompts:  49%|     | 996/2048 [05:07<05:34,  3.15it/s, est. speed input: 3316.78 toks/s, output: 3.24 toks/s]
Processed prompts:  49%|     | 1012/2048 [05:12<05:28,  3.15it/s, est. speed input: 3315.36 toks/s, output: 3.24 toks/s]
Processed prompts:  50%|     | 1028/2048 [05:17<05:23,  3.15it/s, est. speed input: 3313.86 toks/s, output: 3.24 toks/s]
Processed prompts:  51%|     | 1044/2048 [05:22<05:18,  3.15it/s, est. speed input: 3312.43 toks/s, output: 3.23 toks/s]
Processed prompts:  52%|    | 1060/2048 [05:27<05:13,  3.15it/s, est. speed input: 3311.09 toks/s, output: 3.23 toks/s]
Processed prompts:  53%|    | 1076/2048 [05:32<05:08,  3.15it/s, est. speed input: 3309.70 toks/s, output: 3.23 toks/s]
Processed prompts:  53%|    | 1092/2048 [05:37<05:03,  3.15it/s, est. speed input: 3308.37 toks/s, output: 3.23 toks/s]
Processed prompts:  54%|    | 1108/2048 [05:43<04:58,  3.15it/s, est. speed input: 3307.19 toks/s, output: 3.23 toks/s]
Processed prompts:  55%|    | 1124/2048 [05:48<04:53,  3.15it/s, est. speed input: 3306.03 toks/s, output: 3.23 toks/s]
Processed prompts:  56%|    | 1140/2048 [05:53<04:48,  3.15it/s, est. speed input: 3304.92 toks/s, output: 3.23 toks/s]
Processed prompts:  56%|    | 1156/2048 [05:58<04:43,  3.15it/s, est. speed input: 3303.69 toks/s, output: 3.23 toks/s]
Processed prompts:  57%|    | 1172/2048 [06:03<04:38,  3.15it/s, est. speed input: 3302.55 toks/s, output: 3.23 toks/s]
Processed prompts:  58%|    | 1188/2048 [06:08<04:33,  3.15it/s, est. speed input: 3301.42 toks/s, output: 3.22 toks/s]
Processed prompts:  59%|    | 1204/2048 [06:13<04:24,  3.19it/s, est. speed input: 3302.59 toks/s, output: 3.23 toks/s]
Processed prompts:  60%|    | 1220/2048 [06:18<04:20,  3.18it/s, est. speed input: 3301.53 toks/s, output: 3.22 toks/s]
Processed prompts:  60%|    | 1236/2048 [06:23<04:15,  3.17it/s, est. speed input: 3300.55 toks/s, output: 3.22 toks/s]
Processed prompts:  61%|    | 1252/2048 [06:28<04:11,  3.16it/s, est. speed input: 3299.50 toks/s, output: 3.22 toks/s]
Processed prompts:  62%|   | 1268/2048 [06:33<04:06,  3.16it/s, est. speed input: 3298.54 toks/s, output: 3.22 toks/s]
Processed prompts:  63%|   | 1284/2048 [06:38<04:02,  3.16it/s, est. speed input: 3297.61 toks/s, output: 3.22 toks/s]
Processed prompts:  63%|   | 1300/2048 [06:43<03:57,  3.15it/s, est. speed input: 3296.66 toks/s, output: 3.22 toks/s]
Processed prompts:  64%|   | 1316/2048 [06:48<03:52,  3.15it/s, est. speed input: 3295.80 toks/s, output: 3.22 toks/s]
Processed prompts:  65%|   | 1332/2048 [06:53<03:47,  3.15it/s, est. speed input: 3294.92 toks/s, output: 3.22 toks/s]
Processed prompts:  66%|   | 1348/2048 [06:59<03:42,  3.15it/s, est. speed input: 3294.13 toks/s, output: 3.22 toks/s]
Processed prompts:  67%|   | 1364/2048 [07:04<03:37,  3.15it/s, est. speed input: 3293.28 toks/s, output: 3.22 toks/s]
Processed prompts:  67%|   | 1380/2048 [07:09<03:31,  3.15it/s, est. speed input: 3292.51 toks/s, output: 3.22 toks/s]
Processed prompts:  68%|   | 1396/2048 [07:14<03:26,  3.15it/s, est. speed input: 3291.70 toks/s, output: 3.21 toks/s]
Processed prompts:  69%|   | 1412/2048 [07:19<03:21,  3.15it/s, est. speed input: 3290.96 toks/s, output: 3.21 toks/s]
Processed prompts:  70%|   | 1428/2048 [07:24<03:16,  3.15it/s, est. speed input: 3290.25 toks/s, output: 3.21 toks/s]
Processed prompts:  71%|   | 1444/2048 [07:29<03:11,  3.15it/s, est. speed input: 3289.52 toks/s, output: 3.21 toks/s]
Processed prompts:  71%|  | 1460/2048 [07:34<03:06,  3.15it/s, est. speed input: 3288.79 toks/s, output: 3.21 toks/s]
Processed prompts:  72%|  | 1476/2048 [07:39<03:01,  3.15it/s, est. speed input: 3288.11 toks/s, output: 3.21 toks/s]
Processed prompts:  73%|  | 1492/2048 [07:44<02:56,  3.15it/s, est. speed input: 3287.43 toks/s, output: 3.21 toks/s]
Processed prompts:  74%|  | 1508/2048 [07:49<02:51,  3.15it/s, est. speed input: 3286.79 toks/s, output: 3.21 toks/s]
Processed prompts:  74%|  | 1524/2048 [07:54<02:46,  3.15it/s, est. speed input: 3286.14 toks/s, output: 3.21 toks/s]
Processed prompts:  75%|  | 1540/2048 [07:59<02:41,  3.15it/s, est. speed input: 3285.47 toks/s, output: 3.21 toks/s]
Processed prompts:  76%|  | 1556/2048 [08:04<02:33,  3.20it/s, est. speed input: 3286.52 toks/s, output: 3.21 toks/s]
Processed prompts:  77%|  | 1572/2048 [08:09<02:29,  3.19it/s, est. speed input: 3285.98 toks/s, output: 3.21 toks/s]
Processed prompts:  78%|  | 1588/2048 [08:14<02:24,  3.18it/s, est. speed input: 3285.38 toks/s, output: 3.21 toks/s]
Processed prompts:  78%|  | 1604/2048 [08:20<02:20,  3.17it/s, est. speed input: 3284.78 toks/s, output: 3.21 toks/s]
Processed prompts:  79%|  | 1620/2048 [08:24<02:13,  3.21it/s, est. speed input: 3285.79 toks/s, output: 3.21 toks/s]
Processed prompts:  80%|  | 1636/2048 [08:29<02:09,  3.19it/s, est. speed input: 3285.21 toks/s, output: 3.21 toks/s]
Processed prompts:  81%|  | 1652/2048 [08:35<02:04,  3.18it/s, est. speed input: 3284.63 toks/s, output: 3.21 toks/s]
Processed prompts:  81%| | 1668/2048 [08:40<01:59,  3.17it/s, est. speed input: 3284.09 toks/s, output: 3.21 toks/s]
Processed prompts:  82%| | 1684/2048 [08:45<01:55,  3.16it/s, est. speed input: 3283.51 toks/s, output: 3.21 toks/s]
Processed prompts:  83%| | 1700/2048 [08:50<01:50,  3.16it/s, est. speed input: 3283.01 toks/s, output: 3.21 toks/s]
Processed prompts:  84%| | 1716/2048 [08:55<01:45,  3.16it/s, est. speed input: 3282.50 toks/s, output: 3.21 toks/s]
Processed prompts:  85%| | 1732/2048 [09:00<01:40,  3.16it/s, est. speed input: 3282.01 toks/s, output: 3.21 toks/s]
Processed prompts:  85%| | 1748/2048 [09:05<01:33,  3.20it/s, est. speed input: 3283.02 toks/s, output: 3.21 toks/s]
Processed prompts:  86%| | 1764/2048 [09:10<01:29,  3.19it/s, est. speed input: 3282.46 toks/s, output: 3.21 toks/s]
Processed prompts:  87%| | 1780/2048 [09:15<01:24,  3.18it/s, est. speed input: 3282.04 toks/s, output: 3.21 toks/s]
Processed prompts:  88%| | 1796/2048 [09:20<01:19,  3.17it/s, est. speed input: 3281.56 toks/s, output: 3.20 toks/s]
Processed prompts:  88%| | 1812/2048 [09:25<01:14,  3.16it/s, est. speed input: 3281.07 toks/s, output: 3.20 toks/s]
Processed prompts:  89%| | 1828/2048 [09:30<01:09,  3.16it/s, est. speed input: 3280.54 toks/s, output: 3.20 toks/s]
Processed prompts:  90%| | 1844/2048 [09:35<01:04,  3.16it/s, est. speed input: 3280.06 toks/s, output: 3.20 toks/s]
Processed prompts:  91%| | 1860/2048 [09:40<00:59,  3.16it/s, est. speed input: 3279.61 toks/s, output: 3.20 toks/s]
Processed prompts:  92%|| 1876/2048 [09:45<00:54,  3.15it/s, est. speed input: 3279.17 toks/s, output: 3.20 toks/s]
Processed prompts:  92%|| 1892/2048 [09:50<00:49,  3.15it/s, est. speed input: 3278.73 toks/s, output: 3.20 toks/s]
Processed prompts:  93%|| 1908/2048 [09:55<00:44,  3.15it/s, est. speed input: 3278.27 toks/s, output: 3.20 toks/s]
Processed prompts:  94%|| 1924/2048 [10:01<00:39,  3.15it/s, est. speed input: 3277.83 toks/s, output: 3.20 toks/s]
Processed prompts:  95%|| 1940/2048 [10:06<00:34,  3.15it/s, est. speed input: 3277.44 toks/s, output: 3.20 toks/s]
Processed prompts:  96%|| 1956/2048 [10:11<00:29,  3.15it/s, est. speed input: 3277.06 toks/s, output: 3.20 toks/s]
Processed prompts:  96%|| 1972/2048 [10:16<00:24,  3.15it/s, est. speed input: 3276.68 toks/s, output: 3.20 toks/s]
Processed prompts:  97%|| 1988/2048 [10:21<00:19,  3.15it/s, est. speed input: 3276.25 toks/s, output: 3.20 toks/s]
Processed prompts:  98%|| 2004/2048 [10:26<00:13,  3.15it/s, est. speed input: 3275.85 toks/s, output: 3.20 toks/s]
Processed prompts:  99%|| 2020/2048 [10:31<00:08,  3.15it/s, est. speed input: 3275.52 toks/s, output: 3.20 toks/s]
Processed prompts:  99%|| 2036/2048 [10:35<00:03,  3.34it/s, est. speed input: 3279.98 toks/s, output: 3.20 toks/s]
Processed prompts: 100%|| 2048/2048 [10:35<00:00,  3.34it/s, est. speed input: 3299.31 toks/s, output: 3.22 toks/s]
Processed prompts: 100%|| 2048/2048 [10:35<00:00,  3.22it/s, est. speed input: 3299.31 toks/s, output: 3.22 toks/s]
[rank0]:[W127 04:53:26.307065906 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-27 04:53:35
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 04:53:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 04:53:57 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2131218) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2131218) WARNING 01-27 04:56:41 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.14 requests/s, 3220.04 total tokens/s, 3.14 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-27 04:53:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 04:53:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:53:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 04:53:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:53:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:53:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:53:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:53:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:53:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:53:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 04:53:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 04:53:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 04:53:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 04:53:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 04:54:00] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 04:54:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:54:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 04:54:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:54:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:54:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:54:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:54:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 04:54:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 04:54:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 04:54:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 04:54:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 04:54:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 04:54:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2131218) [2026-01-27 04:54:01] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2131218) [2026-01-27 04:54:01] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2131218) [2026-01-27 04:54:01] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2131218) [2026-01-27 04:54:01] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=2131218) [2026-01-27 04:54:01] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=2131218) [2026-01-27 04:54:01] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=2131218) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2131218) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:26,  8.76s/it]
(EngineCore_DP0 pid=2131218) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:41<00:46, 23.05s/it]
(EngineCore_DP0 pid=2131218) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:18<00:29, 29.18s/it]
(EngineCore_DP0 pid=2131218) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:00<00:00, 34.16s/it]
(EngineCore_DP0 pid=2131218) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:00<00:00, 30.02s/it]
(EngineCore_DP0 pid=2131218) 
(EngineCore_DP0 pid=2131218) [2026-01-27 04:56:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=2131218) [2026-01-27 04:56:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 44040192 bytes
(EngineCore_DP0 pid=2131218) [2026-01-27 04:56:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=2131218) [2026-01-27 04:56:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=2131218) [2026-01-27 04:56:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=2131218) [2026-01-27 04:56:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 169869312 bytes
(EngineCore_DP0 pid=2131218) [2026-01-27 04:56:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=2131218) [2026-01-27 04:56:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 85032960 bytes
(EngineCore_DP0 pid=2131218) 2026-01-27 04:56:23,031 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2131218) 2026-01-27 04:56:27,345 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/4096 [00:00<1:04:25,  1.06it/s]
Adding requests:   0%|          | 2/4096 [00:01<36:44,  1.86it/s]  
Adding requests:   0%|          | 3/4096 [00:01<24:25,  2.79it/s]
Adding requests:   0%|          | 5/4096 [00:01<13:40,  4.99it/s]
Adding requests:   0%|          | 8/4096 [00:01<07:36,  8.95it/s]
Adding requests:   0%|          | 12/4096 [00:01<04:39, 14.64it/s]
Adding requests:   0%|          | 17/4096 [00:01<03:07, 21.74it/s]
Adding requests:   1%|          | 33/4096 [00:01<01:17, 52.70it/s]
Adding requests:   1%|         | 52/4096 [00:02<00:47, 85.64it/s]
Adding requests:   2%|         | 80/4096 [00:02<00:29, 134.52it/s]
Adding requests:   3%|         | 118/4096 [00:02<00:19, 199.19it/s]
Adding requests:   4%|         | 162/4096 [00:02<00:14, 264.87it/s]
Adding requests:   5%|         | 208/4096 [00:02<00:12, 318.20it/s]
Adding requests:   6%|         | 248/4096 [00:02<00:11, 339.81it/s]
Adding requests:   7%|         | 292/4096 [00:02<00:10, 366.88it/s]
Adding requests:   8%|         | 333/4096 [00:02<00:09, 378.24it/s]
Adding requests:   9%|         | 380/4096 [00:02<00:09, 404.96it/s]
Adding requests:  10%|         | 428/4096 [00:02<00:08, 424.91it/s]
Adding requests:  12%|        | 477/4096 [00:03<00:08, 442.03it/s]
Adding requests:  13%|        | 528/4096 [00:03<00:07, 460.94it/s]
Adding requests:  14%|        | 576/4096 [00:03<00:07, 463.97it/s]
Adding requests:  15%|        | 623/4096 [00:03<00:07, 455.76it/s]
Adding requests:  16%|        | 669/4096 [00:03<00:07, 439.58it/s]
Adding requests:  17%|        | 714/4096 [00:03<00:07, 435.52it/s]
Adding requests:  19%|        | 758/4096 [00:03<00:07, 433.81it/s]
Adding requests:  20%|        | 803/4096 [00:03<00:07, 435.88it/s]
Adding requests:  21%|        | 853/4096 [00:03<00:07, 454.01it/s]
Adding requests:  22%|       | 899/4096 [00:04<00:07, 438.35it/s]
Adding requests:  23%|       | 944/4096 [00:04<00:07, 437.40it/s]
Adding requests:  24%|       | 988/4096 [00:04<00:07, 437.30it/s]
Adding requests:  25%|       | 1032/4096 [00:04<00:07, 428.88it/s]
Adding requests:  26%|       | 1075/4096 [00:04<00:07, 418.59it/s]
Adding requests:  27%|       | 1117/4096 [00:04<00:07, 413.84it/s]
Adding requests:  28%|       | 1159/4096 [00:04<00:07, 407.99it/s]
Adding requests:  29%|       | 1200/4096 [00:04<00:07, 405.36it/s]
Adding requests:  30%|       | 1243/4096 [00:04<00:06, 408.77it/s]
Adding requests:  31%|      | 1287/4096 [00:04<00:06, 417.39it/s]
Adding requests:  33%|      | 1332/4096 [00:05<00:06, 426.56it/s]
Adding requests:  34%|      | 1377/4096 [00:05<00:06, 432.17it/s]
Adding requests:  35%|      | 1421/4096 [00:05<00:06, 428.17it/s]
Adding requests:  36%|      | 1466/4096 [00:05<00:06, 432.08it/s]
Adding requests:  37%|      | 1512/4096 [00:05<00:05, 438.07it/s]
Adding requests:  38%|      | 1556/4096 [00:05<00:05, 433.80it/s]
Adding requests:  39%|      | 1600/4096 [00:05<00:05, 425.91it/s]
Adding requests:  40%|      | 1643/4096 [00:05<00:05, 420.05it/s]
Adding requests:  41%|      | 1686/4096 [00:05<00:05, 414.64it/s]
Adding requests:  42%|     | 1731/4096 [00:05<00:05, 423.47it/s]
Adding requests:  43%|     | 1776/4096 [00:06<00:05, 429.40it/s]
Adding requests:  44%|     | 1819/4096 [00:06<00:05, 420.06it/s]
Adding requests:  46%|     | 1864/4096 [00:06<00:05, 428.18it/s]
Adding requests:  47%|     | 1907/4096 [00:06<00:05, 424.69it/s]
Adding requests:  48%|     | 1955/4096 [00:06<00:04, 438.34it/s]
Adding requests:  49%|     | 1999/4096 [00:06<00:04, 425.70it/s]
Adding requests:  50%|     | 2042/4096 [00:06<00:04, 424.10it/s]
Adding requests:  51%|     | 2085/4096 [00:06<00:04, 411.77it/s]
Adding requests:  52%|    | 2130/4096 [00:06<00:04, 422.28it/s]
Adding requests:  53%|    | 2173/4096 [00:07<00:04, 403.84it/s]
Adding requests:  54%|    | 2216/4096 [00:07<00:04, 410.95it/s]
Adding requests:  55%|    | 2258/4096 [00:07<00:04, 412.57it/s]
Adding requests:  56%|    | 2304/4096 [00:07<00:04, 424.22it/s]
Adding requests:  57%|    | 2348/4096 [00:07<00:04, 426.77it/s]
Adding requests:  58%|    | 2396/4096 [00:07<00:03, 440.27it/s]
Adding requests:  60%|    | 2441/4096 [00:07<00:03, 423.34it/s]
Adding requests:  61%|    | 2484/4096 [00:07<00:03, 421.28it/s]
Adding requests:  62%|   | 2530/4096 [00:07<00:03, 431.39it/s]
Adding requests:  63%|   | 2577/4096 [00:07<00:03, 441.09it/s]
Adding requests:  64%|   | 2622/4096 [00:08<00:03, 435.36it/s]
Adding requests:  65%|   | 2666/4096 [00:08<00:03, 434.31it/s]
Adding requests:  66%|   | 2710/4096 [00:08<00:03, 426.20it/s]
Adding requests:  67%|   | 2760/4096 [00:08<00:02, 445.82it/s]
Adding requests:  69%|   | 2807/4096 [00:08<00:02, 449.69it/s]
Adding requests:  70%|   | 2853/4096 [00:08<00:02, 443.30it/s]
Adding requests:  71%|   | 2900/4096 [00:08<00:02, 449.53it/s]
Adding requests:  72%|  | 2946/4096 [00:08<00:02, 449.83it/s]
Adding requests:  73%|  | 2992/4096 [00:08<00:02, 439.06it/s]
Adding requests:  74%|  | 3037/4096 [00:09<00:02, 440.94it/s]
Adding requests:  75%|  | 3082/4096 [00:09<00:02, 441.08it/s]
Adding requests:  76%|  | 3128/4096 [00:09<00:02, 445.17it/s]
Adding requests:  77%|  | 3173/4096 [00:09<00:02, 438.25it/s]
Adding requests:  79%|  | 3218/4096 [00:09<00:01, 440.37it/s]
Adding requests:  80%|  | 3263/4096 [00:09<00:01, 438.56it/s]
Adding requests:  81%|  | 3307/4096 [00:09<00:01, 429.52it/s]
Adding requests:  82%| | 3350/4096 [00:09<00:01, 428.38it/s]
Adding requests:  83%| | 3397/4096 [00:09<00:01, 438.20it/s]
Adding requests:  84%| | 3441/4096 [00:09<00:01, 435.58it/s]
Adding requests:  85%| | 3486/4096 [00:10<00:01, 439.24it/s]
Adding requests:  86%| | 3530/4096 [00:10<00:01, 437.05it/s]
Adding requests:  87%| | 3578/4096 [00:10<00:01, 447.25it/s]
Adding requests:  88%| | 3623/4096 [00:10<00:01, 432.73it/s]
Adding requests:  90%| | 3668/4096 [00:10<00:00, 435.80it/s]
Adding requests:  91%| | 3712/4096 [00:10<00:00, 424.11it/s]
Adding requests:  92%|| 3755/4096 [00:10<00:00, 425.70it/s]
Adding requests:  93%|| 3798/4096 [00:10<00:00, 420.55it/s]
Adding requests:  94%|| 3841/4096 [00:10<00:00, 407.27it/s]
Adding requests:  95%|| 3882/4096 [00:10<00:00, 407.46it/s]
Adding requests:  96%|| 3924/4096 [00:11<00:00, 410.35it/s]
Adding requests:  97%|| 3966/4096 [00:11<00:00, 409.94it/s]
Adding requests:  98%|| 4010/4096 [00:11<00:00, 417.81it/s]
Adding requests:  99%|| 4052/4096 [00:11<00:00, 416.69it/s]
Adding requests: 100%|| 4095/4096 [00:11<00:00, 419.27it/s]
Adding requests: 100%|| 4096/4096 [00:11<00:00, 356.61it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 4/4096 [00:00<12:57,  5.26it/s, est. speed input: 5390.37 toks/s, output: 5.26 toks/s]
Processed prompts:   1%|          | 36/4096 [00:10<20:45,  3.26it/s, est. speed input: 3380.31 toks/s, output: 3.30 toks/s]
Processed prompts:   2%|         | 68/4096 [00:21<21:00,  3.20it/s, est. speed input: 3305.57 toks/s, output: 3.23 toks/s]
Processed prompts:   2%|         | 100/4096 [00:31<20:59,  3.17it/s, est. speed input: 3277.59 toks/s, output: 3.20 toks/s]
Processed prompts:   3%|         | 132/4096 [00:41<20:54,  3.16it/s, est. speed input: 3262.98 toks/s, output: 3.19 toks/s]
Processed prompts:   4%|         | 164/4096 [00:51<20:47,  3.15it/s, est. speed input: 3253.26 toks/s, output: 3.18 toks/s]
Processed prompts:   5%|         | 196/4096 [01:01<20:28,  3.17it/s, est. speed input: 3259.75 toks/s, output: 3.18 toks/s]
Processed prompts:   6%|         | 228/4096 [01:11<20:23,  3.16it/s, est. speed input: 3253.04 toks/s, output: 3.18 toks/s]
Processed prompts:   6%|         | 260/4096 [01:21<20:15,  3.16it/s, est. speed input: 3248.66 toks/s, output: 3.17 toks/s]
Processed prompts:   7%|         | 292/4096 [01:31<19:58,  3.18it/s, est. speed input: 3253.81 toks/s, output: 3.18 toks/s]
Processed prompts:   8%|         | 324/4096 [01:42<19:51,  3.16it/s, est. speed input: 3250.04 toks/s, output: 3.17 toks/s]
Processed prompts:   9%|         | 356/4096 [01:52<19:45,  3.16it/s, est. speed input: 3246.63 toks/s, output: 3.17 toks/s]
Processed prompts:   9%|         | 388/4096 [02:02<19:36,  3.15it/s, est. speed input: 3243.82 toks/s, output: 3.17 toks/s]
Processed prompts:  10%|         | 420/4096 [02:12<19:19,  3.17it/s, est. speed input: 3247.56 toks/s, output: 3.17 toks/s]
Processed prompts:  11%|         | 452/4096 [02:22<19:12,  3.16it/s, est. speed input: 3245.17 toks/s, output: 3.17 toks/s]
Processed prompts:  12%|        | 484/4096 [02:32<19:05,  3.15it/s, est. speed input: 3243.07 toks/s, output: 3.17 toks/s]
Processed prompts:  13%|        | 516/4096 [02:43<18:56,  3.15it/s, est. speed input: 3241.44 toks/s, output: 3.17 toks/s]
Processed prompts:  13%|        | 548/4096 [02:53<18:47,  3.15it/s, est. speed input: 3239.94 toks/s, output: 3.16 toks/s]
Processed prompts:  14%|        | 580/4096 [03:03<18:37,  3.15it/s, est. speed input: 3238.57 toks/s, output: 3.16 toks/s]
Processed prompts:  15%|        | 612/4096 [03:13<18:28,  3.14it/s, est. speed input: 3237.31 toks/s, output: 3.16 toks/s]
Processed prompts:  16%|        | 644/4096 [03:23<18:18,  3.14it/s, est. speed input: 3236.03 toks/s, output: 3.16 toks/s]
Processed prompts:  17%|        | 676/4096 [03:33<18:09,  3.14it/s, est. speed input: 3234.92 toks/s, output: 3.16 toks/s]
Processed prompts:  17%|        | 708/4096 [03:44<17:59,  3.14it/s, est. speed input: 3233.93 toks/s, output: 3.16 toks/s]
Processed prompts:  18%|        | 740/4096 [03:54<17:48,  3.14it/s, est. speed input: 3233.11 toks/s, output: 3.16 toks/s]
Processed prompts:  19%|        | 772/4096 [04:04<17:31,  3.16it/s, est. speed input: 3235.49 toks/s, output: 3.16 toks/s]
Processed prompts:  20%|        | 804/4096 [04:14<17:23,  3.15it/s, est. speed input: 3234.50 toks/s, output: 3.16 toks/s]
Processed prompts:  20%|        | 836/4096 [04:24<17:15,  3.15it/s, est. speed input: 3233.45 toks/s, output: 3.16 toks/s]
Processed prompts:  21%|        | 868/4096 [04:34<17:07,  3.14it/s, est. speed input: 3232.53 toks/s, output: 3.16 toks/s]
Processed prompts:  22%|       | 900/4096 [04:45<16:57,  3.14it/s, est. speed input: 3231.67 toks/s, output: 3.16 toks/s]
Processed prompts:  23%|       | 932/4096 [04:55<16:48,  3.14it/s, est. speed input: 3230.83 toks/s, output: 3.16 toks/s]
Processed prompts:  24%|       | 964/4096 [05:05<16:38,  3.14it/s, est. speed input: 3230.24 toks/s, output: 3.15 toks/s]
Processed prompts:  24%|       | 996/4096 [05:15<16:28,  3.14it/s, est. speed input: 3229.44 toks/s, output: 3.15 toks/s]
Processed prompts:  25%|       | 1028/4096 [05:26<16:18,  3.13it/s, est. speed input: 3228.77 toks/s, output: 3.15 toks/s]
Processed prompts:  26%|       | 1060/4096 [05:36<16:08,  3.14it/s, est. speed input: 3228.23 toks/s, output: 3.15 toks/s]
Processed prompts:  27%|       | 1092/4096 [05:46<15:58,  3.13it/s, est. speed input: 3227.63 toks/s, output: 3.15 toks/s]
Processed prompts:  27%|       | 1124/4096 [05:56<15:48,  3.13it/s, est. speed input: 3227.07 toks/s, output: 3.15 toks/s]
Processed prompts:  28%|       | 1156/4096 [06:06<15:38,  3.13it/s, est. speed input: 3226.51 toks/s, output: 3.15 toks/s]
Processed prompts:  29%|       | 1188/4096 [06:16<15:21,  3.16it/s, est. speed input: 3228.12 toks/s, output: 3.15 toks/s]
Processed prompts:  30%|       | 1220/4096 [06:27<15:13,  3.15it/s, est. speed input: 3227.65 toks/s, output: 3.15 toks/s]
Processed prompts:  31%|       | 1252/4096 [06:37<15:04,  3.15it/s, est. speed input: 3227.20 toks/s, output: 3.15 toks/s]
Processed prompts:  31%|      | 1284/4096 [06:47<14:54,  3.14it/s, est. speed input: 3226.87 toks/s, output: 3.15 toks/s]
Processed prompts:  32%|      | 1316/4096 [06:57<14:45,  3.14it/s, est. speed input: 3226.41 toks/s, output: 3.15 toks/s]
Processed prompts:  33%|      | 1348/4096 [07:07<14:35,  3.14it/s, est. speed input: 3226.03 toks/s, output: 3.15 toks/s]
Processed prompts:  34%|      | 1380/4096 [07:18<14:25,  3.14it/s, est. speed input: 3225.71 toks/s, output: 3.15 toks/s]
Processed prompts:  34%|      | 1412/4096 [07:28<14:15,  3.14it/s, est. speed input: 3225.36 toks/s, output: 3.15 toks/s]
Processed prompts:  35%|      | 1444/4096 [07:38<14:05,  3.13it/s, est. speed input: 3224.90 toks/s, output: 3.15 toks/s]
Processed prompts:  36%|      | 1476/4096 [07:48<13:55,  3.13it/s, est. speed input: 3224.53 toks/s, output: 3.15 toks/s]
Processed prompts:  37%|      | 1508/4096 [07:58<13:46,  3.13it/s, est. speed input: 3224.02 toks/s, output: 3.15 toks/s]
Processed prompts:  38%|      | 1540/4096 [08:08<13:30,  3.15it/s, est. speed input: 3225.14 toks/s, output: 3.15 toks/s]
Processed prompts:  38%|      | 1572/4096 [08:19<13:22,  3.15it/s, est. speed input: 3224.75 toks/s, output: 3.15 toks/s]
Processed prompts:  39%|      | 1604/4096 [08:29<13:07,  3.16it/s, est. speed input: 3225.89 toks/s, output: 3.15 toks/s]
Processed prompts:  40%|      | 1636/4096 [08:39<13:00,  3.15it/s, est. speed input: 3225.45 toks/s, output: 3.15 toks/s]
Processed prompts:  41%|      | 1668/4096 [08:49<12:51,  3.15it/s, est. speed input: 3225.01 toks/s, output: 3.15 toks/s]
Processed prompts:  42%|     | 1700/4096 [08:59<12:43,  3.14it/s, est. speed input: 3224.59 toks/s, output: 3.15 toks/s]
Processed prompts:  42%|     | 1732/4096 [09:10<12:33,  3.14it/s, est. speed input: 3224.17 toks/s, output: 3.15 toks/s]
Processed prompts:  43%|     | 1764/4096 [09:20<12:24,  3.13it/s, est. speed input: 3223.79 toks/s, output: 3.15 toks/s]
Processed prompts:  44%|     | 1796/4096 [09:30<12:14,  3.13it/s, est. speed input: 3223.41 toks/s, output: 3.15 toks/s]
Processed prompts:  45%|     | 1828/4096 [09:40<12:04,  3.13it/s, est. speed input: 3223.03 toks/s, output: 3.15 toks/s]
Processed prompts:  45%|     | 1860/4096 [09:51<11:54,  3.13it/s, est. speed input: 3222.69 toks/s, output: 3.15 toks/s]
Processed prompts:  46%|     | 1892/4096 [10:01<11:44,  3.13it/s, est. speed input: 3222.34 toks/s, output: 3.15 toks/s]
Processed prompts:  47%|     | 1924/4096 [10:11<11:34,  3.13it/s, est. speed input: 3222.04 toks/s, output: 3.15 toks/s]
Processed prompts:  48%|     | 1956/4096 [10:21<11:24,  3.13it/s, est. speed input: 3221.71 toks/s, output: 3.15 toks/s]
Processed prompts:  49%|     | 1988/4096 [10:31<11:13,  3.13it/s, est. speed input: 3221.38 toks/s, output: 3.15 toks/s]
Processed prompts:  49%|     | 2020/4096 [10:42<11:03,  3.13it/s, est. speed input: 3221.10 toks/s, output: 3.15 toks/s]
Processed prompts:  50%|     | 2052/4096 [10:52<10:53,  3.13it/s, est. speed input: 3220.77 toks/s, output: 3.15 toks/s]
Processed prompts:  51%|     | 2084/4096 [11:02<10:43,  3.13it/s, est. speed input: 3220.52 toks/s, output: 3.15 toks/s]
Processed prompts:  52%|    | 2116/4096 [11:12<10:33,  3.13it/s, est. speed input: 3220.23 toks/s, output: 3.14 toks/s]
Processed prompts:  52%|    | 2148/4096 [11:23<10:22,  3.13it/s, est. speed input: 3219.97 toks/s, output: 3.14 toks/s]
Processed prompts:  53%|    | 2180/4096 [11:33<10:07,  3.15it/s, est. speed input: 3220.91 toks/s, output: 3.15 toks/s]
Processed prompts:  54%|    | 2212/4096 [11:43<09:59,  3.14it/s, est. speed input: 3220.65 toks/s, output: 3.15 toks/s]
Processed prompts:  55%|    | 2244/4096 [11:53<09:49,  3.14it/s, est. speed input: 3220.40 toks/s, output: 3.14 toks/s]
Processed prompts:  56%|    | 2276/4096 [12:03<09:40,  3.13it/s, est. speed input: 3220.10 toks/s, output: 3.14 toks/s]
Processed prompts:  56%|    | 2308/4096 [12:14<09:30,  3.13it/s, est. speed input: 3219.86 toks/s, output: 3.14 toks/s]
Processed prompts:  57%|    | 2340/4096 [12:24<09:20,  3.13it/s, est. speed input: 3219.64 toks/s, output: 3.14 toks/s]
Processed prompts:  58%|    | 2372/4096 [12:34<09:10,  3.13it/s, est. speed input: 3219.37 toks/s, output: 3.14 toks/s]
Processed prompts:  59%|    | 2404/4096 [12:44<09:00,  3.13it/s, est. speed input: 3219.13 toks/s, output: 3.14 toks/s]
Processed prompts:  59%|    | 2436/4096 [12:54<08:50,  3.13it/s, est. speed input: 3218.84 toks/s, output: 3.14 toks/s]
Processed prompts:  60%|    | 2468/4096 [13:05<08:40,  3.13it/s, est. speed input: 3218.67 toks/s, output: 3.14 toks/s]
Processed prompts:  61%|    | 2500/4096 [13:15<08:29,  3.13it/s, est. speed input: 3218.63 toks/s, output: 3.14 toks/s]
Processed prompts:  62%|   | 2532/4096 [13:25<08:19,  3.13it/s, est. speed input: 3218.49 toks/s, output: 3.14 toks/s]
Processed prompts:  63%|   | 2564/4096 [13:35<08:08,  3.13it/s, est. speed input: 3218.47 toks/s, output: 3.14 toks/s]
Processed prompts:  63%|   | 2596/4096 [13:45<07:54,  3.16it/s, est. speed input: 3219.39 toks/s, output: 3.14 toks/s]
Processed prompts:  64%|   | 2628/4096 [13:55<07:45,  3.15it/s, est. speed input: 3219.37 toks/s, output: 3.14 toks/s]
Processed prompts:  65%|   | 2660/4096 [14:06<07:35,  3.15it/s, est. speed input: 3219.36 toks/s, output: 3.14 toks/s]
Processed prompts:  66%|   | 2692/4096 [14:16<07:26,  3.15it/s, est. speed input: 3219.32 toks/s, output: 3.14 toks/s]
Processed prompts:  67%|   | 2724/4096 [14:26<07:13,  3.17it/s, est. speed input: 3220.17 toks/s, output: 3.14 toks/s]
Processed prompts:  67%|   | 2756/4096 [14:36<07:04,  3.16it/s, est. speed input: 3220.13 toks/s, output: 3.14 toks/s]
Processed prompts:  68%|   | 2788/4096 [14:46<06:54,  3.15it/s, est. speed input: 3220.10 toks/s, output: 3.14 toks/s]
Processed prompts:  69%|   | 2820/4096 [14:56<06:45,  3.15it/s, est. speed input: 3220.05 toks/s, output: 3.14 toks/s]
Processed prompts:  70%|   | 2852/4096 [15:06<06:35,  3.15it/s, est. speed input: 3220.00 toks/s, output: 3.14 toks/s]
Processed prompts:  70%|   | 2884/4096 [15:16<06:22,  3.17it/s, est. speed input: 3220.83 toks/s, output: 3.15 toks/s]
Processed prompts:  71%|   | 2916/4096 [15:26<06:10,  3.18it/s, est. speed input: 3221.67 toks/s, output: 3.15 toks/s]
Processed prompts:  72%|  | 2948/4096 [15:37<06:01,  3.17it/s, est. speed input: 3221.68 toks/s, output: 3.15 toks/s]
Processed prompts:  73%|  | 2980/4096 [15:47<05:52,  3.16it/s, est. speed input: 3221.62 toks/s, output: 3.15 toks/s]
Processed prompts:  74%|  | 3012/4096 [15:57<05:43,  3.16it/s, est. speed input: 3221.62 toks/s, output: 3.15 toks/s]
Processed prompts:  74%|  | 3044/4096 [16:07<05:33,  3.15it/s, est. speed input: 3221.58 toks/s, output: 3.15 toks/s]
Processed prompts:  75%|  | 3076/4096 [16:17<05:23,  3.15it/s, est. speed input: 3221.57 toks/s, output: 3.15 toks/s]
Processed prompts:  76%|  | 3108/4096 [16:27<05:13,  3.15it/s, est. speed input: 3221.60 toks/s, output: 3.15 toks/s]
Processed prompts:  77%|  | 3140/4096 [16:38<05:03,  3.15it/s, est. speed input: 3221.57 toks/s, output: 3.15 toks/s]
Processed prompts:  77%|  | 3172/4096 [16:48<04:53,  3.15it/s, est. speed input: 3221.60 toks/s, output: 3.15 toks/s]
Processed prompts:  78%|  | 3204/4096 [16:58<04:43,  3.15it/s, est. speed input: 3221.60 toks/s, output: 3.15 toks/s]
Processed prompts:  79%|  | 3236/4096 [17:08<04:33,  3.15it/s, est. speed input: 3221.56 toks/s, output: 3.15 toks/s]
Processed prompts:  80%|  | 3268/4096 [17:18<04:23,  3.14it/s, est. speed input: 3221.45 toks/s, output: 3.15 toks/s]
Processed prompts:  81%|  | 3300/4096 [17:28<04:13,  3.14it/s, est. speed input: 3221.37 toks/s, output: 3.15 toks/s]
Processed prompts:  81%| | 3332/4096 [17:39<04:03,  3.14it/s, est. speed input: 3221.29 toks/s, output: 3.15 toks/s]
Processed prompts:  82%| | 3364/4096 [17:49<03:53,  3.14it/s, est. speed input: 3221.18 toks/s, output: 3.15 toks/s]
Processed prompts:  83%| | 3396/4096 [17:59<03:43,  3.14it/s, est. speed input: 3221.05 toks/s, output: 3.15 toks/s]
Processed prompts:  84%| | 3428/4096 [18:09<03:32,  3.14it/s, est. speed input: 3220.99 toks/s, output: 3.15 toks/s]
Processed prompts:  84%| | 3460/4096 [18:20<03:22,  3.14it/s, est. speed input: 3220.88 toks/s, output: 3.15 toks/s]
Processed prompts:  85%| | 3492/4096 [18:30<03:12,  3.14it/s, est. speed input: 3220.80 toks/s, output: 3.15 toks/s]
Processed prompts:  86%| | 3524/4096 [18:40<03:02,  3.14it/s, est. speed input: 3220.67 toks/s, output: 3.15 toks/s]
Processed prompts:  87%| | 3556/4096 [18:50<02:52,  3.14it/s, est. speed input: 3220.61 toks/s, output: 3.15 toks/s]
Processed prompts:  88%| | 3588/4096 [19:00<02:42,  3.13it/s, est. speed input: 3220.47 toks/s, output: 3.14 toks/s]
Processed prompts:  88%| | 3620/4096 [19:11<02:31,  3.13it/s, est. speed input: 3220.36 toks/s, output: 3.14 toks/s]
Processed prompts:  89%| | 3652/4096 [19:21<02:21,  3.13it/s, est. speed input: 3220.28 toks/s, output: 3.14 toks/s]
Processed prompts:  90%| | 3684/4096 [19:31<02:10,  3.16it/s, est. speed input: 3220.87 toks/s, output: 3.15 toks/s]
Processed prompts:  91%| | 3716/4096 [19:41<02:00,  3.15it/s, est. speed input: 3220.78 toks/s, output: 3.15 toks/s]
Processed prompts:  92%|| 3748/4096 [19:51<01:50,  3.15it/s, est. speed input: 3220.68 toks/s, output: 3.15 toks/s]
Processed prompts:  92%|| 3780/4096 [20:01<01:40,  3.14it/s, est. speed input: 3220.60 toks/s, output: 3.15 toks/s]
Processed prompts:  93%|| 3812/4096 [20:12<01:30,  3.14it/s, est. speed input: 3220.53 toks/s, output: 3.15 toks/s]
Processed prompts:  94%|| 3844/4096 [20:22<01:20,  3.14it/s, est. speed input: 3220.47 toks/s, output: 3.14 toks/s]
Processed prompts:  95%|| 3876/4096 [20:32<01:10,  3.14it/s, est. speed input: 3220.33 toks/s, output: 3.14 toks/s]
Processed prompts:  95%|| 3908/4096 [20:42<00:59,  3.16it/s, est. speed input: 3220.87 toks/s, output: 3.15 toks/s]
Processed prompts:  96%|| 3940/4096 [20:52<00:49,  3.15it/s, est. speed input: 3220.78 toks/s, output: 3.15 toks/s]
Processed prompts:  97%|| 3972/4096 [21:02<00:39,  3.15it/s, est. speed input: 3220.66 toks/s, output: 3.15 toks/s]
Processed prompts:  98%|| 4004/4096 [21:12<00:29,  3.16it/s, est. speed input: 3221.15 toks/s, output: 3.15 toks/s]
Processed prompts:  99%|| 4036/4096 [21:23<00:19,  3.15it/s, est. speed input: 3221.05 toks/s, output: 3.15 toks/s]
Processed prompts:  99%|| 4068/4096 [21:32<00:08,  3.24it/s, est. speed input: 3223.32 toks/s, output: 3.15 toks/s]
Processed prompts: 100%|| 4096/4096 [21:32<00:00,  3.24it/s, est. speed input: 3245.50 toks/s, output: 3.17 toks/s]
Processed prompts: 100%|| 4096/4096 [21:32<00:00,  3.17it/s, est. speed input: 3245.50 toks/s, output: 3.17 toks/s]
[rank0]:[W127 05:18:33.678721162 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-27 05:18:41
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 05:19:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 05:19:17 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2152288) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2152288) WARNING 01-27 05:22:23 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.13 requests/s, 3207.51 total tokens/s, 3.13 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-27 05:19:17] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 05:19:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 05:19:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 05:19:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 05:19:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 05:19:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 05:19:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 05:19:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 05:19:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 05:19:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 05:19:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 05:19:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 05:19:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 05:19:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 05:19:20] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 05:19:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 05:19:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 05:19:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 05:19:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 05:19:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 05:19:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 05:19:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 05:19:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 05:19:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 05:19:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 05:19:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 05:19:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 05:19:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2152288) [2026-01-27 05:19:22] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2152288) [2026-01-27 05:19:22] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2152288) [2026-01-27 05:19:22] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2152288) [2026-01-27 05:19:22] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=2152288) [2026-01-27 05:19:22] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=2152288) [2026-01-27 05:19:22] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=2152288) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2152288) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:26,  8.68s/it]
(EngineCore_DP0 pid=2152288) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:41<00:45, 22.77s/it]
(EngineCore_DP0 pid=2152288) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:17<00:28, 28.92s/it]
(EngineCore_DP0 pid=2152288) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:59<00:00, 34.00s/it]
(EngineCore_DP0 pid=2152288) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:59<00:00, 29.84s/it]
(EngineCore_DP0 pid=2152288) 
(EngineCore_DP0 pid=2152288) [2026-01-27 05:21:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=2152288) [2026-01-27 05:21:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 44040192 bytes
(EngineCore_DP0 pid=2152288) [2026-01-27 05:21:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=2152288) [2026-01-27 05:21:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 31457280 bytes
(EngineCore_DP0 pid=2152288) [2026-01-27 05:21:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=2152288) [2026-01-27 05:21:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 169869312 bytes
(EngineCore_DP0 pid=2152288) [2026-01-27 05:21:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=2152288) [2026-01-27 05:21:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 85032960 bytes
(EngineCore_DP0 pid=2152288) 2026-01-27 05:21:52,005 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2152288) 2026-01-27 05:22:00,860 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/8192 [00:00<2:08:56,  1.06it/s]
Adding requests:   0%|          | 2/8192 [00:01<1:18:07,  1.75it/s]
Adding requests:   0%|          | 3/8192 [00:01<51:10,  2.67it/s]  
Adding requests:   0%|          | 4/8192 [00:01<36:55,  3.70it/s]
Adding requests:   0%|          | 6/8192 [00:01<22:59,  5.93it/s]
Adding requests:   0%|          | 9/8192 [00:01<14:13,  9.59it/s]
Adding requests:   0%|          | 12/8192 [00:01<10:14, 13.31it/s]
Adding requests:   0%|          | 16/8192 [00:02<07:18, 18.64it/s]
Adding requests:   0%|          | 26/8192 [00:02<03:42, 36.78it/s]
Adding requests:   0%|          | 39/8192 [00:02<02:17, 59.18it/s]
Adding requests:   1%|          | 55/8192 [00:02<01:35, 85.15it/s]
Adding requests:   1%|          | 73/8192 [00:02<01:13, 110.49it/s]
Adding requests:   1%|          | 100/8192 [00:02<00:52, 153.86it/s]
Adding requests:   2%|         | 129/8192 [00:02<00:42, 190.93it/s]
Adding requests:   2%|         | 162/8192 [00:02<00:35, 228.99it/s]
Adding requests:   2%|         | 195/8192 [00:02<00:31, 255.19it/s]
Adding requests:   3%|         | 226/8192 [00:02<00:29, 269.66it/s]
Adding requests:   3%|         | 258/8192 [00:03<00:27, 283.90it/s]
Adding requests:   4%|         | 289/8192 [00:03<00:27, 290.07it/s]
Adding requests:   4%|         | 319/8192 [00:03<00:27, 291.18it/s]
Adding requests:   4%|         | 354/8192 [00:03<00:25, 308.42it/s]
Adding requests:   5%|         | 397/8192 [00:03<00:22, 342.68it/s]
Adding requests:   5%|         | 440/8192 [00:03<00:21, 367.71it/s]
Adding requests:   6%|         | 484/8192 [00:03<00:19, 388.28it/s]
Adding requests:   6%|         | 531/8192 [00:03<00:18, 412.07it/s]
Adding requests:   7%|         | 575/8192 [00:03<00:18, 417.04it/s]
Adding requests:   8%|         | 619/8192 [00:03<00:17, 421.10it/s]
Adding requests:   8%|         | 663/8192 [00:04<00:17, 426.64it/s]
Adding requests:   9%|         | 706/8192 [00:04<00:17, 424.90it/s]
Adding requests:   9%|         | 749/8192 [00:04<00:17, 416.16it/s]
Adding requests:  10%|         | 794/8192 [00:04<00:17, 423.35it/s]
Adding requests:  10%|         | 837/8192 [00:04<00:17, 425.06it/s]
Adding requests:  11%|         | 882/8192 [00:04<00:16, 430.93it/s]
Adding requests:  11%|        | 926/8192 [00:04<00:17, 425.83it/s]
Adding requests:  12%|        | 969/8192 [00:04<00:17, 422.72it/s]
Adding requests:  12%|        | 1012/8192 [00:04<00:16, 423.11it/s]
Adding requests:  13%|        | 1055/8192 [00:04<00:17, 416.23it/s]
Adding requests:  13%|        | 1097/8192 [00:05<00:17, 404.22it/s]
Adding requests:  14%|        | 1143/8192 [00:05<00:16, 418.90it/s]
Adding requests:  14%|        | 1185/8192 [00:05<00:17, 407.89it/s]
Adding requests:  15%|        | 1230/8192 [00:05<00:16, 417.98it/s]
Adding requests:  16%|        | 1272/8192 [00:05<00:16, 416.61it/s]
Adding requests:  16%|        | 1314/8192 [00:05<00:16, 414.54it/s]
Adding requests:  17%|        | 1359/8192 [00:05<00:16, 423.17it/s]
Adding requests:  17%|        | 1402/8192 [00:05<00:16, 416.45it/s]
Adding requests:  18%|        | 1445/8192 [00:05<00:16, 418.02it/s]
Adding requests:  18%|        | 1490/8192 [00:06<00:15, 425.76it/s]
Adding requests:  19%|        | 1533/8192 [00:06<00:15, 425.76it/s]
Adding requests:  19%|        | 1576/8192 [00:06<00:15, 422.85it/s]
Adding requests:  20%|        | 1619/8192 [00:06<00:15, 416.78it/s]
Adding requests:  20%|        | 1661/8192 [00:06<00:15, 417.52it/s]
Adding requests:  21%|        | 1703/8192 [00:06<00:15, 409.90it/s]
Adding requests:  21%|       | 1745/8192 [00:06<00:15, 409.29it/s]
Adding requests:  22%|       | 1793/8192 [00:06<00:14, 428.23it/s]
Adding requests:  22%|       | 1836/8192 [00:06<00:15, 409.73it/s]
Adding requests:  23%|       | 1878/8192 [00:06<00:15, 404.11it/s]
Adding requests:  23%|       | 1919/8192 [00:07<00:15, 392.81it/s]
Adding requests:  24%|       | 1967/8192 [00:07<00:14, 416.29it/s]
Adding requests:  25%|       | 2009/8192 [00:07<00:15, 395.55it/s]
Adding requests:  25%|       | 2052/8192 [00:07<00:15, 404.27it/s]
Adding requests:  26%|       | 2093/8192 [00:07<00:15, 396.26it/s]
Adding requests:  26%|       | 2143/8192 [00:07<00:14, 425.23it/s]
Adding requests:  27%|       | 2186/8192 [00:07<00:15, 397.93it/s]
Adding requests:  27%|       | 2228/8192 [00:07<00:14, 397.63it/s]
Adding requests:  28%|       | 2269/8192 [00:07<00:14, 396.76it/s]
Adding requests:  28%|       | 2320/8192 [00:08<00:13, 426.80it/s]
Adding requests:  29%|       | 2363/8192 [00:08<00:14, 412.91it/s]
Adding requests:  29%|       | 2409/8192 [00:08<00:13, 426.19it/s]
Adding requests:  30%|       | 2452/8192 [00:08<00:13, 414.86it/s]
Adding requests:  31%|       | 2504/8192 [00:08<00:12, 444.72it/s]
Adding requests:  31%|       | 2549/8192 [00:08<00:12, 442.12it/s]
Adding requests:  32%|      | 2598/8192 [00:08<00:12, 453.66it/s]
Adding requests:  32%|      | 2644/8192 [00:08<00:12, 433.50it/s]
Adding requests:  33%|      | 2692/8192 [00:08<00:12, 445.44it/s]
Adding requests:  33%|      | 2737/8192 [00:09<00:12, 422.83it/s]
Adding requests:  34%|      | 2781/8192 [00:09<00:12, 426.79it/s]
Adding requests:  34%|      | 2824/8192 [00:09<00:12, 422.64it/s]
Adding requests:  35%|      | 2871/8192 [00:09<00:12, 436.08it/s]
Adding requests:  36%|      | 2915/8192 [00:09<00:12, 419.43it/s]
Adding requests:  36%|      | 2962/8192 [00:09<00:12, 433.40it/s]
Adding requests:  37%|      | 3006/8192 [00:09<00:12, 431.12it/s]
Adding requests:  37%|      | 3054/8192 [00:09<00:11, 443.69it/s]
Adding requests:  38%|      | 3099/8192 [00:09<00:11, 428.39it/s]
Adding requests:  38%|      | 3145/8192 [00:09<00:11, 433.32it/s]
Adding requests:  39%|      | 3189/8192 [00:10<00:12, 416.28it/s]
Adding requests:  40%|      | 3238/8192 [00:10<00:11, 433.50it/s]
Adding requests:  40%|      | 3282/8192 [00:10<00:12, 398.66it/s]
Adding requests:  41%|      | 3325/8192 [00:10<00:11, 406.63it/s]
Adding requests:  41%|      | 3367/8192 [00:10<00:11, 404.49it/s]
Adding requests:  42%|     | 3419/8192 [00:10<00:10, 436.23it/s]
Adding requests:  42%|     | 3464/8192 [00:10<00:11, 424.18it/s]
Adding requests:  43%|     | 3509/8192 [00:10<00:10, 431.15it/s]
Adding requests:  43%|     | 3553/8192 [00:10<00:10, 425.33it/s]
Adding requests:  44%|     | 3604/8192 [00:11<00:10, 447.60it/s]
Adding requests:  45%|     | 3649/8192 [00:11<00:10, 426.99it/s]
Adding requests:  45%|     | 3692/8192 [00:11<00:10, 424.18it/s]
Adding requests:  46%|     | 3735/8192 [00:11<00:10, 414.53it/s]
Adding requests:  46%|     | 3783/8192 [00:11<00:10, 432.44it/s]
Adding requests:  47%|     | 3827/8192 [00:11<00:10, 406.54it/s]
Adding requests:  47%|     | 3869/8192 [00:11<00:10, 410.26it/s]
Adding requests:  48%|     | 3911/8192 [00:11<00:10, 399.93it/s]
Adding requests:  48%|     | 3958/8192 [00:11<00:10, 418.30it/s]
Adding requests:  49%|     | 4001/8192 [00:12<00:10, 398.89it/s]
Adding requests:  49%|     | 4044/8192 [00:12<00:10, 406.97it/s]
Adding requests:  50%|     | 4085/8192 [00:12<00:10, 398.26it/s]
Adding requests:  50%|     | 4136/8192 [00:12<00:09, 426.36it/s]
Adding requests:  51%|     | 4179/8192 [00:12<00:09, 418.83it/s]
Adding requests:  52%|    | 4222/8192 [00:12<00:09, 415.33it/s]
Adding requests:  52%|    | 4264/8192 [00:12<00:09, 413.53it/s]
Adding requests:  53%|    | 4313/8192 [00:12<00:08, 434.15it/s]
Adding requests:  53%|    | 4357/8192 [00:12<00:09, 418.75it/s]
Adding requests:  54%|    | 4401/8192 [00:12<00:08, 423.60it/s]
Adding requests:  54%|    | 4444/8192 [00:13<00:09, 413.29it/s]
Adding requests:  55%|    | 4494/8192 [00:13<00:08, 435.09it/s]
Adding requests:  55%|    | 4538/8192 [00:13<00:08, 419.68it/s]
Adding requests:  56%|    | 4584/8192 [00:13<00:08, 430.16it/s]
Adding requests:  56%|    | 4628/8192 [00:13<00:08, 407.38it/s]
Adding requests:  57%|    | 4676/8192 [00:13<00:08, 425.13it/s]
Adding requests:  58%|    | 4719/8192 [00:13<00:08, 412.26it/s]
Adding requests:  58%|    | 4765/8192 [00:13<00:08, 423.32it/s]
Adding requests:  59%|    | 4808/8192 [00:13<00:08, 415.41it/s]
Adding requests:  59%|    | 4851/8192 [00:14<00:08, 415.36it/s]
Adding requests:  60%|    | 4893/8192 [00:14<00:08, 406.71it/s]
Adding requests:  60%|    | 4936/8192 [00:14<00:07, 412.43it/s]
Adding requests:  61%|    | 4978/8192 [00:14<00:07, 402.95it/s]
Adding requests:  61%|   | 5028/8192 [00:14<00:07, 430.28it/s]
Adding requests:  62%|   | 5072/8192 [00:14<00:07, 428.37it/s]
Adding requests:  62%|   | 5117/8192 [00:14<00:07, 432.47it/s]
Adding requests:  63%|   | 5161/8192 [00:14<00:07, 428.68it/s]
Adding requests:  64%|   | 5212/8192 [00:14<00:06, 452.21it/s]
Adding requests:  64%|   | 5258/8192 [00:15<00:06, 431.62it/s]
Adding requests:  65%|   | 5305/8192 [00:15<00:06, 441.05it/s]
Adding requests:  65%|   | 5350/8192 [00:15<00:06, 428.48it/s]
Adding requests:  66%|   | 5401/8192 [00:15<00:06, 449.47it/s]
Adding requests:  66%|   | 5447/8192 [00:15<00:06, 435.82it/s]
Adding requests:  67%|   | 5495/8192 [00:15<00:06, 446.02it/s]
Adding requests:  68%|   | 5540/8192 [00:15<00:06, 439.98it/s]
Adding requests:  68%|   | 5592/8192 [00:15<00:05, 459.18it/s]
Adding requests:  69%|   | 5639/8192 [00:15<00:05, 451.15it/s]
Adding requests:  69%|   | 5685/8192 [00:15<00:05, 422.38it/s]
Adding requests:  70%|   | 5728/8192 [00:16<00:05, 420.60it/s]
Adding requests:  70%|   | 5774/8192 [00:16<00:05, 430.94it/s]
Adding requests:  71%|   | 5818/8192 [00:16<00:05, 421.42it/s]
Adding requests:  72%|  | 5861/8192 [00:16<00:05, 420.59it/s]
Adding requests:  72%|  | 5904/8192 [00:16<00:05, 419.05it/s]
Adding requests:  73%|  | 5956/8192 [00:16<00:05, 446.39it/s]
Adding requests:  73%|  | 6001/8192 [00:16<00:05, 419.68it/s]
Adding requests:  74%|  | 6044/8192 [00:16<00:05, 417.45it/s]
Adding requests:  74%|  | 6087/8192 [00:16<00:05, 415.58it/s]
Adding requests:  75%|  | 6135/8192 [00:17<00:04, 430.70it/s]
Adding requests:  75%|  | 6179/8192 [00:17<00:04, 422.63it/s]
Adding requests:  76%|  | 6222/8192 [00:17<00:04, 418.42it/s]
Adding requests:  76%|  | 6264/8192 [00:17<00:04, 407.67it/s]
Adding requests:  77%|  | 6314/8192 [00:17<00:04, 433.63it/s]
Adding requests:  78%|  | 6358/8192 [00:17<00:04, 417.27it/s]
Adding requests:  78%|  | 6403/8192 [00:17<00:04, 422.86it/s]
Adding requests:  79%|  | 6446/8192 [00:17<00:04, 412.17it/s]
Adding requests:  79%|  | 6493/8192 [00:17<00:03, 425.34it/s]
Adding requests:  80%|  | 6536/8192 [00:17<00:03, 417.67it/s]
Adding requests:  80%|  | 6578/8192 [00:18<00:03, 415.85it/s]
Adding requests:  81%|  | 6620/8192 [00:18<00:03, 400.64it/s]
Adding requests:  81%| | 6671/8192 [00:18<00:03, 429.80it/s]
Adding requests:  82%| | 6715/8192 [00:18<00:03, 413.25it/s]
Adding requests:  83%| | 6761/8192 [00:18<00:03, 425.04it/s]
Adding requests:  83%| | 6804/8192 [00:18<00:03, 417.80it/s]
Adding requests:  84%| | 6850/8192 [00:18<00:03, 429.86it/s]
Adding requests:  84%| | 6894/8192 [00:18<00:03, 420.71it/s]
Adding requests:  85%| | 6939/8192 [00:18<00:02, 426.88it/s]
Adding requests:  85%| | 6982/8192 [00:19<00:02, 409.56it/s]
Adding requests:  86%| | 7032/8192 [00:19<00:02, 434.50it/s]
Adding requests:  86%| | 7076/8192 [00:19<00:02, 411.28it/s]
Adding requests:  87%| | 7119/8192 [00:19<00:02, 415.29it/s]
Adding requests:  87%| | 7161/8192 [00:19<00:02, 406.71it/s]
Adding requests:  88%| | 7211/8192 [00:19<00:02, 430.48it/s]
Adding requests:  89%| | 7255/8192 [00:19<00:02, 419.82it/s]
Adding requests:  89%| | 7300/8192 [00:19<00:02, 427.66it/s]
Adding requests:  90%| | 7343/8192 [00:19<00:02, 423.67it/s]
Adding requests:  90%| | 7390/8192 [00:20<00:01, 435.64it/s]
Adding requests:  91%| | 7434/8192 [00:20<00:01, 420.72it/s]
Adding requests:  91%|| 7478/8192 [00:20<00:01, 424.34it/s]
Adding requests:  92%|| 7521/8192 [00:20<00:01, 413.35it/s]
Adding requests:  92%|| 7569/8192 [00:20<00:01, 431.92it/s]
Adding requests:  93%|| 7613/8192 [00:20<00:01, 409.78it/s]
Adding requests:  93%|| 7656/8192 [00:20<00:01, 412.51it/s]
Adding requests:  94%|| 7698/8192 [00:20<00:01, 408.71it/s]
Adding requests:  95%|| 7745/8192 [00:20<00:01, 423.15it/s]
Adding requests:  95%|| 7788/8192 [00:20<00:00, 407.70it/s]
Adding requests:  96%|| 7832/8192 [00:21<00:00, 414.79it/s]
Adding requests:  96%|| 7874/8192 [00:21<00:00, 398.63it/s]
Adding requests:  97%|| 7923/8192 [00:21<00:00, 423.43it/s]
Adding requests:  97%|| 7966/8192 [00:21<00:00, 409.64it/s]
Adding requests:  98%|| 8010/8192 [00:21<00:00, 417.08it/s]
Adding requests:  98%|| 8052/8192 [00:21<00:00, 399.55it/s]
Adding requests:  99%|| 8101/8192 [00:21<00:00, 423.19it/s]
Adding requests:  99%|| 8144/8192 [00:21<00:00, 407.55it/s]
Adding requests: 100%|| 8186/8192 [00:21<00:00, 401.62it/s]
Adding requests: 100%|| 8192/8192 [00:21<00:00, 372.75it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 18/8192 [00:05<38:00,  3.58it/s, est. speed input: 3670.06 toks/s, output: 3.58 toks/s]
Processed prompts:   1%|          | 82/8192 [00:25<42:13,  3.20it/s, est. speed input: 3300.66 toks/s, output: 3.22 toks/s]
Processed prompts:   2%|         | 146/8192 [00:45<42:08,  3.18it/s, est. speed input: 3275.18 toks/s, output: 3.20 toks/s]
Processed prompts:   3%|         | 210/8192 [01:06<42:07,  3.16it/s, est. speed input: 3253.02 toks/s, output: 3.18 toks/s]
Processed prompts:   3%|         | 274/8192 [01:26<41:43,  3.16it/s, est. speed input: 3251.29 toks/s, output: 3.18 toks/s]
Processed prompts:   4%|         | 338/8192 [01:46<41:32,  3.15it/s, est. speed input: 3242.45 toks/s, output: 3.17 toks/s]
Processed prompts:   5%|         | 402/8192 [02:06<41:07,  3.16it/s, est. speed input: 3242.76 toks/s, output: 3.17 toks/s]
Processed prompts:   6%|         | 466/8192 [02:27<40:54,  3.15it/s, est. speed input: 3237.46 toks/s, output: 3.16 toks/s]
Processed prompts:   6%|         | 530/8192 [02:47<40:38,  3.14it/s, est. speed input: 3233.25 toks/s, output: 3.16 toks/s]
Processed prompts:   7%|         | 594/8192 [03:08<40:22,  3.14it/s, est. speed input: 3229.87 toks/s, output: 3.15 toks/s]
Processed prompts:   8%|         | 658/8192 [03:28<40:04,  3.13it/s, est. speed input: 3227.14 toks/s, output: 3.15 toks/s]
Processed prompts:   9%|         | 722/8192 [03:49<39:45,  3.13it/s, est. speed input: 3224.66 toks/s, output: 3.15 toks/s]
Processed prompts:  10%|         | 786/8192 [04:09<39:17,  3.14it/s, est. speed input: 3226.15 toks/s, output: 3.15 toks/s]
Processed prompts:  10%|         | 850/8192 [04:29<39:00,  3.14it/s, est. speed input: 3224.09 toks/s, output: 3.15 toks/s]
Processed prompts:  11%|         | 914/8192 [04:50<38:43,  3.13it/s, est. speed input: 3222.31 toks/s, output: 3.15 toks/s]
Processed prompts:  12%|        | 978/8192 [05:10<38:24,  3.13it/s, est. speed input: 3220.79 toks/s, output: 3.15 toks/s]
Processed prompts:  13%|        | 1042/8192 [05:31<38:05,  3.13it/s, est. speed input: 3219.50 toks/s, output: 3.14 toks/s]
Processed prompts:  14%|        | 1106/8192 [05:51<37:45,  3.13it/s, est. speed input: 3218.39 toks/s, output: 3.14 toks/s]
Processed prompts:  14%|        | 1170/8192 [06:12<37:17,  3.14it/s, est. speed input: 3219.62 toks/s, output: 3.14 toks/s]
Processed prompts:  15%|        | 1234/8192 [06:32<37:00,  3.13it/s, est. speed input: 3218.46 toks/s, output: 3.14 toks/s]
Processed prompts:  16%|        | 1298/8192 [06:53<36:41,  3.13it/s, est. speed input: 3217.59 toks/s, output: 3.14 toks/s]
Processed prompts:  17%|        | 1362/8192 [07:13<36:22,  3.13it/s, est. speed input: 3216.75 toks/s, output: 3.14 toks/s]
Processed prompts:  17%|        | 1426/8192 [07:34<36:03,  3.13it/s, est. speed input: 3215.86 toks/s, output: 3.14 toks/s]
Processed prompts:  18%|        | 1490/8192 [07:54<35:43,  3.13it/s, est. speed input: 3215.09 toks/s, output: 3.14 toks/s]
Processed prompts:  19%|        | 1554/8192 [08:14<35:16,  3.14it/s, est. speed input: 3215.99 toks/s, output: 3.14 toks/s]
Processed prompts:  20%|        | 1618/8192 [08:35<34:50,  3.14it/s, est. speed input: 3216.85 toks/s, output: 3.14 toks/s]
Processed prompts:  21%|        | 1682/8192 [08:55<34:35,  3.14it/s, est. speed input: 3216.05 toks/s, output: 3.14 toks/s]
Processed prompts:  21%|       | 1746/8192 [09:16<34:18,  3.13it/s, est. speed input: 3215.25 toks/s, output: 3.14 toks/s]
Processed prompts:  22%|       | 1810/8192 [09:36<33:59,  3.13it/s, est. speed input: 3214.63 toks/s, output: 3.14 toks/s]
Processed prompts:  23%|       | 1874/8192 [09:57<33:40,  3.13it/s, est. speed input: 3214.02 toks/s, output: 3.14 toks/s]
Processed prompts:  24%|       | 1938/8192 [10:17<33:21,  3.13it/s, est. speed input: 3213.43 toks/s, output: 3.14 toks/s]
Processed prompts:  24%|       | 2002/8192 [10:38<33:01,  3.12it/s, est. speed input: 3212.86 toks/s, output: 3.14 toks/s]
Processed prompts:  25%|       | 2066/8192 [10:58<32:41,  3.12it/s, est. speed input: 3212.35 toks/s, output: 3.14 toks/s]
Processed prompts:  26%|       | 2130/8192 [11:19<32:21,  3.12it/s, est. speed input: 3211.85 toks/s, output: 3.14 toks/s]
Processed prompts:  27%|       | 2194/8192 [11:39<31:53,  3.13it/s, est. speed input: 3212.56 toks/s, output: 3.14 toks/s]
Processed prompts:  28%|       | 2258/8192 [11:59<31:35,  3.13it/s, est. speed input: 3212.09 toks/s, output: 3.14 toks/s]
Processed prompts:  28%|       | 2322/8192 [12:20<31:17,  3.13it/s, est. speed input: 3211.62 toks/s, output: 3.14 toks/s]
Processed prompts:  29%|       | 2386/8192 [12:40<30:57,  3.13it/s, est. speed input: 3211.22 toks/s, output: 3.14 toks/s]
Processed prompts:  30%|       | 2450/8192 [13:01<30:37,  3.12it/s, est. speed input: 3210.83 toks/s, output: 3.14 toks/s]
Processed prompts:  31%|       | 2514/8192 [13:21<30:17,  3.12it/s, est. speed input: 3210.47 toks/s, output: 3.14 toks/s]
Processed prompts:  31%|      | 2578/8192 [13:42<29:51,  3.13it/s, est. speed input: 3211.05 toks/s, output: 3.14 toks/s]
Processed prompts:  32%|      | 2642/8192 [14:02<29:33,  3.13it/s, est. speed input: 3210.60 toks/s, output: 3.14 toks/s]
Processed prompts:  33%|      | 2706/8192 [14:22<29:08,  3.14it/s, est. speed input: 3211.21 toks/s, output: 3.14 toks/s]
Processed prompts:  34%|      | 2770/8192 [14:43<28:50,  3.13it/s, est. speed input: 3210.85 toks/s, output: 3.14 toks/s]
Processed prompts:  35%|      | 2834/8192 [15:03<28:32,  3.13it/s, est. speed input: 3210.47 toks/s, output: 3.14 toks/s]
Processed prompts:  35%|      | 2898/8192 [15:23<27:58,  3.15it/s, est. speed input: 3212.16 toks/s, output: 3.14 toks/s]
Processed prompts:  36%|      | 2962/8192 [15:44<27:43,  3.14it/s, est. speed input: 3211.86 toks/s, output: 3.14 toks/s]
Processed prompts:  37%|      | 3026/8192 [16:04<27:26,  3.14it/s, est. speed input: 3211.48 toks/s, output: 3.14 toks/s]
Processed prompts:  38%|      | 3090/8192 [16:25<27:09,  3.13it/s, est. speed input: 3211.12 toks/s, output: 3.14 toks/s]
Processed prompts:  39%|      | 3154/8192 [16:45<26:50,  3.13it/s, est. speed input: 3210.77 toks/s, output: 3.14 toks/s]
Processed prompts:  39%|      | 3218/8192 [17:06<26:31,  3.13it/s, est. speed input: 3210.44 toks/s, output: 3.14 toks/s]
Processed prompts:  40%|      | 3282/8192 [17:26<26:11,  3.12it/s, est. speed input: 3210.20 toks/s, output: 3.13 toks/s]
Processed prompts:  41%|      | 3346/8192 [17:47<25:51,  3.12it/s, est. speed input: 3209.95 toks/s, output: 3.13 toks/s]
Processed prompts:  42%|     | 3410/8192 [18:07<25:30,  3.12it/s, est. speed input: 3209.74 toks/s, output: 3.13 toks/s]
Processed prompts:  42%|     | 3474/8192 [18:28<25:10,  3.12it/s, est. speed input: 3209.48 toks/s, output: 3.13 toks/s]
Processed prompts:  43%|     | 3538/8192 [18:48<24:50,  3.12it/s, est. speed input: 3209.19 toks/s, output: 3.13 toks/s]
Processed prompts:  44%|     | 3602/8192 [19:09<24:30,  3.12it/s, est. speed input: 3208.95 toks/s, output: 3.13 toks/s]
Processed prompts:  45%|     | 3666/8192 [19:29<24:04,  3.13it/s, est. speed input: 3209.46 toks/s, output: 3.13 toks/s]
Processed prompts:  46%|     | 3730/8192 [19:50<23:45,  3.13it/s, est. speed input: 3209.28 toks/s, output: 3.13 toks/s]
Processed prompts:  46%|     | 3794/8192 [20:10<23:25,  3.13it/s, est. speed input: 3209.09 toks/s, output: 3.13 toks/s]
Processed prompts:  47%|     | 3858/8192 [20:31<23:06,  3.13it/s, est. speed input: 3208.89 toks/s, output: 3.13 toks/s]
Processed prompts:  48%|     | 3922/8192 [20:51<22:41,  3.14it/s, est. speed input: 3209.34 toks/s, output: 3.13 toks/s]
Processed prompts:  49%|     | 3986/8192 [21:11<22:22,  3.13it/s, est. speed input: 3209.14 toks/s, output: 3.13 toks/s]
Processed prompts:  49%|     | 4050/8192 [21:32<21:58,  3.14it/s, est. speed input: 3209.58 toks/s, output: 3.13 toks/s]
Processed prompts:  50%|     | 4114/8192 [21:52<21:40,  3.14it/s, est. speed input: 3209.42 toks/s, output: 3.13 toks/s]
Processed prompts:  51%|     | 4178/8192 [22:13<21:21,  3.13it/s, est. speed input: 3209.22 toks/s, output: 3.13 toks/s]
Processed prompts:  52%|    | 4242/8192 [22:33<21:02,  3.13it/s, est. speed input: 3209.02 toks/s, output: 3.13 toks/s]
Processed prompts:  53%|    | 4306/8192 [22:54<20:43,  3.13it/s, est. speed input: 3208.83 toks/s, output: 3.13 toks/s]
Processed prompts:  53%|    | 4370/8192 [23:14<20:23,  3.12it/s, est. speed input: 3208.65 toks/s, output: 3.13 toks/s]
Processed prompts:  54%|    | 4434/8192 [23:34<19:58,  3.14it/s, est. speed input: 3209.07 toks/s, output: 3.13 toks/s]
Processed prompts:  55%|    | 4498/8192 [23:55<19:39,  3.13it/s, est. speed input: 3208.92 toks/s, output: 3.13 toks/s]
Processed prompts:  56%|    | 4562/8192 [24:15<19:15,  3.14it/s, est. speed input: 3209.32 toks/s, output: 3.13 toks/s]
Processed prompts:  56%|    | 4626/8192 [24:36<18:57,  3.14it/s, est. speed input: 3209.17 toks/s, output: 3.13 toks/s]
Processed prompts:  57%|    | 4690/8192 [24:56<18:38,  3.13it/s, est. speed input: 3209.03 toks/s, output: 3.13 toks/s]
Processed prompts:  58%|    | 4754/8192 [25:17<18:18,  3.13it/s, est. speed input: 3208.88 toks/s, output: 3.13 toks/s]
Processed prompts:  59%|    | 4818/8192 [25:37<17:58,  3.13it/s, est. speed input: 3208.73 toks/s, output: 3.13 toks/s]
Processed prompts:  60%|    | 4882/8192 [25:58<17:38,  3.13it/s, est. speed input: 3208.58 toks/s, output: 3.13 toks/s]
Processed prompts:  60%|    | 4946/8192 [26:18<17:15,  3.14it/s, est. speed input: 3208.91 toks/s, output: 3.13 toks/s]
Processed prompts:  61%|    | 5010/8192 [26:38<16:56,  3.13it/s, est. speed input: 3208.77 toks/s, output: 3.13 toks/s]
Processed prompts:  62%|   | 5074/8192 [26:59<16:36,  3.13it/s, est. speed input: 3208.62 toks/s, output: 3.13 toks/s]
Processed prompts:  63%|   | 5138/8192 [27:19<16:16,  3.13it/s, est. speed input: 3208.46 toks/s, output: 3.13 toks/s]
Processed prompts:  64%|   | 5202/8192 [27:40<15:53,  3.14it/s, est. speed input: 3208.82 toks/s, output: 3.13 toks/s]
Processed prompts:  64%|   | 5266/8192 [28:00<15:30,  3.14it/s, est. speed input: 3209.18 toks/s, output: 3.13 toks/s]
Processed prompts:  65%|   | 5330/8192 [28:20<15:12,  3.14it/s, est. speed input: 3209.01 toks/s, output: 3.13 toks/s]
Processed prompts:  66%|   | 5394/8192 [28:41<14:53,  3.13it/s, est. speed input: 3208.88 toks/s, output: 3.13 toks/s]
Processed prompts:  67%|   | 5458/8192 [29:01<14:30,  3.14it/s, est. speed input: 3209.21 toks/s, output: 3.13 toks/s]
Processed prompts:  67%|   | 5522/8192 [29:21<14:08,  3.15it/s, est. speed input: 3209.57 toks/s, output: 3.13 toks/s]
Processed prompts:  68%|   | 5586/8192 [29:42<13:49,  3.14it/s, est. speed input: 3209.40 toks/s, output: 3.13 toks/s]
Processed prompts:  69%|   | 5650/8192 [30:02<13:30,  3.14it/s, est. speed input: 3209.31 toks/s, output: 3.13 toks/s]
Processed prompts:  70%|   | 5714/8192 [30:23<13:11,  3.13it/s, est. speed input: 3209.20 toks/s, output: 3.13 toks/s]
Processed prompts:  71%|   | 5778/8192 [30:43<12:51,  3.13it/s, est. speed input: 3209.07 toks/s, output: 3.13 toks/s]
Processed prompts:  71%|  | 5842/8192 [31:04<12:31,  3.13it/s, est. speed input: 3208.95 toks/s, output: 3.13 toks/s]
Processed prompts:  72%|  | 5906/8192 [31:24<12:08,  3.14it/s, est. speed input: 3209.27 toks/s, output: 3.13 toks/s]
Processed prompts:  73%|  | 5970/8192 [31:44<11:46,  3.15it/s, est. speed input: 3209.60 toks/s, output: 3.13 toks/s]
Processed prompts:  74%|  | 6034/8192 [32:05<11:27,  3.14it/s, est. speed input: 3209.49 toks/s, output: 3.13 toks/s]
Processed prompts:  74%|  | 6098/8192 [32:25<11:08,  3.13it/s, est. speed input: 3209.36 toks/s, output: 3.13 toks/s]
Processed prompts:  75%|  | 6162/8192 [32:46<10:48,  3.13it/s, est. speed input: 3209.24 toks/s, output: 3.13 toks/s]
Processed prompts:  76%|  | 6226/8192 [33:06<10:28,  3.13it/s, est. speed input: 3209.15 toks/s, output: 3.13 toks/s]
Processed prompts:  77%|  | 6290/8192 [33:27<10:08,  3.13it/s, est. speed input: 3209.03 toks/s, output: 3.13 toks/s]
Processed prompts:  78%|  | 6354/8192 [33:47<09:47,  3.13it/s, est. speed input: 3208.93 toks/s, output: 3.13 toks/s]
Processed prompts:  78%|  | 6418/8192 [34:08<09:27,  3.13it/s, est. speed input: 3208.82 toks/s, output: 3.13 toks/s]
Processed prompts:  79%|  | 6482/8192 [34:28<09:07,  3.12it/s, est. speed input: 3208.69 toks/s, output: 3.13 toks/s]
Processed prompts:  80%|  | 6546/8192 [34:49<08:46,  3.12it/s, est. speed input: 3208.58 toks/s, output: 3.13 toks/s]
Processed prompts:  81%|  | 6610/8192 [35:09<08:26,  3.12it/s, est. speed input: 3208.48 toks/s, output: 3.13 toks/s]
Processed prompts:  81%| | 6674/8192 [35:30<08:06,  3.12it/s, est. speed input: 3208.38 toks/s, output: 3.13 toks/s]
Processed prompts:  82%| | 6738/8192 [35:50<07:45,  3.12it/s, est. speed input: 3208.26 toks/s, output: 3.13 toks/s]
Processed prompts:  83%| | 6802/8192 [36:11<07:25,  3.12it/s, est. speed input: 3208.15 toks/s, output: 3.13 toks/s]
Processed prompts:  84%| | 6866/8192 [36:31<07:04,  3.12it/s, est. speed input: 3208.05 toks/s, output: 3.13 toks/s]
Processed prompts:  85%| | 6930/8192 [36:52<06:44,  3.12it/s, est. speed input: 3207.95 toks/s, output: 3.13 toks/s]
Processed prompts:  85%| | 6994/8192 [37:12<06:23,  3.12it/s, est. speed input: 3207.86 toks/s, output: 3.13 toks/s]
Processed prompts:  86%| | 7058/8192 [37:33<06:03,  3.12it/s, est. speed input: 3207.78 toks/s, output: 3.13 toks/s]
Processed prompts:  87%| | 7122/8192 [37:53<05:42,  3.12it/s, est. speed input: 3207.71 toks/s, output: 3.13 toks/s]
Processed prompts:  88%| | 7186/8192 [38:14<05:22,  3.12it/s, est. speed input: 3207.64 toks/s, output: 3.13 toks/s]
Processed prompts:  89%| | 7250/8192 [38:34<05:01,  3.12it/s, est. speed input: 3207.56 toks/s, output: 3.13 toks/s]
Processed prompts:  89%| | 7314/8192 [38:55<04:41,  3.12it/s, est. speed input: 3207.50 toks/s, output: 3.13 toks/s]
Processed prompts:  90%| | 7378/8192 [39:15<04:20,  3.12it/s, est. speed input: 3207.42 toks/s, output: 3.13 toks/s]
Processed prompts:  91%| | 7442/8192 [39:35<04:00,  3.12it/s, est. speed input: 3207.36 toks/s, output: 3.13 toks/s]
Processed prompts:  92%|| 7506/8192 [39:56<03:39,  3.12it/s, est. speed input: 3207.26 toks/s, output: 3.13 toks/s]
Processed prompts:  92%|| 7570/8192 [40:16<03:19,  3.12it/s, est. speed input: 3207.19 toks/s, output: 3.13 toks/s]
Processed prompts:  93%|| 7634/8192 [40:37<02:58,  3.12it/s, est. speed input: 3207.13 toks/s, output: 3.13 toks/s]
Processed prompts:  94%|| 7698/8192 [40:57<02:38,  3.12it/s, est. speed input: 3207.05 toks/s, output: 3.13 toks/s]
Processed prompts:  95%|| 7762/8192 [41:18<02:17,  3.12it/s, est. speed input: 3206.99 toks/s, output: 3.13 toks/s]
Processed prompts:  96%|| 7826/8192 [41:38<01:57,  3.12it/s, est. speed input: 3206.93 toks/s, output: 3.13 toks/s]
Processed prompts:  96%|| 7890/8192 [41:59<01:36,  3.12it/s, est. speed input: 3206.87 toks/s, output: 3.13 toks/s]
Processed prompts:  97%|| 7954/8192 [42:19<01:16,  3.12it/s, est. speed input: 3206.79 toks/s, output: 3.13 toks/s]
Processed prompts:  98%|| 8018/8192 [42:40<00:55,  3.12it/s, est. speed input: 3206.71 toks/s, output: 3.13 toks/s]
Processed prompts:  99%|| 8082/8192 [43:00<00:35,  3.12it/s, est. speed input: 3206.65 toks/s, output: 3.13 toks/s]
Processed prompts:  99%|| 8146/8192 [43:15<00:13,  3.40it/s, est. speed input: 3213.37 toks/s, output: 3.14 toks/s]
Processed prompts: 100%|| 8192/8192 [43:15<00:00,  3.40it/s, est. speed input: 3231.52 toks/s, output: 3.16 toks/s]
Processed prompts: 100%|| 8192/8192 [43:15<00:00,  3.16it/s, est. speed input: 3231.52 toks/s, output: 3.16 toks/s]
[rank0]:[W127 06:06:12.679538226 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

