
========== M=512 ==========
Time: 2026-01-25 19:02:21
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:02:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:02:25 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=319504) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=319504) 
(EngineCore_DP0 pid=319504) 
(EngineCore_DP0 pid=319504) ================================================================
(EngineCore_DP0 pid=319504) Internal Triton PTX codegen error
(EngineCore_DP0 pid=319504) `ptxas` stderr:
(EngineCore_DP0 pid=319504) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=319504) 
(EngineCore_DP0 pid=319504) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpm05ds4b8.ptx -o /tmp/tmpm05ds4b8.ptx.o
(EngineCore_DP0 pid=319504) 
(EngineCore_DP0 pid=319504) 
(EngineCore_DP0 pid=319504) //
(EngineCore_DP0 pid=319504) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=319504) //
(EngineCore_DP0 pid=319504) 
(EngineCore_DP0 pid=319504) .version 8.7
(EngineCore_DP0 pid=319504) .target sm_121a
(EngineCore_DP0 pid=319504) .address_size 64
(EngineCore_DP0 pid=319504) 
(EngineCore_DP0 pid=319504) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=319504) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=319504)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=319504) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=319504) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=319504) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=319504) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=319504) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=319504) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=319504) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=319504) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=319504) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=319504) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=319504) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=319504) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=319504) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=319504) )
(EngineCore_DP0 pid=319504) .reqntid 1024
(EngineCore_DP0 pid=319504) {
(EngineCore_DP0 pid=319504) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=319504) 	.reg .b16 	%rs<20>;
(EngineCore_DP0 pid=319504) 	.reg .b32 	%r<120>;
(EngineCore_DP0 pid=319504) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=319504) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=319504) $L__func_begin0:
(EngineCore_DP0 pid=319504) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=319504) 
(EngineCore_DP0 pid=319504) // %bb.0:
(EngineCore_DP0 pid=319504) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=319504) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=319504) 	ld.param.b32 	%r17, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=319504) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=319504) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=319504) $L__tmp0:
(EngineCore_DP0 pid=319504) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=319504) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=319504) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=319504) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=319504) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=319504) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=319504) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=319504) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=319504) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=319504) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=319504) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=319504) 	mov.b32 	%r118, 0f2B8CBCCC;
(EngineCore_DP0 pid=319504) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=319504) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=319504) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=319504) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=319504) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=319504) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=319504) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=319504) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=319504) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=319504) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=319504) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=319504) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=319504) 	mov.b32 	%r116, 0f00000000;
(EngineCore_DP0 pid=319504) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=319504) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=319504) 	mov.b32 	%r117, %r37;
(EngineCore_DP0 pid=319504) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=319504) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=319504) 	add.s32 	%r45, %r3, %r117;
(EngineCore_DP0 pid=319504) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=319504) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=319504) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=319504) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=319504) 	// begin inline asm
(EngineCore_DP0 pid=319504) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=319504) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=319504) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=319504) 	// end inline asm
(EngineCore_DP0 pid=319504) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=319504) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=319504) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=319504) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=319504) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=319504) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=319504) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=319504) $L__tmp1:
(EngineCore_DP0 pid=319504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	bar.sync 	0;
(EngineCore_DP0 pid=319504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=319504) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=319504) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=319504) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=319504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=319504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=319504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=319504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=319504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=319504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=319504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=319504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=319504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=319504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=319504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	// begin inline asm
(EngineCore_DP0 pid=319504) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=319504) 	// end inline asm
(EngineCore_DP0 pid=319504) 	bar.sync 	0;
(EngineCore_DP0 pid=319504) 	// begin inline asm
(EngineCore_DP0 pid=319504) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=319504) 	// end inline asm
(EngineCore_DP0 pid=319504) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=319504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=319504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=319504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=319504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=319504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=319504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=319504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=319504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=319504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=319504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319504) 	// begin inline asm
(EngineCore_DP0 pid=319504) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=319504) 	// end inline asm
(EngineCore_DP0 pid=319504) 	bar.sync 	0;
(EngineCore_DP0 pid=319504) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=319504) $L__tmp2:
(EngineCore_DP0 pid=319504) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=319504) 	max.f32 	%r116, %r116, %r65;
(EngineCore_DP0 pid=319504) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=319504) 	add.s32 	%r117, %r117, 4096;
(EngineCore_DP0 pid=319504) 	setp.lt.s32 	%p6, %r117, %r18;
(EngineCore_DP0 pid=319504) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=319504) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=319504) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=319504) 	max.f32 	%r118, %r116, 0f2B8CBCCC;
(EngineCore_DP0 pid=319504) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=319504) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=319504) 	mov.b32 	%r67, 0f42FE0000;
(EngineCore_DP0 pid=319504) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=319504) 	div.full.f32 	%r68, %r118, %r67;
(EngineCore_DP0 pid=319504) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=319504) 	max.f32 	%r66, %r68, 0f37810204;
(EngineCore_DP0 pid=319504) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=319504) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=319504) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=319504) 	// begin inline asm
(EngineCore_DP0 pid=319504) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=319504) 	// end inline asm
(EngineCore_DP0 pid=319504) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=319504) 	mul.lo.s32 	%r14, %r19, 3;
(EngineCore_DP0 pid=319504) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=319504) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=319504) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=319504) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=319504) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=319504) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=319504) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=319504) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=319504) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=319504) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=319504) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=319504) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=319504) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=319504) 	div.full.f32 	%r13, %r67, %r118;
(EngineCore_DP0 pid=319504) 	mov.b32 	%r119, 0;
(EngineCore_DP0 pid=319504) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=319504)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=319504) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=319504) 	add.s32 	%r72, %r2, %r119;
(EngineCore_DP0 pid=319504) 	setp.lt.s32 	%p13, %r72, %r14;
(EngineCore_DP0 pid=319504) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=319504) 	mul.hi.s32 	%r73, %r72, 1431655766;
(EngineCore_DP0 pid=319504) 	shr.u32 	%r74, %r73, 31;
(EngineCore_DP0 pid=319504) 	add.s32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=319504) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=319504) 	mul.lo.s32 	%r76, %r75, 3;
(EngineCore_DP0 pid=319504) 	sub.s32 	%r77, %r72, %r76;
(EngineCore_DP0 pid=319504) 	.loc	1 319 22                        // quant_slide_tuned_Llama3.2-1B.py:319:22
(EngineCore_DP0 pid=319504) 	shl.b32 	%r78, %r75, 3;
(EngineCore_DP0 pid=319504) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=319504) 	shl.b32 	%r79, %r77, 1;
(EngineCore_DP0 pid=319504) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=319504) 	add.s32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=319504) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=319504) 	setp.lt.s32 	%p14, %r80, %r17;
(EngineCore_DP0 pid=319504) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=319504) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=319504) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=319504) 	mad.wide.s32 	%rd8, %r80, 2, %rd1;
(EngineCore_DP0 pid=319504) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=319504) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=319504) 	// begin inline asm
(EngineCore_DP0 pid=319504) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=319504) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=319504) 	// end inline asm
(EngineCore_DP0 pid=319504) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=319504) 	cvt.f32.bf16 	%r81, %rs12;
(EngineCore_DP0 pid=319504) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=319504) 	or.b32 	%r82, %r80, 1;
(EngineCore_DP0 pid=319504) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=319504) 	setp.lt.s32 	%p15, %r82, %r17;
(EngineCore_DP0 pid=319504) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=319504) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=319504) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=319504) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=319504) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=319504) 	// begin inline asm
(EngineCore_DP0 pid=319504) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=319504) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=319504) 	// end inline asm
(EngineCore_DP0 pid=319504) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=319504) 	cvt.f32.bf16 	%r83, %rs14;
(EngineCore_DP0 pid=319504) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=319504) 	add.s32 	%r84, %r80, 2;
(EngineCore_DP0 pid=319504) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=319504) 	setp.lt.s32 	%p16, %r84, %r17;
(EngineCore_DP0 pid=319504) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=319504) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=319504) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=319504) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=319504) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=319504) 	// begin inline asm
(EngineCore_DP0 pid=319504) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=319504) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=319504) 	// end inline asm
(EngineCore_DP0 pid=319504) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=319504) 	cvt.f32.bf16 	%r85, %rs16;
(EngineCore_DP0 pid=319504) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=319504) 	add.s32 	%r86, %r80, 3;
(EngineCore_DP0 pid=319504) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=319504) 	setp.lt.s32 	%p17, %r86, %r17;
(EngineCore_DP0 pid=319504) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=319504) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=319504) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=319504) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=319504) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=319504) 	// begin inline asm
(EngineCore_DP0 pid=319504) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=319504) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=319504) 	// end inline asm
(EngineCore_DP0 pid=319504) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=319504) 	cvt.f32.bf16 	%r87, %rs18;
(EngineCore_DP0 pid=319504) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=319504) 	mul.f32 	%r88, %r13, %r81;
(EngineCore_DP0 pid=319504) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=319504) 	cvt.rni.f32.f32 	%r89, %r88;
(EngineCore_DP0 pid=319504) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=319504) 	max.f32 	%r90, %r89, 0fC3000000;
(EngineCore_DP0 pid=319504) 	min.f32 	%r91, %r90, 0f42FE0000;
(EngineCore_DP0 pid=319504) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=319504) 	cvt.rzi.s32.f32 	%r92, %r91;
(EngineCore_DP0 pid=319504) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=319504) 	and.b32 	%r93, %r92, 255;
(EngineCore_DP0 pid=319504) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=319504) 	mul.f32 	%r94, %r13, %r83;
(EngineCore_DP0 pid=319504) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=319504) 	cvt.rni.f32.f32 	%r95, %r94;
(EngineCore_DP0 pid=319504) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=319504) 	mul.f32 	%r96, %r13, %r85;
(EngineCore_DP0 pid=319504) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=319504) 	cvt.rni.f32.f32 	%r97, %r96;
(EngineCore_DP0 pid=319504) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=319504) 	mul.f32 	%r98, %r13, %r87;
(EngineCore_DP0 pid=319504) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=319504) 	cvt.rni.f32.f32 	%r99, %r98;
(EngineCore_DP0 pid=319504) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=319504) 	max.f32 	%r100, %r99, 0fC3000000;
(EngineCore_DP0 pid=319504) 	min.f32 	%r101, %r100, 0f42FE0000;
(EngineCore_DP0 pid=319504) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=319504) 	cvt.rzi.s32.f32 	%r102, %r101;
(EngineCore_DP0 pid=319504) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=319504) 	max.f32 	%r103, %r97, 0fC3000000;
(EngineCore_DP0 pid=319504) 	max.f32 	%r104, %r95, 0fC3000000;
(EngineCore_DP0 pid=319504) 	min.f32 	%r105, %r104, 0f42FE0000;
(EngineCore_DP0 pid=319504) 	min.f32 	%r106, %r103, 0f42FE0000;
(EngineCore_DP0 pid=319504) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=319504) 	cvt.rzi.s32.f32 	%r107, %r106;
(EngineCore_DP0 pid=319504) 	cvt.rzi.s32.f32 	%r108, %r105;
(EngineCore_DP0 pid=319504) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=319504) 	shl.b32 	%r109, %r108, 8;
(EngineCore_DP0 pid=319504) 	shl.b32 	%r110, %r107, 16;
(EngineCore_DP0 pid=319504) 	and.b32 	%r111, %r110, 16711680;
(EngineCore_DP0 pid=319504) 	and.b32 	%r112, %r109, 65280;
(EngineCore_DP0 pid=319504) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=319504) 	or.b32 	%r113, %r112, %r93;
(EngineCore_DP0 pid=319504) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=319504) 	or.b32 	%r114, %r113, %r111;
(EngineCore_DP0 pid=319504) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=319504) 	shl.b32 	%r115, %r102, 24;
(EngineCore_DP0 pid=319504) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=319504) 	or.b32 	%r70, %r114, %r115;
(EngineCore_DP0 pid=319504) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=319504) 	mad.wide.s32 	%rd12, %r72, 4, %rd2;
(EngineCore_DP0 pid=319504) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=319504) 	// begin inline asm
(EngineCore_DP0 pid=319504) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r70 };
(EngineCore_DP0 pid=319504) 	// end inline asm
(EngineCore_DP0 pid=319504) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=319504) 	add.s32 	%r119, %r119, 1024;
(EngineCore_DP0 pid=319504) 	setp.lt.s32 	%p18, %r119, %r14;
(EngineCore_DP0 pid=319504) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=319504) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=319504) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=319504) 	ret;
(EngineCore_DP0 pid=319504) $L__tmp3:
(EngineCore_DP0 pid=319504) $L__func_end0:
(EngineCore_DP0 pid=319504)                                         // -- End function
(EngineCore_DP0 pid=319504) }
(EngineCore_DP0 pid=319504) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=319504) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=319504) 	.section	.debug_abbrev
(EngineCore_DP0 pid=319504) 	{
(EngineCore_DP0 pid=319504) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=319504) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=319504) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=319504) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=319504) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=319504) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=319504) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=319504) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=319504) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=319504) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=319504) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=319504) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=319504) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=319504) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=319504) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=319504) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=319504) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=319504) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=319504) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=319504) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=319504) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=319504) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=319504) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=319504) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=319504) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=319504) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=319504) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=319504) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=319504) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=319504) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=319504) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=319504) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=319504) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=319504) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=319504) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=319504) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=319504) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=319504) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=319504) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=319504) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=319504) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=319504) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=319504) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=319504) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=319504) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=319504) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=319504) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=319504) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=319504) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=319504) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=319504) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=319504) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=319504) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=319504) 	}
(EngineCore_DP0 pid=319504) 	.section	.debug_info
(EngineCore_DP0 pid=319504) 	{
(EngineCore_DP0 pid=319504) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=319504) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=319504) .b8 0
(EngineCore_DP0 pid=319504) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=319504) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=319504) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=319504) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=319504) .b8 114
(EngineCore_DP0 pid=319504) .b8 105
(EngineCore_DP0 pid=319504) .b8 116
(EngineCore_DP0 pid=319504) .b8 111
(EngineCore_DP0 pid=319504) .b8 110
(EngineCore_DP0 pid=319504) .b8 0
(EngineCore_DP0 pid=319504) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=319504) .b8 0
(EngineCore_DP0 pid=319504) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=319504) .b8 117
(EngineCore_DP0 pid=319504) .b8 97
(EngineCore_DP0 pid=319504) .b8 110
(EngineCore_DP0 pid=319504) .b8 116
(EngineCore_DP0 pid=319504) .b8 95
(EngineCore_DP0 pid=319504) .b8 115
(EngineCore_DP0 pid=319504) .b8 108
(EngineCore_DP0 pid=319504) .b8 105
(EngineCore_DP0 pid=319504) .b8 100
(EngineCore_DP0 pid=319504) .b8 101
(EngineCore_DP0 pid=319504) .b8 95
(EngineCore_DP0 pid=319504) .b8 116
(EngineCore_DP0 pid=319504) .b8 117
(EngineCore_DP0 pid=319504) .b8 110
(EngineCore_DP0 pid=319504) .b8 101
(EngineCore_DP0 pid=319504) .b8 100
(EngineCore_DP0 pid=319504) .b8 95
(EngineCore_DP0 pid=319504) .b8 76
(EngineCore_DP0 pid=319504) .b8 108
(EngineCore_DP0 pid=319504) .b8 97
(EngineCore_DP0 pid=319504) .b8 109
(EngineCore_DP0 pid=319504) .b8 97
(EngineCore_DP0 pid=319504) .b8 51
(EngineCore_DP0 pid=319504) .b8 46
(EngineCore_DP0 pid=319504) .b8 50
(EngineCore_DP0 pid=319504) .b8 45
(EngineCore_DP0 pid=319504) .b8 49
(EngineCore_DP0 pid=319504) .b8 66
(EngineCore_DP0 pid=319504) .b8 46
(EngineCore_DP0 pid=319504) .b8 112
(EngineCore_DP0 pid=319504) .b8 121
(EngineCore_DP0 pid=319504) .b8 0
(EngineCore_DP0 pid=319504) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=319504) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=319504) .b8 114
(EngineCore_DP0 pid=319504) .b8 111
(EngineCore_DP0 pid=319504) .b8 111
(EngineCore_DP0 pid=319504) .b8 116
(EngineCore_DP0 pid=319504) .b8 47
(EngineCore_DP0 pid=319504) .b8 118
(EngineCore_DP0 pid=319504) .b8 108
(EngineCore_DP0 pid=319504) .b8 108
(EngineCore_DP0 pid=319504) .b8 109
(EngineCore_DP0 pid=319504) .b8 98
(EngineCore_DP0 pid=319504) .b8 101
(EngineCore_DP0 pid=319504) .b8 110
(EngineCore_DP0 pid=319504) .b8 99
(EngineCore_DP0 pid=319504) .b8 104
(EngineCore_DP0 pid=319504) .b8 47
(EngineCore_DP0 pid=319504) .b8 115
(EngineCore_DP0 pid=319504) .b8 108
(EngineCore_DP0 pid=319504) .b8 105
(EngineCore_DP0 pid=319504) .b8 100
(EngineCore_DP0 pid=319504) .b8 101
(EngineCore_DP0 pid=319504) .b8 115
(EngineCore_DP0 pid=319504) .b8 112
(EngineCore_DP0 pid=319504) .b8 97
(EngineCore_DP0 pid=319504) .b8 114
(EngineCore_DP0 pid=319504) .b8 115
(EngineCore_DP0 pid=319504) .b8 101
(EngineCore_DP0 pid=319504) .b8 47
(EngineCore_DP0 pid=319504) .b8 99
(EngineCore_DP0 pid=319504) .b8 115
(EngineCore_DP0 pid=319504) .b8 114
(EngineCore_DP0 pid=319504) .b8 99
(EngineCore_DP0 pid=319504) .b8 47
(EngineCore_DP0 pid=319504) .b8 102
(EngineCore_DP0 pid=319504) .b8 117
(EngineCore_DP0 pid=319504) .b8 115
(EngineCore_DP0 pid=319504) .b8 101
(EngineCore_DP0 pid=319504) .b8 100
(EngineCore_DP0 pid=319504) .b8 95
(EngineCore_DP0 pid=319504) .b8 113
(EngineCore_DP0 pid=319504) .b8 117
(EngineCore_DP0 pid=319504) .b8 97
(EngineCore_DP0 pid=319504) .b8 110
(EngineCore_DP0 pid=319504) .b8 116
(EngineCore_DP0 pid=319504) .b8 95
(EngineCore_DP0 pid=319504) .b8 115
(EngineCore_DP0 pid=319504) .b8 108
(EngineCore_DP0 pid=319504) .b8 105
(EngineCore_DP0 pid=319504) .b8 100
(EngineCore_DP0 pid=319504) .b8 101
(EngineCore_DP0 pid=319504) .b8 95
(EngineCore_DP0 pid=319504) .b8 116
(EngineCore_DP0 pid=319504) .b8 114
(EngineCore_DP0 pid=319504) .b8 105
(EngineCore_DP0 pid=319504) .b8 116
(EngineCore_DP0 pid=319504) .b8 111
(EngineCore_DP0 pid=319504) .b8 110
(EngineCore_DP0 pid=319504) .b8 47
(EngineCore_DP0 pid=319504) .b8 98
(EngineCore_DP0 pid=319504) .b8 117
(EngineCore_DP0 pid=319504) .b8 105
(EngineCore_DP0 pid=319504) .b8 108
(EngineCore_DP0 pid=319504) .b8 100
(EngineCore_DP0 pid=319504) .b8 47
(EngineCore_DP0 pid=319504) .b8 71
(EngineCore_DP0 pid=319504) .b8 66
(EngineCore_DP0 pid=319504) .b8 49
(EngineCore_DP0 pid=319504) .b8 48
(EngineCore_DP0 pid=319504) .b8 95
(EngineCore_DP0 pid=319504) .b8 99
(EngineCore_DP0 pid=319504) .b8 99
(EngineCore_DP0 pid=319504) .b8 49
(EngineCore_DP0 pid=319504) .b8 50
(EngineCore_DP0 pid=319504) .b8 49
(EngineCore_DP0 pid=319504) .b8 95
(EngineCore_DP0 pid=319504) .b8 112
(EngineCore_DP0 pid=319504) .b8 121
(EngineCore_DP0 pid=319504) .b8 51
(EngineCore_DP0 pid=319504) .b8 49
(EngineCore_DP0 pid=319504) .b8 50
(EngineCore_DP0 pid=319504) .b8 95
(EngineCore_DP0 pid=319504) .b8 99
(EngineCore_DP0 pid=319504) .b8 117
(EngineCore_DP0 pid=319504) .b8 49
(EngineCore_DP0 pid=319504) .b8 50
(EngineCore_DP0 pid=319504) .b8 57
(EngineCore_DP0 pid=319504) .b8 95
(EngineCore_DP0 pid=319504) .b8 97
(EngineCore_DP0 pid=319504) .b8 97
(EngineCore_DP0 pid=319504) .b8 114
(EngineCore_DP0 pid=319504) .b8 99
(EngineCore_DP0 pid=319504) .b8 104
(EngineCore_DP0 pid=319504) .b8 54
(EngineCore_DP0 pid=319504) .b8 52
(EngineCore_DP0 pid=319504) .b8 0
(EngineCore_DP0 pid=319504) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=319504) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=319504) .b8 113
(EngineCore_DP0 pid=319504) .b8 117
(EngineCore_DP0 pid=319504) .b8 97
(EngineCore_DP0 pid=319504) .b8 110
(EngineCore_DP0 pid=319504) .b8 116
(EngineCore_DP0 pid=319504) .b8 95
(EngineCore_DP0 pid=319504) .b8 115
(EngineCore_DP0 pid=319504) .b8 108
(EngineCore_DP0 pid=319504) .b8 105
(EngineCore_DP0 pid=319504) .b8 100
(EngineCore_DP0 pid=319504) .b8 101
(EngineCore_DP0 pid=319504) .b8 95
(EngineCore_DP0 pid=319504) .b8 105
(EngineCore_DP0 pid=319504) .b8 110
(EngineCore_DP0 pid=319504) .b8 116
(EngineCore_DP0 pid=319504) .b8 56
(EngineCore_DP0 pid=319504) .b8 95
(EngineCore_DP0 pid=319504) .b8 107
(EngineCore_DP0 pid=319504) .b8 101
(EngineCore_DP0 pid=319504) .b8 114
(EngineCore_DP0 pid=319504) .b8 110
(EngineCore_DP0 pid=319504) .b8 101
(EngineCore_DP0 pid=319504) .b8 108
(EngineCore_DP0 pid=319504) .b8 0
(EngineCore_DP0 pid=319504) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=319504) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=319504) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=319504) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=319504) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=319504) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=319504) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=319504) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=319504) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=319504) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=319504) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=319504) .b8 1
(EngineCore_DP0 pid=319504) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=319504) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=319504) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=319504) 	}
(EngineCore_DP0 pid=319504) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=319504) 
(EngineCore_DP0 pid=319504) ================================================================
(EngineCore_DP0 pid=319504) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=319504) 
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpm05ds4b8.ptx', '-o', '/tmp/tmpm05ds4b8.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866] 
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866] 
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866] 
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpm05ds4b8.ptx -o /tmp/tmpm05ds4b8.ptx.o
(EngineCore_DP0 pid=319504) ERROR 01-25 19:02:42 [core.py:866] 

STDERR:
[2026-01-25 19:02:25] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:02:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:02:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:02:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:02:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:02:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:02:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:02:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:02:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:02:28] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:02:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:02:28] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:02:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:02:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:02:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:02:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:02:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:02:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=319504) [2026-01-25 19:02:29] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=319504) [2026-01-25 19:02:29] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=319504) [2026-01-25 19:02:29] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=319504) [2026-01-25 19:02:29] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=319504) [2026-01-25 19:02:29] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=319504) [2026-01-25 19:02:29] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=319504) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=319504) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.95s/it]
(EngineCore_DP0 pid=319504) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.95s/it]
(EngineCore_DP0 pid=319504) 
(EngineCore_DP0 pid=319504) [2026-01-25 19:02:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=319504) [2026-01-25 19:02:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=319504) [2026-01-25 19:02:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=319504) [2026-01-25 19:02:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=319504) [2026-01-25 19:02:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=319504) [2026-01-25 19:02:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=319504) [2026-01-25 19:02:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=319504) [2026-01-25 19:02:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=319504) Process EngineCore_DP0:
(EngineCore_DP0 pid=319504) Traceback (most recent call last):
(EngineCore_DP0 pid=319504)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=319504)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=319504)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=319504)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=319504) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpm05ds4b8.ptx', '-o', '/tmp/tmpm05ds4b8.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=319504) 
(EngineCore_DP0 pid=319504) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=319504) 
(EngineCore_DP0 pid=319504) Traceback (most recent call last):
(EngineCore_DP0 pid=319504)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=319504)     self.run()
(EngineCore_DP0 pid=319504)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=319504)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=319504)     raise e
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=319504)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=319504)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=319504)     super().__init__(
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=319504)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=319504)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=319504)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=319504)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=319504)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=319504)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=319504)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=319504)     return func(*args, **kwargs)
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=319504)     return func(*args, **kwargs)
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=319504)     self.model_runner.profile_run()
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=319504)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=319504)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=319504)     return func(*args, **kwargs)
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=319504)     outputs = self.model(
(EngineCore_DP0 pid=319504)               ^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=319504)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=319504)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=319504)     model_output = self.model(
(EngineCore_DP0 pid=319504)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=319504)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=319504)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=319504)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=319504)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=319504)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=319504)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=319504)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=319504)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=319504)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=319504)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=319504)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=319504)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=319504)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=319504)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=319504)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=319504)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=319504)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=319504)     return self._linear_fn(
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=319504)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=319504)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=319504)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=319504)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=319504)     return fn(input, L)
(EngineCore_DP0 pid=319504)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=319504)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=319504)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=319504)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=319504)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=319504)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=319504)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=319504)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=319504)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=319504)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=319504)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=319504)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=319504)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319504)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=319504)     raise PTXASError(error)
(EngineCore_DP0 pid=319504) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=319504) `ptxas` stderr:
(EngineCore_DP0 pid=319504) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=319504) 
(EngineCore_DP0 pid=319504) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpm05ds4b8.ptx -o /tmp/tmpm05ds4b8.ptx.o
(EngineCore_DP0 pid=319504) 
[rank0]:[W125 19:02:42.658342679 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 19:02:44
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:02:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:02:47 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=320014) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=320014) 
(EngineCore_DP0 pid=320014) 
(EngineCore_DP0 pid=320014) ================================================================
(EngineCore_DP0 pid=320014) Internal Triton PTX codegen error
(EngineCore_DP0 pid=320014) `ptxas` stderr:
(EngineCore_DP0 pid=320014) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=320014) 
(EngineCore_DP0 pid=320014) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpcr1tm3ro.ptx -o /tmp/tmpcr1tm3ro.ptx.o
(EngineCore_DP0 pid=320014) 
(EngineCore_DP0 pid=320014) 
(EngineCore_DP0 pid=320014) //
(EngineCore_DP0 pid=320014) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=320014) //
(EngineCore_DP0 pid=320014) 
(EngineCore_DP0 pid=320014) .version 8.7
(EngineCore_DP0 pid=320014) .target sm_121a
(EngineCore_DP0 pid=320014) .address_size 64
(EngineCore_DP0 pid=320014) 
(EngineCore_DP0 pid=320014) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=320014) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=320014)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=320014) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=320014) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=320014) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=320014) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=320014) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=320014) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=320014) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=320014) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=320014) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=320014) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=320014) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=320014) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=320014) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=320014) )
(EngineCore_DP0 pid=320014) .reqntid 512
(EngineCore_DP0 pid=320014) {
(EngineCore_DP0 pid=320014) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=320014) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=320014) 	.reg .b32 	%r<132>;
(EngineCore_DP0 pid=320014) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=320014) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=320014) $L__func_begin0:
(EngineCore_DP0 pid=320014) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=320014) 
(EngineCore_DP0 pid=320014) // %bb.0:
(EngineCore_DP0 pid=320014) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=320014) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=320014) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=320014) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=320014) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=320014) $L__tmp0:
(EngineCore_DP0 pid=320014) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=320014) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=320014) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=320014) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=320014) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=320014) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=320014) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=320014) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=320014) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=320014) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=320014) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=320014) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=320014) 	mov.b32 	%r130, 0f2B8CBCCC;
(EngineCore_DP0 pid=320014) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=320014) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=320014) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=320014) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=320014) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=320014) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=320014) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=320014) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=320014) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=320014) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=320014) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=320014) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=320014) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=320014) 	mov.b32 	%r128, 0f00000000;
(EngineCore_DP0 pid=320014) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=320014) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=320014) 	mov.b32 	%r129, %r40;
(EngineCore_DP0 pid=320014) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=320014) 	.loc	1 299 19                        // quant_slide_tuned_Llama3.2-1B.py:299:19
(EngineCore_DP0 pid=320014) 	add.s32 	%r58, %r4, %r129;
(EngineCore_DP0 pid=320014) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=320014) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=320014) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=320014) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=320014) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=320014) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=320014) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=320014) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=320014) 	// begin inline asm
(EngineCore_DP0 pid=320014) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=320014) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=320014) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=320014) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=320014) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=320014) 	// end inline asm
(EngineCore_DP0 pid=320014) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=320014) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=320014) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=320014) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=320014) 	// begin inline asm
(EngineCore_DP0 pid=320014) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=320014) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=320014) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=320014) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=320014) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=320014) 	// end inline asm
(EngineCore_DP0 pid=320014) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=320014) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=320014) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=320014) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=320014) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=320014) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=320014) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=320014) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=320014) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=320014) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=320014) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=320014) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=320014) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=320014) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=320014) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=320014) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=320014) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=320014) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=320014) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=320014) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=320014) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=320014) $L__tmp1:
(EngineCore_DP0 pid=320014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	bar.sync 	0;
(EngineCore_DP0 pid=320014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=320014) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=320014) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=320014) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=320014) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=320014) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=320014) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=320014) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=320014) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=320014) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=320014) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=320014) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=320014) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=320014) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=320014) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=320014) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=320014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=320014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=320014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=320014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=320014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=320014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=320014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=320014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=320014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=320014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=320014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	// begin inline asm
(EngineCore_DP0 pid=320014) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=320014) 	// end inline asm
(EngineCore_DP0 pid=320014) 	bar.sync 	0;
(EngineCore_DP0 pid=320014) 	// begin inline asm
(EngineCore_DP0 pid=320014) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=320014) 	// end inline asm
(EngineCore_DP0 pid=320014) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=320014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=320014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=320014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=320014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=320014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=320014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=320014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=320014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320014) 	// begin inline asm
(EngineCore_DP0 pid=320014) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=320014) 	// end inline asm
(EngineCore_DP0 pid=320014) 	bar.sync 	0;
(EngineCore_DP0 pid=320014) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=320014) $L__tmp2:
(EngineCore_DP0 pid=320014) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=320014) 	max.f32 	%r128, %r128, %r77;
(EngineCore_DP0 pid=320014) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=320014) 	add.s32 	%r129, %r129, 8192;
(EngineCore_DP0 pid=320014) 	setp.lt.s32 	%p7, %r129, %r19;
(EngineCore_DP0 pid=320014) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=320014) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=320014) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=320014) 	max.f32 	%r130, %r128, 0f2B8CBCCC;
(EngineCore_DP0 pid=320014) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=320014) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=320014) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=320014) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=320014) 	div.full.f32 	%r80, %r130, %r79;
(EngineCore_DP0 pid=320014) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=320014) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=320014) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=320014) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=320014) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=320014) 	// begin inline asm
(EngineCore_DP0 pid=320014) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=320014) 	// end inline asm
(EngineCore_DP0 pid=320014) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=320014) 	mul.lo.s32 	%r15, %r20, 3;
(EngineCore_DP0 pid=320014) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=320014) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=320014) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=320014) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=320014) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=320014) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=320014) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=320014) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=320014) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=320014) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=320014) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=320014) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=320014) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=320014) 	div.full.f32 	%r14, %r79, %r130;
(EngineCore_DP0 pid=320014) 	mov.b32 	%r131, 0;
(EngineCore_DP0 pid=320014) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=320014)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=320014) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=320014) 	add.s32 	%r84, %r3, %r131;
(EngineCore_DP0 pid=320014) 	setp.lt.s32 	%p14, %r84, %r15;
(EngineCore_DP0 pid=320014) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=320014) 	mul.hi.s32 	%r85, %r84, 1431655766;
(EngineCore_DP0 pid=320014) 	shr.u32 	%r86, %r85, 31;
(EngineCore_DP0 pid=320014) 	add.s32 	%r87, %r85, %r86;
(EngineCore_DP0 pid=320014) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=320014) 	mul.lo.s32 	%r88, %r87, 3;
(EngineCore_DP0 pid=320014) 	sub.s32 	%r89, %r84, %r88;
(EngineCore_DP0 pid=320014) 	.loc	1 319 22                        // quant_slide_tuned_Llama3.2-1B.py:319:22
(EngineCore_DP0 pid=320014) 	shl.b32 	%r90, %r87, 3;
(EngineCore_DP0 pid=320014) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=320014) 	shl.b32 	%r91, %r89, 1;
(EngineCore_DP0 pid=320014) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=320014) 	add.s32 	%r92, %r90, %r91;
(EngineCore_DP0 pid=320014) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=320014) 	setp.lt.s32 	%p15, %r92, %r18;
(EngineCore_DP0 pid=320014) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=320014) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=320014) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=320014) 	mad.wide.s32 	%rd9, %r92, 2, %rd1;
(EngineCore_DP0 pid=320014) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=320014) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=320014) 	// begin inline asm
(EngineCore_DP0 pid=320014) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=320014) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=320014) 	// end inline asm
(EngineCore_DP0 pid=320014) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=320014) 	cvt.f32.bf16 	%r93, %rs48;
(EngineCore_DP0 pid=320014) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=320014) 	or.b32 	%r94, %r92, 1;
(EngineCore_DP0 pid=320014) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=320014) 	setp.lt.s32 	%p16, %r94, %r18;
(EngineCore_DP0 pid=320014) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=320014) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=320014) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=320014) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=320014) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=320014) 	// begin inline asm
(EngineCore_DP0 pid=320014) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=320014) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=320014) 	// end inline asm
(EngineCore_DP0 pid=320014) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=320014) 	cvt.f32.bf16 	%r95, %rs50;
(EngineCore_DP0 pid=320014) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=320014) 	add.s32 	%r96, %r92, 2;
(EngineCore_DP0 pid=320014) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=320014) 	setp.lt.s32 	%p17, %r96, %r18;
(EngineCore_DP0 pid=320014) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=320014) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=320014) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=320014) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=320014) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=320014) 	// begin inline asm
(EngineCore_DP0 pid=320014) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=320014) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=320014) 	// end inline asm
(EngineCore_DP0 pid=320014) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=320014) 	cvt.f32.bf16 	%r97, %rs52;
(EngineCore_DP0 pid=320014) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=320014) 	add.s32 	%r98, %r92, 3;
(EngineCore_DP0 pid=320014) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=320014) 	setp.lt.s32 	%p18, %r98, %r18;
(EngineCore_DP0 pid=320014) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=320014) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=320014) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=320014) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=320014) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=320014) 	// begin inline asm
(EngineCore_DP0 pid=320014) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=320014) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=320014) 	// end inline asm
(EngineCore_DP0 pid=320014) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=320014) 	cvt.f32.bf16 	%r99, %rs54;
(EngineCore_DP0 pid=320014) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=320014) 	mul.f32 	%r100, %r14, %r93;
(EngineCore_DP0 pid=320014) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=320014) 	cvt.rni.f32.f32 	%r101, %r100;
(EngineCore_DP0 pid=320014) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=320014) 	max.f32 	%r102, %r101, 0fC3000000;
(EngineCore_DP0 pid=320014) 	min.f32 	%r103, %r102, 0f42FE0000;
(EngineCore_DP0 pid=320014) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=320014) 	cvt.rzi.s32.f32 	%r104, %r103;
(EngineCore_DP0 pid=320014) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=320014) 	and.b32 	%r105, %r104, 255;
(EngineCore_DP0 pid=320014) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=320014) 	mul.f32 	%r106, %r14, %r95;
(EngineCore_DP0 pid=320014) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=320014) 	cvt.rni.f32.f32 	%r107, %r106;
(EngineCore_DP0 pid=320014) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=320014) 	mul.f32 	%r108, %r14, %r97;
(EngineCore_DP0 pid=320014) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=320014) 	cvt.rni.f32.f32 	%r109, %r108;
(EngineCore_DP0 pid=320014) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=320014) 	mul.f32 	%r110, %r14, %r99;
(EngineCore_DP0 pid=320014) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=320014) 	cvt.rni.f32.f32 	%r111, %r110;
(EngineCore_DP0 pid=320014) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=320014) 	max.f32 	%r112, %r111, 0fC3000000;
(EngineCore_DP0 pid=320014) 	min.f32 	%r113, %r112, 0f42FE0000;
(EngineCore_DP0 pid=320014) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=320014) 	cvt.rzi.s32.f32 	%r114, %r113;
(EngineCore_DP0 pid=320014) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=320014) 	max.f32 	%r115, %r109, 0fC3000000;
(EngineCore_DP0 pid=320014) 	max.f32 	%r116, %r107, 0fC3000000;
(EngineCore_DP0 pid=320014) 	min.f32 	%r117, %r116, 0f42FE0000;
(EngineCore_DP0 pid=320014) 	min.f32 	%r118, %r115, 0f42FE0000;
(EngineCore_DP0 pid=320014) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=320014) 	cvt.rzi.s32.f32 	%r119, %r118;
(EngineCore_DP0 pid=320014) 	cvt.rzi.s32.f32 	%r120, %r117;
(EngineCore_DP0 pid=320014) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=320014) 	shl.b32 	%r121, %r120, 8;
(EngineCore_DP0 pid=320014) 	shl.b32 	%r122, %r119, 16;
(EngineCore_DP0 pid=320014) 	and.b32 	%r123, %r122, 16711680;
(EngineCore_DP0 pid=320014) 	and.b32 	%r124, %r121, 65280;
(EngineCore_DP0 pid=320014) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=320014) 	or.b32 	%r125, %r124, %r105;
(EngineCore_DP0 pid=320014) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=320014) 	or.b32 	%r126, %r125, %r123;
(EngineCore_DP0 pid=320014) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=320014) 	shl.b32 	%r127, %r114, 24;
(EngineCore_DP0 pid=320014) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=320014) 	or.b32 	%r82, %r126, %r127;
(EngineCore_DP0 pid=320014) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=320014) 	mad.wide.s32 	%rd13, %r84, 4, %rd2;
(EngineCore_DP0 pid=320014) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=320014) 	// begin inline asm
(EngineCore_DP0 pid=320014) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r82 };
(EngineCore_DP0 pid=320014) 	// end inline asm
(EngineCore_DP0 pid=320014) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=320014) 	add.s32 	%r131, %r131, 512;
(EngineCore_DP0 pid=320014) 	setp.lt.s32 	%p19, %r131, %r15;
(EngineCore_DP0 pid=320014) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=320014) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=320014) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=320014) 	ret;
(EngineCore_DP0 pid=320014) $L__tmp3:
(EngineCore_DP0 pid=320014) $L__func_end0:
(EngineCore_DP0 pid=320014)                                         // -- End function
(EngineCore_DP0 pid=320014) }
(EngineCore_DP0 pid=320014) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=320014) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=320014) 	.section	.debug_abbrev
(EngineCore_DP0 pid=320014) 	{
(EngineCore_DP0 pid=320014) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=320014) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=320014) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=320014) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=320014) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=320014) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=320014) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=320014) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=320014) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=320014) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=320014) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=320014) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=320014) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=320014) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=320014) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=320014) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=320014) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=320014) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=320014) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=320014) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=320014) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=320014) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=320014) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=320014) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=320014) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=320014) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=320014) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=320014) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=320014) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=320014) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=320014) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=320014) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=320014) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=320014) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=320014) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=320014) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=320014) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=320014) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=320014) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=320014) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=320014) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=320014) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=320014) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=320014) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=320014) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=320014) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=320014) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=320014) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=320014) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=320014) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=320014) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=320014) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=320014) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=320014) 	}
(EngineCore_DP0 pid=320014) 	.section	.debug_info
(EngineCore_DP0 pid=320014) 	{
(EngineCore_DP0 pid=320014) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=320014) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=320014) .b8 0
(EngineCore_DP0 pid=320014) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=320014) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=320014) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=320014) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=320014) .b8 114
(EngineCore_DP0 pid=320014) .b8 105
(EngineCore_DP0 pid=320014) .b8 116
(EngineCore_DP0 pid=320014) .b8 111
(EngineCore_DP0 pid=320014) .b8 110
(EngineCore_DP0 pid=320014) .b8 0
(EngineCore_DP0 pid=320014) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=320014) .b8 0
(EngineCore_DP0 pid=320014) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=320014) .b8 117
(EngineCore_DP0 pid=320014) .b8 97
(EngineCore_DP0 pid=320014) .b8 110
(EngineCore_DP0 pid=320014) .b8 116
(EngineCore_DP0 pid=320014) .b8 95
(EngineCore_DP0 pid=320014) .b8 115
(EngineCore_DP0 pid=320014) .b8 108
(EngineCore_DP0 pid=320014) .b8 105
(EngineCore_DP0 pid=320014) .b8 100
(EngineCore_DP0 pid=320014) .b8 101
(EngineCore_DP0 pid=320014) .b8 95
(EngineCore_DP0 pid=320014) .b8 116
(EngineCore_DP0 pid=320014) .b8 117
(EngineCore_DP0 pid=320014) .b8 110
(EngineCore_DP0 pid=320014) .b8 101
(EngineCore_DP0 pid=320014) .b8 100
(EngineCore_DP0 pid=320014) .b8 95
(EngineCore_DP0 pid=320014) .b8 76
(EngineCore_DP0 pid=320014) .b8 108
(EngineCore_DP0 pid=320014) .b8 97
(EngineCore_DP0 pid=320014) .b8 109
(EngineCore_DP0 pid=320014) .b8 97
(EngineCore_DP0 pid=320014) .b8 51
(EngineCore_DP0 pid=320014) .b8 46
(EngineCore_DP0 pid=320014) .b8 50
(EngineCore_DP0 pid=320014) .b8 45
(EngineCore_DP0 pid=320014) .b8 49
(EngineCore_DP0 pid=320014) .b8 66
(EngineCore_DP0 pid=320014) .b8 46
(EngineCore_DP0 pid=320014) .b8 112
(EngineCore_DP0 pid=320014) .b8 121
(EngineCore_DP0 pid=320014) .b8 0
(EngineCore_DP0 pid=320014) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=320014) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=320014) .b8 114
(EngineCore_DP0 pid=320014) .b8 111
(EngineCore_DP0 pid=320014) .b8 111
(EngineCore_DP0 pid=320014) .b8 116
(EngineCore_DP0 pid=320014) .b8 47
(EngineCore_DP0 pid=320014) .b8 118
(EngineCore_DP0 pid=320014) .b8 108
(EngineCore_DP0 pid=320014) .b8 108
(EngineCore_DP0 pid=320014) .b8 109
(EngineCore_DP0 pid=320014) .b8 98
(EngineCore_DP0 pid=320014) .b8 101
(EngineCore_DP0 pid=320014) .b8 110
(EngineCore_DP0 pid=320014) .b8 99
(EngineCore_DP0 pid=320014) .b8 104
(EngineCore_DP0 pid=320014) .b8 47
(EngineCore_DP0 pid=320014) .b8 115
(EngineCore_DP0 pid=320014) .b8 108
(EngineCore_DP0 pid=320014) .b8 105
(EngineCore_DP0 pid=320014) .b8 100
(EngineCore_DP0 pid=320014) .b8 101
(EngineCore_DP0 pid=320014) .b8 115
(EngineCore_DP0 pid=320014) .b8 112
(EngineCore_DP0 pid=320014) .b8 97
(EngineCore_DP0 pid=320014) .b8 114
(EngineCore_DP0 pid=320014) .b8 115
(EngineCore_DP0 pid=320014) .b8 101
(EngineCore_DP0 pid=320014) .b8 47
(EngineCore_DP0 pid=320014) .b8 99
(EngineCore_DP0 pid=320014) .b8 115
(EngineCore_DP0 pid=320014) .b8 114
(EngineCore_DP0 pid=320014) .b8 99
(EngineCore_DP0 pid=320014) .b8 47
(EngineCore_DP0 pid=320014) .b8 102
(EngineCore_DP0 pid=320014) .b8 117
(EngineCore_DP0 pid=320014) .b8 115
(EngineCore_DP0 pid=320014) .b8 101
(EngineCore_DP0 pid=320014) .b8 100
(EngineCore_DP0 pid=320014) .b8 95
(EngineCore_DP0 pid=320014) .b8 113
(EngineCore_DP0 pid=320014) .b8 117
(EngineCore_DP0 pid=320014) .b8 97
(EngineCore_DP0 pid=320014) .b8 110
(EngineCore_DP0 pid=320014) .b8 116
(EngineCore_DP0 pid=320014) .b8 95
(EngineCore_DP0 pid=320014) .b8 115
(EngineCore_DP0 pid=320014) .b8 108
(EngineCore_DP0 pid=320014) .b8 105
(EngineCore_DP0 pid=320014) .b8 100
(EngineCore_DP0 pid=320014) .b8 101
(EngineCore_DP0 pid=320014) .b8 95
(EngineCore_DP0 pid=320014) .b8 116
(EngineCore_DP0 pid=320014) .b8 114
(EngineCore_DP0 pid=320014) .b8 105
(EngineCore_DP0 pid=320014) .b8 116
(EngineCore_DP0 pid=320014) .b8 111
(EngineCore_DP0 pid=320014) .b8 110
(EngineCore_DP0 pid=320014) .b8 47
(EngineCore_DP0 pid=320014) .b8 98
(EngineCore_DP0 pid=320014) .b8 117
(EngineCore_DP0 pid=320014) .b8 105
(EngineCore_DP0 pid=320014) .b8 108
(EngineCore_DP0 pid=320014) .b8 100
(EngineCore_DP0 pid=320014) .b8 47
(EngineCore_DP0 pid=320014) .b8 71
(EngineCore_DP0 pid=320014) .b8 66
(EngineCore_DP0 pid=320014) .b8 49
(EngineCore_DP0 pid=320014) .b8 48
(EngineCore_DP0 pid=320014) .b8 95
(EngineCore_DP0 pid=320014) .b8 99
(EngineCore_DP0 pid=320014) .b8 99
(EngineCore_DP0 pid=320014) .b8 49
(EngineCore_DP0 pid=320014) .b8 50
(EngineCore_DP0 pid=320014) .b8 49
(EngineCore_DP0 pid=320014) .b8 95
(EngineCore_DP0 pid=320014) .b8 112
(EngineCore_DP0 pid=320014) .b8 121
(EngineCore_DP0 pid=320014) .b8 51
(EngineCore_DP0 pid=320014) .b8 49
(EngineCore_DP0 pid=320014) .b8 50
(EngineCore_DP0 pid=320014) .b8 95
(EngineCore_DP0 pid=320014) .b8 99
(EngineCore_DP0 pid=320014) .b8 117
(EngineCore_DP0 pid=320014) .b8 49
(EngineCore_DP0 pid=320014) .b8 50
(EngineCore_DP0 pid=320014) .b8 57
(EngineCore_DP0 pid=320014) .b8 95
(EngineCore_DP0 pid=320014) .b8 97
(EngineCore_DP0 pid=320014) .b8 97
(EngineCore_DP0 pid=320014) .b8 114
(EngineCore_DP0 pid=320014) .b8 99
(EngineCore_DP0 pid=320014) .b8 104
(EngineCore_DP0 pid=320014) .b8 54
(EngineCore_DP0 pid=320014) .b8 52
(EngineCore_DP0 pid=320014) .b8 0
(EngineCore_DP0 pid=320014) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=320014) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=320014) .b8 113
(EngineCore_DP0 pid=320014) .b8 117
(EngineCore_DP0 pid=320014) .b8 97
(EngineCore_DP0 pid=320014) .b8 110
(EngineCore_DP0 pid=320014) .b8 116
(EngineCore_DP0 pid=320014) .b8 95
(EngineCore_DP0 pid=320014) .b8 115
(EngineCore_DP0 pid=320014) .b8 108
(EngineCore_DP0 pid=320014) .b8 105
(EngineCore_DP0 pid=320014) .b8 100
(EngineCore_DP0 pid=320014) .b8 101
(EngineCore_DP0 pid=320014) .b8 95
(EngineCore_DP0 pid=320014) .b8 105
(EngineCore_DP0 pid=320014) .b8 110
(EngineCore_DP0 pid=320014) .b8 116
(EngineCore_DP0 pid=320014) .b8 56
(EngineCore_DP0 pid=320014) .b8 95
(EngineCore_DP0 pid=320014) .b8 107
(EngineCore_DP0 pid=320014) .b8 101
(EngineCore_DP0 pid=320014) .b8 114
(EngineCore_DP0 pid=320014) .b8 110
(EngineCore_DP0 pid=320014) .b8 101
(EngineCore_DP0 pid=320014) .b8 108
(EngineCore_DP0 pid=320014) .b8 0
(EngineCore_DP0 pid=320014) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=320014) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=320014) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=320014) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=320014) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=320014) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=320014) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=320014) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=320014) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=320014) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=320014) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=320014) .b8 1
(EngineCore_DP0 pid=320014) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=320014) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=320014) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=320014) 	}
(EngineCore_DP0 pid=320014) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=320014) 
(EngineCore_DP0 pid=320014) ================================================================
(EngineCore_DP0 pid=320014) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=320014) 
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpcr1tm3ro.ptx', '-o', '/tmp/tmpcr1tm3ro.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866] 
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866] 
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866] 
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpcr1tm3ro.ptx -o /tmp/tmpcr1tm3ro.ptx.o
(EngineCore_DP0 pid=320014) ERROR 01-25 19:03:04 [core.py:866] 

STDERR:
[2026-01-25 19:02:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:02:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:02:47] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:02:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:02:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:02:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:02:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:02:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:02:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:02:51] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:02:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:02:51] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:02:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:02:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:02:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:02:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:02:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:02:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=320014) [2026-01-25 19:02:52] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=320014) [2026-01-25 19:02:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=320014) [2026-01-25 19:02:52] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=320014) [2026-01-25 19:02:52] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=320014) [2026-01-25 19:02:52] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=320014) [2026-01-25 19:02:52] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=320014) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=320014) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.83s/it]
(EngineCore_DP0 pid=320014) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.83s/it]
(EngineCore_DP0 pid=320014) 
(EngineCore_DP0 pid=320014) [2026-01-25 19:03:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=320014) [2026-01-25 19:03:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=320014) [2026-01-25 19:03:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=320014) [2026-01-25 19:03:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=320014) [2026-01-25 19:03:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=320014) [2026-01-25 19:03:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=320014) [2026-01-25 19:03:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=320014) [2026-01-25 19:03:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=320014) Process EngineCore_DP0:
(EngineCore_DP0 pid=320014) Traceback (most recent call last):
(EngineCore_DP0 pid=320014)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=320014)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=320014)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=320014)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=320014) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpcr1tm3ro.ptx', '-o', '/tmp/tmpcr1tm3ro.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=320014) 
(EngineCore_DP0 pid=320014) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=320014) 
(EngineCore_DP0 pid=320014) Traceback (most recent call last):
(EngineCore_DP0 pid=320014)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=320014)     self.run()
(EngineCore_DP0 pid=320014)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=320014)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=320014)     raise e
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=320014)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=320014)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=320014)     super().__init__(
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=320014)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=320014)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=320014)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=320014)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=320014)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=320014)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=320014)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=320014)     return func(*args, **kwargs)
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=320014)     return func(*args, **kwargs)
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=320014)     self.model_runner.profile_run()
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=320014)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=320014)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=320014)     return func(*args, **kwargs)
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=320014)     outputs = self.model(
(EngineCore_DP0 pid=320014)               ^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=320014)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=320014)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=320014)     model_output = self.model(
(EngineCore_DP0 pid=320014)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=320014)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=320014)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=320014)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=320014)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=320014)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=320014)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=320014)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=320014)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=320014)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=320014)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=320014)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=320014)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=320014)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=320014)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=320014)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=320014)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=320014)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=320014)     return self._linear_fn(
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=320014)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=320014)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=320014)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=320014)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=320014)     return fn(input, L)
(EngineCore_DP0 pid=320014)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=320014)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=320014)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=320014)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=320014)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=320014)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=320014)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=320014)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=320014)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=320014)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=320014)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=320014)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=320014)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320014)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=320014)     raise PTXASError(error)
(EngineCore_DP0 pid=320014) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=320014) `ptxas` stderr:
(EngineCore_DP0 pid=320014) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=320014) 
(EngineCore_DP0 pid=320014) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpcr1tm3ro.ptx -o /tmp/tmpcr1tm3ro.ptx.o
(EngineCore_DP0 pid=320014) 
[rank0]:[W125 19:03:04.055706568 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 19:03:06
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:03:10 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:03:10 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=320504) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=320504) 
(EngineCore_DP0 pid=320504) 
(EngineCore_DP0 pid=320504) ================================================================
(EngineCore_DP0 pid=320504) Internal Triton PTX codegen error
(EngineCore_DP0 pid=320504) `ptxas` stderr:
(EngineCore_DP0 pid=320504) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=320504) 
(EngineCore_DP0 pid=320504) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpa69bdpqn.ptx -o /tmp/tmpa69bdpqn.ptx.o
(EngineCore_DP0 pid=320504) 
(EngineCore_DP0 pid=320504) 
(EngineCore_DP0 pid=320504) //
(EngineCore_DP0 pid=320504) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=320504) //
(EngineCore_DP0 pid=320504) 
(EngineCore_DP0 pid=320504) .version 8.7
(EngineCore_DP0 pid=320504) .target sm_121a
(EngineCore_DP0 pid=320504) .address_size 64
(EngineCore_DP0 pid=320504) 
(EngineCore_DP0 pid=320504) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=320504) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=320504)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=320504) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=320504) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=320504) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=320504) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=320504) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=320504) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=320504) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=320504) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=320504) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=320504) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=320504) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=320504) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=320504) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=320504) )
(EngineCore_DP0 pid=320504) .reqntid 512
(EngineCore_DP0 pid=320504) {
(EngineCore_DP0 pid=320504) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=320504) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=320504) 	.reg .b32 	%r<132>;
(EngineCore_DP0 pid=320504) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=320504) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=320504) $L__func_begin0:
(EngineCore_DP0 pid=320504) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=320504) 
(EngineCore_DP0 pid=320504) // %bb.0:
(EngineCore_DP0 pid=320504) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=320504) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=320504) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=320504) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=320504) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=320504) $L__tmp0:
(EngineCore_DP0 pid=320504) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=320504) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=320504) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=320504) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=320504) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=320504) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=320504) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=320504) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=320504) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=320504) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=320504) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=320504) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=320504) 	mov.b32 	%r130, 0f2B8CBCCC;
(EngineCore_DP0 pid=320504) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=320504) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=320504) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=320504) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=320504) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=320504) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=320504) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=320504) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=320504) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=320504) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=320504) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=320504) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=320504) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=320504) 	mov.b32 	%r128, 0f00000000;
(EngineCore_DP0 pid=320504) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=320504) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=320504) 	mov.b32 	%r129, %r40;
(EngineCore_DP0 pid=320504) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=320504) 	.loc	1 299 19                        // quant_slide_tuned_Llama3.2-1B.py:299:19
(EngineCore_DP0 pid=320504) 	add.s32 	%r58, %r4, %r129;
(EngineCore_DP0 pid=320504) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=320504) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=320504) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=320504) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=320504) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=320504) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=320504) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=320504) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=320504) 	// begin inline asm
(EngineCore_DP0 pid=320504) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=320504) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=320504) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=320504) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=320504) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=320504) 	// end inline asm
(EngineCore_DP0 pid=320504) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=320504) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=320504) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=320504) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=320504) 	// begin inline asm
(EngineCore_DP0 pid=320504) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=320504) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=320504) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=320504) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=320504) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=320504) 	// end inline asm
(EngineCore_DP0 pid=320504) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=320504) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=320504) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=320504) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=320504) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=320504) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=320504) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=320504) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=320504) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=320504) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=320504) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=320504) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=320504) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=320504) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=320504) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=320504) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=320504) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=320504) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=320504) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=320504) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=320504) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=320504) $L__tmp1:
(EngineCore_DP0 pid=320504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	bar.sync 	0;
(EngineCore_DP0 pid=320504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=320504) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=320504) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=320504) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=320504) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=320504) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=320504) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=320504) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=320504) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=320504) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=320504) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=320504) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=320504) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=320504) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=320504) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=320504) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=320504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=320504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=320504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=320504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=320504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=320504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=320504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=320504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=320504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=320504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=320504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	// begin inline asm
(EngineCore_DP0 pid=320504) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=320504) 	// end inline asm
(EngineCore_DP0 pid=320504) 	bar.sync 	0;
(EngineCore_DP0 pid=320504) 	// begin inline asm
(EngineCore_DP0 pid=320504) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=320504) 	// end inline asm
(EngineCore_DP0 pid=320504) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=320504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=320504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=320504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=320504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=320504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=320504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=320504) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=320504) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=320504) 	// begin inline asm
(EngineCore_DP0 pid=320504) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=320504) 	// end inline asm
(EngineCore_DP0 pid=320504) 	bar.sync 	0;
(EngineCore_DP0 pid=320504) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=320504) $L__tmp2:
(EngineCore_DP0 pid=320504) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=320504) 	max.f32 	%r128, %r128, %r77;
(EngineCore_DP0 pid=320504) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=320504) 	add.s32 	%r129, %r129, 8192;
(EngineCore_DP0 pid=320504) 	setp.lt.s32 	%p7, %r129, %r19;
(EngineCore_DP0 pid=320504) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=320504) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=320504) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=320504) 	max.f32 	%r130, %r128, 0f2B8CBCCC;
(EngineCore_DP0 pid=320504) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=320504) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=320504) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=320504) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=320504) 	div.full.f32 	%r80, %r130, %r79;
(EngineCore_DP0 pid=320504) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=320504) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=320504) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=320504) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=320504) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=320504) 	// begin inline asm
(EngineCore_DP0 pid=320504) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=320504) 	// end inline asm
(EngineCore_DP0 pid=320504) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=320504) 	mul.lo.s32 	%r15, %r20, 3;
(EngineCore_DP0 pid=320504) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=320504) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=320504) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=320504) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=320504) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=320504) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=320504) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=320504) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=320504) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=320504) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=320504) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=320504) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=320504) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=320504) 	div.full.f32 	%r14, %r79, %r130;
(EngineCore_DP0 pid=320504) 	mov.b32 	%r131, 0;
(EngineCore_DP0 pid=320504) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=320504)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=320504) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=320504) 	add.s32 	%r84, %r3, %r131;
(EngineCore_DP0 pid=320504) 	setp.lt.s32 	%p14, %r84, %r15;
(EngineCore_DP0 pid=320504) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=320504) 	mul.hi.s32 	%r85, %r84, 1431655766;
(EngineCore_DP0 pid=320504) 	shr.u32 	%r86, %r85, 31;
(EngineCore_DP0 pid=320504) 	add.s32 	%r87, %r85, %r86;
(EngineCore_DP0 pid=320504) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=320504) 	mul.lo.s32 	%r88, %r87, 3;
(EngineCore_DP0 pid=320504) 	sub.s32 	%r89, %r84, %r88;
(EngineCore_DP0 pid=320504) 	.loc	1 319 22                        // quant_slide_tuned_Llama3.2-1B.py:319:22
(EngineCore_DP0 pid=320504) 	shl.b32 	%r90, %r87, 3;
(EngineCore_DP0 pid=320504) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=320504) 	shl.b32 	%r91, %r89, 1;
(EngineCore_DP0 pid=320504) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=320504) 	add.s32 	%r92, %r90, %r91;
(EngineCore_DP0 pid=320504) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=320504) 	setp.lt.s32 	%p15, %r92, %r18;
(EngineCore_DP0 pid=320504) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=320504) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=320504) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=320504) 	mad.wide.s32 	%rd9, %r92, 2, %rd1;
(EngineCore_DP0 pid=320504) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=320504) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=320504) 	// begin inline asm
(EngineCore_DP0 pid=320504) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=320504) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=320504) 	// end inline asm
(EngineCore_DP0 pid=320504) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=320504) 	cvt.f32.bf16 	%r93, %rs48;
(EngineCore_DP0 pid=320504) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=320504) 	or.b32 	%r94, %r92, 1;
(EngineCore_DP0 pid=320504) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=320504) 	setp.lt.s32 	%p16, %r94, %r18;
(EngineCore_DP0 pid=320504) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=320504) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=320504) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=320504) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=320504) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=320504) 	// begin inline asm
(EngineCore_DP0 pid=320504) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=320504) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=320504) 	// end inline asm
(EngineCore_DP0 pid=320504) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=320504) 	cvt.f32.bf16 	%r95, %rs50;
(EngineCore_DP0 pid=320504) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=320504) 	add.s32 	%r96, %r92, 2;
(EngineCore_DP0 pid=320504) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=320504) 	setp.lt.s32 	%p17, %r96, %r18;
(EngineCore_DP0 pid=320504) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=320504) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=320504) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=320504) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=320504) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=320504) 	// begin inline asm
(EngineCore_DP0 pid=320504) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=320504) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=320504) 	// end inline asm
(EngineCore_DP0 pid=320504) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=320504) 	cvt.f32.bf16 	%r97, %rs52;
(EngineCore_DP0 pid=320504) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=320504) 	add.s32 	%r98, %r92, 3;
(EngineCore_DP0 pid=320504) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=320504) 	setp.lt.s32 	%p18, %r98, %r18;
(EngineCore_DP0 pid=320504) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=320504) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=320504) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=320504) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=320504) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=320504) 	// begin inline asm
(EngineCore_DP0 pid=320504) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=320504) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=320504) 	// end inline asm
(EngineCore_DP0 pid=320504) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=320504) 	cvt.f32.bf16 	%r99, %rs54;
(EngineCore_DP0 pid=320504) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=320504) 	mul.f32 	%r100, %r14, %r93;
(EngineCore_DP0 pid=320504) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=320504) 	cvt.rni.f32.f32 	%r101, %r100;
(EngineCore_DP0 pid=320504) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=320504) 	max.f32 	%r102, %r101, 0fC3000000;
(EngineCore_DP0 pid=320504) 	min.f32 	%r103, %r102, 0f42FE0000;
(EngineCore_DP0 pid=320504) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=320504) 	cvt.rzi.s32.f32 	%r104, %r103;
(EngineCore_DP0 pid=320504) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=320504) 	and.b32 	%r105, %r104, 255;
(EngineCore_DP0 pid=320504) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=320504) 	mul.f32 	%r106, %r14, %r95;
(EngineCore_DP0 pid=320504) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=320504) 	cvt.rni.f32.f32 	%r107, %r106;
(EngineCore_DP0 pid=320504) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=320504) 	mul.f32 	%r108, %r14, %r97;
(EngineCore_DP0 pid=320504) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=320504) 	cvt.rni.f32.f32 	%r109, %r108;
(EngineCore_DP0 pid=320504) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=320504) 	mul.f32 	%r110, %r14, %r99;
(EngineCore_DP0 pid=320504) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=320504) 	cvt.rni.f32.f32 	%r111, %r110;
(EngineCore_DP0 pid=320504) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=320504) 	max.f32 	%r112, %r111, 0fC3000000;
(EngineCore_DP0 pid=320504) 	min.f32 	%r113, %r112, 0f42FE0000;
(EngineCore_DP0 pid=320504) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=320504) 	cvt.rzi.s32.f32 	%r114, %r113;
(EngineCore_DP0 pid=320504) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=320504) 	max.f32 	%r115, %r109, 0fC3000000;
(EngineCore_DP0 pid=320504) 	max.f32 	%r116, %r107, 0fC3000000;
(EngineCore_DP0 pid=320504) 	min.f32 	%r117, %r116, 0f42FE0000;
(EngineCore_DP0 pid=320504) 	min.f32 	%r118, %r115, 0f42FE0000;
(EngineCore_DP0 pid=320504) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=320504) 	cvt.rzi.s32.f32 	%r119, %r118;
(EngineCore_DP0 pid=320504) 	cvt.rzi.s32.f32 	%r120, %r117;
(EngineCore_DP0 pid=320504) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=320504) 	shl.b32 	%r121, %r120, 8;
(EngineCore_DP0 pid=320504) 	shl.b32 	%r122, %r119, 16;
(EngineCore_DP0 pid=320504) 	and.b32 	%r123, %r122, 16711680;
(EngineCore_DP0 pid=320504) 	and.b32 	%r124, %r121, 65280;
(EngineCore_DP0 pid=320504) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=320504) 	or.b32 	%r125, %r124, %r105;
(EngineCore_DP0 pid=320504) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=320504) 	or.b32 	%r126, %r125, %r123;
(EngineCore_DP0 pid=320504) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=320504) 	shl.b32 	%r127, %r114, 24;
(EngineCore_DP0 pid=320504) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=320504) 	or.b32 	%r82, %r126, %r127;
(EngineCore_DP0 pid=320504) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=320504) 	mad.wide.s32 	%rd13, %r84, 4, %rd2;
(EngineCore_DP0 pid=320504) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=320504) 	// begin inline asm
(EngineCore_DP0 pid=320504) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r82 };
(EngineCore_DP0 pid=320504) 	// end inline asm
(EngineCore_DP0 pid=320504) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=320504) 	add.s32 	%r131, %r131, 512;
(EngineCore_DP0 pid=320504) 	setp.lt.s32 	%p19, %r131, %r15;
(EngineCore_DP0 pid=320504) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=320504) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=320504) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=320504) 	ret;
(EngineCore_DP0 pid=320504) $L__tmp3:
(EngineCore_DP0 pid=320504) $L__func_end0:
(EngineCore_DP0 pid=320504)                                         // -- End function
(EngineCore_DP0 pid=320504) }
(EngineCore_DP0 pid=320504) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=320504) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=320504) 	.section	.debug_abbrev
(EngineCore_DP0 pid=320504) 	{
(EngineCore_DP0 pid=320504) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=320504) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=320504) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=320504) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=320504) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=320504) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=320504) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=320504) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=320504) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=320504) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=320504) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=320504) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=320504) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=320504) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=320504) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=320504) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=320504) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=320504) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=320504) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=320504) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=320504) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=320504) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=320504) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=320504) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=320504) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=320504) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=320504) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=320504) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=320504) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=320504) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=320504) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=320504) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=320504) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=320504) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=320504) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=320504) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=320504) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=320504) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=320504) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=320504) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=320504) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=320504) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=320504) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=320504) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=320504) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=320504) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=320504) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=320504) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=320504) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=320504) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=320504) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=320504) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=320504) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=320504) 	}
(EngineCore_DP0 pid=320504) 	.section	.debug_info
(EngineCore_DP0 pid=320504) 	{
(EngineCore_DP0 pid=320504) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=320504) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=320504) .b8 0
(EngineCore_DP0 pid=320504) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=320504) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=320504) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=320504) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=320504) .b8 114
(EngineCore_DP0 pid=320504) .b8 105
(EngineCore_DP0 pid=320504) .b8 116
(EngineCore_DP0 pid=320504) .b8 111
(EngineCore_DP0 pid=320504) .b8 110
(EngineCore_DP0 pid=320504) .b8 0
(EngineCore_DP0 pid=320504) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=320504) .b8 0
(EngineCore_DP0 pid=320504) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=320504) .b8 117
(EngineCore_DP0 pid=320504) .b8 97
(EngineCore_DP0 pid=320504) .b8 110
(EngineCore_DP0 pid=320504) .b8 116
(EngineCore_DP0 pid=320504) .b8 95
(EngineCore_DP0 pid=320504) .b8 115
(EngineCore_DP0 pid=320504) .b8 108
(EngineCore_DP0 pid=320504) .b8 105
(EngineCore_DP0 pid=320504) .b8 100
(EngineCore_DP0 pid=320504) .b8 101
(EngineCore_DP0 pid=320504) .b8 95
(EngineCore_DP0 pid=320504) .b8 116
(EngineCore_DP0 pid=320504) .b8 117
(EngineCore_DP0 pid=320504) .b8 110
(EngineCore_DP0 pid=320504) .b8 101
(EngineCore_DP0 pid=320504) .b8 100
(EngineCore_DP0 pid=320504) .b8 95
(EngineCore_DP0 pid=320504) .b8 76
(EngineCore_DP0 pid=320504) .b8 108
(EngineCore_DP0 pid=320504) .b8 97
(EngineCore_DP0 pid=320504) .b8 109
(EngineCore_DP0 pid=320504) .b8 97
(EngineCore_DP0 pid=320504) .b8 51
(EngineCore_DP0 pid=320504) .b8 46
(EngineCore_DP0 pid=320504) .b8 50
(EngineCore_DP0 pid=320504) .b8 45
(EngineCore_DP0 pid=320504) .b8 49
(EngineCore_DP0 pid=320504) .b8 66
(EngineCore_DP0 pid=320504) .b8 46
(EngineCore_DP0 pid=320504) .b8 112
(EngineCore_DP0 pid=320504) .b8 121
(EngineCore_DP0 pid=320504) .b8 0
(EngineCore_DP0 pid=320504) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=320504) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=320504) .b8 114
(EngineCore_DP0 pid=320504) .b8 111
(EngineCore_DP0 pid=320504) .b8 111
(EngineCore_DP0 pid=320504) .b8 116
(EngineCore_DP0 pid=320504) .b8 47
(EngineCore_DP0 pid=320504) .b8 118
(EngineCore_DP0 pid=320504) .b8 108
(EngineCore_DP0 pid=320504) .b8 108
(EngineCore_DP0 pid=320504) .b8 109
(EngineCore_DP0 pid=320504) .b8 98
(EngineCore_DP0 pid=320504) .b8 101
(EngineCore_DP0 pid=320504) .b8 110
(EngineCore_DP0 pid=320504) .b8 99
(EngineCore_DP0 pid=320504) .b8 104
(EngineCore_DP0 pid=320504) .b8 47
(EngineCore_DP0 pid=320504) .b8 115
(EngineCore_DP0 pid=320504) .b8 108
(EngineCore_DP0 pid=320504) .b8 105
(EngineCore_DP0 pid=320504) .b8 100
(EngineCore_DP0 pid=320504) .b8 101
(EngineCore_DP0 pid=320504) .b8 115
(EngineCore_DP0 pid=320504) .b8 112
(EngineCore_DP0 pid=320504) .b8 97
(EngineCore_DP0 pid=320504) .b8 114
(EngineCore_DP0 pid=320504) .b8 115
(EngineCore_DP0 pid=320504) .b8 101
(EngineCore_DP0 pid=320504) .b8 47
(EngineCore_DP0 pid=320504) .b8 99
(EngineCore_DP0 pid=320504) .b8 115
(EngineCore_DP0 pid=320504) .b8 114
(EngineCore_DP0 pid=320504) .b8 99
(EngineCore_DP0 pid=320504) .b8 47
(EngineCore_DP0 pid=320504) .b8 102
(EngineCore_DP0 pid=320504) .b8 117
(EngineCore_DP0 pid=320504) .b8 115
(EngineCore_DP0 pid=320504) .b8 101
(EngineCore_DP0 pid=320504) .b8 100
(EngineCore_DP0 pid=320504) .b8 95
(EngineCore_DP0 pid=320504) .b8 113
(EngineCore_DP0 pid=320504) .b8 117
(EngineCore_DP0 pid=320504) .b8 97
(EngineCore_DP0 pid=320504) .b8 110
(EngineCore_DP0 pid=320504) .b8 116
(EngineCore_DP0 pid=320504) .b8 95
(EngineCore_DP0 pid=320504) .b8 115
(EngineCore_DP0 pid=320504) .b8 108
(EngineCore_DP0 pid=320504) .b8 105
(EngineCore_DP0 pid=320504) .b8 100
(EngineCore_DP0 pid=320504) .b8 101
(EngineCore_DP0 pid=320504) .b8 95
(EngineCore_DP0 pid=320504) .b8 116
(EngineCore_DP0 pid=320504) .b8 114
(EngineCore_DP0 pid=320504) .b8 105
(EngineCore_DP0 pid=320504) .b8 116
(EngineCore_DP0 pid=320504) .b8 111
(EngineCore_DP0 pid=320504) .b8 110
(EngineCore_DP0 pid=320504) .b8 47
(EngineCore_DP0 pid=320504) .b8 98
(EngineCore_DP0 pid=320504) .b8 117
(EngineCore_DP0 pid=320504) .b8 105
(EngineCore_DP0 pid=320504) .b8 108
(EngineCore_DP0 pid=320504) .b8 100
(EngineCore_DP0 pid=320504) .b8 47
(EngineCore_DP0 pid=320504) .b8 71
(EngineCore_DP0 pid=320504) .b8 66
(EngineCore_DP0 pid=320504) .b8 49
(EngineCore_DP0 pid=320504) .b8 48
(EngineCore_DP0 pid=320504) .b8 95
(EngineCore_DP0 pid=320504) .b8 99
(EngineCore_DP0 pid=320504) .b8 99
(EngineCore_DP0 pid=320504) .b8 49
(EngineCore_DP0 pid=320504) .b8 50
(EngineCore_DP0 pid=320504) .b8 49
(EngineCore_DP0 pid=320504) .b8 95
(EngineCore_DP0 pid=320504) .b8 112
(EngineCore_DP0 pid=320504) .b8 121
(EngineCore_DP0 pid=320504) .b8 51
(EngineCore_DP0 pid=320504) .b8 49
(EngineCore_DP0 pid=320504) .b8 50
(EngineCore_DP0 pid=320504) .b8 95
(EngineCore_DP0 pid=320504) .b8 99
(EngineCore_DP0 pid=320504) .b8 117
(EngineCore_DP0 pid=320504) .b8 49
(EngineCore_DP0 pid=320504) .b8 50
(EngineCore_DP0 pid=320504) .b8 57
(EngineCore_DP0 pid=320504) .b8 95
(EngineCore_DP0 pid=320504) .b8 97
(EngineCore_DP0 pid=320504) .b8 97
(EngineCore_DP0 pid=320504) .b8 114
(EngineCore_DP0 pid=320504) .b8 99
(EngineCore_DP0 pid=320504) .b8 104
(EngineCore_DP0 pid=320504) .b8 54
(EngineCore_DP0 pid=320504) .b8 52
(EngineCore_DP0 pid=320504) .b8 0
(EngineCore_DP0 pid=320504) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=320504) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=320504) .b8 113
(EngineCore_DP0 pid=320504) .b8 117
(EngineCore_DP0 pid=320504) .b8 97
(EngineCore_DP0 pid=320504) .b8 110
(EngineCore_DP0 pid=320504) .b8 116
(EngineCore_DP0 pid=320504) .b8 95
(EngineCore_DP0 pid=320504) .b8 115
(EngineCore_DP0 pid=320504) .b8 108
(EngineCore_DP0 pid=320504) .b8 105
(EngineCore_DP0 pid=320504) .b8 100
(EngineCore_DP0 pid=320504) .b8 101
(EngineCore_DP0 pid=320504) .b8 95
(EngineCore_DP0 pid=320504) .b8 105
(EngineCore_DP0 pid=320504) .b8 110
(EngineCore_DP0 pid=320504) .b8 116
(EngineCore_DP0 pid=320504) .b8 56
(EngineCore_DP0 pid=320504) .b8 95
(EngineCore_DP0 pid=320504) .b8 107
(EngineCore_DP0 pid=320504) .b8 101
(EngineCore_DP0 pid=320504) .b8 114
(EngineCore_DP0 pid=320504) .b8 110
(EngineCore_DP0 pid=320504) .b8 101
(EngineCore_DP0 pid=320504) .b8 108
(EngineCore_DP0 pid=320504) .b8 0
(EngineCore_DP0 pid=320504) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=320504) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=320504) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=320504) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=320504) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=320504) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=320504) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=320504) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=320504) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=320504) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=320504) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=320504) .b8 1
(EngineCore_DP0 pid=320504) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=320504) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=320504) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=320504) 	}
(EngineCore_DP0 pid=320504) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=320504) 
(EngineCore_DP0 pid=320504) ================================================================
(EngineCore_DP0 pid=320504) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=320504) 
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpa69bdpqn.ptx', '-o', '/tmp/tmpa69bdpqn.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866] 
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866] 
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866] 
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpa69bdpqn.ptx -o /tmp/tmpa69bdpqn.ptx.o
(EngineCore_DP0 pid=320504) ERROR 01-25 19:03:27 [core.py:866] 

STDERR:
[2026-01-25 19:03:10] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:03:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:03:10] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:03:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:03:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:03:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:03:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:03:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:03:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:03:14] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:03:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:03:14] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:03:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:03:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:03:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:03:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:03:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:03:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=320504) [2026-01-25 19:03:14] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=320504) [2026-01-25 19:03:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=320504) [2026-01-25 19:03:14] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=320504) [2026-01-25 19:03:14] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=320504) [2026-01-25 19:03:14] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=320504) [2026-01-25 19:03:14] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=320504) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=320504) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.87s/it]
(EngineCore_DP0 pid=320504) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.87s/it]
(EngineCore_DP0 pid=320504) 
(EngineCore_DP0 pid=320504) [2026-01-25 19:03:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=320504) [2026-01-25 19:03:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=320504) [2026-01-25 19:03:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=320504) [2026-01-25 19:03:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=320504) [2026-01-25 19:03:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=320504) [2026-01-25 19:03:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=320504) [2026-01-25 19:03:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=320504) [2026-01-25 19:03:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=320504) Process EngineCore_DP0:
(EngineCore_DP0 pid=320504) Traceback (most recent call last):
(EngineCore_DP0 pid=320504)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=320504)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=320504)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=320504)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=320504) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpa69bdpqn.ptx', '-o', '/tmp/tmpa69bdpqn.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=320504) 
(EngineCore_DP0 pid=320504) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=320504) 
(EngineCore_DP0 pid=320504) Traceback (most recent call last):
(EngineCore_DP0 pid=320504)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=320504)     self.run()
(EngineCore_DP0 pid=320504)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=320504)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=320504)     raise e
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=320504)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=320504)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=320504)     super().__init__(
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=320504)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=320504)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=320504)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=320504)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=320504)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=320504)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=320504)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=320504)     return func(*args, **kwargs)
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=320504)     return func(*args, **kwargs)
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=320504)     self.model_runner.profile_run()
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=320504)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=320504)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=320504)     return func(*args, **kwargs)
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=320504)     outputs = self.model(
(EngineCore_DP0 pid=320504)               ^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=320504)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=320504)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=320504)     model_output = self.model(
(EngineCore_DP0 pid=320504)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=320504)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=320504)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=320504)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=320504)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=320504)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=320504)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=320504)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=320504)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=320504)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=320504)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=320504)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=320504)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=320504)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=320504)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=320504)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=320504)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=320504)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=320504)     return self._linear_fn(
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=320504)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=320504)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=320504)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=320504)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=320504)     return fn(input, L)
(EngineCore_DP0 pid=320504)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=320504)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=320504)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=320504)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=320504)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=320504)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=320504)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=320504)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=320504)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=320504)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=320504)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=320504)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=320504)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=320504)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=320504)     raise PTXASError(error)
(EngineCore_DP0 pid=320504) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=320504) `ptxas` stderr:
(EngineCore_DP0 pid=320504) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=320504) 
(EngineCore_DP0 pid=320504) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpa69bdpqn.ptx -o /tmp/tmpa69bdpqn.ptx.o
(EngineCore_DP0 pid=320504) 
[rank0]:[W125 19:03:27.976940585 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 19:03:29
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:03:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:03:34 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=321034) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=321034) 
(EngineCore_DP0 pid=321034) 
(EngineCore_DP0 pid=321034) ================================================================
(EngineCore_DP0 pid=321034) Internal Triton PTX codegen error
(EngineCore_DP0 pid=321034) `ptxas` stderr:
(EngineCore_DP0 pid=321034) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=321034) 
(EngineCore_DP0 pid=321034) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp0wkhw6zh.ptx -o /tmp/tmp0wkhw6zh.ptx.o
(EngineCore_DP0 pid=321034) 
(EngineCore_DP0 pid=321034) 
(EngineCore_DP0 pid=321034) //
(EngineCore_DP0 pid=321034) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=321034) //
(EngineCore_DP0 pid=321034) 
(EngineCore_DP0 pid=321034) .version 8.7
(EngineCore_DP0 pid=321034) .target sm_121a
(EngineCore_DP0 pid=321034) .address_size 64
(EngineCore_DP0 pid=321034) 
(EngineCore_DP0 pid=321034) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=321034) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=321034)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=321034) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=321034) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=321034) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=321034) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=321034) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=321034) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=321034) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=321034) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=321034) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=321034) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=321034) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=321034) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=321034) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=321034) )
(EngineCore_DP0 pid=321034) .reqntid 512
(EngineCore_DP0 pid=321034) {
(EngineCore_DP0 pid=321034) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=321034) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=321034) 	.reg .b32 	%r<132>;
(EngineCore_DP0 pid=321034) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=321034) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=321034) $L__func_begin0:
(EngineCore_DP0 pid=321034) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=321034) 
(EngineCore_DP0 pid=321034) // %bb.0:
(EngineCore_DP0 pid=321034) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=321034) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=321034) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=321034) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=321034) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=321034) $L__tmp0:
(EngineCore_DP0 pid=321034) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=321034) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=321034) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=321034) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=321034) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=321034) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=321034) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=321034) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=321034) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=321034) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=321034) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=321034) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=321034) 	mov.b32 	%r130, 0f2B8CBCCC;
(EngineCore_DP0 pid=321034) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=321034) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=321034) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=321034) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=321034) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=321034) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=321034) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=321034) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=321034) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=321034) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=321034) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=321034) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=321034) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=321034) 	mov.b32 	%r128, 0f00000000;
(EngineCore_DP0 pid=321034) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=321034) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=321034) 	mov.b32 	%r129, %r40;
(EngineCore_DP0 pid=321034) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=321034) 	.loc	1 299 19                        // quant_slide_tuned_Llama3.2-1B.py:299:19
(EngineCore_DP0 pid=321034) 	add.s32 	%r58, %r4, %r129;
(EngineCore_DP0 pid=321034) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=321034) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=321034) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=321034) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=321034) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=321034) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=321034) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=321034) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=321034) 	// begin inline asm
(EngineCore_DP0 pid=321034) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=321034) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=321034) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=321034) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=321034) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=321034) 	// end inline asm
(EngineCore_DP0 pid=321034) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=321034) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=321034) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=321034) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=321034) 	// begin inline asm
(EngineCore_DP0 pid=321034) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=321034) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=321034) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=321034) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=321034) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=321034) 	// end inline asm
(EngineCore_DP0 pid=321034) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=321034) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=321034) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=321034) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=321034) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=321034) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=321034) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=321034) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=321034) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=321034) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=321034) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=321034) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=321034) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=321034) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=321034) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=321034) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=321034) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=321034) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=321034) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=321034) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=321034) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=321034) $L__tmp1:
(EngineCore_DP0 pid=321034) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	bar.sync 	0;
(EngineCore_DP0 pid=321034) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=321034) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=321034) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=321034) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=321034) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=321034) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=321034) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=321034) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=321034) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=321034) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=321034) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=321034) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=321034) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=321034) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=321034) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=321034) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=321034) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=321034) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=321034) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=321034) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=321034) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=321034) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=321034) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=321034) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=321034) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=321034) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=321034) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	// begin inline asm
(EngineCore_DP0 pid=321034) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=321034) 	// end inline asm
(EngineCore_DP0 pid=321034) 	bar.sync 	0;
(EngineCore_DP0 pid=321034) 	// begin inline asm
(EngineCore_DP0 pid=321034) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=321034) 	// end inline asm
(EngineCore_DP0 pid=321034) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=321034) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=321034) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=321034) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=321034) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=321034) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=321034) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=321034) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=321034) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321034) 	// begin inline asm
(EngineCore_DP0 pid=321034) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=321034) 	// end inline asm
(EngineCore_DP0 pid=321034) 	bar.sync 	0;
(EngineCore_DP0 pid=321034) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=321034) $L__tmp2:
(EngineCore_DP0 pid=321034) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=321034) 	max.f32 	%r128, %r128, %r77;
(EngineCore_DP0 pid=321034) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=321034) 	add.s32 	%r129, %r129, 8192;
(EngineCore_DP0 pid=321034) 	setp.lt.s32 	%p7, %r129, %r19;
(EngineCore_DP0 pid=321034) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=321034) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=321034) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=321034) 	max.f32 	%r130, %r128, 0f2B8CBCCC;
(EngineCore_DP0 pid=321034) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=321034) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=321034) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=321034) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=321034) 	div.full.f32 	%r80, %r130, %r79;
(EngineCore_DP0 pid=321034) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=321034) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=321034) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=321034) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=321034) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=321034) 	// begin inline asm
(EngineCore_DP0 pid=321034) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=321034) 	// end inline asm
(EngineCore_DP0 pid=321034) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=321034) 	mul.lo.s32 	%r15, %r20, 3;
(EngineCore_DP0 pid=321034) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=321034) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=321034) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=321034) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=321034) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=321034) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=321034) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=321034) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=321034) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=321034) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=321034) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=321034) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=321034) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=321034) 	div.full.f32 	%r14, %r79, %r130;
(EngineCore_DP0 pid=321034) 	mov.b32 	%r131, 0;
(EngineCore_DP0 pid=321034) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=321034)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=321034) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=321034) 	add.s32 	%r84, %r3, %r131;
(EngineCore_DP0 pid=321034) 	setp.lt.s32 	%p14, %r84, %r15;
(EngineCore_DP0 pid=321034) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=321034) 	mul.hi.s32 	%r85, %r84, 1431655766;
(EngineCore_DP0 pid=321034) 	shr.u32 	%r86, %r85, 31;
(EngineCore_DP0 pid=321034) 	add.s32 	%r87, %r85, %r86;
(EngineCore_DP0 pid=321034) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=321034) 	mul.lo.s32 	%r88, %r87, 3;
(EngineCore_DP0 pid=321034) 	sub.s32 	%r89, %r84, %r88;
(EngineCore_DP0 pid=321034) 	.loc	1 319 22                        // quant_slide_tuned_Llama3.2-1B.py:319:22
(EngineCore_DP0 pid=321034) 	shl.b32 	%r90, %r87, 3;
(EngineCore_DP0 pid=321034) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=321034) 	shl.b32 	%r91, %r89, 1;
(EngineCore_DP0 pid=321034) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=321034) 	add.s32 	%r92, %r90, %r91;
(EngineCore_DP0 pid=321034) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=321034) 	setp.lt.s32 	%p15, %r92, %r18;
(EngineCore_DP0 pid=321034) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=321034) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=321034) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=321034) 	mad.wide.s32 	%rd9, %r92, 2, %rd1;
(EngineCore_DP0 pid=321034) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=321034) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=321034) 	// begin inline asm
(EngineCore_DP0 pid=321034) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=321034) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=321034) 	// end inline asm
(EngineCore_DP0 pid=321034) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=321034) 	cvt.f32.bf16 	%r93, %rs48;
(EngineCore_DP0 pid=321034) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=321034) 	or.b32 	%r94, %r92, 1;
(EngineCore_DP0 pid=321034) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=321034) 	setp.lt.s32 	%p16, %r94, %r18;
(EngineCore_DP0 pid=321034) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=321034) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=321034) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=321034) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=321034) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=321034) 	// begin inline asm
(EngineCore_DP0 pid=321034) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=321034) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=321034) 	// end inline asm
(EngineCore_DP0 pid=321034) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=321034) 	cvt.f32.bf16 	%r95, %rs50;
(EngineCore_DP0 pid=321034) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=321034) 	add.s32 	%r96, %r92, 2;
(EngineCore_DP0 pid=321034) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=321034) 	setp.lt.s32 	%p17, %r96, %r18;
(EngineCore_DP0 pid=321034) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=321034) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=321034) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=321034) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=321034) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=321034) 	// begin inline asm
(EngineCore_DP0 pid=321034) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=321034) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=321034) 	// end inline asm
(EngineCore_DP0 pid=321034) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=321034) 	cvt.f32.bf16 	%r97, %rs52;
(EngineCore_DP0 pid=321034) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=321034) 	add.s32 	%r98, %r92, 3;
(EngineCore_DP0 pid=321034) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=321034) 	setp.lt.s32 	%p18, %r98, %r18;
(EngineCore_DP0 pid=321034) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=321034) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=321034) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=321034) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=321034) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=321034) 	// begin inline asm
(EngineCore_DP0 pid=321034) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=321034) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=321034) 	// end inline asm
(EngineCore_DP0 pid=321034) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=321034) 	cvt.f32.bf16 	%r99, %rs54;
(EngineCore_DP0 pid=321034) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=321034) 	mul.f32 	%r100, %r14, %r93;
(EngineCore_DP0 pid=321034) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=321034) 	cvt.rni.f32.f32 	%r101, %r100;
(EngineCore_DP0 pid=321034) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=321034) 	max.f32 	%r102, %r101, 0fC3000000;
(EngineCore_DP0 pid=321034) 	min.f32 	%r103, %r102, 0f42FE0000;
(EngineCore_DP0 pid=321034) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=321034) 	cvt.rzi.s32.f32 	%r104, %r103;
(EngineCore_DP0 pid=321034) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=321034) 	and.b32 	%r105, %r104, 255;
(EngineCore_DP0 pid=321034) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=321034) 	mul.f32 	%r106, %r14, %r95;
(EngineCore_DP0 pid=321034) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=321034) 	cvt.rni.f32.f32 	%r107, %r106;
(EngineCore_DP0 pid=321034) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=321034) 	mul.f32 	%r108, %r14, %r97;
(EngineCore_DP0 pid=321034) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=321034) 	cvt.rni.f32.f32 	%r109, %r108;
(EngineCore_DP0 pid=321034) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=321034) 	mul.f32 	%r110, %r14, %r99;
(EngineCore_DP0 pid=321034) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=321034) 	cvt.rni.f32.f32 	%r111, %r110;
(EngineCore_DP0 pid=321034) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=321034) 	max.f32 	%r112, %r111, 0fC3000000;
(EngineCore_DP0 pid=321034) 	min.f32 	%r113, %r112, 0f42FE0000;
(EngineCore_DP0 pid=321034) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=321034) 	cvt.rzi.s32.f32 	%r114, %r113;
(EngineCore_DP0 pid=321034) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=321034) 	max.f32 	%r115, %r109, 0fC3000000;
(EngineCore_DP0 pid=321034) 	max.f32 	%r116, %r107, 0fC3000000;
(EngineCore_DP0 pid=321034) 	min.f32 	%r117, %r116, 0f42FE0000;
(EngineCore_DP0 pid=321034) 	min.f32 	%r118, %r115, 0f42FE0000;
(EngineCore_DP0 pid=321034) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=321034) 	cvt.rzi.s32.f32 	%r119, %r118;
(EngineCore_DP0 pid=321034) 	cvt.rzi.s32.f32 	%r120, %r117;
(EngineCore_DP0 pid=321034) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=321034) 	shl.b32 	%r121, %r120, 8;
(EngineCore_DP0 pid=321034) 	shl.b32 	%r122, %r119, 16;
(EngineCore_DP0 pid=321034) 	and.b32 	%r123, %r122, 16711680;
(EngineCore_DP0 pid=321034) 	and.b32 	%r124, %r121, 65280;
(EngineCore_DP0 pid=321034) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=321034) 	or.b32 	%r125, %r124, %r105;
(EngineCore_DP0 pid=321034) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=321034) 	or.b32 	%r126, %r125, %r123;
(EngineCore_DP0 pid=321034) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=321034) 	shl.b32 	%r127, %r114, 24;
(EngineCore_DP0 pid=321034) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=321034) 	or.b32 	%r82, %r126, %r127;
(EngineCore_DP0 pid=321034) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=321034) 	mad.wide.s32 	%rd13, %r84, 4, %rd2;
(EngineCore_DP0 pid=321034) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=321034) 	// begin inline asm
(EngineCore_DP0 pid=321034) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r82 };
(EngineCore_DP0 pid=321034) 	// end inline asm
(EngineCore_DP0 pid=321034) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=321034) 	add.s32 	%r131, %r131, 512;
(EngineCore_DP0 pid=321034) 	setp.lt.s32 	%p19, %r131, %r15;
(EngineCore_DP0 pid=321034) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=321034) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=321034) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=321034) 	ret;
(EngineCore_DP0 pid=321034) $L__tmp3:
(EngineCore_DP0 pid=321034) $L__func_end0:
(EngineCore_DP0 pid=321034)                                         // -- End function
(EngineCore_DP0 pid=321034) }
(EngineCore_DP0 pid=321034) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=321034) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=321034) 	.section	.debug_abbrev
(EngineCore_DP0 pid=321034) 	{
(EngineCore_DP0 pid=321034) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=321034) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=321034) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=321034) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=321034) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=321034) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=321034) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=321034) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=321034) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=321034) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=321034) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=321034) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=321034) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=321034) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=321034) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=321034) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=321034) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=321034) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=321034) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=321034) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=321034) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=321034) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=321034) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=321034) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=321034) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=321034) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=321034) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=321034) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=321034) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=321034) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=321034) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=321034) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=321034) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=321034) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=321034) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=321034) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=321034) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=321034) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=321034) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=321034) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=321034) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=321034) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=321034) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=321034) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=321034) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=321034) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=321034) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=321034) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=321034) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=321034) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=321034) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=321034) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=321034) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=321034) 	}
(EngineCore_DP0 pid=321034) 	.section	.debug_info
(EngineCore_DP0 pid=321034) 	{
(EngineCore_DP0 pid=321034) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=321034) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=321034) .b8 0
(EngineCore_DP0 pid=321034) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=321034) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=321034) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=321034) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=321034) .b8 114
(EngineCore_DP0 pid=321034) .b8 105
(EngineCore_DP0 pid=321034) .b8 116
(EngineCore_DP0 pid=321034) .b8 111
(EngineCore_DP0 pid=321034) .b8 110
(EngineCore_DP0 pid=321034) .b8 0
(EngineCore_DP0 pid=321034) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=321034) .b8 0
(EngineCore_DP0 pid=321034) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=321034) .b8 117
(EngineCore_DP0 pid=321034) .b8 97
(EngineCore_DP0 pid=321034) .b8 110
(EngineCore_DP0 pid=321034) .b8 116
(EngineCore_DP0 pid=321034) .b8 95
(EngineCore_DP0 pid=321034) .b8 115
(EngineCore_DP0 pid=321034) .b8 108
(EngineCore_DP0 pid=321034) .b8 105
(EngineCore_DP0 pid=321034) .b8 100
(EngineCore_DP0 pid=321034) .b8 101
(EngineCore_DP0 pid=321034) .b8 95
(EngineCore_DP0 pid=321034) .b8 116
(EngineCore_DP0 pid=321034) .b8 117
(EngineCore_DP0 pid=321034) .b8 110
(EngineCore_DP0 pid=321034) .b8 101
(EngineCore_DP0 pid=321034) .b8 100
(EngineCore_DP0 pid=321034) .b8 95
(EngineCore_DP0 pid=321034) .b8 76
(EngineCore_DP0 pid=321034) .b8 108
(EngineCore_DP0 pid=321034) .b8 97
(EngineCore_DP0 pid=321034) .b8 109
(EngineCore_DP0 pid=321034) .b8 97
(EngineCore_DP0 pid=321034) .b8 51
(EngineCore_DP0 pid=321034) .b8 46
(EngineCore_DP0 pid=321034) .b8 50
(EngineCore_DP0 pid=321034) .b8 45
(EngineCore_DP0 pid=321034) .b8 49
(EngineCore_DP0 pid=321034) .b8 66
(EngineCore_DP0 pid=321034) .b8 46
(EngineCore_DP0 pid=321034) .b8 112
(EngineCore_DP0 pid=321034) .b8 121
(EngineCore_DP0 pid=321034) .b8 0
(EngineCore_DP0 pid=321034) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=321034) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=321034) .b8 114
(EngineCore_DP0 pid=321034) .b8 111
(EngineCore_DP0 pid=321034) .b8 111
(EngineCore_DP0 pid=321034) .b8 116
(EngineCore_DP0 pid=321034) .b8 47
(EngineCore_DP0 pid=321034) .b8 118
(EngineCore_DP0 pid=321034) .b8 108
(EngineCore_DP0 pid=321034) .b8 108
(EngineCore_DP0 pid=321034) .b8 109
(EngineCore_DP0 pid=321034) .b8 98
(EngineCore_DP0 pid=321034) .b8 101
(EngineCore_DP0 pid=321034) .b8 110
(EngineCore_DP0 pid=321034) .b8 99
(EngineCore_DP0 pid=321034) .b8 104
(EngineCore_DP0 pid=321034) .b8 47
(EngineCore_DP0 pid=321034) .b8 115
(EngineCore_DP0 pid=321034) .b8 108
(EngineCore_DP0 pid=321034) .b8 105
(EngineCore_DP0 pid=321034) .b8 100
(EngineCore_DP0 pid=321034) .b8 101
(EngineCore_DP0 pid=321034) .b8 115
(EngineCore_DP0 pid=321034) .b8 112
(EngineCore_DP0 pid=321034) .b8 97
(EngineCore_DP0 pid=321034) .b8 114
(EngineCore_DP0 pid=321034) .b8 115
(EngineCore_DP0 pid=321034) .b8 101
(EngineCore_DP0 pid=321034) .b8 47
(EngineCore_DP0 pid=321034) .b8 99
(EngineCore_DP0 pid=321034) .b8 115
(EngineCore_DP0 pid=321034) .b8 114
(EngineCore_DP0 pid=321034) .b8 99
(EngineCore_DP0 pid=321034) .b8 47
(EngineCore_DP0 pid=321034) .b8 102
(EngineCore_DP0 pid=321034) .b8 117
(EngineCore_DP0 pid=321034) .b8 115
(EngineCore_DP0 pid=321034) .b8 101
(EngineCore_DP0 pid=321034) .b8 100
(EngineCore_DP0 pid=321034) .b8 95
(EngineCore_DP0 pid=321034) .b8 113
(EngineCore_DP0 pid=321034) .b8 117
(EngineCore_DP0 pid=321034) .b8 97
(EngineCore_DP0 pid=321034) .b8 110
(EngineCore_DP0 pid=321034) .b8 116
(EngineCore_DP0 pid=321034) .b8 95
(EngineCore_DP0 pid=321034) .b8 115
(EngineCore_DP0 pid=321034) .b8 108
(EngineCore_DP0 pid=321034) .b8 105
(EngineCore_DP0 pid=321034) .b8 100
(EngineCore_DP0 pid=321034) .b8 101
(EngineCore_DP0 pid=321034) .b8 95
(EngineCore_DP0 pid=321034) .b8 116
(EngineCore_DP0 pid=321034) .b8 114
(EngineCore_DP0 pid=321034) .b8 105
(EngineCore_DP0 pid=321034) .b8 116
(EngineCore_DP0 pid=321034) .b8 111
(EngineCore_DP0 pid=321034) .b8 110
(EngineCore_DP0 pid=321034) .b8 47
(EngineCore_DP0 pid=321034) .b8 98
(EngineCore_DP0 pid=321034) .b8 117
(EngineCore_DP0 pid=321034) .b8 105
(EngineCore_DP0 pid=321034) .b8 108
(EngineCore_DP0 pid=321034) .b8 100
(EngineCore_DP0 pid=321034) .b8 47
(EngineCore_DP0 pid=321034) .b8 71
(EngineCore_DP0 pid=321034) .b8 66
(EngineCore_DP0 pid=321034) .b8 49
(EngineCore_DP0 pid=321034) .b8 48
(EngineCore_DP0 pid=321034) .b8 95
(EngineCore_DP0 pid=321034) .b8 99
(EngineCore_DP0 pid=321034) .b8 99
(EngineCore_DP0 pid=321034) .b8 49
(EngineCore_DP0 pid=321034) .b8 50
(EngineCore_DP0 pid=321034) .b8 49
(EngineCore_DP0 pid=321034) .b8 95
(EngineCore_DP0 pid=321034) .b8 112
(EngineCore_DP0 pid=321034) .b8 121
(EngineCore_DP0 pid=321034) .b8 51
(EngineCore_DP0 pid=321034) .b8 49
(EngineCore_DP0 pid=321034) .b8 50
(EngineCore_DP0 pid=321034) .b8 95
(EngineCore_DP0 pid=321034) .b8 99
(EngineCore_DP0 pid=321034) .b8 117
(EngineCore_DP0 pid=321034) .b8 49
(EngineCore_DP0 pid=321034) .b8 50
(EngineCore_DP0 pid=321034) .b8 57
(EngineCore_DP0 pid=321034) .b8 95
(EngineCore_DP0 pid=321034) .b8 97
(EngineCore_DP0 pid=321034) .b8 97
(EngineCore_DP0 pid=321034) .b8 114
(EngineCore_DP0 pid=321034) .b8 99
(EngineCore_DP0 pid=321034) .b8 104
(EngineCore_DP0 pid=321034) .b8 54
(EngineCore_DP0 pid=321034) .b8 52
(EngineCore_DP0 pid=321034) .b8 0
(EngineCore_DP0 pid=321034) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=321034) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=321034) .b8 113
(EngineCore_DP0 pid=321034) .b8 117
(EngineCore_DP0 pid=321034) .b8 97
(EngineCore_DP0 pid=321034) .b8 110
(EngineCore_DP0 pid=321034) .b8 116
(EngineCore_DP0 pid=321034) .b8 95
(EngineCore_DP0 pid=321034) .b8 115
(EngineCore_DP0 pid=321034) .b8 108
(EngineCore_DP0 pid=321034) .b8 105
(EngineCore_DP0 pid=321034) .b8 100
(EngineCore_DP0 pid=321034) .b8 101
(EngineCore_DP0 pid=321034) .b8 95
(EngineCore_DP0 pid=321034) .b8 105
(EngineCore_DP0 pid=321034) .b8 110
(EngineCore_DP0 pid=321034) .b8 116
(EngineCore_DP0 pid=321034) .b8 56
(EngineCore_DP0 pid=321034) .b8 95
(EngineCore_DP0 pid=321034) .b8 107
(EngineCore_DP0 pid=321034) .b8 101
(EngineCore_DP0 pid=321034) .b8 114
(EngineCore_DP0 pid=321034) .b8 110
(EngineCore_DP0 pid=321034) .b8 101
(EngineCore_DP0 pid=321034) .b8 108
(EngineCore_DP0 pid=321034) .b8 0
(EngineCore_DP0 pid=321034) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=321034) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=321034) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=321034) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=321034) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=321034) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=321034) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=321034) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=321034) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=321034) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=321034) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=321034) .b8 1
(EngineCore_DP0 pid=321034) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=321034) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=321034) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=321034) 	}
(EngineCore_DP0 pid=321034) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=321034) 
(EngineCore_DP0 pid=321034) ================================================================
(EngineCore_DP0 pid=321034) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=321034) 
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp0wkhw6zh.ptx', '-o', '/tmp/tmp0wkhw6zh.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866] 
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866] 
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866] 
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp0wkhw6zh.ptx -o /tmp/tmp0wkhw6zh.ptx.o
(EngineCore_DP0 pid=321034) ERROR 01-25 19:03:50 [core.py:866] 

STDERR:
[2026-01-25 19:03:34] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:03:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:03:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:03:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:03:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:03:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:03:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:03:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:03:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:03:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:03:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:03:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:03:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:03:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:03:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:03:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:03:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:03:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=321034) [2026-01-25 19:03:38] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=321034) [2026-01-25 19:03:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=321034) [2026-01-25 19:03:38] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=321034) [2026-01-25 19:03:38] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=321034) [2026-01-25 19:03:38] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=321034) [2026-01-25 19:03:38] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=321034) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=321034) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.81s/it]
(EngineCore_DP0 pid=321034) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.81s/it]
(EngineCore_DP0 pid=321034) 
(EngineCore_DP0 pid=321034) [2026-01-25 19:03:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=321034) [2026-01-25 19:03:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=321034) [2026-01-25 19:03:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=321034) [2026-01-25 19:03:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=321034) [2026-01-25 19:03:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=321034) [2026-01-25 19:03:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=321034) [2026-01-25 19:03:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=321034) [2026-01-25 19:03:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=321034) Process EngineCore_DP0:
(EngineCore_DP0 pid=321034) Traceback (most recent call last):
(EngineCore_DP0 pid=321034)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=321034)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=321034)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=321034)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=321034) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp0wkhw6zh.ptx', '-o', '/tmp/tmp0wkhw6zh.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=321034) 
(EngineCore_DP0 pid=321034) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=321034) 
(EngineCore_DP0 pid=321034) Traceback (most recent call last):
(EngineCore_DP0 pid=321034)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=321034)     self.run()
(EngineCore_DP0 pid=321034)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=321034)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=321034)     raise e
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=321034)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=321034)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=321034)     super().__init__(
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=321034)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=321034)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=321034)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=321034)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=321034)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=321034)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=321034)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=321034)     return func(*args, **kwargs)
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=321034)     return func(*args, **kwargs)
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=321034)     self.model_runner.profile_run()
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=321034)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=321034)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=321034)     return func(*args, **kwargs)
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=321034)     outputs = self.model(
(EngineCore_DP0 pid=321034)               ^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=321034)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=321034)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=321034)     model_output = self.model(
(EngineCore_DP0 pid=321034)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=321034)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=321034)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=321034)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=321034)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=321034)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=321034)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=321034)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=321034)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=321034)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=321034)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=321034)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=321034)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=321034)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=321034)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=321034)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=321034)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=321034)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=321034)     return self._linear_fn(
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=321034)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=321034)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=321034)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=321034)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=321034)     return fn(input, L)
(EngineCore_DP0 pid=321034)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=321034)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=321034)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=321034)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=321034)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=321034)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=321034)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=321034)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=321034)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=321034)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=321034)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=321034)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=321034)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321034)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=321034)     raise PTXASError(error)
(EngineCore_DP0 pid=321034) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=321034) `ptxas` stderr:
(EngineCore_DP0 pid=321034) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=321034) 
(EngineCore_DP0 pid=321034) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp0wkhw6zh.ptx -o /tmp/tmp0wkhw6zh.ptx.o
(EngineCore_DP0 pid=321034) 
[rank0]:[W125 19:03:51.409947142 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 19:03:52
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:03:59 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:03:59 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=321570) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=321570) 
(EngineCore_DP0 pid=321570) 
(EngineCore_DP0 pid=321570) ================================================================
(EngineCore_DP0 pid=321570) Internal Triton PTX codegen error
(EngineCore_DP0 pid=321570) `ptxas` stderr:
(EngineCore_DP0 pid=321570) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=321570) 
(EngineCore_DP0 pid=321570) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmps2q4v6hn.ptx -o /tmp/tmps2q4v6hn.ptx.o
(EngineCore_DP0 pid=321570) 
(EngineCore_DP0 pid=321570) 
(EngineCore_DP0 pid=321570) //
(EngineCore_DP0 pid=321570) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=321570) //
(EngineCore_DP0 pid=321570) 
(EngineCore_DP0 pid=321570) .version 8.7
(EngineCore_DP0 pid=321570) .target sm_121a
(EngineCore_DP0 pid=321570) .address_size 64
(EngineCore_DP0 pid=321570) 
(EngineCore_DP0 pid=321570) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=321570) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=321570)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=321570) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=321570) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=321570) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=321570) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=321570) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=321570) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=321570) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=321570) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=321570) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=321570) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=321570) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=321570) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=321570) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=321570) )
(EngineCore_DP0 pid=321570) .reqntid 512
(EngineCore_DP0 pid=321570) {
(EngineCore_DP0 pid=321570) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=321570) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=321570) 	.reg .b32 	%r<267>;
(EngineCore_DP0 pid=321570) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=321570) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=321570) $L__func_begin0:
(EngineCore_DP0 pid=321570) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=321570) 
(EngineCore_DP0 pid=321570) // %bb.0:
(EngineCore_DP0 pid=321570) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=321570) 	ld.param.b32 	%r28, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=321570) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=321570) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=321570) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=321570) $L__tmp0:
(EngineCore_DP0 pid=321570) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=321570) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=321570) 	ld.param.b32 	%r31, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=321570) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=321570) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=321570) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=321570) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=321570) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=321570) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=321570) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=321570) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=321570) 	mov.b32 	%r265, 0f2B8CBCCC;
(EngineCore_DP0 pid=321570) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=321570) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=321570) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=321570) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=321570) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=321570) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=321570) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=321570) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=321570) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=321570) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=321570) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=321570) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=321570) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=321570) 	mov.b32 	%r263, 0f00000000;
(EngineCore_DP0 pid=321570) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=321570) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=321570) 	mov.b32 	%r264, %r49;
(EngineCore_DP0 pid=321570) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=321570) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=321570) 	add.s32 	%r59, %r4, %r264;
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=321570) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=321570) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=321570) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=321570) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=321570) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=321570) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=321570) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=321570) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=321570) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=321570) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=321570) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=321570) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=321570) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=321570) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=321570) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=321570) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=321570) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=321570) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=321570) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=321570) $L__tmp1:
(EngineCore_DP0 pid=321570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	bar.sync 	0;
(EngineCore_DP0 pid=321570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=321570) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=321570) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=321570) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=321570) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=321570) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=321570) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=321570) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=321570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=321570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=321570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=321570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=321570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=321570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=321570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=321570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=321570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=321570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=321570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	bar.sync 	0;
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=321570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=321570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=321570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=321570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=321570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=321570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=321570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=321570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	bar.sync 	0;
(EngineCore_DP0 pid=321570) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=321570) $L__tmp2:
(EngineCore_DP0 pid=321570) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=321570) 	max.f32 	%r263, %r263, %r77;
(EngineCore_DP0 pid=321570) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=321570) 	add.s32 	%r264, %r264, 4096;
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p6, %r264, %r28;
(EngineCore_DP0 pid=321570) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=321570) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=321570) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=321570) 	max.f32 	%r265, %r263, 0f2B8CBCCC;
(EngineCore_DP0 pid=321570) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=321570) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=321570) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=321570) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=321570) 	div.full.f32 	%r80, %r265, %r79;
(EngineCore_DP0 pid=321570) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=321570) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=321570) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=321570) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=321570) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=321570) 	mul.lo.s32 	%r15, %r29, 3;
(EngineCore_DP0 pid=321570) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=321570) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=321570) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=321570) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=321570) 	ld.param.b32 	%r33, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=321570) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=321570) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=321570) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=321570) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=321570) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=321570) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=321570) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=321570) 	div.full.f32 	%r14, %r79, %r265;
(EngineCore_DP0 pid=321570) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=321570) 	mov.b32 	%r266, 0;
(EngineCore_DP0 pid=321570) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=321570)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=321570) 	.loc	1 313 31                        // quant_slide_tuned_Llama3.2-1B.py:313:31
(EngineCore_DP0 pid=321570) 	add.s32 	%r87, %r16, %r266;
(EngineCore_DP0 pid=321570) 	add.s32 	%r88, %r87, 1;
(EngineCore_DP0 pid=321570) 	add.s32 	%r89, %r87, 2;
(EngineCore_DP0 pid=321570) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=321570) 	add.s32 	%r90, %r87, 3;
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p25, %r87, %r15;
(EngineCore_DP0 pid=321570) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=321570) 	mul.hi.s32 	%r91, %r90, 1431655766;
(EngineCore_DP0 pid=321570) 	shr.u32 	%r92, %r91, 31;
(EngineCore_DP0 pid=321570) 	add.s32 	%r93, %r91, %r92;
(EngineCore_DP0 pid=321570) 	mul.hi.s32 	%r94, %r89, 1431655766;
(EngineCore_DP0 pid=321570) 	shr.u32 	%r95, %r94, 31;
(EngineCore_DP0 pid=321570) 	add.s32 	%r96, %r94, %r95;
(EngineCore_DP0 pid=321570) 	mul.hi.s32 	%r97, %r88, 1431655766;
(EngineCore_DP0 pid=321570) 	shr.u32 	%r98, %r97, 31;
(EngineCore_DP0 pid=321570) 	add.s32 	%r99, %r97, %r98;
(EngineCore_DP0 pid=321570) 	mul.hi.s32 	%r100, %r87, 1431655766;
(EngineCore_DP0 pid=321570) 	shr.u32 	%r101, %r100, 31;
(EngineCore_DP0 pid=321570) 	add.s32 	%r102, %r100, %r101;
(EngineCore_DP0 pid=321570) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=321570) 	mul.lo.s32 	%r103, %r102, 3;
(EngineCore_DP0 pid=321570) 	mul.lo.s32 	%r104, %r99, 3;
(EngineCore_DP0 pid=321570) 	mul.lo.s32 	%r105, %r96, 3;
(EngineCore_DP0 pid=321570) 	mul.lo.s32 	%r106, %r93, 3;
(EngineCore_DP0 pid=321570) 	sub.s32 	%r107, %r90, %r106;
(EngineCore_DP0 pid=321570) 	sub.s32 	%r108, %r89, %r105;
(EngineCore_DP0 pid=321570) 	sub.s32 	%r109, %r88, %r104;
(EngineCore_DP0 pid=321570) 	sub.s32 	%r110, %r87, %r103;
(EngineCore_DP0 pid=321570) 	.loc	1 319 22                        // quant_slide_tuned_Llama3.2-1B.py:319:22
(EngineCore_DP0 pid=321570) 	shl.b32 	%r111, %r102, 3;
(EngineCore_DP0 pid=321570) 	shl.b32 	%r112, %r99, 3;
(EngineCore_DP0 pid=321570) 	shl.b32 	%r113, %r96, 3;
(EngineCore_DP0 pid=321570) 	shl.b32 	%r114, %r93, 3;
(EngineCore_DP0 pid=321570) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=321570) 	shl.b32 	%r115, %r110, 1;
(EngineCore_DP0 pid=321570) 	shl.b32 	%r116, %r109, 1;
(EngineCore_DP0 pid=321570) 	shl.b32 	%r117, %r108, 1;
(EngineCore_DP0 pid=321570) 	shl.b32 	%r118, %r107, 1;
(EngineCore_DP0 pid=321570) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=321570) 	add.s32 	%r119, %r114, %r118;
(EngineCore_DP0 pid=321570) 	add.s32 	%r120, %r113, %r117;
(EngineCore_DP0 pid=321570) 	add.s32 	%r121, %r112, %r116;
(EngineCore_DP0 pid=321570) 	add.s32 	%r122, %r111, %r115;
(EngineCore_DP0 pid=321570) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p26, %r122, %r27;
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p27, %r121, %r27;
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p28, %r120, %r27;
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p29, %r119, %r27;
(EngineCore_DP0 pid=321570) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=321570) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=321570) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=321570) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=321570) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=321570) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=321570) 	mad.wide.s32 	%rd8, %r122, 2, %rd1;
(EngineCore_DP0 pid=321570) 	mad.wide.s32 	%rd9, %r121, 2, %rd1;
(EngineCore_DP0 pid=321570) 	mad.wide.s32 	%rd10, %r120, 2, %rd1;
(EngineCore_DP0 pid=321570) 	mad.wide.s32 	%rd11, %r119, 2, %rd1;
(EngineCore_DP0 pid=321570) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=321570) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=321570) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=321570) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=321570) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=321570) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=321570) 	cvt.f32.bf16 	%r123, %rs24;
(EngineCore_DP0 pid=321570) 	cvt.f32.bf16 	%r124, %rs26;
(EngineCore_DP0 pid=321570) 	cvt.f32.bf16 	%r125, %rs28;
(EngineCore_DP0 pid=321570) 	cvt.f32.bf16 	%r126, %rs30;
(EngineCore_DP0 pid=321570) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=321570) 	or.b32 	%r127, %r122, 1;
(EngineCore_DP0 pid=321570) 	or.b32 	%r128, %r121, 1;
(EngineCore_DP0 pid=321570) 	or.b32 	%r129, %r120, 1;
(EngineCore_DP0 pid=321570) 	or.b32 	%r130, %r119, 1;
(EngineCore_DP0 pid=321570) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p30, %r127, %r27;
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p31, %r128, %r27;
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p32, %r129, %r27;
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p33, %r130, %r27;
(EngineCore_DP0 pid=321570) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=321570) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=321570) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=321570) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=321570) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=321570) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=321570) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=321570) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=321570) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=321570) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=321570) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=321570) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=321570) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=321570) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=321570) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=321570) 	cvt.f32.bf16 	%r131, %rs32;
(EngineCore_DP0 pid=321570) 	cvt.f32.bf16 	%r132, %rs34;
(EngineCore_DP0 pid=321570) 	cvt.f32.bf16 	%r133, %rs36;
(EngineCore_DP0 pid=321570) 	cvt.f32.bf16 	%r134, %rs38;
(EngineCore_DP0 pid=321570) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=321570) 	add.s32 	%r135, %r122, 2;
(EngineCore_DP0 pid=321570) 	add.s32 	%r136, %r121, 2;
(EngineCore_DP0 pid=321570) 	add.s32 	%r137, %r120, 2;
(EngineCore_DP0 pid=321570) 	add.s32 	%r138, %r119, 2;
(EngineCore_DP0 pid=321570) 	add.s32 	%r139, %r122, 3;
(EngineCore_DP0 pid=321570) 	add.s32 	%r140, %r121, 3;
(EngineCore_DP0 pid=321570) 	add.s32 	%r141, %r120, 3;
(EngineCore_DP0 pid=321570) 	add.s32 	%r142, %r119, 3;
(EngineCore_DP0 pid=321570) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p34, %r142, %r27;
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p35, %r141, %r27;
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p36, %r140, %r27;
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p37, %r139, %r27;
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p38, %r138, %r27;
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p39, %r137, %r27;
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p40, %r136, %r27;
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p41, %r135, %r27;
(EngineCore_DP0 pid=321570) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=321570) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=321570) 	and.pred 	%p18, %p25, %p40;
(EngineCore_DP0 pid=321570) 	and.pred 	%p19, %p25, %p39;
(EngineCore_DP0 pid=321570) 	and.pred 	%p20, %p25, %p38;
(EngineCore_DP0 pid=321570) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=321570) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=321570) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=321570) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=321570) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=321570) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=321570) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=321570) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=321570) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=321570) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=321570) 	cvt.f32.bf16 	%r143, %rs40;
(EngineCore_DP0 pid=321570) 	cvt.f32.bf16 	%r144, %rs42;
(EngineCore_DP0 pid=321570) 	cvt.f32.bf16 	%r145, %rs44;
(EngineCore_DP0 pid=321570) 	cvt.f32.bf16 	%r146, %rs46;
(EngineCore_DP0 pid=321570) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=321570) 	and.pred 	%p21, %p25, %p37;
(EngineCore_DP0 pid=321570) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=321570) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=321570) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=321570) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=321570) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=321570) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=321570) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=321570) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=321570) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=321570) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=321570) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=321570) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=321570) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=321570) 	cvt.f32.bf16 	%r147, %rs48;
(EngineCore_DP0 pid=321570) 	cvt.f32.bf16 	%r148, %rs50;
(EngineCore_DP0 pid=321570) 	cvt.f32.bf16 	%r149, %rs52;
(EngineCore_DP0 pid=321570) 	cvt.f32.bf16 	%r150, %rs54;
(EngineCore_DP0 pid=321570) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=321570) 	mul.f32 	%r151, %r14, %r123;
(EngineCore_DP0 pid=321570) 	mul.f32 	%r152, %r14, %r124;
(EngineCore_DP0 pid=321570) 	mul.f32 	%r153, %r14, %r125;
(EngineCore_DP0 pid=321570) 	mul.f32 	%r154, %r14, %r126;
(EngineCore_DP0 pid=321570) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=321570) 	cvt.rni.f32.f32 	%r155, %r151;
(EngineCore_DP0 pid=321570) 	cvt.rni.f32.f32 	%r156, %r152;
(EngineCore_DP0 pid=321570) 	cvt.rni.f32.f32 	%r157, %r153;
(EngineCore_DP0 pid=321570) 	cvt.rni.f32.f32 	%r158, %r154;
(EngineCore_DP0 pid=321570) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=321570) 	max.f32 	%r159, %r155, 0fC3000000;
(EngineCore_DP0 pid=321570) 	min.f32 	%r160, %r159, 0f42FE0000;
(EngineCore_DP0 pid=321570) 	max.f32 	%r161, %r156, 0fC3000000;
(EngineCore_DP0 pid=321570) 	min.f32 	%r162, %r161, 0f42FE0000;
(EngineCore_DP0 pid=321570) 	max.f32 	%r163, %r157, 0fC3000000;
(EngineCore_DP0 pid=321570) 	min.f32 	%r164, %r163, 0f42FE0000;
(EngineCore_DP0 pid=321570) 	max.f32 	%r165, %r158, 0fC3000000;
(EngineCore_DP0 pid=321570) 	min.f32 	%r166, %r165, 0f42FE0000;
(EngineCore_DP0 pid=321570) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=321570) 	cvt.rzi.s32.f32 	%r167, %r160;
(EngineCore_DP0 pid=321570) 	cvt.rzi.s32.f32 	%r168, %r162;
(EngineCore_DP0 pid=321570) 	cvt.rzi.s32.f32 	%r169, %r164;
(EngineCore_DP0 pid=321570) 	cvt.rzi.s32.f32 	%r170, %r166;
(EngineCore_DP0 pid=321570) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=321570) 	and.b32 	%r171, %r167, 255;
(EngineCore_DP0 pid=321570) 	and.b32 	%r172, %r168, 255;
(EngineCore_DP0 pid=321570) 	and.b32 	%r173, %r169, 255;
(EngineCore_DP0 pid=321570) 	and.b32 	%r174, %r170, 255;
(EngineCore_DP0 pid=321570) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=321570) 	mul.f32 	%r175, %r14, %r131;
(EngineCore_DP0 pid=321570) 	mul.f32 	%r176, %r14, %r132;
(EngineCore_DP0 pid=321570) 	mul.f32 	%r177, %r14, %r133;
(EngineCore_DP0 pid=321570) 	mul.f32 	%r178, %r14, %r134;
(EngineCore_DP0 pid=321570) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=321570) 	cvt.rni.f32.f32 	%r179, %r175;
(EngineCore_DP0 pid=321570) 	cvt.rni.f32.f32 	%r180, %r176;
(EngineCore_DP0 pid=321570) 	cvt.rni.f32.f32 	%r181, %r177;
(EngineCore_DP0 pid=321570) 	cvt.rni.f32.f32 	%r182, %r178;
(EngineCore_DP0 pid=321570) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=321570) 	mul.f32 	%r183, %r14, %r143;
(EngineCore_DP0 pid=321570) 	mul.f32 	%r184, %r14, %r144;
(EngineCore_DP0 pid=321570) 	mul.f32 	%r185, %r14, %r145;
(EngineCore_DP0 pid=321570) 	mul.f32 	%r186, %r14, %r146;
(EngineCore_DP0 pid=321570) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=321570) 	cvt.rni.f32.f32 	%r187, %r183;
(EngineCore_DP0 pid=321570) 	cvt.rni.f32.f32 	%r188, %r184;
(EngineCore_DP0 pid=321570) 	cvt.rni.f32.f32 	%r189, %r185;
(EngineCore_DP0 pid=321570) 	cvt.rni.f32.f32 	%r190, %r186;
(EngineCore_DP0 pid=321570) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=321570) 	mul.f32 	%r191, %r14, %r147;
(EngineCore_DP0 pid=321570) 	mul.f32 	%r192, %r14, %r148;
(EngineCore_DP0 pid=321570) 	mul.f32 	%r193, %r14, %r149;
(EngineCore_DP0 pid=321570) 	mul.f32 	%r194, %r14, %r150;
(EngineCore_DP0 pid=321570) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=321570) 	cvt.rni.f32.f32 	%r195, %r191;
(EngineCore_DP0 pid=321570) 	cvt.rni.f32.f32 	%r196, %r192;
(EngineCore_DP0 pid=321570) 	cvt.rni.f32.f32 	%r197, %r193;
(EngineCore_DP0 pid=321570) 	cvt.rni.f32.f32 	%r198, %r194;
(EngineCore_DP0 pid=321570) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=321570) 	max.f32 	%r199, %r195, 0fC3000000;
(EngineCore_DP0 pid=321570) 	min.f32 	%r200, %r199, 0f42FE0000;
(EngineCore_DP0 pid=321570) 	max.f32 	%r201, %r196, 0fC3000000;
(EngineCore_DP0 pid=321570) 	min.f32 	%r202, %r201, 0f42FE0000;
(EngineCore_DP0 pid=321570) 	max.f32 	%r203, %r197, 0fC3000000;
(EngineCore_DP0 pid=321570) 	min.f32 	%r204, %r203, 0f42FE0000;
(EngineCore_DP0 pid=321570) 	max.f32 	%r205, %r198, 0fC3000000;
(EngineCore_DP0 pid=321570) 	min.f32 	%r206, %r205, 0f42FE0000;
(EngineCore_DP0 pid=321570) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=321570) 	cvt.rzi.s32.f32 	%r207, %r200;
(EngineCore_DP0 pid=321570) 	cvt.rzi.s32.f32 	%r208, %r202;
(EngineCore_DP0 pid=321570) 	cvt.rzi.s32.f32 	%r209, %r204;
(EngineCore_DP0 pid=321570) 	cvt.rzi.s32.f32 	%r210, %r206;
(EngineCore_DP0 pid=321570) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=321570) 	max.f32 	%r211, %r187, 0fC3000000;
(EngineCore_DP0 pid=321570) 	max.f32 	%r212, %r179, 0fC3000000;
(EngineCore_DP0 pid=321570) 	min.f32 	%r213, %r212, 0f42FE0000;
(EngineCore_DP0 pid=321570) 	min.f32 	%r214, %r211, 0f42FE0000;
(EngineCore_DP0 pid=321570) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=321570) 	cvt.rzi.s32.f32 	%r215, %r214;
(EngineCore_DP0 pid=321570) 	cvt.rzi.s32.f32 	%r216, %r213;
(EngineCore_DP0 pid=321570) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=321570) 	shl.b32 	%r217, %r216, 8;
(EngineCore_DP0 pid=321570) 	shl.b32 	%r218, %r215, 16;
(EngineCore_DP0 pid=321570) 	and.b32 	%r219, %r218, 16711680;
(EngineCore_DP0 pid=321570) 	and.b32 	%r220, %r217, 65280;
(EngineCore_DP0 pid=321570) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=321570) 	or.b32 	%r221, %r220, %r171;
(EngineCore_DP0 pid=321570) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=321570) 	max.f32 	%r222, %r188, 0fC3000000;
(EngineCore_DP0 pid=321570) 	max.f32 	%r223, %r180, 0fC3000000;
(EngineCore_DP0 pid=321570) 	min.f32 	%r224, %r223, 0f42FE0000;
(EngineCore_DP0 pid=321570) 	min.f32 	%r225, %r222, 0f42FE0000;
(EngineCore_DP0 pid=321570) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=321570) 	cvt.rzi.s32.f32 	%r226, %r225;
(EngineCore_DP0 pid=321570) 	cvt.rzi.s32.f32 	%r227, %r224;
(EngineCore_DP0 pid=321570) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=321570) 	shl.b32 	%r228, %r227, 8;
(EngineCore_DP0 pid=321570) 	shl.b32 	%r229, %r226, 16;
(EngineCore_DP0 pid=321570) 	and.b32 	%r230, %r229, 16711680;
(EngineCore_DP0 pid=321570) 	and.b32 	%r231, %r228, 65280;
(EngineCore_DP0 pid=321570) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=321570) 	or.b32 	%r232, %r231, %r172;
(EngineCore_DP0 pid=321570) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=321570) 	max.f32 	%r233, %r189, 0fC3000000;
(EngineCore_DP0 pid=321570) 	max.f32 	%r234, %r181, 0fC3000000;
(EngineCore_DP0 pid=321570) 	min.f32 	%r235, %r234, 0f42FE0000;
(EngineCore_DP0 pid=321570) 	min.f32 	%r236, %r233, 0f42FE0000;
(EngineCore_DP0 pid=321570) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=321570) 	cvt.rzi.s32.f32 	%r237, %r236;
(EngineCore_DP0 pid=321570) 	cvt.rzi.s32.f32 	%r238, %r235;
(EngineCore_DP0 pid=321570) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=321570) 	shl.b32 	%r239, %r238, 8;
(EngineCore_DP0 pid=321570) 	shl.b32 	%r240, %r237, 16;
(EngineCore_DP0 pid=321570) 	and.b32 	%r241, %r240, 16711680;
(EngineCore_DP0 pid=321570) 	and.b32 	%r242, %r239, 65280;
(EngineCore_DP0 pid=321570) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=321570) 	or.b32 	%r243, %r242, %r173;
(EngineCore_DP0 pid=321570) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=321570) 	max.f32 	%r244, %r190, 0fC3000000;
(EngineCore_DP0 pid=321570) 	max.f32 	%r245, %r182, 0fC3000000;
(EngineCore_DP0 pid=321570) 	min.f32 	%r246, %r245, 0f42FE0000;
(EngineCore_DP0 pid=321570) 	min.f32 	%r247, %r244, 0f42FE0000;
(EngineCore_DP0 pid=321570) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=321570) 	cvt.rzi.s32.f32 	%r248, %r247;
(EngineCore_DP0 pid=321570) 	cvt.rzi.s32.f32 	%r249, %r246;
(EngineCore_DP0 pid=321570) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=321570) 	shl.b32 	%r250, %r249, 8;
(EngineCore_DP0 pid=321570) 	shl.b32 	%r251, %r248, 16;
(EngineCore_DP0 pid=321570) 	and.b32 	%r252, %r251, 16711680;
(EngineCore_DP0 pid=321570) 	and.b32 	%r253, %r250, 65280;
(EngineCore_DP0 pid=321570) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=321570) 	or.b32 	%r254, %r253, %r174;
(EngineCore_DP0 pid=321570) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=321570) 	or.b32 	%r255, %r221, %r219;
(EngineCore_DP0 pid=321570) 	or.b32 	%r256, %r232, %r230;
(EngineCore_DP0 pid=321570) 	or.b32 	%r257, %r243, %r241;
(EngineCore_DP0 pid=321570) 	or.b32 	%r258, %r254, %r252;
(EngineCore_DP0 pid=321570) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=321570) 	shl.b32 	%r259, %r207, 24;
(EngineCore_DP0 pid=321570) 	shl.b32 	%r260, %r208, 24;
(EngineCore_DP0 pid=321570) 	shl.b32 	%r261, %r209, 24;
(EngineCore_DP0 pid=321570) 	shl.b32 	%r262, %r210, 24;
(EngineCore_DP0 pid=321570) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=321570) 	or.b32 	%r82, %r255, %r259;
(EngineCore_DP0 pid=321570) 	or.b32 	%r83, %r256, %r260;
(EngineCore_DP0 pid=321570) 	or.b32 	%r84, %r257, %r261;
(EngineCore_DP0 pid=321570) 	or.b32 	%r85, %r258, %r262;
(EngineCore_DP0 pid=321570) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=321570) 	mad.wide.s32 	%rd24, %r87, 4, %rd2;
(EngineCore_DP0 pid=321570) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=321570) 	// begin inline asm
(EngineCore_DP0 pid=321570) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r82, %r83, %r84, %r85 };
(EngineCore_DP0 pid=321570) 	// end inline asm
(EngineCore_DP0 pid=321570) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=321570) 	add.s32 	%r266, %r266, 2048;
(EngineCore_DP0 pid=321570) 	setp.lt.s32 	%p42, %r266, %r15;
(EngineCore_DP0 pid=321570) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=321570) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=321570) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=321570) 	ret;
(EngineCore_DP0 pid=321570) $L__tmp3:
(EngineCore_DP0 pid=321570) $L__func_end0:
(EngineCore_DP0 pid=321570)                                         // -- End function
(EngineCore_DP0 pid=321570) }
(EngineCore_DP0 pid=321570) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=321570) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=321570) 	.section	.debug_abbrev
(EngineCore_DP0 pid=321570) 	{
(EngineCore_DP0 pid=321570) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=321570) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=321570) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=321570) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=321570) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=321570) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=321570) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=321570) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=321570) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=321570) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=321570) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=321570) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=321570) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=321570) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=321570) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=321570) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=321570) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=321570) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=321570) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=321570) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=321570) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=321570) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=321570) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=321570) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=321570) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=321570) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=321570) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=321570) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=321570) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=321570) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=321570) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=321570) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=321570) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=321570) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=321570) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=321570) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=321570) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=321570) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=321570) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=321570) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=321570) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=321570) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=321570) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=321570) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=321570) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=321570) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=321570) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=321570) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=321570) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=321570) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=321570) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=321570) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=321570) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=321570) 	}
(EngineCore_DP0 pid=321570) 	.section	.debug_info
(EngineCore_DP0 pid=321570) 	{
(EngineCore_DP0 pid=321570) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=321570) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=321570) .b8 0
(EngineCore_DP0 pid=321570) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=321570) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=321570) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=321570) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=321570) .b8 114
(EngineCore_DP0 pid=321570) .b8 105
(EngineCore_DP0 pid=321570) .b8 116
(EngineCore_DP0 pid=321570) .b8 111
(EngineCore_DP0 pid=321570) .b8 110
(EngineCore_DP0 pid=321570) .b8 0
(EngineCore_DP0 pid=321570) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=321570) .b8 0
(EngineCore_DP0 pid=321570) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=321570) .b8 117
(EngineCore_DP0 pid=321570) .b8 97
(EngineCore_DP0 pid=321570) .b8 110
(EngineCore_DP0 pid=321570) .b8 116
(EngineCore_DP0 pid=321570) .b8 95
(EngineCore_DP0 pid=321570) .b8 115
(EngineCore_DP0 pid=321570) .b8 108
(EngineCore_DP0 pid=321570) .b8 105
(EngineCore_DP0 pid=321570) .b8 100
(EngineCore_DP0 pid=321570) .b8 101
(EngineCore_DP0 pid=321570) .b8 95
(EngineCore_DP0 pid=321570) .b8 116
(EngineCore_DP0 pid=321570) .b8 117
(EngineCore_DP0 pid=321570) .b8 110
(EngineCore_DP0 pid=321570) .b8 101
(EngineCore_DP0 pid=321570) .b8 100
(EngineCore_DP0 pid=321570) .b8 95
(EngineCore_DP0 pid=321570) .b8 76
(EngineCore_DP0 pid=321570) .b8 108
(EngineCore_DP0 pid=321570) .b8 97
(EngineCore_DP0 pid=321570) .b8 109
(EngineCore_DP0 pid=321570) .b8 97
(EngineCore_DP0 pid=321570) .b8 51
(EngineCore_DP0 pid=321570) .b8 46
(EngineCore_DP0 pid=321570) .b8 50
(EngineCore_DP0 pid=321570) .b8 45
(EngineCore_DP0 pid=321570) .b8 49
(EngineCore_DP0 pid=321570) .b8 66
(EngineCore_DP0 pid=321570) .b8 46
(EngineCore_DP0 pid=321570) .b8 112
(EngineCore_DP0 pid=321570) .b8 121
(EngineCore_DP0 pid=321570) .b8 0
(EngineCore_DP0 pid=321570) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=321570) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=321570) .b8 114
(EngineCore_DP0 pid=321570) .b8 111
(EngineCore_DP0 pid=321570) .b8 111
(EngineCore_DP0 pid=321570) .b8 116
(EngineCore_DP0 pid=321570) .b8 47
(EngineCore_DP0 pid=321570) .b8 118
(EngineCore_DP0 pid=321570) .b8 108
(EngineCore_DP0 pid=321570) .b8 108
(EngineCore_DP0 pid=321570) .b8 109
(EngineCore_DP0 pid=321570) .b8 98
(EngineCore_DP0 pid=321570) .b8 101
(EngineCore_DP0 pid=321570) .b8 110
(EngineCore_DP0 pid=321570) .b8 99
(EngineCore_DP0 pid=321570) .b8 104
(EngineCore_DP0 pid=321570) .b8 47
(EngineCore_DP0 pid=321570) .b8 115
(EngineCore_DP0 pid=321570) .b8 108
(EngineCore_DP0 pid=321570) .b8 105
(EngineCore_DP0 pid=321570) .b8 100
(EngineCore_DP0 pid=321570) .b8 101
(EngineCore_DP0 pid=321570) .b8 115
(EngineCore_DP0 pid=321570) .b8 112
(EngineCore_DP0 pid=321570) .b8 97
(EngineCore_DP0 pid=321570) .b8 114
(EngineCore_DP0 pid=321570) .b8 115
(EngineCore_DP0 pid=321570) .b8 101
(EngineCore_DP0 pid=321570) .b8 47
(EngineCore_DP0 pid=321570) .b8 99
(EngineCore_DP0 pid=321570) .b8 115
(EngineCore_DP0 pid=321570) .b8 114
(EngineCore_DP0 pid=321570) .b8 99
(EngineCore_DP0 pid=321570) .b8 47
(EngineCore_DP0 pid=321570) .b8 102
(EngineCore_DP0 pid=321570) .b8 117
(EngineCore_DP0 pid=321570) .b8 115
(EngineCore_DP0 pid=321570) .b8 101
(EngineCore_DP0 pid=321570) .b8 100
(EngineCore_DP0 pid=321570) .b8 95
(EngineCore_DP0 pid=321570) .b8 113
(EngineCore_DP0 pid=321570) .b8 117
(EngineCore_DP0 pid=321570) .b8 97
(EngineCore_DP0 pid=321570) .b8 110
(EngineCore_DP0 pid=321570) .b8 116
(EngineCore_DP0 pid=321570) .b8 95
(EngineCore_DP0 pid=321570) .b8 115
(EngineCore_DP0 pid=321570) .b8 108
(EngineCore_DP0 pid=321570) .b8 105
(EngineCore_DP0 pid=321570) .b8 100
(EngineCore_DP0 pid=321570) .b8 101
(EngineCore_DP0 pid=321570) .b8 95
(EngineCore_DP0 pid=321570) .b8 116
(EngineCore_DP0 pid=321570) .b8 114
(EngineCore_DP0 pid=321570) .b8 105
(EngineCore_DP0 pid=321570) .b8 116
(EngineCore_DP0 pid=321570) .b8 111
(EngineCore_DP0 pid=321570) .b8 110
(EngineCore_DP0 pid=321570) .b8 47
(EngineCore_DP0 pid=321570) .b8 98
(EngineCore_DP0 pid=321570) .b8 117
(EngineCore_DP0 pid=321570) .b8 105
(EngineCore_DP0 pid=321570) .b8 108
(EngineCore_DP0 pid=321570) .b8 100
(EngineCore_DP0 pid=321570) .b8 47
(EngineCore_DP0 pid=321570) .b8 71
(EngineCore_DP0 pid=321570) .b8 66
(EngineCore_DP0 pid=321570) .b8 49
(EngineCore_DP0 pid=321570) .b8 48
(EngineCore_DP0 pid=321570) .b8 95
(EngineCore_DP0 pid=321570) .b8 99
(EngineCore_DP0 pid=321570) .b8 99
(EngineCore_DP0 pid=321570) .b8 49
(EngineCore_DP0 pid=321570) .b8 50
(EngineCore_DP0 pid=321570) .b8 49
(EngineCore_DP0 pid=321570) .b8 95
(EngineCore_DP0 pid=321570) .b8 112
(EngineCore_DP0 pid=321570) .b8 121
(EngineCore_DP0 pid=321570) .b8 51
(EngineCore_DP0 pid=321570) .b8 49
(EngineCore_DP0 pid=321570) .b8 50
(EngineCore_DP0 pid=321570) .b8 95
(EngineCore_DP0 pid=321570) .b8 99
(EngineCore_DP0 pid=321570) .b8 117
(EngineCore_DP0 pid=321570) .b8 49
(EngineCore_DP0 pid=321570) .b8 50
(EngineCore_DP0 pid=321570) .b8 57
(EngineCore_DP0 pid=321570) .b8 95
(EngineCore_DP0 pid=321570) .b8 97
(EngineCore_DP0 pid=321570) .b8 97
(EngineCore_DP0 pid=321570) .b8 114
(EngineCore_DP0 pid=321570) .b8 99
(EngineCore_DP0 pid=321570) .b8 104
(EngineCore_DP0 pid=321570) .b8 54
(EngineCore_DP0 pid=321570) .b8 52
(EngineCore_DP0 pid=321570) .b8 0
(EngineCore_DP0 pid=321570) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=321570) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=321570) .b8 113
(EngineCore_DP0 pid=321570) .b8 117
(EngineCore_DP0 pid=321570) .b8 97
(EngineCore_DP0 pid=321570) .b8 110
(EngineCore_DP0 pid=321570) .b8 116
(EngineCore_DP0 pid=321570) .b8 95
(EngineCore_DP0 pid=321570) .b8 115
(EngineCore_DP0 pid=321570) .b8 108
(EngineCore_DP0 pid=321570) .b8 105
(EngineCore_DP0 pid=321570) .b8 100
(EngineCore_DP0 pid=321570) .b8 101
(EngineCore_DP0 pid=321570) .b8 95
(EngineCore_DP0 pid=321570) .b8 105
(EngineCore_DP0 pid=321570) .b8 110
(EngineCore_DP0 pid=321570) .b8 116
(EngineCore_DP0 pid=321570) .b8 56
(EngineCore_DP0 pid=321570) .b8 95
(EngineCore_DP0 pid=321570) .b8 107
(EngineCore_DP0 pid=321570) .b8 101
(EngineCore_DP0 pid=321570) .b8 114
(EngineCore_DP0 pid=321570) .b8 110
(EngineCore_DP0 pid=321570) .b8 101
(EngineCore_DP0 pid=321570) .b8 108
(EngineCore_DP0 pid=321570) .b8 0
(EngineCore_DP0 pid=321570) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=321570) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=321570) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=321570) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=321570) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=321570) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=321570) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=321570) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=321570) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=321570) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=321570) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=321570) .b8 1
(EngineCore_DP0 pid=321570) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=321570) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=321570) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=321570) 	}
(EngineCore_DP0 pid=321570) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=321570) 
(EngineCore_DP0 pid=321570) ================================================================
(EngineCore_DP0 pid=321570) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=321570) 
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmps2q4v6hn.ptx', '-o', '/tmp/tmps2q4v6hn.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866] 
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866] 
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866] 
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmps2q4v6hn.ptx -o /tmp/tmps2q4v6hn.ptx.o
(EngineCore_DP0 pid=321570) ERROR 01-25 19:04:15 [core.py:866] 

STDERR:
[2026-01-25 19:03:59] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:03:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:03:59] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:03:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:03:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:03:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:03:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:03:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:03:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:03:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:04:02] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:04:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:04:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:04:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:04:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:04:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:04:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:04:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:04:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:04:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:04:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:04:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:04:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:04:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=321570) [2026-01-25 19:04:03] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=321570) [2026-01-25 19:04:03] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=321570) [2026-01-25 19:04:03] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=321570) [2026-01-25 19:04:03] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=321570) [2026-01-25 19:04:03] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=321570) [2026-01-25 19:04:03] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=321570) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=321570) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.74s/it]
(EngineCore_DP0 pid=321570) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.74s/it]
(EngineCore_DP0 pid=321570) 
(EngineCore_DP0 pid=321570) [2026-01-25 19:04:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=321570) [2026-01-25 19:04:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=321570) [2026-01-25 19:04:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=321570) [2026-01-25 19:04:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=321570) [2026-01-25 19:04:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=321570) [2026-01-25 19:04:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=321570) [2026-01-25 19:04:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=321570) [2026-01-25 19:04:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=321570) Process EngineCore_DP0:
(EngineCore_DP0 pid=321570) Traceback (most recent call last):
(EngineCore_DP0 pid=321570)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=321570)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=321570)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=321570)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=321570) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmps2q4v6hn.ptx', '-o', '/tmp/tmps2q4v6hn.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=321570) 
(EngineCore_DP0 pid=321570) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=321570) 
(EngineCore_DP0 pid=321570) Traceback (most recent call last):
(EngineCore_DP0 pid=321570)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=321570)     self.run()
(EngineCore_DP0 pid=321570)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=321570)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=321570)     raise e
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=321570)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=321570)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=321570)     super().__init__(
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=321570)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=321570)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=321570)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=321570)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=321570)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=321570)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=321570)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=321570)     return func(*args, **kwargs)
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=321570)     return func(*args, **kwargs)
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=321570)     self.model_runner.profile_run()
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=321570)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=321570)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=321570)     return func(*args, **kwargs)
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=321570)     outputs = self.model(
(EngineCore_DP0 pid=321570)               ^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=321570)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=321570)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=321570)     model_output = self.model(
(EngineCore_DP0 pid=321570)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=321570)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=321570)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=321570)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=321570)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=321570)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=321570)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=321570)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=321570)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=321570)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=321570)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=321570)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=321570)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=321570)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=321570)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=321570)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=321570)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=321570)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=321570)     return self._linear_fn(
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=321570)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=321570)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=321570)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=321570)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=321570)     return fn(input, L)
(EngineCore_DP0 pid=321570)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=321570)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=321570)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=321570)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=321570)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=321570)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=321570)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=321570)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=321570)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=321570)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=321570)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=321570)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=321570)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=321570)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=321570)     raise PTXASError(error)
(EngineCore_DP0 pid=321570) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=321570) `ptxas` stderr:
(EngineCore_DP0 pid=321570) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=321570) 
(EngineCore_DP0 pid=321570) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmps2q4v6hn.ptx -o /tmp/tmps2q4v6hn.ptx.o
(EngineCore_DP0 pid=321570) 
[rank0]:[W125 19:04:16.260688123 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 19:04:17
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:04:26 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:04:26 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=322163) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=322163) 
(EngineCore_DP0 pid=322163) 
(EngineCore_DP0 pid=322163) ================================================================
(EngineCore_DP0 pid=322163) Internal Triton PTX codegen error
(EngineCore_DP0 pid=322163) `ptxas` stderr:
(EngineCore_DP0 pid=322163) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=322163) 
(EngineCore_DP0 pid=322163) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmphyz9n7ut.ptx -o /tmp/tmphyz9n7ut.ptx.o
(EngineCore_DP0 pid=322163) 
(EngineCore_DP0 pid=322163) 
(EngineCore_DP0 pid=322163) //
(EngineCore_DP0 pid=322163) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=322163) //
(EngineCore_DP0 pid=322163) 
(EngineCore_DP0 pid=322163) .version 8.7
(EngineCore_DP0 pid=322163) .target sm_121a
(EngineCore_DP0 pid=322163) .address_size 64
(EngineCore_DP0 pid=322163) 
(EngineCore_DP0 pid=322163) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=322163) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=322163)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=322163) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=322163) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=322163) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=322163) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=322163) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=322163) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=322163) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=322163) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=322163) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=322163) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=322163) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=322163) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=322163) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=322163) )
(EngineCore_DP0 pid=322163) .reqntid 512
(EngineCore_DP0 pid=322163) {
(EngineCore_DP0 pid=322163) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=322163) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=322163) 	.reg .b32 	%r<267>;
(EngineCore_DP0 pid=322163) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=322163) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=322163) $L__func_begin0:
(EngineCore_DP0 pid=322163) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=322163) 
(EngineCore_DP0 pid=322163) // %bb.0:
(EngineCore_DP0 pid=322163) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=322163) 	ld.param.b32 	%r28, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=322163) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=322163) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=322163) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=322163) $L__tmp0:
(EngineCore_DP0 pid=322163) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=322163) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=322163) 	ld.param.b32 	%r31, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=322163) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=322163) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=322163) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=322163) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=322163) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=322163) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=322163) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=322163) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=322163) 	mov.b32 	%r265, 0f2B8CBCCC;
(EngineCore_DP0 pid=322163) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=322163) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=322163) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=322163) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=322163) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=322163) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=322163) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=322163) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=322163) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=322163) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=322163) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=322163) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=322163) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=322163) 	mov.b32 	%r263, 0f00000000;
(EngineCore_DP0 pid=322163) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=322163) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=322163) 	mov.b32 	%r264, %r49;
(EngineCore_DP0 pid=322163) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=322163) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=322163) 	add.s32 	%r59, %r4, %r264;
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=322163) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=322163) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=322163) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=322163) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=322163) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=322163) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=322163) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=322163) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=322163) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=322163) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=322163) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=322163) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=322163) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=322163) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=322163) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=322163) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=322163) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=322163) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=322163) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=322163) $L__tmp1:
(EngineCore_DP0 pid=322163) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	bar.sync 	0;
(EngineCore_DP0 pid=322163) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=322163) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=322163) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=322163) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=322163) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=322163) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=322163) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=322163) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=322163) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=322163) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=322163) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=322163) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=322163) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=322163) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=322163) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=322163) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=322163) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=322163) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=322163) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	bar.sync 	0;
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=322163) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=322163) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=322163) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=322163) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=322163) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=322163) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=322163) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=322163) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	bar.sync 	0;
(EngineCore_DP0 pid=322163) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=322163) $L__tmp2:
(EngineCore_DP0 pid=322163) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=322163) 	max.f32 	%r263, %r263, %r77;
(EngineCore_DP0 pid=322163) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=322163) 	add.s32 	%r264, %r264, 4096;
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p6, %r264, %r28;
(EngineCore_DP0 pid=322163) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=322163) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=322163) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=322163) 	max.f32 	%r265, %r263, 0f2B8CBCCC;
(EngineCore_DP0 pid=322163) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=322163) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=322163) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=322163) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=322163) 	div.full.f32 	%r80, %r265, %r79;
(EngineCore_DP0 pid=322163) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=322163) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=322163) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=322163) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=322163) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=322163) 	mul.lo.s32 	%r15, %r29, 3;
(EngineCore_DP0 pid=322163) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=322163) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=322163) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=322163) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=322163) 	ld.param.b32 	%r33, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=322163) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=322163) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=322163) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=322163) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=322163) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=322163) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=322163) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=322163) 	div.full.f32 	%r14, %r79, %r265;
(EngineCore_DP0 pid=322163) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=322163) 	mov.b32 	%r266, 0;
(EngineCore_DP0 pid=322163) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=322163)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=322163) 	.loc	1 313 31                        // quant_slide_tuned_Llama3.2-1B.py:313:31
(EngineCore_DP0 pid=322163) 	add.s32 	%r87, %r16, %r266;
(EngineCore_DP0 pid=322163) 	add.s32 	%r88, %r87, 1;
(EngineCore_DP0 pid=322163) 	add.s32 	%r89, %r87, 2;
(EngineCore_DP0 pid=322163) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=322163) 	add.s32 	%r90, %r87, 3;
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p25, %r87, %r15;
(EngineCore_DP0 pid=322163) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=322163) 	mul.hi.s32 	%r91, %r90, 1431655766;
(EngineCore_DP0 pid=322163) 	shr.u32 	%r92, %r91, 31;
(EngineCore_DP0 pid=322163) 	add.s32 	%r93, %r91, %r92;
(EngineCore_DP0 pid=322163) 	mul.hi.s32 	%r94, %r89, 1431655766;
(EngineCore_DP0 pid=322163) 	shr.u32 	%r95, %r94, 31;
(EngineCore_DP0 pid=322163) 	add.s32 	%r96, %r94, %r95;
(EngineCore_DP0 pid=322163) 	mul.hi.s32 	%r97, %r88, 1431655766;
(EngineCore_DP0 pid=322163) 	shr.u32 	%r98, %r97, 31;
(EngineCore_DP0 pid=322163) 	add.s32 	%r99, %r97, %r98;
(EngineCore_DP0 pid=322163) 	mul.hi.s32 	%r100, %r87, 1431655766;
(EngineCore_DP0 pid=322163) 	shr.u32 	%r101, %r100, 31;
(EngineCore_DP0 pid=322163) 	add.s32 	%r102, %r100, %r101;
(EngineCore_DP0 pid=322163) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=322163) 	mul.lo.s32 	%r103, %r102, 3;
(EngineCore_DP0 pid=322163) 	mul.lo.s32 	%r104, %r99, 3;
(EngineCore_DP0 pid=322163) 	mul.lo.s32 	%r105, %r96, 3;
(EngineCore_DP0 pid=322163) 	mul.lo.s32 	%r106, %r93, 3;
(EngineCore_DP0 pid=322163) 	sub.s32 	%r107, %r90, %r106;
(EngineCore_DP0 pid=322163) 	sub.s32 	%r108, %r89, %r105;
(EngineCore_DP0 pid=322163) 	sub.s32 	%r109, %r88, %r104;
(EngineCore_DP0 pid=322163) 	sub.s32 	%r110, %r87, %r103;
(EngineCore_DP0 pid=322163) 	.loc	1 319 22                        // quant_slide_tuned_Llama3.2-1B.py:319:22
(EngineCore_DP0 pid=322163) 	shl.b32 	%r111, %r102, 3;
(EngineCore_DP0 pid=322163) 	shl.b32 	%r112, %r99, 3;
(EngineCore_DP0 pid=322163) 	shl.b32 	%r113, %r96, 3;
(EngineCore_DP0 pid=322163) 	shl.b32 	%r114, %r93, 3;
(EngineCore_DP0 pid=322163) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=322163) 	shl.b32 	%r115, %r110, 1;
(EngineCore_DP0 pid=322163) 	shl.b32 	%r116, %r109, 1;
(EngineCore_DP0 pid=322163) 	shl.b32 	%r117, %r108, 1;
(EngineCore_DP0 pid=322163) 	shl.b32 	%r118, %r107, 1;
(EngineCore_DP0 pid=322163) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=322163) 	add.s32 	%r119, %r114, %r118;
(EngineCore_DP0 pid=322163) 	add.s32 	%r120, %r113, %r117;
(EngineCore_DP0 pid=322163) 	add.s32 	%r121, %r112, %r116;
(EngineCore_DP0 pid=322163) 	add.s32 	%r122, %r111, %r115;
(EngineCore_DP0 pid=322163) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p26, %r122, %r27;
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p27, %r121, %r27;
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p28, %r120, %r27;
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p29, %r119, %r27;
(EngineCore_DP0 pid=322163) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=322163) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=322163) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=322163) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=322163) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=322163) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=322163) 	mad.wide.s32 	%rd8, %r122, 2, %rd1;
(EngineCore_DP0 pid=322163) 	mad.wide.s32 	%rd9, %r121, 2, %rd1;
(EngineCore_DP0 pid=322163) 	mad.wide.s32 	%rd10, %r120, 2, %rd1;
(EngineCore_DP0 pid=322163) 	mad.wide.s32 	%rd11, %r119, 2, %rd1;
(EngineCore_DP0 pid=322163) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=322163) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=322163) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=322163) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=322163) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=322163) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=322163) 	cvt.f32.bf16 	%r123, %rs24;
(EngineCore_DP0 pid=322163) 	cvt.f32.bf16 	%r124, %rs26;
(EngineCore_DP0 pid=322163) 	cvt.f32.bf16 	%r125, %rs28;
(EngineCore_DP0 pid=322163) 	cvt.f32.bf16 	%r126, %rs30;
(EngineCore_DP0 pid=322163) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=322163) 	or.b32 	%r127, %r122, 1;
(EngineCore_DP0 pid=322163) 	or.b32 	%r128, %r121, 1;
(EngineCore_DP0 pid=322163) 	or.b32 	%r129, %r120, 1;
(EngineCore_DP0 pid=322163) 	or.b32 	%r130, %r119, 1;
(EngineCore_DP0 pid=322163) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p30, %r127, %r27;
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p31, %r128, %r27;
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p32, %r129, %r27;
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p33, %r130, %r27;
(EngineCore_DP0 pid=322163) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=322163) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=322163) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=322163) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=322163) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=322163) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=322163) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=322163) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=322163) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=322163) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=322163) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=322163) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=322163) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=322163) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=322163) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=322163) 	cvt.f32.bf16 	%r131, %rs32;
(EngineCore_DP0 pid=322163) 	cvt.f32.bf16 	%r132, %rs34;
(EngineCore_DP0 pid=322163) 	cvt.f32.bf16 	%r133, %rs36;
(EngineCore_DP0 pid=322163) 	cvt.f32.bf16 	%r134, %rs38;
(EngineCore_DP0 pid=322163) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=322163) 	add.s32 	%r135, %r122, 2;
(EngineCore_DP0 pid=322163) 	add.s32 	%r136, %r121, 2;
(EngineCore_DP0 pid=322163) 	add.s32 	%r137, %r120, 2;
(EngineCore_DP0 pid=322163) 	add.s32 	%r138, %r119, 2;
(EngineCore_DP0 pid=322163) 	add.s32 	%r139, %r122, 3;
(EngineCore_DP0 pid=322163) 	add.s32 	%r140, %r121, 3;
(EngineCore_DP0 pid=322163) 	add.s32 	%r141, %r120, 3;
(EngineCore_DP0 pid=322163) 	add.s32 	%r142, %r119, 3;
(EngineCore_DP0 pid=322163) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p34, %r142, %r27;
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p35, %r141, %r27;
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p36, %r140, %r27;
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p37, %r139, %r27;
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p38, %r138, %r27;
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p39, %r137, %r27;
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p40, %r136, %r27;
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p41, %r135, %r27;
(EngineCore_DP0 pid=322163) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=322163) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=322163) 	and.pred 	%p18, %p25, %p40;
(EngineCore_DP0 pid=322163) 	and.pred 	%p19, %p25, %p39;
(EngineCore_DP0 pid=322163) 	and.pred 	%p20, %p25, %p38;
(EngineCore_DP0 pid=322163) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=322163) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=322163) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=322163) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=322163) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=322163) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=322163) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=322163) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=322163) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=322163) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=322163) 	cvt.f32.bf16 	%r143, %rs40;
(EngineCore_DP0 pid=322163) 	cvt.f32.bf16 	%r144, %rs42;
(EngineCore_DP0 pid=322163) 	cvt.f32.bf16 	%r145, %rs44;
(EngineCore_DP0 pid=322163) 	cvt.f32.bf16 	%r146, %rs46;
(EngineCore_DP0 pid=322163) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=322163) 	and.pred 	%p21, %p25, %p37;
(EngineCore_DP0 pid=322163) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=322163) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=322163) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=322163) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=322163) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=322163) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=322163) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=322163) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=322163) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=322163) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=322163) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=322163) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=322163) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=322163) 	cvt.f32.bf16 	%r147, %rs48;
(EngineCore_DP0 pid=322163) 	cvt.f32.bf16 	%r148, %rs50;
(EngineCore_DP0 pid=322163) 	cvt.f32.bf16 	%r149, %rs52;
(EngineCore_DP0 pid=322163) 	cvt.f32.bf16 	%r150, %rs54;
(EngineCore_DP0 pid=322163) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=322163) 	mul.f32 	%r151, %r14, %r123;
(EngineCore_DP0 pid=322163) 	mul.f32 	%r152, %r14, %r124;
(EngineCore_DP0 pid=322163) 	mul.f32 	%r153, %r14, %r125;
(EngineCore_DP0 pid=322163) 	mul.f32 	%r154, %r14, %r126;
(EngineCore_DP0 pid=322163) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=322163) 	cvt.rni.f32.f32 	%r155, %r151;
(EngineCore_DP0 pid=322163) 	cvt.rni.f32.f32 	%r156, %r152;
(EngineCore_DP0 pid=322163) 	cvt.rni.f32.f32 	%r157, %r153;
(EngineCore_DP0 pid=322163) 	cvt.rni.f32.f32 	%r158, %r154;
(EngineCore_DP0 pid=322163) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=322163) 	max.f32 	%r159, %r155, 0fC3000000;
(EngineCore_DP0 pid=322163) 	min.f32 	%r160, %r159, 0f42FE0000;
(EngineCore_DP0 pid=322163) 	max.f32 	%r161, %r156, 0fC3000000;
(EngineCore_DP0 pid=322163) 	min.f32 	%r162, %r161, 0f42FE0000;
(EngineCore_DP0 pid=322163) 	max.f32 	%r163, %r157, 0fC3000000;
(EngineCore_DP0 pid=322163) 	min.f32 	%r164, %r163, 0f42FE0000;
(EngineCore_DP0 pid=322163) 	max.f32 	%r165, %r158, 0fC3000000;
(EngineCore_DP0 pid=322163) 	min.f32 	%r166, %r165, 0f42FE0000;
(EngineCore_DP0 pid=322163) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=322163) 	cvt.rzi.s32.f32 	%r167, %r160;
(EngineCore_DP0 pid=322163) 	cvt.rzi.s32.f32 	%r168, %r162;
(EngineCore_DP0 pid=322163) 	cvt.rzi.s32.f32 	%r169, %r164;
(EngineCore_DP0 pid=322163) 	cvt.rzi.s32.f32 	%r170, %r166;
(EngineCore_DP0 pid=322163) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=322163) 	and.b32 	%r171, %r167, 255;
(EngineCore_DP0 pid=322163) 	and.b32 	%r172, %r168, 255;
(EngineCore_DP0 pid=322163) 	and.b32 	%r173, %r169, 255;
(EngineCore_DP0 pid=322163) 	and.b32 	%r174, %r170, 255;
(EngineCore_DP0 pid=322163) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=322163) 	mul.f32 	%r175, %r14, %r131;
(EngineCore_DP0 pid=322163) 	mul.f32 	%r176, %r14, %r132;
(EngineCore_DP0 pid=322163) 	mul.f32 	%r177, %r14, %r133;
(EngineCore_DP0 pid=322163) 	mul.f32 	%r178, %r14, %r134;
(EngineCore_DP0 pid=322163) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=322163) 	cvt.rni.f32.f32 	%r179, %r175;
(EngineCore_DP0 pid=322163) 	cvt.rni.f32.f32 	%r180, %r176;
(EngineCore_DP0 pid=322163) 	cvt.rni.f32.f32 	%r181, %r177;
(EngineCore_DP0 pid=322163) 	cvt.rni.f32.f32 	%r182, %r178;
(EngineCore_DP0 pid=322163) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=322163) 	mul.f32 	%r183, %r14, %r143;
(EngineCore_DP0 pid=322163) 	mul.f32 	%r184, %r14, %r144;
(EngineCore_DP0 pid=322163) 	mul.f32 	%r185, %r14, %r145;
(EngineCore_DP0 pid=322163) 	mul.f32 	%r186, %r14, %r146;
(EngineCore_DP0 pid=322163) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=322163) 	cvt.rni.f32.f32 	%r187, %r183;
(EngineCore_DP0 pid=322163) 	cvt.rni.f32.f32 	%r188, %r184;
(EngineCore_DP0 pid=322163) 	cvt.rni.f32.f32 	%r189, %r185;
(EngineCore_DP0 pid=322163) 	cvt.rni.f32.f32 	%r190, %r186;
(EngineCore_DP0 pid=322163) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=322163) 	mul.f32 	%r191, %r14, %r147;
(EngineCore_DP0 pid=322163) 	mul.f32 	%r192, %r14, %r148;
(EngineCore_DP0 pid=322163) 	mul.f32 	%r193, %r14, %r149;
(EngineCore_DP0 pid=322163) 	mul.f32 	%r194, %r14, %r150;
(EngineCore_DP0 pid=322163) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=322163) 	cvt.rni.f32.f32 	%r195, %r191;
(EngineCore_DP0 pid=322163) 	cvt.rni.f32.f32 	%r196, %r192;
(EngineCore_DP0 pid=322163) 	cvt.rni.f32.f32 	%r197, %r193;
(EngineCore_DP0 pid=322163) 	cvt.rni.f32.f32 	%r198, %r194;
(EngineCore_DP0 pid=322163) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=322163) 	max.f32 	%r199, %r195, 0fC3000000;
(EngineCore_DP0 pid=322163) 	min.f32 	%r200, %r199, 0f42FE0000;
(EngineCore_DP0 pid=322163) 	max.f32 	%r201, %r196, 0fC3000000;
(EngineCore_DP0 pid=322163) 	min.f32 	%r202, %r201, 0f42FE0000;
(EngineCore_DP0 pid=322163) 	max.f32 	%r203, %r197, 0fC3000000;
(EngineCore_DP0 pid=322163) 	min.f32 	%r204, %r203, 0f42FE0000;
(EngineCore_DP0 pid=322163) 	max.f32 	%r205, %r198, 0fC3000000;
(EngineCore_DP0 pid=322163) 	min.f32 	%r206, %r205, 0f42FE0000;
(EngineCore_DP0 pid=322163) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=322163) 	cvt.rzi.s32.f32 	%r207, %r200;
(EngineCore_DP0 pid=322163) 	cvt.rzi.s32.f32 	%r208, %r202;
(EngineCore_DP0 pid=322163) 	cvt.rzi.s32.f32 	%r209, %r204;
(EngineCore_DP0 pid=322163) 	cvt.rzi.s32.f32 	%r210, %r206;
(EngineCore_DP0 pid=322163) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=322163) 	max.f32 	%r211, %r187, 0fC3000000;
(EngineCore_DP0 pid=322163) 	max.f32 	%r212, %r179, 0fC3000000;
(EngineCore_DP0 pid=322163) 	min.f32 	%r213, %r212, 0f42FE0000;
(EngineCore_DP0 pid=322163) 	min.f32 	%r214, %r211, 0f42FE0000;
(EngineCore_DP0 pid=322163) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=322163) 	cvt.rzi.s32.f32 	%r215, %r214;
(EngineCore_DP0 pid=322163) 	cvt.rzi.s32.f32 	%r216, %r213;
(EngineCore_DP0 pid=322163) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=322163) 	shl.b32 	%r217, %r216, 8;
(EngineCore_DP0 pid=322163) 	shl.b32 	%r218, %r215, 16;
(EngineCore_DP0 pid=322163) 	and.b32 	%r219, %r218, 16711680;
(EngineCore_DP0 pid=322163) 	and.b32 	%r220, %r217, 65280;
(EngineCore_DP0 pid=322163) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=322163) 	or.b32 	%r221, %r220, %r171;
(EngineCore_DP0 pid=322163) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=322163) 	max.f32 	%r222, %r188, 0fC3000000;
(EngineCore_DP0 pid=322163) 	max.f32 	%r223, %r180, 0fC3000000;
(EngineCore_DP0 pid=322163) 	min.f32 	%r224, %r223, 0f42FE0000;
(EngineCore_DP0 pid=322163) 	min.f32 	%r225, %r222, 0f42FE0000;
(EngineCore_DP0 pid=322163) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=322163) 	cvt.rzi.s32.f32 	%r226, %r225;
(EngineCore_DP0 pid=322163) 	cvt.rzi.s32.f32 	%r227, %r224;
(EngineCore_DP0 pid=322163) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=322163) 	shl.b32 	%r228, %r227, 8;
(EngineCore_DP0 pid=322163) 	shl.b32 	%r229, %r226, 16;
(EngineCore_DP0 pid=322163) 	and.b32 	%r230, %r229, 16711680;
(EngineCore_DP0 pid=322163) 	and.b32 	%r231, %r228, 65280;
(EngineCore_DP0 pid=322163) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=322163) 	or.b32 	%r232, %r231, %r172;
(EngineCore_DP0 pid=322163) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=322163) 	max.f32 	%r233, %r189, 0fC3000000;
(EngineCore_DP0 pid=322163) 	max.f32 	%r234, %r181, 0fC3000000;
(EngineCore_DP0 pid=322163) 	min.f32 	%r235, %r234, 0f42FE0000;
(EngineCore_DP0 pid=322163) 	min.f32 	%r236, %r233, 0f42FE0000;
(EngineCore_DP0 pid=322163) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=322163) 	cvt.rzi.s32.f32 	%r237, %r236;
(EngineCore_DP0 pid=322163) 	cvt.rzi.s32.f32 	%r238, %r235;
(EngineCore_DP0 pid=322163) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=322163) 	shl.b32 	%r239, %r238, 8;
(EngineCore_DP0 pid=322163) 	shl.b32 	%r240, %r237, 16;
(EngineCore_DP0 pid=322163) 	and.b32 	%r241, %r240, 16711680;
(EngineCore_DP0 pid=322163) 	and.b32 	%r242, %r239, 65280;
(EngineCore_DP0 pid=322163) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=322163) 	or.b32 	%r243, %r242, %r173;
(EngineCore_DP0 pid=322163) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=322163) 	max.f32 	%r244, %r190, 0fC3000000;
(EngineCore_DP0 pid=322163) 	max.f32 	%r245, %r182, 0fC3000000;
(EngineCore_DP0 pid=322163) 	min.f32 	%r246, %r245, 0f42FE0000;
(EngineCore_DP0 pid=322163) 	min.f32 	%r247, %r244, 0f42FE0000;
(EngineCore_DP0 pid=322163) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=322163) 	cvt.rzi.s32.f32 	%r248, %r247;
(EngineCore_DP0 pid=322163) 	cvt.rzi.s32.f32 	%r249, %r246;
(EngineCore_DP0 pid=322163) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=322163) 	shl.b32 	%r250, %r249, 8;
(EngineCore_DP0 pid=322163) 	shl.b32 	%r251, %r248, 16;
(EngineCore_DP0 pid=322163) 	and.b32 	%r252, %r251, 16711680;
(EngineCore_DP0 pid=322163) 	and.b32 	%r253, %r250, 65280;
(EngineCore_DP0 pid=322163) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=322163) 	or.b32 	%r254, %r253, %r174;
(EngineCore_DP0 pid=322163) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=322163) 	or.b32 	%r255, %r221, %r219;
(EngineCore_DP0 pid=322163) 	or.b32 	%r256, %r232, %r230;
(EngineCore_DP0 pid=322163) 	or.b32 	%r257, %r243, %r241;
(EngineCore_DP0 pid=322163) 	or.b32 	%r258, %r254, %r252;
(EngineCore_DP0 pid=322163) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=322163) 	shl.b32 	%r259, %r207, 24;
(EngineCore_DP0 pid=322163) 	shl.b32 	%r260, %r208, 24;
(EngineCore_DP0 pid=322163) 	shl.b32 	%r261, %r209, 24;
(EngineCore_DP0 pid=322163) 	shl.b32 	%r262, %r210, 24;
(EngineCore_DP0 pid=322163) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=322163) 	or.b32 	%r82, %r255, %r259;
(EngineCore_DP0 pid=322163) 	or.b32 	%r83, %r256, %r260;
(EngineCore_DP0 pid=322163) 	or.b32 	%r84, %r257, %r261;
(EngineCore_DP0 pid=322163) 	or.b32 	%r85, %r258, %r262;
(EngineCore_DP0 pid=322163) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=322163) 	mad.wide.s32 	%rd24, %r87, 4, %rd2;
(EngineCore_DP0 pid=322163) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=322163) 	// begin inline asm
(EngineCore_DP0 pid=322163) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r82, %r83, %r84, %r85 };
(EngineCore_DP0 pid=322163) 	// end inline asm
(EngineCore_DP0 pid=322163) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=322163) 	add.s32 	%r266, %r266, 2048;
(EngineCore_DP0 pid=322163) 	setp.lt.s32 	%p42, %r266, %r15;
(EngineCore_DP0 pid=322163) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=322163) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=322163) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=322163) 	ret;
(EngineCore_DP0 pid=322163) $L__tmp3:
(EngineCore_DP0 pid=322163) $L__func_end0:
(EngineCore_DP0 pid=322163)                                         // -- End function
(EngineCore_DP0 pid=322163) }
(EngineCore_DP0 pid=322163) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=322163) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=322163) 	.section	.debug_abbrev
(EngineCore_DP0 pid=322163) 	{
(EngineCore_DP0 pid=322163) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=322163) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=322163) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=322163) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=322163) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=322163) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=322163) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=322163) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=322163) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=322163) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=322163) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=322163) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=322163) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=322163) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=322163) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=322163) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=322163) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=322163) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=322163) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=322163) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=322163) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=322163) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=322163) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=322163) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=322163) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=322163) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=322163) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=322163) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=322163) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=322163) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=322163) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=322163) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=322163) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=322163) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=322163) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=322163) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=322163) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=322163) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=322163) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=322163) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=322163) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=322163) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=322163) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=322163) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=322163) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=322163) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=322163) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=322163) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=322163) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=322163) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=322163) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=322163) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=322163) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=322163) 	}
(EngineCore_DP0 pid=322163) 	.section	.debug_info
(EngineCore_DP0 pid=322163) 	{
(EngineCore_DP0 pid=322163) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=322163) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=322163) .b8 0
(EngineCore_DP0 pid=322163) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=322163) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=322163) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=322163) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=322163) .b8 114
(EngineCore_DP0 pid=322163) .b8 105
(EngineCore_DP0 pid=322163) .b8 116
(EngineCore_DP0 pid=322163) .b8 111
(EngineCore_DP0 pid=322163) .b8 110
(EngineCore_DP0 pid=322163) .b8 0
(EngineCore_DP0 pid=322163) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=322163) .b8 0
(EngineCore_DP0 pid=322163) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=322163) .b8 117
(EngineCore_DP0 pid=322163) .b8 97
(EngineCore_DP0 pid=322163) .b8 110
(EngineCore_DP0 pid=322163) .b8 116
(EngineCore_DP0 pid=322163) .b8 95
(EngineCore_DP0 pid=322163) .b8 115
(EngineCore_DP0 pid=322163) .b8 108
(EngineCore_DP0 pid=322163) .b8 105
(EngineCore_DP0 pid=322163) .b8 100
(EngineCore_DP0 pid=322163) .b8 101
(EngineCore_DP0 pid=322163) .b8 95
(EngineCore_DP0 pid=322163) .b8 116
(EngineCore_DP0 pid=322163) .b8 117
(EngineCore_DP0 pid=322163) .b8 110
(EngineCore_DP0 pid=322163) .b8 101
(EngineCore_DP0 pid=322163) .b8 100
(EngineCore_DP0 pid=322163) .b8 95
(EngineCore_DP0 pid=322163) .b8 76
(EngineCore_DP0 pid=322163) .b8 108
(EngineCore_DP0 pid=322163) .b8 97
(EngineCore_DP0 pid=322163) .b8 109
(EngineCore_DP0 pid=322163) .b8 97
(EngineCore_DP0 pid=322163) .b8 51
(EngineCore_DP0 pid=322163) .b8 46
(EngineCore_DP0 pid=322163) .b8 50
(EngineCore_DP0 pid=322163) .b8 45
(EngineCore_DP0 pid=322163) .b8 49
(EngineCore_DP0 pid=322163) .b8 66
(EngineCore_DP0 pid=322163) .b8 46
(EngineCore_DP0 pid=322163) .b8 112
(EngineCore_DP0 pid=322163) .b8 121
(EngineCore_DP0 pid=322163) .b8 0
(EngineCore_DP0 pid=322163) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=322163) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=322163) .b8 114
(EngineCore_DP0 pid=322163) .b8 111
(EngineCore_DP0 pid=322163) .b8 111
(EngineCore_DP0 pid=322163) .b8 116
(EngineCore_DP0 pid=322163) .b8 47
(EngineCore_DP0 pid=322163) .b8 118
(EngineCore_DP0 pid=322163) .b8 108
(EngineCore_DP0 pid=322163) .b8 108
(EngineCore_DP0 pid=322163) .b8 109
(EngineCore_DP0 pid=322163) .b8 98
(EngineCore_DP0 pid=322163) .b8 101
(EngineCore_DP0 pid=322163) .b8 110
(EngineCore_DP0 pid=322163) .b8 99
(EngineCore_DP0 pid=322163) .b8 104
(EngineCore_DP0 pid=322163) .b8 47
(EngineCore_DP0 pid=322163) .b8 115
(EngineCore_DP0 pid=322163) .b8 108
(EngineCore_DP0 pid=322163) .b8 105
(EngineCore_DP0 pid=322163) .b8 100
(EngineCore_DP0 pid=322163) .b8 101
(EngineCore_DP0 pid=322163) .b8 115
(EngineCore_DP0 pid=322163) .b8 112
(EngineCore_DP0 pid=322163) .b8 97
(EngineCore_DP0 pid=322163) .b8 114
(EngineCore_DP0 pid=322163) .b8 115
(EngineCore_DP0 pid=322163) .b8 101
(EngineCore_DP0 pid=322163) .b8 47
(EngineCore_DP0 pid=322163) .b8 99
(EngineCore_DP0 pid=322163) .b8 115
(EngineCore_DP0 pid=322163) .b8 114
(EngineCore_DP0 pid=322163) .b8 99
(EngineCore_DP0 pid=322163) .b8 47
(EngineCore_DP0 pid=322163) .b8 102
(EngineCore_DP0 pid=322163) .b8 117
(EngineCore_DP0 pid=322163) .b8 115
(EngineCore_DP0 pid=322163) .b8 101
(EngineCore_DP0 pid=322163) .b8 100
(EngineCore_DP0 pid=322163) .b8 95
(EngineCore_DP0 pid=322163) .b8 113
(EngineCore_DP0 pid=322163) .b8 117
(EngineCore_DP0 pid=322163) .b8 97
(EngineCore_DP0 pid=322163) .b8 110
(EngineCore_DP0 pid=322163) .b8 116
(EngineCore_DP0 pid=322163) .b8 95
(EngineCore_DP0 pid=322163) .b8 115
(EngineCore_DP0 pid=322163) .b8 108
(EngineCore_DP0 pid=322163) .b8 105
(EngineCore_DP0 pid=322163) .b8 100
(EngineCore_DP0 pid=322163) .b8 101
(EngineCore_DP0 pid=322163) .b8 95
(EngineCore_DP0 pid=322163) .b8 116
(EngineCore_DP0 pid=322163) .b8 114
(EngineCore_DP0 pid=322163) .b8 105
(EngineCore_DP0 pid=322163) .b8 116
(EngineCore_DP0 pid=322163) .b8 111
(EngineCore_DP0 pid=322163) .b8 110
(EngineCore_DP0 pid=322163) .b8 47
(EngineCore_DP0 pid=322163) .b8 98
(EngineCore_DP0 pid=322163) .b8 117
(EngineCore_DP0 pid=322163) .b8 105
(EngineCore_DP0 pid=322163) .b8 108
(EngineCore_DP0 pid=322163) .b8 100
(EngineCore_DP0 pid=322163) .b8 47
(EngineCore_DP0 pid=322163) .b8 71
(EngineCore_DP0 pid=322163) .b8 66
(EngineCore_DP0 pid=322163) .b8 49
(EngineCore_DP0 pid=322163) .b8 48
(EngineCore_DP0 pid=322163) .b8 95
(EngineCore_DP0 pid=322163) .b8 99
(EngineCore_DP0 pid=322163) .b8 99
(EngineCore_DP0 pid=322163) .b8 49
(EngineCore_DP0 pid=322163) .b8 50
(EngineCore_DP0 pid=322163) .b8 49
(EngineCore_DP0 pid=322163) .b8 95
(EngineCore_DP0 pid=322163) .b8 112
(EngineCore_DP0 pid=322163) .b8 121
(EngineCore_DP0 pid=322163) .b8 51
(EngineCore_DP0 pid=322163) .b8 49
(EngineCore_DP0 pid=322163) .b8 50
(EngineCore_DP0 pid=322163) .b8 95
(EngineCore_DP0 pid=322163) .b8 99
(EngineCore_DP0 pid=322163) .b8 117
(EngineCore_DP0 pid=322163) .b8 49
(EngineCore_DP0 pid=322163) .b8 50
(EngineCore_DP0 pid=322163) .b8 57
(EngineCore_DP0 pid=322163) .b8 95
(EngineCore_DP0 pid=322163) .b8 97
(EngineCore_DP0 pid=322163) .b8 97
(EngineCore_DP0 pid=322163) .b8 114
(EngineCore_DP0 pid=322163) .b8 99
(EngineCore_DP0 pid=322163) .b8 104
(EngineCore_DP0 pid=322163) .b8 54
(EngineCore_DP0 pid=322163) .b8 52
(EngineCore_DP0 pid=322163) .b8 0
(EngineCore_DP0 pid=322163) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=322163) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=322163) .b8 113
(EngineCore_DP0 pid=322163) .b8 117
(EngineCore_DP0 pid=322163) .b8 97
(EngineCore_DP0 pid=322163) .b8 110
(EngineCore_DP0 pid=322163) .b8 116
(EngineCore_DP0 pid=322163) .b8 95
(EngineCore_DP0 pid=322163) .b8 115
(EngineCore_DP0 pid=322163) .b8 108
(EngineCore_DP0 pid=322163) .b8 105
(EngineCore_DP0 pid=322163) .b8 100
(EngineCore_DP0 pid=322163) .b8 101
(EngineCore_DP0 pid=322163) .b8 95
(EngineCore_DP0 pid=322163) .b8 105
(EngineCore_DP0 pid=322163) .b8 110
(EngineCore_DP0 pid=322163) .b8 116
(EngineCore_DP0 pid=322163) .b8 56
(EngineCore_DP0 pid=322163) .b8 95
(EngineCore_DP0 pid=322163) .b8 107
(EngineCore_DP0 pid=322163) .b8 101
(EngineCore_DP0 pid=322163) .b8 114
(EngineCore_DP0 pid=322163) .b8 110
(EngineCore_DP0 pid=322163) .b8 101
(EngineCore_DP0 pid=322163) .b8 108
(EngineCore_DP0 pid=322163) .b8 0
(EngineCore_DP0 pid=322163) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=322163) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=322163) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=322163) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=322163) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=322163) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=322163) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=322163) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=322163) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=322163) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=322163) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=322163) .b8 1
(EngineCore_DP0 pid=322163) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=322163) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=322163) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=322163) 	}
(EngineCore_DP0 pid=322163) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=322163) 
(EngineCore_DP0 pid=322163) ================================================================
(EngineCore_DP0 pid=322163) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=322163) 
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmphyz9n7ut.ptx', '-o', '/tmp/tmphyz9n7ut.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866] 
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866] 
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866] 
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmphyz9n7ut.ptx -o /tmp/tmphyz9n7ut.ptx.o
(EngineCore_DP0 pid=322163) ERROR 01-25 19:04:43 [core.py:866] 

STDERR:
[2026-01-25 19:04:26] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:04:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:04:26] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:04:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:04:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:04:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:04:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:04:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:04:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:04:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:04:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:04:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:04:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:04:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:04:30] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:04:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:04:30] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:04:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:04:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:04:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:04:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:04:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:04:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:04:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:04:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:04:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:04:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:04:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=322163) [2026-01-25 19:04:31] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=322163) [2026-01-25 19:04:31] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=322163) [2026-01-25 19:04:31] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=322163) [2026-01-25 19:04:31] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=322163) [2026-01-25 19:04:31] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=322163) [2026-01-25 19:04:31] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=322163) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=322163) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.74s/it]
(EngineCore_DP0 pid=322163) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.74s/it]
(EngineCore_DP0 pid=322163) 
(EngineCore_DP0 pid=322163) [2026-01-25 19:04:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=322163) [2026-01-25 19:04:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=322163) [2026-01-25 19:04:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=322163) [2026-01-25 19:04:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=322163) [2026-01-25 19:04:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=322163) [2026-01-25 19:04:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=322163) [2026-01-25 19:04:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=322163) [2026-01-25 19:04:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=322163) Process EngineCore_DP0:
(EngineCore_DP0 pid=322163) Traceback (most recent call last):
(EngineCore_DP0 pid=322163)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=322163)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=322163)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=322163)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=322163) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmphyz9n7ut.ptx', '-o', '/tmp/tmphyz9n7ut.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=322163) 
(EngineCore_DP0 pid=322163) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=322163) 
(EngineCore_DP0 pid=322163) Traceback (most recent call last):
(EngineCore_DP0 pid=322163)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=322163)     self.run()
(EngineCore_DP0 pid=322163)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=322163)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=322163)     raise e
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=322163)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=322163)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=322163)     super().__init__(
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=322163)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=322163)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=322163)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=322163)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=322163)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=322163)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=322163)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=322163)     return func(*args, **kwargs)
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=322163)     return func(*args, **kwargs)
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=322163)     self.model_runner.profile_run()
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=322163)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=322163)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=322163)     return func(*args, **kwargs)
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=322163)     outputs = self.model(
(EngineCore_DP0 pid=322163)               ^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=322163)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=322163)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=322163)     model_output = self.model(
(EngineCore_DP0 pid=322163)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=322163)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=322163)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=322163)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=322163)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=322163)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=322163)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=322163)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=322163)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=322163)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=322163)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=322163)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=322163)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=322163)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=322163)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=322163)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=322163)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=322163)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=322163)     return self._linear_fn(
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=322163)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=322163)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=322163)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=322163)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=322163)     return fn(input, L)
(EngineCore_DP0 pid=322163)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=322163)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=322163)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=322163)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=322163)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=322163)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=322163)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=322163)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=322163)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=322163)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=322163)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=322163)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=322163)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322163)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=322163)     raise PTXASError(error)
(EngineCore_DP0 pid=322163) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=322163) `ptxas` stderr:
(EngineCore_DP0 pid=322163) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=322163) 
(EngineCore_DP0 pid=322163) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmphyz9n7ut.ptx -o /tmp/tmphyz9n7ut.ptx.o
(EngineCore_DP0 pid=322163) 
[rank0]:[W125 19:04:43.996876895 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 19:04:45
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:05:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:05:00 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=322793) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=322793) 
(EngineCore_DP0 pid=322793) 
(EngineCore_DP0 pid=322793) ================================================================
(EngineCore_DP0 pid=322793) Internal Triton PTX codegen error
(EngineCore_DP0 pid=322793) `ptxas` stderr:
(EngineCore_DP0 pid=322793) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=322793) 
(EngineCore_DP0 pid=322793) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp0po5u1kv.ptx -o /tmp/tmp0po5u1kv.ptx.o
(EngineCore_DP0 pid=322793) 
(EngineCore_DP0 pid=322793) 
(EngineCore_DP0 pid=322793) //
(EngineCore_DP0 pid=322793) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=322793) //
(EngineCore_DP0 pid=322793) 
(EngineCore_DP0 pid=322793) .version 8.7
(EngineCore_DP0 pid=322793) .target sm_121a
(EngineCore_DP0 pid=322793) .address_size 64
(EngineCore_DP0 pid=322793) 
(EngineCore_DP0 pid=322793) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=322793) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=322793)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=322793) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=322793) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=322793) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=322793) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=322793) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=322793) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=322793) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=322793) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=322793) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=322793) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=322793) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=322793) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=322793) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=322793) )
(EngineCore_DP0 pid=322793) .reqntid 512
(EngineCore_DP0 pid=322793) {
(EngineCore_DP0 pid=322793) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=322793) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=322793) 	.reg .b32 	%r<267>;
(EngineCore_DP0 pid=322793) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=322793) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=322793) $L__func_begin0:
(EngineCore_DP0 pid=322793) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=322793) 
(EngineCore_DP0 pid=322793) // %bb.0:
(EngineCore_DP0 pid=322793) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=322793) 	ld.param.b32 	%r28, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=322793) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=322793) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=322793) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=322793) $L__tmp0:
(EngineCore_DP0 pid=322793) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=322793) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=322793) 	ld.param.b32 	%r31, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=322793) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=322793) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=322793) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=322793) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=322793) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=322793) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=322793) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=322793) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=322793) 	mov.b32 	%r265, 0f2B8CBCCC;
(EngineCore_DP0 pid=322793) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=322793) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=322793) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=322793) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=322793) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=322793) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=322793) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=322793) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=322793) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=322793) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=322793) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=322793) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=322793) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=322793) 	mov.b32 	%r263, 0f00000000;
(EngineCore_DP0 pid=322793) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=322793) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=322793) 	mov.b32 	%r264, %r49;
(EngineCore_DP0 pid=322793) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=322793) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=322793) 	add.s32 	%r59, %r4, %r264;
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=322793) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=322793) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=322793) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=322793) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=322793) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=322793) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=322793) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=322793) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=322793) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=322793) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=322793) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=322793) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=322793) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=322793) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=322793) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=322793) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=322793) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=322793) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=322793) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=322793) $L__tmp1:
(EngineCore_DP0 pid=322793) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	bar.sync 	0;
(EngineCore_DP0 pid=322793) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=322793) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=322793) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=322793) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=322793) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=322793) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=322793) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=322793) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=322793) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=322793) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=322793) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=322793) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=322793) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=322793) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=322793) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=322793) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=322793) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=322793) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=322793) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	bar.sync 	0;
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=322793) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=322793) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=322793) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=322793) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=322793) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=322793) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=322793) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=322793) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	bar.sync 	0;
(EngineCore_DP0 pid=322793) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=322793) $L__tmp2:
(EngineCore_DP0 pid=322793) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=322793) 	max.f32 	%r263, %r263, %r77;
(EngineCore_DP0 pid=322793) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=322793) 	add.s32 	%r264, %r264, 4096;
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p6, %r264, %r28;
(EngineCore_DP0 pid=322793) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=322793) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=322793) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=322793) 	max.f32 	%r265, %r263, 0f2B8CBCCC;
(EngineCore_DP0 pid=322793) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=322793) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=322793) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=322793) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=322793) 	div.full.f32 	%r80, %r265, %r79;
(EngineCore_DP0 pid=322793) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=322793) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=322793) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=322793) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=322793) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=322793) 	mul.lo.s32 	%r15, %r29, 3;
(EngineCore_DP0 pid=322793) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=322793) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=322793) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=322793) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=322793) 	ld.param.b32 	%r33, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=322793) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=322793) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=322793) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=322793) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=322793) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=322793) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=322793) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=322793) 	div.full.f32 	%r14, %r79, %r265;
(EngineCore_DP0 pid=322793) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=322793) 	mov.b32 	%r266, 0;
(EngineCore_DP0 pid=322793) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=322793)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=322793) 	.loc	1 313 31                        // quant_slide_tuned_Llama3.2-1B.py:313:31
(EngineCore_DP0 pid=322793) 	add.s32 	%r87, %r16, %r266;
(EngineCore_DP0 pid=322793) 	add.s32 	%r88, %r87, 1;
(EngineCore_DP0 pid=322793) 	add.s32 	%r89, %r87, 2;
(EngineCore_DP0 pid=322793) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=322793) 	add.s32 	%r90, %r87, 3;
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p25, %r87, %r15;
(EngineCore_DP0 pid=322793) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=322793) 	mul.hi.s32 	%r91, %r90, 1431655766;
(EngineCore_DP0 pid=322793) 	shr.u32 	%r92, %r91, 31;
(EngineCore_DP0 pid=322793) 	add.s32 	%r93, %r91, %r92;
(EngineCore_DP0 pid=322793) 	mul.hi.s32 	%r94, %r89, 1431655766;
(EngineCore_DP0 pid=322793) 	shr.u32 	%r95, %r94, 31;
(EngineCore_DP0 pid=322793) 	add.s32 	%r96, %r94, %r95;
(EngineCore_DP0 pid=322793) 	mul.hi.s32 	%r97, %r88, 1431655766;
(EngineCore_DP0 pid=322793) 	shr.u32 	%r98, %r97, 31;
(EngineCore_DP0 pid=322793) 	add.s32 	%r99, %r97, %r98;
(EngineCore_DP0 pid=322793) 	mul.hi.s32 	%r100, %r87, 1431655766;
(EngineCore_DP0 pid=322793) 	shr.u32 	%r101, %r100, 31;
(EngineCore_DP0 pid=322793) 	add.s32 	%r102, %r100, %r101;
(EngineCore_DP0 pid=322793) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=322793) 	mul.lo.s32 	%r103, %r102, 3;
(EngineCore_DP0 pid=322793) 	mul.lo.s32 	%r104, %r99, 3;
(EngineCore_DP0 pid=322793) 	mul.lo.s32 	%r105, %r96, 3;
(EngineCore_DP0 pid=322793) 	mul.lo.s32 	%r106, %r93, 3;
(EngineCore_DP0 pid=322793) 	sub.s32 	%r107, %r90, %r106;
(EngineCore_DP0 pid=322793) 	sub.s32 	%r108, %r89, %r105;
(EngineCore_DP0 pid=322793) 	sub.s32 	%r109, %r88, %r104;
(EngineCore_DP0 pid=322793) 	sub.s32 	%r110, %r87, %r103;
(EngineCore_DP0 pid=322793) 	.loc	1 319 22                        // quant_slide_tuned_Llama3.2-1B.py:319:22
(EngineCore_DP0 pid=322793) 	shl.b32 	%r111, %r102, 3;
(EngineCore_DP0 pid=322793) 	shl.b32 	%r112, %r99, 3;
(EngineCore_DP0 pid=322793) 	shl.b32 	%r113, %r96, 3;
(EngineCore_DP0 pid=322793) 	shl.b32 	%r114, %r93, 3;
(EngineCore_DP0 pid=322793) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=322793) 	shl.b32 	%r115, %r110, 1;
(EngineCore_DP0 pid=322793) 	shl.b32 	%r116, %r109, 1;
(EngineCore_DP0 pid=322793) 	shl.b32 	%r117, %r108, 1;
(EngineCore_DP0 pid=322793) 	shl.b32 	%r118, %r107, 1;
(EngineCore_DP0 pid=322793) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=322793) 	add.s32 	%r119, %r114, %r118;
(EngineCore_DP0 pid=322793) 	add.s32 	%r120, %r113, %r117;
(EngineCore_DP0 pid=322793) 	add.s32 	%r121, %r112, %r116;
(EngineCore_DP0 pid=322793) 	add.s32 	%r122, %r111, %r115;
(EngineCore_DP0 pid=322793) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p26, %r122, %r27;
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p27, %r121, %r27;
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p28, %r120, %r27;
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p29, %r119, %r27;
(EngineCore_DP0 pid=322793) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=322793) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=322793) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=322793) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=322793) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=322793) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=322793) 	mad.wide.s32 	%rd8, %r122, 2, %rd1;
(EngineCore_DP0 pid=322793) 	mad.wide.s32 	%rd9, %r121, 2, %rd1;
(EngineCore_DP0 pid=322793) 	mad.wide.s32 	%rd10, %r120, 2, %rd1;
(EngineCore_DP0 pid=322793) 	mad.wide.s32 	%rd11, %r119, 2, %rd1;
(EngineCore_DP0 pid=322793) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=322793) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=322793) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=322793) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=322793) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=322793) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=322793) 	cvt.f32.bf16 	%r123, %rs24;
(EngineCore_DP0 pid=322793) 	cvt.f32.bf16 	%r124, %rs26;
(EngineCore_DP0 pid=322793) 	cvt.f32.bf16 	%r125, %rs28;
(EngineCore_DP0 pid=322793) 	cvt.f32.bf16 	%r126, %rs30;
(EngineCore_DP0 pid=322793) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=322793) 	or.b32 	%r127, %r122, 1;
(EngineCore_DP0 pid=322793) 	or.b32 	%r128, %r121, 1;
(EngineCore_DP0 pid=322793) 	or.b32 	%r129, %r120, 1;
(EngineCore_DP0 pid=322793) 	or.b32 	%r130, %r119, 1;
(EngineCore_DP0 pid=322793) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p30, %r127, %r27;
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p31, %r128, %r27;
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p32, %r129, %r27;
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p33, %r130, %r27;
(EngineCore_DP0 pid=322793) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=322793) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=322793) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=322793) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=322793) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=322793) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=322793) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=322793) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=322793) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=322793) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=322793) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=322793) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=322793) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=322793) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=322793) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=322793) 	cvt.f32.bf16 	%r131, %rs32;
(EngineCore_DP0 pid=322793) 	cvt.f32.bf16 	%r132, %rs34;
(EngineCore_DP0 pid=322793) 	cvt.f32.bf16 	%r133, %rs36;
(EngineCore_DP0 pid=322793) 	cvt.f32.bf16 	%r134, %rs38;
(EngineCore_DP0 pid=322793) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=322793) 	add.s32 	%r135, %r122, 2;
(EngineCore_DP0 pid=322793) 	add.s32 	%r136, %r121, 2;
(EngineCore_DP0 pid=322793) 	add.s32 	%r137, %r120, 2;
(EngineCore_DP0 pid=322793) 	add.s32 	%r138, %r119, 2;
(EngineCore_DP0 pid=322793) 	add.s32 	%r139, %r122, 3;
(EngineCore_DP0 pid=322793) 	add.s32 	%r140, %r121, 3;
(EngineCore_DP0 pid=322793) 	add.s32 	%r141, %r120, 3;
(EngineCore_DP0 pid=322793) 	add.s32 	%r142, %r119, 3;
(EngineCore_DP0 pid=322793) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p34, %r142, %r27;
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p35, %r141, %r27;
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p36, %r140, %r27;
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p37, %r139, %r27;
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p38, %r138, %r27;
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p39, %r137, %r27;
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p40, %r136, %r27;
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p41, %r135, %r27;
(EngineCore_DP0 pid=322793) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=322793) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=322793) 	and.pred 	%p18, %p25, %p40;
(EngineCore_DP0 pid=322793) 	and.pred 	%p19, %p25, %p39;
(EngineCore_DP0 pid=322793) 	and.pred 	%p20, %p25, %p38;
(EngineCore_DP0 pid=322793) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=322793) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=322793) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=322793) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=322793) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=322793) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=322793) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=322793) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=322793) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=322793) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=322793) 	cvt.f32.bf16 	%r143, %rs40;
(EngineCore_DP0 pid=322793) 	cvt.f32.bf16 	%r144, %rs42;
(EngineCore_DP0 pid=322793) 	cvt.f32.bf16 	%r145, %rs44;
(EngineCore_DP0 pid=322793) 	cvt.f32.bf16 	%r146, %rs46;
(EngineCore_DP0 pid=322793) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=322793) 	and.pred 	%p21, %p25, %p37;
(EngineCore_DP0 pid=322793) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=322793) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=322793) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=322793) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=322793) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=322793) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=322793) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=322793) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=322793) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=322793) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=322793) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=322793) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=322793) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=322793) 	cvt.f32.bf16 	%r147, %rs48;
(EngineCore_DP0 pid=322793) 	cvt.f32.bf16 	%r148, %rs50;
(EngineCore_DP0 pid=322793) 	cvt.f32.bf16 	%r149, %rs52;
(EngineCore_DP0 pid=322793) 	cvt.f32.bf16 	%r150, %rs54;
(EngineCore_DP0 pid=322793) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=322793) 	mul.f32 	%r151, %r14, %r123;
(EngineCore_DP0 pid=322793) 	mul.f32 	%r152, %r14, %r124;
(EngineCore_DP0 pid=322793) 	mul.f32 	%r153, %r14, %r125;
(EngineCore_DP0 pid=322793) 	mul.f32 	%r154, %r14, %r126;
(EngineCore_DP0 pid=322793) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=322793) 	cvt.rni.f32.f32 	%r155, %r151;
(EngineCore_DP0 pid=322793) 	cvt.rni.f32.f32 	%r156, %r152;
(EngineCore_DP0 pid=322793) 	cvt.rni.f32.f32 	%r157, %r153;
(EngineCore_DP0 pid=322793) 	cvt.rni.f32.f32 	%r158, %r154;
(EngineCore_DP0 pid=322793) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=322793) 	max.f32 	%r159, %r155, 0fC3000000;
(EngineCore_DP0 pid=322793) 	min.f32 	%r160, %r159, 0f42FE0000;
(EngineCore_DP0 pid=322793) 	max.f32 	%r161, %r156, 0fC3000000;
(EngineCore_DP0 pid=322793) 	min.f32 	%r162, %r161, 0f42FE0000;
(EngineCore_DP0 pid=322793) 	max.f32 	%r163, %r157, 0fC3000000;
(EngineCore_DP0 pid=322793) 	min.f32 	%r164, %r163, 0f42FE0000;
(EngineCore_DP0 pid=322793) 	max.f32 	%r165, %r158, 0fC3000000;
(EngineCore_DP0 pid=322793) 	min.f32 	%r166, %r165, 0f42FE0000;
(EngineCore_DP0 pid=322793) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=322793) 	cvt.rzi.s32.f32 	%r167, %r160;
(EngineCore_DP0 pid=322793) 	cvt.rzi.s32.f32 	%r168, %r162;
(EngineCore_DP0 pid=322793) 	cvt.rzi.s32.f32 	%r169, %r164;
(EngineCore_DP0 pid=322793) 	cvt.rzi.s32.f32 	%r170, %r166;
(EngineCore_DP0 pid=322793) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=322793) 	and.b32 	%r171, %r167, 255;
(EngineCore_DP0 pid=322793) 	and.b32 	%r172, %r168, 255;
(EngineCore_DP0 pid=322793) 	and.b32 	%r173, %r169, 255;
(EngineCore_DP0 pid=322793) 	and.b32 	%r174, %r170, 255;
(EngineCore_DP0 pid=322793) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=322793) 	mul.f32 	%r175, %r14, %r131;
(EngineCore_DP0 pid=322793) 	mul.f32 	%r176, %r14, %r132;
(EngineCore_DP0 pid=322793) 	mul.f32 	%r177, %r14, %r133;
(EngineCore_DP0 pid=322793) 	mul.f32 	%r178, %r14, %r134;
(EngineCore_DP0 pid=322793) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=322793) 	cvt.rni.f32.f32 	%r179, %r175;
(EngineCore_DP0 pid=322793) 	cvt.rni.f32.f32 	%r180, %r176;
(EngineCore_DP0 pid=322793) 	cvt.rni.f32.f32 	%r181, %r177;
(EngineCore_DP0 pid=322793) 	cvt.rni.f32.f32 	%r182, %r178;
(EngineCore_DP0 pid=322793) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=322793) 	mul.f32 	%r183, %r14, %r143;
(EngineCore_DP0 pid=322793) 	mul.f32 	%r184, %r14, %r144;
(EngineCore_DP0 pid=322793) 	mul.f32 	%r185, %r14, %r145;
(EngineCore_DP0 pid=322793) 	mul.f32 	%r186, %r14, %r146;
(EngineCore_DP0 pid=322793) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=322793) 	cvt.rni.f32.f32 	%r187, %r183;
(EngineCore_DP0 pid=322793) 	cvt.rni.f32.f32 	%r188, %r184;
(EngineCore_DP0 pid=322793) 	cvt.rni.f32.f32 	%r189, %r185;
(EngineCore_DP0 pid=322793) 	cvt.rni.f32.f32 	%r190, %r186;
(EngineCore_DP0 pid=322793) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=322793) 	mul.f32 	%r191, %r14, %r147;
(EngineCore_DP0 pid=322793) 	mul.f32 	%r192, %r14, %r148;
(EngineCore_DP0 pid=322793) 	mul.f32 	%r193, %r14, %r149;
(EngineCore_DP0 pid=322793) 	mul.f32 	%r194, %r14, %r150;
(EngineCore_DP0 pid=322793) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=322793) 	cvt.rni.f32.f32 	%r195, %r191;
(EngineCore_DP0 pid=322793) 	cvt.rni.f32.f32 	%r196, %r192;
(EngineCore_DP0 pid=322793) 	cvt.rni.f32.f32 	%r197, %r193;
(EngineCore_DP0 pid=322793) 	cvt.rni.f32.f32 	%r198, %r194;
(EngineCore_DP0 pid=322793) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=322793) 	max.f32 	%r199, %r195, 0fC3000000;
(EngineCore_DP0 pid=322793) 	min.f32 	%r200, %r199, 0f42FE0000;
(EngineCore_DP0 pid=322793) 	max.f32 	%r201, %r196, 0fC3000000;
(EngineCore_DP0 pid=322793) 	min.f32 	%r202, %r201, 0f42FE0000;
(EngineCore_DP0 pid=322793) 	max.f32 	%r203, %r197, 0fC3000000;
(EngineCore_DP0 pid=322793) 	min.f32 	%r204, %r203, 0f42FE0000;
(EngineCore_DP0 pid=322793) 	max.f32 	%r205, %r198, 0fC3000000;
(EngineCore_DP0 pid=322793) 	min.f32 	%r206, %r205, 0f42FE0000;
(EngineCore_DP0 pid=322793) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=322793) 	cvt.rzi.s32.f32 	%r207, %r200;
(EngineCore_DP0 pid=322793) 	cvt.rzi.s32.f32 	%r208, %r202;
(EngineCore_DP0 pid=322793) 	cvt.rzi.s32.f32 	%r209, %r204;
(EngineCore_DP0 pid=322793) 	cvt.rzi.s32.f32 	%r210, %r206;
(EngineCore_DP0 pid=322793) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=322793) 	max.f32 	%r211, %r187, 0fC3000000;
(EngineCore_DP0 pid=322793) 	max.f32 	%r212, %r179, 0fC3000000;
(EngineCore_DP0 pid=322793) 	min.f32 	%r213, %r212, 0f42FE0000;
(EngineCore_DP0 pid=322793) 	min.f32 	%r214, %r211, 0f42FE0000;
(EngineCore_DP0 pid=322793) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=322793) 	cvt.rzi.s32.f32 	%r215, %r214;
(EngineCore_DP0 pid=322793) 	cvt.rzi.s32.f32 	%r216, %r213;
(EngineCore_DP0 pid=322793) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=322793) 	shl.b32 	%r217, %r216, 8;
(EngineCore_DP0 pid=322793) 	shl.b32 	%r218, %r215, 16;
(EngineCore_DP0 pid=322793) 	and.b32 	%r219, %r218, 16711680;
(EngineCore_DP0 pid=322793) 	and.b32 	%r220, %r217, 65280;
(EngineCore_DP0 pid=322793) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=322793) 	or.b32 	%r221, %r220, %r171;
(EngineCore_DP0 pid=322793) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=322793) 	max.f32 	%r222, %r188, 0fC3000000;
(EngineCore_DP0 pid=322793) 	max.f32 	%r223, %r180, 0fC3000000;
(EngineCore_DP0 pid=322793) 	min.f32 	%r224, %r223, 0f42FE0000;
(EngineCore_DP0 pid=322793) 	min.f32 	%r225, %r222, 0f42FE0000;
(EngineCore_DP0 pid=322793) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=322793) 	cvt.rzi.s32.f32 	%r226, %r225;
(EngineCore_DP0 pid=322793) 	cvt.rzi.s32.f32 	%r227, %r224;
(EngineCore_DP0 pid=322793) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=322793) 	shl.b32 	%r228, %r227, 8;
(EngineCore_DP0 pid=322793) 	shl.b32 	%r229, %r226, 16;
(EngineCore_DP0 pid=322793) 	and.b32 	%r230, %r229, 16711680;
(EngineCore_DP0 pid=322793) 	and.b32 	%r231, %r228, 65280;
(EngineCore_DP0 pid=322793) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=322793) 	or.b32 	%r232, %r231, %r172;
(EngineCore_DP0 pid=322793) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=322793) 	max.f32 	%r233, %r189, 0fC3000000;
(EngineCore_DP0 pid=322793) 	max.f32 	%r234, %r181, 0fC3000000;
(EngineCore_DP0 pid=322793) 	min.f32 	%r235, %r234, 0f42FE0000;
(EngineCore_DP0 pid=322793) 	min.f32 	%r236, %r233, 0f42FE0000;
(EngineCore_DP0 pid=322793) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=322793) 	cvt.rzi.s32.f32 	%r237, %r236;
(EngineCore_DP0 pid=322793) 	cvt.rzi.s32.f32 	%r238, %r235;
(EngineCore_DP0 pid=322793) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=322793) 	shl.b32 	%r239, %r238, 8;
(EngineCore_DP0 pid=322793) 	shl.b32 	%r240, %r237, 16;
(EngineCore_DP0 pid=322793) 	and.b32 	%r241, %r240, 16711680;
(EngineCore_DP0 pid=322793) 	and.b32 	%r242, %r239, 65280;
(EngineCore_DP0 pid=322793) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=322793) 	or.b32 	%r243, %r242, %r173;
(EngineCore_DP0 pid=322793) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=322793) 	max.f32 	%r244, %r190, 0fC3000000;
(EngineCore_DP0 pid=322793) 	max.f32 	%r245, %r182, 0fC3000000;
(EngineCore_DP0 pid=322793) 	min.f32 	%r246, %r245, 0f42FE0000;
(EngineCore_DP0 pid=322793) 	min.f32 	%r247, %r244, 0f42FE0000;
(EngineCore_DP0 pid=322793) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=322793) 	cvt.rzi.s32.f32 	%r248, %r247;
(EngineCore_DP0 pid=322793) 	cvt.rzi.s32.f32 	%r249, %r246;
(EngineCore_DP0 pid=322793) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=322793) 	shl.b32 	%r250, %r249, 8;
(EngineCore_DP0 pid=322793) 	shl.b32 	%r251, %r248, 16;
(EngineCore_DP0 pid=322793) 	and.b32 	%r252, %r251, 16711680;
(EngineCore_DP0 pid=322793) 	and.b32 	%r253, %r250, 65280;
(EngineCore_DP0 pid=322793) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=322793) 	or.b32 	%r254, %r253, %r174;
(EngineCore_DP0 pid=322793) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=322793) 	or.b32 	%r255, %r221, %r219;
(EngineCore_DP0 pid=322793) 	or.b32 	%r256, %r232, %r230;
(EngineCore_DP0 pid=322793) 	or.b32 	%r257, %r243, %r241;
(EngineCore_DP0 pid=322793) 	or.b32 	%r258, %r254, %r252;
(EngineCore_DP0 pid=322793) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=322793) 	shl.b32 	%r259, %r207, 24;
(EngineCore_DP0 pid=322793) 	shl.b32 	%r260, %r208, 24;
(EngineCore_DP0 pid=322793) 	shl.b32 	%r261, %r209, 24;
(EngineCore_DP0 pid=322793) 	shl.b32 	%r262, %r210, 24;
(EngineCore_DP0 pid=322793) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=322793) 	or.b32 	%r82, %r255, %r259;
(EngineCore_DP0 pid=322793) 	or.b32 	%r83, %r256, %r260;
(EngineCore_DP0 pid=322793) 	or.b32 	%r84, %r257, %r261;
(EngineCore_DP0 pid=322793) 	or.b32 	%r85, %r258, %r262;
(EngineCore_DP0 pid=322793) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=322793) 	mad.wide.s32 	%rd24, %r87, 4, %rd2;
(EngineCore_DP0 pid=322793) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=322793) 	// begin inline asm
(EngineCore_DP0 pid=322793) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r82, %r83, %r84, %r85 };
(EngineCore_DP0 pid=322793) 	// end inline asm
(EngineCore_DP0 pid=322793) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=322793) 	add.s32 	%r266, %r266, 2048;
(EngineCore_DP0 pid=322793) 	setp.lt.s32 	%p42, %r266, %r15;
(EngineCore_DP0 pid=322793) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=322793) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=322793) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=322793) 	ret;
(EngineCore_DP0 pid=322793) $L__tmp3:
(EngineCore_DP0 pid=322793) $L__func_end0:
(EngineCore_DP0 pid=322793)                                         // -- End function
(EngineCore_DP0 pid=322793) }
(EngineCore_DP0 pid=322793) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=322793) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=322793) 	.section	.debug_abbrev
(EngineCore_DP0 pid=322793) 	{
(EngineCore_DP0 pid=322793) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=322793) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=322793) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=322793) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=322793) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=322793) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=322793) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=322793) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=322793) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=322793) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=322793) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=322793) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=322793) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=322793) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=322793) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=322793) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=322793) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=322793) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=322793) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=322793) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=322793) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=322793) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=322793) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=322793) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=322793) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=322793) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=322793) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=322793) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=322793) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=322793) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=322793) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=322793) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=322793) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=322793) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=322793) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=322793) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=322793) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=322793) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=322793) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=322793) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=322793) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=322793) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=322793) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=322793) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=322793) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=322793) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=322793) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=322793) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=322793) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=322793) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=322793) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=322793) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=322793) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=322793) 	}
(EngineCore_DP0 pid=322793) 	.section	.debug_info
(EngineCore_DP0 pid=322793) 	{
(EngineCore_DP0 pid=322793) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=322793) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=322793) .b8 0
(EngineCore_DP0 pid=322793) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=322793) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=322793) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=322793) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=322793) .b8 114
(EngineCore_DP0 pid=322793) .b8 105
(EngineCore_DP0 pid=322793) .b8 116
(EngineCore_DP0 pid=322793) .b8 111
(EngineCore_DP0 pid=322793) .b8 110
(EngineCore_DP0 pid=322793) .b8 0
(EngineCore_DP0 pid=322793) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=322793) .b8 0
(EngineCore_DP0 pid=322793) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=322793) .b8 117
(EngineCore_DP0 pid=322793) .b8 97
(EngineCore_DP0 pid=322793) .b8 110
(EngineCore_DP0 pid=322793) .b8 116
(EngineCore_DP0 pid=322793) .b8 95
(EngineCore_DP0 pid=322793) .b8 115
(EngineCore_DP0 pid=322793) .b8 108
(EngineCore_DP0 pid=322793) .b8 105
(EngineCore_DP0 pid=322793) .b8 100
(EngineCore_DP0 pid=322793) .b8 101
(EngineCore_DP0 pid=322793) .b8 95
(EngineCore_DP0 pid=322793) .b8 116
(EngineCore_DP0 pid=322793) .b8 117
(EngineCore_DP0 pid=322793) .b8 110
(EngineCore_DP0 pid=322793) .b8 101
(EngineCore_DP0 pid=322793) .b8 100
(EngineCore_DP0 pid=322793) .b8 95
(EngineCore_DP0 pid=322793) .b8 76
(EngineCore_DP0 pid=322793) .b8 108
(EngineCore_DP0 pid=322793) .b8 97
(EngineCore_DP0 pid=322793) .b8 109
(EngineCore_DP0 pid=322793) .b8 97
(EngineCore_DP0 pid=322793) .b8 51
(EngineCore_DP0 pid=322793) .b8 46
(EngineCore_DP0 pid=322793) .b8 50
(EngineCore_DP0 pid=322793) .b8 45
(EngineCore_DP0 pid=322793) .b8 49
(EngineCore_DP0 pid=322793) .b8 66
(EngineCore_DP0 pid=322793) .b8 46
(EngineCore_DP0 pid=322793) .b8 112
(EngineCore_DP0 pid=322793) .b8 121
(EngineCore_DP0 pid=322793) .b8 0
(EngineCore_DP0 pid=322793) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=322793) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=322793) .b8 114
(EngineCore_DP0 pid=322793) .b8 111
(EngineCore_DP0 pid=322793) .b8 111
(EngineCore_DP0 pid=322793) .b8 116
(EngineCore_DP0 pid=322793) .b8 47
(EngineCore_DP0 pid=322793) .b8 118
(EngineCore_DP0 pid=322793) .b8 108
(EngineCore_DP0 pid=322793) .b8 108
(EngineCore_DP0 pid=322793) .b8 109
(EngineCore_DP0 pid=322793) .b8 98
(EngineCore_DP0 pid=322793) .b8 101
(EngineCore_DP0 pid=322793) .b8 110
(EngineCore_DP0 pid=322793) .b8 99
(EngineCore_DP0 pid=322793) .b8 104
(EngineCore_DP0 pid=322793) .b8 47
(EngineCore_DP0 pid=322793) .b8 115
(EngineCore_DP0 pid=322793) .b8 108
(EngineCore_DP0 pid=322793) .b8 105
(EngineCore_DP0 pid=322793) .b8 100
(EngineCore_DP0 pid=322793) .b8 101
(EngineCore_DP0 pid=322793) .b8 115
(EngineCore_DP0 pid=322793) .b8 112
(EngineCore_DP0 pid=322793) .b8 97
(EngineCore_DP0 pid=322793) .b8 114
(EngineCore_DP0 pid=322793) .b8 115
(EngineCore_DP0 pid=322793) .b8 101
(EngineCore_DP0 pid=322793) .b8 47
(EngineCore_DP0 pid=322793) .b8 99
(EngineCore_DP0 pid=322793) .b8 115
(EngineCore_DP0 pid=322793) .b8 114
(EngineCore_DP0 pid=322793) .b8 99
(EngineCore_DP0 pid=322793) .b8 47
(EngineCore_DP0 pid=322793) .b8 102
(EngineCore_DP0 pid=322793) .b8 117
(EngineCore_DP0 pid=322793) .b8 115
(EngineCore_DP0 pid=322793) .b8 101
(EngineCore_DP0 pid=322793) .b8 100
(EngineCore_DP0 pid=322793) .b8 95
(EngineCore_DP0 pid=322793) .b8 113
(EngineCore_DP0 pid=322793) .b8 117
(EngineCore_DP0 pid=322793) .b8 97
(EngineCore_DP0 pid=322793) .b8 110
(EngineCore_DP0 pid=322793) .b8 116
(EngineCore_DP0 pid=322793) .b8 95
(EngineCore_DP0 pid=322793) .b8 115
(EngineCore_DP0 pid=322793) .b8 108
(EngineCore_DP0 pid=322793) .b8 105
(EngineCore_DP0 pid=322793) .b8 100
(EngineCore_DP0 pid=322793) .b8 101
(EngineCore_DP0 pid=322793) .b8 95
(EngineCore_DP0 pid=322793) .b8 116
(EngineCore_DP0 pid=322793) .b8 114
(EngineCore_DP0 pid=322793) .b8 105
(EngineCore_DP0 pid=322793) .b8 116
(EngineCore_DP0 pid=322793) .b8 111
(EngineCore_DP0 pid=322793) .b8 110
(EngineCore_DP0 pid=322793) .b8 47
(EngineCore_DP0 pid=322793) .b8 98
(EngineCore_DP0 pid=322793) .b8 117
(EngineCore_DP0 pid=322793) .b8 105
(EngineCore_DP0 pid=322793) .b8 108
(EngineCore_DP0 pid=322793) .b8 100
(EngineCore_DP0 pid=322793) .b8 47
(EngineCore_DP0 pid=322793) .b8 71
(EngineCore_DP0 pid=322793) .b8 66
(EngineCore_DP0 pid=322793) .b8 49
(EngineCore_DP0 pid=322793) .b8 48
(EngineCore_DP0 pid=322793) .b8 95
(EngineCore_DP0 pid=322793) .b8 99
(EngineCore_DP0 pid=322793) .b8 99
(EngineCore_DP0 pid=322793) .b8 49
(EngineCore_DP0 pid=322793) .b8 50
(EngineCore_DP0 pid=322793) .b8 49
(EngineCore_DP0 pid=322793) .b8 95
(EngineCore_DP0 pid=322793) .b8 112
(EngineCore_DP0 pid=322793) .b8 121
(EngineCore_DP0 pid=322793) .b8 51
(EngineCore_DP0 pid=322793) .b8 49
(EngineCore_DP0 pid=322793) .b8 50
(EngineCore_DP0 pid=322793) .b8 95
(EngineCore_DP0 pid=322793) .b8 99
(EngineCore_DP0 pid=322793) .b8 117
(EngineCore_DP0 pid=322793) .b8 49
(EngineCore_DP0 pid=322793) .b8 50
(EngineCore_DP0 pid=322793) .b8 57
(EngineCore_DP0 pid=322793) .b8 95
(EngineCore_DP0 pid=322793) .b8 97
(EngineCore_DP0 pid=322793) .b8 97
(EngineCore_DP0 pid=322793) .b8 114
(EngineCore_DP0 pid=322793) .b8 99
(EngineCore_DP0 pid=322793) .b8 104
(EngineCore_DP0 pid=322793) .b8 54
(EngineCore_DP0 pid=322793) .b8 52
(EngineCore_DP0 pid=322793) .b8 0
(EngineCore_DP0 pid=322793) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=322793) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=322793) .b8 113
(EngineCore_DP0 pid=322793) .b8 117
(EngineCore_DP0 pid=322793) .b8 97
(EngineCore_DP0 pid=322793) .b8 110
(EngineCore_DP0 pid=322793) .b8 116
(EngineCore_DP0 pid=322793) .b8 95
(EngineCore_DP0 pid=322793) .b8 115
(EngineCore_DP0 pid=322793) .b8 108
(EngineCore_DP0 pid=322793) .b8 105
(EngineCore_DP0 pid=322793) .b8 100
(EngineCore_DP0 pid=322793) .b8 101
(EngineCore_DP0 pid=322793) .b8 95
(EngineCore_DP0 pid=322793) .b8 105
(EngineCore_DP0 pid=322793) .b8 110
(EngineCore_DP0 pid=322793) .b8 116
(EngineCore_DP0 pid=322793) .b8 56
(EngineCore_DP0 pid=322793) .b8 95
(EngineCore_DP0 pid=322793) .b8 107
(EngineCore_DP0 pid=322793) .b8 101
(EngineCore_DP0 pid=322793) .b8 114
(EngineCore_DP0 pid=322793) .b8 110
(EngineCore_DP0 pid=322793) .b8 101
(EngineCore_DP0 pid=322793) .b8 108
(EngineCore_DP0 pid=322793) .b8 0
(EngineCore_DP0 pid=322793) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=322793) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=322793) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=322793) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=322793) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=322793) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=322793) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=322793) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=322793) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=322793) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=322793) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=322793) .b8 1
(EngineCore_DP0 pid=322793) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=322793) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=322793) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=322793) 	}
(EngineCore_DP0 pid=322793) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=322793) 
(EngineCore_DP0 pid=322793) ================================================================
(EngineCore_DP0 pid=322793) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=322793) 
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp0po5u1kv.ptx', '-o', '/tmp/tmp0po5u1kv.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866] 
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866] 
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866] 
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp0po5u1kv.ptx -o /tmp/tmp0po5u1kv.ptx.o
(EngineCore_DP0 pid=322793) ERROR 01-25 19:05:17 [core.py:866] 

STDERR:
[2026-01-25 19:05:00] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:05:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:05:00] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:05:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:05:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:05:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:05:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:05:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:05:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:05:03] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:05:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:05:03] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:05:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:05:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:05:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:05:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:05:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:05:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=322793) [2026-01-25 19:05:04] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=322793) [2026-01-25 19:05:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=322793) [2026-01-25 19:05:04] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=322793) [2026-01-25 19:05:04] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=322793) [2026-01-25 19:05:04] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=322793) [2026-01-25 19:05:04] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=322793) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=322793) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.92s/it]
(EngineCore_DP0 pid=322793) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.92s/it]
(EngineCore_DP0 pid=322793) 
(EngineCore_DP0 pid=322793) [2026-01-25 19:05:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=322793) [2026-01-25 19:05:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=322793) [2026-01-25 19:05:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=322793) [2026-01-25 19:05:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=322793) [2026-01-25 19:05:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=322793) [2026-01-25 19:05:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=322793) [2026-01-25 19:05:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=322793) [2026-01-25 19:05:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=322793) Process EngineCore_DP0:
(EngineCore_DP0 pid=322793) Traceback (most recent call last):
(EngineCore_DP0 pid=322793)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=322793)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=322793)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=322793)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=322793) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp0po5u1kv.ptx', '-o', '/tmp/tmp0po5u1kv.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=322793) 
(EngineCore_DP0 pid=322793) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=322793) 
(EngineCore_DP0 pid=322793) Traceback (most recent call last):
(EngineCore_DP0 pid=322793)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=322793)     self.run()
(EngineCore_DP0 pid=322793)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=322793)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=322793)     raise e
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=322793)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=322793)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=322793)     super().__init__(
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=322793)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=322793)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=322793)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=322793)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=322793)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=322793)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=322793)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=322793)     return func(*args, **kwargs)
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=322793)     return func(*args, **kwargs)
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=322793)     self.model_runner.profile_run()
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=322793)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=322793)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=322793)     return func(*args, **kwargs)
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=322793)     outputs = self.model(
(EngineCore_DP0 pid=322793)               ^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=322793)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=322793)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=322793)     model_output = self.model(
(EngineCore_DP0 pid=322793)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=322793)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=322793)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=322793)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=322793)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=322793)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=322793)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=322793)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=322793)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=322793)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=322793)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=322793)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=322793)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=322793)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=322793)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=322793)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=322793)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=322793)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=322793)     return self._linear_fn(
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=322793)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=322793)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=322793)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=322793)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=322793)     return fn(input, L)
(EngineCore_DP0 pid=322793)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=322793)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=322793)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=322793)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=322793)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=322793)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=322793)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=322793)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=322793)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=322793)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=322793)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=322793)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=322793)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=322793)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=322793)     raise PTXASError(error)
(EngineCore_DP0 pid=322793) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=322793) `ptxas` stderr:
(EngineCore_DP0 pid=322793) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=322793) 
(EngineCore_DP0 pid=322793) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp0po5u1kv.ptx -o /tmp/tmp0po5u1kv.ptx.o
(EngineCore_DP0 pid=322793) 
[rank0]:[W125 19:05:17.598583579 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 19:05:19
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:05:45 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:05:45 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=323599) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=323599) 
(EngineCore_DP0 pid=323599) 
(EngineCore_DP0 pid=323599) ================================================================
(EngineCore_DP0 pid=323599) Internal Triton PTX codegen error
(EngineCore_DP0 pid=323599) `ptxas` stderr:
(EngineCore_DP0 pid=323599) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=323599) 
(EngineCore_DP0 pid=323599) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpzuvqk_v7.ptx -o /tmp/tmpzuvqk_v7.ptx.o
(EngineCore_DP0 pid=323599) 
(EngineCore_DP0 pid=323599) 
(EngineCore_DP0 pid=323599) //
(EngineCore_DP0 pid=323599) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=323599) //
(EngineCore_DP0 pid=323599) 
(EngineCore_DP0 pid=323599) .version 8.7
(EngineCore_DP0 pid=323599) .target sm_121a
(EngineCore_DP0 pid=323599) .address_size 64
(EngineCore_DP0 pid=323599) 
(EngineCore_DP0 pid=323599) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=323599) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=323599)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=323599) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=323599) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=323599) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=323599) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=323599) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=323599) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=323599) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=323599) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=323599) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=323599) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=323599) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=323599) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=323599) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=323599) )
(EngineCore_DP0 pid=323599) .reqntid 512
(EngineCore_DP0 pid=323599) {
(EngineCore_DP0 pid=323599) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=323599) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=323599) 	.reg .b32 	%r<267>;
(EngineCore_DP0 pid=323599) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=323599) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=323599) $L__func_begin0:
(EngineCore_DP0 pid=323599) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=323599) 
(EngineCore_DP0 pid=323599) // %bb.0:
(EngineCore_DP0 pid=323599) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=323599) 	ld.param.b32 	%r28, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=323599) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=323599) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=323599) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=323599) $L__tmp0:
(EngineCore_DP0 pid=323599) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=323599) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=323599) 	ld.param.b32 	%r31, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=323599) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=323599) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=323599) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=323599) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=323599) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=323599) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=323599) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=323599) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=323599) 	mov.b32 	%r265, 0f2B8CBCCC;
(EngineCore_DP0 pid=323599) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=323599) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=323599) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=323599) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=323599) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=323599) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=323599) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=323599) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=323599) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=323599) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=323599) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=323599) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=323599) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=323599) 	mov.b32 	%r263, 0f00000000;
(EngineCore_DP0 pid=323599) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=323599) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=323599) 	mov.b32 	%r264, %r49;
(EngineCore_DP0 pid=323599) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=323599) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=323599) 	add.s32 	%r59, %r4, %r264;
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=323599) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=323599) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=323599) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=323599) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=323599) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=323599) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=323599) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=323599) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=323599) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=323599) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=323599) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=323599) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=323599) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=323599) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=323599) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=323599) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=323599) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=323599) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=323599) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=323599) $L__tmp1:
(EngineCore_DP0 pid=323599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	bar.sync 	0;
(EngineCore_DP0 pid=323599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=323599) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=323599) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=323599) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=323599) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=323599) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=323599) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=323599) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=323599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=323599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=323599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=323599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=323599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=323599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=323599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=323599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=323599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=323599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=323599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	bar.sync 	0;
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=323599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=323599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=323599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=323599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=323599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=323599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=323599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=323599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	bar.sync 	0;
(EngineCore_DP0 pid=323599) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=323599) $L__tmp2:
(EngineCore_DP0 pid=323599) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=323599) 	max.f32 	%r263, %r263, %r77;
(EngineCore_DP0 pid=323599) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=323599) 	add.s32 	%r264, %r264, 4096;
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p6, %r264, %r28;
(EngineCore_DP0 pid=323599) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=323599) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=323599) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=323599) 	max.f32 	%r265, %r263, 0f2B8CBCCC;
(EngineCore_DP0 pid=323599) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=323599) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=323599) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=323599) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=323599) 	div.full.f32 	%r80, %r265, %r79;
(EngineCore_DP0 pid=323599) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=323599) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=323599) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=323599) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=323599) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=323599) 	mul.lo.s32 	%r15, %r29, 3;
(EngineCore_DP0 pid=323599) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=323599) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=323599) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=323599) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=323599) 	ld.param.b32 	%r33, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=323599) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=323599) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=323599) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=323599) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=323599) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=323599) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=323599) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=323599) 	div.full.f32 	%r14, %r79, %r265;
(EngineCore_DP0 pid=323599) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=323599) 	mov.b32 	%r266, 0;
(EngineCore_DP0 pid=323599) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=323599)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=323599) 	.loc	1 313 31                        // quant_slide_tuned_Llama3.2-1B.py:313:31
(EngineCore_DP0 pid=323599) 	add.s32 	%r87, %r16, %r266;
(EngineCore_DP0 pid=323599) 	add.s32 	%r88, %r87, 1;
(EngineCore_DP0 pid=323599) 	add.s32 	%r89, %r87, 2;
(EngineCore_DP0 pid=323599) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=323599) 	add.s32 	%r90, %r87, 3;
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p25, %r87, %r15;
(EngineCore_DP0 pid=323599) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=323599) 	mul.hi.s32 	%r91, %r90, 1431655766;
(EngineCore_DP0 pid=323599) 	shr.u32 	%r92, %r91, 31;
(EngineCore_DP0 pid=323599) 	add.s32 	%r93, %r91, %r92;
(EngineCore_DP0 pid=323599) 	mul.hi.s32 	%r94, %r89, 1431655766;
(EngineCore_DP0 pid=323599) 	shr.u32 	%r95, %r94, 31;
(EngineCore_DP0 pid=323599) 	add.s32 	%r96, %r94, %r95;
(EngineCore_DP0 pid=323599) 	mul.hi.s32 	%r97, %r88, 1431655766;
(EngineCore_DP0 pid=323599) 	shr.u32 	%r98, %r97, 31;
(EngineCore_DP0 pid=323599) 	add.s32 	%r99, %r97, %r98;
(EngineCore_DP0 pid=323599) 	mul.hi.s32 	%r100, %r87, 1431655766;
(EngineCore_DP0 pid=323599) 	shr.u32 	%r101, %r100, 31;
(EngineCore_DP0 pid=323599) 	add.s32 	%r102, %r100, %r101;
(EngineCore_DP0 pid=323599) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=323599) 	mul.lo.s32 	%r103, %r102, 3;
(EngineCore_DP0 pid=323599) 	mul.lo.s32 	%r104, %r99, 3;
(EngineCore_DP0 pid=323599) 	mul.lo.s32 	%r105, %r96, 3;
(EngineCore_DP0 pid=323599) 	mul.lo.s32 	%r106, %r93, 3;
(EngineCore_DP0 pid=323599) 	sub.s32 	%r107, %r90, %r106;
(EngineCore_DP0 pid=323599) 	sub.s32 	%r108, %r89, %r105;
(EngineCore_DP0 pid=323599) 	sub.s32 	%r109, %r88, %r104;
(EngineCore_DP0 pid=323599) 	sub.s32 	%r110, %r87, %r103;
(EngineCore_DP0 pid=323599) 	.loc	1 319 22                        // quant_slide_tuned_Llama3.2-1B.py:319:22
(EngineCore_DP0 pid=323599) 	shl.b32 	%r111, %r102, 3;
(EngineCore_DP0 pid=323599) 	shl.b32 	%r112, %r99, 3;
(EngineCore_DP0 pid=323599) 	shl.b32 	%r113, %r96, 3;
(EngineCore_DP0 pid=323599) 	shl.b32 	%r114, %r93, 3;
(EngineCore_DP0 pid=323599) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=323599) 	shl.b32 	%r115, %r110, 1;
(EngineCore_DP0 pid=323599) 	shl.b32 	%r116, %r109, 1;
(EngineCore_DP0 pid=323599) 	shl.b32 	%r117, %r108, 1;
(EngineCore_DP0 pid=323599) 	shl.b32 	%r118, %r107, 1;
(EngineCore_DP0 pid=323599) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=323599) 	add.s32 	%r119, %r114, %r118;
(EngineCore_DP0 pid=323599) 	add.s32 	%r120, %r113, %r117;
(EngineCore_DP0 pid=323599) 	add.s32 	%r121, %r112, %r116;
(EngineCore_DP0 pid=323599) 	add.s32 	%r122, %r111, %r115;
(EngineCore_DP0 pid=323599) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p26, %r122, %r27;
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p27, %r121, %r27;
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p28, %r120, %r27;
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p29, %r119, %r27;
(EngineCore_DP0 pid=323599) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=323599) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=323599) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=323599) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=323599) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=323599) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=323599) 	mad.wide.s32 	%rd8, %r122, 2, %rd1;
(EngineCore_DP0 pid=323599) 	mad.wide.s32 	%rd9, %r121, 2, %rd1;
(EngineCore_DP0 pid=323599) 	mad.wide.s32 	%rd10, %r120, 2, %rd1;
(EngineCore_DP0 pid=323599) 	mad.wide.s32 	%rd11, %r119, 2, %rd1;
(EngineCore_DP0 pid=323599) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=323599) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=323599) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=323599) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=323599) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=323599) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=323599) 	cvt.f32.bf16 	%r123, %rs24;
(EngineCore_DP0 pid=323599) 	cvt.f32.bf16 	%r124, %rs26;
(EngineCore_DP0 pid=323599) 	cvt.f32.bf16 	%r125, %rs28;
(EngineCore_DP0 pid=323599) 	cvt.f32.bf16 	%r126, %rs30;
(EngineCore_DP0 pid=323599) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=323599) 	or.b32 	%r127, %r122, 1;
(EngineCore_DP0 pid=323599) 	or.b32 	%r128, %r121, 1;
(EngineCore_DP0 pid=323599) 	or.b32 	%r129, %r120, 1;
(EngineCore_DP0 pid=323599) 	or.b32 	%r130, %r119, 1;
(EngineCore_DP0 pid=323599) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p30, %r127, %r27;
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p31, %r128, %r27;
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p32, %r129, %r27;
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p33, %r130, %r27;
(EngineCore_DP0 pid=323599) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=323599) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=323599) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=323599) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=323599) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=323599) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=323599) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=323599) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=323599) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=323599) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=323599) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=323599) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=323599) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=323599) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=323599) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=323599) 	cvt.f32.bf16 	%r131, %rs32;
(EngineCore_DP0 pid=323599) 	cvt.f32.bf16 	%r132, %rs34;
(EngineCore_DP0 pid=323599) 	cvt.f32.bf16 	%r133, %rs36;
(EngineCore_DP0 pid=323599) 	cvt.f32.bf16 	%r134, %rs38;
(EngineCore_DP0 pid=323599) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=323599) 	add.s32 	%r135, %r122, 2;
(EngineCore_DP0 pid=323599) 	add.s32 	%r136, %r121, 2;
(EngineCore_DP0 pid=323599) 	add.s32 	%r137, %r120, 2;
(EngineCore_DP0 pid=323599) 	add.s32 	%r138, %r119, 2;
(EngineCore_DP0 pid=323599) 	add.s32 	%r139, %r122, 3;
(EngineCore_DP0 pid=323599) 	add.s32 	%r140, %r121, 3;
(EngineCore_DP0 pid=323599) 	add.s32 	%r141, %r120, 3;
(EngineCore_DP0 pid=323599) 	add.s32 	%r142, %r119, 3;
(EngineCore_DP0 pid=323599) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p34, %r142, %r27;
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p35, %r141, %r27;
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p36, %r140, %r27;
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p37, %r139, %r27;
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p38, %r138, %r27;
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p39, %r137, %r27;
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p40, %r136, %r27;
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p41, %r135, %r27;
(EngineCore_DP0 pid=323599) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=323599) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=323599) 	and.pred 	%p18, %p25, %p40;
(EngineCore_DP0 pid=323599) 	and.pred 	%p19, %p25, %p39;
(EngineCore_DP0 pid=323599) 	and.pred 	%p20, %p25, %p38;
(EngineCore_DP0 pid=323599) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=323599) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=323599) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=323599) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=323599) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=323599) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=323599) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=323599) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=323599) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=323599) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=323599) 	cvt.f32.bf16 	%r143, %rs40;
(EngineCore_DP0 pid=323599) 	cvt.f32.bf16 	%r144, %rs42;
(EngineCore_DP0 pid=323599) 	cvt.f32.bf16 	%r145, %rs44;
(EngineCore_DP0 pid=323599) 	cvt.f32.bf16 	%r146, %rs46;
(EngineCore_DP0 pid=323599) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=323599) 	and.pred 	%p21, %p25, %p37;
(EngineCore_DP0 pid=323599) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=323599) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=323599) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=323599) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=323599) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=323599) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=323599) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=323599) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=323599) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=323599) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=323599) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=323599) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=323599) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=323599) 	cvt.f32.bf16 	%r147, %rs48;
(EngineCore_DP0 pid=323599) 	cvt.f32.bf16 	%r148, %rs50;
(EngineCore_DP0 pid=323599) 	cvt.f32.bf16 	%r149, %rs52;
(EngineCore_DP0 pid=323599) 	cvt.f32.bf16 	%r150, %rs54;
(EngineCore_DP0 pid=323599) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=323599) 	mul.f32 	%r151, %r14, %r123;
(EngineCore_DP0 pid=323599) 	mul.f32 	%r152, %r14, %r124;
(EngineCore_DP0 pid=323599) 	mul.f32 	%r153, %r14, %r125;
(EngineCore_DP0 pid=323599) 	mul.f32 	%r154, %r14, %r126;
(EngineCore_DP0 pid=323599) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=323599) 	cvt.rni.f32.f32 	%r155, %r151;
(EngineCore_DP0 pid=323599) 	cvt.rni.f32.f32 	%r156, %r152;
(EngineCore_DP0 pid=323599) 	cvt.rni.f32.f32 	%r157, %r153;
(EngineCore_DP0 pid=323599) 	cvt.rni.f32.f32 	%r158, %r154;
(EngineCore_DP0 pid=323599) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=323599) 	max.f32 	%r159, %r155, 0fC3000000;
(EngineCore_DP0 pid=323599) 	min.f32 	%r160, %r159, 0f42FE0000;
(EngineCore_DP0 pid=323599) 	max.f32 	%r161, %r156, 0fC3000000;
(EngineCore_DP0 pid=323599) 	min.f32 	%r162, %r161, 0f42FE0000;
(EngineCore_DP0 pid=323599) 	max.f32 	%r163, %r157, 0fC3000000;
(EngineCore_DP0 pid=323599) 	min.f32 	%r164, %r163, 0f42FE0000;
(EngineCore_DP0 pid=323599) 	max.f32 	%r165, %r158, 0fC3000000;
(EngineCore_DP0 pid=323599) 	min.f32 	%r166, %r165, 0f42FE0000;
(EngineCore_DP0 pid=323599) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=323599) 	cvt.rzi.s32.f32 	%r167, %r160;
(EngineCore_DP0 pid=323599) 	cvt.rzi.s32.f32 	%r168, %r162;
(EngineCore_DP0 pid=323599) 	cvt.rzi.s32.f32 	%r169, %r164;
(EngineCore_DP0 pid=323599) 	cvt.rzi.s32.f32 	%r170, %r166;
(EngineCore_DP0 pid=323599) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=323599) 	and.b32 	%r171, %r167, 255;
(EngineCore_DP0 pid=323599) 	and.b32 	%r172, %r168, 255;
(EngineCore_DP0 pid=323599) 	and.b32 	%r173, %r169, 255;
(EngineCore_DP0 pid=323599) 	and.b32 	%r174, %r170, 255;
(EngineCore_DP0 pid=323599) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=323599) 	mul.f32 	%r175, %r14, %r131;
(EngineCore_DP0 pid=323599) 	mul.f32 	%r176, %r14, %r132;
(EngineCore_DP0 pid=323599) 	mul.f32 	%r177, %r14, %r133;
(EngineCore_DP0 pid=323599) 	mul.f32 	%r178, %r14, %r134;
(EngineCore_DP0 pid=323599) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=323599) 	cvt.rni.f32.f32 	%r179, %r175;
(EngineCore_DP0 pid=323599) 	cvt.rni.f32.f32 	%r180, %r176;
(EngineCore_DP0 pid=323599) 	cvt.rni.f32.f32 	%r181, %r177;
(EngineCore_DP0 pid=323599) 	cvt.rni.f32.f32 	%r182, %r178;
(EngineCore_DP0 pid=323599) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=323599) 	mul.f32 	%r183, %r14, %r143;
(EngineCore_DP0 pid=323599) 	mul.f32 	%r184, %r14, %r144;
(EngineCore_DP0 pid=323599) 	mul.f32 	%r185, %r14, %r145;
(EngineCore_DP0 pid=323599) 	mul.f32 	%r186, %r14, %r146;
(EngineCore_DP0 pid=323599) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=323599) 	cvt.rni.f32.f32 	%r187, %r183;
(EngineCore_DP0 pid=323599) 	cvt.rni.f32.f32 	%r188, %r184;
(EngineCore_DP0 pid=323599) 	cvt.rni.f32.f32 	%r189, %r185;
(EngineCore_DP0 pid=323599) 	cvt.rni.f32.f32 	%r190, %r186;
(EngineCore_DP0 pid=323599) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=323599) 	mul.f32 	%r191, %r14, %r147;
(EngineCore_DP0 pid=323599) 	mul.f32 	%r192, %r14, %r148;
(EngineCore_DP0 pid=323599) 	mul.f32 	%r193, %r14, %r149;
(EngineCore_DP0 pid=323599) 	mul.f32 	%r194, %r14, %r150;
(EngineCore_DP0 pid=323599) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=323599) 	cvt.rni.f32.f32 	%r195, %r191;
(EngineCore_DP0 pid=323599) 	cvt.rni.f32.f32 	%r196, %r192;
(EngineCore_DP0 pid=323599) 	cvt.rni.f32.f32 	%r197, %r193;
(EngineCore_DP0 pid=323599) 	cvt.rni.f32.f32 	%r198, %r194;
(EngineCore_DP0 pid=323599) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=323599) 	max.f32 	%r199, %r195, 0fC3000000;
(EngineCore_DP0 pid=323599) 	min.f32 	%r200, %r199, 0f42FE0000;
(EngineCore_DP0 pid=323599) 	max.f32 	%r201, %r196, 0fC3000000;
(EngineCore_DP0 pid=323599) 	min.f32 	%r202, %r201, 0f42FE0000;
(EngineCore_DP0 pid=323599) 	max.f32 	%r203, %r197, 0fC3000000;
(EngineCore_DP0 pid=323599) 	min.f32 	%r204, %r203, 0f42FE0000;
(EngineCore_DP0 pid=323599) 	max.f32 	%r205, %r198, 0fC3000000;
(EngineCore_DP0 pid=323599) 	min.f32 	%r206, %r205, 0f42FE0000;
(EngineCore_DP0 pid=323599) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=323599) 	cvt.rzi.s32.f32 	%r207, %r200;
(EngineCore_DP0 pid=323599) 	cvt.rzi.s32.f32 	%r208, %r202;
(EngineCore_DP0 pid=323599) 	cvt.rzi.s32.f32 	%r209, %r204;
(EngineCore_DP0 pid=323599) 	cvt.rzi.s32.f32 	%r210, %r206;
(EngineCore_DP0 pid=323599) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=323599) 	max.f32 	%r211, %r187, 0fC3000000;
(EngineCore_DP0 pid=323599) 	max.f32 	%r212, %r179, 0fC3000000;
(EngineCore_DP0 pid=323599) 	min.f32 	%r213, %r212, 0f42FE0000;
(EngineCore_DP0 pid=323599) 	min.f32 	%r214, %r211, 0f42FE0000;
(EngineCore_DP0 pid=323599) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=323599) 	cvt.rzi.s32.f32 	%r215, %r214;
(EngineCore_DP0 pid=323599) 	cvt.rzi.s32.f32 	%r216, %r213;
(EngineCore_DP0 pid=323599) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=323599) 	shl.b32 	%r217, %r216, 8;
(EngineCore_DP0 pid=323599) 	shl.b32 	%r218, %r215, 16;
(EngineCore_DP0 pid=323599) 	and.b32 	%r219, %r218, 16711680;
(EngineCore_DP0 pid=323599) 	and.b32 	%r220, %r217, 65280;
(EngineCore_DP0 pid=323599) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=323599) 	or.b32 	%r221, %r220, %r171;
(EngineCore_DP0 pid=323599) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=323599) 	max.f32 	%r222, %r188, 0fC3000000;
(EngineCore_DP0 pid=323599) 	max.f32 	%r223, %r180, 0fC3000000;
(EngineCore_DP0 pid=323599) 	min.f32 	%r224, %r223, 0f42FE0000;
(EngineCore_DP0 pid=323599) 	min.f32 	%r225, %r222, 0f42FE0000;
(EngineCore_DP0 pid=323599) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=323599) 	cvt.rzi.s32.f32 	%r226, %r225;
(EngineCore_DP0 pid=323599) 	cvt.rzi.s32.f32 	%r227, %r224;
(EngineCore_DP0 pid=323599) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=323599) 	shl.b32 	%r228, %r227, 8;
(EngineCore_DP0 pid=323599) 	shl.b32 	%r229, %r226, 16;
(EngineCore_DP0 pid=323599) 	and.b32 	%r230, %r229, 16711680;
(EngineCore_DP0 pid=323599) 	and.b32 	%r231, %r228, 65280;
(EngineCore_DP0 pid=323599) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=323599) 	or.b32 	%r232, %r231, %r172;
(EngineCore_DP0 pid=323599) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=323599) 	max.f32 	%r233, %r189, 0fC3000000;
(EngineCore_DP0 pid=323599) 	max.f32 	%r234, %r181, 0fC3000000;
(EngineCore_DP0 pid=323599) 	min.f32 	%r235, %r234, 0f42FE0000;
(EngineCore_DP0 pid=323599) 	min.f32 	%r236, %r233, 0f42FE0000;
(EngineCore_DP0 pid=323599) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=323599) 	cvt.rzi.s32.f32 	%r237, %r236;
(EngineCore_DP0 pid=323599) 	cvt.rzi.s32.f32 	%r238, %r235;
(EngineCore_DP0 pid=323599) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=323599) 	shl.b32 	%r239, %r238, 8;
(EngineCore_DP0 pid=323599) 	shl.b32 	%r240, %r237, 16;
(EngineCore_DP0 pid=323599) 	and.b32 	%r241, %r240, 16711680;
(EngineCore_DP0 pid=323599) 	and.b32 	%r242, %r239, 65280;
(EngineCore_DP0 pid=323599) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=323599) 	or.b32 	%r243, %r242, %r173;
(EngineCore_DP0 pid=323599) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=323599) 	max.f32 	%r244, %r190, 0fC3000000;
(EngineCore_DP0 pid=323599) 	max.f32 	%r245, %r182, 0fC3000000;
(EngineCore_DP0 pid=323599) 	min.f32 	%r246, %r245, 0f42FE0000;
(EngineCore_DP0 pid=323599) 	min.f32 	%r247, %r244, 0f42FE0000;
(EngineCore_DP0 pid=323599) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=323599) 	cvt.rzi.s32.f32 	%r248, %r247;
(EngineCore_DP0 pid=323599) 	cvt.rzi.s32.f32 	%r249, %r246;
(EngineCore_DP0 pid=323599) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=323599) 	shl.b32 	%r250, %r249, 8;
(EngineCore_DP0 pid=323599) 	shl.b32 	%r251, %r248, 16;
(EngineCore_DP0 pid=323599) 	and.b32 	%r252, %r251, 16711680;
(EngineCore_DP0 pid=323599) 	and.b32 	%r253, %r250, 65280;
(EngineCore_DP0 pid=323599) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=323599) 	or.b32 	%r254, %r253, %r174;
(EngineCore_DP0 pid=323599) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=323599) 	or.b32 	%r255, %r221, %r219;
(EngineCore_DP0 pid=323599) 	or.b32 	%r256, %r232, %r230;
(EngineCore_DP0 pid=323599) 	or.b32 	%r257, %r243, %r241;
(EngineCore_DP0 pid=323599) 	or.b32 	%r258, %r254, %r252;
(EngineCore_DP0 pid=323599) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=323599) 	shl.b32 	%r259, %r207, 24;
(EngineCore_DP0 pid=323599) 	shl.b32 	%r260, %r208, 24;
(EngineCore_DP0 pid=323599) 	shl.b32 	%r261, %r209, 24;
(EngineCore_DP0 pid=323599) 	shl.b32 	%r262, %r210, 24;
(EngineCore_DP0 pid=323599) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=323599) 	or.b32 	%r82, %r255, %r259;
(EngineCore_DP0 pid=323599) 	or.b32 	%r83, %r256, %r260;
(EngineCore_DP0 pid=323599) 	or.b32 	%r84, %r257, %r261;
(EngineCore_DP0 pid=323599) 	or.b32 	%r85, %r258, %r262;
(EngineCore_DP0 pid=323599) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=323599) 	mad.wide.s32 	%rd24, %r87, 4, %rd2;
(EngineCore_DP0 pid=323599) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=323599) 	// begin inline asm
(EngineCore_DP0 pid=323599) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r82, %r83, %r84, %r85 };
(EngineCore_DP0 pid=323599) 	// end inline asm
(EngineCore_DP0 pid=323599) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=323599) 	add.s32 	%r266, %r266, 2048;
(EngineCore_DP0 pid=323599) 	setp.lt.s32 	%p42, %r266, %r15;
(EngineCore_DP0 pid=323599) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=323599) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=323599) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=323599) 	ret;
(EngineCore_DP0 pid=323599) $L__tmp3:
(EngineCore_DP0 pid=323599) $L__func_end0:
(EngineCore_DP0 pid=323599)                                         // -- End function
(EngineCore_DP0 pid=323599) }
(EngineCore_DP0 pid=323599) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=323599) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=323599) 	.section	.debug_abbrev
(EngineCore_DP0 pid=323599) 	{
(EngineCore_DP0 pid=323599) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=323599) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=323599) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=323599) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=323599) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=323599) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=323599) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=323599) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=323599) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=323599) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=323599) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=323599) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=323599) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=323599) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=323599) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=323599) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=323599) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=323599) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=323599) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=323599) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=323599) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=323599) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=323599) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=323599) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=323599) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=323599) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=323599) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=323599) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=323599) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=323599) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=323599) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=323599) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=323599) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=323599) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=323599) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=323599) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=323599) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=323599) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=323599) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=323599) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=323599) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=323599) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=323599) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=323599) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=323599) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=323599) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=323599) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=323599) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=323599) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=323599) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=323599) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=323599) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=323599) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=323599) 	}
(EngineCore_DP0 pid=323599) 	.section	.debug_info
(EngineCore_DP0 pid=323599) 	{
(EngineCore_DP0 pid=323599) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=323599) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=323599) .b8 0
(EngineCore_DP0 pid=323599) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=323599) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=323599) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=323599) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=323599) .b8 114
(EngineCore_DP0 pid=323599) .b8 105
(EngineCore_DP0 pid=323599) .b8 116
(EngineCore_DP0 pid=323599) .b8 111
(EngineCore_DP0 pid=323599) .b8 110
(EngineCore_DP0 pid=323599) .b8 0
(EngineCore_DP0 pid=323599) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=323599) .b8 0
(EngineCore_DP0 pid=323599) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=323599) .b8 117
(EngineCore_DP0 pid=323599) .b8 97
(EngineCore_DP0 pid=323599) .b8 110
(EngineCore_DP0 pid=323599) .b8 116
(EngineCore_DP0 pid=323599) .b8 95
(EngineCore_DP0 pid=323599) .b8 115
(EngineCore_DP0 pid=323599) .b8 108
(EngineCore_DP0 pid=323599) .b8 105
(EngineCore_DP0 pid=323599) .b8 100
(EngineCore_DP0 pid=323599) .b8 101
(EngineCore_DP0 pid=323599) .b8 95
(EngineCore_DP0 pid=323599) .b8 116
(EngineCore_DP0 pid=323599) .b8 117
(EngineCore_DP0 pid=323599) .b8 110
(EngineCore_DP0 pid=323599) .b8 101
(EngineCore_DP0 pid=323599) .b8 100
(EngineCore_DP0 pid=323599) .b8 95
(EngineCore_DP0 pid=323599) .b8 76
(EngineCore_DP0 pid=323599) .b8 108
(EngineCore_DP0 pid=323599) .b8 97
(EngineCore_DP0 pid=323599) .b8 109
(EngineCore_DP0 pid=323599) .b8 97
(EngineCore_DP0 pid=323599) .b8 51
(EngineCore_DP0 pid=323599) .b8 46
(EngineCore_DP0 pid=323599) .b8 50
(EngineCore_DP0 pid=323599) .b8 45
(EngineCore_DP0 pid=323599) .b8 49
(EngineCore_DP0 pid=323599) .b8 66
(EngineCore_DP0 pid=323599) .b8 46
(EngineCore_DP0 pid=323599) .b8 112
(EngineCore_DP0 pid=323599) .b8 121
(EngineCore_DP0 pid=323599) .b8 0
(EngineCore_DP0 pid=323599) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=323599) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=323599) .b8 114
(EngineCore_DP0 pid=323599) .b8 111
(EngineCore_DP0 pid=323599) .b8 111
(EngineCore_DP0 pid=323599) .b8 116
(EngineCore_DP0 pid=323599) .b8 47
(EngineCore_DP0 pid=323599) .b8 118
(EngineCore_DP0 pid=323599) .b8 108
(EngineCore_DP0 pid=323599) .b8 108
(EngineCore_DP0 pid=323599) .b8 109
(EngineCore_DP0 pid=323599) .b8 98
(EngineCore_DP0 pid=323599) .b8 101
(EngineCore_DP0 pid=323599) .b8 110
(EngineCore_DP0 pid=323599) .b8 99
(EngineCore_DP0 pid=323599) .b8 104
(EngineCore_DP0 pid=323599) .b8 47
(EngineCore_DP0 pid=323599) .b8 115
(EngineCore_DP0 pid=323599) .b8 108
(EngineCore_DP0 pid=323599) .b8 105
(EngineCore_DP0 pid=323599) .b8 100
(EngineCore_DP0 pid=323599) .b8 101
(EngineCore_DP0 pid=323599) .b8 115
(EngineCore_DP0 pid=323599) .b8 112
(EngineCore_DP0 pid=323599) .b8 97
(EngineCore_DP0 pid=323599) .b8 114
(EngineCore_DP0 pid=323599) .b8 115
(EngineCore_DP0 pid=323599) .b8 101
(EngineCore_DP0 pid=323599) .b8 47
(EngineCore_DP0 pid=323599) .b8 99
(EngineCore_DP0 pid=323599) .b8 115
(EngineCore_DP0 pid=323599) .b8 114
(EngineCore_DP0 pid=323599) .b8 99
(EngineCore_DP0 pid=323599) .b8 47
(EngineCore_DP0 pid=323599) .b8 102
(EngineCore_DP0 pid=323599) .b8 117
(EngineCore_DP0 pid=323599) .b8 115
(EngineCore_DP0 pid=323599) .b8 101
(EngineCore_DP0 pid=323599) .b8 100
(EngineCore_DP0 pid=323599) .b8 95
(EngineCore_DP0 pid=323599) .b8 113
(EngineCore_DP0 pid=323599) .b8 117
(EngineCore_DP0 pid=323599) .b8 97
(EngineCore_DP0 pid=323599) .b8 110
(EngineCore_DP0 pid=323599) .b8 116
(EngineCore_DP0 pid=323599) .b8 95
(EngineCore_DP0 pid=323599) .b8 115
(EngineCore_DP0 pid=323599) .b8 108
(EngineCore_DP0 pid=323599) .b8 105
(EngineCore_DP0 pid=323599) .b8 100
(EngineCore_DP0 pid=323599) .b8 101
(EngineCore_DP0 pid=323599) .b8 95
(EngineCore_DP0 pid=323599) .b8 116
(EngineCore_DP0 pid=323599) .b8 114
(EngineCore_DP0 pid=323599) .b8 105
(EngineCore_DP0 pid=323599) .b8 116
(EngineCore_DP0 pid=323599) .b8 111
(EngineCore_DP0 pid=323599) .b8 110
(EngineCore_DP0 pid=323599) .b8 47
(EngineCore_DP0 pid=323599) .b8 98
(EngineCore_DP0 pid=323599) .b8 117
(EngineCore_DP0 pid=323599) .b8 105
(EngineCore_DP0 pid=323599) .b8 108
(EngineCore_DP0 pid=323599) .b8 100
(EngineCore_DP0 pid=323599) .b8 47
(EngineCore_DP0 pid=323599) .b8 71
(EngineCore_DP0 pid=323599) .b8 66
(EngineCore_DP0 pid=323599) .b8 49
(EngineCore_DP0 pid=323599) .b8 48
(EngineCore_DP0 pid=323599) .b8 95
(EngineCore_DP0 pid=323599) .b8 99
(EngineCore_DP0 pid=323599) .b8 99
(EngineCore_DP0 pid=323599) .b8 49
(EngineCore_DP0 pid=323599) .b8 50
(EngineCore_DP0 pid=323599) .b8 49
(EngineCore_DP0 pid=323599) .b8 95
(EngineCore_DP0 pid=323599) .b8 112
(EngineCore_DP0 pid=323599) .b8 121
(EngineCore_DP0 pid=323599) .b8 51
(EngineCore_DP0 pid=323599) .b8 49
(EngineCore_DP0 pid=323599) .b8 50
(EngineCore_DP0 pid=323599) .b8 95
(EngineCore_DP0 pid=323599) .b8 99
(EngineCore_DP0 pid=323599) .b8 117
(EngineCore_DP0 pid=323599) .b8 49
(EngineCore_DP0 pid=323599) .b8 50
(EngineCore_DP0 pid=323599) .b8 57
(EngineCore_DP0 pid=323599) .b8 95
(EngineCore_DP0 pid=323599) .b8 97
(EngineCore_DP0 pid=323599) .b8 97
(EngineCore_DP0 pid=323599) .b8 114
(EngineCore_DP0 pid=323599) .b8 99
(EngineCore_DP0 pid=323599) .b8 104
(EngineCore_DP0 pid=323599) .b8 54
(EngineCore_DP0 pid=323599) .b8 52
(EngineCore_DP0 pid=323599) .b8 0
(EngineCore_DP0 pid=323599) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=323599) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=323599) .b8 113
(EngineCore_DP0 pid=323599) .b8 117
(EngineCore_DP0 pid=323599) .b8 97
(EngineCore_DP0 pid=323599) .b8 110
(EngineCore_DP0 pid=323599) .b8 116
(EngineCore_DP0 pid=323599) .b8 95
(EngineCore_DP0 pid=323599) .b8 115
(EngineCore_DP0 pid=323599) .b8 108
(EngineCore_DP0 pid=323599) .b8 105
(EngineCore_DP0 pid=323599) .b8 100
(EngineCore_DP0 pid=323599) .b8 101
(EngineCore_DP0 pid=323599) .b8 95
(EngineCore_DP0 pid=323599) .b8 105
(EngineCore_DP0 pid=323599) .b8 110
(EngineCore_DP0 pid=323599) .b8 116
(EngineCore_DP0 pid=323599) .b8 56
(EngineCore_DP0 pid=323599) .b8 95
(EngineCore_DP0 pid=323599) .b8 107
(EngineCore_DP0 pid=323599) .b8 101
(EngineCore_DP0 pid=323599) .b8 114
(EngineCore_DP0 pid=323599) .b8 110
(EngineCore_DP0 pid=323599) .b8 101
(EngineCore_DP0 pid=323599) .b8 108
(EngineCore_DP0 pid=323599) .b8 0
(EngineCore_DP0 pid=323599) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=323599) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=323599) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=323599) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=323599) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=323599) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=323599) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=323599) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=323599) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=323599) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=323599) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=323599) .b8 1
(EngineCore_DP0 pid=323599) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=323599) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=323599) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=323599) 	}
(EngineCore_DP0 pid=323599) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=323599) 
(EngineCore_DP0 pid=323599) ================================================================
(EngineCore_DP0 pid=323599) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=323599) 
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpzuvqk_v7.ptx', '-o', '/tmp/tmpzuvqk_v7.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866] 
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866] 
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866] 
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpzuvqk_v7.ptx -o /tmp/tmpzuvqk_v7.ptx.o
(EngineCore_DP0 pid=323599) ERROR 01-25 19:06:02 [core.py:866] 

STDERR:
[2026-01-25 19:05:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:05:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:05:45] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:05:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:05:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:05:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:05:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:05:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:05:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:05:48] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:05:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:05:48] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:05:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:05:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:05:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:05:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:05:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:05:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:05:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=323599) [2026-01-25 19:05:49] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=323599) [2026-01-25 19:05:49] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=323599) [2026-01-25 19:05:49] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=323599) [2026-01-25 19:05:49] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=323599) [2026-01-25 19:05:49] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=323599) [2026-01-25 19:05:49] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=323599) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=323599) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:11<00:00, 11.01s/it]
(EngineCore_DP0 pid=323599) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:11<00:00, 11.01s/it]
(EngineCore_DP0 pid=323599) 
(EngineCore_DP0 pid=323599) [2026-01-25 19:06:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=323599) [2026-01-25 19:06:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=323599) [2026-01-25 19:06:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=323599) [2026-01-25 19:06:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=323599) [2026-01-25 19:06:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=323599) [2026-01-25 19:06:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=323599) [2026-01-25 19:06:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=323599) [2026-01-25 19:06:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=323599) Process EngineCore_DP0:
(EngineCore_DP0 pid=323599) Traceback (most recent call last):
(EngineCore_DP0 pid=323599)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=323599)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=323599)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=323599)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=323599) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpzuvqk_v7.ptx', '-o', '/tmp/tmpzuvqk_v7.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=323599) 
(EngineCore_DP0 pid=323599) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=323599) 
(EngineCore_DP0 pid=323599) Traceback (most recent call last):
(EngineCore_DP0 pid=323599)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=323599)     self.run()
(EngineCore_DP0 pid=323599)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=323599)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=323599)     raise e
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=323599)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=323599)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=323599)     super().__init__(
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=323599)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=323599)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=323599)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=323599)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=323599)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=323599)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=323599)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=323599)     return func(*args, **kwargs)
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=323599)     return func(*args, **kwargs)
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=323599)     self.model_runner.profile_run()
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=323599)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=323599)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=323599)     return func(*args, **kwargs)
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=323599)     outputs = self.model(
(EngineCore_DP0 pid=323599)               ^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=323599)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=323599)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=323599)     model_output = self.model(
(EngineCore_DP0 pid=323599)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=323599)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=323599)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=323599)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=323599)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=323599)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=323599)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=323599)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=323599)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=323599)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=323599)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=323599)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=323599)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=323599)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=323599)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=323599)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=323599)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=323599)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=323599)     return self._linear_fn(
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=323599)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=323599)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=323599)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=323599)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=323599)     return fn(input, L)
(EngineCore_DP0 pid=323599)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=323599)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=323599)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=323599)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=323599)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=323599)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=323599)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=323599)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=323599)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=323599)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=323599)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=323599)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=323599)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=323599)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=323599)     raise PTXASError(error)
(EngineCore_DP0 pid=323599) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=323599) `ptxas` stderr:
(EngineCore_DP0 pid=323599) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=323599) 
(EngineCore_DP0 pid=323599) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpzuvqk_v7.ptx -o /tmp/tmpzuvqk_v7.ptx.o
(EngineCore_DP0 pid=323599) 
[rank0]:[W125 19:06:02.612741037 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-25 19:43:04
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:43:07 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:43:08 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=368647) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=368647) 
(EngineCore_DP0 pid=368647) 
(EngineCore_DP0 pid=368647) ================================================================
(EngineCore_DP0 pid=368647) Internal Triton PTX codegen error
(EngineCore_DP0 pid=368647) `ptxas` stderr:
(EngineCore_DP0 pid=368647) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=368647) 
(EngineCore_DP0 pid=368647) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpaboonsog.ptx -o /tmp/tmpaboonsog.ptx.o
(EngineCore_DP0 pid=368647) 
(EngineCore_DP0 pid=368647) 
(EngineCore_DP0 pid=368647) //
(EngineCore_DP0 pid=368647) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=368647) //
(EngineCore_DP0 pid=368647) 
(EngineCore_DP0 pid=368647) .version 8.7
(EngineCore_DP0 pid=368647) .target sm_121a
(EngineCore_DP0 pid=368647) .address_size 64
(EngineCore_DP0 pid=368647) 
(EngineCore_DP0 pid=368647) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=368647) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=368647)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=368647) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=368647) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=368647) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=368647) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=368647) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=368647) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=368647) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=368647) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=368647) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=368647) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=368647) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=368647) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=368647) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=368647) )
(EngineCore_DP0 pid=368647) .reqntid 1024
(EngineCore_DP0 pid=368647) {
(EngineCore_DP0 pid=368647) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=368647) 	.reg .b16 	%rs<20>;
(EngineCore_DP0 pid=368647) 	.reg .b32 	%r<120>;
(EngineCore_DP0 pid=368647) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=368647) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=368647) $L__func_begin0:
(EngineCore_DP0 pid=368647) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=368647) 
(EngineCore_DP0 pid=368647) // %bb.0:
(EngineCore_DP0 pid=368647) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=368647) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=368647) 	ld.param.b32 	%r17, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=368647) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=368647) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=368647) $L__tmp0:
(EngineCore_DP0 pid=368647) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=368647) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=368647) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=368647) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=368647) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=368647) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=368647) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=368647) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=368647) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=368647) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=368647) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=368647) 	mov.b32 	%r118, 0f2B8CBCCC;
(EngineCore_DP0 pid=368647) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=368647) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=368647) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=368647) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=368647) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=368647) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=368647) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=368647) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=368647) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=368647) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=368647) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=368647) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=368647) 	mov.b32 	%r116, 0f00000000;
(EngineCore_DP0 pid=368647) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=368647) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=368647) 	mov.b32 	%r117, %r37;
(EngineCore_DP0 pid=368647) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=368647) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=368647) 	add.s32 	%r45, %r3, %r117;
(EngineCore_DP0 pid=368647) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=368647) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=368647) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=368647) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=368647) 	// begin inline asm
(EngineCore_DP0 pid=368647) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=368647) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=368647) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=368647) 	// end inline asm
(EngineCore_DP0 pid=368647) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=368647) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=368647) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=368647) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=368647) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=368647) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=368647) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=368647) $L__tmp1:
(EngineCore_DP0 pid=368647) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	bar.sync 	0;
(EngineCore_DP0 pid=368647) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=368647) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=368647) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=368647) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=368647) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=368647) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=368647) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=368647) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=368647) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=368647) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=368647) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=368647) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=368647) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=368647) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=368647) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	// begin inline asm
(EngineCore_DP0 pid=368647) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=368647) 	// end inline asm
(EngineCore_DP0 pid=368647) 	bar.sync 	0;
(EngineCore_DP0 pid=368647) 	// begin inline asm
(EngineCore_DP0 pid=368647) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=368647) 	// end inline asm
(EngineCore_DP0 pid=368647) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=368647) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=368647) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=368647) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=368647) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=368647) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=368647) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=368647) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=368647) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=368647) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=368647) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=368647) 	// begin inline asm
(EngineCore_DP0 pid=368647) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=368647) 	// end inline asm
(EngineCore_DP0 pid=368647) 	bar.sync 	0;
(EngineCore_DP0 pid=368647) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=368647) $L__tmp2:
(EngineCore_DP0 pid=368647) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=368647) 	max.f32 	%r116, %r116, %r65;
(EngineCore_DP0 pid=368647) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=368647) 	add.s32 	%r117, %r117, 4096;
(EngineCore_DP0 pid=368647) 	setp.lt.s32 	%p6, %r117, %r18;
(EngineCore_DP0 pid=368647) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=368647) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=368647) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=368647) 	max.f32 	%r118, %r116, 0f2B8CBCCC;
(EngineCore_DP0 pid=368647) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=368647) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=368647) 	mov.b32 	%r67, 0f42FE0000;
(EngineCore_DP0 pid=368647) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=368647) 	div.full.f32 	%r68, %r118, %r67;
(EngineCore_DP0 pid=368647) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=368647) 	max.f32 	%r66, %r68, 0f37810204;
(EngineCore_DP0 pid=368647) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=368647) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=368647) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=368647) 	// begin inline asm
(EngineCore_DP0 pid=368647) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=368647) 	// end inline asm
(EngineCore_DP0 pid=368647) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=368647) 	mul.lo.s32 	%r14, %r19, 3;
(EngineCore_DP0 pid=368647) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=368647) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=368647) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=368647) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=368647) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=368647) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=368647) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=368647) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=368647) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=368647) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=368647) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=368647) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=368647) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=368647) 	div.full.f32 	%r13, %r67, %r118;
(EngineCore_DP0 pid=368647) 	mov.b32 	%r119, 0;
(EngineCore_DP0 pid=368647) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=368647)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=368647) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=368647) 	add.s32 	%r72, %r2, %r119;
(EngineCore_DP0 pid=368647) 	setp.lt.s32 	%p13, %r72, %r14;
(EngineCore_DP0 pid=368647) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=368647) 	mul.hi.s32 	%r73, %r72, 1431655766;
(EngineCore_DP0 pid=368647) 	shr.u32 	%r74, %r73, 31;
(EngineCore_DP0 pid=368647) 	add.s32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=368647) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=368647) 	mul.lo.s32 	%r76, %r75, 3;
(EngineCore_DP0 pid=368647) 	sub.s32 	%r77, %r72, %r76;
(EngineCore_DP0 pid=368647) 	.loc	1 333 22                        // quant_slide_tuned_Llama3.2-3B.py:333:22
(EngineCore_DP0 pid=368647) 	shl.b32 	%r78, %r75, 3;
(EngineCore_DP0 pid=368647) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=368647) 	shl.b32 	%r79, %r77, 1;
(EngineCore_DP0 pid=368647) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=368647) 	add.s32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=368647) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=368647) 	setp.lt.s32 	%p14, %r80, %r17;
(EngineCore_DP0 pid=368647) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=368647) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=368647) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=368647) 	mad.wide.s32 	%rd8, %r80, 2, %rd1;
(EngineCore_DP0 pid=368647) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=368647) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=368647) 	// begin inline asm
(EngineCore_DP0 pid=368647) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=368647) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=368647) 	// end inline asm
(EngineCore_DP0 pid=368647) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=368647) 	cvt.f32.bf16 	%r81, %rs12;
(EngineCore_DP0 pid=368647) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=368647) 	or.b32 	%r82, %r80, 1;
(EngineCore_DP0 pid=368647) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=368647) 	setp.lt.s32 	%p15, %r82, %r17;
(EngineCore_DP0 pid=368647) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=368647) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=368647) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=368647) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=368647) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=368647) 	// begin inline asm
(EngineCore_DP0 pid=368647) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=368647) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=368647) 	// end inline asm
(EngineCore_DP0 pid=368647) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=368647) 	cvt.f32.bf16 	%r83, %rs14;
(EngineCore_DP0 pid=368647) 	.loc	1 340 48                        // quant_slide_tuned_Llama3.2-3B.py:340:48
(EngineCore_DP0 pid=368647) 	add.s32 	%r84, %r80, 2;
(EngineCore_DP0 pid=368647) 	.loc	1 340 53                        // quant_slide_tuned_Llama3.2-3B.py:340:53
(EngineCore_DP0 pid=368647) 	setp.lt.s32 	%p16, %r84, %r17;
(EngineCore_DP0 pid=368647) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=368647) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=368647) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=368647) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=368647) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=368647) 	// begin inline asm
(EngineCore_DP0 pid=368647) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=368647) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=368647) 	// end inline asm
(EngineCore_DP0 pid=368647) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=368647) 	cvt.f32.bf16 	%r85, %rs16;
(EngineCore_DP0 pid=368647) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=368647) 	add.s32 	%r86, %r80, 3;
(EngineCore_DP0 pid=368647) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=368647) 	setp.lt.s32 	%p17, %r86, %r17;
(EngineCore_DP0 pid=368647) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=368647) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=368647) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=368647) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=368647) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=368647) 	// begin inline asm
(EngineCore_DP0 pid=368647) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=368647) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=368647) 	// end inline asm
(EngineCore_DP0 pid=368647) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=368647) 	cvt.f32.bf16 	%r87, %rs18;
(EngineCore_DP0 pid=368647) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=368647) 	mul.f32 	%r88, %r13, %r81;
(EngineCore_DP0 pid=368647) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=368647) 	cvt.rni.f32.f32 	%r89, %r88;
(EngineCore_DP0 pid=368647) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=368647) 	max.f32 	%r90, %r89, 0fC3000000;
(EngineCore_DP0 pid=368647) 	min.f32 	%r91, %r90, 0f42FE0000;
(EngineCore_DP0 pid=368647) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=368647) 	cvt.rzi.s32.f32 	%r92, %r91;
(EngineCore_DP0 pid=368647) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=368647) 	and.b32 	%r93, %r92, 255;
(EngineCore_DP0 pid=368647) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=368647) 	mul.f32 	%r94, %r13, %r83;
(EngineCore_DP0 pid=368647) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=368647) 	cvt.rni.f32.f32 	%r95, %r94;
(EngineCore_DP0 pid=368647) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=368647) 	mul.f32 	%r96, %r13, %r85;
(EngineCore_DP0 pid=368647) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=368647) 	cvt.rni.f32.f32 	%r97, %r96;
(EngineCore_DP0 pid=368647) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=368647) 	mul.f32 	%r98, %r13, %r87;
(EngineCore_DP0 pid=368647) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=368647) 	cvt.rni.f32.f32 	%r99, %r98;
(EngineCore_DP0 pid=368647) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=368647) 	max.f32 	%r100, %r99, 0fC3000000;
(EngineCore_DP0 pid=368647) 	min.f32 	%r101, %r100, 0f42FE0000;
(EngineCore_DP0 pid=368647) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=368647) 	cvt.rzi.s32.f32 	%r102, %r101;
(EngineCore_DP0 pid=368647) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=368647) 	max.f32 	%r103, %r97, 0fC3000000;
(EngineCore_DP0 pid=368647) 	max.f32 	%r104, %r95, 0fC3000000;
(EngineCore_DP0 pid=368647) 	min.f32 	%r105, %r104, 0f42FE0000;
(EngineCore_DP0 pid=368647) 	min.f32 	%r106, %r103, 0f42FE0000;
(EngineCore_DP0 pid=368647) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=368647) 	cvt.rzi.s32.f32 	%r107, %r106;
(EngineCore_DP0 pid=368647) 	cvt.rzi.s32.f32 	%r108, %r105;
(EngineCore_DP0 pid=368647) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=368647) 	shl.b32 	%r109, %r108, 8;
(EngineCore_DP0 pid=368647) 	shl.b32 	%r110, %r107, 16;
(EngineCore_DP0 pid=368647) 	and.b32 	%r111, %r110, 16711680;
(EngineCore_DP0 pid=368647) 	and.b32 	%r112, %r109, 65280;
(EngineCore_DP0 pid=368647) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=368647) 	or.b32 	%r113, %r112, %r93;
(EngineCore_DP0 pid=368647) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=368647) 	or.b32 	%r114, %r113, %r111;
(EngineCore_DP0 pid=368647) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=368647) 	shl.b32 	%r115, %r102, 24;
(EngineCore_DP0 pid=368647) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=368647) 	or.b32 	%r70, %r114, %r115;
(EngineCore_DP0 pid=368647) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=368647) 	mad.wide.s32 	%rd12, %r72, 4, %rd2;
(EngineCore_DP0 pid=368647) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=368647) 	// begin inline asm
(EngineCore_DP0 pid=368647) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r70 };
(EngineCore_DP0 pid=368647) 	// end inline asm
(EngineCore_DP0 pid=368647) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=368647) 	add.s32 	%r119, %r119, 1024;
(EngineCore_DP0 pid=368647) 	setp.lt.s32 	%p18, %r119, %r14;
(EngineCore_DP0 pid=368647) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=368647) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=368647) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=368647) 	ret;
(EngineCore_DP0 pid=368647) $L__tmp3:
(EngineCore_DP0 pid=368647) $L__func_end0:
(EngineCore_DP0 pid=368647)                                         // -- End function
(EngineCore_DP0 pid=368647) }
(EngineCore_DP0 pid=368647) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=368647) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=368647) 	.section	.debug_abbrev
(EngineCore_DP0 pid=368647) 	{
(EngineCore_DP0 pid=368647) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=368647) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=368647) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=368647) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=368647) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=368647) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=368647) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=368647) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=368647) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=368647) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=368647) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=368647) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=368647) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=368647) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=368647) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=368647) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=368647) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=368647) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=368647) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=368647) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=368647) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=368647) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=368647) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=368647) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=368647) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=368647) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=368647) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=368647) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=368647) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=368647) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=368647) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=368647) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=368647) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=368647) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=368647) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=368647) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=368647) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=368647) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=368647) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=368647) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=368647) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=368647) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=368647) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=368647) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=368647) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=368647) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=368647) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=368647) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=368647) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=368647) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=368647) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=368647) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=368647) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=368647) 	}
(EngineCore_DP0 pid=368647) 	.section	.debug_info
(EngineCore_DP0 pid=368647) 	{
(EngineCore_DP0 pid=368647) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=368647) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=368647) .b8 0
(EngineCore_DP0 pid=368647) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=368647) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=368647) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=368647) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=368647) .b8 114
(EngineCore_DP0 pid=368647) .b8 105
(EngineCore_DP0 pid=368647) .b8 116
(EngineCore_DP0 pid=368647) .b8 111
(EngineCore_DP0 pid=368647) .b8 110
(EngineCore_DP0 pid=368647) .b8 0
(EngineCore_DP0 pid=368647) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=368647) .b8 0
(EngineCore_DP0 pid=368647) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=368647) .b8 117
(EngineCore_DP0 pid=368647) .b8 97
(EngineCore_DP0 pid=368647) .b8 110
(EngineCore_DP0 pid=368647) .b8 116
(EngineCore_DP0 pid=368647) .b8 95
(EngineCore_DP0 pid=368647) .b8 115
(EngineCore_DP0 pid=368647) .b8 108
(EngineCore_DP0 pid=368647) .b8 105
(EngineCore_DP0 pid=368647) .b8 100
(EngineCore_DP0 pid=368647) .b8 101
(EngineCore_DP0 pid=368647) .b8 95
(EngineCore_DP0 pid=368647) .b8 116
(EngineCore_DP0 pid=368647) .b8 117
(EngineCore_DP0 pid=368647) .b8 110
(EngineCore_DP0 pid=368647) .b8 101
(EngineCore_DP0 pid=368647) .b8 100
(EngineCore_DP0 pid=368647) .b8 95
(EngineCore_DP0 pid=368647) .b8 76
(EngineCore_DP0 pid=368647) .b8 108
(EngineCore_DP0 pid=368647) .b8 97
(EngineCore_DP0 pid=368647) .b8 109
(EngineCore_DP0 pid=368647) .b8 97
(EngineCore_DP0 pid=368647) .b8 51
(EngineCore_DP0 pid=368647) .b8 46
(EngineCore_DP0 pid=368647) .b8 50
(EngineCore_DP0 pid=368647) .b8 45
(EngineCore_DP0 pid=368647) .b8 51
(EngineCore_DP0 pid=368647) .b8 66
(EngineCore_DP0 pid=368647) .b8 46
(EngineCore_DP0 pid=368647) .b8 112
(EngineCore_DP0 pid=368647) .b8 121
(EngineCore_DP0 pid=368647) .b8 0
(EngineCore_DP0 pid=368647) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=368647) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=368647) .b8 114
(EngineCore_DP0 pid=368647) .b8 111
(EngineCore_DP0 pid=368647) .b8 111
(EngineCore_DP0 pid=368647) .b8 116
(EngineCore_DP0 pid=368647) .b8 47
(EngineCore_DP0 pid=368647) .b8 118
(EngineCore_DP0 pid=368647) .b8 108
(EngineCore_DP0 pid=368647) .b8 108
(EngineCore_DP0 pid=368647) .b8 109
(EngineCore_DP0 pid=368647) .b8 98
(EngineCore_DP0 pid=368647) .b8 101
(EngineCore_DP0 pid=368647) .b8 110
(EngineCore_DP0 pid=368647) .b8 99
(EngineCore_DP0 pid=368647) .b8 104
(EngineCore_DP0 pid=368647) .b8 47
(EngineCore_DP0 pid=368647) .b8 115
(EngineCore_DP0 pid=368647) .b8 108
(EngineCore_DP0 pid=368647) .b8 105
(EngineCore_DP0 pid=368647) .b8 100
(EngineCore_DP0 pid=368647) .b8 101
(EngineCore_DP0 pid=368647) .b8 115
(EngineCore_DP0 pid=368647) .b8 112
(EngineCore_DP0 pid=368647) .b8 97
(EngineCore_DP0 pid=368647) .b8 114
(EngineCore_DP0 pid=368647) .b8 115
(EngineCore_DP0 pid=368647) .b8 101
(EngineCore_DP0 pid=368647) .b8 47
(EngineCore_DP0 pid=368647) .b8 99
(EngineCore_DP0 pid=368647) .b8 115
(EngineCore_DP0 pid=368647) .b8 114
(EngineCore_DP0 pid=368647) .b8 99
(EngineCore_DP0 pid=368647) .b8 47
(EngineCore_DP0 pid=368647) .b8 102
(EngineCore_DP0 pid=368647) .b8 117
(EngineCore_DP0 pid=368647) .b8 115
(EngineCore_DP0 pid=368647) .b8 101
(EngineCore_DP0 pid=368647) .b8 100
(EngineCore_DP0 pid=368647) .b8 95
(EngineCore_DP0 pid=368647) .b8 113
(EngineCore_DP0 pid=368647) .b8 117
(EngineCore_DP0 pid=368647) .b8 97
(EngineCore_DP0 pid=368647) .b8 110
(EngineCore_DP0 pid=368647) .b8 116
(EngineCore_DP0 pid=368647) .b8 95
(EngineCore_DP0 pid=368647) .b8 115
(EngineCore_DP0 pid=368647) .b8 108
(EngineCore_DP0 pid=368647) .b8 105
(EngineCore_DP0 pid=368647) .b8 100
(EngineCore_DP0 pid=368647) .b8 101
(EngineCore_DP0 pid=368647) .b8 95
(EngineCore_DP0 pid=368647) .b8 116
(EngineCore_DP0 pid=368647) .b8 114
(EngineCore_DP0 pid=368647) .b8 105
(EngineCore_DP0 pid=368647) .b8 116
(EngineCore_DP0 pid=368647) .b8 111
(EngineCore_DP0 pid=368647) .b8 110
(EngineCore_DP0 pid=368647) .b8 47
(EngineCore_DP0 pid=368647) .b8 98
(EngineCore_DP0 pid=368647) .b8 117
(EngineCore_DP0 pid=368647) .b8 105
(EngineCore_DP0 pid=368647) .b8 108
(EngineCore_DP0 pid=368647) .b8 100
(EngineCore_DP0 pid=368647) .b8 47
(EngineCore_DP0 pid=368647) .b8 71
(EngineCore_DP0 pid=368647) .b8 66
(EngineCore_DP0 pid=368647) .b8 49
(EngineCore_DP0 pid=368647) .b8 48
(EngineCore_DP0 pid=368647) .b8 95
(EngineCore_DP0 pid=368647) .b8 99
(EngineCore_DP0 pid=368647) .b8 99
(EngineCore_DP0 pid=368647) .b8 49
(EngineCore_DP0 pid=368647) .b8 50
(EngineCore_DP0 pid=368647) .b8 49
(EngineCore_DP0 pid=368647) .b8 95
(EngineCore_DP0 pid=368647) .b8 112
(EngineCore_DP0 pid=368647) .b8 121
(EngineCore_DP0 pid=368647) .b8 51
(EngineCore_DP0 pid=368647) .b8 49
(EngineCore_DP0 pid=368647) .b8 50
(EngineCore_DP0 pid=368647) .b8 95
(EngineCore_DP0 pid=368647) .b8 99
(EngineCore_DP0 pid=368647) .b8 117
(EngineCore_DP0 pid=368647) .b8 49
(EngineCore_DP0 pid=368647) .b8 50
(EngineCore_DP0 pid=368647) .b8 57
(EngineCore_DP0 pid=368647) .b8 95
(EngineCore_DP0 pid=368647) .b8 97
(EngineCore_DP0 pid=368647) .b8 97
(EngineCore_DP0 pid=368647) .b8 114
(EngineCore_DP0 pid=368647) .b8 99
(EngineCore_DP0 pid=368647) .b8 104
(EngineCore_DP0 pid=368647) .b8 54
(EngineCore_DP0 pid=368647) .b8 52
(EngineCore_DP0 pid=368647) .b8 0
(EngineCore_DP0 pid=368647) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=368647) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=368647) .b8 113
(EngineCore_DP0 pid=368647) .b8 117
(EngineCore_DP0 pid=368647) .b8 97
(EngineCore_DP0 pid=368647) .b8 110
(EngineCore_DP0 pid=368647) .b8 116
(EngineCore_DP0 pid=368647) .b8 95
(EngineCore_DP0 pid=368647) .b8 115
(EngineCore_DP0 pid=368647) .b8 108
(EngineCore_DP0 pid=368647) .b8 105
(EngineCore_DP0 pid=368647) .b8 100
(EngineCore_DP0 pid=368647) .b8 101
(EngineCore_DP0 pid=368647) .b8 95
(EngineCore_DP0 pid=368647) .b8 105
(EngineCore_DP0 pid=368647) .b8 110
(EngineCore_DP0 pid=368647) .b8 116
(EngineCore_DP0 pid=368647) .b8 56
(EngineCore_DP0 pid=368647) .b8 95
(EngineCore_DP0 pid=368647) .b8 107
(EngineCore_DP0 pid=368647) .b8 101
(EngineCore_DP0 pid=368647) .b8 114
(EngineCore_DP0 pid=368647) .b8 110
(EngineCore_DP0 pid=368647) .b8 101
(EngineCore_DP0 pid=368647) .b8 108
(EngineCore_DP0 pid=368647) .b8 0
(EngineCore_DP0 pid=368647) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=368647) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=368647) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=368647) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=368647) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=368647) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=368647) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=368647) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=368647) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=368647) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=368647) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=368647) .b8 1
(EngineCore_DP0 pid=368647) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=368647) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=368647) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=368647) 	}
(EngineCore_DP0 pid=368647) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=368647) 
(EngineCore_DP0 pid=368647) ================================================================
(EngineCore_DP0 pid=368647) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=368647) 
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpaboonsog.ptx', '-o', '/tmp/tmpaboonsog.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866] 
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866] 
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866] 
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpaboonsog.ptx -o /tmp/tmpaboonsog.ptx.o
(EngineCore_DP0 pid=368647) ERROR 01-25 19:43:42 [core.py:866] 

STDERR:
[2026-01-25 19:43:07] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:43:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:43:07] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:43:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:43:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:43:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:43:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:43:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:43:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:43:11] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:43:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:43:11] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:43:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:43:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:43:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:43:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:43:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:43:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=368647) [2026-01-25 19:43:12] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=368647) [2026-01-25 19:43:12] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=368647) [2026-01-25 19:43:12] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=368647) [2026-01-25 19:43:12] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=368647) [2026-01-25 19:43:12] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=368647) [2026-01-25 19:43:12] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=368647) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=368647) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:28<00:00, 28.11s/it]
(EngineCore_DP0 pid=368647) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:28<00:00, 28.11s/it]
(EngineCore_DP0 pid=368647) 
(EngineCore_DP0 pid=368647) [2026-01-25 19:43:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=368647) [2026-01-25 19:43:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=368647) [2026-01-25 19:43:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=368647) [2026-01-25 19:43:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10616832 bytes
(EngineCore_DP0 pid=368647) [2026-01-25 19:43:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=368647) [2026-01-25 19:43:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56623104 bytes
(EngineCore_DP0 pid=368647) [2026-01-25 19:43:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=368647) [2026-01-25 19:43:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28311552 bytes
(EngineCore_DP0 pid=368647) Process EngineCore_DP0:
(EngineCore_DP0 pid=368647) Traceback (most recent call last):
(EngineCore_DP0 pid=368647)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=368647)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=368647)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=368647)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=368647) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpaboonsog.ptx', '-o', '/tmp/tmpaboonsog.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=368647) 
(EngineCore_DP0 pid=368647) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=368647) 
(EngineCore_DP0 pid=368647) Traceback (most recent call last):
(EngineCore_DP0 pid=368647)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=368647)     self.run()
(EngineCore_DP0 pid=368647)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=368647)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=368647)     raise e
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=368647)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=368647)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=368647)     super().__init__(
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=368647)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=368647)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=368647)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=368647)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=368647)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=368647)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=368647)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=368647)     return func(*args, **kwargs)
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=368647)     return func(*args, **kwargs)
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=368647)     self.model_runner.profile_run()
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=368647)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=368647)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=368647)     return func(*args, **kwargs)
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=368647)     outputs = self.model(
(EngineCore_DP0 pid=368647)               ^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=368647)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=368647)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=368647)     model_output = self.model(
(EngineCore_DP0 pid=368647)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=368647)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=368647)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=368647)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=368647)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=368647)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=368647)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=368647)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=368647)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=368647)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=368647)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=368647)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=368647)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=368647)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=368647)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=368647)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=368647)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=368647)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=368647)     return self._linear_fn(
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=368647)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=368647)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=368647)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=368647)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=368647)     return fn(input, L)
(EngineCore_DP0 pid=368647)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=368647)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=368647)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=368647)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=368647)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=368647)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=368647)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=368647)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=368647)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=368647)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=368647)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=368647)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=368647)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=368647)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=368647)     raise PTXASError(error)
(EngineCore_DP0 pid=368647) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=368647) `ptxas` stderr:
(EngineCore_DP0 pid=368647) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=368647) 
(EngineCore_DP0 pid=368647) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpaboonsog.ptx -o /tmp/tmpaboonsog.ptx.o
(EngineCore_DP0 pid=368647) 
[rank0]:[W125 19:43:43.337861844 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 19:43:44
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:43:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:43:48 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=369397) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=369397) 
(EngineCore_DP0 pid=369397) 
(EngineCore_DP0 pid=369397) ================================================================
(EngineCore_DP0 pid=369397) Internal Triton PTX codegen error
(EngineCore_DP0 pid=369397) `ptxas` stderr:
(EngineCore_DP0 pid=369397) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=369397) 
(EngineCore_DP0 pid=369397) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp2pijy2m5.ptx -o /tmp/tmp2pijy2m5.ptx.o
(EngineCore_DP0 pid=369397) 
(EngineCore_DP0 pid=369397) 
(EngineCore_DP0 pid=369397) //
(EngineCore_DP0 pid=369397) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=369397) //
(EngineCore_DP0 pid=369397) 
(EngineCore_DP0 pid=369397) .version 8.7
(EngineCore_DP0 pid=369397) .target sm_121a
(EngineCore_DP0 pid=369397) .address_size 64
(EngineCore_DP0 pid=369397) 
(EngineCore_DP0 pid=369397) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=369397) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=369397)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=369397) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=369397) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=369397) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=369397) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=369397) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=369397) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=369397) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=369397) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=369397) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=369397) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=369397) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=369397) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=369397) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=369397) )
(EngineCore_DP0 pid=369397) .reqntid 512
(EngineCore_DP0 pid=369397) {
(EngineCore_DP0 pid=369397) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=369397) 	.reg .b16 	%rs<32>;
(EngineCore_DP0 pid=369397) 	.reg .b32 	%r<123>;
(EngineCore_DP0 pid=369397) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=369397) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=369397) $L__func_begin0:
(EngineCore_DP0 pid=369397) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=369397) 
(EngineCore_DP0 pid=369397) // %bb.0:
(EngineCore_DP0 pid=369397) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=369397) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=369397) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=369397) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=369397) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=369397) $L__tmp0:
(EngineCore_DP0 pid=369397) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=369397) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=369397) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=369397) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=369397) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=369397) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=369397) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=369397) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=369397) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=369397) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=369397) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=369397) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=369397) 	mov.b32 	%r121, 0f2B8CBCCC;
(EngineCore_DP0 pid=369397) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=369397) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=369397) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=369397) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=369397) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=369397) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=369397) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=369397) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=369397) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=369397) 	add.s32 	%r44, %r34, %r33;
(EngineCore_DP0 pid=369397) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=369397) 	add.s32 	%r47, %r34, %r35;
(EngineCore_DP0 pid=369397) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=369397) 	mov.b32 	%r119, 0f00000000;
(EngineCore_DP0 pid=369397) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=369397) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=369397) 	mov.b32 	%r120, %r40;
(EngineCore_DP0 pid=369397) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=369397) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=369397) 	add.s32 	%r50, %r4, %r120;
(EngineCore_DP0 pid=369397) 	setp.lt.s32 	%p2, %r50, %r18;
(EngineCore_DP0 pid=369397) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=369397) 	mad.wide.s32 	%rd6, %r50, 2, %rd1;
(EngineCore_DP0 pid=369397) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=369397) 	// begin inline asm
(EngineCore_DP0 pid=369397) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=369397) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=369397) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=369397) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=369397) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=369397) 	// end inline asm
(EngineCore_DP0 pid=369397) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=369397) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=369397) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=369397) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=369397) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=369397) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=369397) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=369397) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=369397) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=369397) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=369397) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=369397) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=369397) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=369397) $L__tmp1:
(EngineCore_DP0 pid=369397) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	bar.sync 	0;
(EngineCore_DP0 pid=369397) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=369397) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=369397) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=369397) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=369397) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=369397) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=369397) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=369397) 	cvt.f32.bf16 	%r51, %rs23;
(EngineCore_DP0 pid=369397) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	shfl.sync.bfly.b32 	%r52, %r51, 16, 31, -1;
(EngineCore_DP0 pid=369397) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=369397) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	shfl.sync.bfly.b32 	%r54, %r53, 8, 31, -1;
(EngineCore_DP0 pid=369397) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=369397) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	shfl.sync.bfly.b32 	%r56, %r55, 4, 31, -1;
(EngineCore_DP0 pid=369397) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=369397) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	shfl.sync.bfly.b32 	%r58, %r57, 2, 31, -1;
(EngineCore_DP0 pid=369397) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=369397) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	shfl.sync.bfly.b32 	%r60, %r59, 1, 31, -1;
(EngineCore_DP0 pid=369397) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	max.f32 	%r45, %r59, %r60;
(EngineCore_DP0 pid=369397) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	// begin inline asm
(EngineCore_DP0 pid=369397) 	@%p3 st.shared.b32 [ %r44 + 0 ], %r45;
(EngineCore_DP0 pid=369397) 	// end inline asm
(EngineCore_DP0 pid=369397) 	bar.sync 	0;
(EngineCore_DP0 pid=369397) 	// begin inline asm
(EngineCore_DP0 pid=369397) 	@%p4 ld.shared.b32 %r46, [ %r47 + 0 ];
(EngineCore_DP0 pid=369397) 	// end inline asm
(EngineCore_DP0 pid=369397) 	shfl.sync.bfly.b32 	%r61, %r46, 8, 31, -1;
(EngineCore_DP0 pid=369397) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	max.f32 	%r62, %r46, %r61;
(EngineCore_DP0 pid=369397) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	shfl.sync.bfly.b32 	%r63, %r62, 4, 31, -1;
(EngineCore_DP0 pid=369397) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=369397) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	shfl.sync.bfly.b32 	%r65, %r64, 2, 31, -1;
(EngineCore_DP0 pid=369397) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=369397) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	shfl.sync.bfly.b32 	%r67, %r66, 1, 31, -1;
(EngineCore_DP0 pid=369397) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	max.f32 	%r49, %r66, %r67;
(EngineCore_DP0 pid=369397) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=369397) 	// begin inline asm
(EngineCore_DP0 pid=369397) 	@%p19 st.shared.b32 [ %r47 + 0 ], %r49;
(EngineCore_DP0 pid=369397) 	// end inline asm
(EngineCore_DP0 pid=369397) 	bar.sync 	0;
(EngineCore_DP0 pid=369397) 	ld.shared.b32 	%r68, [global_smem];
(EngineCore_DP0 pid=369397) $L__tmp2:
(EngineCore_DP0 pid=369397) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=369397) 	max.f32 	%r119, %r119, %r68;
(EngineCore_DP0 pid=369397) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=369397) 	add.s32 	%r120, %r120, 4096;
(EngineCore_DP0 pid=369397) 	setp.lt.s32 	%p6, %r120, %r19;
(EngineCore_DP0 pid=369397) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=369397) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=369397) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=369397) 	max.f32 	%r121, %r119, 0f2B8CBCCC;
(EngineCore_DP0 pid=369397) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=369397) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=369397) 	mov.b32 	%r70, 0f42FE0000;
(EngineCore_DP0 pid=369397) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=369397) 	div.full.f32 	%r71, %r121, %r70;
(EngineCore_DP0 pid=369397) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=369397) 	max.f32 	%r69, %r71, 0f37810204;
(EngineCore_DP0 pid=369397) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=369397) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=369397) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=369397) 	// begin inline asm
(EngineCore_DP0 pid=369397) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r69 };
(EngineCore_DP0 pid=369397) 	// end inline asm
(EngineCore_DP0 pid=369397) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=369397) 	mul.lo.s32 	%r15, %r20, 3;
(EngineCore_DP0 pid=369397) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=369397) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=369397) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=369397) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=369397) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=369397) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=369397) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=369397) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=369397) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=369397) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=369397) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=369397) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=369397) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=369397) 	div.full.f32 	%r14, %r70, %r121;
(EngineCore_DP0 pid=369397) 	mov.b32 	%r122, 0;
(EngineCore_DP0 pid=369397) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=369397)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=369397) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=369397) 	add.s32 	%r75, %r3, %r122;
(EngineCore_DP0 pid=369397) 	setp.lt.s32 	%p13, %r75, %r15;
(EngineCore_DP0 pid=369397) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=369397) 	mul.hi.s32 	%r76, %r75, 1431655766;
(EngineCore_DP0 pid=369397) 	shr.u32 	%r77, %r76, 31;
(EngineCore_DP0 pid=369397) 	add.s32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=369397) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=369397) 	mul.lo.s32 	%r79, %r78, 3;
(EngineCore_DP0 pid=369397) 	sub.s32 	%r80, %r75, %r79;
(EngineCore_DP0 pid=369397) 	.loc	1 333 22                        // quant_slide_tuned_Llama3.2-3B.py:333:22
(EngineCore_DP0 pid=369397) 	shl.b32 	%r81, %r78, 3;
(EngineCore_DP0 pid=369397) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=369397) 	shl.b32 	%r82, %r80, 1;
(EngineCore_DP0 pid=369397) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=369397) 	add.s32 	%r83, %r81, %r82;
(EngineCore_DP0 pid=369397) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=369397) 	setp.lt.s32 	%p14, %r83, %r18;
(EngineCore_DP0 pid=369397) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=369397) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=369397) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=369397) 	mad.wide.s32 	%rd8, %r83, 2, %rd1;
(EngineCore_DP0 pid=369397) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=369397) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=369397) 	// begin inline asm
(EngineCore_DP0 pid=369397) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=369397) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=369397) 	// end inline asm
(EngineCore_DP0 pid=369397) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=369397) 	cvt.f32.bf16 	%r84, %rs24;
(EngineCore_DP0 pid=369397) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=369397) 	or.b32 	%r85, %r83, 1;
(EngineCore_DP0 pid=369397) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=369397) 	setp.lt.s32 	%p15, %r85, %r18;
(EngineCore_DP0 pid=369397) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=369397) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=369397) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=369397) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=369397) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=369397) 	// begin inline asm
(EngineCore_DP0 pid=369397) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=369397) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=369397) 	// end inline asm
(EngineCore_DP0 pid=369397) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=369397) 	cvt.f32.bf16 	%r86, %rs26;
(EngineCore_DP0 pid=369397) 	.loc	1 340 48                        // quant_slide_tuned_Llama3.2-3B.py:340:48
(EngineCore_DP0 pid=369397) 	add.s32 	%r87, %r83, 2;
(EngineCore_DP0 pid=369397) 	.loc	1 340 53                        // quant_slide_tuned_Llama3.2-3B.py:340:53
(EngineCore_DP0 pid=369397) 	setp.lt.s32 	%p16, %r87, %r18;
(EngineCore_DP0 pid=369397) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=369397) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=369397) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=369397) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=369397) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=369397) 	// begin inline asm
(EngineCore_DP0 pid=369397) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=369397) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=369397) 	// end inline asm
(EngineCore_DP0 pid=369397) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=369397) 	cvt.f32.bf16 	%r88, %rs28;
(EngineCore_DP0 pid=369397) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=369397) 	add.s32 	%r89, %r83, 3;
(EngineCore_DP0 pid=369397) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=369397) 	setp.lt.s32 	%p17, %r89, %r18;
(EngineCore_DP0 pid=369397) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=369397) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=369397) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=369397) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=369397) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=369397) 	// begin inline asm
(EngineCore_DP0 pid=369397) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=369397) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=369397) 	// end inline asm
(EngineCore_DP0 pid=369397) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=369397) 	cvt.f32.bf16 	%r90, %rs30;
(EngineCore_DP0 pid=369397) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=369397) 	mul.f32 	%r91, %r14, %r84;
(EngineCore_DP0 pid=369397) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=369397) 	cvt.rni.f32.f32 	%r92, %r91;
(EngineCore_DP0 pid=369397) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=369397) 	max.f32 	%r93, %r92, 0fC3000000;
(EngineCore_DP0 pid=369397) 	min.f32 	%r94, %r93, 0f42FE0000;
(EngineCore_DP0 pid=369397) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=369397) 	cvt.rzi.s32.f32 	%r95, %r94;
(EngineCore_DP0 pid=369397) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=369397) 	and.b32 	%r96, %r95, 255;
(EngineCore_DP0 pid=369397) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=369397) 	mul.f32 	%r97, %r14, %r86;
(EngineCore_DP0 pid=369397) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=369397) 	cvt.rni.f32.f32 	%r98, %r97;
(EngineCore_DP0 pid=369397) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=369397) 	mul.f32 	%r99, %r14, %r88;
(EngineCore_DP0 pid=369397) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=369397) 	cvt.rni.f32.f32 	%r100, %r99;
(EngineCore_DP0 pid=369397) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=369397) 	mul.f32 	%r101, %r14, %r90;
(EngineCore_DP0 pid=369397) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=369397) 	cvt.rni.f32.f32 	%r102, %r101;
(EngineCore_DP0 pid=369397) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=369397) 	max.f32 	%r103, %r102, 0fC3000000;
(EngineCore_DP0 pid=369397) 	min.f32 	%r104, %r103, 0f42FE0000;
(EngineCore_DP0 pid=369397) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=369397) 	cvt.rzi.s32.f32 	%r105, %r104;
(EngineCore_DP0 pid=369397) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=369397) 	max.f32 	%r106, %r100, 0fC3000000;
(EngineCore_DP0 pid=369397) 	max.f32 	%r107, %r98, 0fC3000000;
(EngineCore_DP0 pid=369397) 	min.f32 	%r108, %r107, 0f42FE0000;
(EngineCore_DP0 pid=369397) 	min.f32 	%r109, %r106, 0f42FE0000;
(EngineCore_DP0 pid=369397) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=369397) 	cvt.rzi.s32.f32 	%r110, %r109;
(EngineCore_DP0 pid=369397) 	cvt.rzi.s32.f32 	%r111, %r108;
(EngineCore_DP0 pid=369397) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=369397) 	shl.b32 	%r112, %r111, 8;
(EngineCore_DP0 pid=369397) 	shl.b32 	%r113, %r110, 16;
(EngineCore_DP0 pid=369397) 	and.b32 	%r114, %r113, 16711680;
(EngineCore_DP0 pid=369397) 	and.b32 	%r115, %r112, 65280;
(EngineCore_DP0 pid=369397) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=369397) 	or.b32 	%r116, %r115, %r96;
(EngineCore_DP0 pid=369397) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=369397) 	or.b32 	%r117, %r116, %r114;
(EngineCore_DP0 pid=369397) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=369397) 	shl.b32 	%r118, %r105, 24;
(EngineCore_DP0 pid=369397) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=369397) 	or.b32 	%r73, %r117, %r118;
(EngineCore_DP0 pid=369397) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=369397) 	mad.wide.s32 	%rd12, %r75, 4, %rd2;
(EngineCore_DP0 pid=369397) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=369397) 	// begin inline asm
(EngineCore_DP0 pid=369397) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r73 };
(EngineCore_DP0 pid=369397) 	// end inline asm
(EngineCore_DP0 pid=369397) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=369397) 	add.s32 	%r122, %r122, 512;
(EngineCore_DP0 pid=369397) 	setp.lt.s32 	%p18, %r122, %r15;
(EngineCore_DP0 pid=369397) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=369397) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=369397) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=369397) 	ret;
(EngineCore_DP0 pid=369397) $L__tmp3:
(EngineCore_DP0 pid=369397) $L__func_end0:
(EngineCore_DP0 pid=369397)                                         // -- End function
(EngineCore_DP0 pid=369397) }
(EngineCore_DP0 pid=369397) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=369397) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=369397) 	.section	.debug_abbrev
(EngineCore_DP0 pid=369397) 	{
(EngineCore_DP0 pid=369397) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=369397) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=369397) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=369397) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=369397) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=369397) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=369397) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=369397) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=369397) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=369397) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=369397) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=369397) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=369397) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=369397) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=369397) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=369397) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=369397) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=369397) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=369397) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=369397) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=369397) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=369397) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=369397) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=369397) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=369397) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=369397) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=369397) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=369397) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=369397) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=369397) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=369397) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=369397) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=369397) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=369397) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=369397) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=369397) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=369397) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=369397) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=369397) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=369397) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=369397) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=369397) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=369397) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=369397) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=369397) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=369397) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=369397) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=369397) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=369397) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=369397) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=369397) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=369397) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=369397) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=369397) 	}
(EngineCore_DP0 pid=369397) 	.section	.debug_info
(EngineCore_DP0 pid=369397) 	{
(EngineCore_DP0 pid=369397) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=369397) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=369397) .b8 0
(EngineCore_DP0 pid=369397) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=369397) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=369397) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=369397) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=369397) .b8 114
(EngineCore_DP0 pid=369397) .b8 105
(EngineCore_DP0 pid=369397) .b8 116
(EngineCore_DP0 pid=369397) .b8 111
(EngineCore_DP0 pid=369397) .b8 110
(EngineCore_DP0 pid=369397) .b8 0
(EngineCore_DP0 pid=369397) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=369397) .b8 0
(EngineCore_DP0 pid=369397) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=369397) .b8 117
(EngineCore_DP0 pid=369397) .b8 97
(EngineCore_DP0 pid=369397) .b8 110
(EngineCore_DP0 pid=369397) .b8 116
(EngineCore_DP0 pid=369397) .b8 95
(EngineCore_DP0 pid=369397) .b8 115
(EngineCore_DP0 pid=369397) .b8 108
(EngineCore_DP0 pid=369397) .b8 105
(EngineCore_DP0 pid=369397) .b8 100
(EngineCore_DP0 pid=369397) .b8 101
(EngineCore_DP0 pid=369397) .b8 95
(EngineCore_DP0 pid=369397) .b8 116
(EngineCore_DP0 pid=369397) .b8 117
(EngineCore_DP0 pid=369397) .b8 110
(EngineCore_DP0 pid=369397) .b8 101
(EngineCore_DP0 pid=369397) .b8 100
(EngineCore_DP0 pid=369397) .b8 95
(EngineCore_DP0 pid=369397) .b8 76
(EngineCore_DP0 pid=369397) .b8 108
(EngineCore_DP0 pid=369397) .b8 97
(EngineCore_DP0 pid=369397) .b8 109
(EngineCore_DP0 pid=369397) .b8 97
(EngineCore_DP0 pid=369397) .b8 51
(EngineCore_DP0 pid=369397) .b8 46
(EngineCore_DP0 pid=369397) .b8 50
(EngineCore_DP0 pid=369397) .b8 45
(EngineCore_DP0 pid=369397) .b8 51
(EngineCore_DP0 pid=369397) .b8 66
(EngineCore_DP0 pid=369397) .b8 46
(EngineCore_DP0 pid=369397) .b8 112
(EngineCore_DP0 pid=369397) .b8 121
(EngineCore_DP0 pid=369397) .b8 0
(EngineCore_DP0 pid=369397) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=369397) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=369397) .b8 114
(EngineCore_DP0 pid=369397) .b8 111
(EngineCore_DP0 pid=369397) .b8 111
(EngineCore_DP0 pid=369397) .b8 116
(EngineCore_DP0 pid=369397) .b8 47
(EngineCore_DP0 pid=369397) .b8 118
(EngineCore_DP0 pid=369397) .b8 108
(EngineCore_DP0 pid=369397) .b8 108
(EngineCore_DP0 pid=369397) .b8 109
(EngineCore_DP0 pid=369397) .b8 98
(EngineCore_DP0 pid=369397) .b8 101
(EngineCore_DP0 pid=369397) .b8 110
(EngineCore_DP0 pid=369397) .b8 99
(EngineCore_DP0 pid=369397) .b8 104
(EngineCore_DP0 pid=369397) .b8 47
(EngineCore_DP0 pid=369397) .b8 115
(EngineCore_DP0 pid=369397) .b8 108
(EngineCore_DP0 pid=369397) .b8 105
(EngineCore_DP0 pid=369397) .b8 100
(EngineCore_DP0 pid=369397) .b8 101
(EngineCore_DP0 pid=369397) .b8 115
(EngineCore_DP0 pid=369397) .b8 112
(EngineCore_DP0 pid=369397) .b8 97
(EngineCore_DP0 pid=369397) .b8 114
(EngineCore_DP0 pid=369397) .b8 115
(EngineCore_DP0 pid=369397) .b8 101
(EngineCore_DP0 pid=369397) .b8 47
(EngineCore_DP0 pid=369397) .b8 99
(EngineCore_DP0 pid=369397) .b8 115
(EngineCore_DP0 pid=369397) .b8 114
(EngineCore_DP0 pid=369397) .b8 99
(EngineCore_DP0 pid=369397) .b8 47
(EngineCore_DP0 pid=369397) .b8 102
(EngineCore_DP0 pid=369397) .b8 117
(EngineCore_DP0 pid=369397) .b8 115
(EngineCore_DP0 pid=369397) .b8 101
(EngineCore_DP0 pid=369397) .b8 100
(EngineCore_DP0 pid=369397) .b8 95
(EngineCore_DP0 pid=369397) .b8 113
(EngineCore_DP0 pid=369397) .b8 117
(EngineCore_DP0 pid=369397) .b8 97
(EngineCore_DP0 pid=369397) .b8 110
(EngineCore_DP0 pid=369397) .b8 116
(EngineCore_DP0 pid=369397) .b8 95
(EngineCore_DP0 pid=369397) .b8 115
(EngineCore_DP0 pid=369397) .b8 108
(EngineCore_DP0 pid=369397) .b8 105
(EngineCore_DP0 pid=369397) .b8 100
(EngineCore_DP0 pid=369397) .b8 101
(EngineCore_DP0 pid=369397) .b8 95
(EngineCore_DP0 pid=369397) .b8 116
(EngineCore_DP0 pid=369397) .b8 114
(EngineCore_DP0 pid=369397) .b8 105
(EngineCore_DP0 pid=369397) .b8 116
(EngineCore_DP0 pid=369397) .b8 111
(EngineCore_DP0 pid=369397) .b8 110
(EngineCore_DP0 pid=369397) .b8 47
(EngineCore_DP0 pid=369397) .b8 98
(EngineCore_DP0 pid=369397) .b8 117
(EngineCore_DP0 pid=369397) .b8 105
(EngineCore_DP0 pid=369397) .b8 108
(EngineCore_DP0 pid=369397) .b8 100
(EngineCore_DP0 pid=369397) .b8 47
(EngineCore_DP0 pid=369397) .b8 71
(EngineCore_DP0 pid=369397) .b8 66
(EngineCore_DP0 pid=369397) .b8 49
(EngineCore_DP0 pid=369397) .b8 48
(EngineCore_DP0 pid=369397) .b8 95
(EngineCore_DP0 pid=369397) .b8 99
(EngineCore_DP0 pid=369397) .b8 99
(EngineCore_DP0 pid=369397) .b8 49
(EngineCore_DP0 pid=369397) .b8 50
(EngineCore_DP0 pid=369397) .b8 49
(EngineCore_DP0 pid=369397) .b8 95
(EngineCore_DP0 pid=369397) .b8 112
(EngineCore_DP0 pid=369397) .b8 121
(EngineCore_DP0 pid=369397) .b8 51
(EngineCore_DP0 pid=369397) .b8 49
(EngineCore_DP0 pid=369397) .b8 50
(EngineCore_DP0 pid=369397) .b8 95
(EngineCore_DP0 pid=369397) .b8 99
(EngineCore_DP0 pid=369397) .b8 117
(EngineCore_DP0 pid=369397) .b8 49
(EngineCore_DP0 pid=369397) .b8 50
(EngineCore_DP0 pid=369397) .b8 57
(EngineCore_DP0 pid=369397) .b8 95
(EngineCore_DP0 pid=369397) .b8 97
(EngineCore_DP0 pid=369397) .b8 97
(EngineCore_DP0 pid=369397) .b8 114
(EngineCore_DP0 pid=369397) .b8 99
(EngineCore_DP0 pid=369397) .b8 104
(EngineCore_DP0 pid=369397) .b8 54
(EngineCore_DP0 pid=369397) .b8 52
(EngineCore_DP0 pid=369397) .b8 0
(EngineCore_DP0 pid=369397) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=369397) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=369397) .b8 113
(EngineCore_DP0 pid=369397) .b8 117
(EngineCore_DP0 pid=369397) .b8 97
(EngineCore_DP0 pid=369397) .b8 110
(EngineCore_DP0 pid=369397) .b8 116
(EngineCore_DP0 pid=369397) .b8 95
(EngineCore_DP0 pid=369397) .b8 115
(EngineCore_DP0 pid=369397) .b8 108
(EngineCore_DP0 pid=369397) .b8 105
(EngineCore_DP0 pid=369397) .b8 100
(EngineCore_DP0 pid=369397) .b8 101
(EngineCore_DP0 pid=369397) .b8 95
(EngineCore_DP0 pid=369397) .b8 105
(EngineCore_DP0 pid=369397) .b8 110
(EngineCore_DP0 pid=369397) .b8 116
(EngineCore_DP0 pid=369397) .b8 56
(EngineCore_DP0 pid=369397) .b8 95
(EngineCore_DP0 pid=369397) .b8 107
(EngineCore_DP0 pid=369397) .b8 101
(EngineCore_DP0 pid=369397) .b8 114
(EngineCore_DP0 pid=369397) .b8 110
(EngineCore_DP0 pid=369397) .b8 101
(EngineCore_DP0 pid=369397) .b8 108
(EngineCore_DP0 pid=369397) .b8 0
(EngineCore_DP0 pid=369397) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=369397) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=369397) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=369397) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=369397) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=369397) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=369397) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=369397) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=369397) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=369397) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=369397) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=369397) .b8 1
(EngineCore_DP0 pid=369397) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=369397) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=369397) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=369397) 	}
(EngineCore_DP0 pid=369397) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=369397) 
(EngineCore_DP0 pid=369397) ================================================================
(EngineCore_DP0 pid=369397) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=369397) 
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp2pijy2m5.ptx', '-o', '/tmp/tmp2pijy2m5.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866] 
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866] 
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866] 
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp2pijy2m5.ptx -o /tmp/tmp2pijy2m5.ptx.o
(EngineCore_DP0 pid=369397) ERROR 01-25 19:44:23 [core.py:866] 

STDERR:
[2026-01-25 19:43:48] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:43:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:43:48] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:43:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:43:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:43:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:43:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:43:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:43:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:43:51] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:43:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:43:52] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:43:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:43:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:43:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:43:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:43:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:43:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:43:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=369397) [2026-01-25 19:43:52] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=369397) [2026-01-25 19:43:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=369397) [2026-01-25 19:43:52] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=369397) [2026-01-25 19:43:52] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=369397) [2026-01-25 19:43:52] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=369397) [2026-01-25 19:43:52] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=369397) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=369397) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.73s/it]
(EngineCore_DP0 pid=369397) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.73s/it]
(EngineCore_DP0 pid=369397) 
(EngineCore_DP0 pid=369397) [2026-01-25 19:44:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=369397) [2026-01-25 19:44:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=369397) [2026-01-25 19:44:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=369397) [2026-01-25 19:44:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10616832 bytes
(EngineCore_DP0 pid=369397) [2026-01-25 19:44:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=369397) [2026-01-25 19:44:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56623104 bytes
(EngineCore_DP0 pid=369397) [2026-01-25 19:44:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=369397) [2026-01-25 19:44:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28311552 bytes
(EngineCore_DP0 pid=369397) Process EngineCore_DP0:
(EngineCore_DP0 pid=369397) Traceback (most recent call last):
(EngineCore_DP0 pid=369397)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=369397)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=369397)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=369397)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=369397) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp2pijy2m5.ptx', '-o', '/tmp/tmp2pijy2m5.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=369397) 
(EngineCore_DP0 pid=369397) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=369397) 
(EngineCore_DP0 pid=369397) Traceback (most recent call last):
(EngineCore_DP0 pid=369397)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=369397)     self.run()
(EngineCore_DP0 pid=369397)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=369397)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=369397)     raise e
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=369397)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=369397)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=369397)     super().__init__(
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=369397)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=369397)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=369397)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=369397)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=369397)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=369397)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=369397)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=369397)     return func(*args, **kwargs)
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=369397)     return func(*args, **kwargs)
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=369397)     self.model_runner.profile_run()
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=369397)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=369397)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=369397)     return func(*args, **kwargs)
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=369397)     outputs = self.model(
(EngineCore_DP0 pid=369397)               ^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=369397)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=369397)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=369397)     model_output = self.model(
(EngineCore_DP0 pid=369397)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=369397)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=369397)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=369397)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=369397)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=369397)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=369397)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=369397)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=369397)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=369397)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=369397)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=369397)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=369397)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=369397)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=369397)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=369397)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=369397)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=369397)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=369397)     return self._linear_fn(
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=369397)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=369397)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=369397)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=369397)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=369397)     return fn(input, L)
(EngineCore_DP0 pid=369397)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=369397)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=369397)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=369397)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=369397)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=369397)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=369397)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=369397)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=369397)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=369397)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=369397)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=369397)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=369397)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=369397)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=369397)     raise PTXASError(error)
(EngineCore_DP0 pid=369397) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=369397) `ptxas` stderr:
(EngineCore_DP0 pid=369397) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=369397) 
(EngineCore_DP0 pid=369397) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp2pijy2m5.ptx -o /tmp/tmp2pijy2m5.ptx.o
(EngineCore_DP0 pid=369397) 
[rank0]:[W125 19:44:23.562133897 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 19:44:24
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:44:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:44:29 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=370145) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=370145) 
(EngineCore_DP0 pid=370145) 
(EngineCore_DP0 pid=370145) ================================================================
(EngineCore_DP0 pid=370145) Internal Triton PTX codegen error
(EngineCore_DP0 pid=370145) `ptxas` stderr:
(EngineCore_DP0 pid=370145) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=370145) 
(EngineCore_DP0 pid=370145) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp_jbp099j.ptx -o /tmp/tmp_jbp099j.ptx.o
(EngineCore_DP0 pid=370145) 
(EngineCore_DP0 pid=370145) 
(EngineCore_DP0 pid=370145) //
(EngineCore_DP0 pid=370145) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=370145) //
(EngineCore_DP0 pid=370145) 
(EngineCore_DP0 pid=370145) .version 8.7
(EngineCore_DP0 pid=370145) .target sm_121a
(EngineCore_DP0 pid=370145) .address_size 64
(EngineCore_DP0 pid=370145) 
(EngineCore_DP0 pid=370145) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=370145) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=370145)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=370145) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=370145) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=370145) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=370145) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=370145) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=370145) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=370145) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=370145) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=370145) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=370145) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=370145) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=370145) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=370145) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=370145) )
(EngineCore_DP0 pid=370145) .reqntid 512
(EngineCore_DP0 pid=370145) {
(EngineCore_DP0 pid=370145) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=370145) 	.reg .b16 	%rs<32>;
(EngineCore_DP0 pid=370145) 	.reg .b32 	%r<123>;
(EngineCore_DP0 pid=370145) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=370145) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=370145) $L__func_begin0:
(EngineCore_DP0 pid=370145) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=370145) 
(EngineCore_DP0 pid=370145) // %bb.0:
(EngineCore_DP0 pid=370145) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=370145) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=370145) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=370145) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=370145) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=370145) $L__tmp0:
(EngineCore_DP0 pid=370145) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=370145) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=370145) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=370145) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=370145) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=370145) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=370145) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=370145) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=370145) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=370145) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=370145) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=370145) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=370145) 	mov.b32 	%r121, 0f2B8CBCCC;
(EngineCore_DP0 pid=370145) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=370145) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=370145) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=370145) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=370145) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=370145) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=370145) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=370145) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=370145) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=370145) 	add.s32 	%r44, %r34, %r33;
(EngineCore_DP0 pid=370145) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=370145) 	add.s32 	%r47, %r34, %r35;
(EngineCore_DP0 pid=370145) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=370145) 	mov.b32 	%r119, 0f00000000;
(EngineCore_DP0 pid=370145) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=370145) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=370145) 	mov.b32 	%r120, %r40;
(EngineCore_DP0 pid=370145) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=370145) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=370145) 	add.s32 	%r50, %r4, %r120;
(EngineCore_DP0 pid=370145) 	setp.lt.s32 	%p2, %r50, %r18;
(EngineCore_DP0 pid=370145) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=370145) 	mad.wide.s32 	%rd6, %r50, 2, %rd1;
(EngineCore_DP0 pid=370145) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=370145) 	// begin inline asm
(EngineCore_DP0 pid=370145) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=370145) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=370145) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=370145) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=370145) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=370145) 	// end inline asm
(EngineCore_DP0 pid=370145) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=370145) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=370145) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=370145) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=370145) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=370145) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=370145) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=370145) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=370145) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=370145) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=370145) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=370145) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=370145) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=370145) $L__tmp1:
(EngineCore_DP0 pid=370145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	bar.sync 	0;
(EngineCore_DP0 pid=370145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=370145) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=370145) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=370145) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=370145) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=370145) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=370145) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=370145) 	cvt.f32.bf16 	%r51, %rs23;
(EngineCore_DP0 pid=370145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	shfl.sync.bfly.b32 	%r52, %r51, 16, 31, -1;
(EngineCore_DP0 pid=370145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=370145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	shfl.sync.bfly.b32 	%r54, %r53, 8, 31, -1;
(EngineCore_DP0 pid=370145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=370145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	shfl.sync.bfly.b32 	%r56, %r55, 4, 31, -1;
(EngineCore_DP0 pid=370145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=370145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	shfl.sync.bfly.b32 	%r58, %r57, 2, 31, -1;
(EngineCore_DP0 pid=370145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=370145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	shfl.sync.bfly.b32 	%r60, %r59, 1, 31, -1;
(EngineCore_DP0 pid=370145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	max.f32 	%r45, %r59, %r60;
(EngineCore_DP0 pid=370145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	// begin inline asm
(EngineCore_DP0 pid=370145) 	@%p3 st.shared.b32 [ %r44 + 0 ], %r45;
(EngineCore_DP0 pid=370145) 	// end inline asm
(EngineCore_DP0 pid=370145) 	bar.sync 	0;
(EngineCore_DP0 pid=370145) 	// begin inline asm
(EngineCore_DP0 pid=370145) 	@%p4 ld.shared.b32 %r46, [ %r47 + 0 ];
(EngineCore_DP0 pid=370145) 	// end inline asm
(EngineCore_DP0 pid=370145) 	shfl.sync.bfly.b32 	%r61, %r46, 8, 31, -1;
(EngineCore_DP0 pid=370145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	max.f32 	%r62, %r46, %r61;
(EngineCore_DP0 pid=370145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	shfl.sync.bfly.b32 	%r63, %r62, 4, 31, -1;
(EngineCore_DP0 pid=370145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=370145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	shfl.sync.bfly.b32 	%r65, %r64, 2, 31, -1;
(EngineCore_DP0 pid=370145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=370145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	shfl.sync.bfly.b32 	%r67, %r66, 1, 31, -1;
(EngineCore_DP0 pid=370145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	max.f32 	%r49, %r66, %r67;
(EngineCore_DP0 pid=370145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370145) 	// begin inline asm
(EngineCore_DP0 pid=370145) 	@%p19 st.shared.b32 [ %r47 + 0 ], %r49;
(EngineCore_DP0 pid=370145) 	// end inline asm
(EngineCore_DP0 pid=370145) 	bar.sync 	0;
(EngineCore_DP0 pid=370145) 	ld.shared.b32 	%r68, [global_smem];
(EngineCore_DP0 pid=370145) $L__tmp2:
(EngineCore_DP0 pid=370145) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=370145) 	max.f32 	%r119, %r119, %r68;
(EngineCore_DP0 pid=370145) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=370145) 	add.s32 	%r120, %r120, 4096;
(EngineCore_DP0 pid=370145) 	setp.lt.s32 	%p6, %r120, %r19;
(EngineCore_DP0 pid=370145) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=370145) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=370145) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=370145) 	max.f32 	%r121, %r119, 0f2B8CBCCC;
(EngineCore_DP0 pid=370145) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=370145) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=370145) 	mov.b32 	%r70, 0f42FE0000;
(EngineCore_DP0 pid=370145) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=370145) 	div.full.f32 	%r71, %r121, %r70;
(EngineCore_DP0 pid=370145) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=370145) 	max.f32 	%r69, %r71, 0f37810204;
(EngineCore_DP0 pid=370145) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=370145) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=370145) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=370145) 	// begin inline asm
(EngineCore_DP0 pid=370145) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r69 };
(EngineCore_DP0 pid=370145) 	// end inline asm
(EngineCore_DP0 pid=370145) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=370145) 	mul.lo.s32 	%r15, %r20, 3;
(EngineCore_DP0 pid=370145) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=370145) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=370145) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=370145) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=370145) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=370145) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=370145) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=370145) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=370145) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=370145) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=370145) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=370145) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=370145) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=370145) 	div.full.f32 	%r14, %r70, %r121;
(EngineCore_DP0 pid=370145) 	mov.b32 	%r122, 0;
(EngineCore_DP0 pid=370145) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=370145)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=370145) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=370145) 	add.s32 	%r75, %r3, %r122;
(EngineCore_DP0 pid=370145) 	setp.lt.s32 	%p13, %r75, %r15;
(EngineCore_DP0 pid=370145) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=370145) 	mul.hi.s32 	%r76, %r75, 1431655766;
(EngineCore_DP0 pid=370145) 	shr.u32 	%r77, %r76, 31;
(EngineCore_DP0 pid=370145) 	add.s32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=370145) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=370145) 	mul.lo.s32 	%r79, %r78, 3;
(EngineCore_DP0 pid=370145) 	sub.s32 	%r80, %r75, %r79;
(EngineCore_DP0 pid=370145) 	.loc	1 333 22                        // quant_slide_tuned_Llama3.2-3B.py:333:22
(EngineCore_DP0 pid=370145) 	shl.b32 	%r81, %r78, 3;
(EngineCore_DP0 pid=370145) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=370145) 	shl.b32 	%r82, %r80, 1;
(EngineCore_DP0 pid=370145) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=370145) 	add.s32 	%r83, %r81, %r82;
(EngineCore_DP0 pid=370145) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=370145) 	setp.lt.s32 	%p14, %r83, %r18;
(EngineCore_DP0 pid=370145) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=370145) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=370145) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=370145) 	mad.wide.s32 	%rd8, %r83, 2, %rd1;
(EngineCore_DP0 pid=370145) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=370145) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=370145) 	// begin inline asm
(EngineCore_DP0 pid=370145) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=370145) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=370145) 	// end inline asm
(EngineCore_DP0 pid=370145) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=370145) 	cvt.f32.bf16 	%r84, %rs24;
(EngineCore_DP0 pid=370145) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=370145) 	or.b32 	%r85, %r83, 1;
(EngineCore_DP0 pid=370145) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=370145) 	setp.lt.s32 	%p15, %r85, %r18;
(EngineCore_DP0 pid=370145) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=370145) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=370145) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=370145) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=370145) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=370145) 	// begin inline asm
(EngineCore_DP0 pid=370145) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=370145) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=370145) 	// end inline asm
(EngineCore_DP0 pid=370145) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=370145) 	cvt.f32.bf16 	%r86, %rs26;
(EngineCore_DP0 pid=370145) 	.loc	1 340 48                        // quant_slide_tuned_Llama3.2-3B.py:340:48
(EngineCore_DP0 pid=370145) 	add.s32 	%r87, %r83, 2;
(EngineCore_DP0 pid=370145) 	.loc	1 340 53                        // quant_slide_tuned_Llama3.2-3B.py:340:53
(EngineCore_DP0 pid=370145) 	setp.lt.s32 	%p16, %r87, %r18;
(EngineCore_DP0 pid=370145) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=370145) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=370145) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=370145) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=370145) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=370145) 	// begin inline asm
(EngineCore_DP0 pid=370145) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=370145) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=370145) 	// end inline asm
(EngineCore_DP0 pid=370145) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=370145) 	cvt.f32.bf16 	%r88, %rs28;
(EngineCore_DP0 pid=370145) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=370145) 	add.s32 	%r89, %r83, 3;
(EngineCore_DP0 pid=370145) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=370145) 	setp.lt.s32 	%p17, %r89, %r18;
(EngineCore_DP0 pid=370145) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=370145) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=370145) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=370145) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=370145) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=370145) 	// begin inline asm
(EngineCore_DP0 pid=370145) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=370145) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=370145) 	// end inline asm
(EngineCore_DP0 pid=370145) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=370145) 	cvt.f32.bf16 	%r90, %rs30;
(EngineCore_DP0 pid=370145) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=370145) 	mul.f32 	%r91, %r14, %r84;
(EngineCore_DP0 pid=370145) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=370145) 	cvt.rni.f32.f32 	%r92, %r91;
(EngineCore_DP0 pid=370145) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=370145) 	max.f32 	%r93, %r92, 0fC3000000;
(EngineCore_DP0 pid=370145) 	min.f32 	%r94, %r93, 0f42FE0000;
(EngineCore_DP0 pid=370145) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=370145) 	cvt.rzi.s32.f32 	%r95, %r94;
(EngineCore_DP0 pid=370145) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=370145) 	and.b32 	%r96, %r95, 255;
(EngineCore_DP0 pid=370145) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=370145) 	mul.f32 	%r97, %r14, %r86;
(EngineCore_DP0 pid=370145) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=370145) 	cvt.rni.f32.f32 	%r98, %r97;
(EngineCore_DP0 pid=370145) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=370145) 	mul.f32 	%r99, %r14, %r88;
(EngineCore_DP0 pid=370145) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=370145) 	cvt.rni.f32.f32 	%r100, %r99;
(EngineCore_DP0 pid=370145) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=370145) 	mul.f32 	%r101, %r14, %r90;
(EngineCore_DP0 pid=370145) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=370145) 	cvt.rni.f32.f32 	%r102, %r101;
(EngineCore_DP0 pid=370145) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=370145) 	max.f32 	%r103, %r102, 0fC3000000;
(EngineCore_DP0 pid=370145) 	min.f32 	%r104, %r103, 0f42FE0000;
(EngineCore_DP0 pid=370145) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=370145) 	cvt.rzi.s32.f32 	%r105, %r104;
(EngineCore_DP0 pid=370145) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=370145) 	max.f32 	%r106, %r100, 0fC3000000;
(EngineCore_DP0 pid=370145) 	max.f32 	%r107, %r98, 0fC3000000;
(EngineCore_DP0 pid=370145) 	min.f32 	%r108, %r107, 0f42FE0000;
(EngineCore_DP0 pid=370145) 	min.f32 	%r109, %r106, 0f42FE0000;
(EngineCore_DP0 pid=370145) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=370145) 	cvt.rzi.s32.f32 	%r110, %r109;
(EngineCore_DP0 pid=370145) 	cvt.rzi.s32.f32 	%r111, %r108;
(EngineCore_DP0 pid=370145) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=370145) 	shl.b32 	%r112, %r111, 8;
(EngineCore_DP0 pid=370145) 	shl.b32 	%r113, %r110, 16;
(EngineCore_DP0 pid=370145) 	and.b32 	%r114, %r113, 16711680;
(EngineCore_DP0 pid=370145) 	and.b32 	%r115, %r112, 65280;
(EngineCore_DP0 pid=370145) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=370145) 	or.b32 	%r116, %r115, %r96;
(EngineCore_DP0 pid=370145) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=370145) 	or.b32 	%r117, %r116, %r114;
(EngineCore_DP0 pid=370145) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=370145) 	shl.b32 	%r118, %r105, 24;
(EngineCore_DP0 pid=370145) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=370145) 	or.b32 	%r73, %r117, %r118;
(EngineCore_DP0 pid=370145) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=370145) 	mad.wide.s32 	%rd12, %r75, 4, %rd2;
(EngineCore_DP0 pid=370145) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=370145) 	// begin inline asm
(EngineCore_DP0 pid=370145) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r73 };
(EngineCore_DP0 pid=370145) 	// end inline asm
(EngineCore_DP0 pid=370145) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=370145) 	add.s32 	%r122, %r122, 512;
(EngineCore_DP0 pid=370145) 	setp.lt.s32 	%p18, %r122, %r15;
(EngineCore_DP0 pid=370145) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=370145) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=370145) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=370145) 	ret;
(EngineCore_DP0 pid=370145) $L__tmp3:
(EngineCore_DP0 pid=370145) $L__func_end0:
(EngineCore_DP0 pid=370145)                                         // -- End function
(EngineCore_DP0 pid=370145) }
(EngineCore_DP0 pid=370145) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=370145) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=370145) 	.section	.debug_abbrev
(EngineCore_DP0 pid=370145) 	{
(EngineCore_DP0 pid=370145) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=370145) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=370145) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=370145) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=370145) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=370145) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=370145) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=370145) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=370145) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=370145) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=370145) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=370145) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=370145) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=370145) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=370145) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=370145) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=370145) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=370145) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=370145) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=370145) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=370145) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=370145) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=370145) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=370145) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=370145) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=370145) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=370145) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=370145) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=370145) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=370145) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=370145) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=370145) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=370145) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=370145) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=370145) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=370145) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=370145) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=370145) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=370145) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=370145) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=370145) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=370145) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=370145) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=370145) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=370145) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=370145) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=370145) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=370145) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=370145) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=370145) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=370145) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=370145) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=370145) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=370145) 	}
(EngineCore_DP0 pid=370145) 	.section	.debug_info
(EngineCore_DP0 pid=370145) 	{
(EngineCore_DP0 pid=370145) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=370145) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=370145) .b8 0
(EngineCore_DP0 pid=370145) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=370145) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=370145) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=370145) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=370145) .b8 114
(EngineCore_DP0 pid=370145) .b8 105
(EngineCore_DP0 pid=370145) .b8 116
(EngineCore_DP0 pid=370145) .b8 111
(EngineCore_DP0 pid=370145) .b8 110
(EngineCore_DP0 pid=370145) .b8 0
(EngineCore_DP0 pid=370145) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=370145) .b8 0
(EngineCore_DP0 pid=370145) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=370145) .b8 117
(EngineCore_DP0 pid=370145) .b8 97
(EngineCore_DP0 pid=370145) .b8 110
(EngineCore_DP0 pid=370145) .b8 116
(EngineCore_DP0 pid=370145) .b8 95
(EngineCore_DP0 pid=370145) .b8 115
(EngineCore_DP0 pid=370145) .b8 108
(EngineCore_DP0 pid=370145) .b8 105
(EngineCore_DP0 pid=370145) .b8 100
(EngineCore_DP0 pid=370145) .b8 101
(EngineCore_DP0 pid=370145) .b8 95
(EngineCore_DP0 pid=370145) .b8 116
(EngineCore_DP0 pid=370145) .b8 117
(EngineCore_DP0 pid=370145) .b8 110
(EngineCore_DP0 pid=370145) .b8 101
(EngineCore_DP0 pid=370145) .b8 100
(EngineCore_DP0 pid=370145) .b8 95
(EngineCore_DP0 pid=370145) .b8 76
(EngineCore_DP0 pid=370145) .b8 108
(EngineCore_DP0 pid=370145) .b8 97
(EngineCore_DP0 pid=370145) .b8 109
(EngineCore_DP0 pid=370145) .b8 97
(EngineCore_DP0 pid=370145) .b8 51
(EngineCore_DP0 pid=370145) .b8 46
(EngineCore_DP0 pid=370145) .b8 50
(EngineCore_DP0 pid=370145) .b8 45
(EngineCore_DP0 pid=370145) .b8 51
(EngineCore_DP0 pid=370145) .b8 66
(EngineCore_DP0 pid=370145) .b8 46
(EngineCore_DP0 pid=370145) .b8 112
(EngineCore_DP0 pid=370145) .b8 121
(EngineCore_DP0 pid=370145) .b8 0
(EngineCore_DP0 pid=370145) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=370145) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=370145) .b8 114
(EngineCore_DP0 pid=370145) .b8 111
(EngineCore_DP0 pid=370145) .b8 111
(EngineCore_DP0 pid=370145) .b8 116
(EngineCore_DP0 pid=370145) .b8 47
(EngineCore_DP0 pid=370145) .b8 118
(EngineCore_DP0 pid=370145) .b8 108
(EngineCore_DP0 pid=370145) .b8 108
(EngineCore_DP0 pid=370145) .b8 109
(EngineCore_DP0 pid=370145) .b8 98
(EngineCore_DP0 pid=370145) .b8 101
(EngineCore_DP0 pid=370145) .b8 110
(EngineCore_DP0 pid=370145) .b8 99
(EngineCore_DP0 pid=370145) .b8 104
(EngineCore_DP0 pid=370145) .b8 47
(EngineCore_DP0 pid=370145) .b8 115
(EngineCore_DP0 pid=370145) .b8 108
(EngineCore_DP0 pid=370145) .b8 105
(EngineCore_DP0 pid=370145) .b8 100
(EngineCore_DP0 pid=370145) .b8 101
(EngineCore_DP0 pid=370145) .b8 115
(EngineCore_DP0 pid=370145) .b8 112
(EngineCore_DP0 pid=370145) .b8 97
(EngineCore_DP0 pid=370145) .b8 114
(EngineCore_DP0 pid=370145) .b8 115
(EngineCore_DP0 pid=370145) .b8 101
(EngineCore_DP0 pid=370145) .b8 47
(EngineCore_DP0 pid=370145) .b8 99
(EngineCore_DP0 pid=370145) .b8 115
(EngineCore_DP0 pid=370145) .b8 114
(EngineCore_DP0 pid=370145) .b8 99
(EngineCore_DP0 pid=370145) .b8 47
(EngineCore_DP0 pid=370145) .b8 102
(EngineCore_DP0 pid=370145) .b8 117
(EngineCore_DP0 pid=370145) .b8 115
(EngineCore_DP0 pid=370145) .b8 101
(EngineCore_DP0 pid=370145) .b8 100
(EngineCore_DP0 pid=370145) .b8 95
(EngineCore_DP0 pid=370145) .b8 113
(EngineCore_DP0 pid=370145) .b8 117
(EngineCore_DP0 pid=370145) .b8 97
(EngineCore_DP0 pid=370145) .b8 110
(EngineCore_DP0 pid=370145) .b8 116
(EngineCore_DP0 pid=370145) .b8 95
(EngineCore_DP0 pid=370145) .b8 115
(EngineCore_DP0 pid=370145) .b8 108
(EngineCore_DP0 pid=370145) .b8 105
(EngineCore_DP0 pid=370145) .b8 100
(EngineCore_DP0 pid=370145) .b8 101
(EngineCore_DP0 pid=370145) .b8 95
(EngineCore_DP0 pid=370145) .b8 116
(EngineCore_DP0 pid=370145) .b8 114
(EngineCore_DP0 pid=370145) .b8 105
(EngineCore_DP0 pid=370145) .b8 116
(EngineCore_DP0 pid=370145) .b8 111
(EngineCore_DP0 pid=370145) .b8 110
(EngineCore_DP0 pid=370145) .b8 47
(EngineCore_DP0 pid=370145) .b8 98
(EngineCore_DP0 pid=370145) .b8 117
(EngineCore_DP0 pid=370145) .b8 105
(EngineCore_DP0 pid=370145) .b8 108
(EngineCore_DP0 pid=370145) .b8 100
(EngineCore_DP0 pid=370145) .b8 47
(EngineCore_DP0 pid=370145) .b8 71
(EngineCore_DP0 pid=370145) .b8 66
(EngineCore_DP0 pid=370145) .b8 49
(EngineCore_DP0 pid=370145) .b8 48
(EngineCore_DP0 pid=370145) .b8 95
(EngineCore_DP0 pid=370145) .b8 99
(EngineCore_DP0 pid=370145) .b8 99
(EngineCore_DP0 pid=370145) .b8 49
(EngineCore_DP0 pid=370145) .b8 50
(EngineCore_DP0 pid=370145) .b8 49
(EngineCore_DP0 pid=370145) .b8 95
(EngineCore_DP0 pid=370145) .b8 112
(EngineCore_DP0 pid=370145) .b8 121
(EngineCore_DP0 pid=370145) .b8 51
(EngineCore_DP0 pid=370145) .b8 49
(EngineCore_DP0 pid=370145) .b8 50
(EngineCore_DP0 pid=370145) .b8 95
(EngineCore_DP0 pid=370145) .b8 99
(EngineCore_DP0 pid=370145) .b8 117
(EngineCore_DP0 pid=370145) .b8 49
(EngineCore_DP0 pid=370145) .b8 50
(EngineCore_DP0 pid=370145) .b8 57
(EngineCore_DP0 pid=370145) .b8 95
(EngineCore_DP0 pid=370145) .b8 97
(EngineCore_DP0 pid=370145) .b8 97
(EngineCore_DP0 pid=370145) .b8 114
(EngineCore_DP0 pid=370145) .b8 99
(EngineCore_DP0 pid=370145) .b8 104
(EngineCore_DP0 pid=370145) .b8 54
(EngineCore_DP0 pid=370145) .b8 52
(EngineCore_DP0 pid=370145) .b8 0
(EngineCore_DP0 pid=370145) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=370145) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=370145) .b8 113
(EngineCore_DP0 pid=370145) .b8 117
(EngineCore_DP0 pid=370145) .b8 97
(EngineCore_DP0 pid=370145) .b8 110
(EngineCore_DP0 pid=370145) .b8 116
(EngineCore_DP0 pid=370145) .b8 95
(EngineCore_DP0 pid=370145) .b8 115
(EngineCore_DP0 pid=370145) .b8 108
(EngineCore_DP0 pid=370145) .b8 105
(EngineCore_DP0 pid=370145) .b8 100
(EngineCore_DP0 pid=370145) .b8 101
(EngineCore_DP0 pid=370145) .b8 95
(EngineCore_DP0 pid=370145) .b8 105
(EngineCore_DP0 pid=370145) .b8 110
(EngineCore_DP0 pid=370145) .b8 116
(EngineCore_DP0 pid=370145) .b8 56
(EngineCore_DP0 pid=370145) .b8 95
(EngineCore_DP0 pid=370145) .b8 107
(EngineCore_DP0 pid=370145) .b8 101
(EngineCore_DP0 pid=370145) .b8 114
(EngineCore_DP0 pid=370145) .b8 110
(EngineCore_DP0 pid=370145) .b8 101
(EngineCore_DP0 pid=370145) .b8 108
(EngineCore_DP0 pid=370145) .b8 0
(EngineCore_DP0 pid=370145) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=370145) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=370145) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=370145) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=370145) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=370145) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=370145) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=370145) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=370145) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=370145) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=370145) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=370145) .b8 1
(EngineCore_DP0 pid=370145) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=370145) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=370145) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=370145) 	}
(EngineCore_DP0 pid=370145) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=370145) 
(EngineCore_DP0 pid=370145) ================================================================
(EngineCore_DP0 pid=370145) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=370145) 
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp_jbp099j.ptx', '-o', '/tmp/tmp_jbp099j.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866] 
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866] 
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866] 
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp_jbp099j.ptx -o /tmp/tmp_jbp099j.ptx.o
(EngineCore_DP0 pid=370145) ERROR 01-25 19:45:03 [core.py:866] 

STDERR:
[2026-01-25 19:44:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:44:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:44:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:44:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:44:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:44:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:44:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:44:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:44:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:44:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:44:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:44:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:44:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:44:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:44:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:44:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:44:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:44:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:44:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:44:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:44:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:44:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:44:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:44:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:44:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:44:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:44:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:44:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=370145) [2026-01-25 19:44:33] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=370145) [2026-01-25 19:44:33] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=370145) [2026-01-25 19:44:33] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=370145) [2026-01-25 19:44:33] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=370145) [2026-01-25 19:44:33] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=370145) [2026-01-25 19:44:33] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=370145) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=370145) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.52s/it]
(EngineCore_DP0 pid=370145) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.52s/it]
(EngineCore_DP0 pid=370145) 
(EngineCore_DP0 pid=370145) [2026-01-25 19:45:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=370145) [2026-01-25 19:45:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=370145) [2026-01-25 19:45:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=370145) [2026-01-25 19:45:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10616832 bytes
(EngineCore_DP0 pid=370145) [2026-01-25 19:45:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=370145) [2026-01-25 19:45:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56623104 bytes
(EngineCore_DP0 pid=370145) [2026-01-25 19:45:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=370145) [2026-01-25 19:45:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28311552 bytes
(EngineCore_DP0 pid=370145) Process EngineCore_DP0:
(EngineCore_DP0 pid=370145) Traceback (most recent call last):
(EngineCore_DP0 pid=370145)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=370145)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=370145)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=370145)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=370145) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp_jbp099j.ptx', '-o', '/tmp/tmp_jbp099j.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=370145) 
(EngineCore_DP0 pid=370145) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=370145) 
(EngineCore_DP0 pid=370145) Traceback (most recent call last):
(EngineCore_DP0 pid=370145)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=370145)     self.run()
(EngineCore_DP0 pid=370145)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=370145)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=370145)     raise e
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=370145)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=370145)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=370145)     super().__init__(
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=370145)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=370145)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=370145)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=370145)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=370145)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=370145)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=370145)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=370145)     return func(*args, **kwargs)
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=370145)     return func(*args, **kwargs)
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=370145)     self.model_runner.profile_run()
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=370145)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=370145)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=370145)     return func(*args, **kwargs)
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=370145)     outputs = self.model(
(EngineCore_DP0 pid=370145)               ^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=370145)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=370145)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=370145)     model_output = self.model(
(EngineCore_DP0 pid=370145)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=370145)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=370145)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=370145)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=370145)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=370145)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=370145)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=370145)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=370145)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=370145)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=370145)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=370145)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=370145)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=370145)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=370145)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=370145)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=370145)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=370145)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=370145)     return self._linear_fn(
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=370145)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=370145)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=370145)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=370145)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=370145)     return fn(input, L)
(EngineCore_DP0 pid=370145)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=370145)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=370145)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=370145)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=370145)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=370145)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=370145)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=370145)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=370145)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=370145)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=370145)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=370145)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=370145)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370145)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=370145)     raise PTXASError(error)
(EngineCore_DP0 pid=370145) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=370145) `ptxas` stderr:
(EngineCore_DP0 pid=370145) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=370145) 
(EngineCore_DP0 pid=370145) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp_jbp099j.ptx -o /tmp/tmp_jbp099j.ptx.o
(EngineCore_DP0 pid=370145) 
[rank0]:[W125 19:45:03.943788731 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 19:45:05
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:45:10 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:45:10 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=370899) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=370899) 
(EngineCore_DP0 pid=370899) 
(EngineCore_DP0 pid=370899) ================================================================
(EngineCore_DP0 pid=370899) Internal Triton PTX codegen error
(EngineCore_DP0 pid=370899) `ptxas` stderr:
(EngineCore_DP0 pid=370899) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=370899) 
(EngineCore_DP0 pid=370899) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp1lgnpwh0.ptx -o /tmp/tmp1lgnpwh0.ptx.o
(EngineCore_DP0 pid=370899) 
(EngineCore_DP0 pid=370899) 
(EngineCore_DP0 pid=370899) //
(EngineCore_DP0 pid=370899) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=370899) //
(EngineCore_DP0 pid=370899) 
(EngineCore_DP0 pid=370899) .version 8.7
(EngineCore_DP0 pid=370899) .target sm_121a
(EngineCore_DP0 pid=370899) .address_size 64
(EngineCore_DP0 pid=370899) 
(EngineCore_DP0 pid=370899) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=370899) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=370899)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=370899) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=370899) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=370899) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=370899) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=370899) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=370899) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=370899) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=370899) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=370899) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=370899) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=370899) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=370899) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=370899) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=370899) )
(EngineCore_DP0 pid=370899) .reqntid 512
(EngineCore_DP0 pid=370899) {
(EngineCore_DP0 pid=370899) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=370899) 	.reg .b16 	%rs<40>;
(EngineCore_DP0 pid=370899) 	.reg .b32 	%r<173>;
(EngineCore_DP0 pid=370899) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=370899) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=370899) $L__func_begin0:
(EngineCore_DP0 pid=370899) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=370899) 
(EngineCore_DP0 pid=370899) // %bb.0:
(EngineCore_DP0 pid=370899) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=370899) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=370899) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=370899) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=370899) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=370899) $L__tmp0:
(EngineCore_DP0 pid=370899) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=370899) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=370899) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=370899) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=370899) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=370899) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=370899) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=370899) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=370899) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=370899) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=370899) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=370899) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=370899) 	mov.b32 	%r171, 0f2B8CBCCC;
(EngineCore_DP0 pid=370899) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=370899) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=370899) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=370899) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=370899) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=370899) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=370899) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=370899) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=370899) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=370899) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=370899) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=370899) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=370899) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=370899) 	mov.b32 	%r169, 0f00000000;
(EngineCore_DP0 pid=370899) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=370899) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=370899) 	mov.b32 	%r170, %r45;
(EngineCore_DP0 pid=370899) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=370899) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=370899) 	add.s32 	%r55, %r4, %r170;
(EngineCore_DP0 pid=370899) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=370899) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=370899) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=370899) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=370899) 	// begin inline asm
(EngineCore_DP0 pid=370899) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=370899) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=370899) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=370899) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=370899) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=370899) 	// end inline asm
(EngineCore_DP0 pid=370899) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=370899) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=370899) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=370899) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=370899) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=370899) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=370899) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=370899) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=370899) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=370899) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=370899) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=370899) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=370899) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=370899) $L__tmp1:
(EngineCore_DP0 pid=370899) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	bar.sync 	0;
(EngineCore_DP0 pid=370899) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=370899) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=370899) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=370899) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=370899) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=370899) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=370899) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=370899) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=370899) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=370899) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=370899) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=370899) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=370899) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=370899) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=370899) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=370899) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=370899) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=370899) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=370899) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	// begin inline asm
(EngineCore_DP0 pid=370899) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=370899) 	// end inline asm
(EngineCore_DP0 pid=370899) 	bar.sync 	0;
(EngineCore_DP0 pid=370899) 	// begin inline asm
(EngineCore_DP0 pid=370899) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=370899) 	// end inline asm
(EngineCore_DP0 pid=370899) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=370899) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=370899) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=370899) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=370899) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=370899) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=370899) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=370899) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=370899) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=370899) 	// begin inline asm
(EngineCore_DP0 pid=370899) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=370899) 	// end inline asm
(EngineCore_DP0 pid=370899) 	bar.sync 	0;
(EngineCore_DP0 pid=370899) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=370899) $L__tmp2:
(EngineCore_DP0 pid=370899) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=370899) 	max.f32 	%r169, %r169, %r73;
(EngineCore_DP0 pid=370899) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=370899) 	add.s32 	%r170, %r170, 4096;
(EngineCore_DP0 pid=370899) 	setp.lt.s32 	%p6, %r170, %r24;
(EngineCore_DP0 pid=370899) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=370899) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=370899) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=370899) 	max.f32 	%r171, %r169, 0f2B8CBCCC;
(EngineCore_DP0 pid=370899) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=370899) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=370899) 	mov.b32 	%r75, 0f42FE0000;
(EngineCore_DP0 pid=370899) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=370899) 	div.full.f32 	%r76, %r171, %r75;
(EngineCore_DP0 pid=370899) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=370899) 	max.f32 	%r74, %r76, 0f37810204;
(EngineCore_DP0 pid=370899) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=370899) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=370899) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=370899) 	// begin inline asm
(EngineCore_DP0 pid=370899) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=370899) 	// end inline asm
(EngineCore_DP0 pid=370899) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=370899) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=370899) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=370899) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=370899) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=370899) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=370899) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=370899) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=370899) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=370899) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=370899) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=370899) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=370899) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=370899) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=370899) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=370899) 	div.full.f32 	%r14, %r75, %r171;
(EngineCore_DP0 pid=370899) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=370899) 	mov.b32 	%r172, 0;
(EngineCore_DP0 pid=370899) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=370899)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=370899) 	.loc	1 327 31                        // quant_slide_tuned_Llama3.2-3B.py:327:31
(EngineCore_DP0 pid=370899) 	add.s32 	%r81, %r16, %r172;
(EngineCore_DP0 pid=370899) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=370899) 	add.s32 	%r82, %r81, 1;
(EngineCore_DP0 pid=370899) 	setp.lt.s32 	%p17, %r81, %r15;
(EngineCore_DP0 pid=370899) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=370899) 	mul.hi.s32 	%r83, %r82, 1431655766;
(EngineCore_DP0 pid=370899) 	shr.u32 	%r84, %r83, 31;
(EngineCore_DP0 pid=370899) 	add.s32 	%r85, %r83, %r84;
(EngineCore_DP0 pid=370899) 	mul.hi.s32 	%r86, %r81, 1431655766;
(EngineCore_DP0 pid=370899) 	shr.u32 	%r87, %r86, 31;
(EngineCore_DP0 pid=370899) 	add.s32 	%r88, %r86, %r87;
(EngineCore_DP0 pid=370899) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=370899) 	mul.lo.s32 	%r89, %r88, 3;
(EngineCore_DP0 pid=370899) 	mul.lo.s32 	%r90, %r85, 3;
(EngineCore_DP0 pid=370899) 	sub.s32 	%r91, %r82, %r90;
(EngineCore_DP0 pid=370899) 	sub.s32 	%r92, %r81, %r89;
(EngineCore_DP0 pid=370899) 	.loc	1 333 22                        // quant_slide_tuned_Llama3.2-3B.py:333:22
(EngineCore_DP0 pid=370899) 	shl.b32 	%r93, %r88, 3;
(EngineCore_DP0 pid=370899) 	shl.b32 	%r94, %r85, 3;
(EngineCore_DP0 pid=370899) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=370899) 	shl.b32 	%r95, %r92, 1;
(EngineCore_DP0 pid=370899) 	shl.b32 	%r96, %r91, 1;
(EngineCore_DP0 pid=370899) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=370899) 	add.s32 	%r97, %r94, %r96;
(EngineCore_DP0 pid=370899) 	add.s32 	%r98, %r93, %r95;
(EngineCore_DP0 pid=370899) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=370899) 	setp.lt.s32 	%p18, %r98, %r23;
(EngineCore_DP0 pid=370899) 	setp.lt.s32 	%p19, %r97, %r23;
(EngineCore_DP0 pid=370899) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=370899) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=370899) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=370899) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=370899) 	mad.wide.s32 	%rd8, %r98, 2, %rd1;
(EngineCore_DP0 pid=370899) 	mad.wide.s32 	%rd9, %r97, 2, %rd1;
(EngineCore_DP0 pid=370899) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=370899) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=370899) 	// begin inline asm
(EngineCore_DP0 pid=370899) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=370899) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=370899) 	// end inline asm
(EngineCore_DP0 pid=370899) 	// begin inline asm
(EngineCore_DP0 pid=370899) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=370899) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=370899) 	// end inline asm
(EngineCore_DP0 pid=370899) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=370899) 	cvt.f32.bf16 	%r99, %rs24;
(EngineCore_DP0 pid=370899) 	cvt.f32.bf16 	%r100, %rs26;
(EngineCore_DP0 pid=370899) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=370899) 	or.b32 	%r101, %r98, 1;
(EngineCore_DP0 pid=370899) 	or.b32 	%r102, %r97, 1;
(EngineCore_DP0 pid=370899) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=370899) 	setp.lt.s32 	%p20, %r101, %r23;
(EngineCore_DP0 pid=370899) 	setp.lt.s32 	%p21, %r102, %r23;
(EngineCore_DP0 pid=370899) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=370899) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=370899) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=370899) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=370899) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=370899) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=370899) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=370899) 	// begin inline asm
(EngineCore_DP0 pid=370899) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=370899) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=370899) 	// end inline asm
(EngineCore_DP0 pid=370899) 	// begin inline asm
(EngineCore_DP0 pid=370899) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=370899) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=370899) 	// end inline asm
(EngineCore_DP0 pid=370899) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=370899) 	cvt.f32.bf16 	%r103, %rs28;
(EngineCore_DP0 pid=370899) 	cvt.f32.bf16 	%r104, %rs30;
(EngineCore_DP0 pid=370899) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=370899) 	add.s32 	%r105, %r98, 2;
(EngineCore_DP0 pid=370899) 	add.s32 	%r106, %r97, 2;
(EngineCore_DP0 pid=370899) 	add.s32 	%r107, %r98, 3;
(EngineCore_DP0 pid=370899) 	add.s32 	%r108, %r97, 3;
(EngineCore_DP0 pid=370899) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=370899) 	setp.lt.s32 	%p22, %r108, %r23;
(EngineCore_DP0 pid=370899) 	setp.lt.s32 	%p23, %r107, %r23;
(EngineCore_DP0 pid=370899) 	setp.lt.s32 	%p24, %r106, %r23;
(EngineCore_DP0 pid=370899) 	setp.lt.s32 	%p25, %r105, %r23;
(EngineCore_DP0 pid=370899) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=370899) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=370899) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=370899) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=370899) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=370899) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=370899) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=370899) 	// begin inline asm
(EngineCore_DP0 pid=370899) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=370899) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=370899) 	// end inline asm
(EngineCore_DP0 pid=370899) 	// begin inline asm
(EngineCore_DP0 pid=370899) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=370899) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=370899) 	// end inline asm
(EngineCore_DP0 pid=370899) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=370899) 	cvt.f32.bf16 	%r109, %rs32;
(EngineCore_DP0 pid=370899) 	cvt.f32.bf16 	%r110, %rs34;
(EngineCore_DP0 pid=370899) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=370899) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=370899) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=370899) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=370899) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=370899) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=370899) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=370899) 	// begin inline asm
(EngineCore_DP0 pid=370899) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=370899) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=370899) 	// end inline asm
(EngineCore_DP0 pid=370899) 	// begin inline asm
(EngineCore_DP0 pid=370899) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=370899) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=370899) 	// end inline asm
(EngineCore_DP0 pid=370899) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=370899) 	cvt.f32.bf16 	%r111, %rs36;
(EngineCore_DP0 pid=370899) 	cvt.f32.bf16 	%r112, %rs38;
(EngineCore_DP0 pid=370899) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=370899) 	mul.f32 	%r113, %r14, %r99;
(EngineCore_DP0 pid=370899) 	mul.f32 	%r114, %r14, %r100;
(EngineCore_DP0 pid=370899) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=370899) 	cvt.rni.f32.f32 	%r115, %r113;
(EngineCore_DP0 pid=370899) 	cvt.rni.f32.f32 	%r116, %r114;
(EngineCore_DP0 pid=370899) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=370899) 	max.f32 	%r117, %r115, 0fC3000000;
(EngineCore_DP0 pid=370899) 	min.f32 	%r118, %r117, 0f42FE0000;
(EngineCore_DP0 pid=370899) 	max.f32 	%r119, %r116, 0fC3000000;
(EngineCore_DP0 pid=370899) 	min.f32 	%r120, %r119, 0f42FE0000;
(EngineCore_DP0 pid=370899) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=370899) 	cvt.rzi.s32.f32 	%r121, %r118;
(EngineCore_DP0 pid=370899) 	cvt.rzi.s32.f32 	%r122, %r120;
(EngineCore_DP0 pid=370899) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=370899) 	and.b32 	%r123, %r121, 255;
(EngineCore_DP0 pid=370899) 	and.b32 	%r124, %r122, 255;
(EngineCore_DP0 pid=370899) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=370899) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=370899) 	mul.f32 	%r126, %r14, %r104;
(EngineCore_DP0 pid=370899) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=370899) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=370899) 	cvt.rni.f32.f32 	%r128, %r126;
(EngineCore_DP0 pid=370899) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=370899) 	mul.f32 	%r129, %r14, %r109;
(EngineCore_DP0 pid=370899) 	mul.f32 	%r130, %r14, %r110;
(EngineCore_DP0 pid=370899) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=370899) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=370899) 	cvt.rni.f32.f32 	%r132, %r130;
(EngineCore_DP0 pid=370899) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=370899) 	mul.f32 	%r133, %r14, %r111;
(EngineCore_DP0 pid=370899) 	mul.f32 	%r134, %r14, %r112;
(EngineCore_DP0 pid=370899) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=370899) 	cvt.rni.f32.f32 	%r135, %r133;
(EngineCore_DP0 pid=370899) 	cvt.rni.f32.f32 	%r136, %r134;
(EngineCore_DP0 pid=370899) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=370899) 	max.f32 	%r137, %r135, 0fC3000000;
(EngineCore_DP0 pid=370899) 	min.f32 	%r138, %r137, 0f42FE0000;
(EngineCore_DP0 pid=370899) 	max.f32 	%r139, %r136, 0fC3000000;
(EngineCore_DP0 pid=370899) 	min.f32 	%r140, %r139, 0f42FE0000;
(EngineCore_DP0 pid=370899) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=370899) 	cvt.rzi.s32.f32 	%r141, %r138;
(EngineCore_DP0 pid=370899) 	cvt.rzi.s32.f32 	%r142, %r140;
(EngineCore_DP0 pid=370899) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=370899) 	max.f32 	%r143, %r131, 0fC3000000;
(EngineCore_DP0 pid=370899) 	max.f32 	%r144, %r127, 0fC3000000;
(EngineCore_DP0 pid=370899) 	min.f32 	%r145, %r144, 0f42FE0000;
(EngineCore_DP0 pid=370899) 	min.f32 	%r146, %r143, 0f42FE0000;
(EngineCore_DP0 pid=370899) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=370899) 	cvt.rzi.s32.f32 	%r147, %r146;
(EngineCore_DP0 pid=370899) 	cvt.rzi.s32.f32 	%r148, %r145;
(EngineCore_DP0 pid=370899) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=370899) 	shl.b32 	%r149, %r148, 8;
(EngineCore_DP0 pid=370899) 	shl.b32 	%r150, %r147, 16;
(EngineCore_DP0 pid=370899) 	and.b32 	%r151, %r150, 16711680;
(EngineCore_DP0 pid=370899) 	and.b32 	%r152, %r149, 65280;
(EngineCore_DP0 pid=370899) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=370899) 	or.b32 	%r153, %r152, %r123;
(EngineCore_DP0 pid=370899) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=370899) 	max.f32 	%r154, %r132, 0fC3000000;
(EngineCore_DP0 pid=370899) 	max.f32 	%r155, %r128, 0fC3000000;
(EngineCore_DP0 pid=370899) 	min.f32 	%r156, %r155, 0f42FE0000;
(EngineCore_DP0 pid=370899) 	min.f32 	%r157, %r154, 0f42FE0000;
(EngineCore_DP0 pid=370899) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=370899) 	cvt.rzi.s32.f32 	%r158, %r157;
(EngineCore_DP0 pid=370899) 	cvt.rzi.s32.f32 	%r159, %r156;
(EngineCore_DP0 pid=370899) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=370899) 	shl.b32 	%r160, %r159, 8;
(EngineCore_DP0 pid=370899) 	shl.b32 	%r161, %r158, 16;
(EngineCore_DP0 pid=370899) 	and.b32 	%r162, %r161, 16711680;
(EngineCore_DP0 pid=370899) 	and.b32 	%r163, %r160, 65280;
(EngineCore_DP0 pid=370899) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=370899) 	or.b32 	%r164, %r163, %r124;
(EngineCore_DP0 pid=370899) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=370899) 	or.b32 	%r165, %r153, %r151;
(EngineCore_DP0 pid=370899) 	or.b32 	%r166, %r164, %r162;
(EngineCore_DP0 pid=370899) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=370899) 	shl.b32 	%r167, %r141, 24;
(EngineCore_DP0 pid=370899) 	shl.b32 	%r168, %r142, 24;
(EngineCore_DP0 pid=370899) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=370899) 	or.b32 	%r78, %r165, %r167;
(EngineCore_DP0 pid=370899) 	or.b32 	%r79, %r166, %r168;
(EngineCore_DP0 pid=370899) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=370899) 	mad.wide.s32 	%rd16, %r81, 4, %rd2;
(EngineCore_DP0 pid=370899) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=370899) 	// begin inline asm
(EngineCore_DP0 pid=370899) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r78, %r79 };
(EngineCore_DP0 pid=370899) 	// end inline asm
(EngineCore_DP0 pid=370899) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=370899) 	add.s32 	%r172, %r172, 1024;
(EngineCore_DP0 pid=370899) 	setp.lt.s32 	%p26, %r172, %r15;
(EngineCore_DP0 pid=370899) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=370899) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=370899) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=370899) 	ret;
(EngineCore_DP0 pid=370899) $L__tmp3:
(EngineCore_DP0 pid=370899) $L__func_end0:
(EngineCore_DP0 pid=370899)                                         // -- End function
(EngineCore_DP0 pid=370899) }
(EngineCore_DP0 pid=370899) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=370899) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=370899) 	.section	.debug_abbrev
(EngineCore_DP0 pid=370899) 	{
(EngineCore_DP0 pid=370899) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=370899) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=370899) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=370899) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=370899) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=370899) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=370899) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=370899) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=370899) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=370899) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=370899) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=370899) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=370899) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=370899) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=370899) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=370899) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=370899) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=370899) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=370899) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=370899) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=370899) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=370899) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=370899) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=370899) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=370899) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=370899) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=370899) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=370899) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=370899) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=370899) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=370899) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=370899) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=370899) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=370899) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=370899) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=370899) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=370899) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=370899) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=370899) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=370899) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=370899) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=370899) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=370899) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=370899) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=370899) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=370899) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=370899) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=370899) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=370899) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=370899) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=370899) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=370899) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=370899) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=370899) 	}
(EngineCore_DP0 pid=370899) 	.section	.debug_info
(EngineCore_DP0 pid=370899) 	{
(EngineCore_DP0 pid=370899) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=370899) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=370899) .b8 0
(EngineCore_DP0 pid=370899) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=370899) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=370899) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=370899) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=370899) .b8 114
(EngineCore_DP0 pid=370899) .b8 105
(EngineCore_DP0 pid=370899) .b8 116
(EngineCore_DP0 pid=370899) .b8 111
(EngineCore_DP0 pid=370899) .b8 110
(EngineCore_DP0 pid=370899) .b8 0
(EngineCore_DP0 pid=370899) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=370899) .b8 0
(EngineCore_DP0 pid=370899) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=370899) .b8 117
(EngineCore_DP0 pid=370899) .b8 97
(EngineCore_DP0 pid=370899) .b8 110
(EngineCore_DP0 pid=370899) .b8 116
(EngineCore_DP0 pid=370899) .b8 95
(EngineCore_DP0 pid=370899) .b8 115
(EngineCore_DP0 pid=370899) .b8 108
(EngineCore_DP0 pid=370899) .b8 105
(EngineCore_DP0 pid=370899) .b8 100
(EngineCore_DP0 pid=370899) .b8 101
(EngineCore_DP0 pid=370899) .b8 95
(EngineCore_DP0 pid=370899) .b8 116
(EngineCore_DP0 pid=370899) .b8 117
(EngineCore_DP0 pid=370899) .b8 110
(EngineCore_DP0 pid=370899) .b8 101
(EngineCore_DP0 pid=370899) .b8 100
(EngineCore_DP0 pid=370899) .b8 95
(EngineCore_DP0 pid=370899) .b8 76
(EngineCore_DP0 pid=370899) .b8 108
(EngineCore_DP0 pid=370899) .b8 97
(EngineCore_DP0 pid=370899) .b8 109
(EngineCore_DP0 pid=370899) .b8 97
(EngineCore_DP0 pid=370899) .b8 51
(EngineCore_DP0 pid=370899) .b8 46
(EngineCore_DP0 pid=370899) .b8 50
(EngineCore_DP0 pid=370899) .b8 45
(EngineCore_DP0 pid=370899) .b8 51
(EngineCore_DP0 pid=370899) .b8 66
(EngineCore_DP0 pid=370899) .b8 46
(EngineCore_DP0 pid=370899) .b8 112
(EngineCore_DP0 pid=370899) .b8 121
(EngineCore_DP0 pid=370899) .b8 0
(EngineCore_DP0 pid=370899) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=370899) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=370899) .b8 114
(EngineCore_DP0 pid=370899) .b8 111
(EngineCore_DP0 pid=370899) .b8 111
(EngineCore_DP0 pid=370899) .b8 116
(EngineCore_DP0 pid=370899) .b8 47
(EngineCore_DP0 pid=370899) .b8 118
(EngineCore_DP0 pid=370899) .b8 108
(EngineCore_DP0 pid=370899) .b8 108
(EngineCore_DP0 pid=370899) .b8 109
(EngineCore_DP0 pid=370899) .b8 98
(EngineCore_DP0 pid=370899) .b8 101
(EngineCore_DP0 pid=370899) .b8 110
(EngineCore_DP0 pid=370899) .b8 99
(EngineCore_DP0 pid=370899) .b8 104
(EngineCore_DP0 pid=370899) .b8 47
(EngineCore_DP0 pid=370899) .b8 115
(EngineCore_DP0 pid=370899) .b8 108
(EngineCore_DP0 pid=370899) .b8 105
(EngineCore_DP0 pid=370899) .b8 100
(EngineCore_DP0 pid=370899) .b8 101
(EngineCore_DP0 pid=370899) .b8 115
(EngineCore_DP0 pid=370899) .b8 112
(EngineCore_DP0 pid=370899) .b8 97
(EngineCore_DP0 pid=370899) .b8 114
(EngineCore_DP0 pid=370899) .b8 115
(EngineCore_DP0 pid=370899) .b8 101
(EngineCore_DP0 pid=370899) .b8 47
(EngineCore_DP0 pid=370899) .b8 99
(EngineCore_DP0 pid=370899) .b8 115
(EngineCore_DP0 pid=370899) .b8 114
(EngineCore_DP0 pid=370899) .b8 99
(EngineCore_DP0 pid=370899) .b8 47
(EngineCore_DP0 pid=370899) .b8 102
(EngineCore_DP0 pid=370899) .b8 117
(EngineCore_DP0 pid=370899) .b8 115
(EngineCore_DP0 pid=370899) .b8 101
(EngineCore_DP0 pid=370899) .b8 100
(EngineCore_DP0 pid=370899) .b8 95
(EngineCore_DP0 pid=370899) .b8 113
(EngineCore_DP0 pid=370899) .b8 117
(EngineCore_DP0 pid=370899) .b8 97
(EngineCore_DP0 pid=370899) .b8 110
(EngineCore_DP0 pid=370899) .b8 116
(EngineCore_DP0 pid=370899) .b8 95
(EngineCore_DP0 pid=370899) .b8 115
(EngineCore_DP0 pid=370899) .b8 108
(EngineCore_DP0 pid=370899) .b8 105
(EngineCore_DP0 pid=370899) .b8 100
(EngineCore_DP0 pid=370899) .b8 101
(EngineCore_DP0 pid=370899) .b8 95
(EngineCore_DP0 pid=370899) .b8 116
(EngineCore_DP0 pid=370899) .b8 114
(EngineCore_DP0 pid=370899) .b8 105
(EngineCore_DP0 pid=370899) .b8 116
(EngineCore_DP0 pid=370899) .b8 111
(EngineCore_DP0 pid=370899) .b8 110
(EngineCore_DP0 pid=370899) .b8 47
(EngineCore_DP0 pid=370899) .b8 98
(EngineCore_DP0 pid=370899) .b8 117
(EngineCore_DP0 pid=370899) .b8 105
(EngineCore_DP0 pid=370899) .b8 108
(EngineCore_DP0 pid=370899) .b8 100
(EngineCore_DP0 pid=370899) .b8 47
(EngineCore_DP0 pid=370899) .b8 71
(EngineCore_DP0 pid=370899) .b8 66
(EngineCore_DP0 pid=370899) .b8 49
(EngineCore_DP0 pid=370899) .b8 48
(EngineCore_DP0 pid=370899) .b8 95
(EngineCore_DP0 pid=370899) .b8 99
(EngineCore_DP0 pid=370899) .b8 99
(EngineCore_DP0 pid=370899) .b8 49
(EngineCore_DP0 pid=370899) .b8 50
(EngineCore_DP0 pid=370899) .b8 49
(EngineCore_DP0 pid=370899) .b8 95
(EngineCore_DP0 pid=370899) .b8 112
(EngineCore_DP0 pid=370899) .b8 121
(EngineCore_DP0 pid=370899) .b8 51
(EngineCore_DP0 pid=370899) .b8 49
(EngineCore_DP0 pid=370899) .b8 50
(EngineCore_DP0 pid=370899) .b8 95
(EngineCore_DP0 pid=370899) .b8 99
(EngineCore_DP0 pid=370899) .b8 117
(EngineCore_DP0 pid=370899) .b8 49
(EngineCore_DP0 pid=370899) .b8 50
(EngineCore_DP0 pid=370899) .b8 57
(EngineCore_DP0 pid=370899) .b8 95
(EngineCore_DP0 pid=370899) .b8 97
(EngineCore_DP0 pid=370899) .b8 97
(EngineCore_DP0 pid=370899) .b8 114
(EngineCore_DP0 pid=370899) .b8 99
(EngineCore_DP0 pid=370899) .b8 104
(EngineCore_DP0 pid=370899) .b8 54
(EngineCore_DP0 pid=370899) .b8 52
(EngineCore_DP0 pid=370899) .b8 0
(EngineCore_DP0 pid=370899) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=370899) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=370899) .b8 113
(EngineCore_DP0 pid=370899) .b8 117
(EngineCore_DP0 pid=370899) .b8 97
(EngineCore_DP0 pid=370899) .b8 110
(EngineCore_DP0 pid=370899) .b8 116
(EngineCore_DP0 pid=370899) .b8 95
(EngineCore_DP0 pid=370899) .b8 115
(EngineCore_DP0 pid=370899) .b8 108
(EngineCore_DP0 pid=370899) .b8 105
(EngineCore_DP0 pid=370899) .b8 100
(EngineCore_DP0 pid=370899) .b8 101
(EngineCore_DP0 pid=370899) .b8 95
(EngineCore_DP0 pid=370899) .b8 105
(EngineCore_DP0 pid=370899) .b8 110
(EngineCore_DP0 pid=370899) .b8 116
(EngineCore_DP0 pid=370899) .b8 56
(EngineCore_DP0 pid=370899) .b8 95
(EngineCore_DP0 pid=370899) .b8 107
(EngineCore_DP0 pid=370899) .b8 101
(EngineCore_DP0 pid=370899) .b8 114
(EngineCore_DP0 pid=370899) .b8 110
(EngineCore_DP0 pid=370899) .b8 101
(EngineCore_DP0 pid=370899) .b8 108
(EngineCore_DP0 pid=370899) .b8 0
(EngineCore_DP0 pid=370899) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=370899) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=370899) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=370899) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=370899) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=370899) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=370899) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=370899) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=370899) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=370899) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=370899) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=370899) .b8 1
(EngineCore_DP0 pid=370899) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=370899) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=370899) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=370899) 	}
(EngineCore_DP0 pid=370899) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=370899) 
(EngineCore_DP0 pid=370899) ================================================================
(EngineCore_DP0 pid=370899) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=370899) 
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp1lgnpwh0.ptx', '-o', '/tmp/tmp1lgnpwh0.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866] 
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866] 
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866] 
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp1lgnpwh0.ptx -o /tmp/tmp1lgnpwh0.ptx.o
(EngineCore_DP0 pid=370899) ERROR 01-25 19:45:44 [core.py:866] 

STDERR:
[2026-01-25 19:45:10] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:45:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:45:10] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:45:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:45:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:45:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:45:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:45:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:45:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:45:13] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:45:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:45:13] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:45:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:45:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:45:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:45:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:45:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:45:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=370899) [2026-01-25 19:45:14] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=370899) [2026-01-25 19:45:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=370899) [2026-01-25 19:45:14] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=370899) [2026-01-25 19:45:14] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=370899) [2026-01-25 19:45:14] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=370899) [2026-01-25 19:45:14] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=370899) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=370899) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.61s/it]
(EngineCore_DP0 pid=370899) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.61s/it]
(EngineCore_DP0 pid=370899) 
(EngineCore_DP0 pid=370899) [2026-01-25 19:45:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=370899) [2026-01-25 19:45:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=370899) [2026-01-25 19:45:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=370899) [2026-01-25 19:45:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10616832 bytes
(EngineCore_DP0 pid=370899) [2026-01-25 19:45:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=370899) [2026-01-25 19:45:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56623104 bytes
(EngineCore_DP0 pid=370899) [2026-01-25 19:45:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=370899) [2026-01-25 19:45:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28311552 bytes
(EngineCore_DP0 pid=370899) Process EngineCore_DP0:
(EngineCore_DP0 pid=370899) Traceback (most recent call last):
(EngineCore_DP0 pid=370899)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=370899)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=370899)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=370899)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=370899) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp1lgnpwh0.ptx', '-o', '/tmp/tmp1lgnpwh0.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=370899) 
(EngineCore_DP0 pid=370899) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=370899) 
(EngineCore_DP0 pid=370899) Traceback (most recent call last):
(EngineCore_DP0 pid=370899)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=370899)     self.run()
(EngineCore_DP0 pid=370899)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=370899)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=370899)     raise e
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=370899)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=370899)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=370899)     super().__init__(
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=370899)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=370899)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=370899)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=370899)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=370899)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=370899)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=370899)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=370899)     return func(*args, **kwargs)
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=370899)     return func(*args, **kwargs)
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=370899)     self.model_runner.profile_run()
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=370899)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=370899)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=370899)     return func(*args, **kwargs)
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=370899)     outputs = self.model(
(EngineCore_DP0 pid=370899)               ^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=370899)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=370899)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=370899)     model_output = self.model(
(EngineCore_DP0 pid=370899)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=370899)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=370899)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=370899)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=370899)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=370899)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=370899)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=370899)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=370899)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=370899)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=370899)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=370899)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=370899)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=370899)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=370899)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=370899)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=370899)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=370899)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=370899)     return self._linear_fn(
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=370899)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=370899)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=370899)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=370899)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=370899)     return fn(input, L)
(EngineCore_DP0 pid=370899)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=370899)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=370899)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=370899)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=370899)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=370899)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=370899)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=370899)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=370899)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=370899)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=370899)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=370899)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=370899)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370899)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=370899)     raise PTXASError(error)
(EngineCore_DP0 pid=370899) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=370899) `ptxas` stderr:
(EngineCore_DP0 pid=370899) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=370899) 
(EngineCore_DP0 pid=370899) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp1lgnpwh0.ptx -o /tmp/tmp1lgnpwh0.ptx.o
(EngineCore_DP0 pid=370899) 
[rank0]:[W125 19:45:45.202753201 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 19:45:46
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:45:52 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:45:52 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=371689) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=371689) 
(EngineCore_DP0 pid=371689) 
(EngineCore_DP0 pid=371689) ================================================================
(EngineCore_DP0 pid=371689) Internal Triton PTX codegen error
(EngineCore_DP0 pid=371689) `ptxas` stderr:
(EngineCore_DP0 pid=371689) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=371689) 
(EngineCore_DP0 pid=371689) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpxsj21ef2.ptx -o /tmp/tmpxsj21ef2.ptx.o
(EngineCore_DP0 pid=371689) 
(EngineCore_DP0 pid=371689) 
(EngineCore_DP0 pid=371689) //
(EngineCore_DP0 pid=371689) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=371689) //
(EngineCore_DP0 pid=371689) 
(EngineCore_DP0 pid=371689) .version 8.7
(EngineCore_DP0 pid=371689) .target sm_121a
(EngineCore_DP0 pid=371689) .address_size 64
(EngineCore_DP0 pid=371689) 
(EngineCore_DP0 pid=371689) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=371689) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=371689)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=371689) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=371689) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=371689) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=371689) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=371689) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=371689) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=371689) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=371689) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=371689) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=371689) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=371689) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=371689) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=371689) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=371689) )
(EngineCore_DP0 pid=371689) .reqntid 512
(EngineCore_DP0 pid=371689) {
(EngineCore_DP0 pid=371689) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=371689) 	.reg .b16 	%rs<64>;
(EngineCore_DP0 pid=371689) 	.reg .b32 	%r<182>;
(EngineCore_DP0 pid=371689) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=371689) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=371689) $L__func_begin0:
(EngineCore_DP0 pid=371689) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=371689) 
(EngineCore_DP0 pid=371689) // %bb.0:
(EngineCore_DP0 pid=371689) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=371689) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=371689) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=371689) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=371689) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=371689) $L__tmp0:
(EngineCore_DP0 pid=371689) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=371689) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=371689) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=371689) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=371689) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=371689) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=371689) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=371689) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=371689) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=371689) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=371689) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=371689) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=371689) 	mov.b32 	%r180, 0f2B8CBCCC;
(EngineCore_DP0 pid=371689) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=371689) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=371689) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=371689) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=371689) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=371689) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=371689) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=371689) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=371689) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=371689) 	add.s32 	%r57, %r39, %r38;
(EngineCore_DP0 pid=371689) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=371689) 	add.s32 	%r60, %r39, %r40;
(EngineCore_DP0 pid=371689) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=371689) 	mov.b32 	%r178, 0f00000000;
(EngineCore_DP0 pid=371689) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=371689) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=371689) 	mov.b32 	%r179, %r45;
(EngineCore_DP0 pid=371689) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=371689) 	.loc	1 313 19                        // quant_slide_tuned_Llama3.2-3B.py:313:19
(EngineCore_DP0 pid=371689) 	add.s32 	%r63, %r4, %r179;
(EngineCore_DP0 pid=371689) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=371689) 	add.s32 	%r64, %r63, 4096;
(EngineCore_DP0 pid=371689) 	setp.lt.s32 	%p2, %r63, %r23;
(EngineCore_DP0 pid=371689) 	setp.lt.s32 	%p3, %r64, %r23;
(EngineCore_DP0 pid=371689) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=371689) 	mad.wide.s32 	%rd6, %r63, 2, %rd1;
(EngineCore_DP0 pid=371689) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=371689) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=371689) 	// begin inline asm
(EngineCore_DP0 pid=371689) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=371689) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=371689) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=371689) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=371689) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=371689) 	// end inline asm
(EngineCore_DP0 pid=371689) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=371689) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=371689) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=371689) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=371689) 	// begin inline asm
(EngineCore_DP0 pid=371689) 	mov.u32 %r49, %r45;
(EngineCore_DP0 pid=371689) 	mov.u32 %r50, %r45;
(EngineCore_DP0 pid=371689) 	mov.u32 %r51, %r45;
(EngineCore_DP0 pid=371689) 	mov.u32 %r52, %r45;
(EngineCore_DP0 pid=371689) 	@%p3 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=371689) 	// end inline asm
(EngineCore_DP0 pid=371689) 	mov.b32 	{%rs9, %rs10}, %r49;
(EngineCore_DP0 pid=371689) 	mov.b32 	{%rs11, %rs12}, %r50;
(EngineCore_DP0 pid=371689) 	mov.b32 	{%rs13, %rs14}, %r51;
(EngineCore_DP0 pid=371689) 	mov.b32 	{%rs15, %rs16}, %r52;
(EngineCore_DP0 pid=371689) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=371689) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=371689) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=371689) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=371689) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=371689) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=371689) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=371689) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=371689) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=371689) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=371689) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=371689) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=371689) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=371689) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=371689) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=371689) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=371689) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=371689) $L__tmp1:
(EngineCore_DP0 pid=371689) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	bar.sync 	0;
(EngineCore_DP0 pid=371689) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=371689) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=371689) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=371689) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=371689) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=371689) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=371689) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=371689) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=371689) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=371689) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=371689) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=371689) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=371689) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=371689) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=371689) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=371689) 	cvt.f32.bf16 	%r65, %rs47;
(EngineCore_DP0 pid=371689) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	shfl.sync.bfly.b32 	%r66, %r65, 16, 31, -1;
(EngineCore_DP0 pid=371689) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=371689) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	shfl.sync.bfly.b32 	%r68, %r67, 8, 31, -1;
(EngineCore_DP0 pid=371689) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=371689) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	shfl.sync.bfly.b32 	%r70, %r69, 4, 31, -1;
(EngineCore_DP0 pid=371689) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=371689) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	shfl.sync.bfly.b32 	%r72, %r71, 2, 31, -1;
(EngineCore_DP0 pid=371689) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=371689) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	shfl.sync.bfly.b32 	%r74, %r73, 1, 31, -1;
(EngineCore_DP0 pid=371689) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	max.f32 	%r58, %r73, %r74;
(EngineCore_DP0 pid=371689) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	// begin inline asm
(EngineCore_DP0 pid=371689) 	@%p4 st.shared.b32 [ %r57 + 0 ], %r58;
(EngineCore_DP0 pid=371689) 	// end inline asm
(EngineCore_DP0 pid=371689) 	bar.sync 	0;
(EngineCore_DP0 pid=371689) 	// begin inline asm
(EngineCore_DP0 pid=371689) 	@%p5 ld.shared.b32 %r59, [ %r60 + 0 ];
(EngineCore_DP0 pid=371689) 	// end inline asm
(EngineCore_DP0 pid=371689) 	shfl.sync.bfly.b32 	%r75, %r59, 8, 31, -1;
(EngineCore_DP0 pid=371689) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	max.f32 	%r76, %r59, %r75;
(EngineCore_DP0 pid=371689) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	shfl.sync.bfly.b32 	%r77, %r76, 4, 31, -1;
(EngineCore_DP0 pid=371689) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=371689) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	shfl.sync.bfly.b32 	%r79, %r78, 2, 31, -1;
(EngineCore_DP0 pid=371689) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	max.f32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=371689) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	shfl.sync.bfly.b32 	%r81, %r80, 1, 31, -1;
(EngineCore_DP0 pid=371689) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	max.f32 	%r62, %r80, %r81;
(EngineCore_DP0 pid=371689) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=371689) 	// begin inline asm
(EngineCore_DP0 pid=371689) 	@%p28 st.shared.b32 [ %r60 + 0 ], %r62;
(EngineCore_DP0 pid=371689) 	// end inline asm
(EngineCore_DP0 pid=371689) 	bar.sync 	0;
(EngineCore_DP0 pid=371689) 	ld.shared.b32 	%r82, [global_smem];
(EngineCore_DP0 pid=371689) $L__tmp2:
(EngineCore_DP0 pid=371689) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=371689) 	max.f32 	%r178, %r178, %r82;
(EngineCore_DP0 pid=371689) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=371689) 	add.s32 	%r179, %r179, 8192;
(EngineCore_DP0 pid=371689) 	setp.lt.s32 	%p7, %r179, %r24;
(EngineCore_DP0 pid=371689) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=371689) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=371689) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=371689) 	max.f32 	%r180, %r178, 0f2B8CBCCC;
(EngineCore_DP0 pid=371689) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=371689) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=371689) 	mov.b32 	%r84, 0f42FE0000;
(EngineCore_DP0 pid=371689) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=371689) 	div.full.f32 	%r85, %r180, %r84;
(EngineCore_DP0 pid=371689) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=371689) 	max.f32 	%r83, %r85, 0f37810204;
(EngineCore_DP0 pid=371689) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=371689) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=371689) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=371689) 	// begin inline asm
(EngineCore_DP0 pid=371689) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r83 };
(EngineCore_DP0 pid=371689) 	// end inline asm
(EngineCore_DP0 pid=371689) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=371689) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=371689) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=371689) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=371689) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=371689) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=371689) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=371689) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=371689) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=371689) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=371689) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=371689) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=371689) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=371689) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=371689) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=371689) 	div.full.f32 	%r14, %r84, %r180;
(EngineCore_DP0 pid=371689) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=371689) 	mov.b32 	%r181, 0;
(EngineCore_DP0 pid=371689) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=371689)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=371689) 	.loc	1 327 31                        // quant_slide_tuned_Llama3.2-3B.py:327:31
(EngineCore_DP0 pid=371689) 	add.s32 	%r90, %r16, %r181;
(EngineCore_DP0 pid=371689) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=371689) 	add.s32 	%r91, %r90, 1;
(EngineCore_DP0 pid=371689) 	setp.lt.s32 	%p18, %r90, %r15;
(EngineCore_DP0 pid=371689) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=371689) 	mul.hi.s32 	%r92, %r91, 1431655766;
(EngineCore_DP0 pid=371689) 	shr.u32 	%r93, %r92, 31;
(EngineCore_DP0 pid=371689) 	add.s32 	%r94, %r92, %r93;
(EngineCore_DP0 pid=371689) 	mul.hi.s32 	%r95, %r90, 1431655766;
(EngineCore_DP0 pid=371689) 	shr.u32 	%r96, %r95, 31;
(EngineCore_DP0 pid=371689) 	add.s32 	%r97, %r95, %r96;
(EngineCore_DP0 pid=371689) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=371689) 	mul.lo.s32 	%r98, %r97, 3;
(EngineCore_DP0 pid=371689) 	mul.lo.s32 	%r99, %r94, 3;
(EngineCore_DP0 pid=371689) 	sub.s32 	%r100, %r91, %r99;
(EngineCore_DP0 pid=371689) 	sub.s32 	%r101, %r90, %r98;
(EngineCore_DP0 pid=371689) 	.loc	1 333 22                        // quant_slide_tuned_Llama3.2-3B.py:333:22
(EngineCore_DP0 pid=371689) 	shl.b32 	%r102, %r97, 3;
(EngineCore_DP0 pid=371689) 	shl.b32 	%r103, %r94, 3;
(EngineCore_DP0 pid=371689) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=371689) 	shl.b32 	%r104, %r101, 1;
(EngineCore_DP0 pid=371689) 	shl.b32 	%r105, %r100, 1;
(EngineCore_DP0 pid=371689) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=371689) 	add.s32 	%r106, %r103, %r105;
(EngineCore_DP0 pid=371689) 	add.s32 	%r107, %r102, %r104;
(EngineCore_DP0 pid=371689) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=371689) 	setp.lt.s32 	%p19, %r107, %r23;
(EngineCore_DP0 pid=371689) 	setp.lt.s32 	%p20, %r106, %r23;
(EngineCore_DP0 pid=371689) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=371689) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=371689) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=371689) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=371689) 	mad.wide.s32 	%rd9, %r107, 2, %rd1;
(EngineCore_DP0 pid=371689) 	mad.wide.s32 	%rd10, %r106, 2, %rd1;
(EngineCore_DP0 pid=371689) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=371689) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=371689) 	// begin inline asm
(EngineCore_DP0 pid=371689) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=371689) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=371689) 	// end inline asm
(EngineCore_DP0 pid=371689) 	// begin inline asm
(EngineCore_DP0 pid=371689) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=371689) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=371689) 	// end inline asm
(EngineCore_DP0 pid=371689) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=371689) 	cvt.f32.bf16 	%r108, %rs48;
(EngineCore_DP0 pid=371689) 	cvt.f32.bf16 	%r109, %rs50;
(EngineCore_DP0 pid=371689) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=371689) 	or.b32 	%r110, %r107, 1;
(EngineCore_DP0 pid=371689) 	or.b32 	%r111, %r106, 1;
(EngineCore_DP0 pid=371689) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=371689) 	setp.lt.s32 	%p21, %r110, %r23;
(EngineCore_DP0 pid=371689) 	setp.lt.s32 	%p22, %r111, %r23;
(EngineCore_DP0 pid=371689) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=371689) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=371689) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=371689) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=371689) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=371689) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=371689) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=371689) 	// begin inline asm
(EngineCore_DP0 pid=371689) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=371689) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=371689) 	// end inline asm
(EngineCore_DP0 pid=371689) 	// begin inline asm
(EngineCore_DP0 pid=371689) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=371689) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=371689) 	// end inline asm
(EngineCore_DP0 pid=371689) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=371689) 	cvt.f32.bf16 	%r112, %rs52;
(EngineCore_DP0 pid=371689) 	cvt.f32.bf16 	%r113, %rs54;
(EngineCore_DP0 pid=371689) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=371689) 	add.s32 	%r114, %r107, 2;
(EngineCore_DP0 pid=371689) 	add.s32 	%r115, %r106, 2;
(EngineCore_DP0 pid=371689) 	add.s32 	%r116, %r107, 3;
(EngineCore_DP0 pid=371689) 	add.s32 	%r117, %r106, 3;
(EngineCore_DP0 pid=371689) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=371689) 	setp.lt.s32 	%p23, %r117, %r23;
(EngineCore_DP0 pid=371689) 	setp.lt.s32 	%p24, %r116, %r23;
(EngineCore_DP0 pid=371689) 	setp.lt.s32 	%p25, %r115, %r23;
(EngineCore_DP0 pid=371689) 	setp.lt.s32 	%p26, %r114, %r23;
(EngineCore_DP0 pid=371689) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=371689) 	and.pred 	%p14, %p18, %p26;
(EngineCore_DP0 pid=371689) 	and.pred 	%p15, %p18, %p25;
(EngineCore_DP0 pid=371689) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=371689) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=371689) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=371689) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=371689) 	// begin inline asm
(EngineCore_DP0 pid=371689) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=371689) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=371689) 	// end inline asm
(EngineCore_DP0 pid=371689) 	// begin inline asm
(EngineCore_DP0 pid=371689) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=371689) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=371689) 	// end inline asm
(EngineCore_DP0 pid=371689) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=371689) 	cvt.f32.bf16 	%r118, %rs56;
(EngineCore_DP0 pid=371689) 	cvt.f32.bf16 	%r119, %rs58;
(EngineCore_DP0 pid=371689) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=371689) 	and.pred 	%p16, %p18, %p24;
(EngineCore_DP0 pid=371689) 	and.pred 	%p17, %p18, %p23;
(EngineCore_DP0 pid=371689) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=371689) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=371689) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=371689) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=371689) 	// begin inline asm
(EngineCore_DP0 pid=371689) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=371689) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=371689) 	// end inline asm
(EngineCore_DP0 pid=371689) 	// begin inline asm
(EngineCore_DP0 pid=371689) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=371689) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=371689) 	// end inline asm
(EngineCore_DP0 pid=371689) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=371689) 	cvt.f32.bf16 	%r120, %rs60;
(EngineCore_DP0 pid=371689) 	cvt.f32.bf16 	%r121, %rs62;
(EngineCore_DP0 pid=371689) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=371689) 	mul.f32 	%r122, %r14, %r108;
(EngineCore_DP0 pid=371689) 	mul.f32 	%r123, %r14, %r109;
(EngineCore_DP0 pid=371689) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=371689) 	cvt.rni.f32.f32 	%r124, %r122;
(EngineCore_DP0 pid=371689) 	cvt.rni.f32.f32 	%r125, %r123;
(EngineCore_DP0 pid=371689) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=371689) 	max.f32 	%r126, %r124, 0fC3000000;
(EngineCore_DP0 pid=371689) 	min.f32 	%r127, %r126, 0f42FE0000;
(EngineCore_DP0 pid=371689) 	max.f32 	%r128, %r125, 0fC3000000;
(EngineCore_DP0 pid=371689) 	min.f32 	%r129, %r128, 0f42FE0000;
(EngineCore_DP0 pid=371689) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=371689) 	cvt.rzi.s32.f32 	%r130, %r127;
(EngineCore_DP0 pid=371689) 	cvt.rzi.s32.f32 	%r131, %r129;
(EngineCore_DP0 pid=371689) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=371689) 	and.b32 	%r132, %r130, 255;
(EngineCore_DP0 pid=371689) 	and.b32 	%r133, %r131, 255;
(EngineCore_DP0 pid=371689) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=371689) 	mul.f32 	%r134, %r14, %r112;
(EngineCore_DP0 pid=371689) 	mul.f32 	%r135, %r14, %r113;
(EngineCore_DP0 pid=371689) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=371689) 	cvt.rni.f32.f32 	%r136, %r134;
(EngineCore_DP0 pid=371689) 	cvt.rni.f32.f32 	%r137, %r135;
(EngineCore_DP0 pid=371689) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=371689) 	mul.f32 	%r138, %r14, %r118;
(EngineCore_DP0 pid=371689) 	mul.f32 	%r139, %r14, %r119;
(EngineCore_DP0 pid=371689) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=371689) 	cvt.rni.f32.f32 	%r140, %r138;
(EngineCore_DP0 pid=371689) 	cvt.rni.f32.f32 	%r141, %r139;
(EngineCore_DP0 pid=371689) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=371689) 	mul.f32 	%r142, %r14, %r120;
(EngineCore_DP0 pid=371689) 	mul.f32 	%r143, %r14, %r121;
(EngineCore_DP0 pid=371689) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=371689) 	cvt.rni.f32.f32 	%r144, %r142;
(EngineCore_DP0 pid=371689) 	cvt.rni.f32.f32 	%r145, %r143;
(EngineCore_DP0 pid=371689) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=371689) 	max.f32 	%r146, %r144, 0fC3000000;
(EngineCore_DP0 pid=371689) 	min.f32 	%r147, %r146, 0f42FE0000;
(EngineCore_DP0 pid=371689) 	max.f32 	%r148, %r145, 0fC3000000;
(EngineCore_DP0 pid=371689) 	min.f32 	%r149, %r148, 0f42FE0000;
(EngineCore_DP0 pid=371689) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=371689) 	cvt.rzi.s32.f32 	%r150, %r147;
(EngineCore_DP0 pid=371689) 	cvt.rzi.s32.f32 	%r151, %r149;
(EngineCore_DP0 pid=371689) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=371689) 	max.f32 	%r152, %r140, 0fC3000000;
(EngineCore_DP0 pid=371689) 	max.f32 	%r153, %r136, 0fC3000000;
(EngineCore_DP0 pid=371689) 	min.f32 	%r154, %r153, 0f42FE0000;
(EngineCore_DP0 pid=371689) 	min.f32 	%r155, %r152, 0f42FE0000;
(EngineCore_DP0 pid=371689) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=371689) 	cvt.rzi.s32.f32 	%r156, %r155;
(EngineCore_DP0 pid=371689) 	cvt.rzi.s32.f32 	%r157, %r154;
(EngineCore_DP0 pid=371689) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=371689) 	shl.b32 	%r158, %r157, 8;
(EngineCore_DP0 pid=371689) 	shl.b32 	%r159, %r156, 16;
(EngineCore_DP0 pid=371689) 	and.b32 	%r160, %r159, 16711680;
(EngineCore_DP0 pid=371689) 	and.b32 	%r161, %r158, 65280;
(EngineCore_DP0 pid=371689) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=371689) 	or.b32 	%r162, %r161, %r132;
(EngineCore_DP0 pid=371689) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=371689) 	max.f32 	%r163, %r141, 0fC3000000;
(EngineCore_DP0 pid=371689) 	max.f32 	%r164, %r137, 0fC3000000;
(EngineCore_DP0 pid=371689) 	min.f32 	%r165, %r164, 0f42FE0000;
(EngineCore_DP0 pid=371689) 	min.f32 	%r166, %r163, 0f42FE0000;
(EngineCore_DP0 pid=371689) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=371689) 	cvt.rzi.s32.f32 	%r167, %r166;
(EngineCore_DP0 pid=371689) 	cvt.rzi.s32.f32 	%r168, %r165;
(EngineCore_DP0 pid=371689) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=371689) 	shl.b32 	%r169, %r168, 8;
(EngineCore_DP0 pid=371689) 	shl.b32 	%r170, %r167, 16;
(EngineCore_DP0 pid=371689) 	and.b32 	%r171, %r170, 16711680;
(EngineCore_DP0 pid=371689) 	and.b32 	%r172, %r169, 65280;
(EngineCore_DP0 pid=371689) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=371689) 	or.b32 	%r173, %r172, %r133;
(EngineCore_DP0 pid=371689) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=371689) 	or.b32 	%r174, %r162, %r160;
(EngineCore_DP0 pid=371689) 	or.b32 	%r175, %r173, %r171;
(EngineCore_DP0 pid=371689) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=371689) 	shl.b32 	%r176, %r150, 24;
(EngineCore_DP0 pid=371689) 	shl.b32 	%r177, %r151, 24;
(EngineCore_DP0 pid=371689) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=371689) 	or.b32 	%r87, %r174, %r176;
(EngineCore_DP0 pid=371689) 	or.b32 	%r88, %r175, %r177;
(EngineCore_DP0 pid=371689) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=371689) 	mad.wide.s32 	%rd17, %r90, 4, %rd2;
(EngineCore_DP0 pid=371689) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=371689) 	// begin inline asm
(EngineCore_DP0 pid=371689) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r87, %r88 };
(EngineCore_DP0 pid=371689) 	// end inline asm
(EngineCore_DP0 pid=371689) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=371689) 	add.s32 	%r181, %r181, 1024;
(EngineCore_DP0 pid=371689) 	setp.lt.s32 	%p27, %r181, %r15;
(EngineCore_DP0 pid=371689) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=371689) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=371689) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=371689) 	ret;
(EngineCore_DP0 pid=371689) $L__tmp3:
(EngineCore_DP0 pid=371689) $L__func_end0:
(EngineCore_DP0 pid=371689)                                         // -- End function
(EngineCore_DP0 pid=371689) }
(EngineCore_DP0 pid=371689) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=371689) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=371689) 	.section	.debug_abbrev
(EngineCore_DP0 pid=371689) 	{
(EngineCore_DP0 pid=371689) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=371689) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=371689) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=371689) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=371689) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=371689) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=371689) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=371689) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=371689) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=371689) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=371689) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=371689) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=371689) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=371689) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=371689) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=371689) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=371689) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=371689) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=371689) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=371689) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=371689) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=371689) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=371689) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=371689) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=371689) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=371689) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=371689) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=371689) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=371689) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=371689) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=371689) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=371689) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=371689) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=371689) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=371689) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=371689) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=371689) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=371689) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=371689) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=371689) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=371689) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=371689) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=371689) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=371689) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=371689) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=371689) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=371689) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=371689) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=371689) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=371689) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=371689) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=371689) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=371689) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=371689) 	}
(EngineCore_DP0 pid=371689) 	.section	.debug_info
(EngineCore_DP0 pid=371689) 	{
(EngineCore_DP0 pid=371689) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=371689) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=371689) .b8 0
(EngineCore_DP0 pid=371689) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=371689) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=371689) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=371689) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=371689) .b8 114
(EngineCore_DP0 pid=371689) .b8 105
(EngineCore_DP0 pid=371689) .b8 116
(EngineCore_DP0 pid=371689) .b8 111
(EngineCore_DP0 pid=371689) .b8 110
(EngineCore_DP0 pid=371689) .b8 0
(EngineCore_DP0 pid=371689) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=371689) .b8 0
(EngineCore_DP0 pid=371689) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=371689) .b8 117
(EngineCore_DP0 pid=371689) .b8 97
(EngineCore_DP0 pid=371689) .b8 110
(EngineCore_DP0 pid=371689) .b8 116
(EngineCore_DP0 pid=371689) .b8 95
(EngineCore_DP0 pid=371689) .b8 115
(EngineCore_DP0 pid=371689) .b8 108
(EngineCore_DP0 pid=371689) .b8 105
(EngineCore_DP0 pid=371689) .b8 100
(EngineCore_DP0 pid=371689) .b8 101
(EngineCore_DP0 pid=371689) .b8 95
(EngineCore_DP0 pid=371689) .b8 116
(EngineCore_DP0 pid=371689) .b8 117
(EngineCore_DP0 pid=371689) .b8 110
(EngineCore_DP0 pid=371689) .b8 101
(EngineCore_DP0 pid=371689) .b8 100
(EngineCore_DP0 pid=371689) .b8 95
(EngineCore_DP0 pid=371689) .b8 76
(EngineCore_DP0 pid=371689) .b8 108
(EngineCore_DP0 pid=371689) .b8 97
(EngineCore_DP0 pid=371689) .b8 109
(EngineCore_DP0 pid=371689) .b8 97
(EngineCore_DP0 pid=371689) .b8 51
(EngineCore_DP0 pid=371689) .b8 46
(EngineCore_DP0 pid=371689) .b8 50
(EngineCore_DP0 pid=371689) .b8 45
(EngineCore_DP0 pid=371689) .b8 51
(EngineCore_DP0 pid=371689) .b8 66
(EngineCore_DP0 pid=371689) .b8 46
(EngineCore_DP0 pid=371689) .b8 112
(EngineCore_DP0 pid=371689) .b8 121
(EngineCore_DP0 pid=371689) .b8 0
(EngineCore_DP0 pid=371689) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=371689) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=371689) .b8 114
(EngineCore_DP0 pid=371689) .b8 111
(EngineCore_DP0 pid=371689) .b8 111
(EngineCore_DP0 pid=371689) .b8 116
(EngineCore_DP0 pid=371689) .b8 47
(EngineCore_DP0 pid=371689) .b8 118
(EngineCore_DP0 pid=371689) .b8 108
(EngineCore_DP0 pid=371689) .b8 108
(EngineCore_DP0 pid=371689) .b8 109
(EngineCore_DP0 pid=371689) .b8 98
(EngineCore_DP0 pid=371689) .b8 101
(EngineCore_DP0 pid=371689) .b8 110
(EngineCore_DP0 pid=371689) .b8 99
(EngineCore_DP0 pid=371689) .b8 104
(EngineCore_DP0 pid=371689) .b8 47
(EngineCore_DP0 pid=371689) .b8 115
(EngineCore_DP0 pid=371689) .b8 108
(EngineCore_DP0 pid=371689) .b8 105
(EngineCore_DP0 pid=371689) .b8 100
(EngineCore_DP0 pid=371689) .b8 101
(EngineCore_DP0 pid=371689) .b8 115
(EngineCore_DP0 pid=371689) .b8 112
(EngineCore_DP0 pid=371689) .b8 97
(EngineCore_DP0 pid=371689) .b8 114
(EngineCore_DP0 pid=371689) .b8 115
(EngineCore_DP0 pid=371689) .b8 101
(EngineCore_DP0 pid=371689) .b8 47
(EngineCore_DP0 pid=371689) .b8 99
(EngineCore_DP0 pid=371689) .b8 115
(EngineCore_DP0 pid=371689) .b8 114
(EngineCore_DP0 pid=371689) .b8 99
(EngineCore_DP0 pid=371689) .b8 47
(EngineCore_DP0 pid=371689) .b8 102
(EngineCore_DP0 pid=371689) .b8 117
(EngineCore_DP0 pid=371689) .b8 115
(EngineCore_DP0 pid=371689) .b8 101
(EngineCore_DP0 pid=371689) .b8 100
(EngineCore_DP0 pid=371689) .b8 95
(EngineCore_DP0 pid=371689) .b8 113
(EngineCore_DP0 pid=371689) .b8 117
(EngineCore_DP0 pid=371689) .b8 97
(EngineCore_DP0 pid=371689) .b8 110
(EngineCore_DP0 pid=371689) .b8 116
(EngineCore_DP0 pid=371689) .b8 95
(EngineCore_DP0 pid=371689) .b8 115
(EngineCore_DP0 pid=371689) .b8 108
(EngineCore_DP0 pid=371689) .b8 105
(EngineCore_DP0 pid=371689) .b8 100
(EngineCore_DP0 pid=371689) .b8 101
(EngineCore_DP0 pid=371689) .b8 95
(EngineCore_DP0 pid=371689) .b8 116
(EngineCore_DP0 pid=371689) .b8 114
(EngineCore_DP0 pid=371689) .b8 105
(EngineCore_DP0 pid=371689) .b8 116
(EngineCore_DP0 pid=371689) .b8 111
(EngineCore_DP0 pid=371689) .b8 110
(EngineCore_DP0 pid=371689) .b8 47
(EngineCore_DP0 pid=371689) .b8 98
(EngineCore_DP0 pid=371689) .b8 117
(EngineCore_DP0 pid=371689) .b8 105
(EngineCore_DP0 pid=371689) .b8 108
(EngineCore_DP0 pid=371689) .b8 100
(EngineCore_DP0 pid=371689) .b8 47
(EngineCore_DP0 pid=371689) .b8 71
(EngineCore_DP0 pid=371689) .b8 66
(EngineCore_DP0 pid=371689) .b8 49
(EngineCore_DP0 pid=371689) .b8 48
(EngineCore_DP0 pid=371689) .b8 95
(EngineCore_DP0 pid=371689) .b8 99
(EngineCore_DP0 pid=371689) .b8 99
(EngineCore_DP0 pid=371689) .b8 49
(EngineCore_DP0 pid=371689) .b8 50
(EngineCore_DP0 pid=371689) .b8 49
(EngineCore_DP0 pid=371689) .b8 95
(EngineCore_DP0 pid=371689) .b8 112
(EngineCore_DP0 pid=371689) .b8 121
(EngineCore_DP0 pid=371689) .b8 51
(EngineCore_DP0 pid=371689) .b8 49
(EngineCore_DP0 pid=371689) .b8 50
(EngineCore_DP0 pid=371689) .b8 95
(EngineCore_DP0 pid=371689) .b8 99
(EngineCore_DP0 pid=371689) .b8 117
(EngineCore_DP0 pid=371689) .b8 49
(EngineCore_DP0 pid=371689) .b8 50
(EngineCore_DP0 pid=371689) .b8 57
(EngineCore_DP0 pid=371689) .b8 95
(EngineCore_DP0 pid=371689) .b8 97
(EngineCore_DP0 pid=371689) .b8 97
(EngineCore_DP0 pid=371689) .b8 114
(EngineCore_DP0 pid=371689) .b8 99
(EngineCore_DP0 pid=371689) .b8 104
(EngineCore_DP0 pid=371689) .b8 54
(EngineCore_DP0 pid=371689) .b8 52
(EngineCore_DP0 pid=371689) .b8 0
(EngineCore_DP0 pid=371689) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=371689) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=371689) .b8 113
(EngineCore_DP0 pid=371689) .b8 117
(EngineCore_DP0 pid=371689) .b8 97
(EngineCore_DP0 pid=371689) .b8 110
(EngineCore_DP0 pid=371689) .b8 116
(EngineCore_DP0 pid=371689) .b8 95
(EngineCore_DP0 pid=371689) .b8 115
(EngineCore_DP0 pid=371689) .b8 108
(EngineCore_DP0 pid=371689) .b8 105
(EngineCore_DP0 pid=371689) .b8 100
(EngineCore_DP0 pid=371689) .b8 101
(EngineCore_DP0 pid=371689) .b8 95
(EngineCore_DP0 pid=371689) .b8 105
(EngineCore_DP0 pid=371689) .b8 110
(EngineCore_DP0 pid=371689) .b8 116
(EngineCore_DP0 pid=371689) .b8 56
(EngineCore_DP0 pid=371689) .b8 95
(EngineCore_DP0 pid=371689) .b8 107
(EngineCore_DP0 pid=371689) .b8 101
(EngineCore_DP0 pid=371689) .b8 114
(EngineCore_DP0 pid=371689) .b8 110
(EngineCore_DP0 pid=371689) .b8 101
(EngineCore_DP0 pid=371689) .b8 108
(EngineCore_DP0 pid=371689) .b8 0
(EngineCore_DP0 pid=371689) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=371689) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=371689) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=371689) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=371689) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=371689) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=371689) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=371689) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=371689) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=371689) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=371689) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=371689) .b8 1
(EngineCore_DP0 pid=371689) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=371689) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=371689) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=371689) 	}
(EngineCore_DP0 pid=371689) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=371689) 
(EngineCore_DP0 pid=371689) ================================================================
(EngineCore_DP0 pid=371689) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=371689) 
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpxsj21ef2.ptx', '-o', '/tmp/tmpxsj21ef2.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866] 
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866] 
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866] 
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpxsj21ef2.ptx -o /tmp/tmpxsj21ef2.ptx.o
(EngineCore_DP0 pid=371689) ERROR 01-25 19:46:27 [core.py:866] 

STDERR:
[2026-01-25 19:45:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:45:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:45:52] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:45:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:45:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:45:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:45:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:45:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:45:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:45:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:45:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:45:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:45:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:45:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:45:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:45:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:45:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:45:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:45:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=371689) [2026-01-25 19:45:57] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=371689) [2026-01-25 19:45:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=371689) [2026-01-25 19:45:57] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=371689) [2026-01-25 19:45:57] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=371689) [2026-01-25 19:45:57] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=371689) [2026-01-25 19:45:57] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=371689) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=371689) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.68s/it]
(EngineCore_DP0 pid=371689) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.68s/it]
(EngineCore_DP0 pid=371689) 
(EngineCore_DP0 pid=371689) [2026-01-25 19:46:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=371689) [2026-01-25 19:46:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=371689) [2026-01-25 19:46:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=371689) [2026-01-25 19:46:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10616832 bytes
(EngineCore_DP0 pid=371689) [2026-01-25 19:46:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=371689) [2026-01-25 19:46:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56623104 bytes
(EngineCore_DP0 pid=371689) [2026-01-25 19:46:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=371689) [2026-01-25 19:46:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28311552 bytes
(EngineCore_DP0 pid=371689) Process EngineCore_DP0:
(EngineCore_DP0 pid=371689) Traceback (most recent call last):
(EngineCore_DP0 pid=371689)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=371689)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=371689)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=371689)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=371689) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpxsj21ef2.ptx', '-o', '/tmp/tmpxsj21ef2.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=371689) 
(EngineCore_DP0 pid=371689) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=371689) 
(EngineCore_DP0 pid=371689) Traceback (most recent call last):
(EngineCore_DP0 pid=371689)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=371689)     self.run()
(EngineCore_DP0 pid=371689)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=371689)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=371689)     raise e
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=371689)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=371689)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=371689)     super().__init__(
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=371689)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=371689)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=371689)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=371689)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=371689)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=371689)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=371689)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=371689)     return func(*args, **kwargs)
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=371689)     return func(*args, **kwargs)
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=371689)     self.model_runner.profile_run()
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=371689)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=371689)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=371689)     return func(*args, **kwargs)
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=371689)     outputs = self.model(
(EngineCore_DP0 pid=371689)               ^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=371689)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=371689)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=371689)     model_output = self.model(
(EngineCore_DP0 pid=371689)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=371689)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=371689)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=371689)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=371689)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=371689)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=371689)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=371689)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=371689)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=371689)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=371689)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=371689)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=371689)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=371689)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=371689)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=371689)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=371689)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=371689)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=371689)     return self._linear_fn(
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=371689)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=371689)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=371689)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=371689)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=371689)     return fn(input, L)
(EngineCore_DP0 pid=371689)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=371689)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=371689)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=371689)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=371689)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=371689)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=371689)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=371689)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=371689)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=371689)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=371689)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=371689)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=371689)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=371689)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=371689)     raise PTXASError(error)
(EngineCore_DP0 pid=371689) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=371689) `ptxas` stderr:
(EngineCore_DP0 pid=371689) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=371689) 
(EngineCore_DP0 pid=371689) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpxsj21ef2.ptx -o /tmp/tmpxsj21ef2.ptx.o
(EngineCore_DP0 pid=371689) 
[rank0]:[W125 19:46:27.719298555 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 19:46:29
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:46:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:46:38 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=372505) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=372505) 
(EngineCore_DP0 pid=372505) 
(EngineCore_DP0 pid=372505) ================================================================
(EngineCore_DP0 pid=372505) Internal Triton PTX codegen error
(EngineCore_DP0 pid=372505) `ptxas` stderr:
(EngineCore_DP0 pid=372505) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=372505) 
(EngineCore_DP0 pid=372505) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpl47s_yxc.ptx -o /tmp/tmpl47s_yxc.ptx.o
(EngineCore_DP0 pid=372505) 
(EngineCore_DP0 pid=372505) 
(EngineCore_DP0 pid=372505) //
(EngineCore_DP0 pid=372505) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=372505) //
(EngineCore_DP0 pid=372505) 
(EngineCore_DP0 pid=372505) .version 8.7
(EngineCore_DP0 pid=372505) .target sm_121a
(EngineCore_DP0 pid=372505) .address_size 64
(EngineCore_DP0 pid=372505) 
(EngineCore_DP0 pid=372505) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=372505) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=372505)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=372505) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=372505) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=372505) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=372505) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=372505) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=372505) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=372505) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=372505) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=372505) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=372505) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=372505) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=372505) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=372505) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=372505) )
(EngineCore_DP0 pid=372505) .reqntid 512
(EngineCore_DP0 pid=372505) {
(EngineCore_DP0 pid=372505) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=372505) 	.reg .b16 	%rs<64>;
(EngineCore_DP0 pid=372505) 	.reg .b32 	%r<182>;
(EngineCore_DP0 pid=372505) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=372505) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=372505) $L__func_begin0:
(EngineCore_DP0 pid=372505) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=372505) 
(EngineCore_DP0 pid=372505) // %bb.0:
(EngineCore_DP0 pid=372505) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=372505) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=372505) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=372505) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=372505) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=372505) $L__tmp0:
(EngineCore_DP0 pid=372505) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=372505) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=372505) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=372505) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=372505) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=372505) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=372505) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=372505) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=372505) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=372505) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=372505) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=372505) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=372505) 	mov.b32 	%r180, 0f2B8CBCCC;
(EngineCore_DP0 pid=372505) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=372505) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=372505) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=372505) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=372505) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=372505) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=372505) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=372505) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=372505) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=372505) 	add.s32 	%r57, %r39, %r38;
(EngineCore_DP0 pid=372505) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=372505) 	add.s32 	%r60, %r39, %r40;
(EngineCore_DP0 pid=372505) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=372505) 	mov.b32 	%r178, 0f00000000;
(EngineCore_DP0 pid=372505) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=372505) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=372505) 	mov.b32 	%r179, %r45;
(EngineCore_DP0 pid=372505) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=372505) 	.loc	1 313 19                        // quant_slide_tuned_Llama3.2-3B.py:313:19
(EngineCore_DP0 pid=372505) 	add.s32 	%r63, %r4, %r179;
(EngineCore_DP0 pid=372505) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=372505) 	add.s32 	%r64, %r63, 4096;
(EngineCore_DP0 pid=372505) 	setp.lt.s32 	%p2, %r63, %r23;
(EngineCore_DP0 pid=372505) 	setp.lt.s32 	%p3, %r64, %r23;
(EngineCore_DP0 pid=372505) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=372505) 	mad.wide.s32 	%rd6, %r63, 2, %rd1;
(EngineCore_DP0 pid=372505) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=372505) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=372505) 	// begin inline asm
(EngineCore_DP0 pid=372505) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=372505) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=372505) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=372505) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=372505) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=372505) 	// end inline asm
(EngineCore_DP0 pid=372505) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=372505) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=372505) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=372505) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=372505) 	// begin inline asm
(EngineCore_DP0 pid=372505) 	mov.u32 %r49, %r45;
(EngineCore_DP0 pid=372505) 	mov.u32 %r50, %r45;
(EngineCore_DP0 pid=372505) 	mov.u32 %r51, %r45;
(EngineCore_DP0 pid=372505) 	mov.u32 %r52, %r45;
(EngineCore_DP0 pid=372505) 	@%p3 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=372505) 	// end inline asm
(EngineCore_DP0 pid=372505) 	mov.b32 	{%rs9, %rs10}, %r49;
(EngineCore_DP0 pid=372505) 	mov.b32 	{%rs11, %rs12}, %r50;
(EngineCore_DP0 pid=372505) 	mov.b32 	{%rs13, %rs14}, %r51;
(EngineCore_DP0 pid=372505) 	mov.b32 	{%rs15, %rs16}, %r52;
(EngineCore_DP0 pid=372505) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=372505) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=372505) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=372505) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=372505) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=372505) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=372505) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=372505) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=372505) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=372505) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=372505) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=372505) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=372505) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=372505) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=372505) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=372505) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=372505) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=372505) $L__tmp1:
(EngineCore_DP0 pid=372505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	bar.sync 	0;
(EngineCore_DP0 pid=372505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=372505) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=372505) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=372505) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=372505) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=372505) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=372505) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=372505) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=372505) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=372505) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=372505) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=372505) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=372505) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=372505) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=372505) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=372505) 	cvt.f32.bf16 	%r65, %rs47;
(EngineCore_DP0 pid=372505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	shfl.sync.bfly.b32 	%r66, %r65, 16, 31, -1;
(EngineCore_DP0 pid=372505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=372505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	shfl.sync.bfly.b32 	%r68, %r67, 8, 31, -1;
(EngineCore_DP0 pid=372505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=372505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	shfl.sync.bfly.b32 	%r70, %r69, 4, 31, -1;
(EngineCore_DP0 pid=372505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=372505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	shfl.sync.bfly.b32 	%r72, %r71, 2, 31, -1;
(EngineCore_DP0 pid=372505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=372505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	shfl.sync.bfly.b32 	%r74, %r73, 1, 31, -1;
(EngineCore_DP0 pid=372505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	max.f32 	%r58, %r73, %r74;
(EngineCore_DP0 pid=372505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	// begin inline asm
(EngineCore_DP0 pid=372505) 	@%p4 st.shared.b32 [ %r57 + 0 ], %r58;
(EngineCore_DP0 pid=372505) 	// end inline asm
(EngineCore_DP0 pid=372505) 	bar.sync 	0;
(EngineCore_DP0 pid=372505) 	// begin inline asm
(EngineCore_DP0 pid=372505) 	@%p5 ld.shared.b32 %r59, [ %r60 + 0 ];
(EngineCore_DP0 pid=372505) 	// end inline asm
(EngineCore_DP0 pid=372505) 	shfl.sync.bfly.b32 	%r75, %r59, 8, 31, -1;
(EngineCore_DP0 pid=372505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	max.f32 	%r76, %r59, %r75;
(EngineCore_DP0 pid=372505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	shfl.sync.bfly.b32 	%r77, %r76, 4, 31, -1;
(EngineCore_DP0 pid=372505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=372505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	shfl.sync.bfly.b32 	%r79, %r78, 2, 31, -1;
(EngineCore_DP0 pid=372505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	max.f32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=372505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	shfl.sync.bfly.b32 	%r81, %r80, 1, 31, -1;
(EngineCore_DP0 pid=372505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	max.f32 	%r62, %r80, %r81;
(EngineCore_DP0 pid=372505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=372505) 	// begin inline asm
(EngineCore_DP0 pid=372505) 	@%p28 st.shared.b32 [ %r60 + 0 ], %r62;
(EngineCore_DP0 pid=372505) 	// end inline asm
(EngineCore_DP0 pid=372505) 	bar.sync 	0;
(EngineCore_DP0 pid=372505) 	ld.shared.b32 	%r82, [global_smem];
(EngineCore_DP0 pid=372505) $L__tmp2:
(EngineCore_DP0 pid=372505) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=372505) 	max.f32 	%r178, %r178, %r82;
(EngineCore_DP0 pid=372505) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=372505) 	add.s32 	%r179, %r179, 8192;
(EngineCore_DP0 pid=372505) 	setp.lt.s32 	%p7, %r179, %r24;
(EngineCore_DP0 pid=372505) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=372505) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=372505) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=372505) 	max.f32 	%r180, %r178, 0f2B8CBCCC;
(EngineCore_DP0 pid=372505) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=372505) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=372505) 	mov.b32 	%r84, 0f42FE0000;
(EngineCore_DP0 pid=372505) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=372505) 	div.full.f32 	%r85, %r180, %r84;
(EngineCore_DP0 pid=372505) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=372505) 	max.f32 	%r83, %r85, 0f37810204;
(EngineCore_DP0 pid=372505) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=372505) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=372505) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=372505) 	// begin inline asm
(EngineCore_DP0 pid=372505) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r83 };
(EngineCore_DP0 pid=372505) 	// end inline asm
(EngineCore_DP0 pid=372505) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=372505) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=372505) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=372505) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=372505) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=372505) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=372505) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=372505) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=372505) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=372505) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=372505) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=372505) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=372505) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=372505) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=372505) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=372505) 	div.full.f32 	%r14, %r84, %r180;
(EngineCore_DP0 pid=372505) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=372505) 	mov.b32 	%r181, 0;
(EngineCore_DP0 pid=372505) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=372505)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=372505) 	.loc	1 327 31                        // quant_slide_tuned_Llama3.2-3B.py:327:31
(EngineCore_DP0 pid=372505) 	add.s32 	%r90, %r16, %r181;
(EngineCore_DP0 pid=372505) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=372505) 	add.s32 	%r91, %r90, 1;
(EngineCore_DP0 pid=372505) 	setp.lt.s32 	%p18, %r90, %r15;
(EngineCore_DP0 pid=372505) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=372505) 	mul.hi.s32 	%r92, %r91, 1431655766;
(EngineCore_DP0 pid=372505) 	shr.u32 	%r93, %r92, 31;
(EngineCore_DP0 pid=372505) 	add.s32 	%r94, %r92, %r93;
(EngineCore_DP0 pid=372505) 	mul.hi.s32 	%r95, %r90, 1431655766;
(EngineCore_DP0 pid=372505) 	shr.u32 	%r96, %r95, 31;
(EngineCore_DP0 pid=372505) 	add.s32 	%r97, %r95, %r96;
(EngineCore_DP0 pid=372505) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=372505) 	mul.lo.s32 	%r98, %r97, 3;
(EngineCore_DP0 pid=372505) 	mul.lo.s32 	%r99, %r94, 3;
(EngineCore_DP0 pid=372505) 	sub.s32 	%r100, %r91, %r99;
(EngineCore_DP0 pid=372505) 	sub.s32 	%r101, %r90, %r98;
(EngineCore_DP0 pid=372505) 	.loc	1 333 22                        // quant_slide_tuned_Llama3.2-3B.py:333:22
(EngineCore_DP0 pid=372505) 	shl.b32 	%r102, %r97, 3;
(EngineCore_DP0 pid=372505) 	shl.b32 	%r103, %r94, 3;
(EngineCore_DP0 pid=372505) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=372505) 	shl.b32 	%r104, %r101, 1;
(EngineCore_DP0 pid=372505) 	shl.b32 	%r105, %r100, 1;
(EngineCore_DP0 pid=372505) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=372505) 	add.s32 	%r106, %r103, %r105;
(EngineCore_DP0 pid=372505) 	add.s32 	%r107, %r102, %r104;
(EngineCore_DP0 pid=372505) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=372505) 	setp.lt.s32 	%p19, %r107, %r23;
(EngineCore_DP0 pid=372505) 	setp.lt.s32 	%p20, %r106, %r23;
(EngineCore_DP0 pid=372505) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=372505) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=372505) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=372505) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=372505) 	mad.wide.s32 	%rd9, %r107, 2, %rd1;
(EngineCore_DP0 pid=372505) 	mad.wide.s32 	%rd10, %r106, 2, %rd1;
(EngineCore_DP0 pid=372505) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=372505) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=372505) 	// begin inline asm
(EngineCore_DP0 pid=372505) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=372505) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=372505) 	// end inline asm
(EngineCore_DP0 pid=372505) 	// begin inline asm
(EngineCore_DP0 pid=372505) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=372505) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=372505) 	// end inline asm
(EngineCore_DP0 pid=372505) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=372505) 	cvt.f32.bf16 	%r108, %rs48;
(EngineCore_DP0 pid=372505) 	cvt.f32.bf16 	%r109, %rs50;
(EngineCore_DP0 pid=372505) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=372505) 	or.b32 	%r110, %r107, 1;
(EngineCore_DP0 pid=372505) 	or.b32 	%r111, %r106, 1;
(EngineCore_DP0 pid=372505) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=372505) 	setp.lt.s32 	%p21, %r110, %r23;
(EngineCore_DP0 pid=372505) 	setp.lt.s32 	%p22, %r111, %r23;
(EngineCore_DP0 pid=372505) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=372505) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=372505) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=372505) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=372505) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=372505) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=372505) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=372505) 	// begin inline asm
(EngineCore_DP0 pid=372505) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=372505) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=372505) 	// end inline asm
(EngineCore_DP0 pid=372505) 	// begin inline asm
(EngineCore_DP0 pid=372505) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=372505) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=372505) 	// end inline asm
(EngineCore_DP0 pid=372505) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=372505) 	cvt.f32.bf16 	%r112, %rs52;
(EngineCore_DP0 pid=372505) 	cvt.f32.bf16 	%r113, %rs54;
(EngineCore_DP0 pid=372505) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=372505) 	add.s32 	%r114, %r107, 2;
(EngineCore_DP0 pid=372505) 	add.s32 	%r115, %r106, 2;
(EngineCore_DP0 pid=372505) 	add.s32 	%r116, %r107, 3;
(EngineCore_DP0 pid=372505) 	add.s32 	%r117, %r106, 3;
(EngineCore_DP0 pid=372505) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=372505) 	setp.lt.s32 	%p23, %r117, %r23;
(EngineCore_DP0 pid=372505) 	setp.lt.s32 	%p24, %r116, %r23;
(EngineCore_DP0 pid=372505) 	setp.lt.s32 	%p25, %r115, %r23;
(EngineCore_DP0 pid=372505) 	setp.lt.s32 	%p26, %r114, %r23;
(EngineCore_DP0 pid=372505) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=372505) 	and.pred 	%p14, %p18, %p26;
(EngineCore_DP0 pid=372505) 	and.pred 	%p15, %p18, %p25;
(EngineCore_DP0 pid=372505) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=372505) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=372505) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=372505) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=372505) 	// begin inline asm
(EngineCore_DP0 pid=372505) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=372505) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=372505) 	// end inline asm
(EngineCore_DP0 pid=372505) 	// begin inline asm
(EngineCore_DP0 pid=372505) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=372505) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=372505) 	// end inline asm
(EngineCore_DP0 pid=372505) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=372505) 	cvt.f32.bf16 	%r118, %rs56;
(EngineCore_DP0 pid=372505) 	cvt.f32.bf16 	%r119, %rs58;
(EngineCore_DP0 pid=372505) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=372505) 	and.pred 	%p16, %p18, %p24;
(EngineCore_DP0 pid=372505) 	and.pred 	%p17, %p18, %p23;
(EngineCore_DP0 pid=372505) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=372505) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=372505) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=372505) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=372505) 	// begin inline asm
(EngineCore_DP0 pid=372505) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=372505) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=372505) 	// end inline asm
(EngineCore_DP0 pid=372505) 	// begin inline asm
(EngineCore_DP0 pid=372505) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=372505) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=372505) 	// end inline asm
(EngineCore_DP0 pid=372505) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=372505) 	cvt.f32.bf16 	%r120, %rs60;
(EngineCore_DP0 pid=372505) 	cvt.f32.bf16 	%r121, %rs62;
(EngineCore_DP0 pid=372505) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=372505) 	mul.f32 	%r122, %r14, %r108;
(EngineCore_DP0 pid=372505) 	mul.f32 	%r123, %r14, %r109;
(EngineCore_DP0 pid=372505) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=372505) 	cvt.rni.f32.f32 	%r124, %r122;
(EngineCore_DP0 pid=372505) 	cvt.rni.f32.f32 	%r125, %r123;
(EngineCore_DP0 pid=372505) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=372505) 	max.f32 	%r126, %r124, 0fC3000000;
(EngineCore_DP0 pid=372505) 	min.f32 	%r127, %r126, 0f42FE0000;
(EngineCore_DP0 pid=372505) 	max.f32 	%r128, %r125, 0fC3000000;
(EngineCore_DP0 pid=372505) 	min.f32 	%r129, %r128, 0f42FE0000;
(EngineCore_DP0 pid=372505) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=372505) 	cvt.rzi.s32.f32 	%r130, %r127;
(EngineCore_DP0 pid=372505) 	cvt.rzi.s32.f32 	%r131, %r129;
(EngineCore_DP0 pid=372505) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=372505) 	and.b32 	%r132, %r130, 255;
(EngineCore_DP0 pid=372505) 	and.b32 	%r133, %r131, 255;
(EngineCore_DP0 pid=372505) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=372505) 	mul.f32 	%r134, %r14, %r112;
(EngineCore_DP0 pid=372505) 	mul.f32 	%r135, %r14, %r113;
(EngineCore_DP0 pid=372505) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=372505) 	cvt.rni.f32.f32 	%r136, %r134;
(EngineCore_DP0 pid=372505) 	cvt.rni.f32.f32 	%r137, %r135;
(EngineCore_DP0 pid=372505) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=372505) 	mul.f32 	%r138, %r14, %r118;
(EngineCore_DP0 pid=372505) 	mul.f32 	%r139, %r14, %r119;
(EngineCore_DP0 pid=372505) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=372505) 	cvt.rni.f32.f32 	%r140, %r138;
(EngineCore_DP0 pid=372505) 	cvt.rni.f32.f32 	%r141, %r139;
(EngineCore_DP0 pid=372505) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=372505) 	mul.f32 	%r142, %r14, %r120;
(EngineCore_DP0 pid=372505) 	mul.f32 	%r143, %r14, %r121;
(EngineCore_DP0 pid=372505) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=372505) 	cvt.rni.f32.f32 	%r144, %r142;
(EngineCore_DP0 pid=372505) 	cvt.rni.f32.f32 	%r145, %r143;
(EngineCore_DP0 pid=372505) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=372505) 	max.f32 	%r146, %r144, 0fC3000000;
(EngineCore_DP0 pid=372505) 	min.f32 	%r147, %r146, 0f42FE0000;
(EngineCore_DP0 pid=372505) 	max.f32 	%r148, %r145, 0fC3000000;
(EngineCore_DP0 pid=372505) 	min.f32 	%r149, %r148, 0f42FE0000;
(EngineCore_DP0 pid=372505) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=372505) 	cvt.rzi.s32.f32 	%r150, %r147;
(EngineCore_DP0 pid=372505) 	cvt.rzi.s32.f32 	%r151, %r149;
(EngineCore_DP0 pid=372505) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=372505) 	max.f32 	%r152, %r140, 0fC3000000;
(EngineCore_DP0 pid=372505) 	max.f32 	%r153, %r136, 0fC3000000;
(EngineCore_DP0 pid=372505) 	min.f32 	%r154, %r153, 0f42FE0000;
(EngineCore_DP0 pid=372505) 	min.f32 	%r155, %r152, 0f42FE0000;
(EngineCore_DP0 pid=372505) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=372505) 	cvt.rzi.s32.f32 	%r156, %r155;
(EngineCore_DP0 pid=372505) 	cvt.rzi.s32.f32 	%r157, %r154;
(EngineCore_DP0 pid=372505) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=372505) 	shl.b32 	%r158, %r157, 8;
(EngineCore_DP0 pid=372505) 	shl.b32 	%r159, %r156, 16;
(EngineCore_DP0 pid=372505) 	and.b32 	%r160, %r159, 16711680;
(EngineCore_DP0 pid=372505) 	and.b32 	%r161, %r158, 65280;
(EngineCore_DP0 pid=372505) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=372505) 	or.b32 	%r162, %r161, %r132;
(EngineCore_DP0 pid=372505) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=372505) 	max.f32 	%r163, %r141, 0fC3000000;
(EngineCore_DP0 pid=372505) 	max.f32 	%r164, %r137, 0fC3000000;
(EngineCore_DP0 pid=372505) 	min.f32 	%r165, %r164, 0f42FE0000;
(EngineCore_DP0 pid=372505) 	min.f32 	%r166, %r163, 0f42FE0000;
(EngineCore_DP0 pid=372505) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=372505) 	cvt.rzi.s32.f32 	%r167, %r166;
(EngineCore_DP0 pid=372505) 	cvt.rzi.s32.f32 	%r168, %r165;
(EngineCore_DP0 pid=372505) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=372505) 	shl.b32 	%r169, %r168, 8;
(EngineCore_DP0 pid=372505) 	shl.b32 	%r170, %r167, 16;
(EngineCore_DP0 pid=372505) 	and.b32 	%r171, %r170, 16711680;
(EngineCore_DP0 pid=372505) 	and.b32 	%r172, %r169, 65280;
(EngineCore_DP0 pid=372505) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=372505) 	or.b32 	%r173, %r172, %r133;
(EngineCore_DP0 pid=372505) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=372505) 	or.b32 	%r174, %r162, %r160;
(EngineCore_DP0 pid=372505) 	or.b32 	%r175, %r173, %r171;
(EngineCore_DP0 pid=372505) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=372505) 	shl.b32 	%r176, %r150, 24;
(EngineCore_DP0 pid=372505) 	shl.b32 	%r177, %r151, 24;
(EngineCore_DP0 pid=372505) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=372505) 	or.b32 	%r87, %r174, %r176;
(EngineCore_DP0 pid=372505) 	or.b32 	%r88, %r175, %r177;
(EngineCore_DP0 pid=372505) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=372505) 	mad.wide.s32 	%rd17, %r90, 4, %rd2;
(EngineCore_DP0 pid=372505) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=372505) 	// begin inline asm
(EngineCore_DP0 pid=372505) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r87, %r88 };
(EngineCore_DP0 pid=372505) 	// end inline asm
(EngineCore_DP0 pid=372505) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=372505) 	add.s32 	%r181, %r181, 1024;
(EngineCore_DP0 pid=372505) 	setp.lt.s32 	%p27, %r181, %r15;
(EngineCore_DP0 pid=372505) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=372505) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=372505) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=372505) 	ret;
(EngineCore_DP0 pid=372505) $L__tmp3:
(EngineCore_DP0 pid=372505) $L__func_end0:
(EngineCore_DP0 pid=372505)                                         // -- End function
(EngineCore_DP0 pid=372505) }
(EngineCore_DP0 pid=372505) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=372505) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=372505) 	.section	.debug_abbrev
(EngineCore_DP0 pid=372505) 	{
(EngineCore_DP0 pid=372505) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=372505) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=372505) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=372505) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=372505) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=372505) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=372505) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=372505) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=372505) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=372505) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=372505) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=372505) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=372505) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=372505) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=372505) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=372505) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=372505) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=372505) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=372505) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=372505) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=372505) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=372505) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=372505) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=372505) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=372505) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=372505) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=372505) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=372505) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=372505) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=372505) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=372505) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=372505) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=372505) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=372505) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=372505) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=372505) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=372505) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=372505) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=372505) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=372505) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=372505) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=372505) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=372505) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=372505) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=372505) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=372505) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=372505) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=372505) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=372505) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=372505) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=372505) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=372505) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=372505) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=372505) 	}
(EngineCore_DP0 pid=372505) 	.section	.debug_info
(EngineCore_DP0 pid=372505) 	{
(EngineCore_DP0 pid=372505) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=372505) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=372505) .b8 0
(EngineCore_DP0 pid=372505) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=372505) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=372505) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=372505) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=372505) .b8 114
(EngineCore_DP0 pid=372505) .b8 105
(EngineCore_DP0 pid=372505) .b8 116
(EngineCore_DP0 pid=372505) .b8 111
(EngineCore_DP0 pid=372505) .b8 110
(EngineCore_DP0 pid=372505) .b8 0
(EngineCore_DP0 pid=372505) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=372505) .b8 0
(EngineCore_DP0 pid=372505) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=372505) .b8 117
(EngineCore_DP0 pid=372505) .b8 97
(EngineCore_DP0 pid=372505) .b8 110
(EngineCore_DP0 pid=372505) .b8 116
(EngineCore_DP0 pid=372505) .b8 95
(EngineCore_DP0 pid=372505) .b8 115
(EngineCore_DP0 pid=372505) .b8 108
(EngineCore_DP0 pid=372505) .b8 105
(EngineCore_DP0 pid=372505) .b8 100
(EngineCore_DP0 pid=372505) .b8 101
(EngineCore_DP0 pid=372505) .b8 95
(EngineCore_DP0 pid=372505) .b8 116
(EngineCore_DP0 pid=372505) .b8 117
(EngineCore_DP0 pid=372505) .b8 110
(EngineCore_DP0 pid=372505) .b8 101
(EngineCore_DP0 pid=372505) .b8 100
(EngineCore_DP0 pid=372505) .b8 95
(EngineCore_DP0 pid=372505) .b8 76
(EngineCore_DP0 pid=372505) .b8 108
(EngineCore_DP0 pid=372505) .b8 97
(EngineCore_DP0 pid=372505) .b8 109
(EngineCore_DP0 pid=372505) .b8 97
(EngineCore_DP0 pid=372505) .b8 51
(EngineCore_DP0 pid=372505) .b8 46
(EngineCore_DP0 pid=372505) .b8 50
(EngineCore_DP0 pid=372505) .b8 45
(EngineCore_DP0 pid=372505) .b8 51
(EngineCore_DP0 pid=372505) .b8 66
(EngineCore_DP0 pid=372505) .b8 46
(EngineCore_DP0 pid=372505) .b8 112
(EngineCore_DP0 pid=372505) .b8 121
(EngineCore_DP0 pid=372505) .b8 0
(EngineCore_DP0 pid=372505) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=372505) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=372505) .b8 114
(EngineCore_DP0 pid=372505) .b8 111
(EngineCore_DP0 pid=372505) .b8 111
(EngineCore_DP0 pid=372505) .b8 116
(EngineCore_DP0 pid=372505) .b8 47
(EngineCore_DP0 pid=372505) .b8 118
(EngineCore_DP0 pid=372505) .b8 108
(EngineCore_DP0 pid=372505) .b8 108
(EngineCore_DP0 pid=372505) .b8 109
(EngineCore_DP0 pid=372505) .b8 98
(EngineCore_DP0 pid=372505) .b8 101
(EngineCore_DP0 pid=372505) .b8 110
(EngineCore_DP0 pid=372505) .b8 99
(EngineCore_DP0 pid=372505) .b8 104
(EngineCore_DP0 pid=372505) .b8 47
(EngineCore_DP0 pid=372505) .b8 115
(EngineCore_DP0 pid=372505) .b8 108
(EngineCore_DP0 pid=372505) .b8 105
(EngineCore_DP0 pid=372505) .b8 100
(EngineCore_DP0 pid=372505) .b8 101
(EngineCore_DP0 pid=372505) .b8 115
(EngineCore_DP0 pid=372505) .b8 112
(EngineCore_DP0 pid=372505) .b8 97
(EngineCore_DP0 pid=372505) .b8 114
(EngineCore_DP0 pid=372505) .b8 115
(EngineCore_DP0 pid=372505) .b8 101
(EngineCore_DP0 pid=372505) .b8 47
(EngineCore_DP0 pid=372505) .b8 99
(EngineCore_DP0 pid=372505) .b8 115
(EngineCore_DP0 pid=372505) .b8 114
(EngineCore_DP0 pid=372505) .b8 99
(EngineCore_DP0 pid=372505) .b8 47
(EngineCore_DP0 pid=372505) .b8 102
(EngineCore_DP0 pid=372505) .b8 117
(EngineCore_DP0 pid=372505) .b8 115
(EngineCore_DP0 pid=372505) .b8 101
(EngineCore_DP0 pid=372505) .b8 100
(EngineCore_DP0 pid=372505) .b8 95
(EngineCore_DP0 pid=372505) .b8 113
(EngineCore_DP0 pid=372505) .b8 117
(EngineCore_DP0 pid=372505) .b8 97
(EngineCore_DP0 pid=372505) .b8 110
(EngineCore_DP0 pid=372505) .b8 116
(EngineCore_DP0 pid=372505) .b8 95
(EngineCore_DP0 pid=372505) .b8 115
(EngineCore_DP0 pid=372505) .b8 108
(EngineCore_DP0 pid=372505) .b8 105
(EngineCore_DP0 pid=372505) .b8 100
(EngineCore_DP0 pid=372505) .b8 101
(EngineCore_DP0 pid=372505) .b8 95
(EngineCore_DP0 pid=372505) .b8 116
(EngineCore_DP0 pid=372505) .b8 114
(EngineCore_DP0 pid=372505) .b8 105
(EngineCore_DP0 pid=372505) .b8 116
(EngineCore_DP0 pid=372505) .b8 111
(EngineCore_DP0 pid=372505) .b8 110
(EngineCore_DP0 pid=372505) .b8 47
(EngineCore_DP0 pid=372505) .b8 98
(EngineCore_DP0 pid=372505) .b8 117
(EngineCore_DP0 pid=372505) .b8 105
(EngineCore_DP0 pid=372505) .b8 108
(EngineCore_DP0 pid=372505) .b8 100
(EngineCore_DP0 pid=372505) .b8 47
(EngineCore_DP0 pid=372505) .b8 71
(EngineCore_DP0 pid=372505) .b8 66
(EngineCore_DP0 pid=372505) .b8 49
(EngineCore_DP0 pid=372505) .b8 48
(EngineCore_DP0 pid=372505) .b8 95
(EngineCore_DP0 pid=372505) .b8 99
(EngineCore_DP0 pid=372505) .b8 99
(EngineCore_DP0 pid=372505) .b8 49
(EngineCore_DP0 pid=372505) .b8 50
(EngineCore_DP0 pid=372505) .b8 49
(EngineCore_DP0 pid=372505) .b8 95
(EngineCore_DP0 pid=372505) .b8 112
(EngineCore_DP0 pid=372505) .b8 121
(EngineCore_DP0 pid=372505) .b8 51
(EngineCore_DP0 pid=372505) .b8 49
(EngineCore_DP0 pid=372505) .b8 50
(EngineCore_DP0 pid=372505) .b8 95
(EngineCore_DP0 pid=372505) .b8 99
(EngineCore_DP0 pid=372505) .b8 117
(EngineCore_DP0 pid=372505) .b8 49
(EngineCore_DP0 pid=372505) .b8 50
(EngineCore_DP0 pid=372505) .b8 57
(EngineCore_DP0 pid=372505) .b8 95
(EngineCore_DP0 pid=372505) .b8 97
(EngineCore_DP0 pid=372505) .b8 97
(EngineCore_DP0 pid=372505) .b8 114
(EngineCore_DP0 pid=372505) .b8 99
(EngineCore_DP0 pid=372505) .b8 104
(EngineCore_DP0 pid=372505) .b8 54
(EngineCore_DP0 pid=372505) .b8 52
(EngineCore_DP0 pid=372505) .b8 0
(EngineCore_DP0 pid=372505) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=372505) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=372505) .b8 113
(EngineCore_DP0 pid=372505) .b8 117
(EngineCore_DP0 pid=372505) .b8 97
(EngineCore_DP0 pid=372505) .b8 110
(EngineCore_DP0 pid=372505) .b8 116
(EngineCore_DP0 pid=372505) .b8 95
(EngineCore_DP0 pid=372505) .b8 115
(EngineCore_DP0 pid=372505) .b8 108
(EngineCore_DP0 pid=372505) .b8 105
(EngineCore_DP0 pid=372505) .b8 100
(EngineCore_DP0 pid=372505) .b8 101
(EngineCore_DP0 pid=372505) .b8 95
(EngineCore_DP0 pid=372505) .b8 105
(EngineCore_DP0 pid=372505) .b8 110
(EngineCore_DP0 pid=372505) .b8 116
(EngineCore_DP0 pid=372505) .b8 56
(EngineCore_DP0 pid=372505) .b8 95
(EngineCore_DP0 pid=372505) .b8 107
(EngineCore_DP0 pid=372505) .b8 101
(EngineCore_DP0 pid=372505) .b8 114
(EngineCore_DP0 pid=372505) .b8 110
(EngineCore_DP0 pid=372505) .b8 101
(EngineCore_DP0 pid=372505) .b8 108
(EngineCore_DP0 pid=372505) .b8 0
(EngineCore_DP0 pid=372505) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=372505) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=372505) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=372505) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=372505) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=372505) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=372505) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=372505) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=372505) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=372505) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=372505) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=372505) .b8 1
(EngineCore_DP0 pid=372505) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=372505) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=372505) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=372505) 	}
(EngineCore_DP0 pid=372505) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=372505) 
(EngineCore_DP0 pid=372505) ================================================================
(EngineCore_DP0 pid=372505) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=372505) 
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpl47s_yxc.ptx', '-o', '/tmp/tmpl47s_yxc.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866] 
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866] 
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866] 
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpl47s_yxc.ptx -o /tmp/tmpl47s_yxc.ptx.o
(EngineCore_DP0 pid=372505) ERROR 01-25 19:47:12 [core.py:866] 

STDERR:
[2026-01-25 19:46:38] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:46:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:46:38] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:46:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:46:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:46:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:46:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:46:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:46:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:46:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:46:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:46:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:46:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:46:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:46:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:46:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:46:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:46:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:46:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:46:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:46:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:46:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:46:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:46:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:46:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:46:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:46:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:46:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=372505) [2026-01-25 19:46:42] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=372505) [2026-01-25 19:46:42] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=372505) [2026-01-25 19:46:42] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=372505) [2026-01-25 19:46:42] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=372505) [2026-01-25 19:46:42] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=372505) [2026-01-25 19:46:42] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=372505) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=372505) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.64s/it]
(EngineCore_DP0 pid=372505) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.64s/it]
(EngineCore_DP0 pid=372505) 
(EngineCore_DP0 pid=372505) [2026-01-25 19:47:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=372505) [2026-01-25 19:47:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=372505) [2026-01-25 19:47:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=372505) [2026-01-25 19:47:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10616832 bytes
(EngineCore_DP0 pid=372505) [2026-01-25 19:47:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=372505) [2026-01-25 19:47:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56623104 bytes
(EngineCore_DP0 pid=372505) [2026-01-25 19:47:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=372505) [2026-01-25 19:47:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28311552 bytes
(EngineCore_DP0 pid=372505) Process EngineCore_DP0:
(EngineCore_DP0 pid=372505) Traceback (most recent call last):
(EngineCore_DP0 pid=372505)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=372505)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=372505)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=372505)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=372505) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpl47s_yxc.ptx', '-o', '/tmp/tmpl47s_yxc.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=372505) 
(EngineCore_DP0 pid=372505) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=372505) 
(EngineCore_DP0 pid=372505) Traceback (most recent call last):
(EngineCore_DP0 pid=372505)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=372505)     self.run()
(EngineCore_DP0 pid=372505)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=372505)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=372505)     raise e
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=372505)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=372505)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=372505)     super().__init__(
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=372505)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=372505)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=372505)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=372505)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=372505)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=372505)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=372505)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=372505)     return func(*args, **kwargs)
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=372505)     return func(*args, **kwargs)
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=372505)     self.model_runner.profile_run()
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=372505)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=372505)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=372505)     return func(*args, **kwargs)
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=372505)     outputs = self.model(
(EngineCore_DP0 pid=372505)               ^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=372505)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=372505)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=372505)     model_output = self.model(
(EngineCore_DP0 pid=372505)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=372505)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=372505)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=372505)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=372505)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=372505)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=372505)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=372505)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=372505)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=372505)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=372505)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=372505)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=372505)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=372505)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=372505)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=372505)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=372505)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=372505)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=372505)     return self._linear_fn(
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=372505)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=372505)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=372505)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=372505)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=372505)     return fn(input, L)
(EngineCore_DP0 pid=372505)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=372505)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=372505)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=372505)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=372505)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=372505)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=372505)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=372505)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=372505)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=372505)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=372505)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=372505)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=372505)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372505)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=372505)     raise PTXASError(error)
(EngineCore_DP0 pid=372505) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=372505) `ptxas` stderr:
(EngineCore_DP0 pid=372505) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=372505) 
(EngineCore_DP0 pid=372505) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpl47s_yxc.ptx -o /tmp/tmpl47s_yxc.ptx.o
(EngineCore_DP0 pid=372505) 
[rank0]:[W125 19:47:13.353031134 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 19:47:14
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:47:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:47:29 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=373396) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=373396) 
(EngineCore_DP0 pid=373396) 
(EngineCore_DP0 pid=373396) ================================================================
(EngineCore_DP0 pid=373396) Internal Triton PTX codegen error
(EngineCore_DP0 pid=373396) `ptxas` stderr:
(EngineCore_DP0 pid=373396) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=373396) 
(EngineCore_DP0 pid=373396) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpblw0d9ci.ptx -o /tmp/tmpblw0d9ci.ptx.o
(EngineCore_DP0 pid=373396) 
(EngineCore_DP0 pid=373396) 
(EngineCore_DP0 pid=373396) //
(EngineCore_DP0 pid=373396) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=373396) //
(EngineCore_DP0 pid=373396) 
(EngineCore_DP0 pid=373396) .version 8.7
(EngineCore_DP0 pid=373396) .target sm_121a
(EngineCore_DP0 pid=373396) .address_size 64
(EngineCore_DP0 pid=373396) 
(EngineCore_DP0 pid=373396) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=373396) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=373396)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=373396) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=373396) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=373396) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=373396) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=373396) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=373396) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=373396) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=373396) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=373396) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=373396) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=373396) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=373396) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=373396) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=373396) )
(EngineCore_DP0 pid=373396) .reqntid 512
(EngineCore_DP0 pid=373396) {
(EngineCore_DP0 pid=373396) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=373396) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=373396) 	.reg .b32 	%r<267>;
(EngineCore_DP0 pid=373396) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=373396) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=373396) $L__func_begin0:
(EngineCore_DP0 pid=373396) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=373396) 
(EngineCore_DP0 pid=373396) // %bb.0:
(EngineCore_DP0 pid=373396) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=373396) 	ld.param.b32 	%r28, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=373396) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=373396) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=373396) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=373396) $L__tmp0:
(EngineCore_DP0 pid=373396) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=373396) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=373396) 	ld.param.b32 	%r31, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=373396) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=373396) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=373396) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=373396) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=373396) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=373396) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=373396) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=373396) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=373396) 	mov.b32 	%r265, 0f2B8CBCCC;
(EngineCore_DP0 pid=373396) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=373396) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=373396) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=373396) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=373396) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=373396) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=373396) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=373396) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=373396) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=373396) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=373396) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=373396) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=373396) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=373396) 	mov.b32 	%r263, 0f00000000;
(EngineCore_DP0 pid=373396) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=373396) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=373396) 	mov.b32 	%r264, %r49;
(EngineCore_DP0 pid=373396) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=373396) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=373396) 	add.s32 	%r59, %r4, %r264;
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=373396) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=373396) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=373396) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=373396) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=373396) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=373396) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=373396) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=373396) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=373396) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=373396) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=373396) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=373396) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=373396) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=373396) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=373396) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=373396) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=373396) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=373396) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=373396) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=373396) $L__tmp1:
(EngineCore_DP0 pid=373396) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	bar.sync 	0;
(EngineCore_DP0 pid=373396) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=373396) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=373396) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=373396) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=373396) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=373396) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=373396) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=373396) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=373396) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=373396) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=373396) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=373396) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=373396) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=373396) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=373396) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=373396) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=373396) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=373396) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=373396) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	bar.sync 	0;
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=373396) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=373396) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=373396) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=373396) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=373396) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=373396) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=373396) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=373396) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	bar.sync 	0;
(EngineCore_DP0 pid=373396) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=373396) $L__tmp2:
(EngineCore_DP0 pid=373396) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=373396) 	max.f32 	%r263, %r263, %r77;
(EngineCore_DP0 pid=373396) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=373396) 	add.s32 	%r264, %r264, 4096;
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p6, %r264, %r28;
(EngineCore_DP0 pid=373396) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=373396) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=373396) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=373396) 	max.f32 	%r265, %r263, 0f2B8CBCCC;
(EngineCore_DP0 pid=373396) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=373396) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=373396) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=373396) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=373396) 	div.full.f32 	%r80, %r265, %r79;
(EngineCore_DP0 pid=373396) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=373396) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=373396) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=373396) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=373396) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=373396) 	mul.lo.s32 	%r15, %r29, 3;
(EngineCore_DP0 pid=373396) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=373396) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=373396) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=373396) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=373396) 	ld.param.b32 	%r33, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=373396) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=373396) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=373396) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=373396) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=373396) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=373396) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=373396) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=373396) 	div.full.f32 	%r14, %r79, %r265;
(EngineCore_DP0 pid=373396) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=373396) 	mov.b32 	%r266, 0;
(EngineCore_DP0 pid=373396) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=373396)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=373396) 	.loc	1 327 31                        // quant_slide_tuned_Llama3.2-3B.py:327:31
(EngineCore_DP0 pid=373396) 	add.s32 	%r87, %r16, %r266;
(EngineCore_DP0 pid=373396) 	add.s32 	%r88, %r87, 1;
(EngineCore_DP0 pid=373396) 	add.s32 	%r89, %r87, 2;
(EngineCore_DP0 pid=373396) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=373396) 	add.s32 	%r90, %r87, 3;
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p25, %r87, %r15;
(EngineCore_DP0 pid=373396) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=373396) 	mul.hi.s32 	%r91, %r90, 1431655766;
(EngineCore_DP0 pid=373396) 	shr.u32 	%r92, %r91, 31;
(EngineCore_DP0 pid=373396) 	add.s32 	%r93, %r91, %r92;
(EngineCore_DP0 pid=373396) 	mul.hi.s32 	%r94, %r89, 1431655766;
(EngineCore_DP0 pid=373396) 	shr.u32 	%r95, %r94, 31;
(EngineCore_DP0 pid=373396) 	add.s32 	%r96, %r94, %r95;
(EngineCore_DP0 pid=373396) 	mul.hi.s32 	%r97, %r88, 1431655766;
(EngineCore_DP0 pid=373396) 	shr.u32 	%r98, %r97, 31;
(EngineCore_DP0 pid=373396) 	add.s32 	%r99, %r97, %r98;
(EngineCore_DP0 pid=373396) 	mul.hi.s32 	%r100, %r87, 1431655766;
(EngineCore_DP0 pid=373396) 	shr.u32 	%r101, %r100, 31;
(EngineCore_DP0 pid=373396) 	add.s32 	%r102, %r100, %r101;
(EngineCore_DP0 pid=373396) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=373396) 	mul.lo.s32 	%r103, %r102, 3;
(EngineCore_DP0 pid=373396) 	mul.lo.s32 	%r104, %r99, 3;
(EngineCore_DP0 pid=373396) 	mul.lo.s32 	%r105, %r96, 3;
(EngineCore_DP0 pid=373396) 	mul.lo.s32 	%r106, %r93, 3;
(EngineCore_DP0 pid=373396) 	sub.s32 	%r107, %r90, %r106;
(EngineCore_DP0 pid=373396) 	sub.s32 	%r108, %r89, %r105;
(EngineCore_DP0 pid=373396) 	sub.s32 	%r109, %r88, %r104;
(EngineCore_DP0 pid=373396) 	sub.s32 	%r110, %r87, %r103;
(EngineCore_DP0 pid=373396) 	.loc	1 333 22                        // quant_slide_tuned_Llama3.2-3B.py:333:22
(EngineCore_DP0 pid=373396) 	shl.b32 	%r111, %r102, 3;
(EngineCore_DP0 pid=373396) 	shl.b32 	%r112, %r99, 3;
(EngineCore_DP0 pid=373396) 	shl.b32 	%r113, %r96, 3;
(EngineCore_DP0 pid=373396) 	shl.b32 	%r114, %r93, 3;
(EngineCore_DP0 pid=373396) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=373396) 	shl.b32 	%r115, %r110, 1;
(EngineCore_DP0 pid=373396) 	shl.b32 	%r116, %r109, 1;
(EngineCore_DP0 pid=373396) 	shl.b32 	%r117, %r108, 1;
(EngineCore_DP0 pid=373396) 	shl.b32 	%r118, %r107, 1;
(EngineCore_DP0 pid=373396) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=373396) 	add.s32 	%r119, %r114, %r118;
(EngineCore_DP0 pid=373396) 	add.s32 	%r120, %r113, %r117;
(EngineCore_DP0 pid=373396) 	add.s32 	%r121, %r112, %r116;
(EngineCore_DP0 pid=373396) 	add.s32 	%r122, %r111, %r115;
(EngineCore_DP0 pid=373396) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p26, %r122, %r27;
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p27, %r121, %r27;
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p28, %r120, %r27;
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p29, %r119, %r27;
(EngineCore_DP0 pid=373396) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=373396) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=373396) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=373396) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=373396) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=373396) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=373396) 	mad.wide.s32 	%rd8, %r122, 2, %rd1;
(EngineCore_DP0 pid=373396) 	mad.wide.s32 	%rd9, %r121, 2, %rd1;
(EngineCore_DP0 pid=373396) 	mad.wide.s32 	%rd10, %r120, 2, %rd1;
(EngineCore_DP0 pid=373396) 	mad.wide.s32 	%rd11, %r119, 2, %rd1;
(EngineCore_DP0 pid=373396) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=373396) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=373396) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=373396) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=373396) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=373396) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=373396) 	cvt.f32.bf16 	%r123, %rs24;
(EngineCore_DP0 pid=373396) 	cvt.f32.bf16 	%r124, %rs26;
(EngineCore_DP0 pid=373396) 	cvt.f32.bf16 	%r125, %rs28;
(EngineCore_DP0 pid=373396) 	cvt.f32.bf16 	%r126, %rs30;
(EngineCore_DP0 pid=373396) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=373396) 	or.b32 	%r127, %r122, 1;
(EngineCore_DP0 pid=373396) 	or.b32 	%r128, %r121, 1;
(EngineCore_DP0 pid=373396) 	or.b32 	%r129, %r120, 1;
(EngineCore_DP0 pid=373396) 	or.b32 	%r130, %r119, 1;
(EngineCore_DP0 pid=373396) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p30, %r127, %r27;
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p31, %r128, %r27;
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p32, %r129, %r27;
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p33, %r130, %r27;
(EngineCore_DP0 pid=373396) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=373396) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=373396) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=373396) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=373396) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=373396) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=373396) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=373396) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=373396) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=373396) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=373396) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=373396) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=373396) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=373396) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=373396) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=373396) 	cvt.f32.bf16 	%r131, %rs32;
(EngineCore_DP0 pid=373396) 	cvt.f32.bf16 	%r132, %rs34;
(EngineCore_DP0 pid=373396) 	cvt.f32.bf16 	%r133, %rs36;
(EngineCore_DP0 pid=373396) 	cvt.f32.bf16 	%r134, %rs38;
(EngineCore_DP0 pid=373396) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=373396) 	add.s32 	%r135, %r122, 2;
(EngineCore_DP0 pid=373396) 	add.s32 	%r136, %r121, 2;
(EngineCore_DP0 pid=373396) 	add.s32 	%r137, %r120, 2;
(EngineCore_DP0 pid=373396) 	add.s32 	%r138, %r119, 2;
(EngineCore_DP0 pid=373396) 	add.s32 	%r139, %r122, 3;
(EngineCore_DP0 pid=373396) 	add.s32 	%r140, %r121, 3;
(EngineCore_DP0 pid=373396) 	add.s32 	%r141, %r120, 3;
(EngineCore_DP0 pid=373396) 	add.s32 	%r142, %r119, 3;
(EngineCore_DP0 pid=373396) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p34, %r142, %r27;
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p35, %r141, %r27;
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p36, %r140, %r27;
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p37, %r139, %r27;
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p38, %r138, %r27;
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p39, %r137, %r27;
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p40, %r136, %r27;
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p41, %r135, %r27;
(EngineCore_DP0 pid=373396) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=373396) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=373396) 	and.pred 	%p18, %p25, %p40;
(EngineCore_DP0 pid=373396) 	and.pred 	%p19, %p25, %p39;
(EngineCore_DP0 pid=373396) 	and.pred 	%p20, %p25, %p38;
(EngineCore_DP0 pid=373396) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=373396) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=373396) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=373396) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=373396) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=373396) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=373396) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=373396) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=373396) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=373396) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=373396) 	cvt.f32.bf16 	%r143, %rs40;
(EngineCore_DP0 pid=373396) 	cvt.f32.bf16 	%r144, %rs42;
(EngineCore_DP0 pid=373396) 	cvt.f32.bf16 	%r145, %rs44;
(EngineCore_DP0 pid=373396) 	cvt.f32.bf16 	%r146, %rs46;
(EngineCore_DP0 pid=373396) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=373396) 	and.pred 	%p21, %p25, %p37;
(EngineCore_DP0 pid=373396) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=373396) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=373396) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=373396) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=373396) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=373396) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=373396) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=373396) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=373396) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=373396) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=373396) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=373396) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=373396) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=373396) 	cvt.f32.bf16 	%r147, %rs48;
(EngineCore_DP0 pid=373396) 	cvt.f32.bf16 	%r148, %rs50;
(EngineCore_DP0 pid=373396) 	cvt.f32.bf16 	%r149, %rs52;
(EngineCore_DP0 pid=373396) 	cvt.f32.bf16 	%r150, %rs54;
(EngineCore_DP0 pid=373396) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=373396) 	mul.f32 	%r151, %r14, %r123;
(EngineCore_DP0 pid=373396) 	mul.f32 	%r152, %r14, %r124;
(EngineCore_DP0 pid=373396) 	mul.f32 	%r153, %r14, %r125;
(EngineCore_DP0 pid=373396) 	mul.f32 	%r154, %r14, %r126;
(EngineCore_DP0 pid=373396) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=373396) 	cvt.rni.f32.f32 	%r155, %r151;
(EngineCore_DP0 pid=373396) 	cvt.rni.f32.f32 	%r156, %r152;
(EngineCore_DP0 pid=373396) 	cvt.rni.f32.f32 	%r157, %r153;
(EngineCore_DP0 pid=373396) 	cvt.rni.f32.f32 	%r158, %r154;
(EngineCore_DP0 pid=373396) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=373396) 	max.f32 	%r159, %r155, 0fC3000000;
(EngineCore_DP0 pid=373396) 	min.f32 	%r160, %r159, 0f42FE0000;
(EngineCore_DP0 pid=373396) 	max.f32 	%r161, %r156, 0fC3000000;
(EngineCore_DP0 pid=373396) 	min.f32 	%r162, %r161, 0f42FE0000;
(EngineCore_DP0 pid=373396) 	max.f32 	%r163, %r157, 0fC3000000;
(EngineCore_DP0 pid=373396) 	min.f32 	%r164, %r163, 0f42FE0000;
(EngineCore_DP0 pid=373396) 	max.f32 	%r165, %r158, 0fC3000000;
(EngineCore_DP0 pid=373396) 	min.f32 	%r166, %r165, 0f42FE0000;
(EngineCore_DP0 pid=373396) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=373396) 	cvt.rzi.s32.f32 	%r167, %r160;
(EngineCore_DP0 pid=373396) 	cvt.rzi.s32.f32 	%r168, %r162;
(EngineCore_DP0 pid=373396) 	cvt.rzi.s32.f32 	%r169, %r164;
(EngineCore_DP0 pid=373396) 	cvt.rzi.s32.f32 	%r170, %r166;
(EngineCore_DP0 pid=373396) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=373396) 	and.b32 	%r171, %r167, 255;
(EngineCore_DP0 pid=373396) 	and.b32 	%r172, %r168, 255;
(EngineCore_DP0 pid=373396) 	and.b32 	%r173, %r169, 255;
(EngineCore_DP0 pid=373396) 	and.b32 	%r174, %r170, 255;
(EngineCore_DP0 pid=373396) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=373396) 	mul.f32 	%r175, %r14, %r131;
(EngineCore_DP0 pid=373396) 	mul.f32 	%r176, %r14, %r132;
(EngineCore_DP0 pid=373396) 	mul.f32 	%r177, %r14, %r133;
(EngineCore_DP0 pid=373396) 	mul.f32 	%r178, %r14, %r134;
(EngineCore_DP0 pid=373396) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=373396) 	cvt.rni.f32.f32 	%r179, %r175;
(EngineCore_DP0 pid=373396) 	cvt.rni.f32.f32 	%r180, %r176;
(EngineCore_DP0 pid=373396) 	cvt.rni.f32.f32 	%r181, %r177;
(EngineCore_DP0 pid=373396) 	cvt.rni.f32.f32 	%r182, %r178;
(EngineCore_DP0 pid=373396) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=373396) 	mul.f32 	%r183, %r14, %r143;
(EngineCore_DP0 pid=373396) 	mul.f32 	%r184, %r14, %r144;
(EngineCore_DP0 pid=373396) 	mul.f32 	%r185, %r14, %r145;
(EngineCore_DP0 pid=373396) 	mul.f32 	%r186, %r14, %r146;
(EngineCore_DP0 pid=373396) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=373396) 	cvt.rni.f32.f32 	%r187, %r183;
(EngineCore_DP0 pid=373396) 	cvt.rni.f32.f32 	%r188, %r184;
(EngineCore_DP0 pid=373396) 	cvt.rni.f32.f32 	%r189, %r185;
(EngineCore_DP0 pid=373396) 	cvt.rni.f32.f32 	%r190, %r186;
(EngineCore_DP0 pid=373396) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=373396) 	mul.f32 	%r191, %r14, %r147;
(EngineCore_DP0 pid=373396) 	mul.f32 	%r192, %r14, %r148;
(EngineCore_DP0 pid=373396) 	mul.f32 	%r193, %r14, %r149;
(EngineCore_DP0 pid=373396) 	mul.f32 	%r194, %r14, %r150;
(EngineCore_DP0 pid=373396) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=373396) 	cvt.rni.f32.f32 	%r195, %r191;
(EngineCore_DP0 pid=373396) 	cvt.rni.f32.f32 	%r196, %r192;
(EngineCore_DP0 pid=373396) 	cvt.rni.f32.f32 	%r197, %r193;
(EngineCore_DP0 pid=373396) 	cvt.rni.f32.f32 	%r198, %r194;
(EngineCore_DP0 pid=373396) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=373396) 	max.f32 	%r199, %r195, 0fC3000000;
(EngineCore_DP0 pid=373396) 	min.f32 	%r200, %r199, 0f42FE0000;
(EngineCore_DP0 pid=373396) 	max.f32 	%r201, %r196, 0fC3000000;
(EngineCore_DP0 pid=373396) 	min.f32 	%r202, %r201, 0f42FE0000;
(EngineCore_DP0 pid=373396) 	max.f32 	%r203, %r197, 0fC3000000;
(EngineCore_DP0 pid=373396) 	min.f32 	%r204, %r203, 0f42FE0000;
(EngineCore_DP0 pid=373396) 	max.f32 	%r205, %r198, 0fC3000000;
(EngineCore_DP0 pid=373396) 	min.f32 	%r206, %r205, 0f42FE0000;
(EngineCore_DP0 pid=373396) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=373396) 	cvt.rzi.s32.f32 	%r207, %r200;
(EngineCore_DP0 pid=373396) 	cvt.rzi.s32.f32 	%r208, %r202;
(EngineCore_DP0 pid=373396) 	cvt.rzi.s32.f32 	%r209, %r204;
(EngineCore_DP0 pid=373396) 	cvt.rzi.s32.f32 	%r210, %r206;
(EngineCore_DP0 pid=373396) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=373396) 	max.f32 	%r211, %r187, 0fC3000000;
(EngineCore_DP0 pid=373396) 	max.f32 	%r212, %r179, 0fC3000000;
(EngineCore_DP0 pid=373396) 	min.f32 	%r213, %r212, 0f42FE0000;
(EngineCore_DP0 pid=373396) 	min.f32 	%r214, %r211, 0f42FE0000;
(EngineCore_DP0 pid=373396) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=373396) 	cvt.rzi.s32.f32 	%r215, %r214;
(EngineCore_DP0 pid=373396) 	cvt.rzi.s32.f32 	%r216, %r213;
(EngineCore_DP0 pid=373396) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=373396) 	shl.b32 	%r217, %r216, 8;
(EngineCore_DP0 pid=373396) 	shl.b32 	%r218, %r215, 16;
(EngineCore_DP0 pid=373396) 	and.b32 	%r219, %r218, 16711680;
(EngineCore_DP0 pid=373396) 	and.b32 	%r220, %r217, 65280;
(EngineCore_DP0 pid=373396) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=373396) 	or.b32 	%r221, %r220, %r171;
(EngineCore_DP0 pid=373396) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=373396) 	max.f32 	%r222, %r188, 0fC3000000;
(EngineCore_DP0 pid=373396) 	max.f32 	%r223, %r180, 0fC3000000;
(EngineCore_DP0 pid=373396) 	min.f32 	%r224, %r223, 0f42FE0000;
(EngineCore_DP0 pid=373396) 	min.f32 	%r225, %r222, 0f42FE0000;
(EngineCore_DP0 pid=373396) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=373396) 	cvt.rzi.s32.f32 	%r226, %r225;
(EngineCore_DP0 pid=373396) 	cvt.rzi.s32.f32 	%r227, %r224;
(EngineCore_DP0 pid=373396) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=373396) 	shl.b32 	%r228, %r227, 8;
(EngineCore_DP0 pid=373396) 	shl.b32 	%r229, %r226, 16;
(EngineCore_DP0 pid=373396) 	and.b32 	%r230, %r229, 16711680;
(EngineCore_DP0 pid=373396) 	and.b32 	%r231, %r228, 65280;
(EngineCore_DP0 pid=373396) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=373396) 	or.b32 	%r232, %r231, %r172;
(EngineCore_DP0 pid=373396) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=373396) 	max.f32 	%r233, %r189, 0fC3000000;
(EngineCore_DP0 pid=373396) 	max.f32 	%r234, %r181, 0fC3000000;
(EngineCore_DP0 pid=373396) 	min.f32 	%r235, %r234, 0f42FE0000;
(EngineCore_DP0 pid=373396) 	min.f32 	%r236, %r233, 0f42FE0000;
(EngineCore_DP0 pid=373396) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=373396) 	cvt.rzi.s32.f32 	%r237, %r236;
(EngineCore_DP0 pid=373396) 	cvt.rzi.s32.f32 	%r238, %r235;
(EngineCore_DP0 pid=373396) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=373396) 	shl.b32 	%r239, %r238, 8;
(EngineCore_DP0 pid=373396) 	shl.b32 	%r240, %r237, 16;
(EngineCore_DP0 pid=373396) 	and.b32 	%r241, %r240, 16711680;
(EngineCore_DP0 pid=373396) 	and.b32 	%r242, %r239, 65280;
(EngineCore_DP0 pid=373396) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=373396) 	or.b32 	%r243, %r242, %r173;
(EngineCore_DP0 pid=373396) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=373396) 	max.f32 	%r244, %r190, 0fC3000000;
(EngineCore_DP0 pid=373396) 	max.f32 	%r245, %r182, 0fC3000000;
(EngineCore_DP0 pid=373396) 	min.f32 	%r246, %r245, 0f42FE0000;
(EngineCore_DP0 pid=373396) 	min.f32 	%r247, %r244, 0f42FE0000;
(EngineCore_DP0 pid=373396) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=373396) 	cvt.rzi.s32.f32 	%r248, %r247;
(EngineCore_DP0 pid=373396) 	cvt.rzi.s32.f32 	%r249, %r246;
(EngineCore_DP0 pid=373396) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=373396) 	shl.b32 	%r250, %r249, 8;
(EngineCore_DP0 pid=373396) 	shl.b32 	%r251, %r248, 16;
(EngineCore_DP0 pid=373396) 	and.b32 	%r252, %r251, 16711680;
(EngineCore_DP0 pid=373396) 	and.b32 	%r253, %r250, 65280;
(EngineCore_DP0 pid=373396) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=373396) 	or.b32 	%r254, %r253, %r174;
(EngineCore_DP0 pid=373396) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=373396) 	or.b32 	%r255, %r221, %r219;
(EngineCore_DP0 pid=373396) 	or.b32 	%r256, %r232, %r230;
(EngineCore_DP0 pid=373396) 	or.b32 	%r257, %r243, %r241;
(EngineCore_DP0 pid=373396) 	or.b32 	%r258, %r254, %r252;
(EngineCore_DP0 pid=373396) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=373396) 	shl.b32 	%r259, %r207, 24;
(EngineCore_DP0 pid=373396) 	shl.b32 	%r260, %r208, 24;
(EngineCore_DP0 pid=373396) 	shl.b32 	%r261, %r209, 24;
(EngineCore_DP0 pid=373396) 	shl.b32 	%r262, %r210, 24;
(EngineCore_DP0 pid=373396) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=373396) 	or.b32 	%r82, %r255, %r259;
(EngineCore_DP0 pid=373396) 	or.b32 	%r83, %r256, %r260;
(EngineCore_DP0 pid=373396) 	or.b32 	%r84, %r257, %r261;
(EngineCore_DP0 pid=373396) 	or.b32 	%r85, %r258, %r262;
(EngineCore_DP0 pid=373396) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=373396) 	mad.wide.s32 	%rd24, %r87, 4, %rd2;
(EngineCore_DP0 pid=373396) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=373396) 	// begin inline asm
(EngineCore_DP0 pid=373396) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r82, %r83, %r84, %r85 };
(EngineCore_DP0 pid=373396) 	// end inline asm
(EngineCore_DP0 pid=373396) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=373396) 	add.s32 	%r266, %r266, 2048;
(EngineCore_DP0 pid=373396) 	setp.lt.s32 	%p42, %r266, %r15;
(EngineCore_DP0 pid=373396) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=373396) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=373396) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=373396) 	ret;
(EngineCore_DP0 pid=373396) $L__tmp3:
(EngineCore_DP0 pid=373396) $L__func_end0:
(EngineCore_DP0 pid=373396)                                         // -- End function
(EngineCore_DP0 pid=373396) }
(EngineCore_DP0 pid=373396) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=373396) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=373396) 	.section	.debug_abbrev
(EngineCore_DP0 pid=373396) 	{
(EngineCore_DP0 pid=373396) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=373396) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=373396) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=373396) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=373396) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=373396) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=373396) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=373396) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=373396) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=373396) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=373396) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=373396) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=373396) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=373396) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=373396) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=373396) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=373396) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=373396) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=373396) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=373396) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=373396) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=373396) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=373396) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=373396) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=373396) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=373396) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=373396) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=373396) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=373396) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=373396) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=373396) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=373396) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=373396) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=373396) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=373396) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=373396) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=373396) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=373396) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=373396) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=373396) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=373396) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=373396) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=373396) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=373396) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=373396) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=373396) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=373396) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=373396) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=373396) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=373396) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=373396) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=373396) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=373396) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=373396) 	}
(EngineCore_DP0 pid=373396) 	.section	.debug_info
(EngineCore_DP0 pid=373396) 	{
(EngineCore_DP0 pid=373396) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=373396) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=373396) .b8 0
(EngineCore_DP0 pid=373396) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=373396) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=373396) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=373396) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=373396) .b8 114
(EngineCore_DP0 pid=373396) .b8 105
(EngineCore_DP0 pid=373396) .b8 116
(EngineCore_DP0 pid=373396) .b8 111
(EngineCore_DP0 pid=373396) .b8 110
(EngineCore_DP0 pid=373396) .b8 0
(EngineCore_DP0 pid=373396) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=373396) .b8 0
(EngineCore_DP0 pid=373396) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=373396) .b8 117
(EngineCore_DP0 pid=373396) .b8 97
(EngineCore_DP0 pid=373396) .b8 110
(EngineCore_DP0 pid=373396) .b8 116
(EngineCore_DP0 pid=373396) .b8 95
(EngineCore_DP0 pid=373396) .b8 115
(EngineCore_DP0 pid=373396) .b8 108
(EngineCore_DP0 pid=373396) .b8 105
(EngineCore_DP0 pid=373396) .b8 100
(EngineCore_DP0 pid=373396) .b8 101
(EngineCore_DP0 pid=373396) .b8 95
(EngineCore_DP0 pid=373396) .b8 116
(EngineCore_DP0 pid=373396) .b8 117
(EngineCore_DP0 pid=373396) .b8 110
(EngineCore_DP0 pid=373396) .b8 101
(EngineCore_DP0 pid=373396) .b8 100
(EngineCore_DP0 pid=373396) .b8 95
(EngineCore_DP0 pid=373396) .b8 76
(EngineCore_DP0 pid=373396) .b8 108
(EngineCore_DP0 pid=373396) .b8 97
(EngineCore_DP0 pid=373396) .b8 109
(EngineCore_DP0 pid=373396) .b8 97
(EngineCore_DP0 pid=373396) .b8 51
(EngineCore_DP0 pid=373396) .b8 46
(EngineCore_DP0 pid=373396) .b8 50
(EngineCore_DP0 pid=373396) .b8 45
(EngineCore_DP0 pid=373396) .b8 51
(EngineCore_DP0 pid=373396) .b8 66
(EngineCore_DP0 pid=373396) .b8 46
(EngineCore_DP0 pid=373396) .b8 112
(EngineCore_DP0 pid=373396) .b8 121
(EngineCore_DP0 pid=373396) .b8 0
(EngineCore_DP0 pid=373396) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=373396) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=373396) .b8 114
(EngineCore_DP0 pid=373396) .b8 111
(EngineCore_DP0 pid=373396) .b8 111
(EngineCore_DP0 pid=373396) .b8 116
(EngineCore_DP0 pid=373396) .b8 47
(EngineCore_DP0 pid=373396) .b8 118
(EngineCore_DP0 pid=373396) .b8 108
(EngineCore_DP0 pid=373396) .b8 108
(EngineCore_DP0 pid=373396) .b8 109
(EngineCore_DP0 pid=373396) .b8 98
(EngineCore_DP0 pid=373396) .b8 101
(EngineCore_DP0 pid=373396) .b8 110
(EngineCore_DP0 pid=373396) .b8 99
(EngineCore_DP0 pid=373396) .b8 104
(EngineCore_DP0 pid=373396) .b8 47
(EngineCore_DP0 pid=373396) .b8 115
(EngineCore_DP0 pid=373396) .b8 108
(EngineCore_DP0 pid=373396) .b8 105
(EngineCore_DP0 pid=373396) .b8 100
(EngineCore_DP0 pid=373396) .b8 101
(EngineCore_DP0 pid=373396) .b8 115
(EngineCore_DP0 pid=373396) .b8 112
(EngineCore_DP0 pid=373396) .b8 97
(EngineCore_DP0 pid=373396) .b8 114
(EngineCore_DP0 pid=373396) .b8 115
(EngineCore_DP0 pid=373396) .b8 101
(EngineCore_DP0 pid=373396) .b8 47
(EngineCore_DP0 pid=373396) .b8 99
(EngineCore_DP0 pid=373396) .b8 115
(EngineCore_DP0 pid=373396) .b8 114
(EngineCore_DP0 pid=373396) .b8 99
(EngineCore_DP0 pid=373396) .b8 47
(EngineCore_DP0 pid=373396) .b8 102
(EngineCore_DP0 pid=373396) .b8 117
(EngineCore_DP0 pid=373396) .b8 115
(EngineCore_DP0 pid=373396) .b8 101
(EngineCore_DP0 pid=373396) .b8 100
(EngineCore_DP0 pid=373396) .b8 95
(EngineCore_DP0 pid=373396) .b8 113
(EngineCore_DP0 pid=373396) .b8 117
(EngineCore_DP0 pid=373396) .b8 97
(EngineCore_DP0 pid=373396) .b8 110
(EngineCore_DP0 pid=373396) .b8 116
(EngineCore_DP0 pid=373396) .b8 95
(EngineCore_DP0 pid=373396) .b8 115
(EngineCore_DP0 pid=373396) .b8 108
(EngineCore_DP0 pid=373396) .b8 105
(EngineCore_DP0 pid=373396) .b8 100
(EngineCore_DP0 pid=373396) .b8 101
(EngineCore_DP0 pid=373396) .b8 95
(EngineCore_DP0 pid=373396) .b8 116
(EngineCore_DP0 pid=373396) .b8 114
(EngineCore_DP0 pid=373396) .b8 105
(EngineCore_DP0 pid=373396) .b8 116
(EngineCore_DP0 pid=373396) .b8 111
(EngineCore_DP0 pid=373396) .b8 110
(EngineCore_DP0 pid=373396) .b8 47
(EngineCore_DP0 pid=373396) .b8 98
(EngineCore_DP0 pid=373396) .b8 117
(EngineCore_DP0 pid=373396) .b8 105
(EngineCore_DP0 pid=373396) .b8 108
(EngineCore_DP0 pid=373396) .b8 100
(EngineCore_DP0 pid=373396) .b8 47
(EngineCore_DP0 pid=373396) .b8 71
(EngineCore_DP0 pid=373396) .b8 66
(EngineCore_DP0 pid=373396) .b8 49
(EngineCore_DP0 pid=373396) .b8 48
(EngineCore_DP0 pid=373396) .b8 95
(EngineCore_DP0 pid=373396) .b8 99
(EngineCore_DP0 pid=373396) .b8 99
(EngineCore_DP0 pid=373396) .b8 49
(EngineCore_DP0 pid=373396) .b8 50
(EngineCore_DP0 pid=373396) .b8 49
(EngineCore_DP0 pid=373396) .b8 95
(EngineCore_DP0 pid=373396) .b8 112
(EngineCore_DP0 pid=373396) .b8 121
(EngineCore_DP0 pid=373396) .b8 51
(EngineCore_DP0 pid=373396) .b8 49
(EngineCore_DP0 pid=373396) .b8 50
(EngineCore_DP0 pid=373396) .b8 95
(EngineCore_DP0 pid=373396) .b8 99
(EngineCore_DP0 pid=373396) .b8 117
(EngineCore_DP0 pid=373396) .b8 49
(EngineCore_DP0 pid=373396) .b8 50
(EngineCore_DP0 pid=373396) .b8 57
(EngineCore_DP0 pid=373396) .b8 95
(EngineCore_DP0 pid=373396) .b8 97
(EngineCore_DP0 pid=373396) .b8 97
(EngineCore_DP0 pid=373396) .b8 114
(EngineCore_DP0 pid=373396) .b8 99
(EngineCore_DP0 pid=373396) .b8 104
(EngineCore_DP0 pid=373396) .b8 54
(EngineCore_DP0 pid=373396) .b8 52
(EngineCore_DP0 pid=373396) .b8 0
(EngineCore_DP0 pid=373396) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=373396) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=373396) .b8 113
(EngineCore_DP0 pid=373396) .b8 117
(EngineCore_DP0 pid=373396) .b8 97
(EngineCore_DP0 pid=373396) .b8 110
(EngineCore_DP0 pid=373396) .b8 116
(EngineCore_DP0 pid=373396) .b8 95
(EngineCore_DP0 pid=373396) .b8 115
(EngineCore_DP0 pid=373396) .b8 108
(EngineCore_DP0 pid=373396) .b8 105
(EngineCore_DP0 pid=373396) .b8 100
(EngineCore_DP0 pid=373396) .b8 101
(EngineCore_DP0 pid=373396) .b8 95
(EngineCore_DP0 pid=373396) .b8 105
(EngineCore_DP0 pid=373396) .b8 110
(EngineCore_DP0 pid=373396) .b8 116
(EngineCore_DP0 pid=373396) .b8 56
(EngineCore_DP0 pid=373396) .b8 95
(EngineCore_DP0 pid=373396) .b8 107
(EngineCore_DP0 pid=373396) .b8 101
(EngineCore_DP0 pid=373396) .b8 114
(EngineCore_DP0 pid=373396) .b8 110
(EngineCore_DP0 pid=373396) .b8 101
(EngineCore_DP0 pid=373396) .b8 108
(EngineCore_DP0 pid=373396) .b8 0
(EngineCore_DP0 pid=373396) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=373396) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=373396) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=373396) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=373396) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=373396) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=373396) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=373396) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=373396) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=373396) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=373396) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=373396) .b8 1
(EngineCore_DP0 pid=373396) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=373396) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=373396) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=373396) 	}
(EngineCore_DP0 pid=373396) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=373396) 
(EngineCore_DP0 pid=373396) ================================================================
(EngineCore_DP0 pid=373396) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=373396) 
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpblw0d9ci.ptx', '-o', '/tmp/tmpblw0d9ci.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866] 
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866] 
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866] 
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpblw0d9ci.ptx -o /tmp/tmpblw0d9ci.ptx.o
(EngineCore_DP0 pid=373396) ERROR 01-25 19:48:03 [core.py:866] 

STDERR:
[2026-01-25 19:47:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:47:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:47:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:47:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:47:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:47:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:47:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:47:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:47:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:47:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:47:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:47:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:47:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:47:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:47:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:47:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:47:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:47:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:47:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:47:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:47:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:47:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:47:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:47:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:47:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:47:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:47:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:47:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=373396) [2026-01-25 19:47:33] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=373396) [2026-01-25 19:47:33] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=373396) [2026-01-25 19:47:33] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=373396) [2026-01-25 19:47:33] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=373396) [2026-01-25 19:47:33] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=373396) [2026-01-25 19:47:33] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=373396) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=373396) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.27s/it]
(EngineCore_DP0 pid=373396) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.27s/it]
(EngineCore_DP0 pid=373396) 
(EngineCore_DP0 pid=373396) [2026-01-25 19:48:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=373396) [2026-01-25 19:48:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=373396) [2026-01-25 19:48:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=373396) [2026-01-25 19:48:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10616832 bytes
(EngineCore_DP0 pid=373396) [2026-01-25 19:48:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=373396) [2026-01-25 19:48:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56623104 bytes
(EngineCore_DP0 pid=373396) [2026-01-25 19:48:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=373396) [2026-01-25 19:48:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28311552 bytes
(EngineCore_DP0 pid=373396) Process EngineCore_DP0:
(EngineCore_DP0 pid=373396) Traceback (most recent call last):
(EngineCore_DP0 pid=373396)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=373396)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=373396)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=373396)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=373396) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpblw0d9ci.ptx', '-o', '/tmp/tmpblw0d9ci.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=373396) 
(EngineCore_DP0 pid=373396) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=373396) 
(EngineCore_DP0 pid=373396) Traceback (most recent call last):
(EngineCore_DP0 pid=373396)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=373396)     self.run()
(EngineCore_DP0 pid=373396)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=373396)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=373396)     raise e
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=373396)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=373396)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=373396)     super().__init__(
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=373396)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=373396)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=373396)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=373396)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=373396)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=373396)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=373396)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=373396)     return func(*args, **kwargs)
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=373396)     return func(*args, **kwargs)
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=373396)     self.model_runner.profile_run()
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=373396)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=373396)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=373396)     return func(*args, **kwargs)
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=373396)     outputs = self.model(
(EngineCore_DP0 pid=373396)               ^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=373396)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=373396)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=373396)     model_output = self.model(
(EngineCore_DP0 pid=373396)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=373396)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=373396)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=373396)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=373396)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=373396)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=373396)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=373396)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=373396)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=373396)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=373396)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=373396)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=373396)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=373396)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=373396)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=373396)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=373396)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=373396)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=373396)     return self._linear_fn(
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=373396)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=373396)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=373396)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=373396)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=373396)     return fn(input, L)
(EngineCore_DP0 pid=373396)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=373396)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=373396)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=373396)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=373396)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=373396)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=373396)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=373396)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=373396)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=373396)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=373396)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=373396)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=373396)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=373396)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=373396)     raise PTXASError(error)
(EngineCore_DP0 pid=373396) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=373396) `ptxas` stderr:
(EngineCore_DP0 pid=373396) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=373396) 
(EngineCore_DP0 pid=373396) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpblw0d9ci.ptx -o /tmp/tmpblw0d9ci.ptx.o
(EngineCore_DP0 pid=373396) 
[rank0]:[W125 19:48:03.090169510 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 19:48:05
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:48:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:48:32 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=374464) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=374464) 
(EngineCore_DP0 pid=374464) 
(EngineCore_DP0 pid=374464) ================================================================
(EngineCore_DP0 pid=374464) Internal Triton PTX codegen error
(EngineCore_DP0 pid=374464) `ptxas` stderr:
(EngineCore_DP0 pid=374464) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=374464) 
(EngineCore_DP0 pid=374464) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpr25im4g_.ptx -o /tmp/tmpr25im4g_.ptx.o
(EngineCore_DP0 pid=374464) 
(EngineCore_DP0 pid=374464) 
(EngineCore_DP0 pid=374464) //
(EngineCore_DP0 pid=374464) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=374464) //
(EngineCore_DP0 pid=374464) 
(EngineCore_DP0 pid=374464) .version 8.7
(EngineCore_DP0 pid=374464) .target sm_121a
(EngineCore_DP0 pid=374464) .address_size 64
(EngineCore_DP0 pid=374464) 
(EngineCore_DP0 pid=374464) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=374464) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=374464)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=374464) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=374464) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=374464) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=374464) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=374464) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=374464) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=374464) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=374464) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=374464) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=374464) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=374464) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=374464) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=374464) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=374464) )
(EngineCore_DP0 pid=374464) .reqntid 512
(EngineCore_DP0 pid=374464) {
(EngineCore_DP0 pid=374464) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=374464) 	.reg .b16 	%rs<40>;
(EngineCore_DP0 pid=374464) 	.reg .b32 	%r<173>;
(EngineCore_DP0 pid=374464) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=374464) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=374464) $L__func_begin0:
(EngineCore_DP0 pid=374464) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=374464) 
(EngineCore_DP0 pid=374464) // %bb.0:
(EngineCore_DP0 pid=374464) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=374464) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=374464) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=374464) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=374464) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=374464) $L__tmp0:
(EngineCore_DP0 pid=374464) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=374464) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=374464) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=374464) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=374464) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=374464) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=374464) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=374464) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=374464) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=374464) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=374464) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=374464) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=374464) 	mov.b32 	%r171, 0f2B8CBCCC;
(EngineCore_DP0 pid=374464) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=374464) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=374464) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=374464) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=374464) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=374464) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=374464) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=374464) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=374464) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=374464) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=374464) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=374464) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=374464) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=374464) 	mov.b32 	%r169, 0f00000000;
(EngineCore_DP0 pid=374464) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=374464) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=374464) 	mov.b32 	%r170, %r45;
(EngineCore_DP0 pid=374464) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=374464) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=374464) 	add.s32 	%r55, %r4, %r170;
(EngineCore_DP0 pid=374464) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=374464) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=374464) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=374464) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=374464) 	// begin inline asm
(EngineCore_DP0 pid=374464) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=374464) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=374464) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=374464) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=374464) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=374464) 	// end inline asm
(EngineCore_DP0 pid=374464) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=374464) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=374464) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=374464) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=374464) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=374464) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=374464) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=374464) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=374464) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=374464) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=374464) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=374464) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=374464) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=374464) $L__tmp1:
(EngineCore_DP0 pid=374464) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	bar.sync 	0;
(EngineCore_DP0 pid=374464) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=374464) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=374464) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=374464) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=374464) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=374464) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=374464) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=374464) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=374464) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=374464) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=374464) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=374464) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=374464) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=374464) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=374464) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=374464) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=374464) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=374464) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=374464) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	// begin inline asm
(EngineCore_DP0 pid=374464) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=374464) 	// end inline asm
(EngineCore_DP0 pid=374464) 	bar.sync 	0;
(EngineCore_DP0 pid=374464) 	// begin inline asm
(EngineCore_DP0 pid=374464) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=374464) 	// end inline asm
(EngineCore_DP0 pid=374464) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=374464) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=374464) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=374464) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=374464) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=374464) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=374464) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=374464) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=374464) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=374464) 	// begin inline asm
(EngineCore_DP0 pid=374464) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=374464) 	// end inline asm
(EngineCore_DP0 pid=374464) 	bar.sync 	0;
(EngineCore_DP0 pid=374464) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=374464) $L__tmp2:
(EngineCore_DP0 pid=374464) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=374464) 	max.f32 	%r169, %r169, %r73;
(EngineCore_DP0 pid=374464) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=374464) 	add.s32 	%r170, %r170, 4096;
(EngineCore_DP0 pid=374464) 	setp.lt.s32 	%p6, %r170, %r24;
(EngineCore_DP0 pid=374464) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=374464) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=374464) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=374464) 	max.f32 	%r171, %r169, 0f2B8CBCCC;
(EngineCore_DP0 pid=374464) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=374464) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=374464) 	mov.b32 	%r75, 0f42FE0000;
(EngineCore_DP0 pid=374464) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=374464) 	div.full.f32 	%r76, %r171, %r75;
(EngineCore_DP0 pid=374464) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=374464) 	max.f32 	%r74, %r76, 0f37810204;
(EngineCore_DP0 pid=374464) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=374464) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=374464) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=374464) 	// begin inline asm
(EngineCore_DP0 pid=374464) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=374464) 	// end inline asm
(EngineCore_DP0 pid=374464) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=374464) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=374464) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=374464) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=374464) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=374464) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=374464) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=374464) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=374464) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=374464) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=374464) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=374464) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=374464) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=374464) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=374464) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=374464) 	div.full.f32 	%r14, %r75, %r171;
(EngineCore_DP0 pid=374464) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=374464) 	mov.b32 	%r172, 0;
(EngineCore_DP0 pid=374464) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=374464)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=374464) 	.loc	1 327 31                        // quant_slide_tuned_Llama3.2-3B.py:327:31
(EngineCore_DP0 pid=374464) 	add.s32 	%r81, %r16, %r172;
(EngineCore_DP0 pid=374464) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=374464) 	add.s32 	%r82, %r81, 1;
(EngineCore_DP0 pid=374464) 	setp.lt.s32 	%p17, %r81, %r15;
(EngineCore_DP0 pid=374464) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=374464) 	mul.hi.s32 	%r83, %r82, 1431655766;
(EngineCore_DP0 pid=374464) 	shr.u32 	%r84, %r83, 31;
(EngineCore_DP0 pid=374464) 	add.s32 	%r85, %r83, %r84;
(EngineCore_DP0 pid=374464) 	mul.hi.s32 	%r86, %r81, 1431655766;
(EngineCore_DP0 pid=374464) 	shr.u32 	%r87, %r86, 31;
(EngineCore_DP0 pid=374464) 	add.s32 	%r88, %r86, %r87;
(EngineCore_DP0 pid=374464) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=374464) 	mul.lo.s32 	%r89, %r88, 3;
(EngineCore_DP0 pid=374464) 	mul.lo.s32 	%r90, %r85, 3;
(EngineCore_DP0 pid=374464) 	sub.s32 	%r91, %r82, %r90;
(EngineCore_DP0 pid=374464) 	sub.s32 	%r92, %r81, %r89;
(EngineCore_DP0 pid=374464) 	.loc	1 333 22                        // quant_slide_tuned_Llama3.2-3B.py:333:22
(EngineCore_DP0 pid=374464) 	shl.b32 	%r93, %r88, 3;
(EngineCore_DP0 pid=374464) 	shl.b32 	%r94, %r85, 3;
(EngineCore_DP0 pid=374464) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=374464) 	shl.b32 	%r95, %r92, 1;
(EngineCore_DP0 pid=374464) 	shl.b32 	%r96, %r91, 1;
(EngineCore_DP0 pid=374464) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=374464) 	add.s32 	%r97, %r94, %r96;
(EngineCore_DP0 pid=374464) 	add.s32 	%r98, %r93, %r95;
(EngineCore_DP0 pid=374464) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=374464) 	setp.lt.s32 	%p18, %r98, %r23;
(EngineCore_DP0 pid=374464) 	setp.lt.s32 	%p19, %r97, %r23;
(EngineCore_DP0 pid=374464) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=374464) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=374464) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=374464) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=374464) 	mad.wide.s32 	%rd8, %r98, 2, %rd1;
(EngineCore_DP0 pid=374464) 	mad.wide.s32 	%rd9, %r97, 2, %rd1;
(EngineCore_DP0 pid=374464) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=374464) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=374464) 	// begin inline asm
(EngineCore_DP0 pid=374464) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=374464) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=374464) 	// end inline asm
(EngineCore_DP0 pid=374464) 	// begin inline asm
(EngineCore_DP0 pid=374464) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=374464) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=374464) 	// end inline asm
(EngineCore_DP0 pid=374464) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=374464) 	cvt.f32.bf16 	%r99, %rs24;
(EngineCore_DP0 pid=374464) 	cvt.f32.bf16 	%r100, %rs26;
(EngineCore_DP0 pid=374464) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=374464) 	or.b32 	%r101, %r98, 1;
(EngineCore_DP0 pid=374464) 	or.b32 	%r102, %r97, 1;
(EngineCore_DP0 pid=374464) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=374464) 	setp.lt.s32 	%p20, %r101, %r23;
(EngineCore_DP0 pid=374464) 	setp.lt.s32 	%p21, %r102, %r23;
(EngineCore_DP0 pid=374464) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=374464) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=374464) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=374464) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=374464) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=374464) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=374464) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=374464) 	// begin inline asm
(EngineCore_DP0 pid=374464) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=374464) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=374464) 	// end inline asm
(EngineCore_DP0 pid=374464) 	// begin inline asm
(EngineCore_DP0 pid=374464) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=374464) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=374464) 	// end inline asm
(EngineCore_DP0 pid=374464) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=374464) 	cvt.f32.bf16 	%r103, %rs28;
(EngineCore_DP0 pid=374464) 	cvt.f32.bf16 	%r104, %rs30;
(EngineCore_DP0 pid=374464) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=374464) 	add.s32 	%r105, %r98, 2;
(EngineCore_DP0 pid=374464) 	add.s32 	%r106, %r97, 2;
(EngineCore_DP0 pid=374464) 	add.s32 	%r107, %r98, 3;
(EngineCore_DP0 pid=374464) 	add.s32 	%r108, %r97, 3;
(EngineCore_DP0 pid=374464) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=374464) 	setp.lt.s32 	%p22, %r108, %r23;
(EngineCore_DP0 pid=374464) 	setp.lt.s32 	%p23, %r107, %r23;
(EngineCore_DP0 pid=374464) 	setp.lt.s32 	%p24, %r106, %r23;
(EngineCore_DP0 pid=374464) 	setp.lt.s32 	%p25, %r105, %r23;
(EngineCore_DP0 pid=374464) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=374464) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=374464) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=374464) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=374464) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=374464) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=374464) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=374464) 	// begin inline asm
(EngineCore_DP0 pid=374464) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=374464) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=374464) 	// end inline asm
(EngineCore_DP0 pid=374464) 	// begin inline asm
(EngineCore_DP0 pid=374464) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=374464) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=374464) 	// end inline asm
(EngineCore_DP0 pid=374464) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=374464) 	cvt.f32.bf16 	%r109, %rs32;
(EngineCore_DP0 pid=374464) 	cvt.f32.bf16 	%r110, %rs34;
(EngineCore_DP0 pid=374464) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=374464) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=374464) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=374464) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=374464) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=374464) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=374464) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=374464) 	// begin inline asm
(EngineCore_DP0 pid=374464) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=374464) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=374464) 	// end inline asm
(EngineCore_DP0 pid=374464) 	// begin inline asm
(EngineCore_DP0 pid=374464) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=374464) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=374464) 	// end inline asm
(EngineCore_DP0 pid=374464) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=374464) 	cvt.f32.bf16 	%r111, %rs36;
(EngineCore_DP0 pid=374464) 	cvt.f32.bf16 	%r112, %rs38;
(EngineCore_DP0 pid=374464) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=374464) 	mul.f32 	%r113, %r14, %r99;
(EngineCore_DP0 pid=374464) 	mul.f32 	%r114, %r14, %r100;
(EngineCore_DP0 pid=374464) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=374464) 	cvt.rni.f32.f32 	%r115, %r113;
(EngineCore_DP0 pid=374464) 	cvt.rni.f32.f32 	%r116, %r114;
(EngineCore_DP0 pid=374464) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=374464) 	max.f32 	%r117, %r115, 0fC3000000;
(EngineCore_DP0 pid=374464) 	min.f32 	%r118, %r117, 0f42FE0000;
(EngineCore_DP0 pid=374464) 	max.f32 	%r119, %r116, 0fC3000000;
(EngineCore_DP0 pid=374464) 	min.f32 	%r120, %r119, 0f42FE0000;
(EngineCore_DP0 pid=374464) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=374464) 	cvt.rzi.s32.f32 	%r121, %r118;
(EngineCore_DP0 pid=374464) 	cvt.rzi.s32.f32 	%r122, %r120;
(EngineCore_DP0 pid=374464) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=374464) 	and.b32 	%r123, %r121, 255;
(EngineCore_DP0 pid=374464) 	and.b32 	%r124, %r122, 255;
(EngineCore_DP0 pid=374464) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=374464) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=374464) 	mul.f32 	%r126, %r14, %r104;
(EngineCore_DP0 pid=374464) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=374464) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=374464) 	cvt.rni.f32.f32 	%r128, %r126;
(EngineCore_DP0 pid=374464) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=374464) 	mul.f32 	%r129, %r14, %r109;
(EngineCore_DP0 pid=374464) 	mul.f32 	%r130, %r14, %r110;
(EngineCore_DP0 pid=374464) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=374464) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=374464) 	cvt.rni.f32.f32 	%r132, %r130;
(EngineCore_DP0 pid=374464) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=374464) 	mul.f32 	%r133, %r14, %r111;
(EngineCore_DP0 pid=374464) 	mul.f32 	%r134, %r14, %r112;
(EngineCore_DP0 pid=374464) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=374464) 	cvt.rni.f32.f32 	%r135, %r133;
(EngineCore_DP0 pid=374464) 	cvt.rni.f32.f32 	%r136, %r134;
(EngineCore_DP0 pid=374464) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=374464) 	max.f32 	%r137, %r135, 0fC3000000;
(EngineCore_DP0 pid=374464) 	min.f32 	%r138, %r137, 0f42FE0000;
(EngineCore_DP0 pid=374464) 	max.f32 	%r139, %r136, 0fC3000000;
(EngineCore_DP0 pid=374464) 	min.f32 	%r140, %r139, 0f42FE0000;
(EngineCore_DP0 pid=374464) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=374464) 	cvt.rzi.s32.f32 	%r141, %r138;
(EngineCore_DP0 pid=374464) 	cvt.rzi.s32.f32 	%r142, %r140;
(EngineCore_DP0 pid=374464) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=374464) 	max.f32 	%r143, %r131, 0fC3000000;
(EngineCore_DP0 pid=374464) 	max.f32 	%r144, %r127, 0fC3000000;
(EngineCore_DP0 pid=374464) 	min.f32 	%r145, %r144, 0f42FE0000;
(EngineCore_DP0 pid=374464) 	min.f32 	%r146, %r143, 0f42FE0000;
(EngineCore_DP0 pid=374464) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=374464) 	cvt.rzi.s32.f32 	%r147, %r146;
(EngineCore_DP0 pid=374464) 	cvt.rzi.s32.f32 	%r148, %r145;
(EngineCore_DP0 pid=374464) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=374464) 	shl.b32 	%r149, %r148, 8;
(EngineCore_DP0 pid=374464) 	shl.b32 	%r150, %r147, 16;
(EngineCore_DP0 pid=374464) 	and.b32 	%r151, %r150, 16711680;
(EngineCore_DP0 pid=374464) 	and.b32 	%r152, %r149, 65280;
(EngineCore_DP0 pid=374464) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=374464) 	or.b32 	%r153, %r152, %r123;
(EngineCore_DP0 pid=374464) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=374464) 	max.f32 	%r154, %r132, 0fC3000000;
(EngineCore_DP0 pid=374464) 	max.f32 	%r155, %r128, 0fC3000000;
(EngineCore_DP0 pid=374464) 	min.f32 	%r156, %r155, 0f42FE0000;
(EngineCore_DP0 pid=374464) 	min.f32 	%r157, %r154, 0f42FE0000;
(EngineCore_DP0 pid=374464) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=374464) 	cvt.rzi.s32.f32 	%r158, %r157;
(EngineCore_DP0 pid=374464) 	cvt.rzi.s32.f32 	%r159, %r156;
(EngineCore_DP0 pid=374464) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=374464) 	shl.b32 	%r160, %r159, 8;
(EngineCore_DP0 pid=374464) 	shl.b32 	%r161, %r158, 16;
(EngineCore_DP0 pid=374464) 	and.b32 	%r162, %r161, 16711680;
(EngineCore_DP0 pid=374464) 	and.b32 	%r163, %r160, 65280;
(EngineCore_DP0 pid=374464) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=374464) 	or.b32 	%r164, %r163, %r124;
(EngineCore_DP0 pid=374464) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=374464) 	or.b32 	%r165, %r153, %r151;
(EngineCore_DP0 pid=374464) 	or.b32 	%r166, %r164, %r162;
(EngineCore_DP0 pid=374464) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=374464) 	shl.b32 	%r167, %r141, 24;
(EngineCore_DP0 pid=374464) 	shl.b32 	%r168, %r142, 24;
(EngineCore_DP0 pid=374464) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=374464) 	or.b32 	%r78, %r165, %r167;
(EngineCore_DP0 pid=374464) 	or.b32 	%r79, %r166, %r168;
(EngineCore_DP0 pid=374464) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=374464) 	mad.wide.s32 	%rd16, %r81, 4, %rd2;
(EngineCore_DP0 pid=374464) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=374464) 	// begin inline asm
(EngineCore_DP0 pid=374464) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r78, %r79 };
(EngineCore_DP0 pid=374464) 	// end inline asm
(EngineCore_DP0 pid=374464) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=374464) 	add.s32 	%r172, %r172, 1024;
(EngineCore_DP0 pid=374464) 	setp.lt.s32 	%p26, %r172, %r15;
(EngineCore_DP0 pid=374464) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=374464) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=374464) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=374464) 	ret;
(EngineCore_DP0 pid=374464) $L__tmp3:
(EngineCore_DP0 pid=374464) $L__func_end0:
(EngineCore_DP0 pid=374464)                                         // -- End function
(EngineCore_DP0 pid=374464) }
(EngineCore_DP0 pid=374464) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=374464) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=374464) 	.section	.debug_abbrev
(EngineCore_DP0 pid=374464) 	{
(EngineCore_DP0 pid=374464) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=374464) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=374464) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=374464) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=374464) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=374464) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=374464) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=374464) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=374464) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=374464) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=374464) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=374464) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=374464) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=374464) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=374464) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=374464) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=374464) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=374464) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=374464) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=374464) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=374464) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=374464) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=374464) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=374464) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=374464) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=374464) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=374464) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=374464) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=374464) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=374464) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=374464) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=374464) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=374464) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=374464) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=374464) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=374464) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=374464) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=374464) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=374464) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=374464) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=374464) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=374464) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=374464) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=374464) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=374464) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=374464) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=374464) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=374464) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=374464) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=374464) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=374464) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=374464) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=374464) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=374464) 	}
(EngineCore_DP0 pid=374464) 	.section	.debug_info
(EngineCore_DP0 pid=374464) 	{
(EngineCore_DP0 pid=374464) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=374464) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=374464) .b8 0
(EngineCore_DP0 pid=374464) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=374464) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=374464) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=374464) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=374464) .b8 114
(EngineCore_DP0 pid=374464) .b8 105
(EngineCore_DP0 pid=374464) .b8 116
(EngineCore_DP0 pid=374464) .b8 111
(EngineCore_DP0 pid=374464) .b8 110
(EngineCore_DP0 pid=374464) .b8 0
(EngineCore_DP0 pid=374464) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=374464) .b8 0
(EngineCore_DP0 pid=374464) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=374464) .b8 117
(EngineCore_DP0 pid=374464) .b8 97
(EngineCore_DP0 pid=374464) .b8 110
(EngineCore_DP0 pid=374464) .b8 116
(EngineCore_DP0 pid=374464) .b8 95
(EngineCore_DP0 pid=374464) .b8 115
(EngineCore_DP0 pid=374464) .b8 108
(EngineCore_DP0 pid=374464) .b8 105
(EngineCore_DP0 pid=374464) .b8 100
(EngineCore_DP0 pid=374464) .b8 101
(EngineCore_DP0 pid=374464) .b8 95
(EngineCore_DP0 pid=374464) .b8 116
(EngineCore_DP0 pid=374464) .b8 117
(EngineCore_DP0 pid=374464) .b8 110
(EngineCore_DP0 pid=374464) .b8 101
(EngineCore_DP0 pid=374464) .b8 100
(EngineCore_DP0 pid=374464) .b8 95
(EngineCore_DP0 pid=374464) .b8 76
(EngineCore_DP0 pid=374464) .b8 108
(EngineCore_DP0 pid=374464) .b8 97
(EngineCore_DP0 pid=374464) .b8 109
(EngineCore_DP0 pid=374464) .b8 97
(EngineCore_DP0 pid=374464) .b8 51
(EngineCore_DP0 pid=374464) .b8 46
(EngineCore_DP0 pid=374464) .b8 50
(EngineCore_DP0 pid=374464) .b8 45
(EngineCore_DP0 pid=374464) .b8 51
(EngineCore_DP0 pid=374464) .b8 66
(EngineCore_DP0 pid=374464) .b8 46
(EngineCore_DP0 pid=374464) .b8 112
(EngineCore_DP0 pid=374464) .b8 121
(EngineCore_DP0 pid=374464) .b8 0
(EngineCore_DP0 pid=374464) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=374464) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=374464) .b8 114
(EngineCore_DP0 pid=374464) .b8 111
(EngineCore_DP0 pid=374464) .b8 111
(EngineCore_DP0 pid=374464) .b8 116
(EngineCore_DP0 pid=374464) .b8 47
(EngineCore_DP0 pid=374464) .b8 118
(EngineCore_DP0 pid=374464) .b8 108
(EngineCore_DP0 pid=374464) .b8 108
(EngineCore_DP0 pid=374464) .b8 109
(EngineCore_DP0 pid=374464) .b8 98
(EngineCore_DP0 pid=374464) .b8 101
(EngineCore_DP0 pid=374464) .b8 110
(EngineCore_DP0 pid=374464) .b8 99
(EngineCore_DP0 pid=374464) .b8 104
(EngineCore_DP0 pid=374464) .b8 47
(EngineCore_DP0 pid=374464) .b8 115
(EngineCore_DP0 pid=374464) .b8 108
(EngineCore_DP0 pid=374464) .b8 105
(EngineCore_DP0 pid=374464) .b8 100
(EngineCore_DP0 pid=374464) .b8 101
(EngineCore_DP0 pid=374464) .b8 115
(EngineCore_DP0 pid=374464) .b8 112
(EngineCore_DP0 pid=374464) .b8 97
(EngineCore_DP0 pid=374464) .b8 114
(EngineCore_DP0 pid=374464) .b8 115
(EngineCore_DP0 pid=374464) .b8 101
(EngineCore_DP0 pid=374464) .b8 47
(EngineCore_DP0 pid=374464) .b8 99
(EngineCore_DP0 pid=374464) .b8 115
(EngineCore_DP0 pid=374464) .b8 114
(EngineCore_DP0 pid=374464) .b8 99
(EngineCore_DP0 pid=374464) .b8 47
(EngineCore_DP0 pid=374464) .b8 102
(EngineCore_DP0 pid=374464) .b8 117
(EngineCore_DP0 pid=374464) .b8 115
(EngineCore_DP0 pid=374464) .b8 101
(EngineCore_DP0 pid=374464) .b8 100
(EngineCore_DP0 pid=374464) .b8 95
(EngineCore_DP0 pid=374464) .b8 113
(EngineCore_DP0 pid=374464) .b8 117
(EngineCore_DP0 pid=374464) .b8 97
(EngineCore_DP0 pid=374464) .b8 110
(EngineCore_DP0 pid=374464) .b8 116
(EngineCore_DP0 pid=374464) .b8 95
(EngineCore_DP0 pid=374464) .b8 115
(EngineCore_DP0 pid=374464) .b8 108
(EngineCore_DP0 pid=374464) .b8 105
(EngineCore_DP0 pid=374464) .b8 100
(EngineCore_DP0 pid=374464) .b8 101
(EngineCore_DP0 pid=374464) .b8 95
(EngineCore_DP0 pid=374464) .b8 116
(EngineCore_DP0 pid=374464) .b8 114
(EngineCore_DP0 pid=374464) .b8 105
(EngineCore_DP0 pid=374464) .b8 116
(EngineCore_DP0 pid=374464) .b8 111
(EngineCore_DP0 pid=374464) .b8 110
(EngineCore_DP0 pid=374464) .b8 47
(EngineCore_DP0 pid=374464) .b8 98
(EngineCore_DP0 pid=374464) .b8 117
(EngineCore_DP0 pid=374464) .b8 105
(EngineCore_DP0 pid=374464) .b8 108
(EngineCore_DP0 pid=374464) .b8 100
(EngineCore_DP0 pid=374464) .b8 47
(EngineCore_DP0 pid=374464) .b8 71
(EngineCore_DP0 pid=374464) .b8 66
(EngineCore_DP0 pid=374464) .b8 49
(EngineCore_DP0 pid=374464) .b8 48
(EngineCore_DP0 pid=374464) .b8 95
(EngineCore_DP0 pid=374464) .b8 99
(EngineCore_DP0 pid=374464) .b8 99
(EngineCore_DP0 pid=374464) .b8 49
(EngineCore_DP0 pid=374464) .b8 50
(EngineCore_DP0 pid=374464) .b8 49
(EngineCore_DP0 pid=374464) .b8 95
(EngineCore_DP0 pid=374464) .b8 112
(EngineCore_DP0 pid=374464) .b8 121
(EngineCore_DP0 pid=374464) .b8 51
(EngineCore_DP0 pid=374464) .b8 49
(EngineCore_DP0 pid=374464) .b8 50
(EngineCore_DP0 pid=374464) .b8 95
(EngineCore_DP0 pid=374464) .b8 99
(EngineCore_DP0 pid=374464) .b8 117
(EngineCore_DP0 pid=374464) .b8 49
(EngineCore_DP0 pid=374464) .b8 50
(EngineCore_DP0 pid=374464) .b8 57
(EngineCore_DP0 pid=374464) .b8 95
(EngineCore_DP0 pid=374464) .b8 97
(EngineCore_DP0 pid=374464) .b8 97
(EngineCore_DP0 pid=374464) .b8 114
(EngineCore_DP0 pid=374464) .b8 99
(EngineCore_DP0 pid=374464) .b8 104
(EngineCore_DP0 pid=374464) .b8 54
(EngineCore_DP0 pid=374464) .b8 52
(EngineCore_DP0 pid=374464) .b8 0
(EngineCore_DP0 pid=374464) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=374464) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=374464) .b8 113
(EngineCore_DP0 pid=374464) .b8 117
(EngineCore_DP0 pid=374464) .b8 97
(EngineCore_DP0 pid=374464) .b8 110
(EngineCore_DP0 pid=374464) .b8 116
(EngineCore_DP0 pid=374464) .b8 95
(EngineCore_DP0 pid=374464) .b8 115
(EngineCore_DP0 pid=374464) .b8 108
(EngineCore_DP0 pid=374464) .b8 105
(EngineCore_DP0 pid=374464) .b8 100
(EngineCore_DP0 pid=374464) .b8 101
(EngineCore_DP0 pid=374464) .b8 95
(EngineCore_DP0 pid=374464) .b8 105
(EngineCore_DP0 pid=374464) .b8 110
(EngineCore_DP0 pid=374464) .b8 116
(EngineCore_DP0 pid=374464) .b8 56
(EngineCore_DP0 pid=374464) .b8 95
(EngineCore_DP0 pid=374464) .b8 107
(EngineCore_DP0 pid=374464) .b8 101
(EngineCore_DP0 pid=374464) .b8 114
(EngineCore_DP0 pid=374464) .b8 110
(EngineCore_DP0 pid=374464) .b8 101
(EngineCore_DP0 pid=374464) .b8 108
(EngineCore_DP0 pid=374464) .b8 0
(EngineCore_DP0 pid=374464) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=374464) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=374464) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=374464) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=374464) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=374464) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=374464) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=374464) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=374464) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=374464) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=374464) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=374464) .b8 1
(EngineCore_DP0 pid=374464) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=374464) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=374464) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=374464) 	}
(EngineCore_DP0 pid=374464) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=374464) 
(EngineCore_DP0 pid=374464) ================================================================
(EngineCore_DP0 pid=374464) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=374464) 
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpr25im4g_.ptx', '-o', '/tmp/tmpr25im4g_.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866] 
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866] 
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866] 
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpr25im4g_.ptx -o /tmp/tmpr25im4g_.ptx.o
(EngineCore_DP0 pid=374464) ERROR 01-25 19:49:06 [core.py:866] 

STDERR:
[2026-01-25 19:48:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:48:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:48:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:48:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:48:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:48:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:48:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:48:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:48:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:48:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:48:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:48:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:48:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:48:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:48:35] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:48:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:48:35] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:48:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:48:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:48:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:48:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:48:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:48:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:48:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:48:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:48:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:48:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:48:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=374464) [2026-01-25 19:48:36] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=374464) [2026-01-25 19:48:36] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=374464) [2026-01-25 19:48:36] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=374464) [2026-01-25 19:48:36] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=374464) [2026-01-25 19:48:36] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=374464) [2026-01-25 19:48:36] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=374464) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=374464) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.61s/it]
(EngineCore_DP0 pid=374464) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.61s/it]
(EngineCore_DP0 pid=374464) 
(EngineCore_DP0 pid=374464) [2026-01-25 19:49:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=374464) [2026-01-25 19:49:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=374464) [2026-01-25 19:49:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=374464) [2026-01-25 19:49:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10616832 bytes
(EngineCore_DP0 pid=374464) [2026-01-25 19:49:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=374464) [2026-01-25 19:49:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56623104 bytes
(EngineCore_DP0 pid=374464) [2026-01-25 19:49:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=374464) [2026-01-25 19:49:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28311552 bytes
(EngineCore_DP0 pid=374464) Process EngineCore_DP0:
(EngineCore_DP0 pid=374464) Traceback (most recent call last):
(EngineCore_DP0 pid=374464)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=374464)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=374464)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=374464)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=374464) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpr25im4g_.ptx', '-o', '/tmp/tmpr25im4g_.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=374464) 
(EngineCore_DP0 pid=374464) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=374464) 
(EngineCore_DP0 pid=374464) Traceback (most recent call last):
(EngineCore_DP0 pid=374464)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=374464)     self.run()
(EngineCore_DP0 pid=374464)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=374464)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=374464)     raise e
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=374464)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=374464)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=374464)     super().__init__(
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=374464)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=374464)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=374464)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=374464)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=374464)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=374464)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=374464)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=374464)     return func(*args, **kwargs)
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=374464)     return func(*args, **kwargs)
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=374464)     self.model_runner.profile_run()
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=374464)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=374464)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=374464)     return func(*args, **kwargs)
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=374464)     outputs = self.model(
(EngineCore_DP0 pid=374464)               ^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=374464)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=374464)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=374464)     model_output = self.model(
(EngineCore_DP0 pid=374464)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=374464)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=374464)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=374464)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=374464)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=374464)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=374464)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=374464)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=374464)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=374464)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=374464)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=374464)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=374464)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=374464)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=374464)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=374464)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=374464)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=374464)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=374464)     return self._linear_fn(
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=374464)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=374464)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=374464)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=374464)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=374464)     return fn(input, L)
(EngineCore_DP0 pid=374464)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=374464)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=374464)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=374464)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=374464)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=374464)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=374464)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=374464)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=374464)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=374464)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=374464)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=374464)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=374464)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=374464)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=374464)     raise PTXASError(error)
(EngineCore_DP0 pid=374464) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=374464) `ptxas` stderr:
(EngineCore_DP0 pid=374464) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=374464) 
(EngineCore_DP0 pid=374464) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpr25im4g_.ptx -o /tmp/tmpr25im4g_.ptx.o
(EngineCore_DP0 pid=374464) 
[rank0]:[W125 19:49:07.257655867 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-25 20:46:57
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:47:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:47:01 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=437005) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=437005) 
(EngineCore_DP0 pid=437005) 
(EngineCore_DP0 pid=437005) ================================================================
(EngineCore_DP0 pid=437005) Internal Triton PTX codegen error
(EngineCore_DP0 pid=437005) `ptxas` stderr:
(EngineCore_DP0 pid=437005) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=437005) 
(EngineCore_DP0 pid=437005) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpfmo67cct.ptx -o /tmp/tmpfmo67cct.ptx.o
(EngineCore_DP0 pid=437005) 
(EngineCore_DP0 pid=437005) 
(EngineCore_DP0 pid=437005) //
(EngineCore_DP0 pid=437005) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=437005) //
(EngineCore_DP0 pid=437005) 
(EngineCore_DP0 pid=437005) .version 8.7
(EngineCore_DP0 pid=437005) .target sm_121a
(EngineCore_DP0 pid=437005) .address_size 64
(EngineCore_DP0 pid=437005) 
(EngineCore_DP0 pid=437005) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=437005) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=437005)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=437005) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=437005) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=437005) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=437005) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=437005) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=437005) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=437005) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=437005) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=437005) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=437005) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=437005) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=437005) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=437005) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=437005) )
(EngineCore_DP0 pid=437005) .reqntid 1024
(EngineCore_DP0 pid=437005) {
(EngineCore_DP0 pid=437005) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=437005) 	.reg .b16 	%rs<20>;
(EngineCore_DP0 pid=437005) 	.reg .b32 	%r<120>;
(EngineCore_DP0 pid=437005) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=437005) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=437005) $L__func_begin0:
(EngineCore_DP0 pid=437005) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=437005) 
(EngineCore_DP0 pid=437005) // %bb.0:
(EngineCore_DP0 pid=437005) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=437005) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=437005) 	ld.param.b32 	%r17, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=437005) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=437005) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=437005) $L__tmp0:
(EngineCore_DP0 pid=437005) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=437005) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=437005) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=437005) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=437005) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=437005) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=437005) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=437005) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=437005) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=437005) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=437005) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=437005) 	mov.b32 	%r118, 0f2B8CBCCC;
(EngineCore_DP0 pid=437005) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=437005) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=437005) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=437005) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=437005) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=437005) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=437005) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=437005) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=437005) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=437005) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=437005) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=437005) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=437005) 	mov.b32 	%r116, 0f00000000;
(EngineCore_DP0 pid=437005) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=437005) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=437005) 	mov.b32 	%r117, %r37;
(EngineCore_DP0 pid=437005) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=437005) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=437005) 	add.s32 	%r45, %r3, %r117;
(EngineCore_DP0 pid=437005) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=437005) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=437005) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=437005) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=437005) 	// begin inline asm
(EngineCore_DP0 pid=437005) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=437005) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=437005) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=437005) 	// end inline asm
(EngineCore_DP0 pid=437005) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=437005) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=437005) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=437005) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=437005) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=437005) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=437005) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=437005) $L__tmp1:
(EngineCore_DP0 pid=437005) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	bar.sync 	0;
(EngineCore_DP0 pid=437005) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=437005) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=437005) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=437005) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=437005) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=437005) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=437005) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=437005) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=437005) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=437005) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=437005) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=437005) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=437005) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=437005) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=437005) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	// begin inline asm
(EngineCore_DP0 pid=437005) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=437005) 	// end inline asm
(EngineCore_DP0 pid=437005) 	bar.sync 	0;
(EngineCore_DP0 pid=437005) 	// begin inline asm
(EngineCore_DP0 pid=437005) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=437005) 	// end inline asm
(EngineCore_DP0 pid=437005) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=437005) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=437005) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=437005) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=437005) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=437005) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=437005) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=437005) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=437005) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=437005) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=437005) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=437005) 	// begin inline asm
(EngineCore_DP0 pid=437005) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=437005) 	// end inline asm
(EngineCore_DP0 pid=437005) 	bar.sync 	0;
(EngineCore_DP0 pid=437005) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=437005) $L__tmp2:
(EngineCore_DP0 pid=437005) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=437005) 	max.f32 	%r116, %r116, %r65;
(EngineCore_DP0 pid=437005) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=437005) 	add.s32 	%r117, %r117, 4096;
(EngineCore_DP0 pid=437005) 	setp.lt.s32 	%p6, %r117, %r18;
(EngineCore_DP0 pid=437005) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=437005) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=437005) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=437005) 	max.f32 	%r118, %r116, 0f2B8CBCCC;
(EngineCore_DP0 pid=437005) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=437005) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=437005) 	mov.b32 	%r67, 0f42FE0000;
(EngineCore_DP0 pid=437005) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=437005) 	div.full.f32 	%r68, %r118, %r67;
(EngineCore_DP0 pid=437005) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=437005) 	max.f32 	%r66, %r68, 0f37810204;
(EngineCore_DP0 pid=437005) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=437005) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=437005) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=437005) 	// begin inline asm
(EngineCore_DP0 pid=437005) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=437005) 	// end inline asm
(EngineCore_DP0 pid=437005) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=437005) 	mul.lo.s32 	%r14, %r19, 3;
(EngineCore_DP0 pid=437005) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=437005) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=437005) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=437005) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=437005) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=437005) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=437005) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=437005) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=437005) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=437005) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=437005) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=437005) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=437005) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=437005) 	div.full.f32 	%r13, %r67, %r118;
(EngineCore_DP0 pid=437005) 	mov.b32 	%r119, 0;
(EngineCore_DP0 pid=437005) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=437005)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=437005) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=437005) 	add.s32 	%r72, %r2, %r119;
(EngineCore_DP0 pid=437005) 	setp.lt.s32 	%p13, %r72, %r14;
(EngineCore_DP0 pid=437005) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=437005) 	mul.hi.s32 	%r73, %r72, 1431655766;
(EngineCore_DP0 pid=437005) 	shr.u32 	%r74, %r73, 31;
(EngineCore_DP0 pid=437005) 	add.s32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=437005) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=437005) 	mul.lo.s32 	%r76, %r75, 3;
(EngineCore_DP0 pid=437005) 	sub.s32 	%r77, %r72, %r76;
(EngineCore_DP0 pid=437005) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=437005) 	shl.b32 	%r78, %r75, 3;
(EngineCore_DP0 pid=437005) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=437005) 	shl.b32 	%r79, %r77, 1;
(EngineCore_DP0 pid=437005) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=437005) 	add.s32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=437005) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=437005) 	setp.lt.s32 	%p14, %r80, %r17;
(EngineCore_DP0 pid=437005) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=437005) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=437005) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=437005) 	mad.wide.s32 	%rd8, %r80, 2, %rd1;
(EngineCore_DP0 pid=437005) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=437005) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=437005) 	// begin inline asm
(EngineCore_DP0 pid=437005) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=437005) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=437005) 	// end inline asm
(EngineCore_DP0 pid=437005) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=437005) 	cvt.f32.bf16 	%r81, %rs12;
(EngineCore_DP0 pid=437005) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=437005) 	or.b32 	%r82, %r80, 1;
(EngineCore_DP0 pid=437005) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=437005) 	setp.lt.s32 	%p15, %r82, %r17;
(EngineCore_DP0 pid=437005) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=437005) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=437005) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=437005) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=437005) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=437005) 	// begin inline asm
(EngineCore_DP0 pid=437005) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=437005) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=437005) 	// end inline asm
(EngineCore_DP0 pid=437005) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=437005) 	cvt.f32.bf16 	%r83, %rs14;
(EngineCore_DP0 pid=437005) 	.loc	1 292 48                        // quant_slide_tuned_Qwen2.5-7B.py:292:48
(EngineCore_DP0 pid=437005) 	add.s32 	%r84, %r80, 2;
(EngineCore_DP0 pid=437005) 	.loc	1 292 53                        // quant_slide_tuned_Qwen2.5-7B.py:292:53
(EngineCore_DP0 pid=437005) 	setp.lt.s32 	%p16, %r84, %r17;
(EngineCore_DP0 pid=437005) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=437005) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=437005) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=437005) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=437005) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=437005) 	// begin inline asm
(EngineCore_DP0 pid=437005) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=437005) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=437005) 	// end inline asm
(EngineCore_DP0 pid=437005) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=437005) 	cvt.f32.bf16 	%r85, %rs16;
(EngineCore_DP0 pid=437005) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=437005) 	add.s32 	%r86, %r80, 3;
(EngineCore_DP0 pid=437005) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=437005) 	setp.lt.s32 	%p17, %r86, %r17;
(EngineCore_DP0 pid=437005) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=437005) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=437005) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=437005) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=437005) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=437005) 	// begin inline asm
(EngineCore_DP0 pid=437005) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=437005) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=437005) 	// end inline asm
(EngineCore_DP0 pid=437005) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=437005) 	cvt.f32.bf16 	%r87, %rs18;
(EngineCore_DP0 pid=437005) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=437005) 	mul.f32 	%r88, %r13, %r81;
(EngineCore_DP0 pid=437005) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=437005) 	cvt.rni.f32.f32 	%r89, %r88;
(EngineCore_DP0 pid=437005) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=437005) 	max.f32 	%r90, %r89, 0fC3000000;
(EngineCore_DP0 pid=437005) 	min.f32 	%r91, %r90, 0f42FE0000;
(EngineCore_DP0 pid=437005) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=437005) 	cvt.rzi.s32.f32 	%r92, %r91;
(EngineCore_DP0 pid=437005) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=437005) 	and.b32 	%r93, %r92, 255;
(EngineCore_DP0 pid=437005) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=437005) 	mul.f32 	%r94, %r13, %r83;
(EngineCore_DP0 pid=437005) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=437005) 	cvt.rni.f32.f32 	%r95, %r94;
(EngineCore_DP0 pid=437005) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=437005) 	mul.f32 	%r96, %r13, %r85;
(EngineCore_DP0 pid=437005) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=437005) 	cvt.rni.f32.f32 	%r97, %r96;
(EngineCore_DP0 pid=437005) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=437005) 	mul.f32 	%r98, %r13, %r87;
(EngineCore_DP0 pid=437005) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=437005) 	cvt.rni.f32.f32 	%r99, %r98;
(EngineCore_DP0 pid=437005) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=437005) 	max.f32 	%r100, %r99, 0fC3000000;
(EngineCore_DP0 pid=437005) 	min.f32 	%r101, %r100, 0f42FE0000;
(EngineCore_DP0 pid=437005) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=437005) 	cvt.rzi.s32.f32 	%r102, %r101;
(EngineCore_DP0 pid=437005) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=437005) 	max.f32 	%r103, %r97, 0fC3000000;
(EngineCore_DP0 pid=437005) 	max.f32 	%r104, %r95, 0fC3000000;
(EngineCore_DP0 pid=437005) 	min.f32 	%r105, %r104, 0f42FE0000;
(EngineCore_DP0 pid=437005) 	min.f32 	%r106, %r103, 0f42FE0000;
(EngineCore_DP0 pid=437005) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=437005) 	cvt.rzi.s32.f32 	%r107, %r106;
(EngineCore_DP0 pid=437005) 	cvt.rzi.s32.f32 	%r108, %r105;
(EngineCore_DP0 pid=437005) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=437005) 	shl.b32 	%r109, %r108, 8;
(EngineCore_DP0 pid=437005) 	shl.b32 	%r110, %r107, 16;
(EngineCore_DP0 pid=437005) 	and.b32 	%r111, %r110, 16711680;
(EngineCore_DP0 pid=437005) 	and.b32 	%r112, %r109, 65280;
(EngineCore_DP0 pid=437005) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=437005) 	or.b32 	%r113, %r112, %r93;
(EngineCore_DP0 pid=437005) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=437005) 	or.b32 	%r114, %r113, %r111;
(EngineCore_DP0 pid=437005) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=437005) 	shl.b32 	%r115, %r102, 24;
(EngineCore_DP0 pid=437005) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=437005) 	or.b32 	%r70, %r114, %r115;
(EngineCore_DP0 pid=437005) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=437005) 	mad.wide.s32 	%rd12, %r72, 4, %rd2;
(EngineCore_DP0 pid=437005) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=437005) 	// begin inline asm
(EngineCore_DP0 pid=437005) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r70 };
(EngineCore_DP0 pid=437005) 	// end inline asm
(EngineCore_DP0 pid=437005) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=437005) 	add.s32 	%r119, %r119, 1024;
(EngineCore_DP0 pid=437005) 	setp.lt.s32 	%p18, %r119, %r14;
(EngineCore_DP0 pid=437005) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=437005) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=437005) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=437005) 	ret;
(EngineCore_DP0 pid=437005) $L__tmp3:
(EngineCore_DP0 pid=437005) $L__func_end0:
(EngineCore_DP0 pid=437005)                                         // -- End function
(EngineCore_DP0 pid=437005) }
(EngineCore_DP0 pid=437005) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=437005) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=437005) 	.section	.debug_abbrev
(EngineCore_DP0 pid=437005) 	{
(EngineCore_DP0 pid=437005) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=437005) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=437005) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=437005) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=437005) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=437005) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=437005) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=437005) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=437005) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=437005) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=437005) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=437005) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=437005) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=437005) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=437005) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=437005) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=437005) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=437005) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=437005) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=437005) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=437005) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=437005) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=437005) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=437005) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=437005) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=437005) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=437005) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=437005) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=437005) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=437005) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=437005) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=437005) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=437005) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=437005) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=437005) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=437005) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=437005) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=437005) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=437005) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=437005) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=437005) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=437005) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=437005) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=437005) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=437005) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=437005) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=437005) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=437005) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=437005) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=437005) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=437005) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=437005) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=437005) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=437005) 	}
(EngineCore_DP0 pid=437005) 	.section	.debug_info
(EngineCore_DP0 pid=437005) 	{
(EngineCore_DP0 pid=437005) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=437005) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=437005) .b8 0
(EngineCore_DP0 pid=437005) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=437005) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=437005) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=437005) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=437005) .b8 114
(EngineCore_DP0 pid=437005) .b8 105
(EngineCore_DP0 pid=437005) .b8 116
(EngineCore_DP0 pid=437005) .b8 111
(EngineCore_DP0 pid=437005) .b8 110
(EngineCore_DP0 pid=437005) .b8 0
(EngineCore_DP0 pid=437005) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=437005) .b8 0
(EngineCore_DP0 pid=437005) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=437005) .b8 117
(EngineCore_DP0 pid=437005) .b8 97
(EngineCore_DP0 pid=437005) .b8 110
(EngineCore_DP0 pid=437005) .b8 116
(EngineCore_DP0 pid=437005) .b8 95
(EngineCore_DP0 pid=437005) .b8 115
(EngineCore_DP0 pid=437005) .b8 108
(EngineCore_DP0 pid=437005) .b8 105
(EngineCore_DP0 pid=437005) .b8 100
(EngineCore_DP0 pid=437005) .b8 101
(EngineCore_DP0 pid=437005) .b8 95
(EngineCore_DP0 pid=437005) .b8 116
(EngineCore_DP0 pid=437005) .b8 117
(EngineCore_DP0 pid=437005) .b8 110
(EngineCore_DP0 pid=437005) .b8 101
(EngineCore_DP0 pid=437005) .b8 100
(EngineCore_DP0 pid=437005) .b8 95
(EngineCore_DP0 pid=437005) .b8 81
(EngineCore_DP0 pid=437005) .b8 119
(EngineCore_DP0 pid=437005) .b8 101
(EngineCore_DP0 pid=437005) .b8 110
(EngineCore_DP0 pid=437005) .b8 50
(EngineCore_DP0 pid=437005) .b8 46
(EngineCore_DP0 pid=437005) .b8 53
(EngineCore_DP0 pid=437005) .b8 45
(EngineCore_DP0 pid=437005) .b8 55
(EngineCore_DP0 pid=437005) .b8 66
(EngineCore_DP0 pid=437005) .b8 46
(EngineCore_DP0 pid=437005) .b8 112
(EngineCore_DP0 pid=437005) .b8 121
(EngineCore_DP0 pid=437005) .b8 0
(EngineCore_DP0 pid=437005) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=437005) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=437005) .b8 114
(EngineCore_DP0 pid=437005) .b8 111
(EngineCore_DP0 pid=437005) .b8 111
(EngineCore_DP0 pid=437005) .b8 116
(EngineCore_DP0 pid=437005) .b8 47
(EngineCore_DP0 pid=437005) .b8 118
(EngineCore_DP0 pid=437005) .b8 108
(EngineCore_DP0 pid=437005) .b8 108
(EngineCore_DP0 pid=437005) .b8 109
(EngineCore_DP0 pid=437005) .b8 98
(EngineCore_DP0 pid=437005) .b8 101
(EngineCore_DP0 pid=437005) .b8 110
(EngineCore_DP0 pid=437005) .b8 99
(EngineCore_DP0 pid=437005) .b8 104
(EngineCore_DP0 pid=437005) .b8 47
(EngineCore_DP0 pid=437005) .b8 115
(EngineCore_DP0 pid=437005) .b8 108
(EngineCore_DP0 pid=437005) .b8 105
(EngineCore_DP0 pid=437005) .b8 100
(EngineCore_DP0 pid=437005) .b8 101
(EngineCore_DP0 pid=437005) .b8 115
(EngineCore_DP0 pid=437005) .b8 112
(EngineCore_DP0 pid=437005) .b8 97
(EngineCore_DP0 pid=437005) .b8 114
(EngineCore_DP0 pid=437005) .b8 115
(EngineCore_DP0 pid=437005) .b8 101
(EngineCore_DP0 pid=437005) .b8 47
(EngineCore_DP0 pid=437005) .b8 99
(EngineCore_DP0 pid=437005) .b8 115
(EngineCore_DP0 pid=437005) .b8 114
(EngineCore_DP0 pid=437005) .b8 99
(EngineCore_DP0 pid=437005) .b8 47
(EngineCore_DP0 pid=437005) .b8 102
(EngineCore_DP0 pid=437005) .b8 117
(EngineCore_DP0 pid=437005) .b8 115
(EngineCore_DP0 pid=437005) .b8 101
(EngineCore_DP0 pid=437005) .b8 100
(EngineCore_DP0 pid=437005) .b8 95
(EngineCore_DP0 pid=437005) .b8 113
(EngineCore_DP0 pid=437005) .b8 117
(EngineCore_DP0 pid=437005) .b8 97
(EngineCore_DP0 pid=437005) .b8 110
(EngineCore_DP0 pid=437005) .b8 116
(EngineCore_DP0 pid=437005) .b8 95
(EngineCore_DP0 pid=437005) .b8 115
(EngineCore_DP0 pid=437005) .b8 108
(EngineCore_DP0 pid=437005) .b8 105
(EngineCore_DP0 pid=437005) .b8 100
(EngineCore_DP0 pid=437005) .b8 101
(EngineCore_DP0 pid=437005) .b8 95
(EngineCore_DP0 pid=437005) .b8 116
(EngineCore_DP0 pid=437005) .b8 114
(EngineCore_DP0 pid=437005) .b8 105
(EngineCore_DP0 pid=437005) .b8 116
(EngineCore_DP0 pid=437005) .b8 111
(EngineCore_DP0 pid=437005) .b8 110
(EngineCore_DP0 pid=437005) .b8 47
(EngineCore_DP0 pid=437005) .b8 98
(EngineCore_DP0 pid=437005) .b8 117
(EngineCore_DP0 pid=437005) .b8 105
(EngineCore_DP0 pid=437005) .b8 108
(EngineCore_DP0 pid=437005) .b8 100
(EngineCore_DP0 pid=437005) .b8 47
(EngineCore_DP0 pid=437005) .b8 71
(EngineCore_DP0 pid=437005) .b8 66
(EngineCore_DP0 pid=437005) .b8 49
(EngineCore_DP0 pid=437005) .b8 48
(EngineCore_DP0 pid=437005) .b8 95
(EngineCore_DP0 pid=437005) .b8 99
(EngineCore_DP0 pid=437005) .b8 99
(EngineCore_DP0 pid=437005) .b8 49
(EngineCore_DP0 pid=437005) .b8 50
(EngineCore_DP0 pid=437005) .b8 49
(EngineCore_DP0 pid=437005) .b8 95
(EngineCore_DP0 pid=437005) .b8 112
(EngineCore_DP0 pid=437005) .b8 121
(EngineCore_DP0 pid=437005) .b8 51
(EngineCore_DP0 pid=437005) .b8 49
(EngineCore_DP0 pid=437005) .b8 50
(EngineCore_DP0 pid=437005) .b8 95
(EngineCore_DP0 pid=437005) .b8 99
(EngineCore_DP0 pid=437005) .b8 117
(EngineCore_DP0 pid=437005) .b8 49
(EngineCore_DP0 pid=437005) .b8 50
(EngineCore_DP0 pid=437005) .b8 57
(EngineCore_DP0 pid=437005) .b8 95
(EngineCore_DP0 pid=437005) .b8 97
(EngineCore_DP0 pid=437005) .b8 97
(EngineCore_DP0 pid=437005) .b8 114
(EngineCore_DP0 pid=437005) .b8 99
(EngineCore_DP0 pid=437005) .b8 104
(EngineCore_DP0 pid=437005) .b8 54
(EngineCore_DP0 pid=437005) .b8 52
(EngineCore_DP0 pid=437005) .b8 0
(EngineCore_DP0 pid=437005) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=437005) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=437005) .b8 113
(EngineCore_DP0 pid=437005) .b8 117
(EngineCore_DP0 pid=437005) .b8 97
(EngineCore_DP0 pid=437005) .b8 110
(EngineCore_DP0 pid=437005) .b8 116
(EngineCore_DP0 pid=437005) .b8 95
(EngineCore_DP0 pid=437005) .b8 115
(EngineCore_DP0 pid=437005) .b8 108
(EngineCore_DP0 pid=437005) .b8 105
(EngineCore_DP0 pid=437005) .b8 100
(EngineCore_DP0 pid=437005) .b8 101
(EngineCore_DP0 pid=437005) .b8 95
(EngineCore_DP0 pid=437005) .b8 105
(EngineCore_DP0 pid=437005) .b8 110
(EngineCore_DP0 pid=437005) .b8 116
(EngineCore_DP0 pid=437005) .b8 56
(EngineCore_DP0 pid=437005) .b8 95
(EngineCore_DP0 pid=437005) .b8 107
(EngineCore_DP0 pid=437005) .b8 101
(EngineCore_DP0 pid=437005) .b8 114
(EngineCore_DP0 pid=437005) .b8 110
(EngineCore_DP0 pid=437005) .b8 101
(EngineCore_DP0 pid=437005) .b8 108
(EngineCore_DP0 pid=437005) .b8 0
(EngineCore_DP0 pid=437005) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=437005) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=437005) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=437005) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=437005) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=437005) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=437005) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=437005) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=437005) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=437005) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=437005) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=437005) .b8 1
(EngineCore_DP0 pid=437005) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=437005) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=437005) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=437005) 	}
(EngineCore_DP0 pid=437005) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=437005) 
(EngineCore_DP0 pid=437005) ================================================================
(EngineCore_DP0 pid=437005) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=437005) 
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpfmo67cct.ptx', '-o', '/tmp/tmpfmo67cct.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866] 
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866] 
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866] 
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpfmo67cct.ptx -o /tmp/tmpfmo67cct.ptx.o
(EngineCore_DP0 pid=437005) ERROR 01-25 20:48:10 [core.py:866] 

STDERR:
[2026-01-25 20:47:00] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:47:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:47:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:47:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:47:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:47:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:47:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:47:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:47:04] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:47:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:47:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:47:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:47:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:47:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:47:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:47:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:47:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=437005) [2026-01-25 20:47:05] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=437005) [2026-01-25 20:47:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=437005) [2026-01-25 20:47:05] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=437005) [2026-01-25 20:47:05] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=437005) [2026-01-25 20:47:05] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=437005) [2026-01-25 20:47:05] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=437005) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=437005) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.90s/it]
(EngineCore_DP0 pid=437005) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:01<00:00, 31.30s/it]
(EngineCore_DP0 pid=437005) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:01<00:00, 30.79s/it]
(EngineCore_DP0 pid=437005) 
(EngineCore_DP0 pid=437005) [2026-01-25 20:48:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=437005) [2026-01-25 20:48:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=437005) [2026-01-25 20:48:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=437005) [2026-01-25 20:48:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=437005) [2026-01-25 20:48:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=437005) [2026-01-25 20:48:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=437005) [2026-01-25 20:48:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=437005) [2026-01-25 20:48:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=437005) Process EngineCore_DP0:
(EngineCore_DP0 pid=437005) Traceback (most recent call last):
(EngineCore_DP0 pid=437005)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=437005)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=437005)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=437005)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=437005) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpfmo67cct.ptx', '-o', '/tmp/tmpfmo67cct.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=437005) 
(EngineCore_DP0 pid=437005) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=437005) 
(EngineCore_DP0 pid=437005) Traceback (most recent call last):
(EngineCore_DP0 pid=437005)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=437005)     self.run()
(EngineCore_DP0 pid=437005)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=437005)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=437005)     raise e
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=437005)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=437005)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=437005)     super().__init__(
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=437005)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=437005)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=437005)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=437005)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=437005)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=437005)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=437005)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=437005)     return func(*args, **kwargs)
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=437005)     return func(*args, **kwargs)
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=437005)     self.model_runner.profile_run()
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=437005)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=437005)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=437005)     return func(*args, **kwargs)
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=437005)     outputs = self.model(
(EngineCore_DP0 pid=437005)               ^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=437005)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=437005)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=437005)     hidden_states = self.model(
(EngineCore_DP0 pid=437005)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=437005)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=437005)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=437005)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=437005)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=437005)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=437005)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=437005)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=437005)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=437005)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=437005)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=437005)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=437005)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=437005)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=437005)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=437005)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=437005)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=437005)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=437005)     return self._linear_fn(
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=437005)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=437005)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=437005)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=437005)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=437005)     return fn(input, L)
(EngineCore_DP0 pid=437005)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=437005)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=437005)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=437005)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=437005)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=437005)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=437005)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=437005)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=437005)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=437005)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=437005)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=437005)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=437005)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=437005)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=437005)     raise PTXASError(error)
(EngineCore_DP0 pid=437005) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=437005) `ptxas` stderr:
(EngineCore_DP0 pid=437005) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=437005) 
(EngineCore_DP0 pid=437005) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpfmo67cct.ptx -o /tmp/tmpfmo67cct.ptx.o
(EngineCore_DP0 pid=437005) 
[rank0]:[W125 20:48:10.893831770 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 20:48:12
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:48:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:48:16 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=438247) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=438247) 
(EngineCore_DP0 pid=438247) 
(EngineCore_DP0 pid=438247) ================================================================
(EngineCore_DP0 pid=438247) Internal Triton PTX codegen error
(EngineCore_DP0 pid=438247) `ptxas` stderr:
(EngineCore_DP0 pid=438247) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=438247) 
(EngineCore_DP0 pid=438247) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp1tsb5qx1.ptx -o /tmp/tmp1tsb5qx1.ptx.o
(EngineCore_DP0 pid=438247) 
(EngineCore_DP0 pid=438247) 
(EngineCore_DP0 pid=438247) //
(EngineCore_DP0 pid=438247) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=438247) //
(EngineCore_DP0 pid=438247) 
(EngineCore_DP0 pid=438247) .version 8.7
(EngineCore_DP0 pid=438247) .target sm_121a
(EngineCore_DP0 pid=438247) .address_size 64
(EngineCore_DP0 pid=438247) 
(EngineCore_DP0 pid=438247) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=438247) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=438247)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=438247) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=438247) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=438247) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=438247) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=438247) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=438247) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=438247) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=438247) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=438247) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=438247) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=438247) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=438247) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=438247) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=438247) )
(EngineCore_DP0 pid=438247) .reqntid 512
(EngineCore_DP0 pid=438247) {
(EngineCore_DP0 pid=438247) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=438247) 	.reg .b16 	%rs<40>;
(EngineCore_DP0 pid=438247) 	.reg .b32 	%r<173>;
(EngineCore_DP0 pid=438247) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=438247) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=438247) $L__func_begin0:
(EngineCore_DP0 pid=438247) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=438247) 
(EngineCore_DP0 pid=438247) // %bb.0:
(EngineCore_DP0 pid=438247) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=438247) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=438247) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=438247) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=438247) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=438247) $L__tmp0:
(EngineCore_DP0 pid=438247) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=438247) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=438247) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=438247) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=438247) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=438247) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=438247) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=438247) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=438247) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=438247) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=438247) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=438247) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=438247) 	mov.b32 	%r171, 0f2B8CBCCC;
(EngineCore_DP0 pid=438247) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=438247) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=438247) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=438247) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=438247) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=438247) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=438247) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=438247) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=438247) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=438247) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=438247) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=438247) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=438247) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=438247) 	mov.b32 	%r169, 0f00000000;
(EngineCore_DP0 pid=438247) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=438247) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=438247) 	mov.b32 	%r170, %r45;
(EngineCore_DP0 pid=438247) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=438247) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=438247) 	add.s32 	%r55, %r4, %r170;
(EngineCore_DP0 pid=438247) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=438247) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=438247) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=438247) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=438247) 	// begin inline asm
(EngineCore_DP0 pid=438247) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=438247) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=438247) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=438247) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=438247) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=438247) 	// end inline asm
(EngineCore_DP0 pid=438247) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=438247) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=438247) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=438247) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=438247) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=438247) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=438247) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=438247) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=438247) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=438247) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=438247) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=438247) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=438247) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=438247) $L__tmp1:
(EngineCore_DP0 pid=438247) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	bar.sync 	0;
(EngineCore_DP0 pid=438247) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=438247) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=438247) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=438247) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=438247) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=438247) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=438247) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=438247) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=438247) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=438247) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=438247) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=438247) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=438247) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=438247) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=438247) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=438247) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=438247) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=438247) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=438247) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	// begin inline asm
(EngineCore_DP0 pid=438247) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=438247) 	// end inline asm
(EngineCore_DP0 pid=438247) 	bar.sync 	0;
(EngineCore_DP0 pid=438247) 	// begin inline asm
(EngineCore_DP0 pid=438247) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=438247) 	// end inline asm
(EngineCore_DP0 pid=438247) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=438247) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=438247) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=438247) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=438247) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=438247) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=438247) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=438247) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=438247) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=438247) 	// begin inline asm
(EngineCore_DP0 pid=438247) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=438247) 	// end inline asm
(EngineCore_DP0 pid=438247) 	bar.sync 	0;
(EngineCore_DP0 pid=438247) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=438247) $L__tmp2:
(EngineCore_DP0 pid=438247) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=438247) 	max.f32 	%r169, %r169, %r73;
(EngineCore_DP0 pid=438247) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=438247) 	add.s32 	%r170, %r170, 4096;
(EngineCore_DP0 pid=438247) 	setp.lt.s32 	%p6, %r170, %r24;
(EngineCore_DP0 pid=438247) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=438247) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=438247) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=438247) 	max.f32 	%r171, %r169, 0f2B8CBCCC;
(EngineCore_DP0 pid=438247) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=438247) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=438247) 	mov.b32 	%r75, 0f42FE0000;
(EngineCore_DP0 pid=438247) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=438247) 	div.full.f32 	%r76, %r171, %r75;
(EngineCore_DP0 pid=438247) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=438247) 	max.f32 	%r74, %r76, 0f37810204;
(EngineCore_DP0 pid=438247) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=438247) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=438247) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=438247) 	// begin inline asm
(EngineCore_DP0 pid=438247) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=438247) 	// end inline asm
(EngineCore_DP0 pid=438247) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=438247) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=438247) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=438247) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=438247) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=438247) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=438247) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=438247) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=438247) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=438247) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=438247) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=438247) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=438247) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=438247) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=438247) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=438247) 	div.full.f32 	%r14, %r75, %r171;
(EngineCore_DP0 pid=438247) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=438247) 	mov.b32 	%r172, 0;
(EngineCore_DP0 pid=438247) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=438247)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=438247) 	.loc	1 279 31                        // quant_slide_tuned_Qwen2.5-7B.py:279:31
(EngineCore_DP0 pid=438247) 	add.s32 	%r81, %r16, %r172;
(EngineCore_DP0 pid=438247) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=438247) 	add.s32 	%r82, %r81, 1;
(EngineCore_DP0 pid=438247) 	setp.lt.s32 	%p17, %r81, %r15;
(EngineCore_DP0 pid=438247) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=438247) 	mul.hi.s32 	%r83, %r82, 1431655766;
(EngineCore_DP0 pid=438247) 	shr.u32 	%r84, %r83, 31;
(EngineCore_DP0 pid=438247) 	add.s32 	%r85, %r83, %r84;
(EngineCore_DP0 pid=438247) 	mul.hi.s32 	%r86, %r81, 1431655766;
(EngineCore_DP0 pid=438247) 	shr.u32 	%r87, %r86, 31;
(EngineCore_DP0 pid=438247) 	add.s32 	%r88, %r86, %r87;
(EngineCore_DP0 pid=438247) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=438247) 	mul.lo.s32 	%r89, %r88, 3;
(EngineCore_DP0 pid=438247) 	mul.lo.s32 	%r90, %r85, 3;
(EngineCore_DP0 pid=438247) 	sub.s32 	%r91, %r82, %r90;
(EngineCore_DP0 pid=438247) 	sub.s32 	%r92, %r81, %r89;
(EngineCore_DP0 pid=438247) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=438247) 	shl.b32 	%r93, %r88, 3;
(EngineCore_DP0 pid=438247) 	shl.b32 	%r94, %r85, 3;
(EngineCore_DP0 pid=438247) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=438247) 	shl.b32 	%r95, %r92, 1;
(EngineCore_DP0 pid=438247) 	shl.b32 	%r96, %r91, 1;
(EngineCore_DP0 pid=438247) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=438247) 	add.s32 	%r97, %r94, %r96;
(EngineCore_DP0 pid=438247) 	add.s32 	%r98, %r93, %r95;
(EngineCore_DP0 pid=438247) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=438247) 	setp.lt.s32 	%p18, %r98, %r23;
(EngineCore_DP0 pid=438247) 	setp.lt.s32 	%p19, %r97, %r23;
(EngineCore_DP0 pid=438247) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=438247) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=438247) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=438247) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=438247) 	mad.wide.s32 	%rd8, %r98, 2, %rd1;
(EngineCore_DP0 pid=438247) 	mad.wide.s32 	%rd9, %r97, 2, %rd1;
(EngineCore_DP0 pid=438247) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=438247) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=438247) 	// begin inline asm
(EngineCore_DP0 pid=438247) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=438247) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=438247) 	// end inline asm
(EngineCore_DP0 pid=438247) 	// begin inline asm
(EngineCore_DP0 pid=438247) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=438247) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=438247) 	// end inline asm
(EngineCore_DP0 pid=438247) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=438247) 	cvt.f32.bf16 	%r99, %rs24;
(EngineCore_DP0 pid=438247) 	cvt.f32.bf16 	%r100, %rs26;
(EngineCore_DP0 pid=438247) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=438247) 	or.b32 	%r101, %r98, 1;
(EngineCore_DP0 pid=438247) 	or.b32 	%r102, %r97, 1;
(EngineCore_DP0 pid=438247) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=438247) 	setp.lt.s32 	%p20, %r101, %r23;
(EngineCore_DP0 pid=438247) 	setp.lt.s32 	%p21, %r102, %r23;
(EngineCore_DP0 pid=438247) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=438247) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=438247) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=438247) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=438247) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=438247) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=438247) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=438247) 	// begin inline asm
(EngineCore_DP0 pid=438247) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=438247) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=438247) 	// end inline asm
(EngineCore_DP0 pid=438247) 	// begin inline asm
(EngineCore_DP0 pid=438247) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=438247) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=438247) 	// end inline asm
(EngineCore_DP0 pid=438247) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=438247) 	cvt.f32.bf16 	%r103, %rs28;
(EngineCore_DP0 pid=438247) 	cvt.f32.bf16 	%r104, %rs30;
(EngineCore_DP0 pid=438247) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=438247) 	add.s32 	%r105, %r98, 2;
(EngineCore_DP0 pid=438247) 	add.s32 	%r106, %r97, 2;
(EngineCore_DP0 pid=438247) 	add.s32 	%r107, %r98, 3;
(EngineCore_DP0 pid=438247) 	add.s32 	%r108, %r97, 3;
(EngineCore_DP0 pid=438247) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=438247) 	setp.lt.s32 	%p22, %r108, %r23;
(EngineCore_DP0 pid=438247) 	setp.lt.s32 	%p23, %r107, %r23;
(EngineCore_DP0 pid=438247) 	setp.lt.s32 	%p24, %r106, %r23;
(EngineCore_DP0 pid=438247) 	setp.lt.s32 	%p25, %r105, %r23;
(EngineCore_DP0 pid=438247) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=438247) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=438247) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=438247) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=438247) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=438247) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=438247) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=438247) 	// begin inline asm
(EngineCore_DP0 pid=438247) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=438247) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=438247) 	// end inline asm
(EngineCore_DP0 pid=438247) 	// begin inline asm
(EngineCore_DP0 pid=438247) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=438247) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=438247) 	// end inline asm
(EngineCore_DP0 pid=438247) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=438247) 	cvt.f32.bf16 	%r109, %rs32;
(EngineCore_DP0 pid=438247) 	cvt.f32.bf16 	%r110, %rs34;
(EngineCore_DP0 pid=438247) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=438247) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=438247) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=438247) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=438247) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=438247) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=438247) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=438247) 	// begin inline asm
(EngineCore_DP0 pid=438247) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=438247) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=438247) 	// end inline asm
(EngineCore_DP0 pid=438247) 	// begin inline asm
(EngineCore_DP0 pid=438247) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=438247) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=438247) 	// end inline asm
(EngineCore_DP0 pid=438247) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=438247) 	cvt.f32.bf16 	%r111, %rs36;
(EngineCore_DP0 pid=438247) 	cvt.f32.bf16 	%r112, %rs38;
(EngineCore_DP0 pid=438247) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=438247) 	mul.f32 	%r113, %r14, %r99;
(EngineCore_DP0 pid=438247) 	mul.f32 	%r114, %r14, %r100;
(EngineCore_DP0 pid=438247) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=438247) 	cvt.rni.f32.f32 	%r115, %r113;
(EngineCore_DP0 pid=438247) 	cvt.rni.f32.f32 	%r116, %r114;
(EngineCore_DP0 pid=438247) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=438247) 	max.f32 	%r117, %r115, 0fC3000000;
(EngineCore_DP0 pid=438247) 	min.f32 	%r118, %r117, 0f42FE0000;
(EngineCore_DP0 pid=438247) 	max.f32 	%r119, %r116, 0fC3000000;
(EngineCore_DP0 pid=438247) 	min.f32 	%r120, %r119, 0f42FE0000;
(EngineCore_DP0 pid=438247) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=438247) 	cvt.rzi.s32.f32 	%r121, %r118;
(EngineCore_DP0 pid=438247) 	cvt.rzi.s32.f32 	%r122, %r120;
(EngineCore_DP0 pid=438247) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=438247) 	and.b32 	%r123, %r121, 255;
(EngineCore_DP0 pid=438247) 	and.b32 	%r124, %r122, 255;
(EngineCore_DP0 pid=438247) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=438247) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=438247) 	mul.f32 	%r126, %r14, %r104;
(EngineCore_DP0 pid=438247) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=438247) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=438247) 	cvt.rni.f32.f32 	%r128, %r126;
(EngineCore_DP0 pid=438247) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=438247) 	mul.f32 	%r129, %r14, %r109;
(EngineCore_DP0 pid=438247) 	mul.f32 	%r130, %r14, %r110;
(EngineCore_DP0 pid=438247) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=438247) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=438247) 	cvt.rni.f32.f32 	%r132, %r130;
(EngineCore_DP0 pid=438247) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=438247) 	mul.f32 	%r133, %r14, %r111;
(EngineCore_DP0 pid=438247) 	mul.f32 	%r134, %r14, %r112;
(EngineCore_DP0 pid=438247) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=438247) 	cvt.rni.f32.f32 	%r135, %r133;
(EngineCore_DP0 pid=438247) 	cvt.rni.f32.f32 	%r136, %r134;
(EngineCore_DP0 pid=438247) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=438247) 	max.f32 	%r137, %r135, 0fC3000000;
(EngineCore_DP0 pid=438247) 	min.f32 	%r138, %r137, 0f42FE0000;
(EngineCore_DP0 pid=438247) 	max.f32 	%r139, %r136, 0fC3000000;
(EngineCore_DP0 pid=438247) 	min.f32 	%r140, %r139, 0f42FE0000;
(EngineCore_DP0 pid=438247) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=438247) 	cvt.rzi.s32.f32 	%r141, %r138;
(EngineCore_DP0 pid=438247) 	cvt.rzi.s32.f32 	%r142, %r140;
(EngineCore_DP0 pid=438247) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=438247) 	max.f32 	%r143, %r131, 0fC3000000;
(EngineCore_DP0 pid=438247) 	max.f32 	%r144, %r127, 0fC3000000;
(EngineCore_DP0 pid=438247) 	min.f32 	%r145, %r144, 0f42FE0000;
(EngineCore_DP0 pid=438247) 	min.f32 	%r146, %r143, 0f42FE0000;
(EngineCore_DP0 pid=438247) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=438247) 	cvt.rzi.s32.f32 	%r147, %r146;
(EngineCore_DP0 pid=438247) 	cvt.rzi.s32.f32 	%r148, %r145;
(EngineCore_DP0 pid=438247) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=438247) 	shl.b32 	%r149, %r148, 8;
(EngineCore_DP0 pid=438247) 	shl.b32 	%r150, %r147, 16;
(EngineCore_DP0 pid=438247) 	and.b32 	%r151, %r150, 16711680;
(EngineCore_DP0 pid=438247) 	and.b32 	%r152, %r149, 65280;
(EngineCore_DP0 pid=438247) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=438247) 	or.b32 	%r153, %r152, %r123;
(EngineCore_DP0 pid=438247) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=438247) 	max.f32 	%r154, %r132, 0fC3000000;
(EngineCore_DP0 pid=438247) 	max.f32 	%r155, %r128, 0fC3000000;
(EngineCore_DP0 pid=438247) 	min.f32 	%r156, %r155, 0f42FE0000;
(EngineCore_DP0 pid=438247) 	min.f32 	%r157, %r154, 0f42FE0000;
(EngineCore_DP0 pid=438247) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=438247) 	cvt.rzi.s32.f32 	%r158, %r157;
(EngineCore_DP0 pid=438247) 	cvt.rzi.s32.f32 	%r159, %r156;
(EngineCore_DP0 pid=438247) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=438247) 	shl.b32 	%r160, %r159, 8;
(EngineCore_DP0 pid=438247) 	shl.b32 	%r161, %r158, 16;
(EngineCore_DP0 pid=438247) 	and.b32 	%r162, %r161, 16711680;
(EngineCore_DP0 pid=438247) 	and.b32 	%r163, %r160, 65280;
(EngineCore_DP0 pid=438247) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=438247) 	or.b32 	%r164, %r163, %r124;
(EngineCore_DP0 pid=438247) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=438247) 	or.b32 	%r165, %r153, %r151;
(EngineCore_DP0 pid=438247) 	or.b32 	%r166, %r164, %r162;
(EngineCore_DP0 pid=438247) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=438247) 	shl.b32 	%r167, %r141, 24;
(EngineCore_DP0 pid=438247) 	shl.b32 	%r168, %r142, 24;
(EngineCore_DP0 pid=438247) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=438247) 	or.b32 	%r78, %r165, %r167;
(EngineCore_DP0 pid=438247) 	or.b32 	%r79, %r166, %r168;
(EngineCore_DP0 pid=438247) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=438247) 	mad.wide.s32 	%rd16, %r81, 4, %rd2;
(EngineCore_DP0 pid=438247) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=438247) 	// begin inline asm
(EngineCore_DP0 pid=438247) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r78, %r79 };
(EngineCore_DP0 pid=438247) 	// end inline asm
(EngineCore_DP0 pid=438247) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=438247) 	add.s32 	%r172, %r172, 1024;
(EngineCore_DP0 pid=438247) 	setp.lt.s32 	%p26, %r172, %r15;
(EngineCore_DP0 pid=438247) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=438247) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=438247) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=438247) 	ret;
(EngineCore_DP0 pid=438247) $L__tmp3:
(EngineCore_DP0 pid=438247) $L__func_end0:
(EngineCore_DP0 pid=438247)                                         // -- End function
(EngineCore_DP0 pid=438247) }
(EngineCore_DP0 pid=438247) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=438247) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=438247) 	.section	.debug_abbrev
(EngineCore_DP0 pid=438247) 	{
(EngineCore_DP0 pid=438247) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=438247) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=438247) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=438247) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=438247) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=438247) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=438247) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=438247) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=438247) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=438247) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=438247) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=438247) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=438247) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=438247) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=438247) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=438247) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=438247) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=438247) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=438247) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=438247) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=438247) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=438247) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=438247) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=438247) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=438247) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=438247) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=438247) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=438247) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=438247) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=438247) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=438247) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=438247) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=438247) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=438247) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=438247) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=438247) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=438247) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=438247) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=438247) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=438247) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=438247) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=438247) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=438247) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=438247) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=438247) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=438247) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=438247) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=438247) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=438247) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=438247) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=438247) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=438247) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=438247) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=438247) 	}
(EngineCore_DP0 pid=438247) 	.section	.debug_info
(EngineCore_DP0 pid=438247) 	{
(EngineCore_DP0 pid=438247) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=438247) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=438247) .b8 0
(EngineCore_DP0 pid=438247) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=438247) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=438247) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=438247) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=438247) .b8 114
(EngineCore_DP0 pid=438247) .b8 105
(EngineCore_DP0 pid=438247) .b8 116
(EngineCore_DP0 pid=438247) .b8 111
(EngineCore_DP0 pid=438247) .b8 110
(EngineCore_DP0 pid=438247) .b8 0
(EngineCore_DP0 pid=438247) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=438247) .b8 0
(EngineCore_DP0 pid=438247) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=438247) .b8 117
(EngineCore_DP0 pid=438247) .b8 97
(EngineCore_DP0 pid=438247) .b8 110
(EngineCore_DP0 pid=438247) .b8 116
(EngineCore_DP0 pid=438247) .b8 95
(EngineCore_DP0 pid=438247) .b8 115
(EngineCore_DP0 pid=438247) .b8 108
(EngineCore_DP0 pid=438247) .b8 105
(EngineCore_DP0 pid=438247) .b8 100
(EngineCore_DP0 pid=438247) .b8 101
(EngineCore_DP0 pid=438247) .b8 95
(EngineCore_DP0 pid=438247) .b8 116
(EngineCore_DP0 pid=438247) .b8 117
(EngineCore_DP0 pid=438247) .b8 110
(EngineCore_DP0 pid=438247) .b8 101
(EngineCore_DP0 pid=438247) .b8 100
(EngineCore_DP0 pid=438247) .b8 95
(EngineCore_DP0 pid=438247) .b8 81
(EngineCore_DP0 pid=438247) .b8 119
(EngineCore_DP0 pid=438247) .b8 101
(EngineCore_DP0 pid=438247) .b8 110
(EngineCore_DP0 pid=438247) .b8 50
(EngineCore_DP0 pid=438247) .b8 46
(EngineCore_DP0 pid=438247) .b8 53
(EngineCore_DP0 pid=438247) .b8 45
(EngineCore_DP0 pid=438247) .b8 55
(EngineCore_DP0 pid=438247) .b8 66
(EngineCore_DP0 pid=438247) .b8 46
(EngineCore_DP0 pid=438247) .b8 112
(EngineCore_DP0 pid=438247) .b8 121
(EngineCore_DP0 pid=438247) .b8 0
(EngineCore_DP0 pid=438247) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=438247) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=438247) .b8 114
(EngineCore_DP0 pid=438247) .b8 111
(EngineCore_DP0 pid=438247) .b8 111
(EngineCore_DP0 pid=438247) .b8 116
(EngineCore_DP0 pid=438247) .b8 47
(EngineCore_DP0 pid=438247) .b8 118
(EngineCore_DP0 pid=438247) .b8 108
(EngineCore_DP0 pid=438247) .b8 108
(EngineCore_DP0 pid=438247) .b8 109
(EngineCore_DP0 pid=438247) .b8 98
(EngineCore_DP0 pid=438247) .b8 101
(EngineCore_DP0 pid=438247) .b8 110
(EngineCore_DP0 pid=438247) .b8 99
(EngineCore_DP0 pid=438247) .b8 104
(EngineCore_DP0 pid=438247) .b8 47
(EngineCore_DP0 pid=438247) .b8 115
(EngineCore_DP0 pid=438247) .b8 108
(EngineCore_DP0 pid=438247) .b8 105
(EngineCore_DP0 pid=438247) .b8 100
(EngineCore_DP0 pid=438247) .b8 101
(EngineCore_DP0 pid=438247) .b8 115
(EngineCore_DP0 pid=438247) .b8 112
(EngineCore_DP0 pid=438247) .b8 97
(EngineCore_DP0 pid=438247) .b8 114
(EngineCore_DP0 pid=438247) .b8 115
(EngineCore_DP0 pid=438247) .b8 101
(EngineCore_DP0 pid=438247) .b8 47
(EngineCore_DP0 pid=438247) .b8 99
(EngineCore_DP0 pid=438247) .b8 115
(EngineCore_DP0 pid=438247) .b8 114
(EngineCore_DP0 pid=438247) .b8 99
(EngineCore_DP0 pid=438247) .b8 47
(EngineCore_DP0 pid=438247) .b8 102
(EngineCore_DP0 pid=438247) .b8 117
(EngineCore_DP0 pid=438247) .b8 115
(EngineCore_DP0 pid=438247) .b8 101
(EngineCore_DP0 pid=438247) .b8 100
(EngineCore_DP0 pid=438247) .b8 95
(EngineCore_DP0 pid=438247) .b8 113
(EngineCore_DP0 pid=438247) .b8 117
(EngineCore_DP0 pid=438247) .b8 97
(EngineCore_DP0 pid=438247) .b8 110
(EngineCore_DP0 pid=438247) .b8 116
(EngineCore_DP0 pid=438247) .b8 95
(EngineCore_DP0 pid=438247) .b8 115
(EngineCore_DP0 pid=438247) .b8 108
(EngineCore_DP0 pid=438247) .b8 105
(EngineCore_DP0 pid=438247) .b8 100
(EngineCore_DP0 pid=438247) .b8 101
(EngineCore_DP0 pid=438247) .b8 95
(EngineCore_DP0 pid=438247) .b8 116
(EngineCore_DP0 pid=438247) .b8 114
(EngineCore_DP0 pid=438247) .b8 105
(EngineCore_DP0 pid=438247) .b8 116
(EngineCore_DP0 pid=438247) .b8 111
(EngineCore_DP0 pid=438247) .b8 110
(EngineCore_DP0 pid=438247) .b8 47
(EngineCore_DP0 pid=438247) .b8 98
(EngineCore_DP0 pid=438247) .b8 117
(EngineCore_DP0 pid=438247) .b8 105
(EngineCore_DP0 pid=438247) .b8 108
(EngineCore_DP0 pid=438247) .b8 100
(EngineCore_DP0 pid=438247) .b8 47
(EngineCore_DP0 pid=438247) .b8 71
(EngineCore_DP0 pid=438247) .b8 66
(EngineCore_DP0 pid=438247) .b8 49
(EngineCore_DP0 pid=438247) .b8 48
(EngineCore_DP0 pid=438247) .b8 95
(EngineCore_DP0 pid=438247) .b8 99
(EngineCore_DP0 pid=438247) .b8 99
(EngineCore_DP0 pid=438247) .b8 49
(EngineCore_DP0 pid=438247) .b8 50
(EngineCore_DP0 pid=438247) .b8 49
(EngineCore_DP0 pid=438247) .b8 95
(EngineCore_DP0 pid=438247) .b8 112
(EngineCore_DP0 pid=438247) .b8 121
(EngineCore_DP0 pid=438247) .b8 51
(EngineCore_DP0 pid=438247) .b8 49
(EngineCore_DP0 pid=438247) .b8 50
(EngineCore_DP0 pid=438247) .b8 95
(EngineCore_DP0 pid=438247) .b8 99
(EngineCore_DP0 pid=438247) .b8 117
(EngineCore_DP0 pid=438247) .b8 49
(EngineCore_DP0 pid=438247) .b8 50
(EngineCore_DP0 pid=438247) .b8 57
(EngineCore_DP0 pid=438247) .b8 95
(EngineCore_DP0 pid=438247) .b8 97
(EngineCore_DP0 pid=438247) .b8 97
(EngineCore_DP0 pid=438247) .b8 114
(EngineCore_DP0 pid=438247) .b8 99
(EngineCore_DP0 pid=438247) .b8 104
(EngineCore_DP0 pid=438247) .b8 54
(EngineCore_DP0 pid=438247) .b8 52
(EngineCore_DP0 pid=438247) .b8 0
(EngineCore_DP0 pid=438247) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=438247) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=438247) .b8 113
(EngineCore_DP0 pid=438247) .b8 117
(EngineCore_DP0 pid=438247) .b8 97
(EngineCore_DP0 pid=438247) .b8 110
(EngineCore_DP0 pid=438247) .b8 116
(EngineCore_DP0 pid=438247) .b8 95
(EngineCore_DP0 pid=438247) .b8 115
(EngineCore_DP0 pid=438247) .b8 108
(EngineCore_DP0 pid=438247) .b8 105
(EngineCore_DP0 pid=438247) .b8 100
(EngineCore_DP0 pid=438247) .b8 101
(EngineCore_DP0 pid=438247) .b8 95
(EngineCore_DP0 pid=438247) .b8 105
(EngineCore_DP0 pid=438247) .b8 110
(EngineCore_DP0 pid=438247) .b8 116
(EngineCore_DP0 pid=438247) .b8 56
(EngineCore_DP0 pid=438247) .b8 95
(EngineCore_DP0 pid=438247) .b8 107
(EngineCore_DP0 pid=438247) .b8 101
(EngineCore_DP0 pid=438247) .b8 114
(EngineCore_DP0 pid=438247) .b8 110
(EngineCore_DP0 pid=438247) .b8 101
(EngineCore_DP0 pid=438247) .b8 108
(EngineCore_DP0 pid=438247) .b8 0
(EngineCore_DP0 pid=438247) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=438247) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=438247) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=438247) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=438247) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=438247) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=438247) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=438247) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=438247) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=438247) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=438247) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=438247) .b8 1
(EngineCore_DP0 pid=438247) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=438247) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=438247) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=438247) 	}
(EngineCore_DP0 pid=438247) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=438247) 
(EngineCore_DP0 pid=438247) ================================================================
(EngineCore_DP0 pid=438247) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=438247) 
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp1tsb5qx1.ptx', '-o', '/tmp/tmp1tsb5qx1.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866] 
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866] 
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866] 
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp1tsb5qx1.ptx -o /tmp/tmp1tsb5qx1.ptx.o
(EngineCore_DP0 pid=438247) ERROR 01-25 20:49:25 [core.py:866] 

STDERR:
[2026-01-25 20:48:16] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:48:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:48:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:48:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:48:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:48:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:48:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:48:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:48:19] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:48:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:48:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:48:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:48:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:48:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:48:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:48:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=438247) [2026-01-25 20:48:20] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=438247) [2026-01-25 20:48:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=438247) [2026-01-25 20:48:20] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=438247) [2026-01-25 20:48:20] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=438247) [2026-01-25 20:48:20] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=438247) [2026-01-25 20:48:20] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=438247) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=438247) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.78s/it]
(EngineCore_DP0 pid=438247) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.94s/it]
(EngineCore_DP0 pid=438247) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.47s/it]
(EngineCore_DP0 pid=438247) 
(EngineCore_DP0 pid=438247) [2026-01-25 20:49:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=438247) [2026-01-25 20:49:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=438247) [2026-01-25 20:49:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=438247) [2026-01-25 20:49:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=438247) [2026-01-25 20:49:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=438247) [2026-01-25 20:49:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=438247) [2026-01-25 20:49:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=438247) [2026-01-25 20:49:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=438247) Process EngineCore_DP0:
(EngineCore_DP0 pid=438247) Traceback (most recent call last):
(EngineCore_DP0 pid=438247)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=438247)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=438247)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=438247)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=438247) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp1tsb5qx1.ptx', '-o', '/tmp/tmp1tsb5qx1.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=438247) 
(EngineCore_DP0 pid=438247) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=438247) 
(EngineCore_DP0 pid=438247) Traceback (most recent call last):
(EngineCore_DP0 pid=438247)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=438247)     self.run()
(EngineCore_DP0 pid=438247)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=438247)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=438247)     raise e
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=438247)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=438247)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=438247)     super().__init__(
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=438247)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=438247)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=438247)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=438247)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=438247)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=438247)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=438247)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=438247)     return func(*args, **kwargs)
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=438247)     return func(*args, **kwargs)
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=438247)     self.model_runner.profile_run()
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=438247)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=438247)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=438247)     return func(*args, **kwargs)
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=438247)     outputs = self.model(
(EngineCore_DP0 pid=438247)               ^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=438247)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=438247)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=438247)     hidden_states = self.model(
(EngineCore_DP0 pid=438247)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=438247)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=438247)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=438247)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=438247)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=438247)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=438247)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=438247)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=438247)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=438247)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=438247)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=438247)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=438247)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=438247)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=438247)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=438247)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=438247)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=438247)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=438247)     return self._linear_fn(
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=438247)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=438247)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=438247)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=438247)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=438247)     return fn(input, L)
(EngineCore_DP0 pid=438247)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=438247)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=438247)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=438247)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=438247)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=438247)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=438247)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=438247)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=438247)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=438247)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=438247)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=438247)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=438247)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=438247)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=438247)     raise PTXASError(error)
(EngineCore_DP0 pid=438247) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=438247) `ptxas` stderr:
(EngineCore_DP0 pid=438247) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=438247) 
(EngineCore_DP0 pid=438247) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp1tsb5qx1.ptx -o /tmp/tmp1tsb5qx1.ptx.o
(EngineCore_DP0 pid=438247) 
[rank0]:[W125 20:49:25.550009794 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 20:49:27
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:49:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:49:31 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=439476) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=439476) 
(EngineCore_DP0 pid=439476) 
(EngineCore_DP0 pid=439476) ================================================================
(EngineCore_DP0 pid=439476) Internal Triton PTX codegen error
(EngineCore_DP0 pid=439476) `ptxas` stderr:
(EngineCore_DP0 pid=439476) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=439476) 
(EngineCore_DP0 pid=439476) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpfy0ndqfk.ptx -o /tmp/tmpfy0ndqfk.ptx.o
(EngineCore_DP0 pid=439476) 
(EngineCore_DP0 pid=439476) 
(EngineCore_DP0 pid=439476) //
(EngineCore_DP0 pid=439476) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=439476) //
(EngineCore_DP0 pid=439476) 
(EngineCore_DP0 pid=439476) .version 8.7
(EngineCore_DP0 pid=439476) .target sm_121a
(EngineCore_DP0 pid=439476) .address_size 64
(EngineCore_DP0 pid=439476) 
(EngineCore_DP0 pid=439476) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=439476) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=439476)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=439476) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=439476) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=439476) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=439476) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=439476) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=439476) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=439476) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=439476) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=439476) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=439476) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=439476) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=439476) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=439476) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=439476) )
(EngineCore_DP0 pid=439476) .reqntid 512
(EngineCore_DP0 pid=439476) {
(EngineCore_DP0 pid=439476) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=439476) 	.reg .b16 	%rs<40>;
(EngineCore_DP0 pid=439476) 	.reg .b32 	%r<173>;
(EngineCore_DP0 pid=439476) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=439476) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=439476) $L__func_begin0:
(EngineCore_DP0 pid=439476) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=439476) 
(EngineCore_DP0 pid=439476) // %bb.0:
(EngineCore_DP0 pid=439476) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=439476) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=439476) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=439476) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=439476) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=439476) $L__tmp0:
(EngineCore_DP0 pid=439476) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=439476) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=439476) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=439476) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=439476) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=439476) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=439476) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=439476) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=439476) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=439476) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=439476) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=439476) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=439476) 	mov.b32 	%r171, 0f2B8CBCCC;
(EngineCore_DP0 pid=439476) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=439476) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=439476) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=439476) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=439476) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=439476) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=439476) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=439476) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=439476) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=439476) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=439476) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=439476) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=439476) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=439476) 	mov.b32 	%r169, 0f00000000;
(EngineCore_DP0 pid=439476) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=439476) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=439476) 	mov.b32 	%r170, %r45;
(EngineCore_DP0 pid=439476) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=439476) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=439476) 	add.s32 	%r55, %r4, %r170;
(EngineCore_DP0 pid=439476) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=439476) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=439476) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=439476) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=439476) 	// begin inline asm
(EngineCore_DP0 pid=439476) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=439476) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=439476) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=439476) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=439476) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=439476) 	// end inline asm
(EngineCore_DP0 pid=439476) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=439476) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=439476) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=439476) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=439476) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=439476) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=439476) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=439476) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=439476) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=439476) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=439476) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=439476) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=439476) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=439476) $L__tmp1:
(EngineCore_DP0 pid=439476) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	bar.sync 	0;
(EngineCore_DP0 pid=439476) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=439476) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=439476) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=439476) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=439476) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=439476) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=439476) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=439476) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=439476) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=439476) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=439476) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=439476) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=439476) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=439476) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=439476) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=439476) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=439476) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=439476) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=439476) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	// begin inline asm
(EngineCore_DP0 pid=439476) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=439476) 	// end inline asm
(EngineCore_DP0 pid=439476) 	bar.sync 	0;
(EngineCore_DP0 pid=439476) 	// begin inline asm
(EngineCore_DP0 pid=439476) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=439476) 	// end inline asm
(EngineCore_DP0 pid=439476) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=439476) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=439476) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=439476) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=439476) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=439476) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=439476) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=439476) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=439476) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=439476) 	// begin inline asm
(EngineCore_DP0 pid=439476) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=439476) 	// end inline asm
(EngineCore_DP0 pid=439476) 	bar.sync 	0;
(EngineCore_DP0 pid=439476) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=439476) $L__tmp2:
(EngineCore_DP0 pid=439476) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=439476) 	max.f32 	%r169, %r169, %r73;
(EngineCore_DP0 pid=439476) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=439476) 	add.s32 	%r170, %r170, 4096;
(EngineCore_DP0 pid=439476) 	setp.lt.s32 	%p6, %r170, %r24;
(EngineCore_DP0 pid=439476) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=439476) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=439476) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=439476) 	max.f32 	%r171, %r169, 0f2B8CBCCC;
(EngineCore_DP0 pid=439476) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=439476) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=439476) 	mov.b32 	%r75, 0f42FE0000;
(EngineCore_DP0 pid=439476) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=439476) 	div.full.f32 	%r76, %r171, %r75;
(EngineCore_DP0 pid=439476) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=439476) 	max.f32 	%r74, %r76, 0f37810204;
(EngineCore_DP0 pid=439476) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=439476) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=439476) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=439476) 	// begin inline asm
(EngineCore_DP0 pid=439476) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=439476) 	// end inline asm
(EngineCore_DP0 pid=439476) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=439476) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=439476) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=439476) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=439476) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=439476) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=439476) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=439476) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=439476) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=439476) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=439476) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=439476) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=439476) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=439476) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=439476) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=439476) 	div.full.f32 	%r14, %r75, %r171;
(EngineCore_DP0 pid=439476) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=439476) 	mov.b32 	%r172, 0;
(EngineCore_DP0 pid=439476) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=439476)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=439476) 	.loc	1 279 31                        // quant_slide_tuned_Qwen2.5-7B.py:279:31
(EngineCore_DP0 pid=439476) 	add.s32 	%r81, %r16, %r172;
(EngineCore_DP0 pid=439476) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=439476) 	add.s32 	%r82, %r81, 1;
(EngineCore_DP0 pid=439476) 	setp.lt.s32 	%p17, %r81, %r15;
(EngineCore_DP0 pid=439476) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=439476) 	mul.hi.s32 	%r83, %r82, 1431655766;
(EngineCore_DP0 pid=439476) 	shr.u32 	%r84, %r83, 31;
(EngineCore_DP0 pid=439476) 	add.s32 	%r85, %r83, %r84;
(EngineCore_DP0 pid=439476) 	mul.hi.s32 	%r86, %r81, 1431655766;
(EngineCore_DP0 pid=439476) 	shr.u32 	%r87, %r86, 31;
(EngineCore_DP0 pid=439476) 	add.s32 	%r88, %r86, %r87;
(EngineCore_DP0 pid=439476) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=439476) 	mul.lo.s32 	%r89, %r88, 3;
(EngineCore_DP0 pid=439476) 	mul.lo.s32 	%r90, %r85, 3;
(EngineCore_DP0 pid=439476) 	sub.s32 	%r91, %r82, %r90;
(EngineCore_DP0 pid=439476) 	sub.s32 	%r92, %r81, %r89;
(EngineCore_DP0 pid=439476) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=439476) 	shl.b32 	%r93, %r88, 3;
(EngineCore_DP0 pid=439476) 	shl.b32 	%r94, %r85, 3;
(EngineCore_DP0 pid=439476) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=439476) 	shl.b32 	%r95, %r92, 1;
(EngineCore_DP0 pid=439476) 	shl.b32 	%r96, %r91, 1;
(EngineCore_DP0 pid=439476) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=439476) 	add.s32 	%r97, %r94, %r96;
(EngineCore_DP0 pid=439476) 	add.s32 	%r98, %r93, %r95;
(EngineCore_DP0 pid=439476) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=439476) 	setp.lt.s32 	%p18, %r98, %r23;
(EngineCore_DP0 pid=439476) 	setp.lt.s32 	%p19, %r97, %r23;
(EngineCore_DP0 pid=439476) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=439476) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=439476) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=439476) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=439476) 	mad.wide.s32 	%rd8, %r98, 2, %rd1;
(EngineCore_DP0 pid=439476) 	mad.wide.s32 	%rd9, %r97, 2, %rd1;
(EngineCore_DP0 pid=439476) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=439476) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=439476) 	// begin inline asm
(EngineCore_DP0 pid=439476) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=439476) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=439476) 	// end inline asm
(EngineCore_DP0 pid=439476) 	// begin inline asm
(EngineCore_DP0 pid=439476) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=439476) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=439476) 	// end inline asm
(EngineCore_DP0 pid=439476) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=439476) 	cvt.f32.bf16 	%r99, %rs24;
(EngineCore_DP0 pid=439476) 	cvt.f32.bf16 	%r100, %rs26;
(EngineCore_DP0 pid=439476) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=439476) 	or.b32 	%r101, %r98, 1;
(EngineCore_DP0 pid=439476) 	or.b32 	%r102, %r97, 1;
(EngineCore_DP0 pid=439476) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=439476) 	setp.lt.s32 	%p20, %r101, %r23;
(EngineCore_DP0 pid=439476) 	setp.lt.s32 	%p21, %r102, %r23;
(EngineCore_DP0 pid=439476) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=439476) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=439476) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=439476) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=439476) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=439476) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=439476) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=439476) 	// begin inline asm
(EngineCore_DP0 pid=439476) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=439476) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=439476) 	// end inline asm
(EngineCore_DP0 pid=439476) 	// begin inline asm
(EngineCore_DP0 pid=439476) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=439476) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=439476) 	// end inline asm
(EngineCore_DP0 pid=439476) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=439476) 	cvt.f32.bf16 	%r103, %rs28;
(EngineCore_DP0 pid=439476) 	cvt.f32.bf16 	%r104, %rs30;
(EngineCore_DP0 pid=439476) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=439476) 	add.s32 	%r105, %r98, 2;
(EngineCore_DP0 pid=439476) 	add.s32 	%r106, %r97, 2;
(EngineCore_DP0 pid=439476) 	add.s32 	%r107, %r98, 3;
(EngineCore_DP0 pid=439476) 	add.s32 	%r108, %r97, 3;
(EngineCore_DP0 pid=439476) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=439476) 	setp.lt.s32 	%p22, %r108, %r23;
(EngineCore_DP0 pid=439476) 	setp.lt.s32 	%p23, %r107, %r23;
(EngineCore_DP0 pid=439476) 	setp.lt.s32 	%p24, %r106, %r23;
(EngineCore_DP0 pid=439476) 	setp.lt.s32 	%p25, %r105, %r23;
(EngineCore_DP0 pid=439476) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=439476) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=439476) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=439476) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=439476) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=439476) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=439476) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=439476) 	// begin inline asm
(EngineCore_DP0 pid=439476) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=439476) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=439476) 	// end inline asm
(EngineCore_DP0 pid=439476) 	// begin inline asm
(EngineCore_DP0 pid=439476) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=439476) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=439476) 	// end inline asm
(EngineCore_DP0 pid=439476) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=439476) 	cvt.f32.bf16 	%r109, %rs32;
(EngineCore_DP0 pid=439476) 	cvt.f32.bf16 	%r110, %rs34;
(EngineCore_DP0 pid=439476) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=439476) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=439476) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=439476) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=439476) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=439476) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=439476) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=439476) 	// begin inline asm
(EngineCore_DP0 pid=439476) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=439476) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=439476) 	// end inline asm
(EngineCore_DP0 pid=439476) 	// begin inline asm
(EngineCore_DP0 pid=439476) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=439476) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=439476) 	// end inline asm
(EngineCore_DP0 pid=439476) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=439476) 	cvt.f32.bf16 	%r111, %rs36;
(EngineCore_DP0 pid=439476) 	cvt.f32.bf16 	%r112, %rs38;
(EngineCore_DP0 pid=439476) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=439476) 	mul.f32 	%r113, %r14, %r99;
(EngineCore_DP0 pid=439476) 	mul.f32 	%r114, %r14, %r100;
(EngineCore_DP0 pid=439476) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=439476) 	cvt.rni.f32.f32 	%r115, %r113;
(EngineCore_DP0 pid=439476) 	cvt.rni.f32.f32 	%r116, %r114;
(EngineCore_DP0 pid=439476) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=439476) 	max.f32 	%r117, %r115, 0fC3000000;
(EngineCore_DP0 pid=439476) 	min.f32 	%r118, %r117, 0f42FE0000;
(EngineCore_DP0 pid=439476) 	max.f32 	%r119, %r116, 0fC3000000;
(EngineCore_DP0 pid=439476) 	min.f32 	%r120, %r119, 0f42FE0000;
(EngineCore_DP0 pid=439476) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=439476) 	cvt.rzi.s32.f32 	%r121, %r118;
(EngineCore_DP0 pid=439476) 	cvt.rzi.s32.f32 	%r122, %r120;
(EngineCore_DP0 pid=439476) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=439476) 	and.b32 	%r123, %r121, 255;
(EngineCore_DP0 pid=439476) 	and.b32 	%r124, %r122, 255;
(EngineCore_DP0 pid=439476) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=439476) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=439476) 	mul.f32 	%r126, %r14, %r104;
(EngineCore_DP0 pid=439476) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=439476) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=439476) 	cvt.rni.f32.f32 	%r128, %r126;
(EngineCore_DP0 pid=439476) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=439476) 	mul.f32 	%r129, %r14, %r109;
(EngineCore_DP0 pid=439476) 	mul.f32 	%r130, %r14, %r110;
(EngineCore_DP0 pid=439476) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=439476) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=439476) 	cvt.rni.f32.f32 	%r132, %r130;
(EngineCore_DP0 pid=439476) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=439476) 	mul.f32 	%r133, %r14, %r111;
(EngineCore_DP0 pid=439476) 	mul.f32 	%r134, %r14, %r112;
(EngineCore_DP0 pid=439476) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=439476) 	cvt.rni.f32.f32 	%r135, %r133;
(EngineCore_DP0 pid=439476) 	cvt.rni.f32.f32 	%r136, %r134;
(EngineCore_DP0 pid=439476) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=439476) 	max.f32 	%r137, %r135, 0fC3000000;
(EngineCore_DP0 pid=439476) 	min.f32 	%r138, %r137, 0f42FE0000;
(EngineCore_DP0 pid=439476) 	max.f32 	%r139, %r136, 0fC3000000;
(EngineCore_DP0 pid=439476) 	min.f32 	%r140, %r139, 0f42FE0000;
(EngineCore_DP0 pid=439476) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=439476) 	cvt.rzi.s32.f32 	%r141, %r138;
(EngineCore_DP0 pid=439476) 	cvt.rzi.s32.f32 	%r142, %r140;
(EngineCore_DP0 pid=439476) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=439476) 	max.f32 	%r143, %r131, 0fC3000000;
(EngineCore_DP0 pid=439476) 	max.f32 	%r144, %r127, 0fC3000000;
(EngineCore_DP0 pid=439476) 	min.f32 	%r145, %r144, 0f42FE0000;
(EngineCore_DP0 pid=439476) 	min.f32 	%r146, %r143, 0f42FE0000;
(EngineCore_DP0 pid=439476) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=439476) 	cvt.rzi.s32.f32 	%r147, %r146;
(EngineCore_DP0 pid=439476) 	cvt.rzi.s32.f32 	%r148, %r145;
(EngineCore_DP0 pid=439476) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=439476) 	shl.b32 	%r149, %r148, 8;
(EngineCore_DP0 pid=439476) 	shl.b32 	%r150, %r147, 16;
(EngineCore_DP0 pid=439476) 	and.b32 	%r151, %r150, 16711680;
(EngineCore_DP0 pid=439476) 	and.b32 	%r152, %r149, 65280;
(EngineCore_DP0 pid=439476) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=439476) 	or.b32 	%r153, %r152, %r123;
(EngineCore_DP0 pid=439476) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=439476) 	max.f32 	%r154, %r132, 0fC3000000;
(EngineCore_DP0 pid=439476) 	max.f32 	%r155, %r128, 0fC3000000;
(EngineCore_DP0 pid=439476) 	min.f32 	%r156, %r155, 0f42FE0000;
(EngineCore_DP0 pid=439476) 	min.f32 	%r157, %r154, 0f42FE0000;
(EngineCore_DP0 pid=439476) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=439476) 	cvt.rzi.s32.f32 	%r158, %r157;
(EngineCore_DP0 pid=439476) 	cvt.rzi.s32.f32 	%r159, %r156;
(EngineCore_DP0 pid=439476) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=439476) 	shl.b32 	%r160, %r159, 8;
(EngineCore_DP0 pid=439476) 	shl.b32 	%r161, %r158, 16;
(EngineCore_DP0 pid=439476) 	and.b32 	%r162, %r161, 16711680;
(EngineCore_DP0 pid=439476) 	and.b32 	%r163, %r160, 65280;
(EngineCore_DP0 pid=439476) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=439476) 	or.b32 	%r164, %r163, %r124;
(EngineCore_DP0 pid=439476) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=439476) 	or.b32 	%r165, %r153, %r151;
(EngineCore_DP0 pid=439476) 	or.b32 	%r166, %r164, %r162;
(EngineCore_DP0 pid=439476) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=439476) 	shl.b32 	%r167, %r141, 24;
(EngineCore_DP0 pid=439476) 	shl.b32 	%r168, %r142, 24;
(EngineCore_DP0 pid=439476) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=439476) 	or.b32 	%r78, %r165, %r167;
(EngineCore_DP0 pid=439476) 	or.b32 	%r79, %r166, %r168;
(EngineCore_DP0 pid=439476) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=439476) 	mad.wide.s32 	%rd16, %r81, 4, %rd2;
(EngineCore_DP0 pid=439476) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=439476) 	// begin inline asm
(EngineCore_DP0 pid=439476) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r78, %r79 };
(EngineCore_DP0 pid=439476) 	// end inline asm
(EngineCore_DP0 pid=439476) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=439476) 	add.s32 	%r172, %r172, 1024;
(EngineCore_DP0 pid=439476) 	setp.lt.s32 	%p26, %r172, %r15;
(EngineCore_DP0 pid=439476) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=439476) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=439476) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=439476) 	ret;
(EngineCore_DP0 pid=439476) $L__tmp3:
(EngineCore_DP0 pid=439476) $L__func_end0:
(EngineCore_DP0 pid=439476)                                         // -- End function
(EngineCore_DP0 pid=439476) }
(EngineCore_DP0 pid=439476) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=439476) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=439476) 	.section	.debug_abbrev
(EngineCore_DP0 pid=439476) 	{
(EngineCore_DP0 pid=439476) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=439476) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=439476) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=439476) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=439476) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=439476) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=439476) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=439476) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=439476) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=439476) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=439476) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=439476) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=439476) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=439476) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=439476) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=439476) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=439476) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=439476) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=439476) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=439476) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=439476) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=439476) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=439476) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=439476) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=439476) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=439476) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=439476) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=439476) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=439476) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=439476) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=439476) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=439476) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=439476) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=439476) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=439476) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=439476) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=439476) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=439476) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=439476) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=439476) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=439476) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=439476) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=439476) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=439476) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=439476) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=439476) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=439476) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=439476) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=439476) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=439476) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=439476) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=439476) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=439476) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=439476) 	}
(EngineCore_DP0 pid=439476) 	.section	.debug_info
(EngineCore_DP0 pid=439476) 	{
(EngineCore_DP0 pid=439476) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=439476) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=439476) .b8 0
(EngineCore_DP0 pid=439476) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=439476) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=439476) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=439476) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=439476) .b8 114
(EngineCore_DP0 pid=439476) .b8 105
(EngineCore_DP0 pid=439476) .b8 116
(EngineCore_DP0 pid=439476) .b8 111
(EngineCore_DP0 pid=439476) .b8 110
(EngineCore_DP0 pid=439476) .b8 0
(EngineCore_DP0 pid=439476) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=439476) .b8 0
(EngineCore_DP0 pid=439476) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=439476) .b8 117
(EngineCore_DP0 pid=439476) .b8 97
(EngineCore_DP0 pid=439476) .b8 110
(EngineCore_DP0 pid=439476) .b8 116
(EngineCore_DP0 pid=439476) .b8 95
(EngineCore_DP0 pid=439476) .b8 115
(EngineCore_DP0 pid=439476) .b8 108
(EngineCore_DP0 pid=439476) .b8 105
(EngineCore_DP0 pid=439476) .b8 100
(EngineCore_DP0 pid=439476) .b8 101
(EngineCore_DP0 pid=439476) .b8 95
(EngineCore_DP0 pid=439476) .b8 116
(EngineCore_DP0 pid=439476) .b8 117
(EngineCore_DP0 pid=439476) .b8 110
(EngineCore_DP0 pid=439476) .b8 101
(EngineCore_DP0 pid=439476) .b8 100
(EngineCore_DP0 pid=439476) .b8 95
(EngineCore_DP0 pid=439476) .b8 81
(EngineCore_DP0 pid=439476) .b8 119
(EngineCore_DP0 pid=439476) .b8 101
(EngineCore_DP0 pid=439476) .b8 110
(EngineCore_DP0 pid=439476) .b8 50
(EngineCore_DP0 pid=439476) .b8 46
(EngineCore_DP0 pid=439476) .b8 53
(EngineCore_DP0 pid=439476) .b8 45
(EngineCore_DP0 pid=439476) .b8 55
(EngineCore_DP0 pid=439476) .b8 66
(EngineCore_DP0 pid=439476) .b8 46
(EngineCore_DP0 pid=439476) .b8 112
(EngineCore_DP0 pid=439476) .b8 121
(EngineCore_DP0 pid=439476) .b8 0
(EngineCore_DP0 pid=439476) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=439476) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=439476) .b8 114
(EngineCore_DP0 pid=439476) .b8 111
(EngineCore_DP0 pid=439476) .b8 111
(EngineCore_DP0 pid=439476) .b8 116
(EngineCore_DP0 pid=439476) .b8 47
(EngineCore_DP0 pid=439476) .b8 118
(EngineCore_DP0 pid=439476) .b8 108
(EngineCore_DP0 pid=439476) .b8 108
(EngineCore_DP0 pid=439476) .b8 109
(EngineCore_DP0 pid=439476) .b8 98
(EngineCore_DP0 pid=439476) .b8 101
(EngineCore_DP0 pid=439476) .b8 110
(EngineCore_DP0 pid=439476) .b8 99
(EngineCore_DP0 pid=439476) .b8 104
(EngineCore_DP0 pid=439476) .b8 47
(EngineCore_DP0 pid=439476) .b8 115
(EngineCore_DP0 pid=439476) .b8 108
(EngineCore_DP0 pid=439476) .b8 105
(EngineCore_DP0 pid=439476) .b8 100
(EngineCore_DP0 pid=439476) .b8 101
(EngineCore_DP0 pid=439476) .b8 115
(EngineCore_DP0 pid=439476) .b8 112
(EngineCore_DP0 pid=439476) .b8 97
(EngineCore_DP0 pid=439476) .b8 114
(EngineCore_DP0 pid=439476) .b8 115
(EngineCore_DP0 pid=439476) .b8 101
(EngineCore_DP0 pid=439476) .b8 47
(EngineCore_DP0 pid=439476) .b8 99
(EngineCore_DP0 pid=439476) .b8 115
(EngineCore_DP0 pid=439476) .b8 114
(EngineCore_DP0 pid=439476) .b8 99
(EngineCore_DP0 pid=439476) .b8 47
(EngineCore_DP0 pid=439476) .b8 102
(EngineCore_DP0 pid=439476) .b8 117
(EngineCore_DP0 pid=439476) .b8 115
(EngineCore_DP0 pid=439476) .b8 101
(EngineCore_DP0 pid=439476) .b8 100
(EngineCore_DP0 pid=439476) .b8 95
(EngineCore_DP0 pid=439476) .b8 113
(EngineCore_DP0 pid=439476) .b8 117
(EngineCore_DP0 pid=439476) .b8 97
(EngineCore_DP0 pid=439476) .b8 110
(EngineCore_DP0 pid=439476) .b8 116
(EngineCore_DP0 pid=439476) .b8 95
(EngineCore_DP0 pid=439476) .b8 115
(EngineCore_DP0 pid=439476) .b8 108
(EngineCore_DP0 pid=439476) .b8 105
(EngineCore_DP0 pid=439476) .b8 100
(EngineCore_DP0 pid=439476) .b8 101
(EngineCore_DP0 pid=439476) .b8 95
(EngineCore_DP0 pid=439476) .b8 116
(EngineCore_DP0 pid=439476) .b8 114
(EngineCore_DP0 pid=439476) .b8 105
(EngineCore_DP0 pid=439476) .b8 116
(EngineCore_DP0 pid=439476) .b8 111
(EngineCore_DP0 pid=439476) .b8 110
(EngineCore_DP0 pid=439476) .b8 47
(EngineCore_DP0 pid=439476) .b8 98
(EngineCore_DP0 pid=439476) .b8 117
(EngineCore_DP0 pid=439476) .b8 105
(EngineCore_DP0 pid=439476) .b8 108
(EngineCore_DP0 pid=439476) .b8 100
(EngineCore_DP0 pid=439476) .b8 47
(EngineCore_DP0 pid=439476) .b8 71
(EngineCore_DP0 pid=439476) .b8 66
(EngineCore_DP0 pid=439476) .b8 49
(EngineCore_DP0 pid=439476) .b8 48
(EngineCore_DP0 pid=439476) .b8 95
(EngineCore_DP0 pid=439476) .b8 99
(EngineCore_DP0 pid=439476) .b8 99
(EngineCore_DP0 pid=439476) .b8 49
(EngineCore_DP0 pid=439476) .b8 50
(EngineCore_DP0 pid=439476) .b8 49
(EngineCore_DP0 pid=439476) .b8 95
(EngineCore_DP0 pid=439476) .b8 112
(EngineCore_DP0 pid=439476) .b8 121
(EngineCore_DP0 pid=439476) .b8 51
(EngineCore_DP0 pid=439476) .b8 49
(EngineCore_DP0 pid=439476) .b8 50
(EngineCore_DP0 pid=439476) .b8 95
(EngineCore_DP0 pid=439476) .b8 99
(EngineCore_DP0 pid=439476) .b8 117
(EngineCore_DP0 pid=439476) .b8 49
(EngineCore_DP0 pid=439476) .b8 50
(EngineCore_DP0 pid=439476) .b8 57
(EngineCore_DP0 pid=439476) .b8 95
(EngineCore_DP0 pid=439476) .b8 97
(EngineCore_DP0 pid=439476) .b8 97
(EngineCore_DP0 pid=439476) .b8 114
(EngineCore_DP0 pid=439476) .b8 99
(EngineCore_DP0 pid=439476) .b8 104
(EngineCore_DP0 pid=439476) .b8 54
(EngineCore_DP0 pid=439476) .b8 52
(EngineCore_DP0 pid=439476) .b8 0
(EngineCore_DP0 pid=439476) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=439476) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=439476) .b8 113
(EngineCore_DP0 pid=439476) .b8 117
(EngineCore_DP0 pid=439476) .b8 97
(EngineCore_DP0 pid=439476) .b8 110
(EngineCore_DP0 pid=439476) .b8 116
(EngineCore_DP0 pid=439476) .b8 95
(EngineCore_DP0 pid=439476) .b8 115
(EngineCore_DP0 pid=439476) .b8 108
(EngineCore_DP0 pid=439476) .b8 105
(EngineCore_DP0 pid=439476) .b8 100
(EngineCore_DP0 pid=439476) .b8 101
(EngineCore_DP0 pid=439476) .b8 95
(EngineCore_DP0 pid=439476) .b8 105
(EngineCore_DP0 pid=439476) .b8 110
(EngineCore_DP0 pid=439476) .b8 116
(EngineCore_DP0 pid=439476) .b8 56
(EngineCore_DP0 pid=439476) .b8 95
(EngineCore_DP0 pid=439476) .b8 107
(EngineCore_DP0 pid=439476) .b8 101
(EngineCore_DP0 pid=439476) .b8 114
(EngineCore_DP0 pid=439476) .b8 110
(EngineCore_DP0 pid=439476) .b8 101
(EngineCore_DP0 pid=439476) .b8 108
(EngineCore_DP0 pid=439476) .b8 0
(EngineCore_DP0 pid=439476) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=439476) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=439476) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=439476) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=439476) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=439476) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=439476) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=439476) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=439476) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=439476) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=439476) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=439476) .b8 1
(EngineCore_DP0 pid=439476) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=439476) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=439476) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=439476) 	}
(EngineCore_DP0 pid=439476) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=439476) 
(EngineCore_DP0 pid=439476) ================================================================
(EngineCore_DP0 pid=439476) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=439476) 
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpfy0ndqfk.ptx', '-o', '/tmp/tmpfy0ndqfk.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866] 
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866] 
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866] 
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpfy0ndqfk.ptx -o /tmp/tmpfy0ndqfk.ptx.o
(EngineCore_DP0 pid=439476) ERROR 01-25 20:50:40 [core.py:866] 

STDERR:
[2026-01-25 20:49:31] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:49:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:49:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:49:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:49:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:49:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:49:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:49:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:49:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:49:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:49:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:49:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:49:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:49:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:49:34] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:49:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:49:34] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:49:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:49:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:49:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:49:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:49:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:49:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:49:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:49:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:49:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:49:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:49:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=439476) [2026-01-25 20:49:35] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=439476) [2026-01-25 20:49:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=439476) [2026-01-25 20:49:35] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=439476) [2026-01-25 20:49:35] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=439476) [2026-01-25 20:49:35] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=439476) [2026-01-25 20:49:35] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=439476) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=439476) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.62s/it]
(EngineCore_DP0 pid=439476) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.91s/it]
(EngineCore_DP0 pid=439476) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.41s/it]
(EngineCore_DP0 pid=439476) 
(EngineCore_DP0 pid=439476) [2026-01-25 20:50:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=439476) [2026-01-25 20:50:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=439476) [2026-01-25 20:50:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=439476) [2026-01-25 20:50:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=439476) [2026-01-25 20:50:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=439476) [2026-01-25 20:50:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=439476) [2026-01-25 20:50:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=439476) [2026-01-25 20:50:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=439476) Process EngineCore_DP0:
(EngineCore_DP0 pid=439476) Traceback (most recent call last):
(EngineCore_DP0 pid=439476)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=439476)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=439476)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=439476)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=439476) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpfy0ndqfk.ptx', '-o', '/tmp/tmpfy0ndqfk.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=439476) 
(EngineCore_DP0 pid=439476) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=439476) 
(EngineCore_DP0 pid=439476) Traceback (most recent call last):
(EngineCore_DP0 pid=439476)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=439476)     self.run()
(EngineCore_DP0 pid=439476)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=439476)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=439476)     raise e
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=439476)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=439476)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=439476)     super().__init__(
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=439476)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=439476)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=439476)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=439476)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=439476)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=439476)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=439476)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=439476)     return func(*args, **kwargs)
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=439476)     return func(*args, **kwargs)
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=439476)     self.model_runner.profile_run()
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=439476)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=439476)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=439476)     return func(*args, **kwargs)
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=439476)     outputs = self.model(
(EngineCore_DP0 pid=439476)               ^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=439476)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=439476)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=439476)     hidden_states = self.model(
(EngineCore_DP0 pid=439476)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=439476)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=439476)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=439476)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=439476)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=439476)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=439476)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=439476)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=439476)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=439476)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=439476)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=439476)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=439476)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=439476)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=439476)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=439476)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=439476)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=439476)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=439476)     return self._linear_fn(
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=439476)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=439476)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=439476)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=439476)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=439476)     return fn(input, L)
(EngineCore_DP0 pid=439476)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=439476)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=439476)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=439476)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=439476)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=439476)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=439476)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=439476)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=439476)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=439476)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=439476)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=439476)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=439476)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=439476)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=439476)     raise PTXASError(error)
(EngineCore_DP0 pid=439476) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=439476) `ptxas` stderr:
(EngineCore_DP0 pid=439476) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=439476) 
(EngineCore_DP0 pid=439476) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpfy0ndqfk.ptx -o /tmp/tmpfy0ndqfk.ptx.o
(EngineCore_DP0 pid=439476) 
[rank0]:[W125 20:50:40.653281076 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 20:50:42
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:50:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:50:47 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=440719) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=440719) 
(EngineCore_DP0 pid=440719) 
(EngineCore_DP0 pid=440719) ================================================================
(EngineCore_DP0 pid=440719) Internal Triton PTX codegen error
(EngineCore_DP0 pid=440719) `ptxas` stderr:
(EngineCore_DP0 pid=440719) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=440719) 
(EngineCore_DP0 pid=440719) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmplfsm4khk.ptx -o /tmp/tmplfsm4khk.ptx.o
(EngineCore_DP0 pid=440719) 
(EngineCore_DP0 pid=440719) 
(EngineCore_DP0 pid=440719) //
(EngineCore_DP0 pid=440719) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=440719) //
(EngineCore_DP0 pid=440719) 
(EngineCore_DP0 pid=440719) .version 8.7
(EngineCore_DP0 pid=440719) .target sm_121a
(EngineCore_DP0 pid=440719) .address_size 64
(EngineCore_DP0 pid=440719) 
(EngineCore_DP0 pid=440719) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=440719) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=440719)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=440719) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=440719) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=440719) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=440719) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=440719) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=440719) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=440719) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=440719) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=440719) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=440719) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=440719) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=440719) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=440719) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=440719) )
(EngineCore_DP0 pid=440719) .reqntid 512
(EngineCore_DP0 pid=440719) {
(EngineCore_DP0 pid=440719) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=440719) 	.reg .b16 	%rs<40>;
(EngineCore_DP0 pid=440719) 	.reg .b32 	%r<173>;
(EngineCore_DP0 pid=440719) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=440719) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=440719) $L__func_begin0:
(EngineCore_DP0 pid=440719) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=440719) 
(EngineCore_DP0 pid=440719) // %bb.0:
(EngineCore_DP0 pid=440719) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=440719) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=440719) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=440719) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=440719) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=440719) $L__tmp0:
(EngineCore_DP0 pid=440719) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=440719) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=440719) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=440719) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=440719) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=440719) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=440719) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=440719) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=440719) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=440719) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=440719) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=440719) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=440719) 	mov.b32 	%r171, 0f2B8CBCCC;
(EngineCore_DP0 pid=440719) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=440719) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=440719) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=440719) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=440719) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=440719) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=440719) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=440719) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=440719) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=440719) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=440719) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=440719) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=440719) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=440719) 	mov.b32 	%r169, 0f00000000;
(EngineCore_DP0 pid=440719) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=440719) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=440719) 	mov.b32 	%r170, %r45;
(EngineCore_DP0 pid=440719) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=440719) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=440719) 	add.s32 	%r55, %r4, %r170;
(EngineCore_DP0 pid=440719) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=440719) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=440719) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=440719) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=440719) 	// begin inline asm
(EngineCore_DP0 pid=440719) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=440719) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=440719) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=440719) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=440719) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=440719) 	// end inline asm
(EngineCore_DP0 pid=440719) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=440719) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=440719) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=440719) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=440719) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=440719) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=440719) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=440719) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=440719) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=440719) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=440719) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=440719) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=440719) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=440719) $L__tmp1:
(EngineCore_DP0 pid=440719) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	bar.sync 	0;
(EngineCore_DP0 pid=440719) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=440719) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=440719) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=440719) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=440719) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=440719) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=440719) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=440719) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=440719) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=440719) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=440719) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=440719) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=440719) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=440719) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=440719) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=440719) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=440719) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=440719) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=440719) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	// begin inline asm
(EngineCore_DP0 pid=440719) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=440719) 	// end inline asm
(EngineCore_DP0 pid=440719) 	bar.sync 	0;
(EngineCore_DP0 pid=440719) 	// begin inline asm
(EngineCore_DP0 pid=440719) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=440719) 	// end inline asm
(EngineCore_DP0 pid=440719) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=440719) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=440719) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=440719) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=440719) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=440719) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=440719) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=440719) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=440719) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=440719) 	// begin inline asm
(EngineCore_DP0 pid=440719) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=440719) 	// end inline asm
(EngineCore_DP0 pid=440719) 	bar.sync 	0;
(EngineCore_DP0 pid=440719) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=440719) $L__tmp2:
(EngineCore_DP0 pid=440719) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=440719) 	max.f32 	%r169, %r169, %r73;
(EngineCore_DP0 pid=440719) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=440719) 	add.s32 	%r170, %r170, 4096;
(EngineCore_DP0 pid=440719) 	setp.lt.s32 	%p6, %r170, %r24;
(EngineCore_DP0 pid=440719) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=440719) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=440719) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=440719) 	max.f32 	%r171, %r169, 0f2B8CBCCC;
(EngineCore_DP0 pid=440719) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=440719) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=440719) 	mov.b32 	%r75, 0f42FE0000;
(EngineCore_DP0 pid=440719) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=440719) 	div.full.f32 	%r76, %r171, %r75;
(EngineCore_DP0 pid=440719) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=440719) 	max.f32 	%r74, %r76, 0f37810204;
(EngineCore_DP0 pid=440719) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=440719) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=440719) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=440719) 	// begin inline asm
(EngineCore_DP0 pid=440719) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=440719) 	// end inline asm
(EngineCore_DP0 pid=440719) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=440719) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=440719) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=440719) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=440719) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=440719) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=440719) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=440719) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=440719) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=440719) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=440719) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=440719) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=440719) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=440719) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=440719) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=440719) 	div.full.f32 	%r14, %r75, %r171;
(EngineCore_DP0 pid=440719) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=440719) 	mov.b32 	%r172, 0;
(EngineCore_DP0 pid=440719) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=440719)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=440719) 	.loc	1 279 31                        // quant_slide_tuned_Qwen2.5-7B.py:279:31
(EngineCore_DP0 pid=440719) 	add.s32 	%r81, %r16, %r172;
(EngineCore_DP0 pid=440719) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=440719) 	add.s32 	%r82, %r81, 1;
(EngineCore_DP0 pid=440719) 	setp.lt.s32 	%p17, %r81, %r15;
(EngineCore_DP0 pid=440719) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=440719) 	mul.hi.s32 	%r83, %r82, 1431655766;
(EngineCore_DP0 pid=440719) 	shr.u32 	%r84, %r83, 31;
(EngineCore_DP0 pid=440719) 	add.s32 	%r85, %r83, %r84;
(EngineCore_DP0 pid=440719) 	mul.hi.s32 	%r86, %r81, 1431655766;
(EngineCore_DP0 pid=440719) 	shr.u32 	%r87, %r86, 31;
(EngineCore_DP0 pid=440719) 	add.s32 	%r88, %r86, %r87;
(EngineCore_DP0 pid=440719) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=440719) 	mul.lo.s32 	%r89, %r88, 3;
(EngineCore_DP0 pid=440719) 	mul.lo.s32 	%r90, %r85, 3;
(EngineCore_DP0 pid=440719) 	sub.s32 	%r91, %r82, %r90;
(EngineCore_DP0 pid=440719) 	sub.s32 	%r92, %r81, %r89;
(EngineCore_DP0 pid=440719) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=440719) 	shl.b32 	%r93, %r88, 3;
(EngineCore_DP0 pid=440719) 	shl.b32 	%r94, %r85, 3;
(EngineCore_DP0 pid=440719) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=440719) 	shl.b32 	%r95, %r92, 1;
(EngineCore_DP0 pid=440719) 	shl.b32 	%r96, %r91, 1;
(EngineCore_DP0 pid=440719) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=440719) 	add.s32 	%r97, %r94, %r96;
(EngineCore_DP0 pid=440719) 	add.s32 	%r98, %r93, %r95;
(EngineCore_DP0 pid=440719) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=440719) 	setp.lt.s32 	%p18, %r98, %r23;
(EngineCore_DP0 pid=440719) 	setp.lt.s32 	%p19, %r97, %r23;
(EngineCore_DP0 pid=440719) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=440719) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=440719) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=440719) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=440719) 	mad.wide.s32 	%rd8, %r98, 2, %rd1;
(EngineCore_DP0 pid=440719) 	mad.wide.s32 	%rd9, %r97, 2, %rd1;
(EngineCore_DP0 pid=440719) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=440719) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=440719) 	// begin inline asm
(EngineCore_DP0 pid=440719) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=440719) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=440719) 	// end inline asm
(EngineCore_DP0 pid=440719) 	// begin inline asm
(EngineCore_DP0 pid=440719) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=440719) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=440719) 	// end inline asm
(EngineCore_DP0 pid=440719) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=440719) 	cvt.f32.bf16 	%r99, %rs24;
(EngineCore_DP0 pid=440719) 	cvt.f32.bf16 	%r100, %rs26;
(EngineCore_DP0 pid=440719) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=440719) 	or.b32 	%r101, %r98, 1;
(EngineCore_DP0 pid=440719) 	or.b32 	%r102, %r97, 1;
(EngineCore_DP0 pid=440719) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=440719) 	setp.lt.s32 	%p20, %r101, %r23;
(EngineCore_DP0 pid=440719) 	setp.lt.s32 	%p21, %r102, %r23;
(EngineCore_DP0 pid=440719) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=440719) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=440719) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=440719) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=440719) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=440719) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=440719) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=440719) 	// begin inline asm
(EngineCore_DP0 pid=440719) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=440719) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=440719) 	// end inline asm
(EngineCore_DP0 pid=440719) 	// begin inline asm
(EngineCore_DP0 pid=440719) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=440719) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=440719) 	// end inline asm
(EngineCore_DP0 pid=440719) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=440719) 	cvt.f32.bf16 	%r103, %rs28;
(EngineCore_DP0 pid=440719) 	cvt.f32.bf16 	%r104, %rs30;
(EngineCore_DP0 pid=440719) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=440719) 	add.s32 	%r105, %r98, 2;
(EngineCore_DP0 pid=440719) 	add.s32 	%r106, %r97, 2;
(EngineCore_DP0 pid=440719) 	add.s32 	%r107, %r98, 3;
(EngineCore_DP0 pid=440719) 	add.s32 	%r108, %r97, 3;
(EngineCore_DP0 pid=440719) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=440719) 	setp.lt.s32 	%p22, %r108, %r23;
(EngineCore_DP0 pid=440719) 	setp.lt.s32 	%p23, %r107, %r23;
(EngineCore_DP0 pid=440719) 	setp.lt.s32 	%p24, %r106, %r23;
(EngineCore_DP0 pid=440719) 	setp.lt.s32 	%p25, %r105, %r23;
(EngineCore_DP0 pid=440719) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=440719) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=440719) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=440719) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=440719) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=440719) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=440719) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=440719) 	// begin inline asm
(EngineCore_DP0 pid=440719) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=440719) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=440719) 	// end inline asm
(EngineCore_DP0 pid=440719) 	// begin inline asm
(EngineCore_DP0 pid=440719) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=440719) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=440719) 	// end inline asm
(EngineCore_DP0 pid=440719) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=440719) 	cvt.f32.bf16 	%r109, %rs32;
(EngineCore_DP0 pid=440719) 	cvt.f32.bf16 	%r110, %rs34;
(EngineCore_DP0 pid=440719) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=440719) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=440719) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=440719) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=440719) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=440719) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=440719) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=440719) 	// begin inline asm
(EngineCore_DP0 pid=440719) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=440719) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=440719) 	// end inline asm
(EngineCore_DP0 pid=440719) 	// begin inline asm
(EngineCore_DP0 pid=440719) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=440719) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=440719) 	// end inline asm
(EngineCore_DP0 pid=440719) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=440719) 	cvt.f32.bf16 	%r111, %rs36;
(EngineCore_DP0 pid=440719) 	cvt.f32.bf16 	%r112, %rs38;
(EngineCore_DP0 pid=440719) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=440719) 	mul.f32 	%r113, %r14, %r99;
(EngineCore_DP0 pid=440719) 	mul.f32 	%r114, %r14, %r100;
(EngineCore_DP0 pid=440719) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=440719) 	cvt.rni.f32.f32 	%r115, %r113;
(EngineCore_DP0 pid=440719) 	cvt.rni.f32.f32 	%r116, %r114;
(EngineCore_DP0 pid=440719) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=440719) 	max.f32 	%r117, %r115, 0fC3000000;
(EngineCore_DP0 pid=440719) 	min.f32 	%r118, %r117, 0f42FE0000;
(EngineCore_DP0 pid=440719) 	max.f32 	%r119, %r116, 0fC3000000;
(EngineCore_DP0 pid=440719) 	min.f32 	%r120, %r119, 0f42FE0000;
(EngineCore_DP0 pid=440719) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=440719) 	cvt.rzi.s32.f32 	%r121, %r118;
(EngineCore_DP0 pid=440719) 	cvt.rzi.s32.f32 	%r122, %r120;
(EngineCore_DP0 pid=440719) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=440719) 	and.b32 	%r123, %r121, 255;
(EngineCore_DP0 pid=440719) 	and.b32 	%r124, %r122, 255;
(EngineCore_DP0 pid=440719) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=440719) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=440719) 	mul.f32 	%r126, %r14, %r104;
(EngineCore_DP0 pid=440719) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=440719) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=440719) 	cvt.rni.f32.f32 	%r128, %r126;
(EngineCore_DP0 pid=440719) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=440719) 	mul.f32 	%r129, %r14, %r109;
(EngineCore_DP0 pid=440719) 	mul.f32 	%r130, %r14, %r110;
(EngineCore_DP0 pid=440719) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=440719) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=440719) 	cvt.rni.f32.f32 	%r132, %r130;
(EngineCore_DP0 pid=440719) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=440719) 	mul.f32 	%r133, %r14, %r111;
(EngineCore_DP0 pid=440719) 	mul.f32 	%r134, %r14, %r112;
(EngineCore_DP0 pid=440719) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=440719) 	cvt.rni.f32.f32 	%r135, %r133;
(EngineCore_DP0 pid=440719) 	cvt.rni.f32.f32 	%r136, %r134;
(EngineCore_DP0 pid=440719) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=440719) 	max.f32 	%r137, %r135, 0fC3000000;
(EngineCore_DP0 pid=440719) 	min.f32 	%r138, %r137, 0f42FE0000;
(EngineCore_DP0 pid=440719) 	max.f32 	%r139, %r136, 0fC3000000;
(EngineCore_DP0 pid=440719) 	min.f32 	%r140, %r139, 0f42FE0000;
(EngineCore_DP0 pid=440719) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=440719) 	cvt.rzi.s32.f32 	%r141, %r138;
(EngineCore_DP0 pid=440719) 	cvt.rzi.s32.f32 	%r142, %r140;
(EngineCore_DP0 pid=440719) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=440719) 	max.f32 	%r143, %r131, 0fC3000000;
(EngineCore_DP0 pid=440719) 	max.f32 	%r144, %r127, 0fC3000000;
(EngineCore_DP0 pid=440719) 	min.f32 	%r145, %r144, 0f42FE0000;
(EngineCore_DP0 pid=440719) 	min.f32 	%r146, %r143, 0f42FE0000;
(EngineCore_DP0 pid=440719) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=440719) 	cvt.rzi.s32.f32 	%r147, %r146;
(EngineCore_DP0 pid=440719) 	cvt.rzi.s32.f32 	%r148, %r145;
(EngineCore_DP0 pid=440719) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=440719) 	shl.b32 	%r149, %r148, 8;
(EngineCore_DP0 pid=440719) 	shl.b32 	%r150, %r147, 16;
(EngineCore_DP0 pid=440719) 	and.b32 	%r151, %r150, 16711680;
(EngineCore_DP0 pid=440719) 	and.b32 	%r152, %r149, 65280;
(EngineCore_DP0 pid=440719) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=440719) 	or.b32 	%r153, %r152, %r123;
(EngineCore_DP0 pid=440719) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=440719) 	max.f32 	%r154, %r132, 0fC3000000;
(EngineCore_DP0 pid=440719) 	max.f32 	%r155, %r128, 0fC3000000;
(EngineCore_DP0 pid=440719) 	min.f32 	%r156, %r155, 0f42FE0000;
(EngineCore_DP0 pid=440719) 	min.f32 	%r157, %r154, 0f42FE0000;
(EngineCore_DP0 pid=440719) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=440719) 	cvt.rzi.s32.f32 	%r158, %r157;
(EngineCore_DP0 pid=440719) 	cvt.rzi.s32.f32 	%r159, %r156;
(EngineCore_DP0 pid=440719) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=440719) 	shl.b32 	%r160, %r159, 8;
(EngineCore_DP0 pid=440719) 	shl.b32 	%r161, %r158, 16;
(EngineCore_DP0 pid=440719) 	and.b32 	%r162, %r161, 16711680;
(EngineCore_DP0 pid=440719) 	and.b32 	%r163, %r160, 65280;
(EngineCore_DP0 pid=440719) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=440719) 	or.b32 	%r164, %r163, %r124;
(EngineCore_DP0 pid=440719) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=440719) 	or.b32 	%r165, %r153, %r151;
(EngineCore_DP0 pid=440719) 	or.b32 	%r166, %r164, %r162;
(EngineCore_DP0 pid=440719) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=440719) 	shl.b32 	%r167, %r141, 24;
(EngineCore_DP0 pid=440719) 	shl.b32 	%r168, %r142, 24;
(EngineCore_DP0 pid=440719) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=440719) 	or.b32 	%r78, %r165, %r167;
(EngineCore_DP0 pid=440719) 	or.b32 	%r79, %r166, %r168;
(EngineCore_DP0 pid=440719) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=440719) 	mad.wide.s32 	%rd16, %r81, 4, %rd2;
(EngineCore_DP0 pid=440719) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=440719) 	// begin inline asm
(EngineCore_DP0 pid=440719) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r78, %r79 };
(EngineCore_DP0 pid=440719) 	// end inline asm
(EngineCore_DP0 pid=440719) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=440719) 	add.s32 	%r172, %r172, 1024;
(EngineCore_DP0 pid=440719) 	setp.lt.s32 	%p26, %r172, %r15;
(EngineCore_DP0 pid=440719) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=440719) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=440719) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=440719) 	ret;
(EngineCore_DP0 pid=440719) $L__tmp3:
(EngineCore_DP0 pid=440719) $L__func_end0:
(EngineCore_DP0 pid=440719)                                         // -- End function
(EngineCore_DP0 pid=440719) }
(EngineCore_DP0 pid=440719) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=440719) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=440719) 	.section	.debug_abbrev
(EngineCore_DP0 pid=440719) 	{
(EngineCore_DP0 pid=440719) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=440719) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=440719) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=440719) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=440719) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=440719) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=440719) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=440719) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=440719) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=440719) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=440719) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=440719) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=440719) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=440719) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=440719) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=440719) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=440719) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=440719) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=440719) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=440719) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=440719) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=440719) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=440719) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=440719) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=440719) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=440719) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=440719) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=440719) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=440719) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=440719) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=440719) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=440719) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=440719) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=440719) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=440719) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=440719) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=440719) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=440719) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=440719) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=440719) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=440719) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=440719) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=440719) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=440719) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=440719) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=440719) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=440719) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=440719) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=440719) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=440719) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=440719) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=440719) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=440719) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=440719) 	}
(EngineCore_DP0 pid=440719) 	.section	.debug_info
(EngineCore_DP0 pid=440719) 	{
(EngineCore_DP0 pid=440719) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=440719) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=440719) .b8 0
(EngineCore_DP0 pid=440719) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=440719) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=440719) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=440719) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=440719) .b8 114
(EngineCore_DP0 pid=440719) .b8 105
(EngineCore_DP0 pid=440719) .b8 116
(EngineCore_DP0 pid=440719) .b8 111
(EngineCore_DP0 pid=440719) .b8 110
(EngineCore_DP0 pid=440719) .b8 0
(EngineCore_DP0 pid=440719) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=440719) .b8 0
(EngineCore_DP0 pid=440719) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=440719) .b8 117
(EngineCore_DP0 pid=440719) .b8 97
(EngineCore_DP0 pid=440719) .b8 110
(EngineCore_DP0 pid=440719) .b8 116
(EngineCore_DP0 pid=440719) .b8 95
(EngineCore_DP0 pid=440719) .b8 115
(EngineCore_DP0 pid=440719) .b8 108
(EngineCore_DP0 pid=440719) .b8 105
(EngineCore_DP0 pid=440719) .b8 100
(EngineCore_DP0 pid=440719) .b8 101
(EngineCore_DP0 pid=440719) .b8 95
(EngineCore_DP0 pid=440719) .b8 116
(EngineCore_DP0 pid=440719) .b8 117
(EngineCore_DP0 pid=440719) .b8 110
(EngineCore_DP0 pid=440719) .b8 101
(EngineCore_DP0 pid=440719) .b8 100
(EngineCore_DP0 pid=440719) .b8 95
(EngineCore_DP0 pid=440719) .b8 81
(EngineCore_DP0 pid=440719) .b8 119
(EngineCore_DP0 pid=440719) .b8 101
(EngineCore_DP0 pid=440719) .b8 110
(EngineCore_DP0 pid=440719) .b8 50
(EngineCore_DP0 pid=440719) .b8 46
(EngineCore_DP0 pid=440719) .b8 53
(EngineCore_DP0 pid=440719) .b8 45
(EngineCore_DP0 pid=440719) .b8 55
(EngineCore_DP0 pid=440719) .b8 66
(EngineCore_DP0 pid=440719) .b8 46
(EngineCore_DP0 pid=440719) .b8 112
(EngineCore_DP0 pid=440719) .b8 121
(EngineCore_DP0 pid=440719) .b8 0
(EngineCore_DP0 pid=440719) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=440719) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=440719) .b8 114
(EngineCore_DP0 pid=440719) .b8 111
(EngineCore_DP0 pid=440719) .b8 111
(EngineCore_DP0 pid=440719) .b8 116
(EngineCore_DP0 pid=440719) .b8 47
(EngineCore_DP0 pid=440719) .b8 118
(EngineCore_DP0 pid=440719) .b8 108
(EngineCore_DP0 pid=440719) .b8 108
(EngineCore_DP0 pid=440719) .b8 109
(EngineCore_DP0 pid=440719) .b8 98
(EngineCore_DP0 pid=440719) .b8 101
(EngineCore_DP0 pid=440719) .b8 110
(EngineCore_DP0 pid=440719) .b8 99
(EngineCore_DP0 pid=440719) .b8 104
(EngineCore_DP0 pid=440719) .b8 47
(EngineCore_DP0 pid=440719) .b8 115
(EngineCore_DP0 pid=440719) .b8 108
(EngineCore_DP0 pid=440719) .b8 105
(EngineCore_DP0 pid=440719) .b8 100
(EngineCore_DP0 pid=440719) .b8 101
(EngineCore_DP0 pid=440719) .b8 115
(EngineCore_DP0 pid=440719) .b8 112
(EngineCore_DP0 pid=440719) .b8 97
(EngineCore_DP0 pid=440719) .b8 114
(EngineCore_DP0 pid=440719) .b8 115
(EngineCore_DP0 pid=440719) .b8 101
(EngineCore_DP0 pid=440719) .b8 47
(EngineCore_DP0 pid=440719) .b8 99
(EngineCore_DP0 pid=440719) .b8 115
(EngineCore_DP0 pid=440719) .b8 114
(EngineCore_DP0 pid=440719) .b8 99
(EngineCore_DP0 pid=440719) .b8 47
(EngineCore_DP0 pid=440719) .b8 102
(EngineCore_DP0 pid=440719) .b8 117
(EngineCore_DP0 pid=440719) .b8 115
(EngineCore_DP0 pid=440719) .b8 101
(EngineCore_DP0 pid=440719) .b8 100
(EngineCore_DP0 pid=440719) .b8 95
(EngineCore_DP0 pid=440719) .b8 113
(EngineCore_DP0 pid=440719) .b8 117
(EngineCore_DP0 pid=440719) .b8 97
(EngineCore_DP0 pid=440719) .b8 110
(EngineCore_DP0 pid=440719) .b8 116
(EngineCore_DP0 pid=440719) .b8 95
(EngineCore_DP0 pid=440719) .b8 115
(EngineCore_DP0 pid=440719) .b8 108
(EngineCore_DP0 pid=440719) .b8 105
(EngineCore_DP0 pid=440719) .b8 100
(EngineCore_DP0 pid=440719) .b8 101
(EngineCore_DP0 pid=440719) .b8 95
(EngineCore_DP0 pid=440719) .b8 116
(EngineCore_DP0 pid=440719) .b8 114
(EngineCore_DP0 pid=440719) .b8 105
(EngineCore_DP0 pid=440719) .b8 116
(EngineCore_DP0 pid=440719) .b8 111
(EngineCore_DP0 pid=440719) .b8 110
(EngineCore_DP0 pid=440719) .b8 47
(EngineCore_DP0 pid=440719) .b8 98
(EngineCore_DP0 pid=440719) .b8 117
(EngineCore_DP0 pid=440719) .b8 105
(EngineCore_DP0 pid=440719) .b8 108
(EngineCore_DP0 pid=440719) .b8 100
(EngineCore_DP0 pid=440719) .b8 47
(EngineCore_DP0 pid=440719) .b8 71
(EngineCore_DP0 pid=440719) .b8 66
(EngineCore_DP0 pid=440719) .b8 49
(EngineCore_DP0 pid=440719) .b8 48
(EngineCore_DP0 pid=440719) .b8 95
(EngineCore_DP0 pid=440719) .b8 99
(EngineCore_DP0 pid=440719) .b8 99
(EngineCore_DP0 pid=440719) .b8 49
(EngineCore_DP0 pid=440719) .b8 50
(EngineCore_DP0 pid=440719) .b8 49
(EngineCore_DP0 pid=440719) .b8 95
(EngineCore_DP0 pid=440719) .b8 112
(EngineCore_DP0 pid=440719) .b8 121
(EngineCore_DP0 pid=440719) .b8 51
(EngineCore_DP0 pid=440719) .b8 49
(EngineCore_DP0 pid=440719) .b8 50
(EngineCore_DP0 pid=440719) .b8 95
(EngineCore_DP0 pid=440719) .b8 99
(EngineCore_DP0 pid=440719) .b8 117
(EngineCore_DP0 pid=440719) .b8 49
(EngineCore_DP0 pid=440719) .b8 50
(EngineCore_DP0 pid=440719) .b8 57
(EngineCore_DP0 pid=440719) .b8 95
(EngineCore_DP0 pid=440719) .b8 97
(EngineCore_DP0 pid=440719) .b8 97
(EngineCore_DP0 pid=440719) .b8 114
(EngineCore_DP0 pid=440719) .b8 99
(EngineCore_DP0 pid=440719) .b8 104
(EngineCore_DP0 pid=440719) .b8 54
(EngineCore_DP0 pid=440719) .b8 52
(EngineCore_DP0 pid=440719) .b8 0
(EngineCore_DP0 pid=440719) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=440719) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=440719) .b8 113
(EngineCore_DP0 pid=440719) .b8 117
(EngineCore_DP0 pid=440719) .b8 97
(EngineCore_DP0 pid=440719) .b8 110
(EngineCore_DP0 pid=440719) .b8 116
(EngineCore_DP0 pid=440719) .b8 95
(EngineCore_DP0 pid=440719) .b8 115
(EngineCore_DP0 pid=440719) .b8 108
(EngineCore_DP0 pid=440719) .b8 105
(EngineCore_DP0 pid=440719) .b8 100
(EngineCore_DP0 pid=440719) .b8 101
(EngineCore_DP0 pid=440719) .b8 95
(EngineCore_DP0 pid=440719) .b8 105
(EngineCore_DP0 pid=440719) .b8 110
(EngineCore_DP0 pid=440719) .b8 116
(EngineCore_DP0 pid=440719) .b8 56
(EngineCore_DP0 pid=440719) .b8 95
(EngineCore_DP0 pid=440719) .b8 107
(EngineCore_DP0 pid=440719) .b8 101
(EngineCore_DP0 pid=440719) .b8 114
(EngineCore_DP0 pid=440719) .b8 110
(EngineCore_DP0 pid=440719) .b8 101
(EngineCore_DP0 pid=440719) .b8 108
(EngineCore_DP0 pid=440719) .b8 0
(EngineCore_DP0 pid=440719) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=440719) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=440719) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=440719) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=440719) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=440719) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=440719) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=440719) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=440719) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=440719) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=440719) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=440719) .b8 1
(EngineCore_DP0 pid=440719) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=440719) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=440719) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=440719) 	}
(EngineCore_DP0 pid=440719) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=440719) 
(EngineCore_DP0 pid=440719) ================================================================
(EngineCore_DP0 pid=440719) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=440719) 
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmplfsm4khk.ptx', '-o', '/tmp/tmplfsm4khk.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866] 
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866] 
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866] 
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmplfsm4khk.ptx -o /tmp/tmplfsm4khk.ptx.o
(EngineCore_DP0 pid=440719) ERROR 01-25 20:51:56 [core.py:866] 

STDERR:
[2026-01-25 20:50:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:50:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:50:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:50:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:50:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:50:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:50:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:50:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:50:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:50:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:50:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:50:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:50:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:50:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:50:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:50:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:50:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:50:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:50:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:50:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:50:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:50:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:50:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:50:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:50:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:50:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:50:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:50:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=440719) [2026-01-25 20:50:51] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=440719) [2026-01-25 20:50:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=440719) [2026-01-25 20:50:51] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=440719) [2026-01-25 20:50:51] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=440719) [2026-01-25 20:50:51] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=440719) [2026-01-25 20:50:51] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=440719) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=440719) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.88s/it]
(EngineCore_DP0 pid=440719) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.95s/it]
(EngineCore_DP0 pid=440719) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.49s/it]
(EngineCore_DP0 pid=440719) 
(EngineCore_DP0 pid=440719) [2026-01-25 20:51:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=440719) [2026-01-25 20:51:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=440719) [2026-01-25 20:51:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=440719) [2026-01-25 20:51:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=440719) [2026-01-25 20:51:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=440719) [2026-01-25 20:51:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=440719) [2026-01-25 20:51:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=440719) [2026-01-25 20:51:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=440719) Process EngineCore_DP0:
(EngineCore_DP0 pid=440719) Traceback (most recent call last):
(EngineCore_DP0 pid=440719)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=440719)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=440719)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=440719)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=440719) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmplfsm4khk.ptx', '-o', '/tmp/tmplfsm4khk.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=440719) 
(EngineCore_DP0 pid=440719) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=440719) 
(EngineCore_DP0 pid=440719) Traceback (most recent call last):
(EngineCore_DP0 pid=440719)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=440719)     self.run()
(EngineCore_DP0 pid=440719)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=440719)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=440719)     raise e
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=440719)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=440719)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=440719)     super().__init__(
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=440719)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=440719)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=440719)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=440719)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=440719)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=440719)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=440719)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=440719)     return func(*args, **kwargs)
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=440719)     return func(*args, **kwargs)
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=440719)     self.model_runner.profile_run()
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=440719)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=440719)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=440719)     return func(*args, **kwargs)
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=440719)     outputs = self.model(
(EngineCore_DP0 pid=440719)               ^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=440719)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=440719)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=440719)     hidden_states = self.model(
(EngineCore_DP0 pid=440719)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=440719)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=440719)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=440719)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=440719)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=440719)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=440719)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=440719)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=440719)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=440719)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=440719)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=440719)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=440719)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=440719)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=440719)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=440719)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=440719)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=440719)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=440719)     return self._linear_fn(
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=440719)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=440719)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=440719)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=440719)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=440719)     return fn(input, L)
(EngineCore_DP0 pid=440719)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=440719)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=440719)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=440719)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=440719)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=440719)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=440719)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=440719)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=440719)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=440719)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=440719)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=440719)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=440719)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=440719)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=440719)     raise PTXASError(error)
(EngineCore_DP0 pid=440719) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=440719) `ptxas` stderr:
(EngineCore_DP0 pid=440719) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=440719) 
(EngineCore_DP0 pid=440719) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmplfsm4khk.ptx -o /tmp/tmplfsm4khk.ptx.o
(EngineCore_DP0 pid=440719) 
[rank0]:[W125 20:51:56.518771662 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 20:51:58
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:52:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:52:05 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=441967) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=441967) 
(EngineCore_DP0 pid=441967) 
(EngineCore_DP0 pid=441967) ================================================================
(EngineCore_DP0 pid=441967) Internal Triton PTX codegen error
(EngineCore_DP0 pid=441967) `ptxas` stderr:
(EngineCore_DP0 pid=441967) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=441967) 
(EngineCore_DP0 pid=441967) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpupss5s7c.ptx -o /tmp/tmpupss5s7c.ptx.o
(EngineCore_DP0 pid=441967) 
(EngineCore_DP0 pid=441967) 
(EngineCore_DP0 pid=441967) //
(EngineCore_DP0 pid=441967) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=441967) //
(EngineCore_DP0 pid=441967) 
(EngineCore_DP0 pid=441967) .version 8.7
(EngineCore_DP0 pid=441967) .target sm_121a
(EngineCore_DP0 pid=441967) .address_size 64
(EngineCore_DP0 pid=441967) 
(EngineCore_DP0 pid=441967) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=441967) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=441967)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=441967) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=441967) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=441967) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=441967) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=441967) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=441967) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=441967) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=441967) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=441967) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=441967) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=441967) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=441967) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=441967) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=441967) )
(EngineCore_DP0 pid=441967) .reqntid 512
(EngineCore_DP0 pid=441967) {
(EngineCore_DP0 pid=441967) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=441967) 	.reg .b16 	%rs<64>;
(EngineCore_DP0 pid=441967) 	.reg .b32 	%r<182>;
(EngineCore_DP0 pid=441967) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=441967) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=441967) $L__func_begin0:
(EngineCore_DP0 pid=441967) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=441967) 
(EngineCore_DP0 pid=441967) // %bb.0:
(EngineCore_DP0 pid=441967) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=441967) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=441967) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=441967) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=441967) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=441967) $L__tmp0:
(EngineCore_DP0 pid=441967) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=441967) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=441967) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=441967) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=441967) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=441967) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=441967) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=441967) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=441967) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=441967) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=441967) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=441967) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=441967) 	mov.b32 	%r180, 0f2B8CBCCC;
(EngineCore_DP0 pid=441967) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=441967) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=441967) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=441967) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=441967) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=441967) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=441967) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=441967) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=441967) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=441967) 	add.s32 	%r57, %r39, %r38;
(EngineCore_DP0 pid=441967) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=441967) 	add.s32 	%r60, %r39, %r40;
(EngineCore_DP0 pid=441967) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=441967) 	mov.b32 	%r178, 0f00000000;
(EngineCore_DP0 pid=441967) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=441967) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=441967) 	mov.b32 	%r179, %r45;
(EngineCore_DP0 pid=441967) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=441967) 	.loc	1 265 19                        // quant_slide_tuned_Qwen2.5-7B.py:265:19
(EngineCore_DP0 pid=441967) 	add.s32 	%r63, %r4, %r179;
(EngineCore_DP0 pid=441967) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=441967) 	add.s32 	%r64, %r63, 4096;
(EngineCore_DP0 pid=441967) 	setp.lt.s32 	%p2, %r63, %r23;
(EngineCore_DP0 pid=441967) 	setp.lt.s32 	%p3, %r64, %r23;
(EngineCore_DP0 pid=441967) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=441967) 	mad.wide.s32 	%rd6, %r63, 2, %rd1;
(EngineCore_DP0 pid=441967) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=441967) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=441967) 	// begin inline asm
(EngineCore_DP0 pid=441967) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=441967) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=441967) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=441967) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=441967) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=441967) 	// end inline asm
(EngineCore_DP0 pid=441967) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=441967) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=441967) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=441967) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=441967) 	// begin inline asm
(EngineCore_DP0 pid=441967) 	mov.u32 %r49, %r45;
(EngineCore_DP0 pid=441967) 	mov.u32 %r50, %r45;
(EngineCore_DP0 pid=441967) 	mov.u32 %r51, %r45;
(EngineCore_DP0 pid=441967) 	mov.u32 %r52, %r45;
(EngineCore_DP0 pid=441967) 	@%p3 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=441967) 	// end inline asm
(EngineCore_DP0 pid=441967) 	mov.b32 	{%rs9, %rs10}, %r49;
(EngineCore_DP0 pid=441967) 	mov.b32 	{%rs11, %rs12}, %r50;
(EngineCore_DP0 pid=441967) 	mov.b32 	{%rs13, %rs14}, %r51;
(EngineCore_DP0 pid=441967) 	mov.b32 	{%rs15, %rs16}, %r52;
(EngineCore_DP0 pid=441967) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=441967) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=441967) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=441967) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=441967) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=441967) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=441967) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=441967) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=441967) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=441967) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=441967) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=441967) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=441967) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=441967) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=441967) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=441967) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=441967) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=441967) $L__tmp1:
(EngineCore_DP0 pid=441967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	bar.sync 	0;
(EngineCore_DP0 pid=441967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=441967) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=441967) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=441967) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=441967) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=441967) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=441967) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=441967) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=441967) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=441967) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=441967) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=441967) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=441967) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=441967) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=441967) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=441967) 	cvt.f32.bf16 	%r65, %rs47;
(EngineCore_DP0 pid=441967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	shfl.sync.bfly.b32 	%r66, %r65, 16, 31, -1;
(EngineCore_DP0 pid=441967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=441967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	shfl.sync.bfly.b32 	%r68, %r67, 8, 31, -1;
(EngineCore_DP0 pid=441967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=441967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	shfl.sync.bfly.b32 	%r70, %r69, 4, 31, -1;
(EngineCore_DP0 pid=441967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=441967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	shfl.sync.bfly.b32 	%r72, %r71, 2, 31, -1;
(EngineCore_DP0 pid=441967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=441967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	shfl.sync.bfly.b32 	%r74, %r73, 1, 31, -1;
(EngineCore_DP0 pid=441967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	max.f32 	%r58, %r73, %r74;
(EngineCore_DP0 pid=441967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	// begin inline asm
(EngineCore_DP0 pid=441967) 	@%p4 st.shared.b32 [ %r57 + 0 ], %r58;
(EngineCore_DP0 pid=441967) 	// end inline asm
(EngineCore_DP0 pid=441967) 	bar.sync 	0;
(EngineCore_DP0 pid=441967) 	// begin inline asm
(EngineCore_DP0 pid=441967) 	@%p5 ld.shared.b32 %r59, [ %r60 + 0 ];
(EngineCore_DP0 pid=441967) 	// end inline asm
(EngineCore_DP0 pid=441967) 	shfl.sync.bfly.b32 	%r75, %r59, 8, 31, -1;
(EngineCore_DP0 pid=441967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	max.f32 	%r76, %r59, %r75;
(EngineCore_DP0 pid=441967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	shfl.sync.bfly.b32 	%r77, %r76, 4, 31, -1;
(EngineCore_DP0 pid=441967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=441967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	shfl.sync.bfly.b32 	%r79, %r78, 2, 31, -1;
(EngineCore_DP0 pid=441967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	max.f32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=441967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	shfl.sync.bfly.b32 	%r81, %r80, 1, 31, -1;
(EngineCore_DP0 pid=441967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	max.f32 	%r62, %r80, %r81;
(EngineCore_DP0 pid=441967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=441967) 	// begin inline asm
(EngineCore_DP0 pid=441967) 	@%p28 st.shared.b32 [ %r60 + 0 ], %r62;
(EngineCore_DP0 pid=441967) 	// end inline asm
(EngineCore_DP0 pid=441967) 	bar.sync 	0;
(EngineCore_DP0 pid=441967) 	ld.shared.b32 	%r82, [global_smem];
(EngineCore_DP0 pid=441967) $L__tmp2:
(EngineCore_DP0 pid=441967) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=441967) 	max.f32 	%r178, %r178, %r82;
(EngineCore_DP0 pid=441967) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=441967) 	add.s32 	%r179, %r179, 8192;
(EngineCore_DP0 pid=441967) 	setp.lt.s32 	%p7, %r179, %r24;
(EngineCore_DP0 pid=441967) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=441967) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=441967) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=441967) 	max.f32 	%r180, %r178, 0f2B8CBCCC;
(EngineCore_DP0 pid=441967) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=441967) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=441967) 	mov.b32 	%r84, 0f42FE0000;
(EngineCore_DP0 pid=441967) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=441967) 	div.full.f32 	%r85, %r180, %r84;
(EngineCore_DP0 pid=441967) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=441967) 	max.f32 	%r83, %r85, 0f37810204;
(EngineCore_DP0 pid=441967) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=441967) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=441967) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=441967) 	// begin inline asm
(EngineCore_DP0 pid=441967) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r83 };
(EngineCore_DP0 pid=441967) 	// end inline asm
(EngineCore_DP0 pid=441967) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=441967) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=441967) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=441967) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=441967) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=441967) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=441967) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=441967) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=441967) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=441967) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=441967) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=441967) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=441967) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=441967) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=441967) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=441967) 	div.full.f32 	%r14, %r84, %r180;
(EngineCore_DP0 pid=441967) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=441967) 	mov.b32 	%r181, 0;
(EngineCore_DP0 pid=441967) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=441967)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=441967) 	.loc	1 279 31                        // quant_slide_tuned_Qwen2.5-7B.py:279:31
(EngineCore_DP0 pid=441967) 	add.s32 	%r90, %r16, %r181;
(EngineCore_DP0 pid=441967) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=441967) 	add.s32 	%r91, %r90, 1;
(EngineCore_DP0 pid=441967) 	setp.lt.s32 	%p18, %r90, %r15;
(EngineCore_DP0 pid=441967) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=441967) 	mul.hi.s32 	%r92, %r91, 1431655766;
(EngineCore_DP0 pid=441967) 	shr.u32 	%r93, %r92, 31;
(EngineCore_DP0 pid=441967) 	add.s32 	%r94, %r92, %r93;
(EngineCore_DP0 pid=441967) 	mul.hi.s32 	%r95, %r90, 1431655766;
(EngineCore_DP0 pid=441967) 	shr.u32 	%r96, %r95, 31;
(EngineCore_DP0 pid=441967) 	add.s32 	%r97, %r95, %r96;
(EngineCore_DP0 pid=441967) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=441967) 	mul.lo.s32 	%r98, %r97, 3;
(EngineCore_DP0 pid=441967) 	mul.lo.s32 	%r99, %r94, 3;
(EngineCore_DP0 pid=441967) 	sub.s32 	%r100, %r91, %r99;
(EngineCore_DP0 pid=441967) 	sub.s32 	%r101, %r90, %r98;
(EngineCore_DP0 pid=441967) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=441967) 	shl.b32 	%r102, %r97, 3;
(EngineCore_DP0 pid=441967) 	shl.b32 	%r103, %r94, 3;
(EngineCore_DP0 pid=441967) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=441967) 	shl.b32 	%r104, %r101, 1;
(EngineCore_DP0 pid=441967) 	shl.b32 	%r105, %r100, 1;
(EngineCore_DP0 pid=441967) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=441967) 	add.s32 	%r106, %r103, %r105;
(EngineCore_DP0 pid=441967) 	add.s32 	%r107, %r102, %r104;
(EngineCore_DP0 pid=441967) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=441967) 	setp.lt.s32 	%p19, %r107, %r23;
(EngineCore_DP0 pid=441967) 	setp.lt.s32 	%p20, %r106, %r23;
(EngineCore_DP0 pid=441967) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=441967) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=441967) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=441967) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=441967) 	mad.wide.s32 	%rd9, %r107, 2, %rd1;
(EngineCore_DP0 pid=441967) 	mad.wide.s32 	%rd10, %r106, 2, %rd1;
(EngineCore_DP0 pid=441967) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=441967) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=441967) 	// begin inline asm
(EngineCore_DP0 pid=441967) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=441967) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=441967) 	// end inline asm
(EngineCore_DP0 pid=441967) 	// begin inline asm
(EngineCore_DP0 pid=441967) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=441967) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=441967) 	// end inline asm
(EngineCore_DP0 pid=441967) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=441967) 	cvt.f32.bf16 	%r108, %rs48;
(EngineCore_DP0 pid=441967) 	cvt.f32.bf16 	%r109, %rs50;
(EngineCore_DP0 pid=441967) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=441967) 	or.b32 	%r110, %r107, 1;
(EngineCore_DP0 pid=441967) 	or.b32 	%r111, %r106, 1;
(EngineCore_DP0 pid=441967) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=441967) 	setp.lt.s32 	%p21, %r110, %r23;
(EngineCore_DP0 pid=441967) 	setp.lt.s32 	%p22, %r111, %r23;
(EngineCore_DP0 pid=441967) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=441967) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=441967) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=441967) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=441967) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=441967) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=441967) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=441967) 	// begin inline asm
(EngineCore_DP0 pid=441967) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=441967) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=441967) 	// end inline asm
(EngineCore_DP0 pid=441967) 	// begin inline asm
(EngineCore_DP0 pid=441967) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=441967) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=441967) 	// end inline asm
(EngineCore_DP0 pid=441967) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=441967) 	cvt.f32.bf16 	%r112, %rs52;
(EngineCore_DP0 pid=441967) 	cvt.f32.bf16 	%r113, %rs54;
(EngineCore_DP0 pid=441967) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=441967) 	add.s32 	%r114, %r107, 2;
(EngineCore_DP0 pid=441967) 	add.s32 	%r115, %r106, 2;
(EngineCore_DP0 pid=441967) 	add.s32 	%r116, %r107, 3;
(EngineCore_DP0 pid=441967) 	add.s32 	%r117, %r106, 3;
(EngineCore_DP0 pid=441967) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=441967) 	setp.lt.s32 	%p23, %r117, %r23;
(EngineCore_DP0 pid=441967) 	setp.lt.s32 	%p24, %r116, %r23;
(EngineCore_DP0 pid=441967) 	setp.lt.s32 	%p25, %r115, %r23;
(EngineCore_DP0 pid=441967) 	setp.lt.s32 	%p26, %r114, %r23;
(EngineCore_DP0 pid=441967) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=441967) 	and.pred 	%p14, %p18, %p26;
(EngineCore_DP0 pid=441967) 	and.pred 	%p15, %p18, %p25;
(EngineCore_DP0 pid=441967) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=441967) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=441967) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=441967) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=441967) 	// begin inline asm
(EngineCore_DP0 pid=441967) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=441967) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=441967) 	// end inline asm
(EngineCore_DP0 pid=441967) 	// begin inline asm
(EngineCore_DP0 pid=441967) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=441967) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=441967) 	// end inline asm
(EngineCore_DP0 pid=441967) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=441967) 	cvt.f32.bf16 	%r118, %rs56;
(EngineCore_DP0 pid=441967) 	cvt.f32.bf16 	%r119, %rs58;
(EngineCore_DP0 pid=441967) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=441967) 	and.pred 	%p16, %p18, %p24;
(EngineCore_DP0 pid=441967) 	and.pred 	%p17, %p18, %p23;
(EngineCore_DP0 pid=441967) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=441967) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=441967) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=441967) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=441967) 	// begin inline asm
(EngineCore_DP0 pid=441967) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=441967) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=441967) 	// end inline asm
(EngineCore_DP0 pid=441967) 	// begin inline asm
(EngineCore_DP0 pid=441967) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=441967) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=441967) 	// end inline asm
(EngineCore_DP0 pid=441967) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=441967) 	cvt.f32.bf16 	%r120, %rs60;
(EngineCore_DP0 pid=441967) 	cvt.f32.bf16 	%r121, %rs62;
(EngineCore_DP0 pid=441967) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=441967) 	mul.f32 	%r122, %r14, %r108;
(EngineCore_DP0 pid=441967) 	mul.f32 	%r123, %r14, %r109;
(EngineCore_DP0 pid=441967) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=441967) 	cvt.rni.f32.f32 	%r124, %r122;
(EngineCore_DP0 pid=441967) 	cvt.rni.f32.f32 	%r125, %r123;
(EngineCore_DP0 pid=441967) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=441967) 	max.f32 	%r126, %r124, 0fC3000000;
(EngineCore_DP0 pid=441967) 	min.f32 	%r127, %r126, 0f42FE0000;
(EngineCore_DP0 pid=441967) 	max.f32 	%r128, %r125, 0fC3000000;
(EngineCore_DP0 pid=441967) 	min.f32 	%r129, %r128, 0f42FE0000;
(EngineCore_DP0 pid=441967) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=441967) 	cvt.rzi.s32.f32 	%r130, %r127;
(EngineCore_DP0 pid=441967) 	cvt.rzi.s32.f32 	%r131, %r129;
(EngineCore_DP0 pid=441967) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=441967) 	and.b32 	%r132, %r130, 255;
(EngineCore_DP0 pid=441967) 	and.b32 	%r133, %r131, 255;
(EngineCore_DP0 pid=441967) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=441967) 	mul.f32 	%r134, %r14, %r112;
(EngineCore_DP0 pid=441967) 	mul.f32 	%r135, %r14, %r113;
(EngineCore_DP0 pid=441967) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=441967) 	cvt.rni.f32.f32 	%r136, %r134;
(EngineCore_DP0 pid=441967) 	cvt.rni.f32.f32 	%r137, %r135;
(EngineCore_DP0 pid=441967) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=441967) 	mul.f32 	%r138, %r14, %r118;
(EngineCore_DP0 pid=441967) 	mul.f32 	%r139, %r14, %r119;
(EngineCore_DP0 pid=441967) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=441967) 	cvt.rni.f32.f32 	%r140, %r138;
(EngineCore_DP0 pid=441967) 	cvt.rni.f32.f32 	%r141, %r139;
(EngineCore_DP0 pid=441967) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=441967) 	mul.f32 	%r142, %r14, %r120;
(EngineCore_DP0 pid=441967) 	mul.f32 	%r143, %r14, %r121;
(EngineCore_DP0 pid=441967) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=441967) 	cvt.rni.f32.f32 	%r144, %r142;
(EngineCore_DP0 pid=441967) 	cvt.rni.f32.f32 	%r145, %r143;
(EngineCore_DP0 pid=441967) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=441967) 	max.f32 	%r146, %r144, 0fC3000000;
(EngineCore_DP0 pid=441967) 	min.f32 	%r147, %r146, 0f42FE0000;
(EngineCore_DP0 pid=441967) 	max.f32 	%r148, %r145, 0fC3000000;
(EngineCore_DP0 pid=441967) 	min.f32 	%r149, %r148, 0f42FE0000;
(EngineCore_DP0 pid=441967) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=441967) 	cvt.rzi.s32.f32 	%r150, %r147;
(EngineCore_DP0 pid=441967) 	cvt.rzi.s32.f32 	%r151, %r149;
(EngineCore_DP0 pid=441967) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=441967) 	max.f32 	%r152, %r140, 0fC3000000;
(EngineCore_DP0 pid=441967) 	max.f32 	%r153, %r136, 0fC3000000;
(EngineCore_DP0 pid=441967) 	min.f32 	%r154, %r153, 0f42FE0000;
(EngineCore_DP0 pid=441967) 	min.f32 	%r155, %r152, 0f42FE0000;
(EngineCore_DP0 pid=441967) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=441967) 	cvt.rzi.s32.f32 	%r156, %r155;
(EngineCore_DP0 pid=441967) 	cvt.rzi.s32.f32 	%r157, %r154;
(EngineCore_DP0 pid=441967) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=441967) 	shl.b32 	%r158, %r157, 8;
(EngineCore_DP0 pid=441967) 	shl.b32 	%r159, %r156, 16;
(EngineCore_DP0 pid=441967) 	and.b32 	%r160, %r159, 16711680;
(EngineCore_DP0 pid=441967) 	and.b32 	%r161, %r158, 65280;
(EngineCore_DP0 pid=441967) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=441967) 	or.b32 	%r162, %r161, %r132;
(EngineCore_DP0 pid=441967) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=441967) 	max.f32 	%r163, %r141, 0fC3000000;
(EngineCore_DP0 pid=441967) 	max.f32 	%r164, %r137, 0fC3000000;
(EngineCore_DP0 pid=441967) 	min.f32 	%r165, %r164, 0f42FE0000;
(EngineCore_DP0 pid=441967) 	min.f32 	%r166, %r163, 0f42FE0000;
(EngineCore_DP0 pid=441967) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=441967) 	cvt.rzi.s32.f32 	%r167, %r166;
(EngineCore_DP0 pid=441967) 	cvt.rzi.s32.f32 	%r168, %r165;
(EngineCore_DP0 pid=441967) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=441967) 	shl.b32 	%r169, %r168, 8;
(EngineCore_DP0 pid=441967) 	shl.b32 	%r170, %r167, 16;
(EngineCore_DP0 pid=441967) 	and.b32 	%r171, %r170, 16711680;
(EngineCore_DP0 pid=441967) 	and.b32 	%r172, %r169, 65280;
(EngineCore_DP0 pid=441967) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=441967) 	or.b32 	%r173, %r172, %r133;
(EngineCore_DP0 pid=441967) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=441967) 	or.b32 	%r174, %r162, %r160;
(EngineCore_DP0 pid=441967) 	or.b32 	%r175, %r173, %r171;
(EngineCore_DP0 pid=441967) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=441967) 	shl.b32 	%r176, %r150, 24;
(EngineCore_DP0 pid=441967) 	shl.b32 	%r177, %r151, 24;
(EngineCore_DP0 pid=441967) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=441967) 	or.b32 	%r87, %r174, %r176;
(EngineCore_DP0 pid=441967) 	or.b32 	%r88, %r175, %r177;
(EngineCore_DP0 pid=441967) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=441967) 	mad.wide.s32 	%rd17, %r90, 4, %rd2;
(EngineCore_DP0 pid=441967) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=441967) 	// begin inline asm
(EngineCore_DP0 pid=441967) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r87, %r88 };
(EngineCore_DP0 pid=441967) 	// end inline asm
(EngineCore_DP0 pid=441967) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=441967) 	add.s32 	%r181, %r181, 1024;
(EngineCore_DP0 pid=441967) 	setp.lt.s32 	%p27, %r181, %r15;
(EngineCore_DP0 pid=441967) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=441967) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=441967) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=441967) 	ret;
(EngineCore_DP0 pid=441967) $L__tmp3:
(EngineCore_DP0 pid=441967) $L__func_end0:
(EngineCore_DP0 pid=441967)                                         // -- End function
(EngineCore_DP0 pid=441967) }
(EngineCore_DP0 pid=441967) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=441967) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=441967) 	.section	.debug_abbrev
(EngineCore_DP0 pid=441967) 	{
(EngineCore_DP0 pid=441967) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=441967) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=441967) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=441967) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=441967) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=441967) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=441967) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=441967) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=441967) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=441967) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=441967) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=441967) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=441967) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=441967) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=441967) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=441967) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=441967) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=441967) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=441967) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=441967) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=441967) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=441967) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=441967) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=441967) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=441967) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=441967) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=441967) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=441967) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=441967) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=441967) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=441967) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=441967) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=441967) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=441967) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=441967) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=441967) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=441967) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=441967) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=441967) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=441967) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=441967) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=441967) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=441967) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=441967) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=441967) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=441967) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=441967) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=441967) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=441967) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=441967) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=441967) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=441967) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=441967) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=441967) 	}
(EngineCore_DP0 pid=441967) 	.section	.debug_info
(EngineCore_DP0 pid=441967) 	{
(EngineCore_DP0 pid=441967) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=441967) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=441967) .b8 0
(EngineCore_DP0 pid=441967) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=441967) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=441967) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=441967) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=441967) .b8 114
(EngineCore_DP0 pid=441967) .b8 105
(EngineCore_DP0 pid=441967) .b8 116
(EngineCore_DP0 pid=441967) .b8 111
(EngineCore_DP0 pid=441967) .b8 110
(EngineCore_DP0 pid=441967) .b8 0
(EngineCore_DP0 pid=441967) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=441967) .b8 0
(EngineCore_DP0 pid=441967) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=441967) .b8 117
(EngineCore_DP0 pid=441967) .b8 97
(EngineCore_DP0 pid=441967) .b8 110
(EngineCore_DP0 pid=441967) .b8 116
(EngineCore_DP0 pid=441967) .b8 95
(EngineCore_DP0 pid=441967) .b8 115
(EngineCore_DP0 pid=441967) .b8 108
(EngineCore_DP0 pid=441967) .b8 105
(EngineCore_DP0 pid=441967) .b8 100
(EngineCore_DP0 pid=441967) .b8 101
(EngineCore_DP0 pid=441967) .b8 95
(EngineCore_DP0 pid=441967) .b8 116
(EngineCore_DP0 pid=441967) .b8 117
(EngineCore_DP0 pid=441967) .b8 110
(EngineCore_DP0 pid=441967) .b8 101
(EngineCore_DP0 pid=441967) .b8 100
(EngineCore_DP0 pid=441967) .b8 95
(EngineCore_DP0 pid=441967) .b8 81
(EngineCore_DP0 pid=441967) .b8 119
(EngineCore_DP0 pid=441967) .b8 101
(EngineCore_DP0 pid=441967) .b8 110
(EngineCore_DP0 pid=441967) .b8 50
(EngineCore_DP0 pid=441967) .b8 46
(EngineCore_DP0 pid=441967) .b8 53
(EngineCore_DP0 pid=441967) .b8 45
(EngineCore_DP0 pid=441967) .b8 55
(EngineCore_DP0 pid=441967) .b8 66
(EngineCore_DP0 pid=441967) .b8 46
(EngineCore_DP0 pid=441967) .b8 112
(EngineCore_DP0 pid=441967) .b8 121
(EngineCore_DP0 pid=441967) .b8 0
(EngineCore_DP0 pid=441967) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=441967) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=441967) .b8 114
(EngineCore_DP0 pid=441967) .b8 111
(EngineCore_DP0 pid=441967) .b8 111
(EngineCore_DP0 pid=441967) .b8 116
(EngineCore_DP0 pid=441967) .b8 47
(EngineCore_DP0 pid=441967) .b8 118
(EngineCore_DP0 pid=441967) .b8 108
(EngineCore_DP0 pid=441967) .b8 108
(EngineCore_DP0 pid=441967) .b8 109
(EngineCore_DP0 pid=441967) .b8 98
(EngineCore_DP0 pid=441967) .b8 101
(EngineCore_DP0 pid=441967) .b8 110
(EngineCore_DP0 pid=441967) .b8 99
(EngineCore_DP0 pid=441967) .b8 104
(EngineCore_DP0 pid=441967) .b8 47
(EngineCore_DP0 pid=441967) .b8 115
(EngineCore_DP0 pid=441967) .b8 108
(EngineCore_DP0 pid=441967) .b8 105
(EngineCore_DP0 pid=441967) .b8 100
(EngineCore_DP0 pid=441967) .b8 101
(EngineCore_DP0 pid=441967) .b8 115
(EngineCore_DP0 pid=441967) .b8 112
(EngineCore_DP0 pid=441967) .b8 97
(EngineCore_DP0 pid=441967) .b8 114
(EngineCore_DP0 pid=441967) .b8 115
(EngineCore_DP0 pid=441967) .b8 101
(EngineCore_DP0 pid=441967) .b8 47
(EngineCore_DP0 pid=441967) .b8 99
(EngineCore_DP0 pid=441967) .b8 115
(EngineCore_DP0 pid=441967) .b8 114
(EngineCore_DP0 pid=441967) .b8 99
(EngineCore_DP0 pid=441967) .b8 47
(EngineCore_DP0 pid=441967) .b8 102
(EngineCore_DP0 pid=441967) .b8 117
(EngineCore_DP0 pid=441967) .b8 115
(EngineCore_DP0 pid=441967) .b8 101
(EngineCore_DP0 pid=441967) .b8 100
(EngineCore_DP0 pid=441967) .b8 95
(EngineCore_DP0 pid=441967) .b8 113
(EngineCore_DP0 pid=441967) .b8 117
(EngineCore_DP0 pid=441967) .b8 97
(EngineCore_DP0 pid=441967) .b8 110
(EngineCore_DP0 pid=441967) .b8 116
(EngineCore_DP0 pid=441967) .b8 95
(EngineCore_DP0 pid=441967) .b8 115
(EngineCore_DP0 pid=441967) .b8 108
(EngineCore_DP0 pid=441967) .b8 105
(EngineCore_DP0 pid=441967) .b8 100
(EngineCore_DP0 pid=441967) .b8 101
(EngineCore_DP0 pid=441967) .b8 95
(EngineCore_DP0 pid=441967) .b8 116
(EngineCore_DP0 pid=441967) .b8 114
(EngineCore_DP0 pid=441967) .b8 105
(EngineCore_DP0 pid=441967) .b8 116
(EngineCore_DP0 pid=441967) .b8 111
(EngineCore_DP0 pid=441967) .b8 110
(EngineCore_DP0 pid=441967) .b8 47
(EngineCore_DP0 pid=441967) .b8 98
(EngineCore_DP0 pid=441967) .b8 117
(EngineCore_DP0 pid=441967) .b8 105
(EngineCore_DP0 pid=441967) .b8 108
(EngineCore_DP0 pid=441967) .b8 100
(EngineCore_DP0 pid=441967) .b8 47
(EngineCore_DP0 pid=441967) .b8 71
(EngineCore_DP0 pid=441967) .b8 66
(EngineCore_DP0 pid=441967) .b8 49
(EngineCore_DP0 pid=441967) .b8 48
(EngineCore_DP0 pid=441967) .b8 95
(EngineCore_DP0 pid=441967) .b8 99
(EngineCore_DP0 pid=441967) .b8 99
(EngineCore_DP0 pid=441967) .b8 49
(EngineCore_DP0 pid=441967) .b8 50
(EngineCore_DP0 pid=441967) .b8 49
(EngineCore_DP0 pid=441967) .b8 95
(EngineCore_DP0 pid=441967) .b8 112
(EngineCore_DP0 pid=441967) .b8 121
(EngineCore_DP0 pid=441967) .b8 51
(EngineCore_DP0 pid=441967) .b8 49
(EngineCore_DP0 pid=441967) .b8 50
(EngineCore_DP0 pid=441967) .b8 95
(EngineCore_DP0 pid=441967) .b8 99
(EngineCore_DP0 pid=441967) .b8 117
(EngineCore_DP0 pid=441967) .b8 49
(EngineCore_DP0 pid=441967) .b8 50
(EngineCore_DP0 pid=441967) .b8 57
(EngineCore_DP0 pid=441967) .b8 95
(EngineCore_DP0 pid=441967) .b8 97
(EngineCore_DP0 pid=441967) .b8 97
(EngineCore_DP0 pid=441967) .b8 114
(EngineCore_DP0 pid=441967) .b8 99
(EngineCore_DP0 pid=441967) .b8 104
(EngineCore_DP0 pid=441967) .b8 54
(EngineCore_DP0 pid=441967) .b8 52
(EngineCore_DP0 pid=441967) .b8 0
(EngineCore_DP0 pid=441967) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=441967) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=441967) .b8 113
(EngineCore_DP0 pid=441967) .b8 117
(EngineCore_DP0 pid=441967) .b8 97
(EngineCore_DP0 pid=441967) .b8 110
(EngineCore_DP0 pid=441967) .b8 116
(EngineCore_DP0 pid=441967) .b8 95
(EngineCore_DP0 pid=441967) .b8 115
(EngineCore_DP0 pid=441967) .b8 108
(EngineCore_DP0 pid=441967) .b8 105
(EngineCore_DP0 pid=441967) .b8 100
(EngineCore_DP0 pid=441967) .b8 101
(EngineCore_DP0 pid=441967) .b8 95
(EngineCore_DP0 pid=441967) .b8 105
(EngineCore_DP0 pid=441967) .b8 110
(EngineCore_DP0 pid=441967) .b8 116
(EngineCore_DP0 pid=441967) .b8 56
(EngineCore_DP0 pid=441967) .b8 95
(EngineCore_DP0 pid=441967) .b8 107
(EngineCore_DP0 pid=441967) .b8 101
(EngineCore_DP0 pid=441967) .b8 114
(EngineCore_DP0 pid=441967) .b8 110
(EngineCore_DP0 pid=441967) .b8 101
(EngineCore_DP0 pid=441967) .b8 108
(EngineCore_DP0 pid=441967) .b8 0
(EngineCore_DP0 pid=441967) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=441967) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=441967) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=441967) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=441967) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=441967) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=441967) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=441967) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=441967) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=441967) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=441967) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=441967) .b8 1
(EngineCore_DP0 pid=441967) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=441967) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=441967) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=441967) 	}
(EngineCore_DP0 pid=441967) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=441967) 
(EngineCore_DP0 pid=441967) ================================================================
(EngineCore_DP0 pid=441967) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=441967) 
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpupss5s7c.ptx', '-o', '/tmp/tmpupss5s7c.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866] 
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866] 
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866] 
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpupss5s7c.ptx -o /tmp/tmpupss5s7c.ptx.o
(EngineCore_DP0 pid=441967) ERROR 01-25 20:53:12 [core.py:866] 

STDERR:
[2026-01-25 20:52:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:52:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:52:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:52:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:52:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:52:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:52:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:52:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:52:08] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:52:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:52:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:52:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:52:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:52:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:52:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:52:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:52:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=441967) [2026-01-25 20:52:09] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=441967) [2026-01-25 20:52:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=441967) [2026-01-25 20:52:09] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=441967) [2026-01-25 20:52:09] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=441967) [2026-01-25 20:52:09] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=441967) [2026-01-25 20:52:09] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=441967) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=441967) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.47s/it]
(EngineCore_DP0 pid=441967) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.49s/it]
(EngineCore_DP0 pid=441967) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.04s/it]
(EngineCore_DP0 pid=441967) 
(EngineCore_DP0 pid=441967) [2026-01-25 20:53:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=441967) [2026-01-25 20:53:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=441967) [2026-01-25 20:53:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=441967) [2026-01-25 20:53:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=441967) [2026-01-25 20:53:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=441967) [2026-01-25 20:53:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=441967) [2026-01-25 20:53:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=441967) [2026-01-25 20:53:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=441967) Process EngineCore_DP0:
(EngineCore_DP0 pid=441967) Traceback (most recent call last):
(EngineCore_DP0 pid=441967)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=441967)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=441967)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=441967)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=441967) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpupss5s7c.ptx', '-o', '/tmp/tmpupss5s7c.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=441967) 
(EngineCore_DP0 pid=441967) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=441967) 
(EngineCore_DP0 pid=441967) Traceback (most recent call last):
(EngineCore_DP0 pid=441967)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=441967)     self.run()
(EngineCore_DP0 pid=441967)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=441967)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=441967)     raise e
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=441967)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=441967)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=441967)     super().__init__(
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=441967)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=441967)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=441967)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=441967)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=441967)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=441967)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=441967)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=441967)     return func(*args, **kwargs)
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=441967)     return func(*args, **kwargs)
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=441967)     self.model_runner.profile_run()
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=441967)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=441967)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=441967)     return func(*args, **kwargs)
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=441967)     outputs = self.model(
(EngineCore_DP0 pid=441967)               ^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=441967)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=441967)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=441967)     hidden_states = self.model(
(EngineCore_DP0 pid=441967)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=441967)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=441967)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=441967)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=441967)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=441967)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=441967)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=441967)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=441967)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=441967)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=441967)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=441967)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=441967)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=441967)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=441967)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=441967)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=441967)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=441967)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=441967)     return self._linear_fn(
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=441967)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=441967)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=441967)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=441967)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=441967)     return fn(input, L)
(EngineCore_DP0 pid=441967)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=441967)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=441967)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=441967)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=441967)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=441967)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=441967)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=441967)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=441967)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=441967)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=441967)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=441967)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=441967)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=441967)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=441967)     raise PTXASError(error)
(EngineCore_DP0 pid=441967) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=441967) `ptxas` stderr:
(EngineCore_DP0 pid=441967) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=441967) 
(EngineCore_DP0 pid=441967) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpupss5s7c.ptx -o /tmp/tmpupss5s7c.ptx.o
(EngineCore_DP0 pid=441967) 
[rank0]:[W125 20:53:13.318338822 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 20:53:14
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:53:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:53:25 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=443267) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=443267) 
(EngineCore_DP0 pid=443267) 
(EngineCore_DP0 pid=443267) ================================================================
(EngineCore_DP0 pid=443267) Internal Triton PTX codegen error
(EngineCore_DP0 pid=443267) `ptxas` stderr:
(EngineCore_DP0 pid=443267) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=443267) 
(EngineCore_DP0 pid=443267) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmptab0jpf6.ptx -o /tmp/tmptab0jpf6.ptx.o
(EngineCore_DP0 pid=443267) 
(EngineCore_DP0 pid=443267) 
(EngineCore_DP0 pid=443267) //
(EngineCore_DP0 pid=443267) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=443267) //
(EngineCore_DP0 pid=443267) 
(EngineCore_DP0 pid=443267) .version 8.7
(EngineCore_DP0 pid=443267) .target sm_121a
(EngineCore_DP0 pid=443267) .address_size 64
(EngineCore_DP0 pid=443267) 
(EngineCore_DP0 pid=443267) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=443267) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=443267)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=443267) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=443267) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=443267) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=443267) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=443267) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=443267) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=443267) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=443267) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=443267) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=443267) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=443267) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=443267) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=443267) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=443267) )
(EngineCore_DP0 pid=443267) .reqntid 512
(EngineCore_DP0 pid=443267) {
(EngineCore_DP0 pid=443267) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=443267) 	.reg .b16 	%rs<64>;
(EngineCore_DP0 pid=443267) 	.reg .b32 	%r<182>;
(EngineCore_DP0 pid=443267) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=443267) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=443267) $L__func_begin0:
(EngineCore_DP0 pid=443267) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=443267) 
(EngineCore_DP0 pid=443267) // %bb.0:
(EngineCore_DP0 pid=443267) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=443267) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=443267) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=443267) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=443267) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=443267) $L__tmp0:
(EngineCore_DP0 pid=443267) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=443267) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=443267) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=443267) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=443267) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=443267) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=443267) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=443267) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=443267) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=443267) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=443267) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=443267) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=443267) 	mov.b32 	%r180, 0f2B8CBCCC;
(EngineCore_DP0 pid=443267) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=443267) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=443267) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=443267) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=443267) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=443267) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=443267) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=443267) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=443267) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=443267) 	add.s32 	%r57, %r39, %r38;
(EngineCore_DP0 pid=443267) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=443267) 	add.s32 	%r60, %r39, %r40;
(EngineCore_DP0 pid=443267) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=443267) 	mov.b32 	%r178, 0f00000000;
(EngineCore_DP0 pid=443267) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=443267) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=443267) 	mov.b32 	%r179, %r45;
(EngineCore_DP0 pid=443267) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=443267) 	.loc	1 265 19                        // quant_slide_tuned_Qwen2.5-7B.py:265:19
(EngineCore_DP0 pid=443267) 	add.s32 	%r63, %r4, %r179;
(EngineCore_DP0 pid=443267) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=443267) 	add.s32 	%r64, %r63, 4096;
(EngineCore_DP0 pid=443267) 	setp.lt.s32 	%p2, %r63, %r23;
(EngineCore_DP0 pid=443267) 	setp.lt.s32 	%p3, %r64, %r23;
(EngineCore_DP0 pid=443267) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=443267) 	mad.wide.s32 	%rd6, %r63, 2, %rd1;
(EngineCore_DP0 pid=443267) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=443267) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=443267) 	// begin inline asm
(EngineCore_DP0 pid=443267) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=443267) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=443267) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=443267) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=443267) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=443267) 	// end inline asm
(EngineCore_DP0 pid=443267) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=443267) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=443267) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=443267) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=443267) 	// begin inline asm
(EngineCore_DP0 pid=443267) 	mov.u32 %r49, %r45;
(EngineCore_DP0 pid=443267) 	mov.u32 %r50, %r45;
(EngineCore_DP0 pid=443267) 	mov.u32 %r51, %r45;
(EngineCore_DP0 pid=443267) 	mov.u32 %r52, %r45;
(EngineCore_DP0 pid=443267) 	@%p3 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=443267) 	// end inline asm
(EngineCore_DP0 pid=443267) 	mov.b32 	{%rs9, %rs10}, %r49;
(EngineCore_DP0 pid=443267) 	mov.b32 	{%rs11, %rs12}, %r50;
(EngineCore_DP0 pid=443267) 	mov.b32 	{%rs13, %rs14}, %r51;
(EngineCore_DP0 pid=443267) 	mov.b32 	{%rs15, %rs16}, %r52;
(EngineCore_DP0 pid=443267) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=443267) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=443267) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=443267) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=443267) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=443267) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=443267) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=443267) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=443267) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=443267) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=443267) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=443267) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=443267) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=443267) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=443267) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=443267) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=443267) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=443267) $L__tmp1:
(EngineCore_DP0 pid=443267) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	bar.sync 	0;
(EngineCore_DP0 pid=443267) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=443267) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=443267) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=443267) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=443267) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=443267) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=443267) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=443267) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=443267) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=443267) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=443267) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=443267) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=443267) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=443267) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=443267) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=443267) 	cvt.f32.bf16 	%r65, %rs47;
(EngineCore_DP0 pid=443267) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	shfl.sync.bfly.b32 	%r66, %r65, 16, 31, -1;
(EngineCore_DP0 pid=443267) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=443267) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	shfl.sync.bfly.b32 	%r68, %r67, 8, 31, -1;
(EngineCore_DP0 pid=443267) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=443267) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	shfl.sync.bfly.b32 	%r70, %r69, 4, 31, -1;
(EngineCore_DP0 pid=443267) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=443267) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	shfl.sync.bfly.b32 	%r72, %r71, 2, 31, -1;
(EngineCore_DP0 pid=443267) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=443267) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	shfl.sync.bfly.b32 	%r74, %r73, 1, 31, -1;
(EngineCore_DP0 pid=443267) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	max.f32 	%r58, %r73, %r74;
(EngineCore_DP0 pid=443267) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	// begin inline asm
(EngineCore_DP0 pid=443267) 	@%p4 st.shared.b32 [ %r57 + 0 ], %r58;
(EngineCore_DP0 pid=443267) 	// end inline asm
(EngineCore_DP0 pid=443267) 	bar.sync 	0;
(EngineCore_DP0 pid=443267) 	// begin inline asm
(EngineCore_DP0 pid=443267) 	@%p5 ld.shared.b32 %r59, [ %r60 + 0 ];
(EngineCore_DP0 pid=443267) 	// end inline asm
(EngineCore_DP0 pid=443267) 	shfl.sync.bfly.b32 	%r75, %r59, 8, 31, -1;
(EngineCore_DP0 pid=443267) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	max.f32 	%r76, %r59, %r75;
(EngineCore_DP0 pid=443267) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	shfl.sync.bfly.b32 	%r77, %r76, 4, 31, -1;
(EngineCore_DP0 pid=443267) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=443267) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	shfl.sync.bfly.b32 	%r79, %r78, 2, 31, -1;
(EngineCore_DP0 pid=443267) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	max.f32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=443267) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	shfl.sync.bfly.b32 	%r81, %r80, 1, 31, -1;
(EngineCore_DP0 pid=443267) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	max.f32 	%r62, %r80, %r81;
(EngineCore_DP0 pid=443267) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=443267) 	// begin inline asm
(EngineCore_DP0 pid=443267) 	@%p28 st.shared.b32 [ %r60 + 0 ], %r62;
(EngineCore_DP0 pid=443267) 	// end inline asm
(EngineCore_DP0 pid=443267) 	bar.sync 	0;
(EngineCore_DP0 pid=443267) 	ld.shared.b32 	%r82, [global_smem];
(EngineCore_DP0 pid=443267) $L__tmp2:
(EngineCore_DP0 pid=443267) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=443267) 	max.f32 	%r178, %r178, %r82;
(EngineCore_DP0 pid=443267) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=443267) 	add.s32 	%r179, %r179, 8192;
(EngineCore_DP0 pid=443267) 	setp.lt.s32 	%p7, %r179, %r24;
(EngineCore_DP0 pid=443267) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=443267) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=443267) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=443267) 	max.f32 	%r180, %r178, 0f2B8CBCCC;
(EngineCore_DP0 pid=443267) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=443267) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=443267) 	mov.b32 	%r84, 0f42FE0000;
(EngineCore_DP0 pid=443267) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=443267) 	div.full.f32 	%r85, %r180, %r84;
(EngineCore_DP0 pid=443267) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=443267) 	max.f32 	%r83, %r85, 0f37810204;
(EngineCore_DP0 pid=443267) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=443267) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=443267) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=443267) 	// begin inline asm
(EngineCore_DP0 pid=443267) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r83 };
(EngineCore_DP0 pid=443267) 	// end inline asm
(EngineCore_DP0 pid=443267) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=443267) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=443267) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=443267) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=443267) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=443267) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=443267) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=443267) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=443267) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=443267) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=443267) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=443267) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=443267) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=443267) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=443267) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=443267) 	div.full.f32 	%r14, %r84, %r180;
(EngineCore_DP0 pid=443267) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=443267) 	mov.b32 	%r181, 0;
(EngineCore_DP0 pid=443267) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=443267)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=443267) 	.loc	1 279 31                        // quant_slide_tuned_Qwen2.5-7B.py:279:31
(EngineCore_DP0 pid=443267) 	add.s32 	%r90, %r16, %r181;
(EngineCore_DP0 pid=443267) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=443267) 	add.s32 	%r91, %r90, 1;
(EngineCore_DP0 pid=443267) 	setp.lt.s32 	%p18, %r90, %r15;
(EngineCore_DP0 pid=443267) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=443267) 	mul.hi.s32 	%r92, %r91, 1431655766;
(EngineCore_DP0 pid=443267) 	shr.u32 	%r93, %r92, 31;
(EngineCore_DP0 pid=443267) 	add.s32 	%r94, %r92, %r93;
(EngineCore_DP0 pid=443267) 	mul.hi.s32 	%r95, %r90, 1431655766;
(EngineCore_DP0 pid=443267) 	shr.u32 	%r96, %r95, 31;
(EngineCore_DP0 pid=443267) 	add.s32 	%r97, %r95, %r96;
(EngineCore_DP0 pid=443267) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=443267) 	mul.lo.s32 	%r98, %r97, 3;
(EngineCore_DP0 pid=443267) 	mul.lo.s32 	%r99, %r94, 3;
(EngineCore_DP0 pid=443267) 	sub.s32 	%r100, %r91, %r99;
(EngineCore_DP0 pid=443267) 	sub.s32 	%r101, %r90, %r98;
(EngineCore_DP0 pid=443267) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=443267) 	shl.b32 	%r102, %r97, 3;
(EngineCore_DP0 pid=443267) 	shl.b32 	%r103, %r94, 3;
(EngineCore_DP0 pid=443267) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=443267) 	shl.b32 	%r104, %r101, 1;
(EngineCore_DP0 pid=443267) 	shl.b32 	%r105, %r100, 1;
(EngineCore_DP0 pid=443267) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=443267) 	add.s32 	%r106, %r103, %r105;
(EngineCore_DP0 pid=443267) 	add.s32 	%r107, %r102, %r104;
(EngineCore_DP0 pid=443267) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=443267) 	setp.lt.s32 	%p19, %r107, %r23;
(EngineCore_DP0 pid=443267) 	setp.lt.s32 	%p20, %r106, %r23;
(EngineCore_DP0 pid=443267) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=443267) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=443267) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=443267) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=443267) 	mad.wide.s32 	%rd9, %r107, 2, %rd1;
(EngineCore_DP0 pid=443267) 	mad.wide.s32 	%rd10, %r106, 2, %rd1;
(EngineCore_DP0 pid=443267) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=443267) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=443267) 	// begin inline asm
(EngineCore_DP0 pid=443267) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=443267) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=443267) 	// end inline asm
(EngineCore_DP0 pid=443267) 	// begin inline asm
(EngineCore_DP0 pid=443267) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=443267) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=443267) 	// end inline asm
(EngineCore_DP0 pid=443267) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=443267) 	cvt.f32.bf16 	%r108, %rs48;
(EngineCore_DP0 pid=443267) 	cvt.f32.bf16 	%r109, %rs50;
(EngineCore_DP0 pid=443267) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=443267) 	or.b32 	%r110, %r107, 1;
(EngineCore_DP0 pid=443267) 	or.b32 	%r111, %r106, 1;
(EngineCore_DP0 pid=443267) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=443267) 	setp.lt.s32 	%p21, %r110, %r23;
(EngineCore_DP0 pid=443267) 	setp.lt.s32 	%p22, %r111, %r23;
(EngineCore_DP0 pid=443267) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=443267) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=443267) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=443267) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=443267) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=443267) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=443267) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=443267) 	// begin inline asm
(EngineCore_DP0 pid=443267) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=443267) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=443267) 	// end inline asm
(EngineCore_DP0 pid=443267) 	// begin inline asm
(EngineCore_DP0 pid=443267) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=443267) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=443267) 	// end inline asm
(EngineCore_DP0 pid=443267) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=443267) 	cvt.f32.bf16 	%r112, %rs52;
(EngineCore_DP0 pid=443267) 	cvt.f32.bf16 	%r113, %rs54;
(EngineCore_DP0 pid=443267) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=443267) 	add.s32 	%r114, %r107, 2;
(EngineCore_DP0 pid=443267) 	add.s32 	%r115, %r106, 2;
(EngineCore_DP0 pid=443267) 	add.s32 	%r116, %r107, 3;
(EngineCore_DP0 pid=443267) 	add.s32 	%r117, %r106, 3;
(EngineCore_DP0 pid=443267) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=443267) 	setp.lt.s32 	%p23, %r117, %r23;
(EngineCore_DP0 pid=443267) 	setp.lt.s32 	%p24, %r116, %r23;
(EngineCore_DP0 pid=443267) 	setp.lt.s32 	%p25, %r115, %r23;
(EngineCore_DP0 pid=443267) 	setp.lt.s32 	%p26, %r114, %r23;
(EngineCore_DP0 pid=443267) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=443267) 	and.pred 	%p14, %p18, %p26;
(EngineCore_DP0 pid=443267) 	and.pred 	%p15, %p18, %p25;
(EngineCore_DP0 pid=443267) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=443267) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=443267) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=443267) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=443267) 	// begin inline asm
(EngineCore_DP0 pid=443267) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=443267) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=443267) 	// end inline asm
(EngineCore_DP0 pid=443267) 	// begin inline asm
(EngineCore_DP0 pid=443267) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=443267) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=443267) 	// end inline asm
(EngineCore_DP0 pid=443267) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=443267) 	cvt.f32.bf16 	%r118, %rs56;
(EngineCore_DP0 pid=443267) 	cvt.f32.bf16 	%r119, %rs58;
(EngineCore_DP0 pid=443267) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=443267) 	and.pred 	%p16, %p18, %p24;
(EngineCore_DP0 pid=443267) 	and.pred 	%p17, %p18, %p23;
(EngineCore_DP0 pid=443267) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=443267) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=443267) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=443267) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=443267) 	// begin inline asm
(EngineCore_DP0 pid=443267) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=443267) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=443267) 	// end inline asm
(EngineCore_DP0 pid=443267) 	// begin inline asm
(EngineCore_DP0 pid=443267) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=443267) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=443267) 	// end inline asm
(EngineCore_DP0 pid=443267) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=443267) 	cvt.f32.bf16 	%r120, %rs60;
(EngineCore_DP0 pid=443267) 	cvt.f32.bf16 	%r121, %rs62;
(EngineCore_DP0 pid=443267) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=443267) 	mul.f32 	%r122, %r14, %r108;
(EngineCore_DP0 pid=443267) 	mul.f32 	%r123, %r14, %r109;
(EngineCore_DP0 pid=443267) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=443267) 	cvt.rni.f32.f32 	%r124, %r122;
(EngineCore_DP0 pid=443267) 	cvt.rni.f32.f32 	%r125, %r123;
(EngineCore_DP0 pid=443267) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=443267) 	max.f32 	%r126, %r124, 0fC3000000;
(EngineCore_DP0 pid=443267) 	min.f32 	%r127, %r126, 0f42FE0000;
(EngineCore_DP0 pid=443267) 	max.f32 	%r128, %r125, 0fC3000000;
(EngineCore_DP0 pid=443267) 	min.f32 	%r129, %r128, 0f42FE0000;
(EngineCore_DP0 pid=443267) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=443267) 	cvt.rzi.s32.f32 	%r130, %r127;
(EngineCore_DP0 pid=443267) 	cvt.rzi.s32.f32 	%r131, %r129;
(EngineCore_DP0 pid=443267) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=443267) 	and.b32 	%r132, %r130, 255;
(EngineCore_DP0 pid=443267) 	and.b32 	%r133, %r131, 255;
(EngineCore_DP0 pid=443267) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=443267) 	mul.f32 	%r134, %r14, %r112;
(EngineCore_DP0 pid=443267) 	mul.f32 	%r135, %r14, %r113;
(EngineCore_DP0 pid=443267) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=443267) 	cvt.rni.f32.f32 	%r136, %r134;
(EngineCore_DP0 pid=443267) 	cvt.rni.f32.f32 	%r137, %r135;
(EngineCore_DP0 pid=443267) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=443267) 	mul.f32 	%r138, %r14, %r118;
(EngineCore_DP0 pid=443267) 	mul.f32 	%r139, %r14, %r119;
(EngineCore_DP0 pid=443267) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=443267) 	cvt.rni.f32.f32 	%r140, %r138;
(EngineCore_DP0 pid=443267) 	cvt.rni.f32.f32 	%r141, %r139;
(EngineCore_DP0 pid=443267) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=443267) 	mul.f32 	%r142, %r14, %r120;
(EngineCore_DP0 pid=443267) 	mul.f32 	%r143, %r14, %r121;
(EngineCore_DP0 pid=443267) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=443267) 	cvt.rni.f32.f32 	%r144, %r142;
(EngineCore_DP0 pid=443267) 	cvt.rni.f32.f32 	%r145, %r143;
(EngineCore_DP0 pid=443267) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=443267) 	max.f32 	%r146, %r144, 0fC3000000;
(EngineCore_DP0 pid=443267) 	min.f32 	%r147, %r146, 0f42FE0000;
(EngineCore_DP0 pid=443267) 	max.f32 	%r148, %r145, 0fC3000000;
(EngineCore_DP0 pid=443267) 	min.f32 	%r149, %r148, 0f42FE0000;
(EngineCore_DP0 pid=443267) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=443267) 	cvt.rzi.s32.f32 	%r150, %r147;
(EngineCore_DP0 pid=443267) 	cvt.rzi.s32.f32 	%r151, %r149;
(EngineCore_DP0 pid=443267) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=443267) 	max.f32 	%r152, %r140, 0fC3000000;
(EngineCore_DP0 pid=443267) 	max.f32 	%r153, %r136, 0fC3000000;
(EngineCore_DP0 pid=443267) 	min.f32 	%r154, %r153, 0f42FE0000;
(EngineCore_DP0 pid=443267) 	min.f32 	%r155, %r152, 0f42FE0000;
(EngineCore_DP0 pid=443267) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=443267) 	cvt.rzi.s32.f32 	%r156, %r155;
(EngineCore_DP0 pid=443267) 	cvt.rzi.s32.f32 	%r157, %r154;
(EngineCore_DP0 pid=443267) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=443267) 	shl.b32 	%r158, %r157, 8;
(EngineCore_DP0 pid=443267) 	shl.b32 	%r159, %r156, 16;
(EngineCore_DP0 pid=443267) 	and.b32 	%r160, %r159, 16711680;
(EngineCore_DP0 pid=443267) 	and.b32 	%r161, %r158, 65280;
(EngineCore_DP0 pid=443267) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=443267) 	or.b32 	%r162, %r161, %r132;
(EngineCore_DP0 pid=443267) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=443267) 	max.f32 	%r163, %r141, 0fC3000000;
(EngineCore_DP0 pid=443267) 	max.f32 	%r164, %r137, 0fC3000000;
(EngineCore_DP0 pid=443267) 	min.f32 	%r165, %r164, 0f42FE0000;
(EngineCore_DP0 pid=443267) 	min.f32 	%r166, %r163, 0f42FE0000;
(EngineCore_DP0 pid=443267) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=443267) 	cvt.rzi.s32.f32 	%r167, %r166;
(EngineCore_DP0 pid=443267) 	cvt.rzi.s32.f32 	%r168, %r165;
(EngineCore_DP0 pid=443267) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=443267) 	shl.b32 	%r169, %r168, 8;
(EngineCore_DP0 pid=443267) 	shl.b32 	%r170, %r167, 16;
(EngineCore_DP0 pid=443267) 	and.b32 	%r171, %r170, 16711680;
(EngineCore_DP0 pid=443267) 	and.b32 	%r172, %r169, 65280;
(EngineCore_DP0 pid=443267) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=443267) 	or.b32 	%r173, %r172, %r133;
(EngineCore_DP0 pid=443267) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=443267) 	or.b32 	%r174, %r162, %r160;
(EngineCore_DP0 pid=443267) 	or.b32 	%r175, %r173, %r171;
(EngineCore_DP0 pid=443267) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=443267) 	shl.b32 	%r176, %r150, 24;
(EngineCore_DP0 pid=443267) 	shl.b32 	%r177, %r151, 24;
(EngineCore_DP0 pid=443267) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=443267) 	or.b32 	%r87, %r174, %r176;
(EngineCore_DP0 pid=443267) 	or.b32 	%r88, %r175, %r177;
(EngineCore_DP0 pid=443267) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=443267) 	mad.wide.s32 	%rd17, %r90, 4, %rd2;
(EngineCore_DP0 pid=443267) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=443267) 	// begin inline asm
(EngineCore_DP0 pid=443267) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r87, %r88 };
(EngineCore_DP0 pid=443267) 	// end inline asm
(EngineCore_DP0 pid=443267) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=443267) 	add.s32 	%r181, %r181, 1024;
(EngineCore_DP0 pid=443267) 	setp.lt.s32 	%p27, %r181, %r15;
(EngineCore_DP0 pid=443267) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=443267) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=443267) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=443267) 	ret;
(EngineCore_DP0 pid=443267) $L__tmp3:
(EngineCore_DP0 pid=443267) $L__func_end0:
(EngineCore_DP0 pid=443267)                                         // -- End function
(EngineCore_DP0 pid=443267) }
(EngineCore_DP0 pid=443267) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=443267) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=443267) 	.section	.debug_abbrev
(EngineCore_DP0 pid=443267) 	{
(EngineCore_DP0 pid=443267) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=443267) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=443267) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=443267) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=443267) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=443267) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=443267) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=443267) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=443267) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=443267) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=443267) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=443267) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=443267) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=443267) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=443267) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=443267) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=443267) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=443267) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=443267) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=443267) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=443267) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=443267) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=443267) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=443267) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=443267) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=443267) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=443267) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=443267) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=443267) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=443267) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=443267) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=443267) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=443267) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=443267) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=443267) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=443267) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=443267) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=443267) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=443267) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=443267) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=443267) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=443267) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=443267) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=443267) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=443267) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=443267) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=443267) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=443267) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=443267) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=443267) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=443267) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=443267) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=443267) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=443267) 	}
(EngineCore_DP0 pid=443267) 	.section	.debug_info
(EngineCore_DP0 pid=443267) 	{
(EngineCore_DP0 pid=443267) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=443267) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=443267) .b8 0
(EngineCore_DP0 pid=443267) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=443267) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=443267) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=443267) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=443267) .b8 114
(EngineCore_DP0 pid=443267) .b8 105
(EngineCore_DP0 pid=443267) .b8 116
(EngineCore_DP0 pid=443267) .b8 111
(EngineCore_DP0 pid=443267) .b8 110
(EngineCore_DP0 pid=443267) .b8 0
(EngineCore_DP0 pid=443267) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=443267) .b8 0
(EngineCore_DP0 pid=443267) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=443267) .b8 117
(EngineCore_DP0 pid=443267) .b8 97
(EngineCore_DP0 pid=443267) .b8 110
(EngineCore_DP0 pid=443267) .b8 116
(EngineCore_DP0 pid=443267) .b8 95
(EngineCore_DP0 pid=443267) .b8 115
(EngineCore_DP0 pid=443267) .b8 108
(EngineCore_DP0 pid=443267) .b8 105
(EngineCore_DP0 pid=443267) .b8 100
(EngineCore_DP0 pid=443267) .b8 101
(EngineCore_DP0 pid=443267) .b8 95
(EngineCore_DP0 pid=443267) .b8 116
(EngineCore_DP0 pid=443267) .b8 117
(EngineCore_DP0 pid=443267) .b8 110
(EngineCore_DP0 pid=443267) .b8 101
(EngineCore_DP0 pid=443267) .b8 100
(EngineCore_DP0 pid=443267) .b8 95
(EngineCore_DP0 pid=443267) .b8 81
(EngineCore_DP0 pid=443267) .b8 119
(EngineCore_DP0 pid=443267) .b8 101
(EngineCore_DP0 pid=443267) .b8 110
(EngineCore_DP0 pid=443267) .b8 50
(EngineCore_DP0 pid=443267) .b8 46
(EngineCore_DP0 pid=443267) .b8 53
(EngineCore_DP0 pid=443267) .b8 45
(EngineCore_DP0 pid=443267) .b8 55
(EngineCore_DP0 pid=443267) .b8 66
(EngineCore_DP0 pid=443267) .b8 46
(EngineCore_DP0 pid=443267) .b8 112
(EngineCore_DP0 pid=443267) .b8 121
(EngineCore_DP0 pid=443267) .b8 0
(EngineCore_DP0 pid=443267) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=443267) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=443267) .b8 114
(EngineCore_DP0 pid=443267) .b8 111
(EngineCore_DP0 pid=443267) .b8 111
(EngineCore_DP0 pid=443267) .b8 116
(EngineCore_DP0 pid=443267) .b8 47
(EngineCore_DP0 pid=443267) .b8 118
(EngineCore_DP0 pid=443267) .b8 108
(EngineCore_DP0 pid=443267) .b8 108
(EngineCore_DP0 pid=443267) .b8 109
(EngineCore_DP0 pid=443267) .b8 98
(EngineCore_DP0 pid=443267) .b8 101
(EngineCore_DP0 pid=443267) .b8 110
(EngineCore_DP0 pid=443267) .b8 99
(EngineCore_DP0 pid=443267) .b8 104
(EngineCore_DP0 pid=443267) .b8 47
(EngineCore_DP0 pid=443267) .b8 115
(EngineCore_DP0 pid=443267) .b8 108
(EngineCore_DP0 pid=443267) .b8 105
(EngineCore_DP0 pid=443267) .b8 100
(EngineCore_DP0 pid=443267) .b8 101
(EngineCore_DP0 pid=443267) .b8 115
(EngineCore_DP0 pid=443267) .b8 112
(EngineCore_DP0 pid=443267) .b8 97
(EngineCore_DP0 pid=443267) .b8 114
(EngineCore_DP0 pid=443267) .b8 115
(EngineCore_DP0 pid=443267) .b8 101
(EngineCore_DP0 pid=443267) .b8 47
(EngineCore_DP0 pid=443267) .b8 99
(EngineCore_DP0 pid=443267) .b8 115
(EngineCore_DP0 pid=443267) .b8 114
(EngineCore_DP0 pid=443267) .b8 99
(EngineCore_DP0 pid=443267) .b8 47
(EngineCore_DP0 pid=443267) .b8 102
(EngineCore_DP0 pid=443267) .b8 117
(EngineCore_DP0 pid=443267) .b8 115
(EngineCore_DP0 pid=443267) .b8 101
(EngineCore_DP0 pid=443267) .b8 100
(EngineCore_DP0 pid=443267) .b8 95
(EngineCore_DP0 pid=443267) .b8 113
(EngineCore_DP0 pid=443267) .b8 117
(EngineCore_DP0 pid=443267) .b8 97
(EngineCore_DP0 pid=443267) .b8 110
(EngineCore_DP0 pid=443267) .b8 116
(EngineCore_DP0 pid=443267) .b8 95
(EngineCore_DP0 pid=443267) .b8 115
(EngineCore_DP0 pid=443267) .b8 108
(EngineCore_DP0 pid=443267) .b8 105
(EngineCore_DP0 pid=443267) .b8 100
(EngineCore_DP0 pid=443267) .b8 101
(EngineCore_DP0 pid=443267) .b8 95
(EngineCore_DP0 pid=443267) .b8 116
(EngineCore_DP0 pid=443267) .b8 114
(EngineCore_DP0 pid=443267) .b8 105
(EngineCore_DP0 pid=443267) .b8 116
(EngineCore_DP0 pid=443267) .b8 111
(EngineCore_DP0 pid=443267) .b8 110
(EngineCore_DP0 pid=443267) .b8 47
(EngineCore_DP0 pid=443267) .b8 98
(EngineCore_DP0 pid=443267) .b8 117
(EngineCore_DP0 pid=443267) .b8 105
(EngineCore_DP0 pid=443267) .b8 108
(EngineCore_DP0 pid=443267) .b8 100
(EngineCore_DP0 pid=443267) .b8 47
(EngineCore_DP0 pid=443267) .b8 71
(EngineCore_DP0 pid=443267) .b8 66
(EngineCore_DP0 pid=443267) .b8 49
(EngineCore_DP0 pid=443267) .b8 48
(EngineCore_DP0 pid=443267) .b8 95
(EngineCore_DP0 pid=443267) .b8 99
(EngineCore_DP0 pid=443267) .b8 99
(EngineCore_DP0 pid=443267) .b8 49
(EngineCore_DP0 pid=443267) .b8 50
(EngineCore_DP0 pid=443267) .b8 49
(EngineCore_DP0 pid=443267) .b8 95
(EngineCore_DP0 pid=443267) .b8 112
(EngineCore_DP0 pid=443267) .b8 121
(EngineCore_DP0 pid=443267) .b8 51
(EngineCore_DP0 pid=443267) .b8 49
(EngineCore_DP0 pid=443267) .b8 50
(EngineCore_DP0 pid=443267) .b8 95
(EngineCore_DP0 pid=443267) .b8 99
(EngineCore_DP0 pid=443267) .b8 117
(EngineCore_DP0 pid=443267) .b8 49
(EngineCore_DP0 pid=443267) .b8 50
(EngineCore_DP0 pid=443267) .b8 57
(EngineCore_DP0 pid=443267) .b8 95
(EngineCore_DP0 pid=443267) .b8 97
(EngineCore_DP0 pid=443267) .b8 97
(EngineCore_DP0 pid=443267) .b8 114
(EngineCore_DP0 pid=443267) .b8 99
(EngineCore_DP0 pid=443267) .b8 104
(EngineCore_DP0 pid=443267) .b8 54
(EngineCore_DP0 pid=443267) .b8 52
(EngineCore_DP0 pid=443267) .b8 0
(EngineCore_DP0 pid=443267) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=443267) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=443267) .b8 113
(EngineCore_DP0 pid=443267) .b8 117
(EngineCore_DP0 pid=443267) .b8 97
(EngineCore_DP0 pid=443267) .b8 110
(EngineCore_DP0 pid=443267) .b8 116
(EngineCore_DP0 pid=443267) .b8 95
(EngineCore_DP0 pid=443267) .b8 115
(EngineCore_DP0 pid=443267) .b8 108
(EngineCore_DP0 pid=443267) .b8 105
(EngineCore_DP0 pid=443267) .b8 100
(EngineCore_DP0 pid=443267) .b8 101
(EngineCore_DP0 pid=443267) .b8 95
(EngineCore_DP0 pid=443267) .b8 105
(EngineCore_DP0 pid=443267) .b8 110
(EngineCore_DP0 pid=443267) .b8 116
(EngineCore_DP0 pid=443267) .b8 56
(EngineCore_DP0 pid=443267) .b8 95
(EngineCore_DP0 pid=443267) .b8 107
(EngineCore_DP0 pid=443267) .b8 101
(EngineCore_DP0 pid=443267) .b8 114
(EngineCore_DP0 pid=443267) .b8 110
(EngineCore_DP0 pid=443267) .b8 101
(EngineCore_DP0 pid=443267) .b8 108
(EngineCore_DP0 pid=443267) .b8 0
(EngineCore_DP0 pid=443267) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=443267) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=443267) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=443267) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=443267) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=443267) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=443267) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=443267) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=443267) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=443267) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=443267) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=443267) .b8 1
(EngineCore_DP0 pid=443267) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=443267) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=443267) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=443267) 	}
(EngineCore_DP0 pid=443267) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=443267) 
(EngineCore_DP0 pid=443267) ================================================================
(EngineCore_DP0 pid=443267) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=443267) 
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmptab0jpf6.ptx', '-o', '/tmp/tmptab0jpf6.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866] 
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866] 
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866] 
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmptab0jpf6.ptx -o /tmp/tmptab0jpf6.ptx.o
(EngineCore_DP0 pid=443267) ERROR 01-25 20:54:33 [core.py:866] 

STDERR:
[2026-01-25 20:53:25] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:53:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:53:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:53:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:53:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:53:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:53:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:53:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:53:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:53:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:53:29] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:53:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:53:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:53:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:53:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:53:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:53:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=443267) [2026-01-25 20:53:30] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=443267) [2026-01-25 20:53:30] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=443267) [2026-01-25 20:53:30] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=443267) [2026-01-25 20:53:30] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=443267) [2026-01-25 20:53:30] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=443267) [2026-01-25 20:53:30] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=443267) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=443267) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.24s/it]
(EngineCore_DP0 pid=443267) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.56s/it]
(EngineCore_DP0 pid=443267) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.06s/it]
(EngineCore_DP0 pid=443267) 
(EngineCore_DP0 pid=443267) [2026-01-25 20:54:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=443267) [2026-01-25 20:54:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=443267) [2026-01-25 20:54:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=443267) [2026-01-25 20:54:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=443267) [2026-01-25 20:54:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=443267) [2026-01-25 20:54:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=443267) [2026-01-25 20:54:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=443267) [2026-01-25 20:54:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=443267) Process EngineCore_DP0:
(EngineCore_DP0 pid=443267) Traceback (most recent call last):
(EngineCore_DP0 pid=443267)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=443267)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=443267)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=443267)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=443267) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmptab0jpf6.ptx', '-o', '/tmp/tmptab0jpf6.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=443267) 
(EngineCore_DP0 pid=443267) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=443267) 
(EngineCore_DP0 pid=443267) Traceback (most recent call last):
(EngineCore_DP0 pid=443267)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=443267)     self.run()
(EngineCore_DP0 pid=443267)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=443267)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=443267)     raise e
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=443267)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=443267)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=443267)     super().__init__(
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=443267)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=443267)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=443267)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=443267)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=443267)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=443267)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=443267)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=443267)     return func(*args, **kwargs)
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=443267)     return func(*args, **kwargs)
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=443267)     self.model_runner.profile_run()
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=443267)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=443267)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=443267)     return func(*args, **kwargs)
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=443267)     outputs = self.model(
(EngineCore_DP0 pid=443267)               ^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=443267)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=443267)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=443267)     hidden_states = self.model(
(EngineCore_DP0 pid=443267)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=443267)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=443267)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=443267)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=443267)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=443267)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=443267)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=443267)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=443267)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=443267)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=443267)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=443267)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=443267)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=443267)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=443267)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=443267)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=443267)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=443267)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=443267)     return self._linear_fn(
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=443267)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=443267)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=443267)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=443267)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=443267)     return fn(input, L)
(EngineCore_DP0 pid=443267)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=443267)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=443267)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=443267)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=443267)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=443267)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=443267)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=443267)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=443267)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=443267)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=443267)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=443267)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=443267)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=443267)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=443267)     raise PTXASError(error)
(EngineCore_DP0 pid=443267) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=443267) `ptxas` stderr:
(EngineCore_DP0 pid=443267) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=443267) 
(EngineCore_DP0 pid=443267) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmptab0jpf6.ptx -o /tmp/tmptab0jpf6.ptx.o
(EngineCore_DP0 pid=443267) 
[rank0]:[W125 20:54:34.258510261 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 20:54:35
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:54:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:54:53 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=444692) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=444692) 
(EngineCore_DP0 pid=444692) 
(EngineCore_DP0 pid=444692) ================================================================
(EngineCore_DP0 pid=444692) Internal Triton PTX codegen error
(EngineCore_DP0 pid=444692) `ptxas` stderr:
(EngineCore_DP0 pid=444692) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=444692) 
(EngineCore_DP0 pid=444692) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp39ita67i.ptx -o /tmp/tmp39ita67i.ptx.o
(EngineCore_DP0 pid=444692) 
(EngineCore_DP0 pid=444692) 
(EngineCore_DP0 pid=444692) //
(EngineCore_DP0 pid=444692) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=444692) //
(EngineCore_DP0 pid=444692) 
(EngineCore_DP0 pid=444692) .version 8.7
(EngineCore_DP0 pid=444692) .target sm_121a
(EngineCore_DP0 pid=444692) .address_size 64
(EngineCore_DP0 pid=444692) 
(EngineCore_DP0 pid=444692) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=444692) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=444692)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=444692) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=444692) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=444692) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=444692) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=444692) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=444692) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=444692) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=444692) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=444692) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=444692) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=444692) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=444692) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=444692) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=444692) )
(EngineCore_DP0 pid=444692) .reqntid 512
(EngineCore_DP0 pid=444692) {
(EngineCore_DP0 pid=444692) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=444692) 	.reg .b16 	%rs<40>;
(EngineCore_DP0 pid=444692) 	.reg .b32 	%r<173>;
(EngineCore_DP0 pid=444692) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=444692) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=444692) $L__func_begin0:
(EngineCore_DP0 pid=444692) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=444692) 
(EngineCore_DP0 pid=444692) // %bb.0:
(EngineCore_DP0 pid=444692) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=444692) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=444692) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=444692) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=444692) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=444692) $L__tmp0:
(EngineCore_DP0 pid=444692) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=444692) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=444692) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=444692) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=444692) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=444692) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=444692) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=444692) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=444692) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=444692) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=444692) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=444692) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=444692) 	mov.b32 	%r171, 0f2B8CBCCC;
(EngineCore_DP0 pid=444692) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=444692) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=444692) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=444692) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=444692) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=444692) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=444692) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=444692) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=444692) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=444692) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=444692) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=444692) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=444692) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=444692) 	mov.b32 	%r169, 0f00000000;
(EngineCore_DP0 pid=444692) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=444692) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=444692) 	mov.b32 	%r170, %r45;
(EngineCore_DP0 pid=444692) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=444692) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=444692) 	add.s32 	%r55, %r4, %r170;
(EngineCore_DP0 pid=444692) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=444692) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=444692) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=444692) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=444692) 	// begin inline asm
(EngineCore_DP0 pid=444692) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=444692) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=444692) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=444692) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=444692) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=444692) 	// end inline asm
(EngineCore_DP0 pid=444692) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=444692) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=444692) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=444692) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=444692) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=444692) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=444692) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=444692) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=444692) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=444692) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=444692) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=444692) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=444692) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=444692) $L__tmp1:
(EngineCore_DP0 pid=444692) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	bar.sync 	0;
(EngineCore_DP0 pid=444692) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=444692) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=444692) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=444692) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=444692) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=444692) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=444692) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=444692) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=444692) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=444692) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=444692) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=444692) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=444692) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=444692) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=444692) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=444692) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=444692) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=444692) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=444692) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	// begin inline asm
(EngineCore_DP0 pid=444692) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=444692) 	// end inline asm
(EngineCore_DP0 pid=444692) 	bar.sync 	0;
(EngineCore_DP0 pid=444692) 	// begin inline asm
(EngineCore_DP0 pid=444692) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=444692) 	// end inline asm
(EngineCore_DP0 pid=444692) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=444692) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=444692) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=444692) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=444692) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=444692) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=444692) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=444692) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=444692) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=444692) 	// begin inline asm
(EngineCore_DP0 pid=444692) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=444692) 	// end inline asm
(EngineCore_DP0 pid=444692) 	bar.sync 	0;
(EngineCore_DP0 pid=444692) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=444692) $L__tmp2:
(EngineCore_DP0 pid=444692) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=444692) 	max.f32 	%r169, %r169, %r73;
(EngineCore_DP0 pid=444692) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=444692) 	add.s32 	%r170, %r170, 4096;
(EngineCore_DP0 pid=444692) 	setp.lt.s32 	%p6, %r170, %r24;
(EngineCore_DP0 pid=444692) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=444692) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=444692) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=444692) 	max.f32 	%r171, %r169, 0f2B8CBCCC;
(EngineCore_DP0 pid=444692) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=444692) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=444692) 	mov.b32 	%r75, 0f42FE0000;
(EngineCore_DP0 pid=444692) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=444692) 	div.full.f32 	%r76, %r171, %r75;
(EngineCore_DP0 pid=444692) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=444692) 	max.f32 	%r74, %r76, 0f37810204;
(EngineCore_DP0 pid=444692) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=444692) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=444692) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=444692) 	// begin inline asm
(EngineCore_DP0 pid=444692) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=444692) 	// end inline asm
(EngineCore_DP0 pid=444692) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=444692) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=444692) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=444692) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=444692) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=444692) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=444692) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=444692) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=444692) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=444692) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=444692) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=444692) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=444692) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=444692) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=444692) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=444692) 	div.full.f32 	%r14, %r75, %r171;
(EngineCore_DP0 pid=444692) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=444692) 	mov.b32 	%r172, 0;
(EngineCore_DP0 pid=444692) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=444692)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=444692) 	.loc	1 279 31                        // quant_slide_tuned_Qwen2.5-7B.py:279:31
(EngineCore_DP0 pid=444692) 	add.s32 	%r81, %r16, %r172;
(EngineCore_DP0 pid=444692) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=444692) 	add.s32 	%r82, %r81, 1;
(EngineCore_DP0 pid=444692) 	setp.lt.s32 	%p17, %r81, %r15;
(EngineCore_DP0 pid=444692) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=444692) 	mul.hi.s32 	%r83, %r82, 1431655766;
(EngineCore_DP0 pid=444692) 	shr.u32 	%r84, %r83, 31;
(EngineCore_DP0 pid=444692) 	add.s32 	%r85, %r83, %r84;
(EngineCore_DP0 pid=444692) 	mul.hi.s32 	%r86, %r81, 1431655766;
(EngineCore_DP0 pid=444692) 	shr.u32 	%r87, %r86, 31;
(EngineCore_DP0 pid=444692) 	add.s32 	%r88, %r86, %r87;
(EngineCore_DP0 pid=444692) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=444692) 	mul.lo.s32 	%r89, %r88, 3;
(EngineCore_DP0 pid=444692) 	mul.lo.s32 	%r90, %r85, 3;
(EngineCore_DP0 pid=444692) 	sub.s32 	%r91, %r82, %r90;
(EngineCore_DP0 pid=444692) 	sub.s32 	%r92, %r81, %r89;
(EngineCore_DP0 pid=444692) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=444692) 	shl.b32 	%r93, %r88, 3;
(EngineCore_DP0 pid=444692) 	shl.b32 	%r94, %r85, 3;
(EngineCore_DP0 pid=444692) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=444692) 	shl.b32 	%r95, %r92, 1;
(EngineCore_DP0 pid=444692) 	shl.b32 	%r96, %r91, 1;
(EngineCore_DP0 pid=444692) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=444692) 	add.s32 	%r97, %r94, %r96;
(EngineCore_DP0 pid=444692) 	add.s32 	%r98, %r93, %r95;
(EngineCore_DP0 pid=444692) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=444692) 	setp.lt.s32 	%p18, %r98, %r23;
(EngineCore_DP0 pid=444692) 	setp.lt.s32 	%p19, %r97, %r23;
(EngineCore_DP0 pid=444692) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=444692) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=444692) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=444692) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=444692) 	mad.wide.s32 	%rd8, %r98, 2, %rd1;
(EngineCore_DP0 pid=444692) 	mad.wide.s32 	%rd9, %r97, 2, %rd1;
(EngineCore_DP0 pid=444692) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=444692) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=444692) 	// begin inline asm
(EngineCore_DP0 pid=444692) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=444692) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=444692) 	// end inline asm
(EngineCore_DP0 pid=444692) 	// begin inline asm
(EngineCore_DP0 pid=444692) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=444692) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=444692) 	// end inline asm
(EngineCore_DP0 pid=444692) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=444692) 	cvt.f32.bf16 	%r99, %rs24;
(EngineCore_DP0 pid=444692) 	cvt.f32.bf16 	%r100, %rs26;
(EngineCore_DP0 pid=444692) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=444692) 	or.b32 	%r101, %r98, 1;
(EngineCore_DP0 pid=444692) 	or.b32 	%r102, %r97, 1;
(EngineCore_DP0 pid=444692) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=444692) 	setp.lt.s32 	%p20, %r101, %r23;
(EngineCore_DP0 pid=444692) 	setp.lt.s32 	%p21, %r102, %r23;
(EngineCore_DP0 pid=444692) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=444692) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=444692) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=444692) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=444692) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=444692) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=444692) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=444692) 	// begin inline asm
(EngineCore_DP0 pid=444692) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=444692) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=444692) 	// end inline asm
(EngineCore_DP0 pid=444692) 	// begin inline asm
(EngineCore_DP0 pid=444692) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=444692) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=444692) 	// end inline asm
(EngineCore_DP0 pid=444692) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=444692) 	cvt.f32.bf16 	%r103, %rs28;
(EngineCore_DP0 pid=444692) 	cvt.f32.bf16 	%r104, %rs30;
(EngineCore_DP0 pid=444692) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=444692) 	add.s32 	%r105, %r98, 2;
(EngineCore_DP0 pid=444692) 	add.s32 	%r106, %r97, 2;
(EngineCore_DP0 pid=444692) 	add.s32 	%r107, %r98, 3;
(EngineCore_DP0 pid=444692) 	add.s32 	%r108, %r97, 3;
(EngineCore_DP0 pid=444692) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=444692) 	setp.lt.s32 	%p22, %r108, %r23;
(EngineCore_DP0 pid=444692) 	setp.lt.s32 	%p23, %r107, %r23;
(EngineCore_DP0 pid=444692) 	setp.lt.s32 	%p24, %r106, %r23;
(EngineCore_DP0 pid=444692) 	setp.lt.s32 	%p25, %r105, %r23;
(EngineCore_DP0 pid=444692) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=444692) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=444692) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=444692) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=444692) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=444692) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=444692) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=444692) 	// begin inline asm
(EngineCore_DP0 pid=444692) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=444692) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=444692) 	// end inline asm
(EngineCore_DP0 pid=444692) 	// begin inline asm
(EngineCore_DP0 pid=444692) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=444692) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=444692) 	// end inline asm
(EngineCore_DP0 pid=444692) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=444692) 	cvt.f32.bf16 	%r109, %rs32;
(EngineCore_DP0 pid=444692) 	cvt.f32.bf16 	%r110, %rs34;
(EngineCore_DP0 pid=444692) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=444692) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=444692) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=444692) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=444692) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=444692) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=444692) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=444692) 	// begin inline asm
(EngineCore_DP0 pid=444692) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=444692) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=444692) 	// end inline asm
(EngineCore_DP0 pid=444692) 	// begin inline asm
(EngineCore_DP0 pid=444692) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=444692) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=444692) 	// end inline asm
(EngineCore_DP0 pid=444692) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=444692) 	cvt.f32.bf16 	%r111, %rs36;
(EngineCore_DP0 pid=444692) 	cvt.f32.bf16 	%r112, %rs38;
(EngineCore_DP0 pid=444692) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=444692) 	mul.f32 	%r113, %r14, %r99;
(EngineCore_DP0 pid=444692) 	mul.f32 	%r114, %r14, %r100;
(EngineCore_DP0 pid=444692) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=444692) 	cvt.rni.f32.f32 	%r115, %r113;
(EngineCore_DP0 pid=444692) 	cvt.rni.f32.f32 	%r116, %r114;
(EngineCore_DP0 pid=444692) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=444692) 	max.f32 	%r117, %r115, 0fC3000000;
(EngineCore_DP0 pid=444692) 	min.f32 	%r118, %r117, 0f42FE0000;
(EngineCore_DP0 pid=444692) 	max.f32 	%r119, %r116, 0fC3000000;
(EngineCore_DP0 pid=444692) 	min.f32 	%r120, %r119, 0f42FE0000;
(EngineCore_DP0 pid=444692) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=444692) 	cvt.rzi.s32.f32 	%r121, %r118;
(EngineCore_DP0 pid=444692) 	cvt.rzi.s32.f32 	%r122, %r120;
(EngineCore_DP0 pid=444692) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=444692) 	and.b32 	%r123, %r121, 255;
(EngineCore_DP0 pid=444692) 	and.b32 	%r124, %r122, 255;
(EngineCore_DP0 pid=444692) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=444692) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=444692) 	mul.f32 	%r126, %r14, %r104;
(EngineCore_DP0 pid=444692) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=444692) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=444692) 	cvt.rni.f32.f32 	%r128, %r126;
(EngineCore_DP0 pid=444692) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=444692) 	mul.f32 	%r129, %r14, %r109;
(EngineCore_DP0 pid=444692) 	mul.f32 	%r130, %r14, %r110;
(EngineCore_DP0 pid=444692) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=444692) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=444692) 	cvt.rni.f32.f32 	%r132, %r130;
(EngineCore_DP0 pid=444692) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=444692) 	mul.f32 	%r133, %r14, %r111;
(EngineCore_DP0 pid=444692) 	mul.f32 	%r134, %r14, %r112;
(EngineCore_DP0 pid=444692) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=444692) 	cvt.rni.f32.f32 	%r135, %r133;
(EngineCore_DP0 pid=444692) 	cvt.rni.f32.f32 	%r136, %r134;
(EngineCore_DP0 pid=444692) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=444692) 	max.f32 	%r137, %r135, 0fC3000000;
(EngineCore_DP0 pid=444692) 	min.f32 	%r138, %r137, 0f42FE0000;
(EngineCore_DP0 pid=444692) 	max.f32 	%r139, %r136, 0fC3000000;
(EngineCore_DP0 pid=444692) 	min.f32 	%r140, %r139, 0f42FE0000;
(EngineCore_DP0 pid=444692) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=444692) 	cvt.rzi.s32.f32 	%r141, %r138;
(EngineCore_DP0 pid=444692) 	cvt.rzi.s32.f32 	%r142, %r140;
(EngineCore_DP0 pid=444692) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=444692) 	max.f32 	%r143, %r131, 0fC3000000;
(EngineCore_DP0 pid=444692) 	max.f32 	%r144, %r127, 0fC3000000;
(EngineCore_DP0 pid=444692) 	min.f32 	%r145, %r144, 0f42FE0000;
(EngineCore_DP0 pid=444692) 	min.f32 	%r146, %r143, 0f42FE0000;
(EngineCore_DP0 pid=444692) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=444692) 	cvt.rzi.s32.f32 	%r147, %r146;
(EngineCore_DP0 pid=444692) 	cvt.rzi.s32.f32 	%r148, %r145;
(EngineCore_DP0 pid=444692) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=444692) 	shl.b32 	%r149, %r148, 8;
(EngineCore_DP0 pid=444692) 	shl.b32 	%r150, %r147, 16;
(EngineCore_DP0 pid=444692) 	and.b32 	%r151, %r150, 16711680;
(EngineCore_DP0 pid=444692) 	and.b32 	%r152, %r149, 65280;
(EngineCore_DP0 pid=444692) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=444692) 	or.b32 	%r153, %r152, %r123;
(EngineCore_DP0 pid=444692) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=444692) 	max.f32 	%r154, %r132, 0fC3000000;
(EngineCore_DP0 pid=444692) 	max.f32 	%r155, %r128, 0fC3000000;
(EngineCore_DP0 pid=444692) 	min.f32 	%r156, %r155, 0f42FE0000;
(EngineCore_DP0 pid=444692) 	min.f32 	%r157, %r154, 0f42FE0000;
(EngineCore_DP0 pid=444692) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=444692) 	cvt.rzi.s32.f32 	%r158, %r157;
(EngineCore_DP0 pid=444692) 	cvt.rzi.s32.f32 	%r159, %r156;
(EngineCore_DP0 pid=444692) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=444692) 	shl.b32 	%r160, %r159, 8;
(EngineCore_DP0 pid=444692) 	shl.b32 	%r161, %r158, 16;
(EngineCore_DP0 pid=444692) 	and.b32 	%r162, %r161, 16711680;
(EngineCore_DP0 pid=444692) 	and.b32 	%r163, %r160, 65280;
(EngineCore_DP0 pid=444692) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=444692) 	or.b32 	%r164, %r163, %r124;
(EngineCore_DP0 pid=444692) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=444692) 	or.b32 	%r165, %r153, %r151;
(EngineCore_DP0 pid=444692) 	or.b32 	%r166, %r164, %r162;
(EngineCore_DP0 pid=444692) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=444692) 	shl.b32 	%r167, %r141, 24;
(EngineCore_DP0 pid=444692) 	shl.b32 	%r168, %r142, 24;
(EngineCore_DP0 pid=444692) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=444692) 	or.b32 	%r78, %r165, %r167;
(EngineCore_DP0 pid=444692) 	or.b32 	%r79, %r166, %r168;
(EngineCore_DP0 pid=444692) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=444692) 	mad.wide.s32 	%rd16, %r81, 4, %rd2;
(EngineCore_DP0 pid=444692) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=444692) 	// begin inline asm
(EngineCore_DP0 pid=444692) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r78, %r79 };
(EngineCore_DP0 pid=444692) 	// end inline asm
(EngineCore_DP0 pid=444692) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=444692) 	add.s32 	%r172, %r172, 1024;
(EngineCore_DP0 pid=444692) 	setp.lt.s32 	%p26, %r172, %r15;
(EngineCore_DP0 pid=444692) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=444692) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=444692) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=444692) 	ret;
(EngineCore_DP0 pid=444692) $L__tmp3:
(EngineCore_DP0 pid=444692) $L__func_end0:
(EngineCore_DP0 pid=444692)                                         // -- End function
(EngineCore_DP0 pid=444692) }
(EngineCore_DP0 pid=444692) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=444692) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=444692) 	.section	.debug_abbrev
(EngineCore_DP0 pid=444692) 	{
(EngineCore_DP0 pid=444692) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=444692) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=444692) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=444692) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=444692) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=444692) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=444692) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=444692) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=444692) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=444692) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=444692) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=444692) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=444692) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=444692) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=444692) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=444692) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=444692) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=444692) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=444692) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=444692) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=444692) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=444692) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=444692) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=444692) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=444692) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=444692) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=444692) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=444692) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=444692) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=444692) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=444692) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=444692) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=444692) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=444692) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=444692) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=444692) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=444692) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=444692) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=444692) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=444692) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=444692) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=444692) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=444692) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=444692) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=444692) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=444692) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=444692) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=444692) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=444692) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=444692) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=444692) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=444692) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=444692) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=444692) 	}
(EngineCore_DP0 pid=444692) 	.section	.debug_info
(EngineCore_DP0 pid=444692) 	{
(EngineCore_DP0 pid=444692) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=444692) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=444692) .b8 0
(EngineCore_DP0 pid=444692) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=444692) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=444692) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=444692) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=444692) .b8 114
(EngineCore_DP0 pid=444692) .b8 105
(EngineCore_DP0 pid=444692) .b8 116
(EngineCore_DP0 pid=444692) .b8 111
(EngineCore_DP0 pid=444692) .b8 110
(EngineCore_DP0 pid=444692) .b8 0
(EngineCore_DP0 pid=444692) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=444692) .b8 0
(EngineCore_DP0 pid=444692) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=444692) .b8 117
(EngineCore_DP0 pid=444692) .b8 97
(EngineCore_DP0 pid=444692) .b8 110
(EngineCore_DP0 pid=444692) .b8 116
(EngineCore_DP0 pid=444692) .b8 95
(EngineCore_DP0 pid=444692) .b8 115
(EngineCore_DP0 pid=444692) .b8 108
(EngineCore_DP0 pid=444692) .b8 105
(EngineCore_DP0 pid=444692) .b8 100
(EngineCore_DP0 pid=444692) .b8 101
(EngineCore_DP0 pid=444692) .b8 95
(EngineCore_DP0 pid=444692) .b8 116
(EngineCore_DP0 pid=444692) .b8 117
(EngineCore_DP0 pid=444692) .b8 110
(EngineCore_DP0 pid=444692) .b8 101
(EngineCore_DP0 pid=444692) .b8 100
(EngineCore_DP0 pid=444692) .b8 95
(EngineCore_DP0 pid=444692) .b8 81
(EngineCore_DP0 pid=444692) .b8 119
(EngineCore_DP0 pid=444692) .b8 101
(EngineCore_DP0 pid=444692) .b8 110
(EngineCore_DP0 pid=444692) .b8 50
(EngineCore_DP0 pid=444692) .b8 46
(EngineCore_DP0 pid=444692) .b8 53
(EngineCore_DP0 pid=444692) .b8 45
(EngineCore_DP0 pid=444692) .b8 55
(EngineCore_DP0 pid=444692) .b8 66
(EngineCore_DP0 pid=444692) .b8 46
(EngineCore_DP0 pid=444692) .b8 112
(EngineCore_DP0 pid=444692) .b8 121
(EngineCore_DP0 pid=444692) .b8 0
(EngineCore_DP0 pid=444692) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=444692) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=444692) .b8 114
(EngineCore_DP0 pid=444692) .b8 111
(EngineCore_DP0 pid=444692) .b8 111
(EngineCore_DP0 pid=444692) .b8 116
(EngineCore_DP0 pid=444692) .b8 47
(EngineCore_DP0 pid=444692) .b8 118
(EngineCore_DP0 pid=444692) .b8 108
(EngineCore_DP0 pid=444692) .b8 108
(EngineCore_DP0 pid=444692) .b8 109
(EngineCore_DP0 pid=444692) .b8 98
(EngineCore_DP0 pid=444692) .b8 101
(EngineCore_DP0 pid=444692) .b8 110
(EngineCore_DP0 pid=444692) .b8 99
(EngineCore_DP0 pid=444692) .b8 104
(EngineCore_DP0 pid=444692) .b8 47
(EngineCore_DP0 pid=444692) .b8 115
(EngineCore_DP0 pid=444692) .b8 108
(EngineCore_DP0 pid=444692) .b8 105
(EngineCore_DP0 pid=444692) .b8 100
(EngineCore_DP0 pid=444692) .b8 101
(EngineCore_DP0 pid=444692) .b8 115
(EngineCore_DP0 pid=444692) .b8 112
(EngineCore_DP0 pid=444692) .b8 97
(EngineCore_DP0 pid=444692) .b8 114
(EngineCore_DP0 pid=444692) .b8 115
(EngineCore_DP0 pid=444692) .b8 101
(EngineCore_DP0 pid=444692) .b8 47
(EngineCore_DP0 pid=444692) .b8 99
(EngineCore_DP0 pid=444692) .b8 115
(EngineCore_DP0 pid=444692) .b8 114
(EngineCore_DP0 pid=444692) .b8 99
(EngineCore_DP0 pid=444692) .b8 47
(EngineCore_DP0 pid=444692) .b8 102
(EngineCore_DP0 pid=444692) .b8 117
(EngineCore_DP0 pid=444692) .b8 115
(EngineCore_DP0 pid=444692) .b8 101
(EngineCore_DP0 pid=444692) .b8 100
(EngineCore_DP0 pid=444692) .b8 95
(EngineCore_DP0 pid=444692) .b8 113
(EngineCore_DP0 pid=444692) .b8 117
(EngineCore_DP0 pid=444692) .b8 97
(EngineCore_DP0 pid=444692) .b8 110
(EngineCore_DP0 pid=444692) .b8 116
(EngineCore_DP0 pid=444692) .b8 95
(EngineCore_DP0 pid=444692) .b8 115
(EngineCore_DP0 pid=444692) .b8 108
(EngineCore_DP0 pid=444692) .b8 105
(EngineCore_DP0 pid=444692) .b8 100
(EngineCore_DP0 pid=444692) .b8 101
(EngineCore_DP0 pid=444692) .b8 95
(EngineCore_DP0 pid=444692) .b8 116
(EngineCore_DP0 pid=444692) .b8 114
(EngineCore_DP0 pid=444692) .b8 105
(EngineCore_DP0 pid=444692) .b8 116
(EngineCore_DP0 pid=444692) .b8 111
(EngineCore_DP0 pid=444692) .b8 110
(EngineCore_DP0 pid=444692) .b8 47
(EngineCore_DP0 pid=444692) .b8 98
(EngineCore_DP0 pid=444692) .b8 117
(EngineCore_DP0 pid=444692) .b8 105
(EngineCore_DP0 pid=444692) .b8 108
(EngineCore_DP0 pid=444692) .b8 100
(EngineCore_DP0 pid=444692) .b8 47
(EngineCore_DP0 pid=444692) .b8 71
(EngineCore_DP0 pid=444692) .b8 66
(EngineCore_DP0 pid=444692) .b8 49
(EngineCore_DP0 pid=444692) .b8 48
(EngineCore_DP0 pid=444692) .b8 95
(EngineCore_DP0 pid=444692) .b8 99
(EngineCore_DP0 pid=444692) .b8 99
(EngineCore_DP0 pid=444692) .b8 49
(EngineCore_DP0 pid=444692) .b8 50
(EngineCore_DP0 pid=444692) .b8 49
(EngineCore_DP0 pid=444692) .b8 95
(EngineCore_DP0 pid=444692) .b8 112
(EngineCore_DP0 pid=444692) .b8 121
(EngineCore_DP0 pid=444692) .b8 51
(EngineCore_DP0 pid=444692) .b8 49
(EngineCore_DP0 pid=444692) .b8 50
(EngineCore_DP0 pid=444692) .b8 95
(EngineCore_DP0 pid=444692) .b8 99
(EngineCore_DP0 pid=444692) .b8 117
(EngineCore_DP0 pid=444692) .b8 49
(EngineCore_DP0 pid=444692) .b8 50
(EngineCore_DP0 pid=444692) .b8 57
(EngineCore_DP0 pid=444692) .b8 95
(EngineCore_DP0 pid=444692) .b8 97
(EngineCore_DP0 pid=444692) .b8 97
(EngineCore_DP0 pid=444692) .b8 114
(EngineCore_DP0 pid=444692) .b8 99
(EngineCore_DP0 pid=444692) .b8 104
(EngineCore_DP0 pid=444692) .b8 54
(EngineCore_DP0 pid=444692) .b8 52
(EngineCore_DP0 pid=444692) .b8 0
(EngineCore_DP0 pid=444692) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=444692) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=444692) .b8 113
(EngineCore_DP0 pid=444692) .b8 117
(EngineCore_DP0 pid=444692) .b8 97
(EngineCore_DP0 pid=444692) .b8 110
(EngineCore_DP0 pid=444692) .b8 116
(EngineCore_DP0 pid=444692) .b8 95
(EngineCore_DP0 pid=444692) .b8 115
(EngineCore_DP0 pid=444692) .b8 108
(EngineCore_DP0 pid=444692) .b8 105
(EngineCore_DP0 pid=444692) .b8 100
(EngineCore_DP0 pid=444692) .b8 101
(EngineCore_DP0 pid=444692) .b8 95
(EngineCore_DP0 pid=444692) .b8 105
(EngineCore_DP0 pid=444692) .b8 110
(EngineCore_DP0 pid=444692) .b8 116
(EngineCore_DP0 pid=444692) .b8 56
(EngineCore_DP0 pid=444692) .b8 95
(EngineCore_DP0 pid=444692) .b8 107
(EngineCore_DP0 pid=444692) .b8 101
(EngineCore_DP0 pid=444692) .b8 114
(EngineCore_DP0 pid=444692) .b8 110
(EngineCore_DP0 pid=444692) .b8 101
(EngineCore_DP0 pid=444692) .b8 108
(EngineCore_DP0 pid=444692) .b8 0
(EngineCore_DP0 pid=444692) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=444692) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=444692) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=444692) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=444692) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=444692) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=444692) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=444692) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=444692) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=444692) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=444692) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=444692) .b8 1
(EngineCore_DP0 pid=444692) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=444692) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=444692) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=444692) 	}
(EngineCore_DP0 pid=444692) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=444692) 
(EngineCore_DP0 pid=444692) ================================================================
(EngineCore_DP0 pid=444692) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=444692) 
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp39ita67i.ptx', '-o', '/tmp/tmp39ita67i.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866] 
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866] 
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866] 
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp39ita67i.ptx -o /tmp/tmp39ita67i.ptx.o
(EngineCore_DP0 pid=444692) ERROR 01-25 20:56:01 [core.py:866] 

STDERR:
[2026-01-25 20:54:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:54:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:54:53] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:54:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:54:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:54:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:54:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:54:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:54:57] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:54:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:54:57] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:54:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:54:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:54:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:54:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:54:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:54:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=444692) [2026-01-25 20:54:58] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=444692) [2026-01-25 20:54:58] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=444692) [2026-01-25 20:54:58] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=444692) [2026-01-25 20:54:58] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=444692) [2026-01-25 20:54:58] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=444692) [2026-01-25 20:54:58] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=444692) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=444692) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.43s/it]
(EngineCore_DP0 pid=444692) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.59s/it]
(EngineCore_DP0 pid=444692) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.12s/it]
(EngineCore_DP0 pid=444692) 
(EngineCore_DP0 pid=444692) [2026-01-25 20:55:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=444692) [2026-01-25 20:55:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=444692) [2026-01-25 20:55:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=444692) [2026-01-25 20:55:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=444692) [2026-01-25 20:55:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=444692) [2026-01-25 20:55:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=444692) [2026-01-25 20:55:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=444692) [2026-01-25 20:55:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=444692) Process EngineCore_DP0:
(EngineCore_DP0 pid=444692) Traceback (most recent call last):
(EngineCore_DP0 pid=444692)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=444692)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=444692)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=444692)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=444692) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp39ita67i.ptx', '-o', '/tmp/tmp39ita67i.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=444692) 
(EngineCore_DP0 pid=444692) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=444692) 
(EngineCore_DP0 pid=444692) Traceback (most recent call last):
(EngineCore_DP0 pid=444692)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=444692)     self.run()
(EngineCore_DP0 pid=444692)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=444692)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=444692)     raise e
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=444692)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=444692)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=444692)     super().__init__(
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=444692)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=444692)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=444692)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=444692)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=444692)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=444692)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=444692)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=444692)     return func(*args, **kwargs)
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=444692)     return func(*args, **kwargs)
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=444692)     self.model_runner.profile_run()
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=444692)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=444692)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=444692)     return func(*args, **kwargs)
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=444692)     outputs = self.model(
(EngineCore_DP0 pid=444692)               ^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=444692)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=444692)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=444692)     hidden_states = self.model(
(EngineCore_DP0 pid=444692)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=444692)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=444692)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=444692)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=444692)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=444692)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=444692)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=444692)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=444692)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=444692)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=444692)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=444692)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=444692)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=444692)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=444692)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=444692)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=444692)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=444692)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=444692)     return self._linear_fn(
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=444692)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=444692)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=444692)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=444692)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=444692)     return fn(input, L)
(EngineCore_DP0 pid=444692)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=444692)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=444692)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=444692)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=444692)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=444692)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=444692)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=444692)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=444692)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=444692)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=444692)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=444692)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=444692)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=444692)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=444692)     raise PTXASError(error)
(EngineCore_DP0 pid=444692) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=444692) `ptxas` stderr:
(EngineCore_DP0 pid=444692) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=444692) 
(EngineCore_DP0 pid=444692) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp39ita67i.ptx -o /tmp/tmp39ita67i.ptx.o
(EngineCore_DP0 pid=444692) 
[rank0]:[W125 20:56:02.271138301 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 20:56:03
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:56:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:56:36 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=446285) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=446285) 
(EngineCore_DP0 pid=446285) 
(EngineCore_DP0 pid=446285) ================================================================
(EngineCore_DP0 pid=446285) Internal Triton PTX codegen error
(EngineCore_DP0 pid=446285) `ptxas` stderr:
(EngineCore_DP0 pid=446285) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=446285) 
(EngineCore_DP0 pid=446285) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpnpojcrme.ptx -o /tmp/tmpnpojcrme.ptx.o
(EngineCore_DP0 pid=446285) 
(EngineCore_DP0 pid=446285) 
(EngineCore_DP0 pid=446285) //
(EngineCore_DP0 pid=446285) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=446285) //
(EngineCore_DP0 pid=446285) 
(EngineCore_DP0 pid=446285) .version 8.7
(EngineCore_DP0 pid=446285) .target sm_121a
(EngineCore_DP0 pid=446285) .address_size 64
(EngineCore_DP0 pid=446285) 
(EngineCore_DP0 pid=446285) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=446285) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=446285)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=446285) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=446285) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=446285) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=446285) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=446285) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=446285) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=446285) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=446285) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=446285) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=446285) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=446285) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=446285) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=446285) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=446285) )
(EngineCore_DP0 pid=446285) .reqntid 512
(EngineCore_DP0 pid=446285) {
(EngineCore_DP0 pid=446285) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=446285) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=446285) 	.reg .b32 	%r<132>;
(EngineCore_DP0 pid=446285) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=446285) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=446285) $L__func_begin0:
(EngineCore_DP0 pid=446285) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=446285) 
(EngineCore_DP0 pid=446285) // %bb.0:
(EngineCore_DP0 pid=446285) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=446285) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=446285) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=446285) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=446285) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=446285) $L__tmp0:
(EngineCore_DP0 pid=446285) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=446285) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=446285) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=446285) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=446285) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=446285) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=446285) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=446285) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=446285) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=446285) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=446285) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=446285) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=446285) 	mov.b32 	%r130, 0f2B8CBCCC;
(EngineCore_DP0 pid=446285) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=446285) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=446285) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=446285) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=446285) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=446285) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=446285) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=446285) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=446285) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=446285) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=446285) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=446285) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=446285) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=446285) 	mov.b32 	%r128, 0f00000000;
(EngineCore_DP0 pid=446285) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=446285) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=446285) 	mov.b32 	%r129, %r40;
(EngineCore_DP0 pid=446285) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=446285) 	.loc	1 265 19                        // quant_slide_tuned_Qwen2.5-7B.py:265:19
(EngineCore_DP0 pid=446285) 	add.s32 	%r58, %r4, %r129;
(EngineCore_DP0 pid=446285) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=446285) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=446285) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=446285) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=446285) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=446285) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=446285) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=446285) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=446285) 	// begin inline asm
(EngineCore_DP0 pid=446285) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=446285) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=446285) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=446285) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=446285) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=446285) 	// end inline asm
(EngineCore_DP0 pid=446285) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=446285) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=446285) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=446285) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=446285) 	// begin inline asm
(EngineCore_DP0 pid=446285) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=446285) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=446285) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=446285) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=446285) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=446285) 	// end inline asm
(EngineCore_DP0 pid=446285) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=446285) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=446285) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=446285) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=446285) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=446285) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=446285) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=446285) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=446285) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=446285) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=446285) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=446285) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=446285) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=446285) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=446285) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=446285) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=446285) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=446285) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=446285) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=446285) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=446285) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=446285) $L__tmp1:
(EngineCore_DP0 pid=446285) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	bar.sync 	0;
(EngineCore_DP0 pid=446285) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=446285) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=446285) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=446285) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=446285) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=446285) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=446285) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=446285) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=446285) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=446285) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=446285) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=446285) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=446285) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=446285) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=446285) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=446285) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=446285) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=446285) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=446285) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=446285) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=446285) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=446285) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=446285) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=446285) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=446285) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=446285) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=446285) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	// begin inline asm
(EngineCore_DP0 pid=446285) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=446285) 	// end inline asm
(EngineCore_DP0 pid=446285) 	bar.sync 	0;
(EngineCore_DP0 pid=446285) 	// begin inline asm
(EngineCore_DP0 pid=446285) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=446285) 	// end inline asm
(EngineCore_DP0 pid=446285) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=446285) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=446285) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=446285) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=446285) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=446285) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=446285) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=446285) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=446285) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=446285) 	// begin inline asm
(EngineCore_DP0 pid=446285) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=446285) 	// end inline asm
(EngineCore_DP0 pid=446285) 	bar.sync 	0;
(EngineCore_DP0 pid=446285) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=446285) $L__tmp2:
(EngineCore_DP0 pid=446285) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=446285) 	max.f32 	%r128, %r128, %r77;
(EngineCore_DP0 pid=446285) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=446285) 	add.s32 	%r129, %r129, 8192;
(EngineCore_DP0 pid=446285) 	setp.lt.s32 	%p7, %r129, %r19;
(EngineCore_DP0 pid=446285) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=446285) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=446285) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=446285) 	max.f32 	%r130, %r128, 0f2B8CBCCC;
(EngineCore_DP0 pid=446285) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=446285) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=446285) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=446285) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=446285) 	div.full.f32 	%r80, %r130, %r79;
(EngineCore_DP0 pid=446285) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=446285) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=446285) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=446285) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=446285) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=446285) 	// begin inline asm
(EngineCore_DP0 pid=446285) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=446285) 	// end inline asm
(EngineCore_DP0 pid=446285) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=446285) 	mul.lo.s32 	%r15, %r20, 3;
(EngineCore_DP0 pid=446285) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=446285) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=446285) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=446285) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=446285) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=446285) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=446285) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=446285) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=446285) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=446285) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=446285) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=446285) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=446285) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=446285) 	div.full.f32 	%r14, %r79, %r130;
(EngineCore_DP0 pid=446285) 	mov.b32 	%r131, 0;
(EngineCore_DP0 pid=446285) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=446285)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=446285) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=446285) 	add.s32 	%r84, %r3, %r131;
(EngineCore_DP0 pid=446285) 	setp.lt.s32 	%p14, %r84, %r15;
(EngineCore_DP0 pid=446285) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=446285) 	mul.hi.s32 	%r85, %r84, 1431655766;
(EngineCore_DP0 pid=446285) 	shr.u32 	%r86, %r85, 31;
(EngineCore_DP0 pid=446285) 	add.s32 	%r87, %r85, %r86;
(EngineCore_DP0 pid=446285) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=446285) 	mul.lo.s32 	%r88, %r87, 3;
(EngineCore_DP0 pid=446285) 	sub.s32 	%r89, %r84, %r88;
(EngineCore_DP0 pid=446285) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=446285) 	shl.b32 	%r90, %r87, 3;
(EngineCore_DP0 pid=446285) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=446285) 	shl.b32 	%r91, %r89, 1;
(EngineCore_DP0 pid=446285) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=446285) 	add.s32 	%r92, %r90, %r91;
(EngineCore_DP0 pid=446285) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=446285) 	setp.lt.s32 	%p15, %r92, %r18;
(EngineCore_DP0 pid=446285) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=446285) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=446285) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=446285) 	mad.wide.s32 	%rd9, %r92, 2, %rd1;
(EngineCore_DP0 pid=446285) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=446285) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=446285) 	// begin inline asm
(EngineCore_DP0 pid=446285) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=446285) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=446285) 	// end inline asm
(EngineCore_DP0 pid=446285) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=446285) 	cvt.f32.bf16 	%r93, %rs48;
(EngineCore_DP0 pid=446285) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=446285) 	or.b32 	%r94, %r92, 1;
(EngineCore_DP0 pid=446285) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=446285) 	setp.lt.s32 	%p16, %r94, %r18;
(EngineCore_DP0 pid=446285) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=446285) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=446285) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=446285) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=446285) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=446285) 	// begin inline asm
(EngineCore_DP0 pid=446285) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=446285) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=446285) 	// end inline asm
(EngineCore_DP0 pid=446285) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=446285) 	cvt.f32.bf16 	%r95, %rs50;
(EngineCore_DP0 pid=446285) 	.loc	1 292 48                        // quant_slide_tuned_Qwen2.5-7B.py:292:48
(EngineCore_DP0 pid=446285) 	add.s32 	%r96, %r92, 2;
(EngineCore_DP0 pid=446285) 	.loc	1 292 53                        // quant_slide_tuned_Qwen2.5-7B.py:292:53
(EngineCore_DP0 pid=446285) 	setp.lt.s32 	%p17, %r96, %r18;
(EngineCore_DP0 pid=446285) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=446285) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=446285) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=446285) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=446285) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=446285) 	// begin inline asm
(EngineCore_DP0 pid=446285) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=446285) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=446285) 	// end inline asm
(EngineCore_DP0 pid=446285) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=446285) 	cvt.f32.bf16 	%r97, %rs52;
(EngineCore_DP0 pid=446285) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=446285) 	add.s32 	%r98, %r92, 3;
(EngineCore_DP0 pid=446285) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=446285) 	setp.lt.s32 	%p18, %r98, %r18;
(EngineCore_DP0 pid=446285) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=446285) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=446285) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=446285) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=446285) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=446285) 	// begin inline asm
(EngineCore_DP0 pid=446285) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=446285) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=446285) 	// end inline asm
(EngineCore_DP0 pid=446285) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=446285) 	cvt.f32.bf16 	%r99, %rs54;
(EngineCore_DP0 pid=446285) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=446285) 	mul.f32 	%r100, %r14, %r93;
(EngineCore_DP0 pid=446285) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=446285) 	cvt.rni.f32.f32 	%r101, %r100;
(EngineCore_DP0 pid=446285) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=446285) 	max.f32 	%r102, %r101, 0fC3000000;
(EngineCore_DP0 pid=446285) 	min.f32 	%r103, %r102, 0f42FE0000;
(EngineCore_DP0 pid=446285) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=446285) 	cvt.rzi.s32.f32 	%r104, %r103;
(EngineCore_DP0 pid=446285) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=446285) 	and.b32 	%r105, %r104, 255;
(EngineCore_DP0 pid=446285) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=446285) 	mul.f32 	%r106, %r14, %r95;
(EngineCore_DP0 pid=446285) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=446285) 	cvt.rni.f32.f32 	%r107, %r106;
(EngineCore_DP0 pid=446285) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=446285) 	mul.f32 	%r108, %r14, %r97;
(EngineCore_DP0 pid=446285) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=446285) 	cvt.rni.f32.f32 	%r109, %r108;
(EngineCore_DP0 pid=446285) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=446285) 	mul.f32 	%r110, %r14, %r99;
(EngineCore_DP0 pid=446285) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=446285) 	cvt.rni.f32.f32 	%r111, %r110;
(EngineCore_DP0 pid=446285) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=446285) 	max.f32 	%r112, %r111, 0fC3000000;
(EngineCore_DP0 pid=446285) 	min.f32 	%r113, %r112, 0f42FE0000;
(EngineCore_DP0 pid=446285) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=446285) 	cvt.rzi.s32.f32 	%r114, %r113;
(EngineCore_DP0 pid=446285) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=446285) 	max.f32 	%r115, %r109, 0fC3000000;
(EngineCore_DP0 pid=446285) 	max.f32 	%r116, %r107, 0fC3000000;
(EngineCore_DP0 pid=446285) 	min.f32 	%r117, %r116, 0f42FE0000;
(EngineCore_DP0 pid=446285) 	min.f32 	%r118, %r115, 0f42FE0000;
(EngineCore_DP0 pid=446285) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=446285) 	cvt.rzi.s32.f32 	%r119, %r118;
(EngineCore_DP0 pid=446285) 	cvt.rzi.s32.f32 	%r120, %r117;
(EngineCore_DP0 pid=446285) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=446285) 	shl.b32 	%r121, %r120, 8;
(EngineCore_DP0 pid=446285) 	shl.b32 	%r122, %r119, 16;
(EngineCore_DP0 pid=446285) 	and.b32 	%r123, %r122, 16711680;
(EngineCore_DP0 pid=446285) 	and.b32 	%r124, %r121, 65280;
(EngineCore_DP0 pid=446285) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=446285) 	or.b32 	%r125, %r124, %r105;
(EngineCore_DP0 pid=446285) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=446285) 	or.b32 	%r126, %r125, %r123;
(EngineCore_DP0 pid=446285) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=446285) 	shl.b32 	%r127, %r114, 24;
(EngineCore_DP0 pid=446285) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=446285) 	or.b32 	%r82, %r126, %r127;
(EngineCore_DP0 pid=446285) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=446285) 	mad.wide.s32 	%rd13, %r84, 4, %rd2;
(EngineCore_DP0 pid=446285) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=446285) 	// begin inline asm
(EngineCore_DP0 pid=446285) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r82 };
(EngineCore_DP0 pid=446285) 	// end inline asm
(EngineCore_DP0 pid=446285) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=446285) 	add.s32 	%r131, %r131, 512;
(EngineCore_DP0 pid=446285) 	setp.lt.s32 	%p19, %r131, %r15;
(EngineCore_DP0 pid=446285) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=446285) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=446285) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=446285) 	ret;
(EngineCore_DP0 pid=446285) $L__tmp3:
(EngineCore_DP0 pid=446285) $L__func_end0:
(EngineCore_DP0 pid=446285)                                         // -- End function
(EngineCore_DP0 pid=446285) }
(EngineCore_DP0 pid=446285) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=446285) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=446285) 	.section	.debug_abbrev
(EngineCore_DP0 pid=446285) 	{
(EngineCore_DP0 pid=446285) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=446285) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=446285) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=446285) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=446285) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=446285) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=446285) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=446285) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=446285) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=446285) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=446285) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=446285) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=446285) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=446285) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=446285) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=446285) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=446285) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=446285) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=446285) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=446285) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=446285) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=446285) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=446285) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=446285) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=446285) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=446285) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=446285) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=446285) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=446285) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=446285) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=446285) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=446285) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=446285) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=446285) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=446285) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=446285) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=446285) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=446285) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=446285) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=446285) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=446285) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=446285) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=446285) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=446285) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=446285) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=446285) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=446285) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=446285) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=446285) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=446285) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=446285) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=446285) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=446285) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=446285) 	}
(EngineCore_DP0 pid=446285) 	.section	.debug_info
(EngineCore_DP0 pid=446285) 	{
(EngineCore_DP0 pid=446285) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=446285) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=446285) .b8 0
(EngineCore_DP0 pid=446285) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=446285) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=446285) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=446285) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=446285) .b8 114
(EngineCore_DP0 pid=446285) .b8 105
(EngineCore_DP0 pid=446285) .b8 116
(EngineCore_DP0 pid=446285) .b8 111
(EngineCore_DP0 pid=446285) .b8 110
(EngineCore_DP0 pid=446285) .b8 0
(EngineCore_DP0 pid=446285) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=446285) .b8 0
(EngineCore_DP0 pid=446285) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=446285) .b8 117
(EngineCore_DP0 pid=446285) .b8 97
(EngineCore_DP0 pid=446285) .b8 110
(EngineCore_DP0 pid=446285) .b8 116
(EngineCore_DP0 pid=446285) .b8 95
(EngineCore_DP0 pid=446285) .b8 115
(EngineCore_DP0 pid=446285) .b8 108
(EngineCore_DP0 pid=446285) .b8 105
(EngineCore_DP0 pid=446285) .b8 100
(EngineCore_DP0 pid=446285) .b8 101
(EngineCore_DP0 pid=446285) .b8 95
(EngineCore_DP0 pid=446285) .b8 116
(EngineCore_DP0 pid=446285) .b8 117
(EngineCore_DP0 pid=446285) .b8 110
(EngineCore_DP0 pid=446285) .b8 101
(EngineCore_DP0 pid=446285) .b8 100
(EngineCore_DP0 pid=446285) .b8 95
(EngineCore_DP0 pid=446285) .b8 81
(EngineCore_DP0 pid=446285) .b8 119
(EngineCore_DP0 pid=446285) .b8 101
(EngineCore_DP0 pid=446285) .b8 110
(EngineCore_DP0 pid=446285) .b8 50
(EngineCore_DP0 pid=446285) .b8 46
(EngineCore_DP0 pid=446285) .b8 53
(EngineCore_DP0 pid=446285) .b8 45
(EngineCore_DP0 pid=446285) .b8 55
(EngineCore_DP0 pid=446285) .b8 66
(EngineCore_DP0 pid=446285) .b8 46
(EngineCore_DP0 pid=446285) .b8 112
(EngineCore_DP0 pid=446285) .b8 121
(EngineCore_DP0 pid=446285) .b8 0
(EngineCore_DP0 pid=446285) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=446285) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=446285) .b8 114
(EngineCore_DP0 pid=446285) .b8 111
(EngineCore_DP0 pid=446285) .b8 111
(EngineCore_DP0 pid=446285) .b8 116
(EngineCore_DP0 pid=446285) .b8 47
(EngineCore_DP0 pid=446285) .b8 118
(EngineCore_DP0 pid=446285) .b8 108
(EngineCore_DP0 pid=446285) .b8 108
(EngineCore_DP0 pid=446285) .b8 109
(EngineCore_DP0 pid=446285) .b8 98
(EngineCore_DP0 pid=446285) .b8 101
(EngineCore_DP0 pid=446285) .b8 110
(EngineCore_DP0 pid=446285) .b8 99
(EngineCore_DP0 pid=446285) .b8 104
(EngineCore_DP0 pid=446285) .b8 47
(EngineCore_DP0 pid=446285) .b8 115
(EngineCore_DP0 pid=446285) .b8 108
(EngineCore_DP0 pid=446285) .b8 105
(EngineCore_DP0 pid=446285) .b8 100
(EngineCore_DP0 pid=446285) .b8 101
(EngineCore_DP0 pid=446285) .b8 115
(EngineCore_DP0 pid=446285) .b8 112
(EngineCore_DP0 pid=446285) .b8 97
(EngineCore_DP0 pid=446285) .b8 114
(EngineCore_DP0 pid=446285) .b8 115
(EngineCore_DP0 pid=446285) .b8 101
(EngineCore_DP0 pid=446285) .b8 47
(EngineCore_DP0 pid=446285) .b8 99
(EngineCore_DP0 pid=446285) .b8 115
(EngineCore_DP0 pid=446285) .b8 114
(EngineCore_DP0 pid=446285) .b8 99
(EngineCore_DP0 pid=446285) .b8 47
(EngineCore_DP0 pid=446285) .b8 102
(EngineCore_DP0 pid=446285) .b8 117
(EngineCore_DP0 pid=446285) .b8 115
(EngineCore_DP0 pid=446285) .b8 101
(EngineCore_DP0 pid=446285) .b8 100
(EngineCore_DP0 pid=446285) .b8 95
(EngineCore_DP0 pid=446285) .b8 113
(EngineCore_DP0 pid=446285) .b8 117
(EngineCore_DP0 pid=446285) .b8 97
(EngineCore_DP0 pid=446285) .b8 110
(EngineCore_DP0 pid=446285) .b8 116
(EngineCore_DP0 pid=446285) .b8 95
(EngineCore_DP0 pid=446285) .b8 115
(EngineCore_DP0 pid=446285) .b8 108
(EngineCore_DP0 pid=446285) .b8 105
(EngineCore_DP0 pid=446285) .b8 100
(EngineCore_DP0 pid=446285) .b8 101
(EngineCore_DP0 pid=446285) .b8 95
(EngineCore_DP0 pid=446285) .b8 116
(EngineCore_DP0 pid=446285) .b8 114
(EngineCore_DP0 pid=446285) .b8 105
(EngineCore_DP0 pid=446285) .b8 116
(EngineCore_DP0 pid=446285) .b8 111
(EngineCore_DP0 pid=446285) .b8 110
(EngineCore_DP0 pid=446285) .b8 47
(EngineCore_DP0 pid=446285) .b8 98
(EngineCore_DP0 pid=446285) .b8 117
(EngineCore_DP0 pid=446285) .b8 105
(EngineCore_DP0 pid=446285) .b8 108
(EngineCore_DP0 pid=446285) .b8 100
(EngineCore_DP0 pid=446285) .b8 47
(EngineCore_DP0 pid=446285) .b8 71
(EngineCore_DP0 pid=446285) .b8 66
(EngineCore_DP0 pid=446285) .b8 49
(EngineCore_DP0 pid=446285) .b8 48
(EngineCore_DP0 pid=446285) .b8 95
(EngineCore_DP0 pid=446285) .b8 99
(EngineCore_DP0 pid=446285) .b8 99
(EngineCore_DP0 pid=446285) .b8 49
(EngineCore_DP0 pid=446285) .b8 50
(EngineCore_DP0 pid=446285) .b8 49
(EngineCore_DP0 pid=446285) .b8 95
(EngineCore_DP0 pid=446285) .b8 112
(EngineCore_DP0 pid=446285) .b8 121
(EngineCore_DP0 pid=446285) .b8 51
(EngineCore_DP0 pid=446285) .b8 49
(EngineCore_DP0 pid=446285) .b8 50
(EngineCore_DP0 pid=446285) .b8 95
(EngineCore_DP0 pid=446285) .b8 99
(EngineCore_DP0 pid=446285) .b8 117
(EngineCore_DP0 pid=446285) .b8 49
(EngineCore_DP0 pid=446285) .b8 50
(EngineCore_DP0 pid=446285) .b8 57
(EngineCore_DP0 pid=446285) .b8 95
(EngineCore_DP0 pid=446285) .b8 97
(EngineCore_DP0 pid=446285) .b8 97
(EngineCore_DP0 pid=446285) .b8 114
(EngineCore_DP0 pid=446285) .b8 99
(EngineCore_DP0 pid=446285) .b8 104
(EngineCore_DP0 pid=446285) .b8 54
(EngineCore_DP0 pid=446285) .b8 52
(EngineCore_DP0 pid=446285) .b8 0
(EngineCore_DP0 pid=446285) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=446285) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=446285) .b8 113
(EngineCore_DP0 pid=446285) .b8 117
(EngineCore_DP0 pid=446285) .b8 97
(EngineCore_DP0 pid=446285) .b8 110
(EngineCore_DP0 pid=446285) .b8 116
(EngineCore_DP0 pid=446285) .b8 95
(EngineCore_DP0 pid=446285) .b8 115
(EngineCore_DP0 pid=446285) .b8 108
(EngineCore_DP0 pid=446285) .b8 105
(EngineCore_DP0 pid=446285) .b8 100
(EngineCore_DP0 pid=446285) .b8 101
(EngineCore_DP0 pid=446285) .b8 95
(EngineCore_DP0 pid=446285) .b8 105
(EngineCore_DP0 pid=446285) .b8 110
(EngineCore_DP0 pid=446285) .b8 116
(EngineCore_DP0 pid=446285) .b8 56
(EngineCore_DP0 pid=446285) .b8 95
(EngineCore_DP0 pid=446285) .b8 107
(EngineCore_DP0 pid=446285) .b8 101
(EngineCore_DP0 pid=446285) .b8 114
(EngineCore_DP0 pid=446285) .b8 110
(EngineCore_DP0 pid=446285) .b8 101
(EngineCore_DP0 pid=446285) .b8 108
(EngineCore_DP0 pid=446285) .b8 0
(EngineCore_DP0 pid=446285) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=446285) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=446285) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=446285) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=446285) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=446285) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=446285) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=446285) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=446285) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=446285) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=446285) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=446285) .b8 1
(EngineCore_DP0 pid=446285) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=446285) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=446285) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=446285) 	}
(EngineCore_DP0 pid=446285) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=446285) 
(EngineCore_DP0 pid=446285) ================================================================
(EngineCore_DP0 pid=446285) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=446285) 
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpnpojcrme.ptx', '-o', '/tmp/tmpnpojcrme.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866] 
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866] 
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866] 
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpnpojcrme.ptx -o /tmp/tmpnpojcrme.ptx.o
(EngineCore_DP0 pid=446285) ERROR 01-25 20:57:44 [core.py:866] 

STDERR:
[2026-01-25 20:56:35] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:56:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:56:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:56:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:56:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:56:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:56:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:56:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:56:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:56:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:56:39] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:56:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:56:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:56:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:56:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:56:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:56:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=446285) [2026-01-25 20:56:40] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=446285) [2026-01-25 20:56:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=446285) [2026-01-25 20:56:40] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=446285) [2026-01-25 20:56:40] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=446285) [2026-01-25 20:56:40] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=446285) [2026-01-25 20:56:40] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=446285) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=446285) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.37s/it]
(EngineCore_DP0 pid=446285) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.66s/it]
(EngineCore_DP0 pid=446285) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.16s/it]
(EngineCore_DP0 pid=446285) 
(EngineCore_DP0 pid=446285) [2026-01-25 20:57:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=446285) [2026-01-25 20:57:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=446285) [2026-01-25 20:57:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=446285) [2026-01-25 20:57:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=446285) [2026-01-25 20:57:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=446285) [2026-01-25 20:57:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=446285) [2026-01-25 20:57:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=446285) [2026-01-25 20:57:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=446285) Process EngineCore_DP0:
(EngineCore_DP0 pid=446285) Traceback (most recent call last):
(EngineCore_DP0 pid=446285)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=446285)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=446285)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=446285)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=446285) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpnpojcrme.ptx', '-o', '/tmp/tmpnpojcrme.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=446285) 
(EngineCore_DP0 pid=446285) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=446285) 
(EngineCore_DP0 pid=446285) Traceback (most recent call last):
(EngineCore_DP0 pid=446285)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=446285)     self.run()
(EngineCore_DP0 pid=446285)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=446285)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=446285)     raise e
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=446285)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=446285)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=446285)     super().__init__(
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=446285)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=446285)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=446285)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=446285)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=446285)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=446285)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=446285)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=446285)     return func(*args, **kwargs)
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=446285)     return func(*args, **kwargs)
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=446285)     self.model_runner.profile_run()
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=446285)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=446285)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=446285)     return func(*args, **kwargs)
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=446285)     outputs = self.model(
(EngineCore_DP0 pid=446285)               ^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=446285)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=446285)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=446285)     hidden_states = self.model(
(EngineCore_DP0 pid=446285)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=446285)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=446285)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=446285)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=446285)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=446285)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=446285)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=446285)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=446285)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=446285)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=446285)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=446285)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=446285)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=446285)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=446285)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=446285)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=446285)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=446285)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=446285)     return self._linear_fn(
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=446285)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=446285)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=446285)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=446285)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=446285)     return fn(input, L)
(EngineCore_DP0 pid=446285)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=446285)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=446285)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=446285)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=446285)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=446285)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=446285)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=446285)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=446285)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=446285)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=446285)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=446285)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=446285)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=446285)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=446285)     raise PTXASError(error)
(EngineCore_DP0 pid=446285) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=446285) `ptxas` stderr:
(EngineCore_DP0 pid=446285) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=446285) 
(EngineCore_DP0 pid=446285) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpnpojcrme.ptx -o /tmp/tmpnpojcrme.ptx.o
(EngineCore_DP0 pid=446285) 
[rank0]:[W125 20:57:44.810961274 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-26 03:25:45
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:25:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:25:49 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=801458) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=801458) WARNING 01-26 03:26:10 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 46.52 requests/s, 23863.63 total tokens/s, 46.52 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 03:25:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:25:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:25:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:25:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:25:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:25:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:25:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:25:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:25:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:25:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:25:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:25:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:25:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:25:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:25:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:25:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:25:52] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:25:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:25:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:25:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:25:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:25:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:25:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:25:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:25:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:25:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:25:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:25:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=801458) [2026-01-26 03:25:53] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=801458) [2026-01-26 03:25:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=801458) [2026-01-26 03:25:53] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=801458) [2026-01-26 03:25:53] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=801458) [2026-01-26 03:25:53] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=801458) [2026-01-26 03:25:53] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=801458) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=801458) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.74s/it]
(EngineCore_DP0 pid=801458) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.74s/it]
(EngineCore_DP0 pid=801458) 
(EngineCore_DP0 pid=801458) [2026-01-26 03:26:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=801458) [2026-01-26 03:26:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=801458) [2026-01-26 03:26:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=801458) [2026-01-26 03:26:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=801458) [2026-01-26 03:26:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=801458) [2026-01-26 03:26:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=801458) [2026-01-26 03:26:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=801458) [2026-01-26 03:26:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=801458) 2026-01-26 03:26:10,314 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=801458) 2026-01-26 03:26:10,321 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1351.11it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:22,  5.72it/s, est. speed input: 2928.87 toks/s, output: 5.72 toks/s]
Processed prompts:   5%|         | 6/128 [00:00<00:04, 25.24it/s, est. speed input: 11041.65 toks/s, output: 21.56 toks/s]
Processed prompts:   9%|         | 12/128 [00:00<00:03, 36.06it/s, est. speed input: 15467.80 toks/s, output: 30.21 toks/s]
Processed prompts:  14%|        | 18/128 [00:00<00:02, 41.67it/s, est. speed input: 17894.02 toks/s, output: 34.95 toks/s]
Processed prompts:  19%|        | 24/128 [00:00<00:02, 45.23it/s, est. speed input: 19488.58 toks/s, output: 38.06 toks/s]
Processed prompts:  23%|       | 30/128 [00:00<00:02, 47.44it/s, est. speed input: 20586.10 toks/s, output: 40.21 toks/s]
Processed prompts:  28%|       | 36/128 [00:00<00:01, 48.90it/s, est. speed input: 21394.59 toks/s, output: 41.79 toks/s]
Processed prompts:  33%|      | 42/128 [00:00<00:01, 49.74it/s, est. speed input: 21989.46 toks/s, output: 42.95 toks/s]
Processed prompts:  38%|      | 48/128 [00:01<00:01, 50.55it/s, est. speed input: 22495.17 toks/s, output: 43.93 toks/s]
Processed prompts:  42%|     | 54/128 [00:01<00:01, 50.72it/s, est. speed input: 22851.33 toks/s, output: 44.63 toks/s]
Processed prompts:  47%|     | 60/128 [00:01<00:01, 50.60it/s, est. speed input: 23112.55 toks/s, output: 45.14 toks/s]
Processed prompts:  52%|    | 66/128 [00:01<00:01, 50.74it/s, est. speed input: 23359.60 toks/s, output: 45.62 toks/s]
Processed prompts:  56%|    | 72/128 [00:01<00:01, 50.99it/s, est. speed input: 23585.84 toks/s, output: 46.07 toks/s]
Processed prompts:  61%|    | 78/128 [00:01<00:00, 50.81it/s, est. speed input: 23742.86 toks/s, output: 46.37 toks/s]
Processed prompts:  66%|   | 84/128 [00:01<00:00, 51.14it/s, est. speed input: 23925.78 toks/s, output: 46.73 toks/s]
Processed prompts:  70%|   | 90/128 [00:01<00:00, 51.10it/s, est. speed input: 24060.63 toks/s, output: 46.99 toks/s]
Processed prompts:  75%|  | 96/128 [00:02<00:00, 51.35it/s, est. speed input: 24204.57 toks/s, output: 47.27 toks/s]
Processed prompts:  80%|  | 102/128 [00:02<00:00, 51.60it/s, est. speed input: 24338.98 toks/s, output: 47.54 toks/s]
Processed prompts:  84%| | 108/128 [00:02<00:00, 51.58it/s, est. speed input: 24444.10 toks/s, output: 47.74 toks/s]
Processed prompts:  89%| | 114/128 [00:02<00:00, 50.80it/s, est. speed input: 24479.32 toks/s, output: 47.81 toks/s]
Processed prompts:  94%|| 120/128 [00:02<00:00, 50.85it/s, est. speed input: 24556.11 toks/s, output: 47.96 toks/s]
Processed prompts:  98%|| 126/128 [00:02<00:00, 51.13it/s, est. speed input: 24642.15 toks/s, output: 48.13 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 51.13it/s, est. speed input: 24677.64 toks/s, output: 48.20 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 48.20it/s, est. speed input: 24677.64 toks/s, output: 48.20 toks/s]
[rank0]:[W126 03:26:13.146805256 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 03:26:16
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:26:20 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:26:20 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=802081) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=802081) WARNING 01-26 03:26:42 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 27.54 requests/s, 28231.21 total tokens/s, 27.54 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 03:26:20] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:26:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:26:20] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:26:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:26:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:26:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:26:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:26:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:26:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:26:23] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:26:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:26:23] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:26:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:26:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:26:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:26:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:26:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:26:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=802081) [2026-01-26 03:26:24] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=802081) [2026-01-26 03:26:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=802081) [2026-01-26 03:26:24] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=802081) [2026-01-26 03:26:24] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=802081) [2026-01-26 03:26:24] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=802081) [2026-01-26 03:26:24] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=802081) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=802081) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.97s/it]
(EngineCore_DP0 pid=802081) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.97s/it]
(EngineCore_DP0 pid=802081) 
(EngineCore_DP0 pid=802081) [2026-01-26 03:26:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=802081) [2026-01-26 03:26:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=802081) [2026-01-26 03:26:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=802081) [2026-01-26 03:26:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=802081) [2026-01-26 03:26:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=802081) [2026-01-26 03:26:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=802081) [2026-01-26 03:26:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=802081) [2026-01-26 03:26:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=802081) 2026-01-26 03:26:41,542 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=802081) 2026-01-26 03:26:41,549 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  34%|      | 43/128 [00:00<00:00, 427.49it/s]
Adding requests:  78%|  | 100/128 [00:00<00:00, 509.63it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 502.66it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:01, 77.93it/s, est. speed input: 79821.35 toks/s, output: 77.94 toks/s]
Processed prompts:  12%|        | 16/128 [00:00<00:02, 37.70it/s, est. speed input: 41851.80 toks/s, output: 40.87 toks/s]
Processed prompts:  16%|        | 21/128 [00:00<00:03, 33.80it/s, est. speed input: 37816.83 toks/s, output: 36.93 toks/s]
Processed prompts:  20%|        | 25/128 [00:00<00:03, 31.88it/s, est. speed input: 35948.92 toks/s, output: 35.11 toks/s]
Processed prompts:  23%|       | 29/128 [00:00<00:03, 30.52it/s, est. speed input: 34647.90 toks/s, output: 33.83 toks/s]
Processed prompts:  26%|       | 33/128 [00:00<00:03, 29.88it/s, est. speed input: 33867.72 toks/s, output: 33.07 toks/s]
Processed prompts:  29%|       | 37/128 [00:01<00:03, 29.39it/s, est. speed input: 33256.99 toks/s, output: 32.48 toks/s]
Processed prompts:  32%|      | 41/128 [00:01<00:02, 29.04it/s, est. speed input: 32777.87 toks/s, output: 32.01 toks/s]
Processed prompts:  34%|      | 44/128 [00:01<00:02, 28.50it/s, est. speed input: 32360.90 toks/s, output: 31.60 toks/s]
Processed prompts:  37%|      | 47/128 [00:01<00:02, 28.51it/s, est. speed input: 32139.03 toks/s, output: 31.39 toks/s]
Processed prompts:  39%|      | 50/128 [00:01<00:02, 28.31it/s, est. speed input: 31891.11 toks/s, output: 31.14 toks/s]
Processed prompts:  41%|     | 53/128 [00:01<00:02, 28.29it/s, est. speed input: 31706.39 toks/s, output: 30.96 toks/s]
Processed prompts:  44%|     | 56/128 [00:01<00:02, 28.20it/s, est. speed input: 31525.63 toks/s, output: 30.79 toks/s]
Processed prompts:  46%|     | 59/128 [00:01<00:02, 28.27it/s, est. speed input: 31395.02 toks/s, output: 30.66 toks/s]
Processed prompts:  48%|     | 62/128 [00:02<00:02, 28.31it/s, est. speed input: 31274.58 toks/s, output: 30.54 toks/s]
Processed prompts:  51%|     | 65/128 [00:02<00:02, 28.08it/s, est. speed input: 31118.11 toks/s, output: 30.39 toks/s]
Processed prompts:  53%|    | 68/128 [00:02<00:02, 28.13it/s, est. speed input: 31013.87 toks/s, output: 30.29 toks/s]
Processed prompts:  55%|    | 71/128 [00:02<00:02, 28.00it/s, est. speed input: 30892.59 toks/s, output: 30.17 toks/s]
Processed prompts:  58%|    | 74/128 [00:02<00:01, 27.63it/s, est. speed input: 30734.73 toks/s, output: 30.01 toks/s]
Processed prompts:  60%|    | 77/128 [00:02<00:01, 27.87it/s, est. speed input: 30670.19 toks/s, output: 29.95 toks/s]
Processed prompts:  62%|   | 80/128 [00:02<00:01, 27.98it/s, est. speed input: 30600.97 toks/s, output: 29.88 toks/s]
Processed prompts:  65%|   | 83/128 [00:02<00:01, 27.98it/s, est. speed input: 30526.13 toks/s, output: 29.81 toks/s]
Processed prompts:  67%|   | 86/128 [00:02<00:01, 28.01it/s, est. speed input: 30460.21 toks/s, output: 29.75 toks/s]
Processed prompts:  70%|   | 89/128 [00:02<00:01, 28.04it/s, est. speed input: 30400.53 toks/s, output: 29.69 toks/s]
Processed prompts:  72%|  | 92/128 [00:03<00:01, 27.92it/s, est. speed input: 30326.87 toks/s, output: 29.62 toks/s]
Processed prompts:  74%|  | 95/128 [00:03<00:01, 28.06it/s, est. speed input: 30285.75 toks/s, output: 29.58 toks/s]
Processed prompts:  77%|  | 98/128 [00:03<00:01, 28.21it/s, est. speed input: 30253.62 toks/s, output: 29.54 toks/s]
Processed prompts:  79%|  | 101/128 [00:03<00:00, 27.84it/s, est. speed input: 30169.47 toks/s, output: 29.46 toks/s]
Processed prompts:  81%| | 104/128 [00:03<00:00, 27.75it/s, est. speed input: 30108.75 toks/s, output: 29.40 toks/s]
Processed prompts:  84%| | 107/128 [00:03<00:00, 27.86it/s, est. speed input: 30070.27 toks/s, output: 29.37 toks/s]
Processed prompts:  86%| | 110/128 [00:03<00:00, 27.75it/s, est. speed input: 30014.40 toks/s, output: 29.31 toks/s]
Processed prompts:  88%| | 113/128 [00:03<00:00, 27.93it/s, est. speed input: 29988.23 toks/s, output: 29.29 toks/s]
Processed prompts:  91%| | 116/128 [00:03<00:00, 28.04it/s, est. speed input: 29960.97 toks/s, output: 29.26 toks/s]
Processed prompts:  93%|| 119/128 [00:04<00:00, 28.12it/s, est. speed input: 29936.11 toks/s, output: 29.23 toks/s]
Processed prompts:  95%|| 122/128 [00:04<00:00, 28.30it/s, est. speed input: 29922.57 toks/s, output: 29.22 toks/s]
Processed prompts:  98%|| 125/128 [00:04<00:00, 28.18it/s, est. speed input: 29888.70 toks/s, output: 29.19 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 28.01it/s, est. speed input: 29848.96 toks/s, output: 29.15 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 28.01it/s, est. speed input: 29848.96 toks/s, output: 29.15 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 29.15it/s, est. speed input: 29848.96 toks/s, output: 29.15 toks/s]
[rank0]:[W126 03:26:46.123319459 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 03:26:49
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:26:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:26:53 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=802737) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=802737) WARNING 01-26 03:27:15 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 29.31 requests/s, 30041.56 total tokens/s, 29.31 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 03:26:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:26:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:26:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:26:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:26:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:26:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:26:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:26:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:26:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:26:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:26:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:26:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:26:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:26:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:26:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:26:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:26:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:26:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:26:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=802737) [2026-01-26 03:26:57] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=802737) [2026-01-26 03:26:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=802737) [2026-01-26 03:26:57] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=802737) [2026-01-26 03:26:57] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=802737) [2026-01-26 03:26:57] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=802737) [2026-01-26 03:26:57] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=802737) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=802737) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.85s/it]
(EngineCore_DP0 pid=802737) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.85s/it]
(EngineCore_DP0 pid=802737) 
(EngineCore_DP0 pid=802737) [2026-01-26 03:27:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=802737) [2026-01-26 03:27:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=802737) [2026-01-26 03:27:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=802737) [2026-01-26 03:27:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=802737) [2026-01-26 03:27:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=802737) [2026-01-26 03:27:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=802737) [2026-01-26 03:27:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=802737) [2026-01-26 03:27:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=802737) 2026-01-26 03:27:14,587 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=802737) 2026-01-26 03:27:14,594 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  24%|       | 61/256 [00:00<00:00, 608.22it/s]
Adding requests:  48%|     | 122/256 [00:00<00:00, 590.10it/s]
Adding requests:  71%|   | 182/256 [00:00<00:00, 572.47it/s]
Adding requests:  94%|| 240/256 [00:00<00:00, 572.21it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 575.69it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 12/256 [00:00<00:02, 104.65it/s, est. speed input: 107172.12 toks/s, output: 104.65 toks/s]
Processed prompts:   9%|         | 23/256 [00:00<00:04, 46.93it/s, est. speed input: 52593.71 toks/s, output: 51.36 toks/s]   
Processed prompts:  12%|        | 30/256 [00:00<00:06, 36.44it/s, est. speed input: 42479.76 toks/s, output: 41.48 toks/s]
Processed prompts:  14%|        | 35/256 [00:00<00:06, 36.71it/s, est. speed input: 41846.19 toks/s, output: 40.87 toks/s]
Processed prompts:  16%|        | 40/256 [00:01<00:06, 32.42it/s, est. speed input: 38656.85 toks/s, output: 37.75 toks/s]
Processed prompts:  17%|        | 44/256 [00:01<00:06, 31.70it/s, est. speed input: 37706.39 toks/s, output: 36.82 toks/s]
Processed prompts:  19%|        | 48/256 [00:01<00:06, 31.19it/s, est. speed input: 36977.86 toks/s, output: 36.11 toks/s]
Processed prompts:  20%|        | 52/256 [00:01<00:06, 31.00it/s, est. speed input: 36460.25 toks/s, output: 35.61 toks/s]
Processed prompts:  22%|       | 56/256 [00:01<00:06, 30.51it/s, est. speed input: 35904.99 toks/s, output: 35.06 toks/s]
Processed prompts:  23%|       | 60/256 [00:01<00:06, 30.13it/s, est. speed input: 35430.53 toks/s, output: 34.60 toks/s]
Processed prompts:  25%|       | 64/256 [00:01<00:06, 29.89it/s, est. speed input: 35035.72 toks/s, output: 34.21 toks/s]
Processed prompts:  27%|       | 68/256 [00:02<00:06, 29.84it/s, est. speed input: 34726.66 toks/s, output: 33.91 toks/s]
Processed prompts:  28%|       | 72/256 [00:02<00:06, 29.79it/s, est. speed input: 34451.96 toks/s, output: 33.64 toks/s]
Processed prompts:  30%|       | 76/256 [00:02<00:06, 29.95it/s, est. speed input: 34255.58 toks/s, output: 33.45 toks/s]
Processed prompts:  31%|      | 80/256 [00:02<00:05, 29.89it/s, est. speed input: 34043.04 toks/s, output: 33.24 toks/s]
Processed prompts:  33%|      | 84/256 [00:02<00:05, 29.97it/s, est. speed input: 33878.63 toks/s, output: 33.08 toks/s]
Processed prompts:  34%|      | 88/256 [00:02<00:05, 29.55it/s, est. speed input: 33639.54 toks/s, output: 32.85 toks/s]
Processed prompts:  36%|      | 92/256 [00:02<00:05, 29.56it/s, est. speed input: 33479.54 toks/s, output: 32.69 toks/s]
Processed prompts:  38%|      | 96/256 [00:02<00:05, 29.68it/s, est. speed input: 33351.85 toks/s, output: 32.57 toks/s]
Processed prompts:  39%|      | 100/256 [00:03<00:05, 29.71it/s, est. speed input: 33226.85 toks/s, output: 32.45 toks/s]
Processed prompts:  41%|      | 104/256 [00:03<00:05, 29.84it/s, est. speed input: 33130.82 toks/s, output: 32.35 toks/s]
Processed prompts:  42%|     | 108/256 [00:03<00:04, 29.92it/s, est. speed input: 33039.66 toks/s, output: 32.27 toks/s]
Processed prompts:  44%|     | 112/256 [00:03<00:04, 29.99it/s, est. speed input: 32956.80 toks/s, output: 32.18 toks/s]
Processed prompts:  45%|     | 116/256 [00:03<00:04, 29.99it/s, est. speed input: 32874.25 toks/s, output: 32.10 toks/s]
Processed prompts:  47%|     | 120/256 [00:03<00:04, 29.73it/s, est. speed input: 32763.19 toks/s, output: 32.00 toks/s]
Processed prompts:  48%|     | 124/256 [00:03<00:04, 29.83it/s, est. speed input: 32695.59 toks/s, output: 31.93 toks/s]
Processed prompts:  50%|     | 128/256 [00:04<00:04, 30.00it/s, est. speed input: 32644.21 toks/s, output: 31.88 toks/s]
Processed prompts:  52%|    | 132/256 [00:04<00:04, 29.94it/s, est. speed input: 32574.92 toks/s, output: 31.81 toks/s]
Processed prompts:  53%|    | 136/256 [00:04<00:04, 29.91it/s, est. speed input: 32512.01 toks/s, output: 31.75 toks/s]
Processed prompts:  55%|    | 140/256 [00:04<00:03, 29.87it/s, est. speed input: 32450.76 toks/s, output: 31.69 toks/s]
Processed prompts:  56%|    | 144/256 [00:04<00:03, 29.89it/s, est. speed input: 32397.85 toks/s, output: 31.64 toks/s]
Processed prompts:  58%|    | 148/256 [00:04<00:03, 29.91it/s, est. speed input: 32348.42 toks/s, output: 31.59 toks/s]
Processed prompts:  59%|    | 152/256 [00:04<00:03, 29.40it/s, est. speed input: 32249.02 toks/s, output: 31.49 toks/s]
Processed prompts:  61%|    | 156/256 [00:04<00:03, 29.51it/s, est. speed input: 32201.43 toks/s, output: 31.45 toks/s]
Processed prompts:  62%|   | 160/256 [00:05<00:03, 29.70it/s, est. speed input: 32167.31 toks/s, output: 31.41 toks/s]
Processed prompts:  64%|   | 164/256 [00:05<00:03, 29.68it/s, est. speed input: 32120.10 toks/s, output: 31.37 toks/s]
Processed prompts:  66%|   | 168/256 [00:05<00:02, 29.79it/s, est. speed input: 32086.30 toks/s, output: 31.33 toks/s]
Processed prompts:  67%|   | 172/256 [00:05<00:02, 29.91it/s, est. speed input: 32058.43 toks/s, output: 31.31 toks/s]
Processed prompts:  69%|   | 176/256 [00:05<00:02, 29.96it/s, est. speed input: 32028.49 toks/s, output: 31.28 toks/s]
Processed prompts:  70%|   | 180/256 [00:05<00:02, 29.84it/s, est. speed input: 31986.99 toks/s, output: 31.24 toks/s]
Processed prompts:  72%|  | 184/256 [00:05<00:02, 29.50it/s, est. speed input: 31926.68 toks/s, output: 31.18 toks/s]
Processed prompts:  73%|  | 188/256 [00:06<00:02, 29.59it/s, est. speed input: 31895.59 toks/s, output: 31.15 toks/s]
Processed prompts:  75%|  | 192/256 [00:06<00:02, 29.83it/s, est. speed input: 31879.22 toks/s, output: 31.13 toks/s]
Processed prompts:  77%|  | 196/256 [00:06<00:02, 29.88it/s, est. speed input: 31854.59 toks/s, output: 31.11 toks/s]
Processed prompts:  78%|  | 200/256 [00:06<00:01, 29.76it/s, est. speed input: 31819.37 toks/s, output: 31.07 toks/s]
Processed prompts:  80%|  | 204/256 [00:06<00:01, 29.91it/s, est. speed input: 31802.85 toks/s, output: 31.06 toks/s]
Processed prompts:  81%| | 208/256 [00:06<00:01, 29.71it/s, est. speed input: 31765.50 toks/s, output: 31.02 toks/s]
Processed prompts:  83%| | 212/256 [00:06<00:01, 29.76it/s, est. speed input: 31742.23 toks/s, output: 31.00 toks/s]
Processed prompts:  84%| | 216/256 [00:06<00:01, 29.35it/s, est. speed input: 31689.78 toks/s, output: 30.95 toks/s]
Processed prompts:  86%| | 220/256 [00:07<00:01, 29.63it/s, est. speed input: 31677.46 toks/s, output: 30.93 toks/s]
Processed prompts:  88%| | 224/256 [00:07<00:01, 29.71it/s, est. speed input: 31657.91 toks/s, output: 30.92 toks/s]
Processed prompts:  89%| | 228/256 [00:07<00:00, 29.76it/s, est. speed input: 31638.75 toks/s, output: 30.90 toks/s]
Processed prompts:  91%| | 232/256 [00:07<00:00, 29.75it/s, est. speed input: 31617.17 toks/s, output: 30.88 toks/s]
Processed prompts:  92%|| 236/256 [00:07<00:00, 29.88it/s, est. speed input: 31604.85 toks/s, output: 30.86 toks/s]
Processed prompts:  94%|| 240/256 [00:07<00:00, 29.94it/s, est. speed input: 31591.36 toks/s, output: 30.85 toks/s]
Processed prompts:  95%|| 244/256 [00:07<00:00, 29.99it/s, est. speed input: 31578.27 toks/s, output: 30.84 toks/s]
Processed prompts:  97%|| 248/256 [00:08<00:00, 29.46it/s, est. speed input: 31532.76 toks/s, output: 30.79 toks/s]
Processed prompts:  98%|| 252/256 [00:08<00:00, 29.71it/s, est. speed input: 31524.74 toks/s, output: 30.79 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 31.99it/s, est. speed input: 31628.63 toks/s, output: 30.89 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 31.99it/s, est. speed input: 31628.63 toks/s, output: 30.89 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 30.89it/s, est. speed input: 31628.63 toks/s, output: 30.89 toks/s]
[rank0]:[W126 03:27:24.393365055 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 03:27:26
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:27:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:27:31 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=803454) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=803454) WARNING 01-26 03:27:52 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.88 requests/s, 29600.26 total tokens/s, 28.88 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 03:27:31] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:27:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:27:31] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:27:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:27:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:27:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:27:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:27:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:27:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:27:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:27:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:27:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:27:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:27:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:27:34] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:27:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:27:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:27:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:27:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:27:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:27:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:27:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:27:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:27:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:27:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:27:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:27:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:27:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=803454) [2026-01-26 03:27:35] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=803454) [2026-01-26 03:27:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=803454) [2026-01-26 03:27:35] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=803454) [2026-01-26 03:27:35] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=803454) [2026-01-26 03:27:35] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=803454) [2026-01-26 03:27:35] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=803454) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=803454) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.72s/it]
(EngineCore_DP0 pid=803454) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.72s/it]
(EngineCore_DP0 pid=803454) 
(EngineCore_DP0 pid=803454) [2026-01-26 03:27:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=803454) [2026-01-26 03:27:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=803454) [2026-01-26 03:27:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=803454) [2026-01-26 03:27:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=803454) [2026-01-26 03:27:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=803454) [2026-01-26 03:27:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=803454) [2026-01-26 03:27:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=803454) [2026-01-26 03:27:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=803454) 2026-01-26 03:27:52,232 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=803454) 2026-01-26 03:27:52,249 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   8%|         | 43/512 [00:00<00:01, 424.21it/s]
Adding requests:  20%|        | 102/512 [00:00<00:00, 520.18it/s]
Adding requests:  30%|       | 155/512 [00:00<00:00, 512.25it/s]
Adding requests:  40%|      | 207/512 [00:00<00:00, 511.13it/s]
Adding requests:  51%|     | 262/512 [00:00<00:00, 524.07it/s]
Adding requests:  62%|   | 316/512 [00:00<00:00, 526.82it/s]
Adding requests:  73%|  | 372/512 [00:00<00:00, 535.68it/s]
Adding requests:  83%| | 426/512 [00:00<00:00, 534.66it/s]
Adding requests:  94%|| 480/512 [00:00<00:00, 535.92it/s]
Adding requests: 100%|| 512/512 [00:00<00:00, 525.77it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 26/512 [00:00<00:02, 169.93it/s, est. speed input: 174072.62 toks/s, output: 169.96 toks/s]
Processed prompts:   8%|         | 43/512 [00:00<00:08, 53.46it/s, est. speed input: 62517.76 toks/s, output: 61.05 toks/s]   
Processed prompts:  10%|         | 52/512 [00:00<00:10, 45.85it/s, est. speed input: 54496.81 toks/s, output: 53.22 toks/s]
Processed prompts:  12%|        | 59/512 [00:01<00:11, 38.51it/s, est. speed input: 48074.95 toks/s, output: 46.95 toks/s]
Processed prompts:  12%|        | 64/512 [00:01<00:11, 38.24it/s, est. speed input: 47102.87 toks/s, output: 46.00 toks/s]
Processed prompts:  13%|        | 69/512 [00:01<00:11, 37.82it/s, est. speed input: 46212.27 toks/s, output: 45.13 toks/s]
Processed prompts:  14%|        | 74/512 [00:01<00:14, 30.29it/s, est. speed input: 42051.82 toks/s, output: 41.07 toks/s]
Processed prompts:  15%|        | 78/512 [00:01<00:14, 29.92it/s, est. speed input: 41133.41 toks/s, output: 40.17 toks/s]
Processed prompts:  16%|        | 82/512 [00:02<00:14, 29.80it/s, est. speed input: 40409.81 toks/s, output: 39.46 toks/s]
Processed prompts:  17%|        | 86/512 [00:02<00:14, 29.32it/s, est. speed input: 39650.98 toks/s, output: 38.72 toks/s]
Processed prompts:  18%|        | 90/512 [00:02<00:14, 29.20it/s, est. speed input: 39060.56 toks/s, output: 38.14 toks/s]
Processed prompts:  18%|        | 94/512 [00:02<00:14, 29.30it/s, est. speed input: 38584.29 toks/s, output: 37.68 toks/s]
Processed prompts:  19%|        | 98/512 [00:02<00:14, 29.18it/s, est. speed input: 38109.53 toks/s, output: 37.22 toks/s]
Processed prompts:  20%|        | 102/512 [00:02<00:13, 29.41it/s, est. speed input: 37754.43 toks/s, output: 36.87 toks/s]
Processed prompts:  21%|        | 106/512 [00:02<00:13, 29.24it/s, est. speed input: 37361.29 toks/s, output: 36.49 toks/s]
Processed prompts:  21%|       | 110/512 [00:03<00:13, 29.34it/s, est. speed input: 37046.86 toks/s, output: 36.18 toks/s]
Processed prompts:  22%|       | 114/512 [00:03<00:13, 29.23it/s, est. speed input: 36725.29 toks/s, output: 35.86 toks/s]
Processed prompts:  23%|       | 118/512 [00:03<00:13, 28.78it/s, est. speed input: 36366.14 toks/s, output: 35.51 toks/s]
Processed prompts:  24%|       | 122/512 [00:03<00:13, 28.99it/s, est. speed input: 36124.60 toks/s, output: 35.28 toks/s]
Processed prompts:  25%|       | 126/512 [00:03<00:13, 29.13it/s, est. speed input: 35900.25 toks/s, output: 35.06 toks/s]
Processed prompts:  25%|       | 130/512 [00:03<00:13, 29.26it/s, est. speed input: 35696.50 toks/s, output: 34.86 toks/s]
Processed prompts:  26%|       | 134/512 [00:03<00:13, 29.07it/s, est. speed input: 35465.71 toks/s, output: 34.63 toks/s]
Processed prompts:  27%|       | 138/512 [00:04<00:12, 29.20it/s, est. speed input: 35288.27 toks/s, output: 34.46 toks/s]
Processed prompts:  28%|       | 142/512 [00:04<00:12, 29.25it/s, est. speed input: 35116.68 toks/s, output: 34.29 toks/s]
Processed prompts:  29%|       | 146/512 [00:04<00:12, 29.23it/s, est. speed input: 34948.83 toks/s, output: 34.13 toks/s]
Processed prompts:  29%|       | 150/512 [00:04<00:12, 28.89it/s, est. speed input: 34751.39 toks/s, output: 33.94 toks/s]
Processed prompts:  30%|       | 154/512 [00:04<00:12, 28.97it/s, est. speed input: 34603.72 toks/s, output: 33.79 toks/s]
Processed prompts:  31%|       | 158/512 [00:04<00:12, 29.05it/s, est. speed input: 34467.39 toks/s, output: 33.66 toks/s]
Processed prompts:  32%|      | 162/512 [00:04<00:11, 29.17it/s, est. speed input: 34346.79 toks/s, output: 33.54 toks/s]
Processed prompts:  32%|      | 166/512 [00:04<00:11, 29.29it/s, est. speed input: 34235.66 toks/s, output: 33.43 toks/s]
Processed prompts:  33%|      | 170/512 [00:05<00:11, 29.35it/s, est. speed input: 34128.80 toks/s, output: 33.33 toks/s]
Processed prompts:  34%|      | 174/512 [00:05<00:11, 29.24it/s, est. speed input: 34011.20 toks/s, output: 33.21 toks/s]
Processed prompts:  35%|      | 178/512 [00:05<00:11, 29.04it/s, est. speed input: 33888.14 toks/s, output: 33.09 toks/s]
Processed prompts:  36%|      | 182/512 [00:05<00:11, 29.04it/s, est. speed input: 33784.13 toks/s, output: 32.99 toks/s]
Processed prompts:  36%|      | 186/512 [00:05<00:11, 29.09it/s, est. speed input: 33690.85 toks/s, output: 32.90 toks/s]
Processed prompts:  37%|      | 190/512 [00:05<00:11, 29.19it/s, est. speed input: 33606.89 toks/s, output: 32.82 toks/s]
Processed prompts:  38%|      | 194/512 [00:05<00:10, 29.07it/s, est. speed input: 33509.92 toks/s, output: 32.72 toks/s]
Processed prompts:  39%|      | 198/512 [00:06<00:10, 29.11it/s, est. speed input: 33428.81 toks/s, output: 32.65 toks/s]
Processed prompts:  39%|      | 202/512 [00:06<00:10, 29.18it/s, est. speed input: 33354.63 toks/s, output: 32.57 toks/s]
Processed prompts:  40%|      | 206/512 [00:06<00:10, 29.17it/s, est. speed input: 33278.68 toks/s, output: 32.50 toks/s]
Processed prompts:  41%|      | 210/512 [00:06<00:10, 28.84it/s, est. speed input: 33179.57 toks/s, output: 32.40 toks/s]
Processed prompts:  42%|     | 214/512 [00:06<00:10, 28.96it/s, est. speed input: 33112.72 toks/s, output: 32.34 toks/s]
Processed prompts:  43%|     | 218/512 [00:06<00:10, 29.09it/s, est. speed input: 33051.91 toks/s, output: 32.28 toks/s]
Processed prompts:  43%|     | 222/512 [00:06<00:09, 29.10it/s, est. speed input: 32987.54 toks/s, output: 32.21 toks/s]
Processed prompts:  44%|     | 226/512 [00:07<00:09, 29.08it/s, est. speed input: 32924.08 toks/s, output: 32.15 toks/s]
Processed prompts:  45%|     | 230/512 [00:07<00:09, 29.09it/s, est. speed input: 32864.36 toks/s, output: 32.09 toks/s]
Processed prompts:  46%|     | 234/512 [00:07<00:09, 29.11it/s, est. speed input: 32807.55 toks/s, output: 32.04 toks/s]
Processed prompts:  46%|     | 238/512 [00:07<00:09, 29.16it/s, est. speed input: 32755.84 toks/s, output: 31.99 toks/s]
Processed prompts:  47%|     | 242/512 [00:07<00:09, 28.84it/s, est. speed input: 32681.30 toks/s, output: 31.92 toks/s]
Processed prompts:  48%|     | 246/512 [00:07<00:09, 29.03it/s, est. speed input: 32637.80 toks/s, output: 31.87 toks/s]
Processed prompts:  49%|     | 250/512 [00:07<00:09, 28.92it/s, est. speed input: 32579.50 toks/s, output: 31.82 toks/s]
Processed prompts:  50%|     | 254/512 [00:07<00:08, 29.05it/s, est. speed input: 32536.29 toks/s, output: 31.77 toks/s]
Processed prompts:  50%|     | 258/512 [00:08<00:08, 29.10it/s, est. speed input: 32492.55 toks/s, output: 31.73 toks/s]
Processed prompts:  51%|     | 262/512 [00:08<00:08, 29.05it/s, est. speed input: 32444.44 toks/s, output: 31.68 toks/s]
Processed prompts:  52%|    | 266/512 [00:08<00:08, 29.20it/s, est. speed input: 32409.71 toks/s, output: 31.65 toks/s]
Processed prompts:  53%|    | 270/512 [00:08<00:08, 28.82it/s, est. speed input: 32346.51 toks/s, output: 31.59 toks/s]
Processed prompts:  54%|    | 274/512 [00:08<00:08, 28.87it/s, est. speed input: 32304.19 toks/s, output: 31.55 toks/s]
Processed prompts:  54%|    | 278/512 [00:08<00:08, 28.90it/s, est. speed input: 32262.96 toks/s, output: 31.51 toks/s]
Processed prompts:  55%|    | 282/512 [00:08<00:07, 28.94it/s, est. speed input: 32223.94 toks/s, output: 31.47 toks/s]
Processed prompts:  56%|    | 286/512 [00:09<00:07, 29.00it/s, est. speed input: 32187.82 toks/s, output: 31.43 toks/s]
Processed prompts:  57%|    | 290/512 [00:09<00:07, 29.14it/s, est. speed input: 32158.27 toks/s, output: 31.40 toks/s]
Processed prompts:  57%|    | 294/512 [00:09<00:07, 29.14it/s, est. speed input: 32124.20 toks/s, output: 31.37 toks/s]
Processed prompts:  58%|    | 298/512 [00:09<00:07, 29.15it/s, est. speed input: 32091.78 toks/s, output: 31.34 toks/s]
Processed prompts:  59%|    | 302/512 [00:09<00:07, 28.81it/s, est. speed input: 32042.19 toks/s, output: 31.29 toks/s]
Processed prompts:  60%|    | 306/512 [00:09<00:07, 28.94it/s, est. speed input: 32013.10 toks/s, output: 31.26 toks/s]
Processed prompts:  61%|    | 310/512 [00:09<00:06, 29.11it/s, est. speed input: 31988.59 toks/s, output: 31.24 toks/s]
Processed prompts:  61%|   | 314/512 [00:10<00:06, 29.32it/s, est. speed input: 31969.03 toks/s, output: 31.22 toks/s]
Processed prompts:  62%|   | 318/512 [00:10<00:06, 29.40it/s, est. speed input: 31946.71 toks/s, output: 31.20 toks/s]
Processed prompts:  63%|   | 322/512 [00:10<00:06, 29.25it/s, est. speed input: 31915.35 toks/s, output: 31.17 toks/s]
Processed prompts:  64%|   | 326/512 [00:10<00:06, 29.17it/s, est. speed input: 31886.03 toks/s, output: 31.14 toks/s]
Processed prompts:  64%|   | 330/512 [00:10<00:06, 29.23it/s, est. speed input: 31863.59 toks/s, output: 31.12 toks/s]
Processed prompts:  65%|   | 334/512 [00:10<00:06, 28.86it/s, est. speed input: 31821.11 toks/s, output: 31.08 toks/s]
Processed prompts:  66%|   | 338/512 [00:10<00:05, 29.08it/s, est. speed input: 31802.21 toks/s, output: 31.06 toks/s]
Processed prompts:  67%|   | 342/512 [00:11<00:05, 30.11it/s, est. speed input: 31822.41 toks/s, output: 31.08 toks/s]
Processed prompts:  68%|   | 346/512 [00:11<00:05, 29.78it/s, est. speed input: 31796.53 toks/s, output: 31.05 toks/s]
Processed prompts:  68%|   | 350/512 [00:11<00:05, 29.67it/s, est. speed input: 31776.28 toks/s, output: 31.03 toks/s]
Processed prompts:  69%|   | 354/512 [00:11<00:05, 29.50it/s, est. speed input: 31752.75 toks/s, output: 31.01 toks/s]
Processed prompts:  70%|   | 358/512 [00:11<00:05, 29.45it/s, est. speed input: 31732.37 toks/s, output: 30.99 toks/s]
Processed prompts:  71%|   | 362/512 [00:11<00:05, 29.27it/s, est. speed input: 31706.55 toks/s, output: 30.96 toks/s]
Processed prompts:  71%|  | 366/512 [00:11<00:05, 29.01it/s, est. speed input: 31675.39 toks/s, output: 30.93 toks/s]
Processed prompts:  72%|  | 370/512 [00:11<00:04, 29.16it/s, est. speed input: 31659.26 toks/s, output: 30.92 toks/s]
Processed prompts:  73%|  | 374/512 [00:12<00:04, 29.07it/s, est. speed input: 31634.80 toks/s, output: 30.89 toks/s]
Processed prompts:  74%|  | 378/512 [00:12<00:04, 29.13it/s, est. speed input: 31616.26 toks/s, output: 30.88 toks/s]
Processed prompts:  75%|  | 382/512 [00:12<00:04, 29.16it/s, est. speed input: 31597.69 toks/s, output: 30.86 toks/s]
Processed prompts:  75%|  | 386/512 [00:12<00:04, 29.12it/s, est. speed input: 31577.06 toks/s, output: 30.84 toks/s]
Processed prompts:  76%|  | 390/512 [00:12<00:04, 29.03it/s, est. speed input: 31554.56 toks/s, output: 30.81 toks/s]
Processed prompts:  77%|  | 394/512 [00:12<00:04, 28.68it/s, est. speed input: 31520.96 toks/s, output: 30.78 toks/s]
Processed prompts:  78%|  | 398/512 [00:12<00:03, 28.74it/s, est. speed input: 31500.07 toks/s, output: 30.76 toks/s]
Processed prompts:  79%|  | 402/512 [00:13<00:03, 29.02it/s, est. speed input: 31489.01 toks/s, output: 30.75 toks/s]
Processed prompts:  79%|  | 406/512 [00:13<00:03, 29.03it/s, est. speed input: 31470.64 toks/s, output: 30.73 toks/s]
Processed prompts:  80%|  | 410/512 [00:13<00:03, 29.01it/s, est. speed input: 31452.10 toks/s, output: 30.71 toks/s]
Processed prompts:  81%|  | 414/512 [00:13<00:03, 29.08it/s, est. speed input: 31436.71 toks/s, output: 30.70 toks/s]
Processed prompts:  82%| | 418/512 [00:13<00:03, 29.16it/s, est. speed input: 31422.78 toks/s, output: 30.69 toks/s]
Processed prompts:  82%| | 422/512 [00:13<00:03, 29.18it/s, est. speed input: 31408.06 toks/s, output: 30.67 toks/s]
Processed prompts:  83%| | 426/512 [00:13<00:03, 28.65it/s, est. speed input: 31373.72 toks/s, output: 30.64 toks/s]
Processed prompts:  84%| | 430/512 [00:14<00:02, 28.73it/s, est. speed input: 31356.50 toks/s, output: 30.62 toks/s]
Processed prompts:  85%| | 434/512 [00:14<00:02, 28.98it/s, est. speed input: 31346.29 toks/s, output: 30.61 toks/s]
Processed prompts:  86%| | 438/512 [00:14<00:02, 29.10it/s, est. speed input: 31334.17 toks/s, output: 30.60 toks/s]
Processed prompts:  86%| | 442/512 [00:14<00:02, 29.00it/s, est. speed input: 31316.08 toks/s, output: 30.58 toks/s]
Processed prompts:  87%| | 446/512 [00:14<00:02, 29.15it/s, est. speed input: 31305.79 toks/s, output: 30.57 toks/s]
Processed prompts:  88%| | 450/512 [00:14<00:02, 30.35it/s, est. speed input: 31330.77 toks/s, output: 30.60 toks/s]
Processed prompts:  89%| | 454/512 [00:14<00:01, 29.74it/s, est. speed input: 31309.45 toks/s, output: 30.58 toks/s]
Processed prompts:  89%| | 458/512 [00:14<00:01, 29.14it/s, est. speed input: 31282.70 toks/s, output: 30.55 toks/s]
Processed prompts:  90%| | 462/512 [00:15<00:01, 29.09it/s, est. speed input: 31267.89 toks/s, output: 30.53 toks/s]
Processed prompts:  91%| | 466/512 [00:15<00:01, 29.04it/s, est. speed input: 31253.02 toks/s, output: 30.52 toks/s]
Processed prompts:  92%|| 470/512 [00:15<00:01, 28.98it/s, est. speed input: 31237.48 toks/s, output: 30.51 toks/s]
Processed prompts:  93%|| 474/512 [00:15<00:01, 29.00it/s, est. speed input: 31224.23 toks/s, output: 30.49 toks/s]
Processed prompts:  93%|| 478/512 [00:15<00:01, 29.07it/s, est. speed input: 31212.84 toks/s, output: 30.48 toks/s]
Processed prompts:  94%|| 482/512 [00:15<00:01, 29.05it/s, est. speed input: 31199.82 toks/s, output: 30.47 toks/s]
Processed prompts:  95%|| 486/512 [00:15<00:00, 28.88it/s, est. speed input: 31181.81 toks/s, output: 30.45 toks/s]
Processed prompts:  96%|| 490/512 [00:16<00:00, 28.91it/s, est. speed input: 31168.85 toks/s, output: 30.44 toks/s]
Processed prompts:  96%|| 494/512 [00:16<00:00, 29.06it/s, est. speed input: 31160.21 toks/s, output: 30.43 toks/s]
Processed prompts:  97%|| 498/512 [00:16<00:00, 29.20it/s, est. speed input: 31152.63 toks/s, output: 30.42 toks/s]
Processed prompts:  98%|| 502/512 [00:16<00:00, 29.22it/s, est. speed input: 31142.83 toks/s, output: 30.41 toks/s]
Processed prompts:  99%|| 506/512 [00:16<00:00, 29.34it/s, est. speed input: 31136.11 toks/s, output: 30.41 toks/s]
Processed prompts: 100%|| 510/512 [00:16<00:00, 30.92it/s, est. speed input: 31170.50 toks/s, output: 30.44 toks/s]
Processed prompts: 100%|| 512/512 [00:16<00:00, 30.92it/s, est. speed input: 31292.55 toks/s, output: 30.56 toks/s]
Processed prompts: 100%|| 512/512 [00:16<00:00, 30.56it/s, est. speed input: 31292.55 toks/s, output: 30.56 toks/s]
[rank0]:[W126 03:28:10.000744952 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 03:28:13
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:28:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:28:19 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=804321) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=804321) WARNING 01-26 03:28:41 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.12 requests/s, 28822.87 total tokens/s, 28.12 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 03:28:19] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:28:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:28:19] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:28:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:28:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:28:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:28:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:28:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:28:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:28:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:28:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:28:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:28:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:28:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:28:22] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:28:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:28:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:28:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:28:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:28:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:28:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:28:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:28:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:28:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:28:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:28:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:28:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:28:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=804321) [2026-01-26 03:28:23] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=804321) [2026-01-26 03:28:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=804321) [2026-01-26 03:28:23] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=804321) [2026-01-26 03:28:23] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=804321) [2026-01-26 03:28:23] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=804321) [2026-01-26 03:28:23] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=804321) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=804321) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.70s/it]
(EngineCore_DP0 pid=804321) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.70s/it]
(EngineCore_DP0 pid=804321) 
(EngineCore_DP0 pid=804321) [2026-01-26 03:28:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=804321) [2026-01-26 03:28:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=804321) [2026-01-26 03:28:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=804321) [2026-01-26 03:28:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=804321) [2026-01-26 03:28:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=804321) [2026-01-26 03:28:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=804321) [2026-01-26 03:28:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=804321) [2026-01-26 03:28:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=804321) 2026-01-26 03:28:40,345 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=804321) 2026-01-26 03:28:40,399 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   6%|         | 62/1024 [00:00<00:01, 614.37it/s]
Adding requests:  12%|        | 124/1024 [00:00<00:01, 589.72it/s]
Adding requests:  18%|        | 184/1024 [00:00<00:01, 549.37it/s]
Adding requests:  23%|       | 240/1024 [00:00<00:01, 550.80it/s]
Adding requests:  29%|       | 296/1024 [00:00<00:01, 537.95it/s]
Adding requests:  34%|      | 350/1024 [00:00<00:01, 529.40it/s]
Adding requests:  39%|      | 404/1024 [00:00<00:01, 527.83it/s]
Adding requests:  45%|     | 457/1024 [00:00<00:01, 513.94it/s]
Adding requests:  50%|     | 509/1024 [00:00<00:01, 511.06it/s]
Adding requests:  55%|    | 561/1024 [00:01<00:00, 494.49it/s]
Adding requests:  60%|    | 614/1024 [00:01<00:00, 503.55it/s]
Adding requests:  65%|   | 668/1024 [00:01<00:00, 514.00it/s]
Adding requests:  70%|   | 721/1024 [00:01<00:00, 517.93it/s]
Adding requests:  75%|  | 773/1024 [00:01<00:00, 514.89it/s]
Adding requests:  81%|  | 825/1024 [00:01<00:00, 515.01it/s]
Adding requests:  86%| | 877/1024 [00:01<00:00, 510.25it/s]
Adding requests:  91%| | 931/1024 [00:01<00:00, 517.49it/s]
Adding requests:  96%|| 985/1024 [00:01<00:00, 521.86it/s]
Adding requests: 100%|| 1024/1024 [00:01<00:00, 523.11it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 50/1024 [00:00<00:03, 247.67it/s, est. speed input: 253672.36 toks/s, output: 247.69 toks/s]
Processed prompts:   7%|         | 75/1024 [00:01<00:15, 60.18it/s, est. speed input: 72615.61 toks/s, output: 70.91 toks/s]   
Processed prompts:   8%|         | 87/1024 [00:01<00:17, 54.85it/s, est. speed input: 66274.67 toks/s, output: 64.72 toks/s]
Processed prompts:   9%|         | 96/1024 [00:01<00:19, 48.08it/s, est. speed input: 60371.31 toks/s, output: 58.96 toks/s]
Processed prompts:  10%|         | 103/1024 [00:01<00:22, 41.27it/s, est. speed input: 55208.45 toks/s, output: 53.91 toks/s]
Processed prompts:  11%|         | 108/1024 [00:02<00:26, 34.27it/s, est. speed input: 50407.16 toks/s, output: 49.23 toks/s]
Processed prompts:  11%|         | 114/1024 [00:02<00:30, 30.33it/s, est. speed input: 47090.52 toks/s, output: 45.99 toks/s]
Processed prompts:  12%|        | 122/1024 [00:02<00:30, 29.77it/s, est. speed input: 45256.68 toks/s, output: 44.20 toks/s]
Processed prompts:  13%|        | 130/1024 [00:03<00:30, 29.32it/s, est. speed input: 43742.07 toks/s, output: 42.72 toks/s]
Processed prompts:  13%|        | 138/1024 [00:03<00:30, 28.98it/s, est. speed input: 42472.95 toks/s, output: 41.48 toks/s]
Processed prompts:  14%|        | 146/1024 [00:03<00:30, 28.61it/s, est. speed input: 41353.53 toks/s, output: 40.38 toks/s]
Processed prompts:  15%|        | 154/1024 [00:03<00:30, 28.50it/s, est. speed input: 40450.38 toks/s, output: 39.50 toks/s]
Processed prompts:  16%|        | 162/1024 [00:04<00:30, 28.47it/s, est. speed input: 39684.28 toks/s, output: 38.75 toks/s]
Processed prompts:  17%|        | 170/1024 [00:04<00:29, 28.48it/s, est. speed input: 39024.54 toks/s, output: 38.11 toks/s]
Processed prompts:  17%|        | 178/1024 [00:04<00:29, 28.28it/s, est. speed input: 38387.05 toks/s, output: 37.49 toks/s]
Processed prompts:  18%|        | 186/1024 [00:05<00:29, 28.31it/s, est. speed input: 37862.44 toks/s, output: 36.97 toks/s]
Processed prompts:  19%|        | 194/1024 [00:05<00:29, 28.32it/s, est. speed input: 37393.72 toks/s, output: 36.52 toks/s]
Processed prompts:  20%|        | 202/1024 [00:05<00:29, 28.10it/s, est. speed input: 36921.27 toks/s, output: 36.06 toks/s]
Processed prompts:  21%|        | 210/1024 [00:05<00:28, 28.19it/s, est. speed input: 36545.65 toks/s, output: 35.69 toks/s]
Processed prompts:  21%|       | 218/1024 [00:06<00:28, 28.18it/s, est. speed input: 36191.28 toks/s, output: 35.34 toks/s]
Processed prompts:  22%|       | 226/1024 [00:06<00:28, 28.21it/s, est. speed input: 35873.67 toks/s, output: 35.03 toks/s]
Processed prompts:  23%|       | 234/1024 [00:06<00:28, 28.01it/s, est. speed input: 35544.48 toks/s, output: 34.71 toks/s]
Processed prompts:  24%|       | 242/1024 [00:07<00:27, 28.16it/s, est. speed input: 35291.33 toks/s, output: 34.46 toks/s]
Processed prompts:  24%|       | 250/1024 [00:07<00:27, 28.18it/s, est. speed input: 35043.76 toks/s, output: 34.22 toks/s]
Processed prompts:  25%|       | 258/1024 [00:07<00:27, 28.29it/s, est. speed input: 34828.69 toks/s, output: 34.01 toks/s]
Processed prompts:  26%|       | 266/1024 [00:07<00:26, 28.21it/s, est. speed input: 34606.45 toks/s, output: 33.80 toks/s]
Processed prompts:  27%|       | 274/1024 [00:08<00:26, 28.17it/s, est. speed input: 34401.31 toks/s, output: 33.59 toks/s]
Processed prompts:  28%|       | 282/1024 [00:08<00:26, 28.25it/s, est. speed input: 34226.11 toks/s, output: 33.42 toks/s]
Processed prompts:  28%|       | 290/1024 [00:08<00:25, 28.28it/s, est. speed input: 34057.23 toks/s, output: 33.26 toks/s]
Processed prompts:  29%|       | 298/1024 [00:09<00:25, 28.07it/s, est. speed input: 33871.23 toks/s, output: 33.08 toks/s]
Processed prompts:  30%|       | 306/1024 [00:09<00:25, 28.22it/s, est. speed input: 33732.49 toks/s, output: 32.94 toks/s]
Processed prompts:  31%|       | 314/1024 [00:09<00:25, 28.28it/s, est. speed input: 33596.06 toks/s, output: 32.81 toks/s]
Processed prompts:  31%|      | 322/1024 [00:09<00:24, 28.18it/s, est. speed input: 33451.20 toks/s, output: 32.67 toks/s]
Processed prompts:  32%|      | 330/1024 [00:10<00:24, 28.18it/s, est. speed input: 33322.94 toks/s, output: 32.54 toks/s]
Processed prompts:  33%|      | 338/1024 [00:10<00:23, 28.91it/s, est. speed input: 33277.18 toks/s, output: 32.50 toks/s]
Processed prompts:  34%|      | 346/1024 [00:10<00:23, 28.74it/s, est. speed input: 33164.91 toks/s, output: 32.39 toks/s]
Processed prompts:  35%|      | 354/1024 [00:10<00:23, 28.48it/s, est. speed input: 33045.05 toks/s, output: 32.27 toks/s]
Processed prompts:  35%|      | 362/1024 [00:11<00:23, 28.43it/s, est. speed input: 32942.63 toks/s, output: 32.17 toks/s]
Processed prompts:  36%|      | 370/1024 [00:11<00:23, 28.32it/s, est. speed input: 32839.31 toks/s, output: 32.07 toks/s]
Processed prompts:  37%|      | 378/1024 [00:11<00:22, 28.27it/s, est. speed input: 32743.19 toks/s, output: 31.98 toks/s]
Processed prompts:  38%|      | 386/1024 [00:12<00:22, 28.16it/s, est. speed input: 32644.70 toks/s, output: 31.88 toks/s]
Processed prompts:  38%|      | 394/1024 [00:12<00:22, 28.18it/s, est. speed input: 32558.95 toks/s, output: 31.80 toks/s]
Processed prompts:  39%|      | 402/1024 [00:12<00:22, 28.15it/s, est. speed input: 32473.50 toks/s, output: 31.71 toks/s]
Processed prompts:  40%|      | 410/1024 [00:12<00:21, 28.21it/s, est. speed input: 32398.44 toks/s, output: 31.64 toks/s]
Processed prompts:  41%|      | 418/1024 [00:13<00:21, 28.03it/s, est. speed input: 32308.10 toks/s, output: 31.55 toks/s]
Processed prompts:  42%|     | 426/1024 [00:13<00:21, 28.20it/s, est. speed input: 32246.15 toks/s, output: 31.49 toks/s]
Processed prompts:  42%|     | 434/1024 [00:13<00:20, 28.21it/s, est. speed input: 32177.65 toks/s, output: 31.42 toks/s]
Processed prompts:  43%|     | 442/1024 [00:14<00:20, 28.20it/s, est. speed input: 32110.39 toks/s, output: 31.36 toks/s]
Processed prompts:  44%|     | 450/1024 [00:14<00:19, 28.71it/s, est. speed input: 32084.20 toks/s, output: 31.33 toks/s]
Processed prompts:  45%|     | 458/1024 [00:14<00:19, 28.59it/s, est. speed input: 32024.83 toks/s, output: 31.27 toks/s]
Processed prompts:  46%|     | 466/1024 [00:14<00:19, 28.46it/s, est. speed input: 31964.04 toks/s, output: 31.21 toks/s]
Processed prompts:  46%|     | 474/1024 [00:15<00:19, 28.25it/s, est. speed input: 31897.16 toks/s, output: 31.15 toks/s]
Processed prompts:  47%|     | 482/1024 [00:15<00:19, 28.25it/s, est. speed input: 31842.88 toks/s, output: 31.10 toks/s]
Processed prompts:  48%|     | 490/1024 [00:15<00:18, 28.27it/s, est. speed input: 31791.68 toks/s, output: 31.05 toks/s]
Processed prompts:  49%|     | 498/1024 [00:16<00:18, 28.24it/s, est. speed input: 31739.71 toks/s, output: 31.00 toks/s]
Processed prompts:  49%|     | 506/1024 [00:16<00:18, 28.09it/s, est. speed input: 31681.38 toks/s, output: 30.94 toks/s]
Processed prompts:  50%|     | 514/1024 [00:16<00:18, 28.08it/s, est. speed input: 31630.65 toks/s, output: 30.89 toks/s]
Processed prompts:  51%|     | 522/1024 [00:16<00:17, 28.11it/s, est. speed input: 31584.10 toks/s, output: 30.84 toks/s]
Processed prompts:  52%|    | 530/1024 [00:17<00:17, 28.20it/s, est. speed input: 31543.43 toks/s, output: 30.80 toks/s]
Processed prompts:  53%|    | 538/1024 [00:17<00:17, 28.05it/s, est. speed input: 31490.86 toks/s, output: 30.75 toks/s]
Processed prompts:  53%|    | 546/1024 [00:17<00:17, 28.02it/s, est. speed input: 31445.07 toks/s, output: 30.71 toks/s]
Processed prompts:  54%|    | 554/1024 [00:18<00:16, 28.14it/s, est. speed input: 31408.63 toks/s, output: 30.67 toks/s]
Processed prompts:  55%|    | 562/1024 [00:18<00:16, 28.18it/s, est. speed input: 31370.62 toks/s, output: 30.64 toks/s]
Processed prompts:  56%|    | 570/1024 [00:18<00:16, 28.00it/s, est. speed input: 31321.91 toks/s, output: 30.59 toks/s]
Processed prompts:  56%|    | 578/1024 [00:18<00:15, 28.11it/s, est. speed input: 31288.15 toks/s, output: 30.55 toks/s]
Processed prompts:  57%|    | 586/1024 [00:19<00:15, 28.09it/s, est. speed input: 31250.05 toks/s, output: 30.52 toks/s]
Processed prompts:  58%|    | 594/1024 [00:19<00:15, 27.97it/s, est. speed input: 31207.09 toks/s, output: 30.48 toks/s]
Processed prompts:  59%|    | 602/1024 [00:19<00:15, 28.05it/s, est. speed input: 31174.34 toks/s, output: 30.44 toks/s]
Processed prompts:  60%|    | 610/1024 [00:20<00:14, 28.07it/s, est. speed input: 31140.56 toks/s, output: 30.41 toks/s]
Processed prompts:  60%|    | 618/1024 [00:20<00:14, 28.11it/s, est. speed input: 31109.28 toks/s, output: 30.38 toks/s]
Processed prompts:  61%|    | 626/1024 [00:20<00:14, 27.93it/s, est. speed input: 31067.99 toks/s, output: 30.34 toks/s]
Processed prompts:  62%|   | 634/1024 [00:20<00:13, 28.00it/s, est. speed input: 31037.81 toks/s, output: 30.31 toks/s]
Processed prompts:  63%|   | 642/1024 [00:21<00:13, 28.13it/s, est. speed input: 31012.40 toks/s, output: 30.29 toks/s]
Processed prompts:  63%|   | 650/1024 [00:21<00:13, 28.17it/s, est. speed input: 30985.22 toks/s, output: 30.26 toks/s]
Processed prompts:  64%|   | 658/1024 [00:21<00:13, 28.10it/s, est. speed input: 30953.80 toks/s, output: 30.23 toks/s]
Processed prompts:  65%|   | 666/1024 [00:22<00:12, 28.14it/s, est. speed input: 30927.49 toks/s, output: 30.20 toks/s]
Processed prompts:  66%|   | 674/1024 [00:22<00:12, 28.25it/s, est. speed input: 30905.94 toks/s, output: 30.18 toks/s]
Processed prompts:  67%|   | 682/1024 [00:22<00:12, 28.12it/s, est. speed input: 30874.92 toks/s, output: 30.15 toks/s]
Processed prompts:  67%|   | 690/1024 [00:22<00:11, 28.13it/s, est. speed input: 30849.86 toks/s, output: 30.13 toks/s]
Processed prompts:  68%|   | 698/1024 [00:23<00:11, 28.23it/s, est. speed input: 30828.97 toks/s, output: 30.11 toks/s]
Processed prompts:  69%|   | 706/1024 [00:23<00:11, 28.25it/s, est. speed input: 30806.83 toks/s, output: 30.08 toks/s]
Processed prompts:  70%|   | 714/1024 [00:23<00:11, 28.15it/s, est. speed input: 30779.93 toks/s, output: 30.06 toks/s]
Processed prompts:  71%|   | 722/1024 [00:24<00:10, 28.20it/s, est. speed input: 30758.85 toks/s, output: 30.04 toks/s]
Processed prompts:  71%|  | 730/1024 [00:24<00:10, 28.30it/s, est. speed input: 30741.31 toks/s, output: 30.02 toks/s]
Processed prompts:  72%|  | 738/1024 [00:24<00:10, 28.22it/s, est. speed input: 30717.59 toks/s, output: 30.00 toks/s]
Processed prompts:  73%|  | 746/1024 [00:24<00:09, 28.09it/s, est. speed input: 30691.59 toks/s, output: 29.97 toks/s]
Processed prompts:  74%|  | 754/1024 [00:25<00:09, 28.15it/s, est. speed input: 30672.24 toks/s, output: 29.95 toks/s]
Processed prompts:  74%|  | 762/1024 [00:25<00:09, 28.27it/s, est. speed input: 30656.58 toks/s, output: 29.94 toks/s]
Processed prompts:  75%|  | 770/1024 [00:25<00:08, 28.27it/s, est. speed input: 30637.88 toks/s, output: 29.92 toks/s]
Processed prompts:  76%|  | 778/1024 [00:26<00:08, 28.05it/s, est. speed input: 30610.64 toks/s, output: 29.89 toks/s]
Processed prompts:  77%|  | 786/1024 [00:26<00:08, 28.09it/s, est. speed input: 30591.76 toks/s, output: 29.87 toks/s]
Processed prompts:  78%|  | 794/1024 [00:26<00:08, 28.11it/s, est. speed input: 30572.84 toks/s, output: 29.86 toks/s]
Processed prompts:  78%|  | 802/1024 [00:26<00:07, 27.97it/s, est. speed input: 30548.53 toks/s, output: 29.83 toks/s]
Processed prompts:  79%|  | 810/1024 [00:27<00:07, 28.05it/s, est. speed input: 30531.63 toks/s, output: 29.82 toks/s]
Processed prompts:  80%|  | 818/1024 [00:27<00:07, 28.22it/s, est. speed input: 30519.07 toks/s, output: 29.80 toks/s]
Processed prompts:  81%|  | 826/1024 [00:27<00:07, 28.27it/s, est. speed input: 30504.40 toks/s, output: 29.79 toks/s]
Processed prompts:  81%| | 834/1024 [00:28<00:06, 28.11it/s, est. speed input: 30482.85 toks/s, output: 29.77 toks/s]
Processed prompts:  82%| | 842/1024 [00:28<00:06, 28.18it/s, est. speed input: 30468.38 toks/s, output: 29.75 toks/s]
Processed prompts:  83%| | 850/1024 [00:28<00:06, 28.10it/s, est. speed input: 30449.55 toks/s, output: 29.74 toks/s]
Processed prompts:  84%| | 858/1024 [00:28<00:05, 28.18it/s, est. speed input: 30435.91 toks/s, output: 29.72 toks/s]
Processed prompts:  85%| | 866/1024 [00:29<00:05, 28.02it/s, est. speed input: 30414.78 toks/s, output: 29.70 toks/s]
Processed prompts:  85%| | 874/1024 [00:29<00:05, 28.09it/s, est. speed input: 30400.49 toks/s, output: 29.69 toks/s]
Processed prompts:  86%| | 882/1024 [00:29<00:05, 28.11it/s, est. speed input: 30385.43 toks/s, output: 29.67 toks/s]
Processed prompts:  87%| | 890/1024 [00:30<00:04, 28.12it/s, est. speed input: 30370.65 toks/s, output: 29.66 toks/s]
Processed prompts:  88%| | 898/1024 [00:30<00:04, 28.08it/s, est. speed input: 30354.68 toks/s, output: 29.64 toks/s]
Processed prompts:  88%| | 906/1024 [00:30<00:04, 28.11it/s, est. speed input: 30340.75 toks/s, output: 29.63 toks/s]
Processed prompts:  89%| | 914/1024 [00:30<00:03, 28.15it/s, est. speed input: 30327.68 toks/s, output: 29.62 toks/s]
Processed prompts:  90%| | 922/1024 [00:31<00:03, 28.07it/s, est. speed input: 30311.20 toks/s, output: 29.60 toks/s]
Processed prompts:  91%| | 930/1024 [00:31<00:03, 28.15it/s, est. speed input: 30299.82 toks/s, output: 29.59 toks/s]
Processed prompts:  92%|| 938/1024 [00:31<00:02, 29.35it/s, est. speed input: 30323.65 toks/s, output: 29.61 toks/s]
Processed prompts:  92%|| 946/1024 [00:31<00:02, 29.03it/s, est. speed input: 30311.91 toks/s, output: 29.60 toks/s]
Processed prompts:  93%|| 954/1024 [00:32<00:02, 28.60it/s, est. speed input: 30293.70 toks/s, output: 29.58 toks/s]
Processed prompts:  94%|| 962/1024 [00:32<00:02, 28.57it/s, est. speed input: 30284.38 toks/s, output: 29.57 toks/s]
Processed prompts:  95%|| 970/1024 [00:32<00:01, 28.38it/s, est. speed input: 30269.80 toks/s, output: 29.56 toks/s]
Processed prompts:  96%|| 978/1024 [00:33<00:01, 28.36it/s, est. speed input: 30258.73 toks/s, output: 29.55 toks/s]
Processed prompts:  96%|| 986/1024 [00:33<00:01, 29.29it/s, est. speed input: 30275.51 toks/s, output: 29.57 toks/s]
Processed prompts:  97%|| 994/1024 [00:33<00:01, 28.99it/s, est. speed input: 30264.81 toks/s, output: 29.56 toks/s]
Processed prompts:  98%|| 1002/1024 [00:33<00:00, 28.79it/s, est. speed input: 30254.45 toks/s, output: 29.55 toks/s]
Processed prompts:  99%|| 1010/1024 [00:34<00:00, 28.60it/s, est. speed input: 30242.61 toks/s, output: 29.53 toks/s]
Processed prompts:  99%|| 1018/1024 [00:34<00:00, 29.28it/s, est. speed input: 30253.97 toks/s, output: 29.54 toks/s]
Processed prompts: 100%|| 1024/1024 [00:34<00:00, 29.28it/s, est. speed input: 30432.15 toks/s, output: 29.72 toks/s]
Processed prompts: 100%|| 1024/1024 [00:34<00:00, 29.72it/s, est. speed input: 30432.15 toks/s, output: 29.72 toks/s]
[rank0]:[W126 03:29:17.959278454 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 03:29:20
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:29:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:29:29 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=805482) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=805482) WARNING 01-26 03:29:51 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.42 requests/s, 29132.76 total tokens/s, 28.42 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 03:29:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:29:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:29:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:29:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:29:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:29:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:29:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:29:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:29:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:29:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:29:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:29:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:29:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:29:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:29:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:29:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:29:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:29:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:29:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:29:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:29:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:29:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:29:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:29:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:29:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:29:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:29:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:29:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=805482) [2026-01-26 03:29:33] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=805482) [2026-01-26 03:29:33] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=805482) [2026-01-26 03:29:33] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=805482) [2026-01-26 03:29:33] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=805482) [2026-01-26 03:29:33] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=805482) [2026-01-26 03:29:33] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=805482) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=805482) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.55s/it]
(EngineCore_DP0 pid=805482) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.55s/it]
(EngineCore_DP0 pid=805482) 
(EngineCore_DP0 pid=805482) [2026-01-26 03:29:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=805482) [2026-01-26 03:29:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=805482) [2026-01-26 03:29:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=805482) [2026-01-26 03:29:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=805482) [2026-01-26 03:29:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=805482) [2026-01-26 03:29:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=805482) [2026-01-26 03:29:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=805482) [2026-01-26 03:29:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=805482) 2026-01-26 03:29:50,575 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=805482) 2026-01-26 03:29:50,690 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 61/2048 [00:00<00:03, 604.17it/s]
Adding requests:   6%|         | 122/2048 [00:00<00:03, 586.76it/s]
Adding requests:   9%|         | 181/2048 [00:00<00:03, 539.04it/s]
Adding requests:  12%|        | 236/2048 [00:00<00:03, 538.61it/s]
Adding requests:  14%|        | 291/2048 [00:00<00:03, 532.44it/s]
Adding requests:  17%|        | 345/2048 [00:00<00:03, 532.02it/s]
Adding requests:  20%|        | 400/2048 [00:00<00:03, 536.93it/s]
Adding requests:  22%|       | 454/2048 [00:00<00:03, 524.47it/s]
Adding requests:  25%|       | 507/2048 [00:00<00:02, 517.98it/s]
Adding requests:  27%|       | 559/2048 [00:01<00:02, 509.76it/s]
Adding requests:  30%|       | 612/2048 [00:01<00:02, 515.46it/s]
Adding requests:  33%|      | 666/2048 [00:01<00:02, 522.72it/s]
Adding requests:  35%|      | 721/2048 [00:01<00:02, 527.98it/s]
Adding requests:  38%|      | 774/2048 [00:01<00:02, 509.05it/s]
Adding requests:  40%|      | 826/2048 [00:01<00:02, 506.07it/s]
Adding requests:  43%|     | 877/2048 [00:02<00:05, 208.69it/s]
Adding requests:  45%|     | 931/2048 [00:02<00:04, 256.44it/s]
Adding requests:  48%|     | 983/2048 [00:02<00:03, 301.76it/s]
Adding requests:  51%|     | 1037/2048 [00:02<00:02, 347.31it/s]
Adding requests:  53%|    | 1089/2048 [00:02<00:02, 384.84it/s]
Adding requests:  56%|    | 1141/2048 [00:02<00:02, 416.12it/s]
Adding requests:  58%|    | 1196/2048 [00:02<00:01, 450.02it/s]
Adding requests:  61%|    | 1251/2048 [00:02<00:01, 473.37it/s]
Adding requests:  64%|   | 1304/2048 [00:02<00:01, 487.57it/s]
Adding requests:  66%|   | 1357/2048 [00:03<00:01, 492.83it/s]
Adding requests:  69%|   | 1413/2048 [00:03<00:01, 510.05it/s]
Adding requests:  72%|  | 1466/2048 [00:03<00:01, 514.35it/s]
Adding requests:  74%|  | 1524/2048 [00:03<00:00, 530.90it/s]
Adding requests:  77%|  | 1580/2048 [00:03<00:00, 538.54it/s]
Adding requests:  80%|  | 1635/2048 [00:03<00:00, 537.95it/s]
Adding requests:  83%| | 1690/2048 [00:03<00:00, 532.92it/s]
Adding requests:  85%| | 1744/2048 [00:03<00:00, 532.23it/s]
Adding requests:  88%| | 1799/2048 [00:03<00:00, 536.85it/s]
Adding requests:  90%| | 1853/2048 [00:03<00:00, 537.47it/s]
Adding requests:  93%|| 1908/2048 [00:04<00:00, 540.62it/s]
Adding requests:  96%|| 1963/2048 [00:04<00:00, 529.12it/s]
Adding requests:  98%|| 2017/2048 [00:04<00:00, 511.72it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 467.90it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 114/2048 [00:00<00:04, 390.07it/s, est. speed input: 399495.66 toks/s, output: 390.09 toks/s]
Processed prompts:   8%|         | 154/2048 [00:01<00:21, 89.87it/s, est. speed input: 110997.57 toks/s, output: 108.40 toks/s] 
Processed prompts:   8%|         | 173/2048 [00:01<00:27, 68.85it/s, est. speed input: 89395.62 toks/s, output: 87.30 toks/s]  
Processed prompts:   9%|         | 185/2048 [00:02<00:35, 52.12it/s, est. speed input: 74365.15 toks/s, output: 72.62 toks/s]
Processed prompts:   9%|         | 194/2048 [00:03<00:46, 40.08it/s, est. speed input: 63855.68 toks/s, output: 62.36 toks/s]
Processed prompts:  10%|         | 210/2048 [00:03<00:50, 36.19it/s, est. speed input: 58429.70 toks/s, output: 57.06 toks/s]
Processed prompts:  11%|         | 226/2048 [00:04<00:53, 33.78it/s, est. speed input: 54563.79 toks/s, output: 53.28 toks/s]
Processed prompts:  12%|        | 242/2048 [00:04<00:56, 32.09it/s, est. speed input: 51560.91 toks/s, output: 50.35 toks/s]
Processed prompts:  13%|        | 258/2048 [00:05<00:57, 30.89it/s, est. speed input: 49166.70 toks/s, output: 48.01 toks/s]
Processed prompts:  13%|        | 274/2048 [00:05<00:58, 30.14it/s, est. speed input: 47266.28 toks/s, output: 46.16 toks/s]
Processed prompts:  14%|        | 290/2048 [00:06<00:59, 29.56it/s, est. speed input: 45664.84 toks/s, output: 44.59 toks/s]
Processed prompts:  15%|        | 306/2048 [00:07<00:59, 29.23it/s, est. speed input: 44350.90 toks/s, output: 43.31 toks/s]
Processed prompts:  16%|        | 322/2048 [00:07<00:59, 28.93it/s, est. speed input: 43205.14 toks/s, output: 42.19 toks/s]
Processed prompts:  17%|        | 338/2048 [00:08<00:58, 28.99it/s, est. speed input: 42307.52 toks/s, output: 41.32 toks/s]
Processed prompts:  17%|        | 354/2048 [00:08<00:58, 28.78it/s, est. speed input: 41446.24 toks/s, output: 40.47 toks/s]
Processed prompts:  18%|        | 370/2048 [00:09<00:58, 28.69it/s, est. speed input: 40703.53 toks/s, output: 39.75 toks/s]
Processed prompts:  19%|        | 386/2048 [00:09<00:58, 28.55it/s, est. speed input: 40025.97 toks/s, output: 39.09 toks/s]
Processed prompts:  20%|        | 402/2048 [00:10<00:57, 28.54it/s, est. speed input: 39443.56 toks/s, output: 38.52 toks/s]
Processed prompts:  20%|        | 418/2048 [00:11<00:57, 28.44it/s, est. speed input: 38899.54 toks/s, output: 37.99 toks/s]
Processed prompts:  21%|        | 434/2048 [00:11<00:56, 28.48it/s, est. speed input: 38432.12 toks/s, output: 37.53 toks/s]
Processed prompts:  22%|       | 450/2048 [00:12<00:55, 28.75it/s, est. speed input: 38058.88 toks/s, output: 37.17 toks/s]
Processed prompts:  23%|       | 466/2048 [00:12<00:55, 28.71it/s, est. speed input: 37672.49 toks/s, output: 36.79 toks/s]
Processed prompts:  24%|       | 482/2048 [00:13<00:54, 28.59it/s, est. speed input: 37302.51 toks/s, output: 36.43 toks/s]
Processed prompts:  24%|       | 498/2048 [00:13<00:54, 28.56it/s, est. speed input: 36970.71 toks/s, output: 36.10 toks/s]
Processed prompts:  25%|       | 514/2048 [00:14<00:53, 28.44it/s, est. speed input: 36648.95 toks/s, output: 35.79 toks/s]
Processed prompts:  26%|       | 530/2048 [00:14<00:53, 28.39it/s, est. speed input: 36357.47 toks/s, output: 35.51 toks/s]
Processed prompts:  27%|       | 546/2048 [00:15<00:52, 28.42it/s, est. speed input: 36096.38 toks/s, output: 35.25 toks/s]
Processed prompts:  27%|       | 562/2048 [00:16<00:52, 28.35it/s, est. speed input: 35840.47 toks/s, output: 35.00 toks/s]
Processed prompts:  28%|       | 578/2048 [00:16<00:51, 28.37it/s, est. speed input: 35611.89 toks/s, output: 34.78 toks/s]
Processed prompts:  29%|       | 594/2048 [00:17<00:51, 28.35it/s, est. speed input: 35394.02 toks/s, output: 34.56 toks/s]
Processed prompts:  30%|       | 610/2048 [00:17<00:50, 28.38it/s, est. speed input: 35195.90 toks/s, output: 34.37 toks/s]
Processed prompts:  31%|       | 626/2048 [00:18<00:50, 28.34it/s, est. speed input: 35002.37 toks/s, output: 34.18 toks/s]
Processed prompts:  31%|      | 642/2048 [00:18<00:49, 28.37it/s, est. speed input: 34826.42 toks/s, output: 34.01 toks/s]
Processed prompts:  32%|      | 658/2048 [00:19<00:49, 28.32it/s, est. speed input: 34653.69 toks/s, output: 33.84 toks/s]
Processed prompts:  33%|      | 674/2048 [00:20<00:48, 28.38it/s, est. speed input: 34500.84 toks/s, output: 33.69 toks/s]
Processed prompts:  34%|      | 690/2048 [00:20<00:47, 28.30it/s, est. speed input: 34342.55 toks/s, output: 33.54 toks/s]
Processed prompts:  34%|      | 706/2048 [00:21<00:47, 28.39it/s, est. speed input: 34209.47 toks/s, output: 33.41 toks/s]
Processed prompts:  35%|      | 722/2048 [00:21<00:46, 28.32it/s, est. speed input: 34068.17 toks/s, output: 33.27 toks/s]
Processed prompts:  36%|      | 738/2048 [00:22<00:46, 28.39it/s, est. speed input: 33946.87 toks/s, output: 33.15 toks/s]
Processed prompts:  37%|      | 754/2048 [00:22<00:45, 28.35it/s, est. speed input: 33822.88 toks/s, output: 33.03 toks/s]
Processed prompts:  38%|      | 770/2048 [00:23<00:45, 28.39it/s, est. speed input: 33710.42 toks/s, output: 32.92 toks/s]
Processed prompts:  38%|      | 786/2048 [00:23<00:44, 28.31it/s, est. speed input: 33594.54 toks/s, output: 32.81 toks/s]
Processed prompts:  39%|      | 802/2048 [00:24<00:43, 28.32it/s, est. speed input: 33488.96 toks/s, output: 32.70 toks/s]
Processed prompts:  40%|      | 818/2048 [00:25<00:43, 28.34it/s, est. speed input: 33390.00 toks/s, output: 32.61 toks/s]
Processed prompts:  41%|      | 834/2048 [00:25<00:42, 28.28it/s, est. speed input: 33288.61 toks/s, output: 32.51 toks/s]
Processed prompts:  42%|     | 850/2048 [00:26<00:42, 28.38it/s, est. speed input: 33203.63 toks/s, output: 32.43 toks/s]
Processed prompts:  42%|     | 866/2048 [00:26<00:41, 28.31it/s, est. speed input: 33110.75 toks/s, output: 32.33 toks/s]
Processed prompts:  43%|     | 882/2048 [00:27<00:41, 28.30it/s, est. speed input: 33025.01 toks/s, output: 32.25 toks/s]
Processed prompts:  44%|     | 898/2048 [00:27<00:40, 28.22it/s, est. speed input: 32936.64 toks/s, output: 32.16 toks/s]
Processed prompts:  45%|     | 914/2048 [00:28<00:40, 28.34it/s, est. speed input: 32865.42 toks/s, output: 32.10 toks/s]
Processed prompts:  45%|     | 930/2048 [00:29<00:38, 28.70it/s, est. speed input: 32817.52 toks/s, output: 32.05 toks/s]
Processed prompts:  46%|     | 946/2048 [00:29<00:38, 28.64it/s, est. speed input: 32748.80 toks/s, output: 31.98 toks/s]
Processed prompts:  47%|     | 962/2048 [00:30<00:38, 28.44it/s, est. speed input: 32671.07 toks/s, output: 31.91 toks/s]
Processed prompts:  48%|     | 978/2048 [00:30<00:36, 28.93it/s, est. speed input: 32639.63 toks/s, output: 31.87 toks/s]
Processed prompts:  49%|     | 994/2048 [00:31<00:36, 28.74it/s, est. speed input: 32573.32 toks/s, output: 31.81 toks/s]
Processed prompts:  49%|     | 1010/2048 [00:31<00:36, 28.68it/s, est. speed input: 32514.36 toks/s, output: 31.75 toks/s]
Processed prompts:  50%|     | 1026/2048 [00:32<00:35, 28.52it/s, est. speed input: 32449.64 toks/s, output: 31.69 toks/s]
Processed prompts:  51%|     | 1042/2048 [00:32<00:35, 28.51it/s, est. speed input: 32393.82 toks/s, output: 31.63 toks/s]
Processed prompts:  52%|    | 1058/2048 [00:33<00:34, 28.42it/s, est. speed input: 32334.21 toks/s, output: 31.58 toks/s]
Processed prompts:  52%|    | 1074/2048 [00:34<00:34, 28.35it/s, est. speed input: 32276.68 toks/s, output: 31.52 toks/s]
Processed prompts:  53%|    | 1090/2048 [00:34<00:33, 28.39it/s, est. speed input: 32226.25 toks/s, output: 31.47 toks/s]
Processed prompts:  54%|    | 1106/2048 [00:35<00:33, 28.35it/s, est. speed input: 32173.31 toks/s, output: 31.42 toks/s]
Processed prompts:  55%|    | 1122/2048 [00:35<00:32, 28.39it/s, est. speed input: 32126.01 toks/s, output: 31.37 toks/s]
Processed prompts:  56%|    | 1138/2048 [00:36<00:32, 28.32it/s, est. speed input: 32074.49 toks/s, output: 31.32 toks/s]
Processed prompts:  56%|    | 1154/2048 [00:36<00:31, 28.82it/s, est. speed input: 32055.72 toks/s, output: 31.30 toks/s]
Processed prompts:  57%|    | 1170/2048 [00:37<00:30, 28.63it/s, est. speed input: 32007.54 toks/s, output: 31.26 toks/s]
Processed prompts:  58%|    | 1186/2048 [00:37<00:30, 28.62it/s, est. speed input: 31967.36 toks/s, output: 31.22 toks/s]
Processed prompts:  59%|    | 1202/2048 [00:38<00:29, 28.47it/s, est. speed input: 31920.45 toks/s, output: 31.17 toks/s]
Processed prompts:  59%|    | 1218/2048 [00:39<00:29, 28.51it/s, est. speed input: 31883.01 toks/s, output: 31.14 toks/s]
Processed prompts:  60%|    | 1234/2048 [00:39<00:28, 28.39it/s, est. speed input: 31838.51 toks/s, output: 31.09 toks/s]
Processed prompts:  61%|    | 1250/2048 [00:40<00:28, 28.44it/s, est. speed input: 31802.23 toks/s, output: 31.06 toks/s]
Processed prompts:  62%|   | 1266/2048 [00:40<00:27, 28.82it/s, est. speed input: 31784.44 toks/s, output: 31.04 toks/s]
Processed prompts:  63%|   | 1282/2048 [00:41<00:26, 28.72it/s, est. speed input: 31748.95 toks/s, output: 31.00 toks/s]
Processed prompts:  63%|   | 1298/2048 [00:41<00:25, 28.99it/s, est. speed input: 31731.14 toks/s, output: 30.99 toks/s]
Processed prompts:  64%|   | 1314/2048 [00:42<00:25, 28.84it/s, est. speed input: 31697.12 toks/s, output: 30.95 toks/s]
Processed prompts:  65%|   | 1330/2048 [00:43<00:25, 28.59it/s, est. speed input: 31657.63 toks/s, output: 30.92 toks/s]
Processed prompts:  66%|   | 1346/2048 [00:43<00:24, 28.57it/s, est. speed input: 31625.77 toks/s, output: 30.88 toks/s]
Processed prompts:  67%|   | 1362/2048 [00:44<00:24, 28.41it/s, est. speed input: 31588.26 toks/s, output: 30.85 toks/s]
Processed prompts:  67%|   | 1378/2048 [00:44<00:23, 28.35it/s, est. speed input: 31553.95 toks/s, output: 30.81 toks/s]
Processed prompts:  68%|   | 1394/2048 [00:45<00:23, 28.35it/s, est. speed input: 31522.55 toks/s, output: 30.78 toks/s]
Processed prompts:  69%|   | 1410/2048 [00:45<00:22, 28.36it/s, est. speed input: 31492.41 toks/s, output: 30.75 toks/s]
Processed prompts:  70%|   | 1426/2048 [00:46<00:21, 28.36it/s, est. speed input: 31462.73 toks/s, output: 30.73 toks/s]
Processed prompts:  70%|   | 1442/2048 [00:46<00:21, 28.34it/s, est. speed input: 31432.75 toks/s, output: 30.70 toks/s]
Processed prompts:  71%|   | 1458/2048 [00:47<00:20, 28.37it/s, est. speed input: 31405.15 toks/s, output: 30.67 toks/s]
Processed prompts:  72%|  | 1474/2048 [00:48<00:20, 28.28it/s, est. speed input: 31373.71 toks/s, output: 30.64 toks/s]
Processed prompts:  73%|  | 1490/2048 [00:48<00:19, 28.39it/s, est. speed input: 31350.28 toks/s, output: 30.62 toks/s]
Processed prompts:  74%|  | 1506/2048 [00:49<00:19, 28.32it/s, est. speed input: 31321.29 toks/s, output: 30.59 toks/s]
Processed prompts:  74%|  | 1522/2048 [00:49<00:18, 28.38it/s, est. speed input: 31297.26 toks/s, output: 30.56 toks/s]
Processed prompts:  75%|  | 1538/2048 [00:50<00:18, 28.28it/s, est. speed input: 31268.22 toks/s, output: 30.54 toks/s]
Processed prompts:  76%|  | 1554/2048 [00:50<00:17, 28.30it/s, est. speed input: 31243.43 toks/s, output: 30.51 toks/s]
Processed prompts:  77%|  | 1570/2048 [00:51<00:16, 28.26it/s, est. speed input: 31216.94 toks/s, output: 30.49 toks/s]
Processed prompts:  77%|  | 1586/2048 [00:52<00:16, 28.72it/s, est. speed input: 31210.17 toks/s, output: 30.48 toks/s]
Processed prompts:  78%|  | 1602/2048 [00:52<00:15, 28.56it/s, est. speed input: 31185.12 toks/s, output: 30.45 toks/s]
Processed prompts:  79%|  | 1618/2048 [00:53<00:15, 28.48it/s, est. speed input: 31161.36 toks/s, output: 30.43 toks/s]
Processed prompts:  80%|  | 1634/2048 [00:53<00:14, 28.40it/s, est. speed input: 31137.51 toks/s, output: 30.41 toks/s]
Processed prompts:  81%|  | 1650/2048 [00:54<00:13, 28.80it/s, est. speed input: 31131.33 toks/s, output: 30.40 toks/s]
Processed prompts:  81%| | 1666/2048 [00:54<00:13, 28.59it/s, est. speed input: 31106.82 toks/s, output: 30.38 toks/s]
Processed prompts:  82%| | 1682/2048 [00:55<00:12, 28.49it/s, est. speed input: 31084.57 toks/s, output: 30.36 toks/s]
Processed prompts:  83%| | 1698/2048 [00:55<00:12, 28.49it/s, est. speed input: 31065.42 toks/s, output: 30.34 toks/s]
Processed prompts:  84%| | 1714/2048 [00:56<00:11, 28.39it/s, est. speed input: 31043.08 toks/s, output: 30.32 toks/s]
Processed prompts:  84%| | 1730/2048 [00:57<00:11, 28.38it/s, est. speed input: 31023.13 toks/s, output: 30.30 toks/s]
Processed prompts:  85%| | 1746/2048 [00:57<00:10, 28.36it/s, est. speed input: 31003.41 toks/s, output: 30.28 toks/s]
Processed prompts:  86%| | 1762/2048 [00:58<00:10, 28.39it/s, est. speed input: 30985.51 toks/s, output: 30.26 toks/s]
Processed prompts:  87%| | 1778/2048 [00:58<00:09, 28.32it/s, est. speed input: 30964.73 toks/s, output: 30.24 toks/s]
Processed prompts:  88%| | 1794/2048 [00:59<00:08, 28.39it/s, est. speed input: 30948.48 toks/s, output: 30.22 toks/s]
Processed prompts:  88%| | 1810/2048 [00:59<00:08, 28.35it/s, est. speed input: 30929.27 toks/s, output: 30.20 toks/s]
Processed prompts:  89%| | 1826/2048 [01:00<00:07, 28.40it/s, est. speed input: 30913.35 toks/s, output: 30.19 toks/s]
Processed prompts:  90%| | 1842/2048 [01:01<00:07, 28.31it/s, est. speed input: 30893.35 toks/s, output: 30.17 toks/s]
Processed prompts:  91%| | 1858/2048 [01:01<00:06, 28.30it/s, est. speed input: 30875.48 toks/s, output: 30.15 toks/s]
Processed prompts:  92%|| 1874/2048 [01:02<00:06, 28.71it/s, est. speed input: 30871.62 toks/s, output: 30.15 toks/s]
Processed prompts:  92%|| 1890/2048 [01:02<00:05, 28.61it/s, est. speed input: 30855.41 toks/s, output: 30.13 toks/s]
Processed prompts:  93%|| 1906/2048 [01:03<00:04, 28.48it/s, est. speed input: 30837.54 toks/s, output: 30.11 toks/s]
Processed prompts:  94%|| 1922/2048 [01:03<00:04, 28.46it/s, est. speed input: 30822.26 toks/s, output: 30.10 toks/s]
Processed prompts:  95%|| 1938/2048 [01:04<00:03, 28.35it/s, est. speed input: 30803.99 toks/s, output: 30.08 toks/s]
Processed prompts:  95%|| 1954/2048 [01:04<00:03, 28.76it/s, est. speed input: 30801.43 toks/s, output: 30.08 toks/s]
Processed prompts:  96%|| 1970/2048 [01:05<00:02, 28.61it/s, est. speed input: 30785.35 toks/s, output: 30.06 toks/s]
Processed prompts:  97%|| 1986/2048 [01:06<00:02, 28.94it/s, est. speed input: 30782.71 toks/s, output: 30.06 toks/s]
Processed prompts:  98%|| 2002/2048 [01:06<00:01, 29.71it/s, est. speed input: 30795.08 toks/s, output: 30.07 toks/s]
Processed prompts:  99%|| 2018/2048 [01:07<00:01, 29.21it/s, est. speed input: 30778.12 toks/s, output: 30.06 toks/s]
Processed prompts:  99%|| 2034/2048 [01:07<00:00, 29.37it/s, est. speed input: 30775.59 toks/s, output: 30.05 toks/s]
Processed prompts: 100%|| 2048/2048 [01:07<00:00, 29.37it/s, est. speed input: 30987.34 toks/s, output: 30.26 toks/s]
Processed prompts: 100%|| 2048/2048 [01:07<00:00, 30.26it/s, est. speed input: 30987.34 toks/s, output: 30.26 toks/s]
[rank0]:[W126 03:31:04.248403045 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 03:31:06
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:31:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:31:21 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=807206) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=807206) WARNING 01-26 03:31:44 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.55 requests/s, 29265.33 total tokens/s, 28.55 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 03:31:21] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:31:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:31:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:31:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:31:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:31:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:31:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:31:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:31:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:31:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:31:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:31:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:31:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:31:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:31:24] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:31:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:31:24] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:31:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:31:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:31:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:31:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:31:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:31:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:31:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:31:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:31:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:31:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:31:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=807206) [2026-01-26 03:31:25] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=807206) [2026-01-26 03:31:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=807206) [2026-01-26 03:31:25] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=807206) [2026-01-26 03:31:25] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=807206) [2026-01-26 03:31:25] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=807206) [2026-01-26 03:31:25] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=807206) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=807206) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.58s/it]
(EngineCore_DP0 pid=807206) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.58s/it]
(EngineCore_DP0 pid=807206) 
(EngineCore_DP0 pid=807206) [2026-01-26 03:31:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=807206) [2026-01-26 03:31:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=807206) [2026-01-26 03:31:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=807206) [2026-01-26 03:31:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=807206) [2026-01-26 03:31:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=807206) [2026-01-26 03:31:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=807206) [2026-01-26 03:31:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=807206) [2026-01-26 03:31:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=807206) 2026-01-26 03:31:43,094 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=807206) 2026-01-26 03:31:43,315 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   2%|         | 67/4096 [00:00<00:06, 660.75it/s]
Adding requests:   3%|         | 134/4096 [00:00<00:06, 647.42it/s]
Adding requests:   5%|         | 199/4096 [00:00<00:06, 585.21it/s]
Adding requests:   6%|         | 259/4096 [00:00<00:06, 570.01it/s]
Adding requests:   8%|         | 317/4096 [00:00<00:06, 552.97it/s]
Adding requests:   9%|         | 373/4096 [00:00<00:06, 543.95it/s]
Adding requests:  10%|         | 428/4096 [00:00<00:06, 545.61it/s]
Adding requests:  12%|        | 483/4096 [00:00<00:06, 538.44it/s]
Adding requests:  13%|        | 537/4096 [00:00<00:06, 526.91it/s]
Adding requests:  14%|        | 590/4096 [00:01<00:06, 523.65it/s]
Adding requests:  16%|        | 645/4096 [00:01<00:06, 530.36it/s]
Adding requests:  17%|        | 699/4096 [00:01<00:06, 532.72it/s]
Adding requests:  18%|        | 753/4096 [00:01<00:06, 524.85it/s]
Adding requests:  20%|        | 806/4096 [00:01<00:06, 518.61it/s]
Adding requests:  21%|        | 860/4096 [00:01<00:06, 522.95it/s]
Adding requests:  22%|       | 914/4096 [00:01<00:06, 526.52it/s]
Adding requests:  24%|       | 967/4096 [00:01<00:05, 524.44it/s]
Adding requests:  25%|       | 1020/4096 [00:01<00:05, 520.63it/s]
Adding requests:  26%|       | 1073/4096 [00:01<00:05, 520.08it/s]
Adding requests:  28%|       | 1127/4096 [00:02<00:05, 522.44it/s]
Adding requests:  29%|       | 1180/4096 [00:02<00:05, 523.52it/s]
Adding requests:  30%|       | 1235/4096 [00:02<00:05, 530.58it/s]
Adding requests:  31%|      | 1289/4096 [00:02<00:05, 503.45it/s]
Adding requests:  33%|      | 1340/4096 [00:02<00:05, 502.84it/s]
Adding requests:  34%|      | 1391/4096 [00:02<00:05, 491.27it/s]
Adding requests:  35%|      | 1441/4096 [00:02<00:05, 484.57it/s]
Adding requests:  36%|      | 1493/4096 [00:02<00:05, 494.54it/s]
Adding requests:  38%|      | 1547/4096 [00:02<00:05, 506.71it/s]
Adding requests:  39%|      | 1602/4096 [00:03<00:04, 518.91it/s]
Adding requests:  40%|      | 1655/4096 [00:03<00:04, 521.81it/s]
Adding requests:  42%|     | 1709/4096 [00:03<00:04, 526.31it/s]
Adding requests:  43%|     | 1765/4096 [00:03<00:04, 530.80it/s]
Adding requests:  44%|     | 1822/4096 [00:03<00:04, 541.78it/s]
Adding requests:  46%|     | 1877/4096 [00:03<00:04, 534.84it/s]
Adding requests:  47%|     | 1931/4096 [00:03<00:04, 531.05it/s]
Adding requests:  48%|     | 1985/4096 [00:03<00:04, 526.86it/s]
Adding requests:  50%|     | 2039/4096 [00:03<00:03, 530.66it/s]
Adding requests:  51%|     | 2093/4096 [00:03<00:03, 519.16it/s]
Adding requests:  52%|    | 2145/4096 [00:04<00:03, 512.61it/s]
Adding requests:  54%|    | 2197/4096 [00:04<00:03, 505.77it/s]
Adding requests:  55%|    | 2252/4096 [00:04<00:03, 517.64it/s]
Adding requests:  56%|    | 2305/4096 [00:04<00:03, 515.74it/s]
Adding requests:  58%|    | 2359/4096 [00:04<00:03, 518.89it/s]
Adding requests:  59%|    | 2413/4096 [00:04<00:03, 523.33it/s]
Adding requests:  60%|    | 2466/4096 [00:04<00:03, 523.59it/s]
Adding requests:  61%|   | 2519/4096 [00:04<00:03, 519.77it/s]
Adding requests:  63%|   | 2571/4096 [00:04<00:03, 487.73it/s]
Adding requests:  64%|   | 2624/4096 [00:05<00:02, 498.83it/s]
Adding requests:  65%|   | 2677/4096 [00:05<00:02, 503.91it/s]
Adding requests:  67%|   | 2728/4096 [00:05<00:02, 503.52it/s]
Adding requests:  68%|   | 2779/4096 [00:05<00:02, 504.55it/s]
Adding requests:  69%|   | 2833/4096 [00:05<00:02, 511.61it/s]
Adding requests:  70%|   | 2886/4096 [00:05<00:02, 513.70it/s]
Adding requests:  72%|  | 2938/4096 [00:05<00:02, 513.34it/s]
Adding requests:  73%|  | 2990/4096 [00:05<00:02, 509.33it/s]
Adding requests:  74%|  | 3041/4096 [00:05<00:02, 508.72it/s]
Adding requests:  75%|  | 3092/4096 [00:05<00:01, 504.58it/s]
Adding requests:  77%|  | 3143/4096 [00:06<00:01, 497.78it/s]
Adding requests:  78%|  | 3199/4096 [00:06<00:01, 514.15it/s]
Adding requests:  79%|  | 3254/4096 [00:06<00:01, 524.37it/s]
Adding requests:  81%|  | 3308/4096 [00:06<00:01, 527.99it/s]
Adding requests:  82%| | 3361/4096 [00:06<00:01, 521.22it/s]
Adding requests:  83%| | 3416/4096 [00:06<00:01, 529.47it/s]
Adding requests:  85%| | 3469/4096 [00:06<00:01, 522.34it/s]
Adding requests:  86%| | 3524/4096 [00:06<00:01, 528.79it/s]
Adding requests:  87%| | 3577/4096 [00:06<00:00, 523.19it/s]
Adding requests:  89%| | 3631/4096 [00:06<00:00, 527.84it/s]
Adding requests:  90%| | 3684/4096 [00:07<00:00, 527.52it/s]
Adding requests:  91%| | 3737/4096 [00:07<00:00, 526.45it/s]
Adding requests:  93%|| 3794/4096 [00:07<00:00, 538.61it/s]
Adding requests:  94%|| 3848/4096 [00:07<00:00, 538.42it/s]
Adding requests:  95%|| 3902/4096 [00:07<00:00, 516.73it/s]
Adding requests:  97%|| 3954/4096 [00:07<00:00, 514.19it/s]
Adding requests:  98%|| 4009/4096 [00:07<00:00, 523.75it/s]
Adding requests:  99%|| 4062/4096 [00:07<00:00, 519.23it/s]
Adding requests: 100%|| 4096/4096 [00:07<00:00, 522.50it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 194/4096 [00:00<00:04, 813.24it/s, est. speed input: 832818.07 toks/s, output: 813.26 toks/s]
Processed prompts:   7%|         | 276/4096 [00:02<00:42, 89.59it/s, est. speed input: 112933.15 toks/s, output: 110.29 toks/s] 
Processed prompts:   8%|         | 312/4096 [00:03<00:56, 66.58it/s, est. speed input: 87977.86 toks/s, output: 85.92 toks/s]  
Processed prompts:   8%|         | 333/4096 [00:04<01:16, 49.33it/s, est. speed input: 71789.37 toks/s, output: 70.11 toks/s]
Processed prompts:   9%|         | 354/4096 [00:05<01:36, 38.81it/s, est. speed input: 61657.23 toks/s, output: 60.21 toks/s]
Processed prompts:   9%|         | 386/4096 [00:07<01:45, 35.32it/s, est. speed input: 56362.17 toks/s, output: 55.04 toks/s]
Processed prompts:  10%|         | 418/4096 [00:08<01:51, 33.13it/s, est. speed input: 52591.21 toks/s, output: 51.36 toks/s]
Processed prompts:  11%|         | 450/4096 [00:09<01:54, 31.75it/s, est. speed input: 49793.70 toks/s, output: 48.63 toks/s]
Processed prompts:  12%|        | 482/4096 [00:10<01:57, 30.69it/s, est. speed input: 47532.42 toks/s, output: 46.42 toks/s]
Processed prompts:  13%|        | 514/4096 [00:11<01:59, 29.97it/s, est. speed input: 45717.45 toks/s, output: 44.65 toks/s]
Processed prompts:  13%|        | 546/4096 [00:12<02:00, 29.47it/s, est. speed input: 44223.98 toks/s, output: 43.19 toks/s]
Processed prompts:  14%|        | 578/4096 [00:13<02:00, 29.09it/s, est. speed input: 42964.20 toks/s, output: 41.96 toks/s]
Processed prompts:  15%|        | 610/4096 [00:14<02:00, 28.90it/s, est. speed input: 41919.94 toks/s, output: 40.94 toks/s]
Processed prompts:  16%|        | 642/4096 [00:16<02:00, 28.72it/s, est. speed input: 41009.00 toks/s, output: 40.05 toks/s]
Processed prompts:  16%|        | 674/4096 [00:17<01:59, 28.59it/s, est. speed input: 40213.29 toks/s, output: 39.27 toks/s]
Processed prompts:  17%|        | 706/4096 [00:18<01:58, 28.49it/s, est. speed input: 39517.37 toks/s, output: 38.59 toks/s]
Processed prompts:  18%|        | 738/4096 [00:19<01:58, 28.41it/s, est. speed input: 38896.05 toks/s, output: 37.98 toks/s]
Processed prompts:  19%|        | 770/4096 [00:20<01:57, 28.38it/s, est. speed input: 38351.46 toks/s, output: 37.45 toks/s]
Processed prompts:  20%|        | 802/4096 [00:21<01:56, 28.36it/s, est. speed input: 37864.25 toks/s, output: 36.98 toks/s]
Processed prompts:  20%|        | 834/4096 [00:22<01:55, 28.36it/s, est. speed input: 37428.24 toks/s, output: 36.55 toks/s]
Processed prompts:  21%|        | 866/4096 [00:23<01:53, 28.38it/s, est. speed input: 37036.22 toks/s, output: 36.17 toks/s]
Processed prompts:  22%|       | 898/4096 [00:25<01:52, 28.34it/s, est. speed input: 36670.52 toks/s, output: 35.81 toks/s]
Processed prompts:  23%|       | 930/4096 [00:26<01:51, 28.47it/s, est. speed input: 36364.89 toks/s, output: 35.51 toks/s]
Processed prompts:  23%|       | 962/4096 [00:27<01:49, 28.60it/s, est. speed input: 36090.50 toks/s, output: 35.24 toks/s]
Processed prompts:  24%|       | 994/4096 [00:28<01:48, 28.52it/s, est. speed input: 35809.53 toks/s, output: 34.97 toks/s]
Processed prompts:  25%|       | 1026/4096 [00:29<01:47, 28.43it/s, est. speed input: 35544.26 toks/s, output: 34.71 toks/s]
Processed prompts:  26%|       | 1058/4096 [00:30<01:46, 28.41it/s, est. speed input: 35305.07 toks/s, output: 34.48 toks/s]
Processed prompts:  27%|       | 1090/4096 [00:31<01:49, 27.49it/s, est. speed input: 34947.30 toks/s, output: 34.13 toks/s]
Processed prompts:  27%|       | 1122/4096 [00:33<01:47, 27.72it/s, est. speed input: 34741.79 toks/s, output: 33.93 toks/s]
Processed prompts:  28%|       | 1154/4096 [00:34<01:44, 28.07it/s, est. speed input: 34576.15 toks/s, output: 33.77 toks/s]
Processed prompts:  29%|       | 1186/4096 [00:35<01:43, 28.13it/s, est. speed input: 34395.83 toks/s, output: 33.59 toks/s]
Processed prompts:  30%|       | 1218/4096 [00:36<01:42, 28.18it/s, est. speed input: 34227.72 toks/s, output: 33.43 toks/s]
Processed prompts:  31%|       | 1250/4096 [00:37<01:40, 28.40it/s, est. speed input: 34091.60 toks/s, output: 33.29 toks/s]
Processed prompts:  31%|      | 1282/4096 [00:38<01:38, 28.53it/s, est. speed input: 33960.64 toks/s, output: 33.16 toks/s]
Processed prompts:  32%|      | 1314/4096 [00:39<01:37, 28.44it/s, est. speed input: 33816.58 toks/s, output: 33.02 toks/s]
Processed prompts:  33%|      | 1346/4096 [00:40<01:36, 28.41it/s, est. speed input: 33684.79 toks/s, output: 32.90 toks/s]
Processed prompts:  34%|      | 1378/4096 [00:42<01:35, 28.33it/s, est. speed input: 33553.30 toks/s, output: 32.77 toks/s]
Processed prompts:  34%|      | 1410/4096 [00:43<01:34, 28.36it/s, est. speed input: 33436.94 toks/s, output: 32.65 toks/s]
Processed prompts:  35%|      | 1442/4096 [00:44<01:33, 28.33it/s, est. speed input: 33322.28 toks/s, output: 32.54 toks/s]
Processed prompts:  36%|      | 1474/4096 [00:45<01:32, 28.30it/s, est. speed input: 33211.86 toks/s, output: 32.43 toks/s]
Processed prompts:  37%|      | 1506/4096 [00:46<01:31, 28.30it/s, est. speed input: 33109.24 toks/s, output: 32.33 toks/s]
Processed prompts:  38%|      | 1538/4096 [00:47<01:30, 28.26it/s, est. speed input: 33007.78 toks/s, output: 32.23 toks/s]
Processed prompts:  38%|      | 1570/4096 [00:48<01:28, 28.44it/s, est. speed input: 32929.86 toks/s, output: 32.16 toks/s]
Processed prompts:  39%|      | 1602/4096 [00:49<01:27, 28.38it/s, est. speed input: 32838.96 toks/s, output: 32.07 toks/s]
Processed prompts:  40%|      | 1634/4096 [00:51<01:26, 28.54it/s, est. speed input: 32768.70 toks/s, output: 32.00 toks/s]
Processed prompts:  41%|      | 1666/4096 [00:52<01:25, 28.46it/s, est. speed input: 32686.35 toks/s, output: 31.92 toks/s]
Processed prompts:  41%|     | 1698/4096 [00:53<01:24, 28.44it/s, est. speed input: 32609.63 toks/s, output: 31.85 toks/s]
Processed prompts:  42%|     | 1730/4096 [00:54<01:23, 28.37it/s, est. speed input: 32531.81 toks/s, output: 31.77 toks/s]
Processed prompts:  43%|     | 1762/4096 [00:55<01:22, 28.36it/s, est. speed input: 32460.72 toks/s, output: 31.70 toks/s]
Processed prompts:  44%|     | 1794/4096 [00:56<01:21, 28.31it/s, est. speed input: 32388.85 toks/s, output: 31.63 toks/s]
Processed prompts:  45%|     | 1826/4096 [00:57<01:20, 28.31it/s, est. speed input: 32322.33 toks/s, output: 31.56 toks/s]
Processed prompts:  45%|     | 1858/4096 [00:58<01:18, 28.48it/s, est. speed input: 32270.59 toks/s, output: 31.51 toks/s]
Processed prompts:  46%|     | 1890/4096 [01:00<01:17, 28.44it/s, est. speed input: 32209.64 toks/s, output: 31.45 toks/s]
Processed prompts:  47%|     | 1922/4096 [01:01<01:16, 28.39it/s, est. speed input: 32149.62 toks/s, output: 31.40 toks/s]
Processed prompts:  48%|     | 1954/4096 [01:02<01:15, 28.51it/s, est. speed input: 32102.26 toks/s, output: 31.35 toks/s]
Processed prompts:  48%|     | 1986/4096 [01:03<01:12, 29.09it/s, est. speed input: 32088.67 toks/s, output: 31.34 toks/s]
Processed prompts:  49%|     | 2018/4096 [01:04<01:12, 28.77it/s, est. speed input: 32029.24 toks/s, output: 31.28 toks/s]
Processed prompts:  50%|     | 2050/4096 [01:05<01:10, 28.96it/s, est. speed input: 31997.50 toks/s, output: 31.25 toks/s]
Processed prompts:  51%|     | 2082/4096 [01:06<01:09, 28.90it/s, est. speed input: 31955.10 toks/s, output: 31.21 toks/s]
Processed prompts:  52%|    | 2114/4096 [01:07<01:09, 28.71it/s, est. speed input: 31905.22 toks/s, output: 31.16 toks/s]
Processed prompts:  52%|    | 2146/4096 [01:08<01:08, 28.60it/s, est. speed input: 31857.84 toks/s, output: 31.11 toks/s]
Processed prompts:  53%|    | 2178/4096 [01:10<01:06, 28.91it/s, est. speed input: 31834.76 toks/s, output: 31.09 toks/s]
Processed prompts:  54%|    | 2210/4096 [01:11<01:04, 29.12it/s, est. speed input: 31811.87 toks/s, output: 31.07 toks/s]
Processed prompts:  55%|    | 2242/4096 [01:12<01:04, 28.83it/s, est. speed input: 31765.68 toks/s, output: 31.02 toks/s]
Processed prompts:  56%|    | 2274/4096 [01:13<01:03, 28.81it/s, est. speed input: 31730.72 toks/s, output: 30.99 toks/s]
Processed prompts:  56%|    | 2306/4096 [01:14<01:02, 28.81it/s, est. speed input: 31697.25 toks/s, output: 30.95 toks/s]
Processed prompts:  57%|    | 2338/4096 [01:15<01:01, 28.81it/s, est. speed input: 31665.29 toks/s, output: 30.92 toks/s]
Processed prompts:  58%|    | 2370/4096 [01:16<00:58, 29.38it/s, est. speed input: 31663.67 toks/s, output: 30.92 toks/s]
Processed prompts:  59%|    | 2402/4096 [01:17<00:58, 29.20it/s, est. speed input: 31632.43 toks/s, output: 30.89 toks/s]
Processed prompts:  59%|    | 2434/4096 [01:18<00:57, 29.12it/s, est. speed input: 31604.33 toks/s, output: 30.86 toks/s]
Processed prompts:  60%|    | 2466/4096 [01:19<00:56, 29.01it/s, est. speed input: 31574.18 toks/s, output: 30.83 toks/s]
Processed prompts:  61%|    | 2498/4096 [01:21<00:55, 28.98it/s, est. speed input: 31547.57 toks/s, output: 30.81 toks/s]
Processed prompts:  62%|   | 2530/4096 [01:22<00:54, 28.74it/s, est. speed input: 31510.61 toks/s, output: 30.77 toks/s]
Processed prompts:  63%|   | 2562/4096 [01:23<00:53, 28.79it/s, est. speed input: 31485.24 toks/s, output: 30.75 toks/s]
Processed prompts:  63%|   | 2594/4096 [01:24<00:52, 28.80it/s, est. speed input: 31459.13 toks/s, output: 30.72 toks/s]
Processed prompts:  64%|   | 2626/4096 [01:25<00:51, 28.66it/s, est. speed input: 31427.12 toks/s, output: 30.69 toks/s]
Processed prompts:  65%|   | 2658/4096 [01:26<00:50, 28.53it/s, est. speed input: 31393.94 toks/s, output: 30.66 toks/s]
Processed prompts:  66%|   | 2690/4096 [01:27<00:48, 28.87it/s, est. speed input: 31382.16 toks/s, output: 30.65 toks/s]
Processed prompts:  66%|   | 2722/4096 [01:28<00:47, 28.70it/s, est. speed input: 31351.65 toks/s, output: 30.62 toks/s]
Processed prompts:  67%|   | 2754/4096 [01:30<00:46, 28.71it/s, est. speed input: 31327.58 toks/s, output: 30.59 toks/s]
Processed prompts:  68%|   | 2786/4096 [01:31<00:45, 28.57it/s, est. speed input: 31297.91 toks/s, output: 30.56 toks/s]
Processed prompts:  69%|   | 2818/4096 [01:32<00:44, 28.89it/s, est. speed input: 31287.29 toks/s, output: 30.55 toks/s]
Processed prompts:  70%|   | 2850/4096 [01:33<00:43, 28.88it/s, est. speed input: 31266.34 toks/s, output: 30.53 toks/s]
Processed prompts:  70%|   | 2882/4096 [01:34<00:42, 28.73it/s, est. speed input: 31240.13 toks/s, output: 30.51 toks/s]
Processed prompts:  71%|   | 2914/4096 [01:35<00:41, 28.61it/s, est. speed input: 31214.07 toks/s, output: 30.48 toks/s]
Processed prompts:  72%|  | 2946/4096 [01:36<00:40, 28.60it/s, est. speed input: 31191.24 toks/s, output: 30.46 toks/s]
Processed prompts:  73%|  | 2978/4096 [01:37<00:39, 28.45it/s, est. speed input: 31163.22 toks/s, output: 30.43 toks/s]
Processed prompts:  73%|  | 3010/4096 [01:38<00:37, 28.81it/s, est. speed input: 31155.10 toks/s, output: 30.42 toks/s]
Processed prompts:  74%|  | 3042/4096 [01:40<00:36, 28.81it/s, est. speed input: 31136.43 toks/s, output: 30.41 toks/s]
Processed prompts:  75%|  | 3074/4096 [01:41<00:35, 28.65it/s, est. speed input: 31112.39 toks/s, output: 30.38 toks/s]
Processed prompts:  76%|  | 3106/4096 [01:42<00:33, 29.23it/s, est. speed input: 31115.29 toks/s, output: 30.39 toks/s]
Processed prompts:  77%|  | 3138/4096 [01:43<00:32, 29.35it/s, est. speed input: 31107.22 toks/s, output: 30.38 toks/s]
Processed prompts:  77%|  | 3170/4096 [01:44<00:31, 29.01it/s, est. speed input: 31083.77 toks/s, output: 30.36 toks/s]
Processed prompts:  78%|  | 3202/4096 [01:45<00:30, 29.24it/s, est. speed input: 31077.70 toks/s, output: 30.35 toks/s]
Processed prompts:  79%|  | 3234/4096 [01:46<00:29, 29.11it/s, est. speed input: 31061.46 toks/s, output: 30.33 toks/s]
Processed prompts:  80%|  | 3266/4096 [01:47<00:28, 28.86it/s, est. speed input: 31039.43 toks/s, output: 30.31 toks/s]
Processed prompts:  81%|  | 3298/4096 [01:48<00:27, 28.85it/s, est. speed input: 31023.97 toks/s, output: 30.30 toks/s]
Processed prompts:  81%| | 3330/4096 [01:49<00:26, 29.09it/s, est. speed input: 31017.59 toks/s, output: 30.29 toks/s]
Processed prompts:  82%| | 3362/4096 [01:51<00:25, 28.80it/s, est. speed input: 30994.95 toks/s, output: 30.27 toks/s]
Processed prompts:  83%| | 3394/4096 [01:52<00:24, 28.67it/s, est. speed input: 30975.68 toks/s, output: 30.25 toks/s]
Processed prompts:  84%| | 3426/4096 [01:53<00:23, 28.71it/s, est. speed input: 30961.05 toks/s, output: 30.24 toks/s]
Processed prompts:  84%| | 3458/4096 [01:54<00:22, 28.74it/s, est. speed input: 30946.77 toks/s, output: 30.22 toks/s]
Processed prompts:  85%| | 3490/4096 [01:55<00:20, 29.03it/s, est. speed input: 30942.14 toks/s, output: 30.22 toks/s]
Processed prompts:  86%| | 3522/4096 [01:56<00:19, 28.82it/s, est. speed input: 30923.69 toks/s, output: 30.20 toks/s]
Processed prompts:  87%| | 3554/4096 [01:57<00:18, 28.64it/s, est. speed input: 30904.20 toks/s, output: 30.18 toks/s]
Processed prompts:  88%| | 3586/4096 [01:58<00:17, 28.52it/s, est. speed input: 30885.43 toks/s, output: 30.16 toks/s]
Processed prompts:  88%| | 3618/4096 [02:00<00:16, 28.45it/s, est. speed input: 30867.38 toks/s, output: 30.14 toks/s]
Processed prompts:  89%| | 3650/4096 [02:01<00:15, 28.58it/s, est. speed input: 30855.45 toks/s, output: 30.13 toks/s]
Processed prompts:  90%| | 3682/4096 [02:02<00:14, 28.66it/s, est. speed input: 30843.74 toks/s, output: 30.12 toks/s]
Processed prompts:  91%| | 3714/4096 [02:03<00:13, 28.67it/s, est. speed input: 30830.33 toks/s, output: 30.11 toks/s]
Processed prompts:  91%|| 3746/4096 [02:04<00:12, 28.51it/s, est. speed input: 30811.96 toks/s, output: 30.09 toks/s]
Processed prompts:  92%|| 3778/4096 [02:05<00:11, 28.41it/s, est. speed input: 30794.45 toks/s, output: 30.07 toks/s]
Processed prompts:  93%|| 3810/4096 [02:06<00:10, 28.53it/s, est. speed input: 30782.97 toks/s, output: 30.06 toks/s]
Processed prompts:  94%|| 3842/4096 [02:07<00:08, 28.84it/s, est. speed input: 30778.97 toks/s, output: 30.06 toks/s]
Processed prompts:  95%|| 3874/4096 [02:08<00:07, 28.58it/s, est. speed input: 30760.22 toks/s, output: 30.04 toks/s]
Processed prompts:  95%|| 3906/4096 [02:10<00:06, 28.48it/s, est. speed input: 30744.35 toks/s, output: 30.02 toks/s]
Processed prompts:  96%|| 3938/4096 [02:11<00:05, 28.59it/s, est. speed input: 30734.04 toks/s, output: 30.01 toks/s]
Processed prompts:  97%|| 3970/4096 [02:12<00:04, 28.50it/s, est. speed input: 30718.97 toks/s, output: 30.00 toks/s]
Processed prompts:  98%|| 4002/4096 [02:13<00:03, 28.39it/s, est. speed input: 30702.90 toks/s, output: 29.98 toks/s]
Processed prompts:  98%|| 4034/4096 [02:14<00:02, 29.07it/s, est. speed input: 30709.32 toks/s, output: 29.99 toks/s]
Processed prompts:  99%|| 4066/4096 [02:15<00:01, 29.05it/s, est. speed input: 30700.89 toks/s, output: 29.98 toks/s]
Processed prompts: 100%|| 4096/4096 [02:15<00:00, 29.05it/s, est. speed input: 30927.35 toks/s, output: 30.20 toks/s]
Processed prompts: 100%|| 4096/4096 [02:15<00:00, 30.20it/s, est. speed input: 30927.35 toks/s, output: 30.20 toks/s]
[rank0]:[W126 03:34:08.838010447 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 03:34:10
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:34:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:34:36 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=810078) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=810078) WARNING 01-26 03:35:02 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.61 requests/s, 29324.87 total tokens/s, 28.61 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 03:34:36] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:34:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:34:36] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:34:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:34:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:34:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:34:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:34:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:34:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:34:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:34:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:34:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:34:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:34:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:34:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:34:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:34:40] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:34:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:34:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:34:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:34:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:34:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:34:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:34:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:34:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:34:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:34:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:34:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=810078) [2026-01-26 03:34:41] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=810078) [2026-01-26 03:34:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=810078) [2026-01-26 03:34:41] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=810078) [2026-01-26 03:34:41] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=810078) [2026-01-26 03:34:41] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=810078) [2026-01-26 03:34:41] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=810078) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=810078) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.63s/it]
(EngineCore_DP0 pid=810078) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.63s/it]
(EngineCore_DP0 pid=810078) 
(EngineCore_DP0 pid=810078) [2026-01-26 03:34:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=810078) [2026-01-26 03:34:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=810078) [2026-01-26 03:34:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=810078) [2026-01-26 03:34:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=810078) [2026-01-26 03:34:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=810078) [2026-01-26 03:34:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=810078) [2026-01-26 03:34:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=810078) [2026-01-26 03:34:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=810078) 2026-01-26 03:34:59,760 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=810078) 2026-01-26 03:35:00,010 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 60/8192 [00:00<00:13, 594.30it/s]
Adding requests:   1%|         | 120/8192 [00:00<00:14, 574.31it/s]
Adding requests:   2%|         | 178/8192 [00:00<00:14, 539.43it/s]
Adding requests:   3%|         | 233/8192 [00:00<00:15, 529.03it/s]
Adding requests:   4%|         | 287/8192 [00:00<00:15, 526.21it/s]
Adding requests:   4%|         | 340/8192 [00:00<00:15, 513.93it/s]
Adding requests:   5%|         | 392/8192 [00:00<00:15, 510.63it/s]
Adding requests:   5%|         | 444/8192 [00:00<00:15, 505.73it/s]
Adding requests:   6%|         | 496/8192 [00:00<00:15, 508.90it/s]
Adding requests:   7%|         | 547/8192 [00:01<00:15, 495.36it/s]
Adding requests:   7%|         | 598/8192 [00:01<00:15, 497.94it/s]
Adding requests:   8%|         | 652/8192 [00:01<00:14, 508.30it/s]
Adding requests:   9%|         | 704/8192 [00:01<00:14, 510.18it/s]
Adding requests:   9%|         | 756/8192 [00:01<00:14, 495.81it/s]
Adding requests:  10%|         | 806/8192 [00:01<00:15, 491.92it/s]
Adding requests:  10%|         | 857/8192 [00:01<00:14, 496.43it/s]
Adding requests:  11%|         | 914/8192 [00:01<00:14, 515.02it/s]
Adding requests:  12%|        | 966/8192 [00:01<00:14, 509.19it/s]
Adding requests:  12%|        | 1017/8192 [00:01<00:14, 509.38it/s]
Adding requests:  13%|        | 1070/8192 [00:02<00:13, 512.91it/s]
Adding requests:  14%|        | 1122/8192 [00:02<00:13, 510.68it/s]
Adding requests:  14%|        | 1174/8192 [00:02<00:14, 499.48it/s]
Adding requests:  15%|        | 1227/8192 [00:02<00:13, 505.16it/s]
Adding requests:  16%|        | 1278/8192 [00:02<00:13, 500.75it/s]
Adding requests:  16%|        | 1329/8192 [00:02<00:13, 499.25it/s]
Adding requests:  17%|        | 1379/8192 [00:02<00:13, 499.37it/s]
Adding requests:  17%|        | 1431/8192 [00:02<00:13, 504.90it/s]
Adding requests:  18%|        | 1486/8192 [00:02<00:12, 517.65it/s]
Adding requests:  19%|        | 1538/8192 [00:03<00:13, 510.31it/s]
Adding requests:  19%|        | 1590/8192 [00:03<00:12, 508.96it/s]
Adding requests:  20%|        | 1644/8192 [00:03<00:12, 515.85it/s]
Adding requests:  21%|        | 1696/8192 [00:03<00:12, 514.43it/s]
Adding requests:  21%|       | 1748/8192 [00:03<00:12, 511.04it/s]
Adding requests:  22%|       | 1800/8192 [00:03<00:12, 510.98it/s]
Adding requests:  23%|       | 1856/8192 [00:03<00:12, 523.53it/s]
Adding requests:  23%|       | 1909/8192 [00:03<00:13, 480.14it/s]
Adding requests:  24%|       | 1958/8192 [00:03<00:13, 478.69it/s]
Adding requests:  25%|       | 2011/8192 [00:03<00:12, 492.48it/s]
Adding requests:  25%|       | 2062/8192 [00:04<00:12, 496.69it/s]
Adding requests:  26%|       | 2113/8192 [00:04<00:12, 498.85it/s]
Adding requests:  26%|       | 2164/8192 [00:04<00:12, 495.05it/s]
Adding requests:  27%|       | 2214/8192 [00:04<00:12, 494.93it/s]
Adding requests:  28%|       | 2269/8192 [00:04<00:11, 507.48it/s]
Adding requests:  28%|       | 2320/8192 [00:04<00:11, 507.20it/s]
Adding requests:  29%|       | 2371/8192 [00:04<00:11, 507.34it/s]
Adding requests:  30%|       | 2422/8192 [00:04<00:11, 505.65it/s]
Adding requests:  30%|       | 2473/8192 [00:04<00:11, 500.27it/s]
Adding requests:  31%|       | 2524/8192 [00:04<00:11, 497.88it/s]
Adding requests:  31%|      | 2577/8192 [00:05<00:11, 504.31it/s]
Adding requests:  32%|      | 2631/8192 [00:05<00:10, 514.53it/s]
Adding requests:  33%|      | 2683/8192 [00:05<00:10, 504.34it/s]
Adding requests:  33%|      | 2734/8192 [00:05<00:10, 504.45it/s]
Adding requests:  34%|      | 2785/8192 [00:05<00:10, 505.17it/s]
Adding requests:  35%|      | 2840/8192 [00:05<00:10, 517.88it/s]
Adding requests:  35%|      | 2892/8192 [00:05<00:10, 506.09it/s]
Adding requests:  36%|      | 2943/8192 [00:05<00:10, 505.69it/s]
Adding requests:  37%|      | 2995/8192 [00:05<00:10, 508.70it/s]
Adding requests:  37%|      | 3047/8192 [00:06<00:10, 511.00it/s]
Adding requests:  38%|      | 3099/8192 [00:06<00:10, 507.03it/s]
Adding requests:  38%|      | 3150/8192 [00:06<00:09, 504.73it/s]
Adding requests:  39%|      | 3206/8192 [00:06<00:09, 518.16it/s]
Adding requests:  40%|      | 3258/8192 [00:06<00:10, 476.92it/s]
Adding requests:  40%|      | 3308/8192 [00:06<00:10, 480.51it/s]
Adding requests:  41%|      | 3359/8192 [00:06<00:09, 486.83it/s]
Adding requests:  42%|     | 3411/8192 [00:06<00:09, 492.83it/s]
Adding requests:  42%|     | 3462/8192 [00:06<00:09, 497.18it/s]
Adding requests:  43%|     | 3512/8192 [00:06<00:09, 495.01it/s]
Adding requests:  43%|     | 3562/8192 [00:07<00:09, 487.55it/s]
Adding requests:  44%|     | 3618/8192 [00:07<00:09, 507.73it/s]
Adding requests:  45%|     | 3669/8192 [00:07<00:09, 501.70it/s]
Adding requests:  45%|     | 3722/8192 [00:07<00:08, 507.70it/s]
Adding requests:  46%|     | 3779/8192 [00:07<00:08, 523.06it/s]
Adding requests:  47%|     | 3835/8192 [00:07<00:08, 533.39it/s]
Adding requests:  47%|     | 3889/8192 [00:07<00:08, 531.51it/s]
Adding requests:  48%|     | 3944/8192 [00:07<00:07, 536.63it/s]
Adding requests:  49%|     | 4001/8192 [00:07<00:07, 541.53it/s]
Adding requests:  50%|     | 4056/8192 [00:07<00:07, 534.30it/s]
Adding requests:  50%|     | 4111/8192 [00:08<00:07, 538.24it/s]
Adding requests:  51%|     | 4166/8192 [00:08<00:07, 540.34it/s]
Adding requests:  52%|    | 4226/8192 [00:08<00:07, 555.02it/s]
Adding requests:  52%|    | 4282/8192 [00:08<00:07, 534.31it/s]
Adding requests:  53%|    | 4339/8192 [00:08<00:07, 543.33it/s]
Adding requests:  54%|    | 4394/8192 [00:08<00:06, 544.39it/s]
Adding requests:  54%|    | 4453/8192 [00:08<00:06, 556.31it/s]
Adding requests:  55%|    | 4509/8192 [00:08<00:06, 536.17it/s]
Adding requests:  56%|    | 4563/8192 [00:08<00:06, 534.05it/s]
Adding requests:  56%|    | 4617/8192 [00:09<00:07, 501.33it/s]
Adding requests:  57%|    | 4672/8192 [00:09<00:06, 513.78it/s]
Adding requests:  58%|    | 4724/8192 [00:09<00:06, 514.35it/s]
Adding requests:  58%|    | 4777/8192 [00:09<00:06, 518.65it/s]
Adding requests:  59%|    | 4833/8192 [00:09<00:06, 528.89it/s]
Adding requests:  60%|    | 4887/8192 [00:09<00:06, 530.79it/s]
Adding requests:  60%|    | 4941/8192 [00:09<00:06, 529.45it/s]
Adding requests:  61%|    | 4997/8192 [00:09<00:05, 533.96it/s]
Adding requests:  62%|   | 5056/8192 [00:09<00:05, 548.92it/s]
Adding requests:  62%|   | 5112/8192 [00:09<00:05, 551.60it/s]
Adding requests:  63%|   | 5168/8192 [00:10<00:05, 544.46it/s]
Adding requests:  64%|   | 5223/8192 [00:10<00:05, 543.41it/s]
Adding requests:  64%|   | 5278/8192 [00:10<00:05, 544.01it/s]
Adding requests:  65%|   | 5333/8192 [00:10<00:05, 545.34it/s]
Adding requests:  66%|   | 5388/8192 [00:10<00:05, 542.40it/s]
Adding requests:  66%|   | 5446/8192 [00:10<00:04, 552.37it/s]
Adding requests:  67%|   | 5502/8192 [00:10<00:04, 542.35it/s]
Adding requests:  68%|   | 5557/8192 [00:10<00:04, 538.60it/s]
Adding requests:  69%|   | 5612/8192 [00:10<00:04, 540.52it/s]
Adding requests:  69%|   | 5668/8192 [00:10<00:04, 545.05it/s]
Adding requests:  70%|   | 5723/8192 [00:11<00:04, 544.59it/s]
Adding requests:  71%|   | 5780/8192 [00:11<00:04, 550.92it/s]
Adding requests:  71%|   | 5836/8192 [00:11<00:04, 542.19it/s]
Adding requests:  72%|  | 5895/8192 [00:11<00:04, 554.25it/s]
Adding requests:  73%|  | 5951/8192 [00:11<00:04, 542.54it/s]
Adding requests:  73%|  | 6006/8192 [00:11<00:04, 541.18it/s]
Adding requests:  74%|  | 6067/8192 [00:11<00:03, 559.45it/s]
Adding requests:  75%|  | 6124/8192 [00:11<00:03, 556.52it/s]
Adding requests:  75%|  | 6180/8192 [00:11<00:03, 552.91it/s]
Adding requests:  76%|  | 6239/8192 [00:12<00:03, 562.02it/s]
Adding requests:  77%|  | 6298/8192 [00:12<00:03, 568.57it/s]
Adding requests:  78%|  | 6355/8192 [00:12<00:03, 567.76it/s]
Adding requests:  78%|  | 6412/8192 [00:12<00:03, 565.86it/s]
Adding requests:  79%|  | 6473/8192 [00:12<00:02, 577.02it/s]
Adding requests:  80%|  | 6532/8192 [00:12<00:02, 579.13it/s]
Adding requests:  80%|  | 6590/8192 [00:12<00:02, 573.22it/s]
Adding requests:  81%|  | 6648/8192 [00:12<00:02, 571.91it/s]
Adding requests:  82%| | 6709/8192 [00:12<00:02, 582.51it/s]
Adding requests:  83%| | 6768/8192 [00:12<00:02, 567.57it/s]
Adding requests:  83%| | 6825/8192 [00:13<00:02, 564.43it/s]
Adding requests:  84%| | 6884/8192 [00:13<00:02, 569.58it/s]
Adding requests:  85%| | 6947/8192 [00:13<00:02, 584.77it/s]
Adding requests:  86%| | 7006/8192 [00:13<00:02, 562.85it/s]
Adding requests:  86%| | 7063/8192 [00:13<00:02, 559.68it/s]
Adding requests:  87%| | 7121/8192 [00:13<00:01, 564.28it/s]
Adding requests:  88%| | 7178/8192 [00:13<00:01, 565.19it/s]
Adding requests:  88%| | 7235/8192 [00:13<00:01, 552.21it/s]
Adding requests:  89%| | 7291/8192 [00:13<00:01, 551.34it/s]
Adding requests:  90%| | 7347/8192 [00:13<00:01, 521.92it/s]
Adding requests:  90%| | 7406/8192 [00:14<00:01, 541.04it/s]
Adding requests:  91%| | 7462/8192 [00:14<00:01, 545.35it/s]
Adding requests:  92%|| 7517/8192 [00:14<00:01, 538.79it/s]
Adding requests:  92%|| 7573/8192 [00:14<00:01, 542.84it/s]
Adding requests:  93%|| 7628/8192 [00:14<00:01, 544.31it/s]
Adding requests:  94%|| 7685/8192 [00:14<00:00, 550.65it/s]
Adding requests:  95%|| 7743/8192 [00:14<00:00, 557.99it/s]
Adding requests:  95%|| 7799/8192 [00:14<00:00, 557.93it/s]
Adding requests:  96%|| 7855/8192 [00:14<00:00, 554.91it/s]
Adding requests:  97%|| 7911/8192 [00:14<00:00, 552.24it/s]
Adding requests:  97%|| 7967/8192 [00:15<00:00, 553.36it/s]
Adding requests:  98%|| 8023/8192 [00:15<00:00, 549.97it/s]
Adding requests:  99%|| 8079/8192 [00:15<00:00, 550.77it/s]
Adding requests:  99%|| 8135/8192 [00:15<00:00, 551.71it/s]
Adding requests: 100%|| 8192/8192 [00:15<00:00, 528.55it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 386/8192 [00:00<00:10, 773.37it/s, est. speed input: 791959.24 toks/s, output: 773.38 toks/s]
Processed prompts:   6%|         | 464/8192 [00:02<00:57, 133.96it/s, est. speed input: 172840.59 toks/s, output: 168.79 toks/s]
Processed prompts:   6%|         | 514/8192 [00:05<01:46, 71.98it/s, est. speed input: 105056.35 toks/s, output: 102.59 toks/s] 
Processed prompts:   7%|         | 578/8192 [00:07<02:24, 52.66it/s, est. speed input: 81378.05 toks/s, output: 79.47 toks/s]  
Processed prompts:   8%|         | 642/8192 [00:09<02:54, 43.22it/s, est. speed input: 68932.31 toks/s, output: 67.32 toks/s]
Processed prompts:   9%|         | 706/8192 [00:11<03:17, 37.93it/s, est. speed input: 61289.56 toks/s, output: 59.85 toks/s]
Processed prompts:   9%|         | 770/8192 [00:14<03:33, 34.73it/s, est. speed input: 56127.70 toks/s, output: 54.81 toks/s]
Processed prompts:  10%|         | 834/8192 [00:16<03:45, 32.64it/s, est. speed input: 52366.92 toks/s, output: 51.14 toks/s]
Processed prompts:  11%|         | 898/8192 [00:18<03:52, 31.36it/s, est. speed input: 49573.55 toks/s, output: 48.41 toks/s]
Processed prompts:  12%|        | 962/8192 [00:20<03:57, 30.45it/s, est. speed input: 47362.28 toks/s, output: 46.25 toks/s]
Processed prompts:  13%|        | 1026/8192 [00:23<04:00, 29.80it/s, est. speed input: 45567.93 toks/s, output: 44.50 toks/s]
Processed prompts:  13%|        | 1090/8192 [00:25<04:02, 29.32it/s, est. speed input: 44075.33 toks/s, output: 43.04 toks/s]
Processed prompts:  14%|        | 1154/8192 [00:27<04:02, 29.07it/s, est. speed input: 42863.02 toks/s, output: 41.86 toks/s]
Processed prompts:  15%|        | 1218/8192 [00:29<04:01, 28.90it/s, est. speed input: 41832.43 toks/s, output: 40.85 toks/s]
Processed prompts:  16%|        | 1282/8192 [00:32<04:01, 28.65it/s, est. speed input: 40904.87 toks/s, output: 39.95 toks/s]
Processed prompts:  16%|        | 1346/8192 [00:34<03:59, 28.53it/s, est. speed input: 40115.99 toks/s, output: 39.18 toks/s]
Processed prompts:  17%|        | 1410/8192 [00:36<03:58, 28.46it/s, est. speed input: 39426.41 toks/s, output: 38.50 toks/s]
Processed prompts:  18%|        | 1474/8192 [00:38<03:56, 28.42it/s, est. speed input: 38822.46 toks/s, output: 37.91 toks/s]
Processed prompts:  19%|        | 1538/8192 [00:41<03:53, 28.44it/s, est. speed input: 38295.72 toks/s, output: 37.40 toks/s]
Processed prompts:  20%|        | 1602/8192 [00:43<03:51, 28.46it/s, est. speed input: 37823.42 toks/s, output: 36.94 toks/s]
Processed prompts:  20%|        | 1666/8192 [00:45<03:49, 28.41it/s, est. speed input: 37384.13 toks/s, output: 36.51 toks/s]
Processed prompts:  21%|        | 1730/8192 [00:47<03:47, 28.37it/s, est. speed input: 36986.43 toks/s, output: 36.12 toks/s]
Processed prompts:  22%|       | 1794/8192 [00:50<03:45, 28.35it/s, est. speed input: 36624.94 toks/s, output: 35.77 toks/s]
Processed prompts:  23%|       | 1858/8192 [00:52<03:43, 28.39it/s, est. speed input: 36304.83 toks/s, output: 35.45 toks/s]
Processed prompts:  23%|       | 1922/8192 [00:54<03:40, 28.40it/s, est. speed input: 36008.33 toks/s, output: 35.16 toks/s]
Processed prompts:  24%|       | 1986/8192 [00:56<03:36, 28.67it/s, est. speed input: 35779.54 toks/s, output: 34.94 toks/s]
Processed prompts:  25%|       | 2050/8192 [00:59<03:32, 28.88it/s, est. speed input: 35569.70 toks/s, output: 34.74 toks/s]
Processed prompts:  26%|       | 2114/8192 [01:01<03:31, 28.69it/s, est. speed input: 35323.95 toks/s, output: 34.50 toks/s]
Processed prompts:  27%|       | 2178/8192 [01:03<03:28, 28.81it/s, est. speed input: 35132.46 toks/s, output: 34.31 toks/s]
Processed prompts:  27%|       | 2242/8192 [01:05<03:27, 28.71it/s, est. speed input: 34928.31 toks/s, output: 34.11 toks/s]
Processed prompts:  28%|       | 2306/8192 [01:07<03:24, 28.76it/s, est. speed input: 34753.32 toks/s, output: 33.94 toks/s]
Processed prompts:  29%|       | 2370/8192 [01:10<03:20, 29.06it/s, est. speed input: 34622.94 toks/s, output: 33.81 toks/s]
Processed prompts:  30%|       | 2434/8192 [01:12<03:18, 29.01it/s, est. speed input: 34468.25 toks/s, output: 33.66 toks/s]
Processed prompts:  30%|       | 2498/8192 [01:14<03:17, 28.88it/s, est. speed input: 34312.36 toks/s, output: 33.51 toks/s]
Processed prompts:  31%|      | 2562/8192 [01:16<03:14, 28.89it/s, est. speed input: 34177.13 toks/s, output: 33.38 toks/s]
Processed prompts:  32%|      | 2626/8192 [01:19<03:13, 28.74it/s, est. speed input: 34031.58 toks/s, output: 33.23 toks/s]
Processed prompts:  33%|      | 2690/8192 [01:21<03:11, 28.76it/s, est. speed input: 33907.82 toks/s, output: 33.11 toks/s]
Processed prompts:  34%|      | 2754/8192 [01:23<03:09, 28.67it/s, est. speed input: 33779.44 toks/s, output: 32.99 toks/s]
Processed prompts:  34%|      | 2818/8192 [01:25<03:05, 28.91it/s, est. speed input: 33688.19 toks/s, output: 32.90 toks/s]
Processed prompts:  35%|      | 2882/8192 [01:27<03:04, 28.72it/s, est. speed input: 33567.19 toks/s, output: 32.78 toks/s]
Processed prompts:  36%|      | 2946/8192 [01:30<03:03, 28.65it/s, est. speed input: 33457.12 toks/s, output: 32.67 toks/s]
Processed prompts:  37%|      | 3010/8192 [01:32<02:59, 28.87it/s, est. speed input: 33378.54 toks/s, output: 32.60 toks/s]
Processed prompts:  38%|      | 3074/8192 [01:34<02:56, 29.07it/s, est. speed input: 33306.75 toks/s, output: 32.53 toks/s]
Processed prompts:  38%|      | 3138/8192 [01:36<02:55, 28.87it/s, est. speed input: 33208.85 toks/s, output: 32.43 toks/s]
Processed prompts:  39%|      | 3202/8192 [01:38<02:51, 29.02it/s, est. speed input: 33140.17 toks/s, output: 32.36 toks/s]
Processed prompts:  40%|      | 3266/8192 [01:41<02:50, 28.85it/s, est. speed input: 33051.45 toks/s, output: 32.28 toks/s]
Processed prompts:  41%|      | 3330/8192 [01:43<02:48, 28.88it/s, est. speed input: 32978.32 toks/s, output: 32.21 toks/s]
Processed prompts:  41%|     | 3394/8192 [01:45<02:46, 28.74it/s, est. speed input: 32896.11 toks/s, output: 32.13 toks/s]
Processed prompts:  42%|     | 3458/8192 [01:47<02:43, 28.95it/s, est. speed input: 32840.45 toks/s, output: 32.07 toks/s]
Processed prompts:  43%|     | 3522/8192 [01:50<02:42, 28.76it/s, est. speed input: 32761.94 toks/s, output: 31.99 toks/s]
Processed prompts:  44%|     | 3586/8192 [01:52<02:40, 28.62it/s, est. speed input: 32685.72 toks/s, output: 31.92 toks/s]
Processed prompts:  45%|     | 3650/8192 [01:54<02:38, 28.72it/s, est. speed input: 32626.99 toks/s, output: 31.86 toks/s]
Processed prompts:  45%|     | 3714/8192 [01:56<02:36, 28.63it/s, est. speed input: 32559.10 toks/s, output: 31.80 toks/s]
Processed prompts:  46%|     | 3778/8192 [01:59<02:34, 28.60it/s, est. speed input: 32495.83 toks/s, output: 31.73 toks/s]
Processed prompts:  47%|     | 3842/8192 [02:01<02:31, 28.72it/s, est. speed input: 32445.07 toks/s, output: 31.68 toks/s]
Processed prompts:  48%|     | 3906/8192 [02:03<02:29, 28.65it/s, est. speed input: 32385.81 toks/s, output: 31.63 toks/s]
Processed prompts:  48%|     | 3970/8192 [02:05<02:28, 28.52it/s, est. speed input: 32323.10 toks/s, output: 31.57 toks/s]
Processed prompts:  49%|     | 4034/8192 [02:07<02:24, 28.80it/s, est. speed input: 32286.61 toks/s, output: 31.53 toks/s]
Processed prompts:  50%|     | 4098/8192 [02:10<02:22, 28.64it/s, est. speed input: 32228.79 toks/s, output: 31.47 toks/s]
Processed prompts:  51%|     | 4162/8192 [02:12<02:19, 28.85it/s, est. speed input: 32193.12 toks/s, output: 31.44 toks/s]
Processed prompts:  52%|    | 4226/8192 [02:14<02:17, 28.86it/s, est. speed input: 32149.71 toks/s, output: 31.40 toks/s]
Processed prompts:  52%|    | 4290/8192 [02:16<02:15, 28.77it/s, est. speed input: 32102.34 toks/s, output: 31.35 toks/s]
Processed prompts:  53%|    | 4354/8192 [02:19<02:14, 28.63it/s, est. speed input: 32051.86 toks/s, output: 31.30 toks/s]
Processed prompts:  54%|    | 4418/8192 [02:21<02:11, 28.70it/s, est. speed input: 32012.53 toks/s, output: 31.26 toks/s]
Processed prompts:  55%|    | 4482/8192 [02:23<02:09, 28.55it/s, est. speed input: 31962.86 toks/s, output: 31.21 toks/s]
Processed prompts:  55%|    | 4546/8192 [02:25<02:06, 28.77it/s, est. speed input: 31933.69 toks/s, output: 31.19 toks/s]
Processed prompts:  56%|    | 4610/8192 [02:28<02:04, 28.70it/s, est. speed input: 31892.59 toks/s, output: 31.15 toks/s]
Processed prompts:  57%|    | 4674/8192 [02:30<02:03, 28.57it/s, est. speed input: 31848.07 toks/s, output: 31.10 toks/s]
Processed prompts:  58%|    | 4738/8192 [02:32<02:00, 28.68it/s, est. speed input: 31816.10 toks/s, output: 31.07 toks/s]
Processed prompts:  59%|    | 4802/8192 [02:34<01:58, 28.59it/s, est. speed input: 31775.76 toks/s, output: 31.03 toks/s]
Processed prompts:  59%|    | 4866/8192 [02:36<01:56, 28.55it/s, est. speed input: 31738.29 toks/s, output: 30.99 toks/s]
Processed prompts:  60%|    | 4930/8192 [02:39<01:54, 28.54it/s, est. speed input: 31702.43 toks/s, output: 30.96 toks/s]
Processed prompts:  61%|    | 4994/8192 [02:41<01:52, 28.41it/s, est. speed input: 31661.47 toks/s, output: 30.92 toks/s]
Processed prompts:  62%|   | 5058/8192 [02:43<01:49, 28.66it/s, est. speed input: 31638.51 toks/s, output: 30.90 toks/s]
Processed prompts:  63%|   | 5122/8192 [02:45<01:47, 28.54it/s, est. speed input: 31601.98 toks/s, output: 30.86 toks/s]
Processed prompts:  63%|   | 5186/8192 [02:48<01:44, 28.78it/s, est. speed input: 31581.66 toks/s, output: 30.84 toks/s]
Processed prompts:  64%|   | 5250/8192 [02:50<01:41, 28.97it/s, est. speed input: 31563.09 toks/s, output: 30.82 toks/s]
Processed prompts:  65%|   | 5314/8192 [02:52<01:38, 29.10it/s, est. speed input: 31544.71 toks/s, output: 30.81 toks/s]
Processed prompts:  66%|   | 5378/8192 [02:54<01:37, 28.93it/s, est. speed input: 31514.96 toks/s, output: 30.78 toks/s]
Processed prompts:  66%|   | 5442/8192 [02:56<01:35, 28.91it/s, est. speed input: 31490.40 toks/s, output: 30.75 toks/s]
Processed prompts:  67%|   | 5506/8192 [02:59<01:33, 28.76it/s, est. speed input: 31460.31 toks/s, output: 30.72 toks/s]
Processed prompts:  68%|   | 5570/8192 [03:01<01:31, 28.64it/s, est. speed input: 31430.31 toks/s, output: 30.69 toks/s]
Processed prompts:  69%|   | 5634/8192 [03:03<01:29, 28.70it/s, est. speed input: 31407.29 toks/s, output: 30.67 toks/s]
Processed prompts:  70%|   | 5698/8192 [03:05<01:26, 28.77it/s, est. speed input: 31386.38 toks/s, output: 30.65 toks/s]
Processed prompts:  70%|   | 5762/8192 [03:08<01:24, 28.65it/s, est. speed input: 31358.17 toks/s, output: 30.62 toks/s]
Processed prompts:  71%|   | 5826/8192 [03:10<01:22, 28.64it/s, est. speed input: 31333.99 toks/s, output: 30.60 toks/s]
Processed prompts:  72%|  | 5890/8192 [03:12<01:20, 28.46it/s, est. speed input: 31303.23 toks/s, output: 30.57 toks/s]
Processed prompts:  73%|  | 5954/8192 [03:14<01:18, 28.41it/s, est. speed input: 31276.05 toks/s, output: 30.54 toks/s]
Processed prompts:  73%|  | 6018/8192 [03:17<01:16, 28.43it/s, est. speed input: 31251.80 toks/s, output: 30.52 toks/s]
Processed prompts:  74%|  | 6082/8192 [03:19<01:14, 28.37it/s, est. speed input: 31225.38 toks/s, output: 30.49 toks/s]
Processed prompts:  75%|  | 6146/8192 [03:21<01:11, 28.64it/s, est. speed input: 31212.10 toks/s, output: 30.48 toks/s]
Processed prompts:  76%|  | 6210/8192 [03:23<01:09, 28.59it/s, est. speed input: 31189.21 toks/s, output: 30.46 toks/s]
Processed prompts:  77%|  | 6274/8192 [03:26<01:07, 28.47it/s, est. speed input: 31163.72 toks/s, output: 30.43 toks/s]
Processed prompts:  77%|  | 6338/8192 [03:28<01:04, 28.61it/s, est. speed input: 31147.37 toks/s, output: 30.42 toks/s]
Processed prompts:  78%|  | 6402/8192 [03:30<01:02, 28.59it/s, est. speed input: 31126.98 toks/s, output: 30.40 toks/s]
Processed prompts:  79%|  | 6466/8192 [03:32<01:00, 28.49it/s, est. speed input: 31103.90 toks/s, output: 30.37 toks/s]
Processed prompts:  80%|  | 6530/8192 [03:35<00:58, 28.61it/s, est. speed input: 31088.11 toks/s, output: 30.36 toks/s]
Processed prompts:  80%|  | 6594/8192 [03:37<00:55, 28.60it/s, est. speed input: 31069.28 toks/s, output: 30.34 toks/s]
Processed prompts:  81%| | 6658/8192 [03:39<00:53, 28.67it/s, est. speed input: 31053.66 toks/s, output: 30.33 toks/s]
Processed prompts:  82%| | 6722/8192 [03:41<00:51, 28.56it/s, est. speed input: 31032.56 toks/s, output: 30.31 toks/s]
Processed prompts:  83%| | 6786/8192 [03:44<00:49, 28.53it/s, est. speed input: 31013.62 toks/s, output: 30.29 toks/s]
Processed prompts:  84%| | 6850/8192 [03:46<00:47, 28.40it/s, est. speed input: 30991.11 toks/s, output: 30.26 toks/s]
Processed prompts:  84%| | 6914/8192 [03:48<00:44, 28.41it/s, est. speed input: 30972.75 toks/s, output: 30.25 toks/s]
Processed prompts:  85%| | 6978/8192 [03:50<00:42, 28.56it/s, est. speed input: 30959.54 toks/s, output: 30.23 toks/s]
Processed prompts:  86%| | 7042/8192 [03:53<00:40, 28.52it/s, est. speed input: 30941.77 toks/s, output: 30.22 toks/s]
Processed prompts:  87%| | 7106/8192 [03:55<00:37, 28.91it/s, est. speed input: 30938.29 toks/s, output: 30.21 toks/s]
Processed prompts:  88%| | 7170/8192 [03:57<00:35, 28.78it/s, est. speed input: 30921.75 toks/s, output: 30.20 toks/s]
Processed prompts:  88%| | 7234/8192 [03:59<00:33, 28.83it/s, est. speed input: 30909.71 toks/s, output: 30.19 toks/s]
Processed prompts:  89%| | 7298/8192 [04:01<00:31, 28.70it/s, est. speed input: 30892.86 toks/s, output: 30.17 toks/s]
Processed prompts:  90%| | 7362/8192 [04:04<00:28, 28.78it/s, est. speed input: 30881.66 toks/s, output: 30.16 toks/s]
Processed prompts:  91%| | 7426/8192 [04:06<00:26, 28.71it/s, est. speed input: 30866.83 toks/s, output: 30.14 toks/s]
Processed prompts:  91%|| 7490/8192 [04:08<00:24, 28.91it/s, est. speed input: 30860.07 toks/s, output: 30.14 toks/s]
Processed prompts:  92%|| 7554/8192 [04:10<00:21, 29.07it/s, est. speed input: 30853.88 toks/s, output: 30.13 toks/s]
Processed prompts:  93%|| 7618/8192 [04:12<00:19, 29.30it/s, est. speed input: 30851.57 toks/s, output: 30.13 toks/s]
Processed prompts:  94%|| 7682/8192 [04:15<00:17, 29.07it/s, est. speed input: 30837.26 toks/s, output: 30.11 toks/s]
Processed prompts:  95%|| 7746/8192 [04:17<00:15, 28.81it/s, est. speed input: 30820.11 toks/s, output: 30.10 toks/s]
Processed prompts:  95%|| 7810/8192 [04:19<00:13, 28.60it/s, est. speed input: 30802.40 toks/s, output: 30.08 toks/s]
Processed prompts:  96%|| 7874/8192 [04:21<00:11, 28.48it/s, est. speed input: 30785.91 toks/s, output: 30.06 toks/s]
Processed prompts:  97%|| 7938/8192 [04:24<00:08, 28.46it/s, est. speed input: 30771.46 toks/s, output: 30.05 toks/s]
Processed prompts:  98%|| 8002/8192 [04:26<00:06, 28.44it/s, est. speed input: 30757.21 toks/s, output: 30.04 toks/s]
Processed prompts:  98%|| 8066/8192 [04:28<00:04, 28.58it/s, est. speed input: 30747.67 toks/s, output: 30.03 toks/s]
Processed prompts:  99%|| 8130/8192 [04:30<00:02, 28.69it/s, est. speed input: 30738.75 toks/s, output: 30.02 toks/s]
Processed prompts: 100%|| 8192/8192 [04:30<00:00, 28.69it/s, est. speed input: 30973.11 toks/s, output: 30.25 toks/s]
Processed prompts: 100%|| 8192/8192 [04:30<00:00, 30.25it/s, est. speed input: 30973.11 toks/s, output: 30.25 toks/s]
[rank0]:[W126 03:39:49.571849461 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 07:19:54
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:19:58 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:19:58 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1010512) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1010512) WARNING 01-26 07:20:20 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 50.36 requests/s, 25836.69 total tokens/s, 50.36 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 07:19:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:19:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:19:58] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:19:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:19:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:19:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:19:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:19:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:19:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:19:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:19:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:19:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:19:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:19:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:20:02] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:20:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:20:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:20:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:20:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:20:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:20:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:20:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:20:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:20:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:20:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:20:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:20:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:20:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1010512) [2026-01-26 07:20:03] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1010512) [2026-01-26 07:20:03] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1010512) [2026-01-26 07:20:03] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1010512) [2026-01-26 07:20:03] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1010512) [2026-01-26 07:20:03] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1010512) [2026-01-26 07:20:03] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1010512) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1010512) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.90s/it]
(EngineCore_DP0 pid=1010512) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.90s/it]
(EngineCore_DP0 pid=1010512) 
(EngineCore_DP0 pid=1010512) [2026-01-26 07:20:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1010512) [2026-01-26 07:20:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=1010512) [2026-01-26 07:20:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1010512) [2026-01-26 07:20:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=1010512) [2026-01-26 07:20:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1010512) [2026-01-26 07:20:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=1010512) [2026-01-26 07:20:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1010512) [2026-01-26 07:20:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=1010512) 2026-01-26 07:20:19,791 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1010512) 2026-01-26 07:20:19,798 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  65%|   | 83/128 [00:00<00:00, 824.26it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 909.88it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|         | 9/128 [00:00<00:01, 77.07it/s, est. speed input: 39464.36 toks/s, output: 77.07 toks/s]
Processed prompts:  13%|        | 17/128 [00:00<00:01, 60.97it/s, est. speed input: 32287.99 toks/s, output: 63.06 toks/s]
Processed prompts:  19%|        | 24/128 [00:00<00:01, 57.11it/s, est. speed input: 30475.37 toks/s, output: 59.52 toks/s]
Processed prompts:  23%|       | 30/128 [00:00<00:01, 55.47it/s, est. speed input: 29677.14 toks/s, output: 57.96 toks/s]
Processed prompts:  28%|       | 36/128 [00:00<00:01, 54.56it/s, est. speed input: 29197.25 toks/s, output: 57.02 toks/s]
Processed prompts:  33%|      | 42/128 [00:00<00:01, 53.81it/s, est. speed input: 28821.42 toks/s, output: 56.29 toks/s]
Processed prompts:  38%|      | 48/128 [00:00<00:01, 52.68it/s, est. speed input: 28402.16 toks/s, output: 55.47 toks/s]
Processed prompts:  42%|     | 54/128 [00:00<00:01, 52.48it/s, est. speed input: 28194.53 toks/s, output: 55.07 toks/s]
Processed prompts:  47%|     | 60/128 [00:01<00:01, 52.57it/s, est. speed input: 28072.29 toks/s, output: 54.83 toks/s]
Processed prompts:  52%|    | 66/128 [00:01<00:01, 52.57it/s, est. speed input: 27963.93 toks/s, output: 54.62 toks/s]
Processed prompts:  56%|    | 72/128 [00:01<00:01, 52.31it/s, est. speed input: 27834.01 toks/s, output: 54.36 toks/s]
Processed prompts:  61%|    | 78/128 [00:01<00:00, 52.43it/s, est. speed input: 27767.11 toks/s, output: 54.23 toks/s]
Processed prompts:  66%|   | 84/128 [00:01<00:00, 52.15it/s, est. speed input: 27662.81 toks/s, output: 54.03 toks/s]
Processed prompts:  70%|   | 90/128 [00:01<00:00, 52.47it/s, est. speed input: 27634.70 toks/s, output: 53.97 toks/s]
Processed prompts:  75%|  | 96/128 [00:01<00:00, 52.13it/s, est. speed input: 27547.38 toks/s, output: 53.80 toks/s]
Processed prompts:  80%|  | 102/128 [00:01<00:00, 51.58it/s, est. speed input: 27436.54 toks/s, output: 53.59 toks/s]
Processed prompts:  84%| | 108/128 [00:02<00:00, 51.77it/s, est. speed input: 27396.29 toks/s, output: 53.51 toks/s]
Processed prompts:  89%| | 114/128 [00:02<00:00, 51.82it/s, est. speed input: 27353.13 toks/s, output: 53.42 toks/s]
Processed prompts:  94%|| 120/128 [00:02<00:00, 52.21it/s, est. speed input: 27346.05 toks/s, output: 53.41 toks/s]
Processed prompts:  98%|| 126/128 [00:02<00:00, 52.09it/s, est. speed input: 27305.44 toks/s, output: 53.33 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 52.09it/s, est. speed input: 27310.29 toks/s, output: 53.34 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 53.34it/s, est. speed input: 27310.29 toks/s, output: 53.34 toks/s]
[rank0]:[W126 07:20:23.256174341 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 07:20:25
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:20:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:20:29 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1011120) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1011120) WARNING 01-26 07:20:50 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 27.59 requests/s, 28278.02 total tokens/s, 27.59 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 07:20:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:20:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:20:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:20:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:20:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:20:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:20:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:20:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:20:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:20:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:20:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:20:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:20:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:20:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:20:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:20:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:20:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:20:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:20:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:20:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:20:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:20:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:20:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:20:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:20:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:20:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:20:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:20:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1011120) [2026-01-26 07:20:33] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1011120) [2026-01-26 07:20:33] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1011120) [2026-01-26 07:20:33] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1011120) [2026-01-26 07:20:33] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1011120) [2026-01-26 07:20:33] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1011120) [2026-01-26 07:20:33] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1011120) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1011120) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.88s/it]
(EngineCore_DP0 pid=1011120) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.88s/it]
(EngineCore_DP0 pid=1011120) 
(EngineCore_DP0 pid=1011120) [2026-01-26 07:20:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1011120) [2026-01-26 07:20:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=1011120) [2026-01-26 07:20:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1011120) [2026-01-26 07:20:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=1011120) [2026-01-26 07:20:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1011120) [2026-01-26 07:20:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=1011120) [2026-01-26 07:20:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1011120) [2026-01-26 07:20:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=1011120) 2026-01-26 07:20:50,132 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1011120) 2026-01-26 07:20:50,139 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  52%|    | 67/128 [00:00<00:00, 659.36it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 627.83it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:02, 58.46it/s, est. speed input: 59872.69 toks/s, output: 58.47 toks/s]
Processed prompts:  10%|         | 13/128 [00:00<00:03, 36.69it/s, est. speed input: 39974.67 toks/s, output: 39.04 toks/s]
Processed prompts:  14%|        | 18/128 [00:00<00:03, 32.80it/s, est. speed input: 36137.43 toks/s, output: 35.29 toks/s]
Processed prompts:  17%|        | 22/128 [00:00<00:03, 30.87it/s, est. speed input: 34312.97 toks/s, output: 33.51 toks/s]
Processed prompts:  20%|        | 26/128 [00:00<00:03, 29.85it/s, est. speed input: 33258.07 toks/s, output: 32.48 toks/s]
Processed prompts:  23%|       | 30/128 [00:00<00:03, 29.53it/s, est. speed input: 32709.36 toks/s, output: 31.94 toks/s]
Processed prompts:  26%|       | 33/128 [00:01<00:03, 29.21it/s, est. speed input: 32326.79 toks/s, output: 31.57 toks/s]
Processed prompts:  28%|       | 36/128 [00:01<00:03, 28.86it/s, est. speed input: 31977.57 toks/s, output: 31.23 toks/s]
Processed prompts:  30%|       | 39/128 [00:01<00:03, 28.72it/s, est. speed input: 31729.39 toks/s, output: 30.99 toks/s]
Processed prompts:  33%|      | 42/128 [00:01<00:03, 28.39it/s, est. speed input: 31452.42 toks/s, output: 30.71 toks/s]
Processed prompts:  35%|      | 45/128 [00:01<00:02, 28.40it/s, est. speed input: 31284.00 toks/s, output: 30.55 toks/s]
Processed prompts:  38%|      | 48/128 [00:01<00:02, 27.99it/s, est. speed input: 31031.36 toks/s, output: 30.30 toks/s]
Processed prompts:  40%|      | 51/128 [00:01<00:02, 28.05it/s, est. speed input: 30894.52 toks/s, output: 30.17 toks/s]
Processed prompts:  42%|     | 54/128 [00:01<00:02, 28.12it/s, est. speed input: 30782.22 toks/s, output: 30.06 toks/s]
Processed prompts:  45%|     | 57/128 [00:01<00:02, 28.20it/s, est. speed input: 30686.26 toks/s, output: 29.97 toks/s]
Processed prompts:  47%|     | 60/128 [00:02<00:02, 28.23it/s, est. speed input: 30596.55 toks/s, output: 29.88 toks/s]
Processed prompts:  49%|     | 63/128 [00:02<00:02, 28.16it/s, est. speed input: 30498.81 toks/s, output: 29.78 toks/s]
Processed prompts:  52%|    | 66/128 [00:02<00:02, 27.90it/s, est. speed input: 30374.14 toks/s, output: 29.66 toks/s]
Processed prompts:  54%|    | 69/128 [00:02<00:02, 27.99it/s, est. speed input: 30305.28 toks/s, output: 29.59 toks/s]
Processed prompts:  56%|    | 72/128 [00:02<00:01, 28.05it/s, est. speed input: 30243.52 toks/s, output: 29.53 toks/s]
Processed prompts:  59%|    | 75/128 [00:02<00:01, 28.07it/s, est. speed input: 30182.48 toks/s, output: 29.47 toks/s]
Processed prompts:  61%|    | 78/128 [00:02<00:01, 27.62it/s, est. speed input: 30057.81 toks/s, output: 29.35 toks/s]
Processed prompts:  63%|   | 81/128 [00:02<00:01, 27.72it/s, est. speed input: 30003.01 toks/s, output: 29.30 toks/s]
Processed prompts:  66%|   | 84/128 [00:02<00:01, 27.78it/s, est. speed input: 29950.17 toks/s, output: 29.25 toks/s]
Processed prompts:  68%|   | 87/128 [00:02<00:01, 27.85it/s, est. speed input: 29905.02 toks/s, output: 29.20 toks/s]
Processed prompts:  70%|   | 90/128 [00:03<00:01, 28.01it/s, est. speed input: 29875.96 toks/s, output: 29.18 toks/s]
Processed prompts:  73%|  | 93/128 [00:03<00:01, 28.11it/s, est. speed input: 29847.63 toks/s, output: 29.15 toks/s]
Processed prompts:  75%|  | 96/128 [00:03<00:01, 28.22it/s, est. speed input: 29826.08 toks/s, output: 29.13 toks/s]
Processed prompts:  77%|  | 99/128 [00:03<00:01, 28.17it/s, est. speed input: 29791.27 toks/s, output: 29.09 toks/s]
Processed prompts:  80%|  | 102/128 [00:03<00:00, 28.27it/s, est. speed input: 29773.01 toks/s, output: 29.08 toks/s]
Processed prompts:  82%| | 105/128 [00:03<00:00, 28.42it/s, est. speed input: 29764.82 toks/s, output: 29.07 toks/s]
Processed prompts:  84%| | 108/128 [00:03<00:00, 27.97it/s, est. speed input: 29700.76 toks/s, output: 29.00 toks/s]
Processed prompts:  87%| | 111/128 [00:03<00:00, 27.99it/s, est. speed input: 29673.01 toks/s, output: 28.98 toks/s]
Processed prompts:  89%| | 114/128 [00:03<00:00, 28.05it/s, est. speed input: 29651.59 toks/s, output: 28.96 toks/s]
Processed prompts:  91%|| 117/128 [00:04<00:00, 28.12it/s, est. speed input: 29633.20 toks/s, output: 28.94 toks/s]
Processed prompts:  94%|| 120/128 [00:04<00:00, 28.16it/s, est. speed input: 29614.89 toks/s, output: 28.92 toks/s]
Processed prompts:  96%|| 123/128 [00:04<00:00, 28.19it/s, est. speed input: 29598.19 toks/s, output: 28.90 toks/s]
Processed prompts:  98%|| 126/128 [00:04<00:00, 28.08it/s, est. speed input: 29570.90 toks/s, output: 28.88 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 28.08it/s, est. speed input: 29555.85 toks/s, output: 28.86 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 28.86it/s, est. speed input: 29555.85 toks/s, output: 28.86 toks/s]
[rank0]:[W126 07:20:55.708298576 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 07:20:57
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:21:01 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:21:01 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1011763) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1011763) WARNING 01-26 07:21:23 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 29.26 requests/s, 29993.20 total tokens/s, 29.26 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 07:21:01] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:21:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:21:01] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:21:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:21:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:21:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:21:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:21:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:21:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:21:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:21:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:21:05] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:21:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:21:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:21:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:21:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:21:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:21:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1011763) [2026-01-26 07:21:06] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1011763) [2026-01-26 07:21:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1011763) [2026-01-26 07:21:06] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1011763) [2026-01-26 07:21:06] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1011763) [2026-01-26 07:21:06] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1011763) [2026-01-26 07:21:06] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1011763) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1011763) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.92s/it]
(EngineCore_DP0 pid=1011763) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.92s/it]
(EngineCore_DP0 pid=1011763) 
(EngineCore_DP0 pid=1011763) [2026-01-26 07:21:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1011763) [2026-01-26 07:21:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=1011763) [2026-01-26 07:21:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1011763) [2026-01-26 07:21:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=1011763) [2026-01-26 07:21:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1011763) [2026-01-26 07:21:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=1011763) [2026-01-26 07:21:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1011763) [2026-01-26 07:21:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=1011763) 2026-01-26 07:21:22,958 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1011763) 2026-01-26 07:21:22,964 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  26%|       | 66/256 [00:00<00:00, 658.16it/s]
Adding requests:  52%|    | 132/256 [00:00<00:00, 635.03it/s]
Adding requests:  77%|  | 196/256 [00:00<00:00, 592.60it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 586.33it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 598.27it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 12/256 [00:00<00:02, 82.57it/s, est. speed input: 84566.16 toks/s, output: 82.58 toks/s]
Processed prompts:   8%|         | 21/256 [00:00<00:04, 47.09it/s, est. speed input: 52059.46 toks/s, output: 50.84 toks/s]
Processed prompts:  11%|         | 27/256 [00:00<00:05, 39.59it/s, est. speed input: 45058.84 toks/s, output: 44.00 toks/s]
Processed prompts:  12%|        | 32/256 [00:00<00:06, 34.08it/s, est. speed input: 40342.05 toks/s, output: 39.40 toks/s]
Processed prompts:  14%|        | 36/256 [00:00<00:06, 32.53it/s, est. speed input: 38696.09 toks/s, output: 37.79 toks/s]
Processed prompts:  16%|        | 40/256 [00:01<00:06, 31.72it/s, est. speed input: 37656.27 toks/s, output: 36.77 toks/s]
Processed prompts:  17%|        | 44/256 [00:01<00:06, 31.12it/s, est. speed input: 36845.09 toks/s, output: 35.98 toks/s]
Processed prompts:  19%|        | 48/256 [00:01<00:06, 30.99it/s, est. speed input: 36318.15 toks/s, output: 35.47 toks/s]
Processed prompts:  20%|        | 52/256 [00:01<00:06, 30.60it/s, est. speed input: 35779.13 toks/s, output: 34.94 toks/s]
Processed prompts:  22%|       | 56/256 [00:01<00:06, 30.42it/s, est. speed input: 35360.82 toks/s, output: 34.53 toks/s]
Processed prompts:  23%|       | 60/256 [00:01<00:06, 30.17it/s, est. speed input: 34970.09 toks/s, output: 34.15 toks/s]
Processed prompts:  25%|       | 64/256 [00:01<00:06, 30.19it/s, est. speed input: 34690.67 toks/s, output: 33.88 toks/s]
Processed prompts:  27%|       | 68/256 [00:02<00:06, 29.58it/s, est. speed input: 34286.47 toks/s, output: 33.48 toks/s]
Processed prompts:  28%|       | 72/256 [00:02<00:06, 29.71it/s, est. speed input: 34069.26 toks/s, output: 33.27 toks/s]
Processed prompts:  30%|       | 76/256 [00:02<00:06, 29.85it/s, est. speed input: 33886.46 toks/s, output: 33.09 toks/s]
Processed prompts:  31%|      | 80/256 [00:02<00:05, 29.80it/s, est. speed input: 33693.80 toks/s, output: 32.90 toks/s]
Processed prompts:  33%|      | 84/256 [00:02<00:05, 29.76it/s, est. speed input: 33518.01 toks/s, output: 32.73 toks/s]
Processed prompts:  34%|      | 88/256 [00:02<00:05, 29.81it/s, est. speed input: 33375.67 toks/s, output: 32.59 toks/s]
Processed prompts:  36%|      | 92/256 [00:02<00:05, 29.95it/s, est. speed input: 33266.17 toks/s, output: 32.49 toks/s]
Processed prompts:  38%|      | 96/256 [00:02<00:05, 29.97it/s, est. speed input: 33152.46 toks/s, output: 32.38 toks/s]
Processed prompts:  39%|      | 100/256 [00:03<00:05, 29.72it/s, est. speed input: 33005.82 toks/s, output: 32.23 toks/s]
Processed prompts:  41%|      | 104/256 [00:03<00:05, 29.73it/s, est. speed input: 32901.23 toks/s, output: 32.13 toks/s]
Processed prompts:  42%|     | 108/256 [00:03<00:04, 29.92it/s, est. speed input: 32830.61 toks/s, output: 32.06 toks/s]
Processed prompts:  44%|     | 112/256 [00:03<00:04, 29.91it/s, est. speed input: 32745.86 toks/s, output: 31.98 toks/s]
Processed prompts:  45%|     | 116/256 [00:03<00:04, 29.95it/s, est. speed input: 32673.46 toks/s, output: 31.91 toks/s]
Processed prompts:  47%|     | 120/256 [00:03<00:04, 29.88it/s, est. speed input: 32593.64 toks/s, output: 31.83 toks/s]
Processed prompts:  48%|     | 124/256 [00:03<00:04, 29.86it/s, est. speed input: 32522.79 toks/s, output: 31.76 toks/s]
Processed prompts:  50%|     | 128/256 [00:04<00:04, 29.91it/s, est. speed input: 32464.02 toks/s, output: 31.70 toks/s]
Processed prompts:  52%|    | 132/256 [00:04<00:04, 29.55it/s, est. speed input: 32362.42 toks/s, output: 31.60 toks/s]
Processed prompts:  53%|    | 136/256 [00:04<00:04, 29.62it/s, est. speed input: 32304.92 toks/s, output: 31.55 toks/s]
Processed prompts:  55%|    | 140/256 [00:04<00:03, 29.81it/s, est. speed input: 32265.71 toks/s, output: 31.51 toks/s]
Processed prompts:  56%|    | 144/256 [00:04<00:03, 29.74it/s, est. speed input: 32207.51 toks/s, output: 31.45 toks/s]
Processed prompts:  58%|    | 148/256 [00:04<00:03, 29.78it/s, est. speed input: 32160.94 toks/s, output: 31.41 toks/s]
Processed prompts:  59%|    | 152/256 [00:04<00:03, 29.83it/s, est. speed input: 32120.59 toks/s, output: 31.37 toks/s]
Processed prompts:  61%|    | 156/256 [00:04<00:03, 29.99it/s, est. speed input: 32092.64 toks/s, output: 31.34 toks/s]
Processed prompts:  62%|   | 160/256 [00:05<00:03, 29.88it/s, est. speed input: 32046.33 toks/s, output: 31.30 toks/s]
Processed prompts:  64%|   | 164/256 [00:05<00:03, 29.56it/s, est. speed input: 31979.81 toks/s, output: 31.23 toks/s]
Processed prompts:  66%|   | 168/256 [00:05<00:02, 29.66it/s, est. speed input: 31946.37 toks/s, output: 31.20 toks/s]
Processed prompts:  67%|   | 172/256 [00:05<00:02, 29.66it/s, est. speed input: 31908.01 toks/s, output: 31.16 toks/s]
Processed prompts:  69%|   | 176/256 [00:05<00:02, 29.58it/s, est. speed input: 31864.34 toks/s, output: 31.12 toks/s]
Processed prompts:  70%|   | 180/256 [00:05<00:02, 29.69it/s, est. speed input: 31836.44 toks/s, output: 31.09 toks/s]
Processed prompts:  72%|  | 184/256 [00:05<00:02, 29.82it/s, est. speed input: 31814.55 toks/s, output: 31.07 toks/s]
Processed prompts:  73%|  | 188/256 [00:06<00:02, 29.80it/s, est. speed input: 31784.50 toks/s, output: 31.04 toks/s]
Processed prompts:  75%|  | 192/256 [00:06<00:02, 29.48it/s, est. speed input: 31732.54 toks/s, output: 30.99 toks/s]
Processed prompts:  77%|  | 196/256 [00:06<00:02, 29.52it/s, est. speed input: 31702.02 toks/s, output: 30.96 toks/s]
Processed prompts:  78%|  | 200/256 [00:06<00:01, 29.76it/s, est. speed input: 31689.36 toks/s, output: 30.95 toks/s]
Processed prompts:  80%|  | 204/256 [00:06<00:01, 29.84it/s, est. speed input: 31670.06 toks/s, output: 30.93 toks/s]
Processed prompts:  81%| | 208/256 [00:06<00:01, 30.01it/s, est. speed input: 31659.98 toks/s, output: 30.92 toks/s]
Processed prompts:  83%| | 212/256 [00:06<00:01, 29.97it/s, est. speed input: 31638.95 toks/s, output: 30.90 toks/s]
Processed prompts:  84%| | 216/256 [00:06<00:01, 29.87it/s, est. speed input: 31614.02 toks/s, output: 30.87 toks/s]
Processed prompts:  86%| | 220/256 [00:07<00:01, 29.81it/s, est. speed input: 31590.69 toks/s, output: 30.85 toks/s]
Processed prompts:  88%| | 224/256 [00:07<00:01, 29.44it/s, est. speed input: 31546.54 toks/s, output: 30.81 toks/s]
Processed prompts:  89%| | 228/256 [00:07<00:00, 29.41it/s, est. speed input: 31519.00 toks/s, output: 30.78 toks/s]
Processed prompts:  91%| | 232/256 [00:07<00:00, 29.59it/s, est. speed input: 31505.25 toks/s, output: 30.77 toks/s]
Processed prompts:  92%|| 236/256 [00:07<00:00, 29.61it/s, est. speed input: 31485.45 toks/s, output: 30.75 toks/s]
Processed prompts:  94%|| 240/256 [00:07<00:00, 29.75it/s, est. speed input: 31473.81 toks/s, output: 30.74 toks/s]
Processed prompts:  95%|| 244/256 [00:07<00:00, 29.78it/s, est. speed input: 31458.71 toks/s, output: 30.72 toks/s]
Processed prompts:  97%|| 248/256 [00:08<00:00, 29.70it/s, est. speed input: 31437.91 toks/s, output: 30.70 toks/s]
Processed prompts:  98%|| 252/256 [00:08<00:00, 29.72it/s, est. speed input: 31421.90 toks/s, output: 30.69 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 31.63it/s, est. speed input: 31508.25 toks/s, output: 30.77 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 31.63it/s, est. speed input: 31508.25 toks/s, output: 30.77 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 30.77it/s, est. speed input: 31508.25 toks/s, output: 30.77 toks/s]
[rank0]:[W126 07:21:32.671803442 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 07:21:34
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:21:39 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:21:39 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1012490) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1012490) WARNING 01-26 07:22:01 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.80 requests/s, 29522.36 total tokens/s, 28.80 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 07:21:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:21:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:21:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:21:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:21:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:21:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:21:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:21:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:21:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:21:43] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:21:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:21:43] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:21:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:21:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:21:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:21:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:21:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:21:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:21:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1012490) [2026-01-26 07:21:44] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1012490) [2026-01-26 07:21:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1012490) [2026-01-26 07:21:44] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1012490) [2026-01-26 07:21:44] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1012490) [2026-01-26 07:21:44] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1012490) [2026-01-26 07:21:44] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1012490) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1012490) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.92s/it]
(EngineCore_DP0 pid=1012490) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.92s/it]
(EngineCore_DP0 pid=1012490) 
(EngineCore_DP0 pid=1012490) [2026-01-26 07:21:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1012490) [2026-01-26 07:21:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=1012490) [2026-01-26 07:21:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1012490) [2026-01-26 07:21:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=1012490) [2026-01-26 07:21:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1012490) [2026-01-26 07:21:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=1012490) [2026-01-26 07:21:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1012490) [2026-01-26 07:21:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=1012490) 2026-01-26 07:22:00,868 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1012490) 2026-01-26 07:22:00,886 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  13%|        | 66/512 [00:00<00:00, 655.94it/s]
Adding requests:  26%|       | 132/512 [00:00<00:00, 611.53it/s]
Adding requests:  38%|      | 194/512 [00:00<00:00, 567.00it/s]
Adding requests:  49%|     | 252/512 [00:00<00:00, 561.60it/s]
Adding requests:  60%|    | 309/512 [00:00<00:00, 546.99it/s]
Adding requests:  71%|   | 364/512 [00:00<00:00, 542.10it/s]
Adding requests:  82%| | 419/512 [00:00<00:00, 536.05it/s]
Adding requests:  92%|| 473/512 [00:00<00:00, 536.68it/s]
Adding requests: 100%|| 512/512 [00:00<00:00, 547.72it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 26/512 [00:00<00:03, 134.38it/s, est. speed input: 137634.44 toks/s, output: 134.40 toks/s]
Processed prompts:   8%|         | 40/512 [00:00<00:08, 58.84it/s, est. speed input: 67665.20 toks/s, output: 66.08 toks/s]   
Processed prompts:   9%|         | 48/512 [00:00<00:10, 46.38it/s, est. speed input: 55809.99 toks/s, output: 54.50 toks/s]
Processed prompts:  11%|         | 54/512 [00:01<00:12, 36.94it/s, est. speed input: 47627.84 toks/s, output: 46.51 toks/s]
Processed prompts:  12%|        | 59/512 [00:01<00:12, 36.92it/s, est. speed input: 46596.62 toks/s, output: 45.50 toks/s]
Processed prompts:  12%|        | 63/512 [00:01<00:12, 35.10it/s, est. speed input: 44974.21 toks/s, output: 43.92 toks/s]
Processed prompts:  13%|        | 67/512 [00:01<00:13, 33.73it/s, est. speed input: 43703.80 toks/s, output: 42.68 toks/s]
Processed prompts:  14%|        | 71/512 [00:01<00:13, 32.54it/s, est. speed input: 42591.06 toks/s, output: 41.59 toks/s]
Processed prompts:  15%|        | 75/512 [00:01<00:13, 31.72it/s, est. speed input: 41682.73 toks/s, output: 40.71 toks/s]
Processed prompts:  15%|        | 79/512 [00:01<00:13, 30.96it/s, est. speed input: 40850.10 toks/s, output: 39.89 toks/s]
Processed prompts:  16%|        | 83/512 [00:02<00:14, 30.16it/s, est. speed input: 40052.22 toks/s, output: 39.11 toks/s]
Processed prompts:  17%|        | 86/512 [00:02<00:15, 27.67it/s, est. speed input: 38948.59 toks/s, output: 38.04 toks/s]
Processed prompts:  18%|        | 90/512 [00:02<00:15, 28.02it/s, est. speed input: 38407.96 toks/s, output: 37.51 toks/s]
Processed prompts:  18%|        | 94/512 [00:02<00:14, 28.25it/s, est. speed input: 37920.15 toks/s, output: 37.03 toks/s]
Processed prompts:  19%|        | 98/512 [00:02<00:14, 28.55it/s, est. speed input: 37513.91 toks/s, output: 36.63 toks/s]
Processed prompts:  20%|        | 102/512 [00:02<00:14, 28.67it/s, est. speed input: 37127.30 toks/s, output: 36.26 toks/s]
Processed prompts:  21%|        | 106/512 [00:02<00:14, 28.81it/s, est. speed input: 36789.38 toks/s, output: 35.93 toks/s]
Processed prompts:  21%|       | 110/512 [00:03<00:14, 28.65it/s, est. speed input: 36430.25 toks/s, output: 35.58 toks/s]
Processed prompts:  22%|       | 114/512 [00:03<00:13, 28.72it/s, est. speed input: 36136.95 toks/s, output: 35.29 toks/s]
Processed prompts:  23%|       | 118/512 [00:03<00:13, 28.92it/s, est. speed input: 35893.69 toks/s, output: 35.05 toks/s]
Processed prompts:  24%|       | 122/512 [00:03<00:13, 28.91it/s, est. speed input: 35643.64 toks/s, output: 34.81 toks/s]
Processed prompts:  25%|       | 126/512 [00:03<00:13, 28.96it/s, est. speed input: 35422.85 toks/s, output: 34.59 toks/s]
Processed prompts:  25%|       | 130/512 [00:03<00:13, 28.94it/s, est. speed input: 35208.89 toks/s, output: 34.38 toks/s]
Processed prompts:  26%|       | 134/512 [00:03<00:13, 29.01it/s, est. speed input: 35021.80 toks/s, output: 34.20 toks/s]
Processed prompts:  27%|       | 138/512 [00:04<00:12, 29.24it/s, est. speed input: 34872.22 toks/s, output: 34.05 toks/s]
Processed prompts:  28%|       | 142/512 [00:04<00:12, 28.91it/s, est. speed input: 34668.03 toks/s, output: 33.86 toks/s]
Processed prompts:  29%|       | 146/512 [00:04<00:12, 29.21it/s, est. speed input: 34543.84 toks/s, output: 33.73 toks/s]
Processed prompts:  29%|       | 150/512 [00:04<00:12, 29.23it/s, est. speed input: 34403.93 toks/s, output: 33.60 toks/s]
Processed prompts:  30%|       | 154/512 [00:04<00:12, 29.26it/s, est. speed input: 34274.24 toks/s, output: 33.47 toks/s]
Processed prompts:  31%|       | 158/512 [00:04<00:12, 29.15it/s, est. speed input: 34138.10 toks/s, output: 33.34 toks/s]
Processed prompts:  32%|      | 162/512 [00:04<00:12, 29.15it/s, est. speed input: 34017.18 toks/s, output: 33.22 toks/s]
Processed prompts:  32%|      | 166/512 [00:05<00:11, 29.03it/s, est. speed input: 33890.33 toks/s, output: 33.10 toks/s]
Processed prompts:  33%|      | 170/512 [00:05<00:11, 29.05it/s, est. speed input: 33780.75 toks/s, output: 32.99 toks/s]
Processed prompts:  34%|      | 174/512 [00:05<00:11, 28.70it/s, est. speed input: 33641.33 toks/s, output: 32.85 toks/s]
Processed prompts:  35%|      | 178/512 [00:05<00:11, 28.94it/s, est. speed input: 33554.88 toks/s, output: 32.77 toks/s]
Processed prompts:  36%|      | 182/512 [00:05<00:11, 28.90it/s, est. speed input: 33453.93 toks/s, output: 32.67 toks/s]
Processed prompts:  36%|      | 186/512 [00:05<00:11, 29.11it/s, est. speed input: 33380.08 toks/s, output: 32.60 toks/s]
Processed prompts:  37%|      | 190/512 [00:05<00:11, 29.04it/s, est. speed input: 33289.29 toks/s, output: 32.51 toks/s]
Processed prompts:  38%|      | 194/512 [00:05<00:10, 29.06it/s, est. speed input: 33209.34 toks/s, output: 32.43 toks/s]
Processed prompts:  39%|      | 198/512 [00:06<00:10, 29.05it/s, est. speed input: 33130.61 toks/s, output: 32.35 toks/s]
Processed prompts:  39%|      | 202/512 [00:06<00:10, 28.82it/s, est. speed input: 33037.13 toks/s, output: 32.26 toks/s]
Processed prompts:  40%|      | 206/512 [00:06<00:10, 29.01it/s, est. speed input: 32976.52 toks/s, output: 32.20 toks/s]
Processed prompts:  41%|      | 210/512 [00:06<00:10, 29.06it/s, est. speed input: 32911.61 toks/s, output: 32.14 toks/s]
Processed prompts:  42%|     | 214/512 [00:06<00:10, 29.07it/s, est. speed input: 32847.23 toks/s, output: 32.08 toks/s]
Processed prompts:  43%|     | 218/512 [00:06<00:10, 29.09it/s, est. speed input: 32786.35 toks/s, output: 32.02 toks/s]
Processed prompts:  43%|     | 222/512 [00:06<00:09, 29.11it/s, est. speed input: 32728.26 toks/s, output: 31.96 toks/s]
Processed prompts:  44%|     | 226/512 [00:07<00:09, 29.13it/s, est. speed input: 32673.39 toks/s, output: 31.91 toks/s]
Processed prompts:  45%|     | 230/512 [00:07<00:09, 29.27it/s, est. speed input: 32629.04 toks/s, output: 31.86 toks/s]
Processed prompts:  46%|     | 234/512 [00:07<00:09, 28.88it/s, est. speed input: 32552.50 toks/s, output: 31.79 toks/s]
Processed prompts:  46%|     | 238/512 [00:07<00:09, 28.94it/s, est. speed input: 32501.93 toks/s, output: 31.74 toks/s]
Processed prompts:  47%|     | 242/512 [00:07<00:09, 28.97it/s, est. speed input: 32451.71 toks/s, output: 31.69 toks/s]
Processed prompts:  48%|     | 246/512 [00:07<00:09, 28.91it/s, est. speed input: 32398.16 toks/s, output: 31.64 toks/s]
Processed prompts:  49%|     | 250/512 [00:07<00:09, 28.87it/s, est. speed input: 32347.11 toks/s, output: 31.59 toks/s]
Processed prompts:  50%|     | 254/512 [00:08<00:08, 28.94it/s, est. speed input: 32303.69 toks/s, output: 31.55 toks/s]
Processed prompts:  50%|     | 258/512 [00:08<00:08, 28.87it/s, est. speed input: 32254.07 toks/s, output: 31.50 toks/s]
Processed prompts:  51%|     | 262/512 [00:08<00:08, 28.96it/s, est. speed input: 32215.14 toks/s, output: 31.46 toks/s]
Processed prompts:  52%|    | 266/512 [00:08<00:08, 28.72it/s, est. speed input: 32158.58 toks/s, output: 31.40 toks/s]
Processed prompts:  53%|    | 270/512 [00:08<00:08, 28.75it/s, est. speed input: 32115.81 toks/s, output: 31.36 toks/s]
Processed prompts:  54%|    | 274/512 [00:08<00:08, 28.80it/s, est. speed input: 32076.27 toks/s, output: 31.32 toks/s]
Processed prompts:  54%|    | 278/512 [00:08<00:08, 28.83it/s, est. speed input: 32037.55 toks/s, output: 31.29 toks/s]
Processed prompts:  55%|    | 282/512 [00:09<00:07, 28.79it/s, est. speed input: 31996.79 toks/s, output: 31.25 toks/s]
Processed prompts:  56%|    | 286/512 [00:09<00:07, 28.81it/s, est. speed input: 31959.45 toks/s, output: 31.21 toks/s]
Processed prompts:  57%|    | 290/512 [00:09<00:07, 28.80it/s, est. speed input: 31922.58 toks/s, output: 31.17 toks/s]
Processed prompts:  57%|    | 294/512 [00:09<00:07, 28.49it/s, est. speed input: 31869.59 toks/s, output: 31.12 toks/s]
Processed prompts:  58%|    | 298/512 [00:09<00:07, 28.69it/s, est. speed input: 31840.91 toks/s, output: 31.09 toks/s]
Processed prompts:  59%|    | 302/512 [00:09<00:07, 28.89it/s, est. speed input: 31815.92 toks/s, output: 31.07 toks/s]
Processed prompts:  60%|    | 306/512 [00:09<00:07, 28.96it/s, est. speed input: 31788.59 toks/s, output: 31.04 toks/s]
Processed prompts:  61%|    | 310/512 [00:09<00:06, 28.98it/s, est. speed input: 31759.71 toks/s, output: 31.02 toks/s]
Processed prompts:  61%|   | 314/512 [00:10<00:06, 29.05it/s, est. speed input: 31735.20 toks/s, output: 30.99 toks/s]
Processed prompts:  62%|   | 318/512 [00:10<00:06, 28.97it/s, est. speed input: 31704.60 toks/s, output: 30.96 toks/s]
Processed prompts:  63%|   | 322/512 [00:10<00:06, 28.86it/s, est. speed input: 31672.31 toks/s, output: 30.93 toks/s]
Processed prompts:  64%|   | 326/512 [00:10<00:06, 28.73it/s, est. speed input: 31638.31 toks/s, output: 30.90 toks/s]
Processed prompts:  64%|   | 330/512 [00:10<00:06, 28.83it/s, est. speed input: 31613.98 toks/s, output: 30.87 toks/s]
Processed prompts:  65%|   | 334/512 [00:10<00:06, 29.02it/s, est. speed input: 31595.97 toks/s, output: 30.86 toks/s]
Processed prompts:  66%|   | 338/512 [00:10<00:05, 29.07it/s, est. speed input: 31574.46 toks/s, output: 30.83 toks/s]
Processed prompts:  67%|   | 342/512 [00:11<00:05, 30.02it/s, est. speed input: 31593.40 toks/s, output: 30.85 toks/s]
Processed prompts:  68%|   | 346/512 [00:11<00:05, 29.55it/s, est. speed input: 31563.55 toks/s, output: 30.82 toks/s]
Processed prompts:  68%|   | 350/512 [00:11<00:05, 29.41it/s, est. speed input: 31541.82 toks/s, output: 30.80 toks/s]
Processed prompts:  69%|   | 354/512 [00:11<00:05, 29.42it/s, est. speed input: 31525.64 toks/s, output: 30.79 toks/s]
Processed prompts:  70%|   | 358/512 [00:11<00:05, 28.90it/s, est. speed input: 31487.07 toks/s, output: 30.75 toks/s]
Processed prompts:  71%|   | 362/512 [00:11<00:05, 28.97it/s, est. speed input: 31467.84 toks/s, output: 30.73 toks/s]
Processed prompts:  71%|  | 366/512 [00:11<00:05, 29.12it/s, est. speed input: 31453.26 toks/s, output: 30.72 toks/s]
Processed prompts:  72%|  | 370/512 [00:12<00:04, 28.97it/s, est. speed input: 31428.55 toks/s, output: 30.69 toks/s]
Processed prompts:  73%|  | 374/512 [00:12<00:04, 28.96it/s, est. speed input: 31408.03 toks/s, output: 30.67 toks/s]
Processed prompts:  74%|  | 378/512 [00:12<00:04, 29.14it/s, est. speed input: 31395.49 toks/s, output: 30.66 toks/s]
Processed prompts:  75%|  | 382/512 [00:12<00:04, 29.14it/s, est. speed input: 31378.65 toks/s, output: 30.64 toks/s]
Processed prompts:  75%|  | 386/512 [00:12<00:04, 28.92it/s, est. speed input: 31353.26 toks/s, output: 30.62 toks/s]
Processed prompts:  76%|  | 390/512 [00:12<00:04, 28.97it/s, est. speed input: 31336.26 toks/s, output: 30.60 toks/s]
Processed prompts:  77%|  | 394/512 [00:12<00:04, 29.12it/s, est. speed input: 31324.04 toks/s, output: 30.59 toks/s]
Processed prompts:  78%|  | 398/512 [00:13<00:03, 29.11it/s, est. speed input: 31307.84 toks/s, output: 30.57 toks/s]
Processed prompts:  79%|  | 402/512 [00:13<00:03, 29.13it/s, est. speed input: 31292.76 toks/s, output: 30.56 toks/s]
Processed prompts:  79%|  | 406/512 [00:13<00:03, 29.06it/s, est. speed input: 31275.33 toks/s, output: 30.54 toks/s]
Processed prompts:  80%|  | 410/512 [00:13<00:03, 29.11it/s, est. speed input: 31261.49 toks/s, output: 30.53 toks/s]
Processed prompts:  81%|  | 414/512 [00:13<00:03, 29.17it/s, est. speed input: 31248.90 toks/s, output: 30.52 toks/s]
Processed prompts:  82%| | 418/512 [00:13<00:03, 28.81it/s, est. speed input: 31222.15 toks/s, output: 30.49 toks/s]
Processed prompts:  82%| | 422/512 [00:13<00:03, 28.97it/s, est. speed input: 31210.51 toks/s, output: 30.48 toks/s]
Processed prompts:  83%| | 426/512 [00:13<00:02, 29.07it/s, est. speed input: 31198.89 toks/s, output: 30.47 toks/s]
Processed prompts:  84%| | 430/512 [00:14<00:02, 29.00it/s, est. speed input: 31182.39 toks/s, output: 30.45 toks/s]
Processed prompts:  85%| | 434/512 [00:14<00:02, 29.00it/s, est. speed input: 31167.96 toks/s, output: 30.44 toks/s]
Processed prompts:  86%| | 438/512 [00:14<00:02, 29.23it/s, est. speed input: 31161.86 toks/s, output: 30.43 toks/s]
Processed prompts:  86%| | 442/512 [00:14<00:02, 29.27it/s, est. speed input: 31151.59 toks/s, output: 30.42 toks/s]
Processed prompts:  87%| | 446/512 [00:14<00:02, 29.11it/s, est. speed input: 31135.22 toks/s, output: 30.41 toks/s]
Processed prompts:  88%| | 450/512 [00:14<00:02, 30.16it/s, est. speed input: 31156.36 toks/s, output: 30.43 toks/s]
Processed prompts:  89%| | 454/512 [00:14<00:01, 29.89it/s, est. speed input: 31145.76 toks/s, output: 30.42 toks/s]
Processed prompts:  89%| | 458/512 [00:15<00:01, 29.62it/s, est. speed input: 31132.55 toks/s, output: 30.40 toks/s]
Processed prompts:  90%| | 462/512 [00:15<00:01, 29.36it/s, est. speed input: 31117.40 toks/s, output: 30.39 toks/s]
Processed prompts:  91%| | 466/512 [00:15<00:01, 29.16it/s, est. speed input: 31101.65 toks/s, output: 30.37 toks/s]
Processed prompts:  92%|| 470/512 [00:15<00:01, 29.25it/s, est. speed input: 31093.47 toks/s, output: 30.36 toks/s]
Processed prompts:  93%|| 474/512 [00:15<00:01, 29.32it/s, est. speed input: 31085.64 toks/s, output: 30.36 toks/s]
Processed prompts:  93%|| 478/512 [00:15<00:01, 29.15it/s, est. speed input: 31071.13 toks/s, output: 30.34 toks/s]
Processed prompts:  94%|| 482/512 [00:15<00:01, 28.73it/s, est. speed input: 31047.71 toks/s, output: 30.32 toks/s]
Processed prompts:  95%|| 486/512 [00:16<00:00, 28.87it/s, est. speed input: 31037.98 toks/s, output: 30.31 toks/s]
Processed prompts:  96%|| 490/512 [00:16<00:00, 29.00it/s, est. speed input: 31029.19 toks/s, output: 30.30 toks/s]
Processed prompts:  96%|| 494/512 [00:16<00:00, 29.05it/s, est. speed input: 31019.59 toks/s, output: 30.29 toks/s]
Processed prompts:  97%|| 498/512 [00:16<00:00, 29.03it/s, est. speed input: 31008.38 toks/s, output: 30.28 toks/s]
Processed prompts:  98%|| 502/512 [00:16<00:00, 28.89it/s, est. speed input: 30993.57 toks/s, output: 30.27 toks/s]
Processed prompts:  99%|| 506/512 [00:16<00:00, 28.90it/s, est. speed input: 30981.97 toks/s, output: 30.26 toks/s]
Processed prompts: 100%|| 510/512 [00:16<00:00, 30.37it/s, est. speed input: 31011.60 toks/s, output: 30.28 toks/s]
Processed prompts: 100%|| 512/512 [00:16<00:00, 30.37it/s, est. speed input: 31133.01 toks/s, output: 30.40 toks/s]
Processed prompts: 100%|| 512/512 [00:16<00:00, 30.40it/s, est. speed input: 31133.01 toks/s, output: 30.40 toks/s]
[rank0]:[W126 07:22:19.696461496 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 07:22:21
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:22:28 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:22:28 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1013333) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1013333) WARNING 01-26 07:22:49 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.19 requests/s, 28895.09 total tokens/s, 28.19 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 07:22:27] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:22:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:22:28] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:22:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:22:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:22:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:22:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:22:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:22:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:22:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:22:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:22:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:22:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:22:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:22:31] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:22:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:22:31] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:22:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:22:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:22:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:22:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:22:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:22:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:22:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:22:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:22:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:22:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:22:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1013333) [2026-01-26 07:22:32] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1013333) [2026-01-26 07:22:32] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1013333) [2026-01-26 07:22:32] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1013333) [2026-01-26 07:22:32] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1013333) [2026-01-26 07:22:32] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1013333) [2026-01-26 07:22:32] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1013333) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1013333) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.77s/it]
(EngineCore_DP0 pid=1013333) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.77s/it]
(EngineCore_DP0 pid=1013333) 
(EngineCore_DP0 pid=1013333) [2026-01-26 07:22:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1013333) [2026-01-26 07:22:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=1013333) [2026-01-26 07:22:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1013333) [2026-01-26 07:22:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=1013333) [2026-01-26 07:22:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1013333) [2026-01-26 07:22:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=1013333) [2026-01-26 07:22:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1013333) [2026-01-26 07:22:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=1013333) 2026-01-26 07:22:49,210 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1013333) 2026-01-26 07:22:49,260 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   6%|         | 61/1024 [00:00<00:01, 605.74it/s]
Adding requests:  12%|        | 122/1024 [00:00<00:01, 590.31it/s]
Adding requests:  18%|        | 182/1024 [00:00<00:01, 554.91it/s]
Adding requests:  23%|       | 238/1024 [00:00<00:01, 552.61it/s]
Adding requests:  29%|       | 294/1024 [00:00<00:01, 538.19it/s]
Adding requests:  34%|      | 348/1024 [00:00<00:01, 535.66it/s]
Adding requests:  39%|      | 403/1024 [00:00<00:01, 537.40it/s]
Adding requests:  45%|     | 457/1024 [00:00<00:01, 527.65it/s]
Adding requests:  50%|     | 510/1024 [00:00<00:00, 527.08it/s]
Adding requests:  55%|    | 563/1024 [00:01<00:00, 508.91it/s]
Adding requests:  60%|    | 616/1024 [00:01<00:00, 513.88it/s]
Adding requests:  65%|   | 670/1024 [00:01<00:00, 518.96it/s]
Adding requests:  71%|   | 724/1024 [00:01<00:00, 524.26it/s]
Adding requests:  76%|  | 777/1024 [00:01<00:00, 519.39it/s]
Adding requests:  81%|  | 829/1024 [00:01<00:00, 516.40it/s]
Adding requests:  86%| | 883/1024 [00:01<00:00, 521.23it/s]
Adding requests:  91%|| 936/1024 [00:01<00:00, 523.48it/s]
Adding requests:  97%|| 990/1024 [00:01<00:00, 527.75it/s]
Adding requests: 100%|| 1024/1024 [00:01<00:00, 529.73it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 50/1024 [00:00<00:04, 237.91it/s, est. speed input: 243674.75 toks/s, output: 237.93 toks/s]
Processed prompts:   7%|         | 74/1024 [00:01<00:16, 59.09it/s, est. speed input: 71383.24 toks/s, output: 69.71 toks/s]   
Processed prompts:   8%|         | 86/1024 [00:01<00:17, 54.06it/s, est. speed input: 65303.14 toks/s, output: 63.77 toks/s]
Processed prompts:   9%|         | 95/1024 [00:01<00:19, 47.67it/s, est. speed input: 59682.85 toks/s, output: 58.28 toks/s]
Processed prompts:  10%|         | 102/1024 [00:01<00:22, 41.09it/s, est. speed input: 54712.64 toks/s, output: 53.43 toks/s]
Processed prompts:  10%|         | 107/1024 [00:02<00:26, 34.19it/s, est. speed input: 50012.93 toks/s, output: 48.84 toks/s]
Processed prompts:  11%|         | 114/1024 [00:02<00:29, 31.21it/s, est. speed input: 47095.76 toks/s, output: 45.99 toks/s]
Processed prompts:  12%|        | 122/1024 [00:02<00:29, 30.28it/s, est. speed input: 45207.58 toks/s, output: 44.15 toks/s]
Processed prompts:  13%|        | 130/1024 [00:03<00:29, 29.81it/s, est. speed input: 43756.29 toks/s, output: 42.73 toks/s]
Processed prompts:  13%|        | 138/1024 [00:03<00:30, 29.36it/s, est. speed input: 42499.18 toks/s, output: 41.50 toks/s]
Processed prompts:  14%|        | 146/1024 [00:03<00:30, 28.97it/s, est. speed input: 41412.82 toks/s, output: 40.44 toks/s]
Processed prompts:  15%|        | 154/1024 [00:03<00:30, 28.82it/s, est. speed input: 40525.51 toks/s, output: 39.58 toks/s]
Processed prompts:  16%|        | 162/1024 [00:04<00:30, 28.70it/s, est. speed input: 39757.10 toks/s, output: 38.83 toks/s]
Processed prompts:  17%|        | 170/1024 [00:04<00:29, 28.60it/s, est. speed input: 39078.51 toks/s, output: 38.16 toks/s]
Processed prompts:  17%|        | 178/1024 [00:04<00:29, 28.38it/s, est. speed input: 38440.89 toks/s, output: 37.54 toks/s]
Processed prompts:  18%|        | 186/1024 [00:05<00:29, 28.40it/s, est. speed input: 37919.69 toks/s, output: 37.03 toks/s]
Processed prompts:  19%|        | 194/1024 [00:05<00:29, 28.40it/s, est. speed input: 37449.40 toks/s, output: 36.57 toks/s]
Processed prompts:  20%|        | 202/1024 [00:05<00:29, 28.25it/s, est. speed input: 36993.65 toks/s, output: 36.13 toks/s]
Processed prompts:  21%|        | 210/1024 [00:05<00:28, 28.27it/s, est. speed input: 36610.13 toks/s, output: 35.75 toks/s]
Processed prompts:  21%|       | 218/1024 [00:06<00:28, 28.34it/s, est. speed input: 36271.34 toks/s, output: 35.42 toks/s]
Processed prompts:  22%|       | 226/1024 [00:06<00:28, 28.38it/s, est. speed input: 35960.69 toks/s, output: 35.12 toks/s]
Processed prompts:  23%|       | 234/1024 [00:06<00:28, 28.17it/s, est. speed input: 35634.58 toks/s, output: 34.80 toks/s]
Processed prompts:  24%|       | 242/1024 [00:07<00:27, 28.19it/s, est. speed input: 35362.75 toks/s, output: 34.53 toks/s]
Processed prompts:  24%|       | 250/1024 [00:07<00:27, 28.19it/s, est. speed input: 35110.03 toks/s, output: 34.29 toks/s]
Processed prompts:  25%|       | 258/1024 [00:07<00:27, 28.22it/s, est. speed input: 34880.17 toks/s, output: 34.06 toks/s]
Processed prompts:  26%|       | 266/1024 [00:07<00:27, 28.06it/s, est. speed input: 34641.39 toks/s, output: 33.83 toks/s]
Processed prompts:  27%|       | 274/1024 [00:08<00:26, 28.15it/s, est. speed input: 34447.79 toks/s, output: 33.64 toks/s]
Processed prompts:  28%|       | 282/1024 [00:08<00:26, 28.21it/s, est. speed input: 34266.47 toks/s, output: 33.46 toks/s]
Processed prompts:  28%|       | 290/1024 [00:08<00:26, 28.17it/s, est. speed input: 34085.55 toks/s, output: 33.29 toks/s]
Processed prompts:  29%|       | 298/1024 [00:08<00:25, 28.19it/s, est. speed input: 33922.95 toks/s, output: 33.13 toks/s]
Processed prompts:  30%|       | 306/1024 [00:09<00:25, 28.19it/s, est. speed input: 33767.76 toks/s, output: 32.98 toks/s]
Processed prompts:  31%|       | 314/1024 [00:09<00:25, 28.19it/s, est. speed input: 33623.23 toks/s, output: 32.84 toks/s]
Processed prompts:  31%|      | 322/1024 [00:09<00:25, 28.07it/s, est. speed input: 33471.72 toks/s, output: 32.69 toks/s]
Processed prompts:  32%|      | 330/1024 [00:10<00:24, 28.21it/s, est. speed input: 33354.75 toks/s, output: 32.57 toks/s]
Processed prompts:  33%|      | 338/1024 [00:10<00:23, 28.68it/s, est. speed input: 33282.58 toks/s, output: 32.50 toks/s]
Processed prompts:  34%|      | 346/1024 [00:10<00:23, 28.65it/s, est. speed input: 33176.99 toks/s, output: 32.40 toks/s]
Processed prompts:  35%|      | 354/1024 [00:10<00:23, 28.44it/s, est. speed input: 33059.03 toks/s, output: 32.28 toks/s]
Processed prompts:  35%|      | 362/1024 [00:11<00:23, 28.46it/s, est. speed input: 32961.70 toks/s, output: 32.19 toks/s]
Processed prompts:  36%|      | 370/1024 [00:11<00:23, 28.42it/s, est. speed input: 32865.32 toks/s, output: 32.09 toks/s]
Processed prompts:  37%|      | 378/1024 [00:11<00:22, 28.41it/s, est. speed input: 32774.76 toks/s, output: 32.01 toks/s]
Processed prompts:  38%|      | 386/1024 [00:12<00:22, 28.29it/s, est. speed input: 32677.84 toks/s, output: 31.91 toks/s]
Processed prompts:  38%|      | 394/1024 [00:12<00:22, 28.25it/s, est. speed input: 32589.37 toks/s, output: 31.83 toks/s]
Processed prompts:  39%|      | 402/1024 [00:12<00:21, 28.27it/s, est. speed input: 32509.85 toks/s, output: 31.75 toks/s]
Processed prompts:  40%|      | 410/1024 [00:12<00:21, 28.20it/s, est. speed input: 32426.01 toks/s, output: 31.67 toks/s]
Processed prompts:  41%|      | 418/1024 [00:13<00:21, 28.18it/s, est. speed input: 32348.00 toks/s, output: 31.59 toks/s]
Processed prompts:  42%|     | 426/1024 [00:13<00:21, 28.21it/s, est. speed input: 32277.11 toks/s, output: 31.52 toks/s]
Processed prompts:  42%|     | 434/1024 [00:13<00:20, 28.16it/s, est. speed input: 32203.33 toks/s, output: 31.45 toks/s]
Processed prompts:  43%|     | 442/1024 [00:14<00:20, 28.07it/s, est. speed input: 32128.34 toks/s, output: 31.38 toks/s]
Processed prompts:  44%|     | 450/1024 [00:14<00:19, 28.90it/s, est. speed input: 32122.56 toks/s, output: 31.37 toks/s]
Processed prompts:  45%|     | 458/1024 [00:14<00:19, 28.73it/s, est. speed input: 32062.28 toks/s, output: 31.31 toks/s]
Processed prompts:  46%|     | 466/1024 [00:14<00:19, 28.67it/s, est. speed input: 32008.80 toks/s, output: 31.26 toks/s]
Processed prompts:  46%|     | 474/1024 [00:15<00:19, 28.48it/s, est. speed input: 31947.07 toks/s, output: 31.20 toks/s]
Processed prompts:  47%|     | 482/1024 [00:15<00:19, 28.45it/s, est. speed input: 31894.45 toks/s, output: 31.15 toks/s]
Processed prompts:  48%|     | 490/1024 [00:15<00:18, 28.38it/s, est. speed input: 31840.82 toks/s, output: 31.09 toks/s]
Processed prompts:  49%|     | 498/1024 [00:16<00:18, 28.35it/s, est. speed input: 31789.53 toks/s, output: 31.04 toks/s]
Processed prompts:  49%|     | 506/1024 [00:16<00:18, 28.20it/s, est. speed input: 31732.28 toks/s, output: 30.99 toks/s]
Processed prompts:  50%|     | 514/1024 [00:16<00:18, 28.19it/s, est. speed input: 31682.88 toks/s, output: 30.94 toks/s]
Processed prompts:  51%|     | 522/1024 [00:16<00:17, 28.23it/s, est. speed input: 31638.03 toks/s, output: 30.90 toks/s]
Processed prompts:  52%|    | 530/1024 [00:17<00:17, 28.32it/s, est. speed input: 31598.31 toks/s, output: 30.86 toks/s]
Processed prompts:  53%|    | 538/1024 [00:17<00:17, 28.20it/s, est. speed input: 31549.01 toks/s, output: 30.81 toks/s]
Processed prompts:  53%|    | 546/1024 [00:17<00:16, 28.18it/s, est. speed input: 31505.28 toks/s, output: 30.77 toks/s]
Processed prompts:  54%|    | 554/1024 [00:18<00:16, 28.19it/s, est. speed input: 31464.34 toks/s, output: 30.73 toks/s]
Processed prompts:  55%|    | 562/1024 [00:18<00:16, 28.11it/s, est. speed input: 31419.07 toks/s, output: 30.68 toks/s]
Processed prompts:  56%|    | 570/1024 [00:18<00:16, 28.19it/s, est. speed input: 31383.65 toks/s, output: 30.65 toks/s]
Processed prompts:  56%|    | 578/1024 [00:18<00:15, 28.22it/s, est. speed input: 31347.37 toks/s, output: 30.61 toks/s]
Processed prompts:  57%|    | 586/1024 [00:19<00:15, 28.34it/s, est. speed input: 31317.59 toks/s, output: 30.58 toks/s]
Processed prompts:  58%|    | 594/1024 [00:19<00:15, 28.20it/s, est. speed input: 31276.64 toks/s, output: 30.54 toks/s]
Processed prompts:  59%|    | 602/1024 [00:19<00:14, 28.19it/s, est. speed input: 31241.59 toks/s, output: 30.51 toks/s]
Processed prompts:  60%|    | 610/1024 [00:20<00:14, 28.23it/s, est. speed input: 31209.77 toks/s, output: 30.48 toks/s]
Processed prompts:  60%|    | 618/1024 [00:20<00:14, 28.23it/s, est. speed input: 31177.68 toks/s, output: 30.45 toks/s]
Processed prompts:  61%|    | 626/1024 [00:20<00:14, 28.16it/s, est. speed input: 31143.03 toks/s, output: 30.41 toks/s]
Processed prompts:  62%|   | 634/1024 [00:20<00:13, 28.29it/s, est. speed input: 31118.27 toks/s, output: 30.39 toks/s]
Processed prompts:  63%|   | 642/1024 [00:21<00:13, 28.27it/s, est. speed input: 31088.42 toks/s, output: 30.36 toks/s]
Processed prompts:  63%|   | 650/1024 [00:21<00:13, 28.30it/s, est. speed input: 31061.74 toks/s, output: 30.33 toks/s]
Processed prompts:  64%|   | 658/1024 [00:21<00:12, 28.22it/s, est. speed input: 31030.84 toks/s, output: 30.30 toks/s]
Processed prompts:  65%|   | 666/1024 [00:21<00:12, 28.26it/s, est. speed input: 31005.11 toks/s, output: 30.28 toks/s]
Processed prompts:  66%|   | 674/1024 [00:22<00:12, 28.17it/s, est. speed input: 30974.73 toks/s, output: 30.25 toks/s]
Processed prompts:  67%|   | 682/1024 [00:22<00:12, 28.06it/s, est. speed input: 30942.61 toks/s, output: 30.22 toks/s]
Processed prompts:  67%|   | 690/1024 [00:22<00:11, 28.15it/s, est. speed input: 30919.08 toks/s, output: 30.19 toks/s]
Processed prompts:  68%|   | 698/1024 [00:23<00:11, 28.21it/s, est. speed input: 30896.14 toks/s, output: 30.17 toks/s]
Processed prompts:  69%|   | 706/1024 [00:23<00:11, 28.29it/s, est. speed input: 30875.27 toks/s, output: 30.15 toks/s]
Processed prompts:  70%|   | 714/1024 [00:23<00:11, 28.16it/s, est. speed input: 30846.96 toks/s, output: 30.12 toks/s]
Processed prompts:  71%|   | 722/1024 [00:23<00:10, 28.18it/s, est. speed input: 30824.16 toks/s, output: 30.10 toks/s]
Processed prompts:  71%|  | 730/1024 [00:24<00:10, 28.22it/s, est. speed input: 30802.75 toks/s, output: 30.08 toks/s]
Processed prompts:  72%|  | 738/1024 [00:24<00:10, 28.31it/s, est. speed input: 30784.47 toks/s, output: 30.06 toks/s]
Processed prompts:  73%|  | 746/1024 [00:24<00:09, 28.15it/s, est. speed input: 30757.60 toks/s, output: 30.04 toks/s]
Processed prompts:  74%|  | 754/1024 [00:25<00:09, 28.28it/s, est. speed input: 30741.00 toks/s, output: 30.02 toks/s]
Processed prompts:  74%|  | 762/1024 [00:25<00:09, 28.27it/s, est. speed input: 30720.76 toks/s, output: 30.00 toks/s]
Processed prompts:  75%|  | 770/1024 [00:25<00:08, 28.29it/s, est. speed input: 30702.08 toks/s, output: 29.98 toks/s]
Processed prompts:  76%|  | 778/1024 [00:25<00:08, 28.12it/s, est. speed input: 30676.54 toks/s, output: 29.96 toks/s]
Processed prompts:  77%|  | 786/1024 [00:26<00:08, 28.19it/s, est. speed input: 30658.84 toks/s, output: 29.94 toks/s]
Processed prompts:  78%|  | 794/1024 [00:26<00:08, 28.24it/s, est. speed input: 30641.65 toks/s, output: 29.92 toks/s]
Processed prompts:  78%|  | 802/1024 [00:26<00:07, 28.07it/s, est. speed input: 30617.01 toks/s, output: 29.90 toks/s]
Processed prompts:  79%|  | 810/1024 [00:27<00:07, 28.18it/s, est. speed input: 30601.44 toks/s, output: 29.88 toks/s]
Processed prompts:  80%|  | 818/1024 [00:27<00:07, 28.24it/s, est. speed input: 30585.38 toks/s, output: 29.87 toks/s]
Processed prompts:  81%|  | 826/1024 [00:27<00:06, 28.32it/s, est. speed input: 30571.52 toks/s, output: 29.85 toks/s]
Processed prompts:  81%| | 834/1024 [00:27<00:06, 28.16it/s, est. speed input: 30549.61 toks/s, output: 29.83 toks/s]
Processed prompts:  82%| | 842/1024 [00:28<00:06, 28.19it/s, est. speed input: 30533.60 toks/s, output: 29.82 toks/s]
Processed prompts:  83%| | 850/1024 [00:28<00:06, 28.27it/s, est. speed input: 30519.80 toks/s, output: 29.80 toks/s]
Processed prompts:  84%| | 858/1024 [00:28<00:05, 28.34it/s, est. speed input: 30506.77 toks/s, output: 29.79 toks/s]
Processed prompts:  85%| | 866/1024 [00:29<00:05, 28.18it/s, est. speed input: 30486.73 toks/s, output: 29.77 toks/s]
Processed prompts:  85%| | 874/1024 [00:29<00:05, 28.22it/s, est. speed input: 30472.52 toks/s, output: 29.76 toks/s]
Processed prompts:  86%| | 882/1024 [00:29<00:05, 28.28it/s, est. speed input: 30459.43 toks/s, output: 29.75 toks/s]
Processed prompts:  87%| | 890/1024 [00:29<00:04, 28.20it/s, est. speed input: 30442.40 toks/s, output: 29.73 toks/s]
Processed prompts:  88%| | 898/1024 [00:30<00:04, 28.06it/s, est. speed input: 30423.16 toks/s, output: 29.71 toks/s]
Processed prompts:  88%| | 906/1024 [00:30<00:04, 28.19it/s, est. speed input: 30411.60 toks/s, output: 29.70 toks/s]
Processed prompts:  89%| | 914/1024 [00:30<00:03, 28.27it/s, est. speed input: 30400.00 toks/s, output: 29.69 toks/s]
Processed prompts:  90%| | 922/1024 [00:31<00:03, 28.09it/s, est. speed input: 30380.85 toks/s, output: 29.67 toks/s]
Processed prompts:  91%| | 930/1024 [00:31<00:03, 28.14it/s, est. speed input: 30367.88 toks/s, output: 29.66 toks/s]
Processed prompts:  92%|| 938/1024 [00:31<00:02, 29.16it/s, est. speed input: 30385.86 toks/s, output: 29.67 toks/s]
Processed prompts:  92%|| 946/1024 [00:31<00:02, 28.87it/s, est. speed input: 30372.59 toks/s, output: 29.66 toks/s]
Processed prompts:  93%|| 954/1024 [00:32<00:02, 28.59it/s, est. speed input: 30356.96 toks/s, output: 29.65 toks/s]
Processed prompts:  94%|| 962/1024 [00:32<00:02, 28.57it/s, est. speed input: 30347.08 toks/s, output: 29.64 toks/s]
Processed prompts:  95%|| 970/1024 [00:32<00:01, 28.52it/s, est. speed input: 30336.30 toks/s, output: 29.63 toks/s]
Processed prompts:  96%|| 978/1024 [00:33<00:01, 28.46it/s, est. speed input: 30324.67 toks/s, output: 29.61 toks/s]
Processed prompts:  96%|| 986/1024 [00:33<00:01, 29.19it/s, est. speed input: 30336.12 toks/s, output: 29.63 toks/s]
Processed prompts:  97%|| 994/1024 [00:33<00:01, 28.94it/s, est. speed input: 30325.39 toks/s, output: 29.61 toks/s]
Processed prompts:  98%|| 1002/1024 [00:33<00:00, 28.72it/s, est. speed input: 30313.38 toks/s, output: 29.60 toks/s]
Processed prompts:  99%|| 1010/1024 [00:34<00:00, 28.58it/s, est. speed input: 30301.96 toks/s, output: 29.59 toks/s]
Processed prompts:  99%|| 1018/1024 [00:34<00:00, 29.23it/s, est. speed input: 30311.76 toks/s, output: 29.60 toks/s]
Processed prompts: 100%|| 1024/1024 [00:34<00:00, 29.23it/s, est. speed input: 30490.31 toks/s, output: 29.78 toks/s]
Processed prompts: 100%|| 1024/1024 [00:34<00:00, 29.78it/s, est. speed input: 30490.31 toks/s, output: 29.78 toks/s]
[rank0]:[W126 07:23:26.718768274 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 07:23:28
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:23:37 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:23:37 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1014482) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1014482) WARNING 01-26 07:24:00 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.37 requests/s, 29080.68 total tokens/s, 28.37 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 07:23:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:23:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:23:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:23:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:23:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:23:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:23:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:23:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:23:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:23:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:23:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:23:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:23:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:23:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:23:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:23:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:23:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:23:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:23:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:23:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:23:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:23:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:23:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:23:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:23:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:23:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:23:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:23:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1014482) [2026-01-26 07:23:42] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1014482) [2026-01-26 07:23:42] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1014482) [2026-01-26 07:23:42] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1014482) [2026-01-26 07:23:42] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1014482) [2026-01-26 07:23:42] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1014482) [2026-01-26 07:23:42] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1014482) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1014482) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.75s/it]
(EngineCore_DP0 pid=1014482) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.75s/it]
(EngineCore_DP0 pid=1014482) 
(EngineCore_DP0 pid=1014482) [2026-01-26 07:23:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1014482) [2026-01-26 07:23:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=1014482) [2026-01-26 07:23:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1014482) [2026-01-26 07:23:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=1014482) [2026-01-26 07:23:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1014482) [2026-01-26 07:23:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=1014482) [2026-01-26 07:23:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1014482) [2026-01-26 07:23:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=1014482) 2026-01-26 07:23:59,237 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1014482) 2026-01-26 07:23:59,353 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 66/2048 [00:00<00:03, 653.88it/s]
Adding requests:   6%|         | 132/2048 [00:00<00:03, 608.31it/s]
Adding requests:   9%|         | 194/2048 [00:00<00:03, 558.70it/s]
Adding requests:  12%|        | 251/2048 [00:00<00:03, 552.50it/s]
Adding requests:  15%|        | 307/2048 [00:00<00:03, 539.80it/s]
Adding requests:  18%|        | 362/2048 [00:00<00:03, 538.53it/s]
Adding requests:  20%|        | 416/2048 [00:00<00:03, 534.66it/s]
Adding requests:  23%|       | 470/2048 [00:00<00:02, 530.80it/s]
Adding requests:  26%|       | 524/2048 [00:00<00:02, 521.14it/s]
Adding requests:  28%|       | 579/2048 [00:01<00:02, 529.20it/s]
Adding requests:  31%|       | 633/2048 [00:01<00:02, 530.63it/s]
Adding requests:  34%|      | 687/2048 [00:01<00:02, 521.20it/s]
Adding requests:  36%|      | 741/2048 [00:01<00:02, 523.04it/s]
Adding requests:  39%|      | 794/2048 [00:02<00:06, 207.37it/s]
Adding requests:  41%|      | 843/2048 [00:02<00:04, 247.06it/s]
Adding requests:  44%|     | 899/2048 [00:02<00:03, 299.77it/s]
Adding requests:  46%|     | 951/2048 [00:02<00:03, 342.02it/s]
Adding requests:  49%|     | 1006/2048 [00:02<00:02, 385.47it/s]
Adding requests:  52%|    | 1058/2048 [00:02<00:02, 416.25it/s]
Adding requests:  54%|    | 1110/2048 [00:02<00:02, 440.65it/s]
Adding requests:  57%|    | 1162/2048 [00:02<00:01, 461.40it/s]
Adding requests:  59%|    | 1216/2048 [00:02<00:01, 482.27it/s]
Adding requests:  62%|   | 1268/2048 [00:02<00:01, 490.87it/s]
Adding requests:  65%|   | 1322/2048 [00:03<00:01, 500.79it/s]
Adding requests:  67%|   | 1374/2048 [00:03<00:01, 501.45it/s]
Adding requests:  70%|   | 1427/2048 [00:03<00:01, 509.67it/s]
Adding requests:  72%|  | 1481/2048 [00:03<00:01, 516.96it/s]
Adding requests:  75%|  | 1536/2048 [00:03<00:00, 525.52it/s]
Adding requests:  78%|  | 1590/2048 [00:03<00:00, 526.73it/s]
Adding requests:  80%|  | 1644/2048 [00:03<00:00, 523.28it/s]
Adding requests:  83%| | 1697/2048 [00:03<00:00, 523.93it/s]
Adding requests:  85%| | 1750/2048 [00:03<00:00, 524.07it/s]
Adding requests:  88%| | 1803/2048 [00:03<00:00, 524.31it/s]
Adding requests:  91%| | 1856/2048 [00:04<00:00, 525.56it/s]
Adding requests:  93%|| 1909/2048 [00:04<00:00, 509.77it/s]
Adding requests:  96%|| 1961/2048 [00:04<00:00, 506.02it/s]
Adding requests:  98%|| 2014/2048 [00:04<00:00, 512.32it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 464.79it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 114/2048 [00:00<00:04, 399.90it/s, est. speed input: 409578.98 toks/s, output: 399.94 toks/s]
Processed prompts:   8%|         | 154/2048 [00:01<00:21, 90.07it/s, est. speed input: 111401.21 toks/s, output: 108.79 toks/s] 
Processed prompts:   8%|         | 173/2048 [00:01<00:27, 68.96it/s, est. speed input: 89641.82 toks/s, output: 87.54 toks/s]  
Processed prompts:   9%|         | 185/2048 [00:02<00:35, 52.19it/s, est. speed input: 74537.43 toks/s, output: 72.79 toks/s]
Processed prompts:   9%|         | 194/2048 [00:03<00:46, 40.16it/s, est. speed input: 64019.22 toks/s, output: 62.52 toks/s]
Processed prompts:  10%|         | 210/2048 [00:03<00:50, 36.30it/s, est. speed input: 58599.55 toks/s, output: 57.23 toks/s]
Processed prompts:  11%|         | 226/2048 [00:04<00:53, 33.83it/s, est. speed input: 54685.24 toks/s, output: 53.40 toks/s]
Processed prompts:  12%|        | 242/2048 [00:04<00:56, 32.09it/s, est. speed input: 51642.82 toks/s, output: 50.43 toks/s]
Processed prompts:  13%|        | 258/2048 [00:05<00:57, 30.96it/s, est. speed input: 49276.86 toks/s, output: 48.12 toks/s]
Processed prompts:  13%|        | 274/2048 [00:05<00:58, 30.10it/s, est. speed input: 47317.52 toks/s, output: 46.21 toks/s]
Processed prompts:  14%|        | 290/2048 [00:06<00:59, 29.49it/s, est. speed input: 45690.64 toks/s, output: 44.62 toks/s]
Processed prompts:  15%|        | 306/2048 [00:07<00:59, 29.17it/s, est. speed input: 44368.37 toks/s, output: 43.33 toks/s]
Processed prompts:  16%|        | 322/2048 [00:07<00:59, 28.84it/s, est. speed input: 43202.58 toks/s, output: 42.19 toks/s]
Processed prompts:  17%|        | 338/2048 [00:08<00:59, 28.91it/s, est. speed input: 42301.20 toks/s, output: 41.31 toks/s]
Processed prompts:  17%|        | 354/2048 [00:08<00:59, 28.67it/s, est. speed input: 41421.81 toks/s, output: 40.45 toks/s]
Processed prompts:  18%|        | 370/2048 [00:09<00:58, 28.58it/s, est. speed input: 40674.72 toks/s, output: 39.72 toks/s]
Processed prompts:  19%|        | 386/2048 [00:09<00:58, 28.39it/s, est. speed input: 39976.67 toks/s, output: 39.04 toks/s]
Processed prompts:  20%|        | 402/2048 [00:10<00:58, 28.36it/s, est. speed input: 39382.01 toks/s, output: 38.46 toks/s]
Processed prompts:  20%|        | 418/2048 [00:11<00:57, 28.28it/s, est. speed input: 38832.75 toks/s, output: 37.92 toks/s]
Processed prompts:  21%|        | 434/2048 [00:11<00:56, 28.37it/s, est. speed input: 38370.80 toks/s, output: 37.47 toks/s]
Processed prompts:  22%|       | 450/2048 [00:12<00:55, 28.63it/s, est. speed input: 37990.58 toks/s, output: 37.10 toks/s]
Processed prompts:  23%|       | 466/2048 [00:12<00:55, 28.58it/s, est. speed input: 37598.70 toks/s, output: 36.72 toks/s]
Processed prompts:  24%|       | 482/2048 [00:13<00:55, 28.43it/s, est. speed input: 37220.30 toks/s, output: 36.35 toks/s]
Processed prompts:  24%|       | 498/2048 [00:13<00:54, 28.51it/s, est. speed input: 36902.99 toks/s, output: 36.04 toks/s]
Processed prompts:  25%|       | 514/2048 [00:14<00:54, 28.40it/s, est. speed input: 36584.27 toks/s, output: 35.73 toks/s]
Processed prompts:  26%|       | 530/2048 [00:14<00:53, 28.43it/s, est. speed input: 36306.71 toks/s, output: 35.46 toks/s]
Processed prompts:  27%|       | 546/2048 [00:15<00:53, 28.33it/s, est. speed input: 36030.67 toks/s, output: 35.19 toks/s]
Processed prompts:  27%|       | 562/2048 [00:16<00:52, 28.26it/s, est. speed input: 35774.13 toks/s, output: 34.94 toks/s]
Processed prompts:  28%|       | 578/2048 [00:16<00:52, 28.27it/s, est. speed input: 35542.04 toks/s, output: 34.71 toks/s]
Processed prompts:  29%|       | 594/2048 [00:17<00:51, 28.27it/s, est. speed input: 35325.49 toks/s, output: 34.50 toks/s]
Processed prompts:  30%|       | 610/2048 [00:17<00:50, 28.32it/s, est. speed input: 35129.60 toks/s, output: 34.31 toks/s]
Processed prompts:  31%|       | 626/2048 [00:18<00:50, 28.29it/s, est. speed input: 34937.36 toks/s, output: 34.12 toks/s]
Processed prompts:  31%|      | 642/2048 [00:18<00:49, 28.36it/s, est. speed input: 34767.24 toks/s, output: 33.95 toks/s]
Processed prompts:  32%|      | 658/2048 [00:19<00:49, 28.30it/s, est. speed input: 34594.33 toks/s, output: 33.78 toks/s]
Processed prompts:  33%|      | 674/2048 [00:20<00:48, 28.39it/s, est. speed input: 34445.79 toks/s, output: 33.64 toks/s]
Processed prompts:  34%|      | 690/2048 [00:20<00:47, 28.31it/s, est. speed input: 34290.23 toks/s, output: 33.49 toks/s]
Processed prompts:  34%|      | 706/2048 [00:21<00:47, 28.30it/s, est. speed input: 34147.90 toks/s, output: 33.35 toks/s]
Processed prompts:  35%|      | 722/2048 [00:21<00:46, 28.26it/s, est. speed input: 34008.74 toks/s, output: 33.21 toks/s]
Processed prompts:  36%|      | 738/2048 [00:22<00:46, 28.33it/s, est. speed input: 33887.68 toks/s, output: 33.09 toks/s]
Processed prompts:  37%|      | 754/2048 [00:22<00:45, 28.26it/s, est. speed input: 33760.07 toks/s, output: 32.97 toks/s]
Processed prompts:  38%|      | 770/2048 [00:23<00:45, 28.31it/s, est. speed input: 33648.84 toks/s, output: 32.86 toks/s]
Processed prompts:  38%|      | 786/2048 [00:23<00:44, 28.31it/s, est. speed input: 33538.93 toks/s, output: 32.75 toks/s]
Processed prompts:  39%|      | 802/2048 [00:24<00:44, 28.30it/s, est. speed input: 33433.53 toks/s, output: 32.65 toks/s]
Processed prompts:  40%|      | 818/2048 [00:25<00:43, 28.33it/s, est. speed input: 33335.77 toks/s, output: 32.55 toks/s]
Processed prompts:  41%|      | 834/2048 [00:25<00:42, 28.28it/s, est. speed input: 33236.39 toks/s, output: 32.46 toks/s]
Processed prompts:  42%|     | 850/2048 [00:26<00:42, 28.36it/s, est. speed input: 33150.54 toks/s, output: 32.37 toks/s]
Processed prompts:  42%|     | 866/2048 [00:26<00:41, 28.32it/s, est. speed input: 33061.25 toks/s, output: 32.29 toks/s]
Processed prompts:  43%|     | 882/2048 [00:27<00:41, 28.37it/s, est. speed input: 32981.64 toks/s, output: 32.21 toks/s]
Processed prompts:  44%|     | 898/2048 [00:27<00:40, 28.25it/s, est. speed input: 32892.96 toks/s, output: 32.12 toks/s]
Processed prompts:  45%|     | 914/2048 [00:28<00:40, 28.30it/s, est. speed input: 32817.51 toks/s, output: 32.05 toks/s]
Processed prompts:  45%|     | 930/2048 [00:29<00:38, 28.69it/s, est. speed input: 32771.73 toks/s, output: 32.00 toks/s]
Processed prompts:  46%|     | 946/2048 [00:29<00:38, 28.61it/s, est. speed input: 32702.44 toks/s, output: 31.94 toks/s]
Processed prompts:  47%|     | 962/2048 [00:30<00:38, 28.51it/s, est. speed input: 32632.15 toks/s, output: 31.87 toks/s]
Processed prompts:  48%|     | 978/2048 [00:30<00:37, 28.90it/s, est. speed input: 32595.90 toks/s, output: 31.83 toks/s]
Processed prompts:  49%|     | 994/2048 [00:31<00:36, 28.73it/s, est. speed input: 32531.82 toks/s, output: 31.77 toks/s]
Processed prompts:  49%|     | 1010/2048 [00:31<00:36, 28.66it/s, est. speed input: 32472.90 toks/s, output: 31.71 toks/s]
Processed prompts:  50%|     | 1026/2048 [00:32<00:35, 28.48it/s, est. speed input: 32406.87 toks/s, output: 31.65 toks/s]
Processed prompts:  51%|     | 1042/2048 [00:32<00:35, 28.41it/s, est. speed input: 32347.37 toks/s, output: 31.59 toks/s]
Processed prompts:  52%|    | 1058/2048 [00:33<00:34, 28.31it/s, est. speed input: 32286.25 toks/s, output: 31.53 toks/s]
Processed prompts:  52%|    | 1074/2048 [00:34<00:34, 28.27it/s, est. speed input: 32228.97 toks/s, output: 31.47 toks/s]
Processed prompts:  53%|    | 1090/2048 [00:34<00:33, 28.28it/s, est. speed input: 32176.02 toks/s, output: 31.42 toks/s]
Processed prompts:  54%|    | 1106/2048 [00:35<00:33, 28.27it/s, est. speed input: 32123.96 toks/s, output: 31.37 toks/s]
Processed prompts:  55%|    | 1122/2048 [00:35<00:32, 28.27it/s, est. speed input: 32073.60 toks/s, output: 31.32 toks/s]
Processed prompts:  56%|    | 1138/2048 [00:36<00:32, 28.24it/s, est. speed input: 32023.12 toks/s, output: 31.27 toks/s]
Processed prompts:  56%|    | 1154/2048 [00:36<00:31, 28.69it/s, est. speed input: 32001.31 toks/s, output: 31.25 toks/s]
Processed prompts:  57%|    | 1170/2048 [00:37<00:30, 28.51it/s, est. speed input: 31952.45 toks/s, output: 31.20 toks/s]
Processed prompts:  58%|    | 1186/2048 [00:38<00:30, 28.48it/s, est. speed input: 31909.79 toks/s, output: 31.16 toks/s]
Processed prompts:  59%|    | 1202/2048 [00:38<00:29, 28.41it/s, est. speed input: 31866.33 toks/s, output: 31.12 toks/s]
Processed prompts:  59%|    | 1218/2048 [00:39<00:29, 28.42it/s, est. speed input: 31827.04 toks/s, output: 31.08 toks/s]
Processed prompts:  60%|    | 1234/2048 [00:39<00:28, 28.36it/s, est. speed input: 31785.39 toks/s, output: 31.04 toks/s]
Processed prompts:  61%|    | 1250/2048 [00:40<00:28, 28.40it/s, est. speed input: 31748.81 toks/s, output: 31.00 toks/s]
Processed prompts:  62%|   | 1266/2048 [00:40<00:27, 28.76it/s, est. speed input: 31730.44 toks/s, output: 30.99 toks/s]
Processed prompts:  63%|   | 1282/2048 [00:41<00:26, 28.68it/s, est. speed input: 31695.81 toks/s, output: 30.95 toks/s]
Processed prompts:  63%|   | 1298/2048 [00:41<00:25, 28.92it/s, est. speed input: 31676.45 toks/s, output: 30.93 toks/s]
Processed prompts:  64%|   | 1314/2048 [00:42<00:25, 28.73it/s, est. speed input: 31640.44 toks/s, output: 30.90 toks/s]
Processed prompts:  65%|   | 1330/2048 [00:43<00:25, 28.56it/s, est. speed input: 31603.94 toks/s, output: 30.86 toks/s]
Processed prompts:  66%|   | 1346/2048 [00:43<00:24, 28.55it/s, est. speed input: 31573.29 toks/s, output: 30.83 toks/s]
Processed prompts:  67%|   | 1362/2048 [00:44<00:24, 28.45it/s, est. speed input: 31538.58 toks/s, output: 30.80 toks/s]
Processed prompts:  67%|   | 1378/2048 [00:44<00:23, 28.39it/s, est. speed input: 31505.55 toks/s, output: 30.77 toks/s]
Processed prompts:  68%|   | 1394/2048 [00:45<00:23, 28.35it/s, est. speed input: 31473.42 toks/s, output: 30.74 toks/s]
Processed prompts:  69%|   | 1410/2048 [00:45<00:22, 28.25it/s, est. speed input: 31438.91 toks/s, output: 30.70 toks/s]
Processed prompts:  70%|   | 1426/2048 [00:46<00:21, 28.31it/s, est. speed input: 31411.19 toks/s, output: 30.67 toks/s]
Processed prompts:  70%|   | 1442/2048 [00:47<00:21, 28.33it/s, est. speed input: 31382.73 toks/s, output: 30.65 toks/s]
Processed prompts:  71%|   | 1458/2048 [00:47<00:20, 28.37it/s, est. speed input: 31356.24 toks/s, output: 30.62 toks/s]
Processed prompts:  72%|  | 1474/2048 [00:48<00:20, 28.30it/s, est. speed input: 31326.30 toks/s, output: 30.59 toks/s]
Processed prompts:  73%|  | 1490/2048 [00:48<00:19, 28.35it/s, est. speed input: 31301.19 toks/s, output: 30.57 toks/s]
Processed prompts:  74%|  | 1506/2048 [00:49<00:19, 28.35it/s, est. speed input: 31275.35 toks/s, output: 30.54 toks/s]
Processed prompts:  74%|  | 1522/2048 [00:49<00:18, 28.37it/s, est. speed input: 31250.77 toks/s, output: 30.52 toks/s]
Processed prompts:  75%|  | 1538/2048 [00:50<00:18, 28.24it/s, est. speed input: 31220.72 toks/s, output: 30.49 toks/s]
Processed prompts:  76%|  | 1554/2048 [00:51<00:17, 28.28it/s, est. speed input: 31196.62 toks/s, output: 30.47 toks/s]
Processed prompts:  77%|  | 1570/2048 [00:51<00:16, 28.25it/s, est. speed input: 31170.84 toks/s, output: 30.44 toks/s]
Processed prompts:  77%|  | 1586/2048 [00:52<00:16, 28.75it/s, est. speed input: 31166.03 toks/s, output: 30.44 toks/s]
Processed prompts:  78%|  | 1602/2048 [00:52<00:15, 28.59it/s, est. speed input: 31141.76 toks/s, output: 30.41 toks/s]
Processed prompts:  79%|  | 1618/2048 [00:53<00:15, 28.58it/s, est. speed input: 31121.80 toks/s, output: 30.39 toks/s]
Processed prompts:  80%|  | 1634/2048 [00:53<00:14, 28.40it/s, est. speed input: 31095.79 toks/s, output: 30.37 toks/s]
Processed prompts:  81%|  | 1650/2048 [00:54<00:13, 28.75it/s, est. speed input: 31088.03 toks/s, output: 30.36 toks/s]
Processed prompts:  81%| | 1666/2048 [00:54<00:13, 28.67it/s, est. speed input: 31068.32 toks/s, output: 30.34 toks/s]
Processed prompts:  82%| | 1682/2048 [00:55<00:12, 28.51it/s, est. speed input: 31045.32 toks/s, output: 30.32 toks/s]
Processed prompts:  83%| | 1698/2048 [00:56<00:12, 28.50it/s, est. speed input: 31026.50 toks/s, output: 30.30 toks/s]
Processed prompts:  84%| | 1714/2048 [00:56<00:11, 28.42it/s, est. speed input: 31005.13 toks/s, output: 30.28 toks/s]
Processed prompts:  84%| | 1730/2048 [00:57<00:11, 28.41it/s, est. speed input: 30986.28 toks/s, output: 30.26 toks/s]
Processed prompts:  85%| | 1746/2048 [00:57<00:10, 28.29it/s, est. speed input: 30963.52 toks/s, output: 30.24 toks/s]
Processed prompts:  86%| | 1762/2048 [00:58<00:10, 28.37it/s, est. speed input: 30946.80 toks/s, output: 30.22 toks/s]
Processed prompts:  87%| | 1778/2048 [00:58<00:09, 28.21it/s, est. speed input: 30923.10 toks/s, output: 30.20 toks/s]
Processed prompts:  88%| | 1794/2048 [00:59<00:08, 28.29it/s, est. speed input: 30906.29 toks/s, output: 30.18 toks/s]
Processed prompts:  88%| | 1810/2048 [01:00<00:08, 28.22it/s, est. speed input: 30885.76 toks/s, output: 30.16 toks/s]
Processed prompts:  89%| | 1826/2048 [01:00<00:07, 28.30it/s, est. speed input: 30869.77 toks/s, output: 30.15 toks/s]
Processed prompts:  90%| | 1842/2048 [01:01<00:07, 28.22it/s, est. speed input: 30849.63 toks/s, output: 30.13 toks/s]
Processed prompts:  91%| | 1858/2048 [01:01<00:06, 28.25it/s, est. speed input: 30832.83 toks/s, output: 30.11 toks/s]
Processed prompts:  92%|| 1874/2048 [01:02<00:06, 28.62it/s, est. speed input: 30827.48 toks/s, output: 30.10 toks/s]
Processed prompts:  92%|| 1890/2048 [01:02<00:05, 28.51it/s, est. speed input: 30810.31 toks/s, output: 30.09 toks/s]
Processed prompts:  93%|| 1906/2048 [01:03<00:05, 28.38it/s, est. speed input: 30791.81 toks/s, output: 30.07 toks/s]
Processed prompts:  94%|| 1922/2048 [01:03<00:04, 28.27it/s, est. speed input: 30773.23 toks/s, output: 30.05 toks/s]
Processed prompts:  95%|| 1938/2048 [01:04<00:03, 28.29it/s, est. speed input: 30757.84 toks/s, output: 30.04 toks/s]
Processed prompts:  95%|| 1954/2048 [01:05<00:03, 28.64it/s, est. speed input: 30753.19 toks/s, output: 30.03 toks/s]
Processed prompts:  96%|| 1970/2048 [01:05<00:02, 28.56it/s, est. speed input: 30738.49 toks/s, output: 30.02 toks/s]
Processed prompts:  97%|| 1986/2048 [01:06<00:02, 28.84it/s, est. speed input: 30734.38 toks/s, output: 30.01 toks/s]
Processed prompts:  98%|| 2002/2048 [01:06<00:01, 29.62it/s, est. speed input: 30746.90 toks/s, output: 30.03 toks/s]
Processed prompts:  99%|| 2018/2048 [01:07<00:01, 29.19it/s, est. speed input: 30731.23 toks/s, output: 30.01 toks/s]
Processed prompts:  99%|| 2034/2048 [01:07<00:00, 29.39it/s, est. speed input: 30730.14 toks/s, output: 30.01 toks/s]
Processed prompts: 100%|| 2048/2048 [01:07<00:00, 29.39it/s, est. speed input: 30941.57 toks/s, output: 30.22 toks/s]
Processed prompts: 100%|| 2048/2048 [01:07<00:00, 30.22it/s, est. speed input: 30941.57 toks/s, output: 30.22 toks/s]
[rank0]:[W126 07:25:12.947464099 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 07:25:15
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:25:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:25:30 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1016241) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1016241) WARNING 01-26 07:25:53 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.54 requests/s, 29255.62 total tokens/s, 28.54 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 07:25:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:25:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:25:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:25:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:25:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:25:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:25:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:25:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:25:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:25:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:25:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:25:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:25:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:25:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:25:33] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:25:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:25:33] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:25:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:25:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:25:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:25:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:25:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:25:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:25:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:25:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:25:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:25:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:25:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1016241) [2026-01-26 07:25:34] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1016241) [2026-01-26 07:25:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1016241) [2026-01-26 07:25:34] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1016241) [2026-01-26 07:25:34] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1016241) [2026-01-26 07:25:34] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1016241) [2026-01-26 07:25:34] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1016241) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1016241) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.71s/it]
(EngineCore_DP0 pid=1016241) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.71s/it]
(EngineCore_DP0 pid=1016241) 
(EngineCore_DP0 pid=1016241) [2026-01-26 07:25:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1016241) [2026-01-26 07:25:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=1016241) [2026-01-26 07:25:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1016241) [2026-01-26 07:25:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=1016241) [2026-01-26 07:25:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1016241) [2026-01-26 07:25:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=1016241) [2026-01-26 07:25:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1016241) [2026-01-26 07:25:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=1016241) 2026-01-26 07:25:51,897 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1016241) 2026-01-26 07:25:52,106 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   2%|         | 66/4096 [00:00<00:06, 655.38it/s]
Adding requests:   3%|         | 132/4096 [00:00<00:06, 640.91it/s]
Adding requests:   5%|         | 197/4096 [00:00<00:06, 557.43it/s]
Adding requests:   6%|         | 254/4096 [00:00<00:07, 547.97it/s]
Adding requests:   8%|         | 310/4096 [00:00<00:07, 528.81it/s]
Adding requests:   9%|         | 364/4096 [00:00<00:07, 523.30it/s]
Adding requests:  10%|         | 417/4096 [00:00<00:07, 512.16it/s]
Adding requests:  11%|        | 469/4096 [00:00<00:07, 512.19it/s]
Adding requests:  13%|        | 521/4096 [00:00<00:07, 501.60it/s]
Adding requests:  14%|        | 575/4096 [00:01<00:06, 508.85it/s]
Adding requests:  15%|        | 627/4096 [00:01<00:06, 510.72it/s]
Adding requests:  17%|        | 683/4096 [00:01<00:06, 522.91it/s]
Adding requests:  18%|        | 736/4096 [00:01<00:06, 515.06it/s]
Adding requests:  19%|        | 788/4096 [00:01<00:06, 508.52it/s]
Adding requests:  20%|        | 839/4096 [00:01<00:06, 496.18it/s]
Adding requests:  22%|       | 893/4096 [00:01<00:06, 508.45it/s]
Adding requests:  23%|       | 944/4096 [00:01<00:06, 506.60it/s]
Adding requests:  24%|       | 997/4096 [00:01<00:06, 511.55it/s]
Adding requests:  26%|       | 1051/4096 [00:02<00:05, 517.75it/s]
Adding requests:  27%|       | 1103/4096 [00:02<00:05, 512.50it/s]
Adding requests:  28%|       | 1155/4096 [00:02<00:05, 512.00it/s]
Adding requests:  29%|       | 1207/4096 [00:02<00:05, 499.48it/s]
Adding requests:  31%|       | 1258/4096 [00:02<00:05, 490.59it/s]
Adding requests:  32%|      | 1309/4096 [00:02<00:05, 492.98it/s]
Adding requests:  33%|      | 1363/4096 [00:02<00:05, 504.72it/s]
Adding requests:  35%|      | 1414/4096 [00:02<00:05, 505.69it/s]
Adding requests:  36%|      | 1467/4096 [00:02<00:05, 511.49it/s]
Adding requests:  37%|      | 1519/4096 [00:02<00:05, 507.03it/s]
Adding requests:  38%|      | 1573/4096 [00:03<00:04, 515.60it/s]
Adding requests:  40%|      | 1627/4096 [00:03<00:04, 521.16it/s]
Adding requests:  41%|      | 1680/4096 [00:03<00:04, 513.03it/s]
Adding requests:  42%|     | 1736/4096 [00:03<00:04, 522.26it/s]
Adding requests:  44%|     | 1789/4096 [00:03<00:04, 510.32it/s]
Adding requests:  45%|     | 1843/4096 [00:03<00:04, 516.94it/s]
Adding requests:  46%|     | 1895/4096 [00:03<00:04, 510.85it/s]
Adding requests:  48%|     | 1948/4096 [00:03<00:04, 515.00it/s]
Adding requests:  49%|     | 2000/4096 [00:03<00:04, 511.05it/s]
Adding requests:  50%|     | 2055/4096 [00:03<00:03, 519.79it/s]
Adding requests:  51%|    | 2108/4096 [00:04<00:03, 513.95it/s]
Adding requests:  53%|    | 2160/4096 [00:04<00:03, 509.55it/s]
Adding requests:  54%|    | 2211/4096 [00:04<00:03, 506.35it/s]
Adding requests:  55%|    | 2265/4096 [00:04<00:03, 513.69it/s]
Adding requests:  57%|    | 2319/4096 [00:04<00:03, 518.12it/s]
Adding requests:  58%|    | 2372/4096 [00:04<00:03, 519.75it/s]
Adding requests:  59%|    | 2424/4096 [00:04<00:03, 495.36it/s]
Adding requests:  60%|    | 2474/4096 [00:04<00:03, 495.14it/s]
Adding requests:  62%|   | 2525/4096 [00:04<00:03, 496.18it/s]
Adding requests:  63%|   | 2575/4096 [00:05<00:03, 494.18it/s]
Adding requests:  64%|   | 2629/4096 [00:05<00:02, 506.68it/s]
Adding requests:  65%|   | 2680/4096 [00:05<00:02, 504.32it/s]
Adding requests:  67%|   | 2733/4096 [00:05<00:02, 511.40it/s]
Adding requests:  68%|   | 2785/4096 [00:05<00:02, 506.69it/s]
Adding requests:  69%|   | 2837/4096 [00:05<00:02, 508.66it/s]
Adding requests:  71%|   | 2890/4096 [00:05<00:02, 513.03it/s]
Adding requests:  72%|  | 2942/4096 [00:05<00:02, 508.98it/s]
Adding requests:  73%|  | 2993/4096 [00:05<00:02, 506.63it/s]
Adding requests:  74%|  | 3044/4096 [00:05<00:02, 503.36it/s]
Adding requests:  76%|  | 3096/4096 [00:06<00:01, 507.10it/s]
Adding requests:  77%|  | 3147/4096 [00:06<00:01, 503.97it/s]
Adding requests:  78%|  | 3201/4096 [00:06<00:01, 513.17it/s]
Adding requests:  79%|  | 3253/4096 [00:06<00:01, 513.21it/s]
Adding requests:  81%|  | 3306/4096 [00:06<00:01, 514.62it/s]
Adding requests:  82%| | 3360/4096 [00:06<00:01, 518.96it/s]
Adding requests:  83%| | 3413/4096 [00:06<00:01, 519.94it/s]
Adding requests:  85%| | 3465/4096 [00:06<00:01, 508.76it/s]
Adding requests:  86%| | 3518/4096 [00:06<00:01, 512.90it/s]
Adding requests:  87%| | 3570/4096 [00:06<00:01, 511.64it/s]
Adding requests:  88%| | 3622/4096 [00:07<00:00, 506.84it/s]
Adding requests:  90%| | 3676/4096 [00:07<00:00, 515.36it/s]
Adding requests:  91%| | 3729/4096 [00:07<00:00, 518.75it/s]
Adding requests:  92%|| 3781/4096 [00:07<00:00, 506.71it/s]
Adding requests:  94%|| 3834/4096 [00:07<00:00, 511.65it/s]
Adding requests:  95%|| 3887/4096 [00:07<00:00, 514.91it/s]
Adding requests:  96%|| 3941/4096 [00:07<00:00, 520.35it/s]
Adding requests:  98%|| 3994/4096 [00:07<00:00, 519.53it/s]
Adding requests:  99%|| 4047/4096 [00:07<00:00, 522.45it/s]
Adding requests: 100%|| 4096/4096 [00:07<00:00, 513.48it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 194/4096 [00:00<00:03, 1200.07it/s, est. speed input: 1229309.70 toks/s, output: 1200.25 toks/s]
Processed prompts:   8%|         | 315/4096 [00:03<00:51, 73.15it/s, est. speed input: 90626.60 toks/s, output: 88.50 toks/s]      
Processed prompts:   9%|         | 367/4096 [00:05<01:15, 49.23it/s, est. speed input: 64686.67 toks/s, output: 63.17 toks/s]
Processed prompts:  10%|         | 397/4096 [00:06<01:25, 43.39it/s, est. speed input: 58541.92 toks/s, output: 57.17 toks/s]
Processed prompts:  10%|         | 418/4096 [00:08<01:40, 36.75it/s, est. speed input: 53000.61 toks/s, output: 51.76 toks/s]
Processed prompts:  11%|         | 450/4096 [00:09<01:45, 34.57it/s, est. speed input: 50148.99 toks/s, output: 48.97 toks/s]
Processed prompts:  12%|        | 482/4096 [00:10<01:50, 32.77it/s, est. speed input: 47820.74 toks/s, output: 46.70 toks/s]
Processed prompts:  13%|        | 514/4096 [00:11<01:53, 31.49it/s, est. speed input: 45961.18 toks/s, output: 44.88 toks/s]
Processed prompts:  13%|        | 546/4096 [00:12<01:56, 30.57it/s, est. speed input: 44439.83 toks/s, output: 43.40 toks/s]
Processed prompts:  14%|        | 578/4096 [00:13<01:57, 29.91it/s, est. speed input: 43168.22 toks/s, output: 42.16 toks/s]
Processed prompts:  15%|        | 610/4096 [00:14<01:58, 29.45it/s, est. speed input: 42094.17 toks/s, output: 41.11 toks/s]
Processed prompts:  16%|        | 642/4096 [00:15<01:58, 29.09it/s, est. speed input: 41160.53 toks/s, output: 40.20 toks/s]
Processed prompts:  16%|        | 674/4096 [00:17<01:58, 28.82it/s, est. speed input: 40345.23 toks/s, output: 39.40 toks/s]
Processed prompts:  17%|        | 706/4096 [00:18<01:58, 28.67it/s, est. speed input: 39639.75 toks/s, output: 38.71 toks/s]
Processed prompts:  18%|        | 738/4096 [00:19<01:57, 28.54it/s, est. speed input: 39012.23 toks/s, output: 38.10 toks/s]
Processed prompts:  19%|        | 770/4096 [00:20<01:56, 28.47it/s, est. speed input: 38458.64 toks/s, output: 37.56 toks/s]
Processed prompts:  20%|        | 802/4096 [00:21<01:56, 28.39it/s, est. speed input: 37957.46 toks/s, output: 37.07 toks/s]
Processed prompts:  20%|        | 834/4096 [00:22<01:54, 28.37it/s, est. speed input: 37513.16 toks/s, output: 36.63 toks/s]
Processed prompts:  21%|        | 866/4096 [00:23<01:54, 28.31it/s, est. speed input: 37101.41 toks/s, output: 36.23 toks/s]
Processed prompts:  22%|       | 898/4096 [00:25<01:53, 28.28it/s, est. speed input: 36728.50 toks/s, output: 35.87 toks/s]
Processed prompts:  23%|       | 930/4096 [00:26<01:51, 28.43it/s, est. speed input: 36420.61 toks/s, output: 35.57 toks/s]
Processed prompts:  23%|       | 962/4096 [00:27<01:49, 28.55it/s, est. speed input: 36140.70 toks/s, output: 35.29 toks/s]
Processed prompts:  24%|       | 994/4096 [00:28<01:49, 28.41it/s, est. speed input: 35844.69 toks/s, output: 35.00 toks/s]
Processed prompts:  25%|       | 1026/4096 [00:29<01:48, 28.36it/s, est. speed input: 35578.36 toks/s, output: 34.74 toks/s]
Processed prompts:  26%|       | 1058/4096 [00:30<01:47, 28.29it/s, est. speed input: 35327.90 toks/s, output: 34.50 toks/s]
Processed prompts:  27%|       | 1090/4096 [00:31<01:46, 28.27it/s, est. speed input: 35097.89 toks/s, output: 34.28 toks/s]
Processed prompts:  27%|       | 1122/4096 [00:32<01:45, 28.27it/s, est. speed input: 34887.05 toks/s, output: 34.07 toks/s]
Processed prompts:  28%|       | 1154/4096 [00:34<01:43, 28.45it/s, est. speed input: 34714.34 toks/s, output: 33.90 toks/s]
Processed prompts:  29%|       | 1186/4096 [00:35<01:42, 28.40it/s, est. speed input: 34528.79 toks/s, output: 33.72 toks/s]
Processed prompts:  30%|       | 1218/4096 [00:36<01:41, 28.36it/s, est. speed input: 34354.57 toks/s, output: 33.55 toks/s]
Processed prompts:  31%|       | 1250/4096 [00:37<01:39, 28.52it/s, est. speed input: 34214.23 toks/s, output: 33.41 toks/s]
Processed prompts:  31%|      | 1282/4096 [00:38<01:38, 28.60it/s, est. speed input: 34077.67 toks/s, output: 33.28 toks/s]
Processed prompts:  32%|      | 1314/4096 [00:39<01:37, 28.50it/s, est. speed input: 33930.75 toks/s, output: 33.14 toks/s]
Processed prompts:  33%|      | 1346/4096 [00:40<01:36, 28.42it/s, est. speed input: 33792.02 toks/s, output: 33.00 toks/s]
Processed prompts:  34%|      | 1378/4096 [00:41<01:35, 28.34it/s, est. speed input: 33656.87 toks/s, output: 32.87 toks/s]
Processed prompts:  34%|      | 1410/4096 [00:43<01:34, 28.28it/s, est. speed input: 33529.77 toks/s, output: 32.74 toks/s]
Processed prompts:  35%|      | 1442/4096 [00:44<01:33, 28.30it/s, est. speed input: 33413.91 toks/s, output: 32.63 toks/s]
Processed prompts:  36%|      | 1474/4096 [00:45<01:32, 28.26it/s, est. speed input: 33299.77 toks/s, output: 32.52 toks/s]
Processed prompts:  37%|      | 1506/4096 [00:46<01:31, 28.23it/s, est. speed input: 33190.47 toks/s, output: 32.41 toks/s]
Processed prompts:  38%|      | 1538/4096 [00:47<01:30, 28.24it/s, est. speed input: 33089.73 toks/s, output: 32.31 toks/s]
Processed prompts:  38%|      | 1570/4096 [00:48<01:28, 28.47it/s, est. speed input: 33012.81 toks/s, output: 32.24 toks/s]
Processed prompts:  39%|      | 1602/4096 [00:49<01:27, 28.41it/s, est. speed input: 32920.52 toks/s, output: 32.15 toks/s]
Processed prompts:  40%|      | 1634/4096 [00:50<01:26, 28.56it/s, est. speed input: 32848.72 toks/s, output: 32.08 toks/s]
Processed prompts:  41%|      | 1666/4096 [00:52<01:25, 28.45it/s, est. speed input: 32761.87 toks/s, output: 31.99 toks/s]
Processed prompts:  41%|     | 1698/4096 [00:53<01:24, 28.39it/s, est. speed input: 32680.70 toks/s, output: 31.91 toks/s]
Processed prompts:  42%|     | 1730/4096 [00:54<01:23, 28.32it/s, est. speed input: 32600.36 toks/s, output: 31.84 toks/s]
Processed prompts:  43%|     | 1762/4096 [00:55<01:22, 28.28it/s, est. speed input: 32523.97 toks/s, output: 31.76 toks/s]
Processed prompts:  44%|     | 1794/4096 [00:56<01:21, 28.28it/s, est. speed input: 32452.31 toks/s, output: 31.69 toks/s]
Processed prompts:  45%|     | 1826/4096 [00:57<01:20, 28.25it/s, est. speed input: 32381.39 toks/s, output: 31.62 toks/s]
Processed prompts:  45%|     | 1858/4096 [00:58<01:18, 28.40it/s, est. speed input: 32325.83 toks/s, output: 31.57 toks/s]
Processed prompts:  46%|     | 1890/4096 [00:59<01:17, 28.34it/s, est. speed input: 32260.98 toks/s, output: 31.50 toks/s]
Processed prompts:  47%|     | 1922/4096 [01:01<01:16, 28.33it/s, est. speed input: 32200.09 toks/s, output: 31.45 toks/s]
Processed prompts:  48%|     | 1954/4096 [01:02<01:15, 28.47it/s, est. speed input: 32151.98 toks/s, output: 31.40 toks/s]
Processed prompts:  48%|     | 1986/4096 [01:03<01:12, 29.07it/s, est. speed input: 32137.90 toks/s, output: 31.38 toks/s]
Processed prompts:  49%|     | 2018/4096 [01:04<01:12, 28.79it/s, est. speed input: 32079.34 toks/s, output: 31.33 toks/s]
Processed prompts:  50%|     | 2050/4096 [01:05<01:10, 29.01it/s, est. speed input: 32049.33 toks/s, output: 31.30 toks/s]
Processed prompts:  51%|     | 2082/4096 [01:06<01:09, 28.97it/s, est. speed input: 32008.04 toks/s, output: 31.26 toks/s]
Processed prompts:  52%|    | 2114/4096 [01:07<01:09, 28.68it/s, est. speed input: 31952.17 toks/s, output: 31.20 toks/s]
Processed prompts:  52%|    | 2146/4096 [01:08<01:08, 28.53it/s, est. speed input: 31901.40 toks/s, output: 31.15 toks/s]
Processed prompts:  53%|    | 2178/4096 [01:09<01:06, 28.89it/s, est. speed input: 31879.36 toks/s, output: 31.13 toks/s]
Processed prompts:  54%|    | 2210/4096 [01:11<01:04, 29.15it/s, est. speed input: 31858.55 toks/s, output: 31.11 toks/s]
Processed prompts:  55%|    | 2242/4096 [01:12<01:04, 28.88it/s, est. speed input: 31812.95 toks/s, output: 31.07 toks/s]
Processed prompts:  56%|    | 2274/4096 [01:13<01:03, 28.87it/s, est. speed input: 31778.34 toks/s, output: 31.03 toks/s]
Processed prompts:  56%|    | 2306/4096 [01:14<01:02, 28.85it/s, est. speed input: 31744.44 toks/s, output: 31.00 toks/s]
Processed prompts:  57%|    | 2338/4096 [01:15<01:00, 28.89it/s, est. speed input: 31713.86 toks/s, output: 30.97 toks/s]
Processed prompts:  58%|    | 2370/4096 [01:16<00:58, 29.43it/s, est. speed input: 31711.12 toks/s, output: 30.97 toks/s]
Processed prompts:  59%|    | 2402/4096 [01:17<00:57, 29.24it/s, est. speed input: 31679.33 toks/s, output: 30.94 toks/s]
Processed prompts:  59%|    | 2434/4096 [01:18<00:57, 29.14it/s, est. speed input: 31650.15 toks/s, output: 30.91 toks/s]
Processed prompts:  60%|    | 2466/4096 [01:19<00:56, 29.02it/s, est. speed input: 31619.58 toks/s, output: 30.88 toks/s]
Processed prompts:  61%|    | 2498/4096 [01:20<00:55, 28.99it/s, est. speed input: 31591.97 toks/s, output: 30.85 toks/s]
Processed prompts:  62%|   | 2530/4096 [01:22<00:54, 28.73it/s, est. speed input: 31553.49 toks/s, output: 30.81 toks/s]
Processed prompts:  63%|   | 2562/4096 [01:23<00:53, 28.80it/s, est. speed input: 31528.28 toks/s, output: 30.79 toks/s]
Processed prompts:  63%|   | 2594/4096 [01:24<00:52, 28.79it/s, est. speed input: 31501.24 toks/s, output: 30.76 toks/s]
Processed prompts:  64%|   | 2626/4096 [01:25<00:51, 28.61it/s, est. speed input: 31466.22 toks/s, output: 30.73 toks/s]
Processed prompts:  65%|   | 2658/4096 [01:26<00:50, 28.47it/s, est. speed input: 31431.71 toks/s, output: 30.70 toks/s]
Processed prompts:  66%|   | 2690/4096 [01:27<00:48, 28.84it/s, est. speed input: 31419.45 toks/s, output: 30.68 toks/s]
Processed prompts:  66%|   | 2722/4096 [01:28<00:47, 28.64it/s, est. speed input: 31386.64 toks/s, output: 30.65 toks/s]
Processed prompts:  67%|   | 2754/4096 [01:29<00:46, 28.70it/s, est. speed input: 31364.06 toks/s, output: 30.63 toks/s]
Processed prompts:  68%|   | 2786/4096 [01:31<00:45, 28.58it/s, est. speed input: 31334.23 toks/s, output: 30.60 toks/s]
Processed prompts:  69%|   | 2818/4096 [01:32<00:44, 28.90it/s, est. speed input: 31323.23 toks/s, output: 30.59 toks/s]
Processed prompts:  70%|   | 2850/4096 [01:33<00:43, 28.86it/s, est. speed input: 31300.80 toks/s, output: 30.57 toks/s]
Processed prompts:  70%|   | 2882/4096 [01:34<00:42, 28.64it/s, est. speed input: 31270.86 toks/s, output: 30.54 toks/s]
Processed prompts:  71%|   | 2914/4096 [01:35<00:41, 28.50it/s, est. speed input: 31242.32 toks/s, output: 30.51 toks/s]
Processed prompts:  72%|  | 2946/4096 [01:36<00:40, 28.58it/s, est. speed input: 31221.72 toks/s, output: 30.49 toks/s]
Processed prompts:  73%|  | 2978/4096 [01:37<00:39, 28.48it/s, est. speed input: 31195.24 toks/s, output: 30.46 toks/s]
Processed prompts:  73%|  | 3010/4096 [01:38<00:37, 28.83it/s, est. speed input: 31186.34 toks/s, output: 30.46 toks/s]
Processed prompts:  74%|  | 3042/4096 [01:39<00:36, 28.83it/s, est. speed input: 31167.89 toks/s, output: 30.44 toks/s]
Processed prompts:  75%|  | 3074/4096 [01:41<00:35, 28.65it/s, est. speed input: 31142.74 toks/s, output: 30.41 toks/s]
Processed prompts:  76%|  | 3106/4096 [01:42<00:33, 29.24it/s, est. speed input: 31145.88 toks/s, output: 30.42 toks/s]
Processed prompts:  77%|  | 3138/4096 [01:43<00:32, 29.39it/s, est. speed input: 31138.55 toks/s, output: 30.41 toks/s]
Processed prompts:  77%|  | 3170/4096 [01:44<00:31, 29.00it/s, est. speed input: 31113.19 toks/s, output: 30.38 toks/s]
Processed prompts:  78%|  | 3202/4096 [01:45<00:30, 29.25it/s, est. speed input: 31107.62 toks/s, output: 30.38 toks/s]
Processed prompts:  79%|  | 3234/4096 [01:46<00:29, 29.12it/s, est. speed input: 31091.16 toks/s, output: 30.36 toks/s]
Processed prompts:  80%|  | 3266/4096 [01:47<00:28, 28.86it/s, est. speed input: 31068.62 toks/s, output: 30.34 toks/s]
Processed prompts:  81%|  | 3298/4096 [01:48<00:27, 28.82it/s, est. speed input: 31051.64 toks/s, output: 30.32 toks/s]
Processed prompts:  81%| | 3330/4096 [01:49<00:26, 29.09it/s, est. speed input: 31045.67 toks/s, output: 30.32 toks/s]
Processed prompts:  82%| | 3362/4096 [01:50<00:25, 28.81it/s, est. speed input: 31023.14 toks/s, output: 30.30 toks/s]
Processed prompts:  83%| | 3394/4096 [01:52<00:24, 28.62it/s, est. speed input: 31001.42 toks/s, output: 30.27 toks/s]
Processed prompts:  84%| | 3426/4096 [01:53<00:23, 28.67it/s, est. speed input: 30986.42 toks/s, output: 30.26 toks/s]
Processed prompts:  84%| | 3458/4096 [01:54<00:22, 28.72it/s, est. speed input: 30972.22 toks/s, output: 30.25 toks/s]
Processed prompts:  85%| | 3490/4096 [01:55<00:20, 28.99it/s, est. speed input: 30966.42 toks/s, output: 30.24 toks/s]
Processed prompts:  86%| | 3522/4096 [01:56<00:19, 28.75it/s, est. speed input: 30946.30 toks/s, output: 30.22 toks/s]
Processed prompts:  87%| | 3554/4096 [01:57<00:18, 28.59it/s, est. speed input: 30926.62 toks/s, output: 30.20 toks/s]
Processed prompts:  88%| | 3586/4096 [01:58<00:17, 28.48it/s, est. speed input: 30907.15 toks/s, output: 30.18 toks/s]
Processed prompts:  88%| | 3618/4096 [01:59<00:16, 28.34it/s, est. speed input: 30886.20 toks/s, output: 30.16 toks/s]
Processed prompts:  89%| | 3650/4096 [02:01<00:15, 28.51it/s, est. speed input: 30874.36 toks/s, output: 30.15 toks/s]
Processed prompts:  90%| | 3682/4096 [02:02<00:14, 28.60it/s, est. speed input: 30861.86 toks/s, output: 30.14 toks/s]
Processed prompts:  91%| | 3714/4096 [02:03<00:13, 28.64it/s, est. speed input: 30849.06 toks/s, output: 30.13 toks/s]
Processed prompts:  91%|| 3746/4096 [02:04<00:12, 28.50it/s, est. speed input: 30830.65 toks/s, output: 30.11 toks/s]
Processed prompts:  92%|| 3778/4096 [02:05<00:11, 28.43it/s, est. speed input: 30813.86 toks/s, output: 30.09 toks/s]
Processed prompts:  93%|| 3810/4096 [02:06<00:10, 28.51it/s, est. speed input: 30801.32 toks/s, output: 30.08 toks/s]
Processed prompts:  94%|| 3842/4096 [02:07<00:08, 28.90it/s, est. speed input: 30799.15 toks/s, output: 30.08 toks/s]
Processed prompts:  95%|| 3874/4096 [02:08<00:07, 28.71it/s, est. speed input: 30783.10 toks/s, output: 30.06 toks/s]
Processed prompts:  95%|| 3906/4096 [02:10<00:06, 28.56it/s, est. speed input: 30766.45 toks/s, output: 30.05 toks/s]
Processed prompts:  96%|| 3938/4096 [02:11<00:05, 28.64it/s, est. speed input: 30755.91 toks/s, output: 30.04 toks/s]
Processed prompts:  97%|| 3970/4096 [02:12<00:04, 28.51it/s, est. speed input: 30740.07 toks/s, output: 30.02 toks/s]
Processed prompts:  98%|| 4002/4096 [02:13<00:03, 28.40it/s, est. speed input: 30723.57 toks/s, output: 30.00 toks/s]
Processed prompts:  98%|| 4034/4096 [02:14<00:02, 29.06it/s, est. speed input: 30729.49 toks/s, output: 30.01 toks/s]
Processed prompts:  99%|| 4066/4096 [02:15<00:01, 29.06it/s, est. speed input: 30721.36 toks/s, output: 30.00 toks/s]
Processed prompts: 100%|| 4096/4096 [02:15<00:00, 29.06it/s, est. speed input: 30947.97 toks/s, output: 30.22 toks/s]
Processed prompts: 100%|| 4096/4096 [02:15<00:00, 30.22it/s, est. speed input: 30947.97 toks/s, output: 30.22 toks/s]
[rank0]:[W126 07:28:17.665923971 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 07:28:19
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:28:45 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:28:45 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1019110) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1019110) WARNING 01-26 07:29:11 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.84 requests/s, 29558.55 total tokens/s, 28.84 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 07:28:45] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:28:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:28:45] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:28:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:28:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:28:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:28:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:28:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:28:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:28:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:28:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:28:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:28:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:28:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:28:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:28:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:28:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:28:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:28:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:28:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:28:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:28:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:28:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:28:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:28:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:28:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:28:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:28:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1019110) [2026-01-26 07:28:50] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1019110) [2026-01-26 07:28:50] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1019110) [2026-01-26 07:28:50] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1019110) [2026-01-26 07:28:50] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1019110) [2026-01-26 07:28:50] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1019110) [2026-01-26 07:28:50] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1019110) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1019110) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.68s/it]
(EngineCore_DP0 pid=1019110) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.68s/it]
(EngineCore_DP0 pid=1019110) 
(EngineCore_DP0 pid=1019110) [2026-01-26 07:29:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1019110) [2026-01-26 07:29:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=1019110) [2026-01-26 07:29:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1019110) [2026-01-26 07:29:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=1019110) [2026-01-26 07:29:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1019110) [2026-01-26 07:29:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=1019110) [2026-01-26 07:29:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1019110) [2026-01-26 07:29:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=1019110) 2026-01-26 07:29:08,859 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1019110) 2026-01-26 07:29:09,102 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 61/8192 [00:00<00:13, 601.93it/s]
Adding requests:   1%|         | 122/8192 [00:00<00:13, 580.84it/s]
Adding requests:   2%|         | 181/8192 [00:00<00:14, 542.83it/s]
Adding requests:   3%|         | 236/8192 [00:00<00:14, 532.94it/s]
Adding requests:   4%|         | 291/8192 [00:00<00:14, 536.04it/s]
Adding requests:   4%|         | 345/8192 [00:00<00:15, 519.81it/s]
Adding requests:   5%|         | 398/8192 [00:00<00:15, 509.45it/s]
Adding requests:   5%|         | 450/8192 [00:00<00:15, 506.47it/s]
Adding requests:   6%|         | 501/8192 [00:00<00:15, 505.15it/s]
Adding requests:   7%|         | 552/8192 [00:01<00:15, 502.79it/s]
Adding requests:   7%|         | 603/8192 [00:01<00:15, 504.01it/s]
Adding requests:   8%|         | 658/8192 [00:01<00:14, 515.38it/s]
Adding requests:   9%|         | 710/8192 [00:01<00:14, 504.30it/s]
Adding requests:   9%|         | 761/8192 [00:01<00:14, 500.21it/s]
Adding requests:  10%|         | 812/8192 [00:01<00:14, 497.64it/s]
Adding requests:  11%|         | 862/8192 [00:01<00:14, 495.50it/s]
Adding requests:  11%|         | 917/8192 [00:01<00:14, 510.89it/s]
Adding requests:  12%|        | 969/8192 [00:01<00:14, 502.86it/s]
Adding requests:  12%|        | 1022/8192 [00:01<00:14, 507.67it/s]
Adding requests:  13%|        | 1074/8192 [00:02<00:13, 510.91it/s]
Adding requests:  14%|        | 1128/8192 [00:02<00:13, 518.12it/s]
Adding requests:  14%|        | 1180/8192 [00:02<00:13, 513.03it/s]
Adding requests:  15%|        | 1233/8192 [00:02<00:13, 513.11it/s]
Adding requests:  16%|        | 1285/8192 [00:02<00:13, 508.92it/s]
Adding requests:  16%|        | 1336/8192 [00:02<00:13, 506.03it/s]
Adding requests:  17%|        | 1387/8192 [00:02<00:13, 499.72it/s]
Adding requests:  18%|        | 1437/8192 [00:02<00:13, 498.47it/s]
Adding requests:  18%|        | 1493/8192 [00:02<00:12, 516.32it/s]
Adding requests:  19%|        | 1545/8192 [00:03<00:12, 511.87it/s]
Adding requests:  20%|        | 1598/8192 [00:03<00:12, 514.78it/s]
Adding requests:  20%|        | 1651/8192 [00:03<00:12, 518.63it/s]
Adding requests:  21%|        | 1705/8192 [00:03<00:12, 524.52it/s]
Adding requests:  21%|       | 1758/8192 [00:03<00:12, 506.03it/s]
Adding requests:  22%|       | 1811/8192 [00:03<00:12, 511.13it/s]
Adding requests:  23%|       | 1863/8192 [00:03<00:13, 481.03it/s]
Adding requests:  23%|       | 1916/8192 [00:03<00:12, 493.62it/s]
Adding requests:  24%|       | 1966/8192 [00:03<00:12, 489.12it/s]
Adding requests:  25%|       | 2019/8192 [00:03<00:12, 500.34it/s]
Adding requests:  25%|       | 2072/8192 [00:04<00:12, 508.28it/s]
Adding requests:  26%|       | 2124/8192 [00:04<00:11, 511.47it/s]
Adding requests:  27%|       | 2176/8192 [00:04<00:12, 497.89it/s]
Adding requests:  27%|       | 2226/8192 [00:04<00:11, 497.72it/s]
Adding requests:  28%|       | 2279/8192 [00:04<00:11, 505.79it/s]
Adding requests:  28%|       | 2334/8192 [00:04<00:11, 514.95it/s]
Adding requests:  29%|       | 2386/8192 [00:04<00:11, 507.42it/s]
Adding requests:  30%|       | 2437/8192 [00:04<00:11, 502.48it/s]
Adding requests:  30%|       | 2490/8192 [00:04<00:11, 508.93it/s]
Adding requests:  31%|       | 2541/8192 [00:04<00:11, 506.06it/s]
Adding requests:  32%|      | 2593/8192 [00:05<00:11, 507.13it/s]
Adding requests:  32%|      | 2644/8192 [00:05<00:11, 504.32it/s]
Adding requests:  33%|      | 2698/8192 [00:05<00:10, 511.28it/s]
Adding requests:  34%|      | 2750/8192 [00:05<00:10, 505.81it/s]
Adding requests:  34%|      | 2802/8192 [00:05<00:10, 509.02it/s]
Adding requests:  35%|      | 2856/8192 [00:05<00:10, 517.26it/s]
Adding requests:  36%|      | 2909/8192 [00:05<00:10, 520.26it/s]
Adding requests:  36%|      | 2962/8192 [00:05<00:10, 502.74it/s]
Adding requests:  37%|      | 3014/8192 [00:05<00:10, 504.46it/s]
Adding requests:  37%|      | 3067/8192 [00:06<00:10, 509.38it/s]
Adding requests:  38%|      | 3122/8192 [00:06<00:09, 520.91it/s]
Adding requests:  39%|      | 3175/8192 [00:06<00:09, 509.68it/s]
Adding requests:  39%|      | 3227/8192 [00:06<00:10, 477.17it/s]
Adding requests:  40%|      | 3280/8192 [00:06<00:10, 489.87it/s]
Adding requests:  41%|      | 3333/8192 [00:06<00:09, 499.55it/s]
Adding requests:  41%|     | 3386/8192 [00:06<00:09, 507.64it/s]
Adding requests:  42%|     | 3438/8192 [00:06<00:09, 502.69it/s]
Adding requests:  43%|     | 3489/8192 [00:06<00:09, 499.61it/s]
Adding requests:  43%|     | 3542/8192 [00:06<00:09, 506.59it/s]
Adding requests:  44%|     | 3593/8192 [00:07<00:09, 500.33it/s]
Adding requests:  44%|     | 3644/8192 [00:07<00:09, 503.10it/s]
Adding requests:  45%|     | 3698/8192 [00:07<00:08, 513.20it/s]
Adding requests:  46%|     | 3750/8192 [00:07<00:08, 513.54it/s]
Adding requests:  46%|     | 3803/8192 [00:07<00:08, 518.23it/s]
Adding requests:  47%|     | 3857/8192 [00:07<00:08, 523.04it/s]
Adding requests:  48%|     | 3910/8192 [00:07<00:08, 511.33it/s]
Adding requests:  48%|     | 3962/8192 [00:07<00:08, 507.78it/s]
Adding requests:  49%|     | 4013/8192 [00:07<00:08, 503.85it/s]
Adding requests:  50%|     | 4067/8192 [00:07<00:08, 509.91it/s]
Adding requests:  50%|     | 4124/8192 [00:08<00:07, 527.35it/s]
Adding requests:  51%|     | 4177/8192 [00:08<00:07, 519.91it/s]
Adding requests:  52%|    | 4231/8192 [00:08<00:07, 523.72it/s]
Adding requests:  52%|    | 4284/8192 [00:08<00:07, 525.18it/s]
Adding requests:  53%|    | 4342/8192 [00:08<00:07, 540.69it/s]
Adding requests:  54%|    | 4397/8192 [00:08<00:07, 528.49it/s]
Adding requests:  54%|    | 4450/8192 [00:08<00:07, 525.24it/s]
Adding requests:  55%|    | 4503/8192 [00:08<00:07, 522.38it/s]
Adding requests:  56%|    | 4558/8192 [00:08<00:06, 528.89it/s]
Adding requests:  56%|    | 4611/8192 [00:09<00:07, 493.84it/s]
Adding requests:  57%|    | 4662/8192 [00:09<00:07, 496.98it/s]
Adding requests:  58%|    | 4713/8192 [00:09<00:07, 491.83it/s]
Adding requests:  58%|    | 4768/8192 [00:09<00:06, 507.45it/s]
Adding requests:  59%|    | 4819/8192 [00:09<00:06, 503.85it/s]
Adding requests:  59%|    | 4872/8192 [00:09<00:06, 509.65it/s]
Adding requests:  60%|    | 4927/8192 [00:09<00:06, 518.73it/s]
Adding requests:  61%|    | 4979/8192 [00:09<00:06, 518.38it/s]
Adding requests:  61%|   | 5031/8192 [00:09<00:06, 518.09it/s]
Adding requests:  62%|   | 5086/8192 [00:09<00:05, 525.96it/s]
Adding requests:  63%|   | 5144/8192 [00:10<00:05, 538.93it/s]
Adding requests:  63%|   | 5198/8192 [00:10<00:05, 528.99it/s]
Adding requests:  64%|   | 5251/8192 [00:10<00:05, 525.94it/s]
Adding requests:  65%|   | 5304/8192 [00:10<00:05, 524.16it/s]
Adding requests:  65%|   | 5360/8192 [00:10<00:05, 530.67it/s]
Adding requests:  66%|   | 5414/8192 [00:10<00:05, 520.13it/s]
Adding requests:  67%|   | 5467/8192 [00:10<00:05, 516.91it/s]
Adding requests:  67%|   | 5519/8192 [00:10<00:05, 502.79it/s]
Adding requests:  68%|   | 5572/8192 [00:10<00:05, 508.18it/s]
Adding requests:  69%|   | 5623/8192 [00:11<00:05, 502.58it/s]
Adding requests:  69%|   | 5674/8192 [00:11<00:05, 499.92it/s]
Adding requests:  70%|   | 5726/8192 [00:11<00:04, 504.18it/s]
Adding requests:  71%|   | 5781/8192 [00:11<00:04, 517.34it/s]
Adding requests:  71%|   | 5833/8192 [00:11<00:04, 509.49it/s]
Adding requests:  72%|  | 5886/8192 [00:11<00:04, 514.39it/s]
Adding requests:  72%|  | 5938/8192 [00:11<00:04, 490.55it/s]
Adding requests:  73%|  | 5990/8192 [00:11<00:04, 498.46it/s]
Adding requests:  74%|  | 6042/8192 [00:11<00:04, 502.59it/s]
Adding requests:  74%|  | 6096/8192 [00:11<00:04, 512.92it/s]
Adding requests:  75%|  | 6153/8192 [00:12<00:03, 528.21it/s]
Adding requests:  76%|  | 6207/8192 [00:12<00:03, 530.52it/s]
Adding requests:  76%|  | 6266/8192 [00:12<00:03, 547.12it/s]
Adding requests:  77%|  | 6324/8192 [00:12<00:03, 555.12it/s]
Adding requests:  78%|  | 6380/8192 [00:12<00:03, 554.58it/s]
Adding requests:  79%|  | 6436/8192 [00:12<00:03, 550.62it/s]
Adding requests:  79%|  | 6492/8192 [00:12<00:03, 552.12it/s]
Adding requests:  80%|  | 6548/8192 [00:12<00:02, 551.17it/s]
Adding requests:  81%|  | 6606/8192 [00:12<00:02, 557.44it/s]
Adding requests:  81%| | 6662/8192 [00:12<00:02, 550.20it/s]
Adding requests:  82%| | 6718/8192 [00:13<00:02, 551.26it/s]
Adding requests:  83%| | 6774/8192 [00:13<00:02, 547.65it/s]
Adding requests:  83%| | 6829/8192 [00:13<00:02, 545.89it/s]
Adding requests:  84%| | 6884/8192 [00:13<00:02, 544.39it/s]
Adding requests:  85%| | 6941/8192 [00:13<00:02, 550.92it/s]
Adding requests:  85%| | 6997/8192 [00:13<00:02, 553.11it/s]
Adding requests:  86%| | 7053/8192 [00:13<00:02, 536.97it/s]
Adding requests:  87%| | 7107/8192 [00:13<00:02, 531.24it/s]
Adding requests:  87%| | 7162/8192 [00:13<00:01, 535.51it/s]
Adding requests:  88%| | 7220/8192 [00:13<00:01, 546.53it/s]
Adding requests:  89%| | 7275/8192 [00:14<00:01, 535.65it/s]
Adding requests:  89%| | 7329/8192 [00:14<00:01, 489.60it/s]
Adding requests:  90%| | 7383/8192 [00:14<00:01, 502.10it/s]
Adding requests:  91%| | 7443/8192 [00:14<00:01, 528.59it/s]
Adding requests:  92%|| 7497/8192 [00:14<00:01, 529.30it/s]
Adding requests:  92%|| 7551/8192 [00:14<00:01, 528.44it/s]
Adding requests:  93%|| 7605/8192 [00:14<00:01, 528.64it/s]
Adding requests:  94%|| 7665/8192 [00:14<00:00, 546.19it/s]
Adding requests:  94%|| 7720/8192 [00:14<00:00, 538.63it/s]
Adding requests:  95%|| 7774/8192 [00:15<00:00, 538.66it/s]
Adding requests:  96%|| 7829/8192 [00:15<00:00, 541.71it/s]
Adding requests:  96%|| 7885/8192 [00:15<00:00, 546.45it/s]
Adding requests:  97%|| 7940/8192 [00:15<00:00, 531.48it/s]
Adding requests:  98%|| 7995/8192 [00:15<00:00, 535.47it/s]
Adding requests:  98%|| 8049/8192 [00:15<00:00, 533.41it/s]
Adding requests:  99%|| 8106/8192 [00:15<00:00, 542.51it/s]
Adding requests: 100%|| 8161/8192 [00:15<00:00, 538.27it/s]
Adding requests: 100%|| 8192/8192 [00:15<00:00, 518.23it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 450/8192 [00:02<00:39, 194.79it/s, est. speed input: 199467.27 toks/s, output: 194.79 toks/s]
Processed prompts:   6%|         | 514/8192 [00:04<01:18, 98.32it/s, est. speed input: 115739.31 toks/s, output: 113.03 toks/s] 
Processed prompts:   7%|         | 578/8192 [00:06<01:54, 66.63it/s, est. speed input: 87150.44 toks/s, output: 85.11 toks/s]  
Processed prompts:   8%|         | 642/8192 [00:09<02:26, 51.65it/s, est. speed input: 72770.00 toks/s, output: 71.06 toks/s]
Processed prompts:   9%|         | 706/8192 [00:11<02:52, 43.34it/s, est. speed input: 64115.06 toks/s, output: 62.61 toks/s]
Processed prompts:   9%|         | 770/8192 [00:13<03:14, 38.25it/s, est. speed input: 58278.75 toks/s, output: 56.91 toks/s]
Processed prompts:  10%|         | 834/8192 [00:15<03:29, 35.11it/s, est. speed input: 54162.83 toks/s, output: 52.89 toks/s]
Processed prompts:  11%|         | 898/8192 [00:17<03:40, 33.13it/s, est. speed input: 51123.22 toks/s, output: 49.92 toks/s]
Processed prompts:  12%|        | 962/8192 [00:20<03:47, 31.77it/s, est. speed input: 48739.32 toks/s, output: 47.60 toks/s]
Processed prompts:  13%|        | 1026/8192 [00:22<03:53, 30.75it/s, est. speed input: 46780.90 toks/s, output: 45.68 toks/s]
Processed prompts:  13%|        | 1090/8192 [00:24<03:56, 30.03it/s, est. speed input: 45168.99 toks/s, output: 44.11 toks/s]
Processed prompts:  14%|        | 1154/8192 [00:26<03:57, 29.64it/s, est. speed input: 43868.44 toks/s, output: 42.84 toks/s]
Processed prompts:  15%|        | 1218/8192 [00:29<03:57, 29.33it/s, est. speed input: 42751.23 toks/s, output: 41.75 toks/s]
Processed prompts:  16%|        | 1282/8192 [00:31<03:57, 29.11it/s, est. speed input: 41791.26 toks/s, output: 40.81 toks/s]
Processed prompts:  16%|        | 1346/8192 [00:33<03:56, 28.94it/s, est. speed input: 40955.09 toks/s, output: 40.00 toks/s]
Processed prompts:  17%|        | 1410/8192 [00:35<03:55, 28.80it/s, est. speed input: 40216.95 toks/s, output: 39.27 toks/s]
Processed prompts:  18%|        | 1474/8192 [00:38<03:54, 28.71it/s, est. speed input: 39566.30 toks/s, output: 38.64 toks/s]
Processed prompts:  19%|        | 1538/8192 [00:40<03:51, 28.70it/s, est. speed input: 39002.61 toks/s, output: 38.09 toks/s]
Processed prompts:  20%|        | 1602/8192 [00:42<03:49, 28.71it/s, est. speed input: 38502.53 toks/s, output: 37.60 toks/s]
Processed prompts:  20%|        | 1666/8192 [00:44<03:47, 28.63it/s, est. speed input: 38032.67 toks/s, output: 37.14 toks/s]
Processed prompts:  21%|        | 1730/8192 [00:47<03:45, 28.61it/s, est. speed input: 37613.98 toks/s, output: 36.73 toks/s]
Processed prompts:  22%|       | 1794/8192 [00:49<03:43, 28.58it/s, est. speed input: 37230.34 toks/s, output: 36.36 toks/s]
Processed prompts:  23%|       | 1858/8192 [00:51<03:41, 28.60it/s, est. speed input: 36889.01 toks/s, output: 36.02 toks/s]
Processed prompts:  23%|       | 1922/8192 [00:53<03:39, 28.59it/s, est. speed input: 36571.61 toks/s, output: 35.71 toks/s]
Processed prompts:  24%|       | 1986/8192 [00:55<03:35, 28.86it/s, est. speed input: 36325.56 toks/s, output: 35.47 toks/s]
Processed prompts:  25%|       | 2050/8192 [00:58<03:31, 29.10it/s, est. speed input: 36105.35 toks/s, output: 35.26 toks/s]
Processed prompts:  26%|       | 2114/8192 [01:00<03:30, 28.92it/s, est. speed input: 35848.13 toks/s, output: 35.01 toks/s]
Processed prompts:  27%|       | 2178/8192 [01:02<03:25, 29.23it/s, est. speed input: 35672.87 toks/s, output: 34.84 toks/s]
Processed prompts:  27%|       | 2242/8192 [01:04<03:24, 29.04it/s, est. speed input: 35452.18 toks/s, output: 34.62 toks/s]
Processed prompts:  28%|       | 2306/8192 [01:06<03:22, 29.06it/s, est. speed input: 35267.22 toks/s, output: 34.44 toks/s]
Processed prompts:  29%|       | 2370/8192 [01:09<03:18, 29.35it/s, est. speed input: 35128.26 toks/s, output: 34.30 toks/s]
Processed prompts:  30%|       | 2434/8192 [01:11<03:16, 29.30it/s, est. speed input: 34967.20 toks/s, output: 34.15 toks/s]
Processed prompts:  30%|       | 2498/8192 [01:13<03:15, 29.09it/s, est. speed input: 34794.65 toks/s, output: 33.98 toks/s]
Processed prompts:  31%|      | 2562/8192 [01:15<03:13, 29.16it/s, est. speed input: 34656.99 toks/s, output: 33.84 toks/s]
Processed prompts:  32%|      | 2626/8192 [01:17<03:12, 28.96it/s, est. speed input: 34499.48 toks/s, output: 33.69 toks/s]
Processed prompts:  33%|      | 2690/8192 [01:20<03:09, 28.99it/s, est. speed input: 34369.17 toks/s, output: 33.56 toks/s]
Processed prompts:  34%|      | 2754/8192 [01:22<03:08, 28.91it/s, est. speed input: 34235.16 toks/s, output: 33.43 toks/s]
Processed prompts:  34%|      | 2818/8192 [01:24<03:04, 29.13it/s, est. speed input: 34136.01 toks/s, output: 33.34 toks/s]
Processed prompts:  35%|      | 2882/8192 [01:26<03:03, 28.93it/s, est. speed input: 34007.46 toks/s, output: 33.21 toks/s]
Processed prompts:  36%|      | 2946/8192 [01:29<03:01, 28.85it/s, est. speed input: 33890.30 toks/s, output: 33.10 toks/s]
Processed prompts:  37%|      | 3010/8192 [01:31<02:58, 29.05it/s, est. speed input: 33803.42 toks/s, output: 33.01 toks/s]
Processed prompts:  38%|      | 3074/8192 [01:33<02:55, 29.19it/s, est. speed input: 33720.82 toks/s, output: 32.93 toks/s]
Processed prompts:  38%|      | 3138/8192 [01:35<02:53, 29.14it/s, est. speed input: 33628.18 toks/s, output: 32.84 toks/s]
Processed prompts:  39%|      | 3202/8192 [01:37<02:50, 29.29it/s, est. speed input: 33555.63 toks/s, output: 32.77 toks/s]
Processed prompts:  40%|      | 3266/8192 [01:39<02:49, 29.04it/s, est. speed input: 33457.22 toks/s, output: 32.67 toks/s]
Processed prompts:  41%|      | 3330/8192 [01:42<02:47, 29.10it/s, est. speed input: 33381.72 toks/s, output: 32.60 toks/s]
Processed prompts:  41%|     | 3394/8192 [01:44<02:45, 28.97it/s, est. speed input: 33295.80 toks/s, output: 32.52 toks/s]
Processed prompts:  42%|     | 3458/8192 [01:46<02:42, 29.16it/s, est. speed input: 33235.46 toks/s, output: 32.46 toks/s]
Processed prompts:  43%|     | 3522/8192 [01:48<02:41, 28.94it/s, est. speed input: 33150.34 toks/s, output: 32.37 toks/s]
Processed prompts:  44%|     | 3586/8192 [01:51<02:39, 28.81it/s, est. speed input: 33070.16 toks/s, output: 32.30 toks/s]
Processed prompts:  45%|     | 3650/8192 [01:53<02:37, 28.89it/s, est. speed input: 33006.51 toks/s, output: 32.23 toks/s]
Processed prompts:  45%|     | 3714/8192 [01:55<02:35, 28.82it/s, est. speed input: 32935.41 toks/s, output: 32.16 toks/s]
Processed prompts:  46%|     | 3778/8192 [01:57<02:33, 28.77it/s, est. speed input: 32867.01 toks/s, output: 32.10 toks/s]
Processed prompts:  47%|     | 3842/8192 [01:59<02:30, 28.91it/s, est. speed input: 32813.78 toks/s, output: 32.04 toks/s]
Processed prompts:  48%|     | 3906/8192 [02:02<02:28, 28.82it/s, est. speed input: 32749.61 toks/s, output: 31.98 toks/s]
Processed prompts:  48%|     | 3970/8192 [02:04<02:26, 28.74it/s, est. speed input: 32686.35 toks/s, output: 31.92 toks/s]
Processed prompts:  49%|     | 4034/8192 [02:06<02:23, 28.95it/s, est. speed input: 32642.91 toks/s, output: 31.88 toks/s]
Processed prompts:  50%|     | 4098/8192 [02:08<02:22, 28.78it/s, est. speed input: 32580.28 toks/s, output: 31.82 toks/s]
Processed prompts:  51%|     | 4162/8192 [02:10<02:18, 29.02it/s, est. speed input: 32542.70 toks/s, output: 31.78 toks/s]
Processed prompts:  52%|    | 4226/8192 [02:13<02:16, 29.05it/s, est. speed input: 32497.82 toks/s, output: 31.74 toks/s]
Processed prompts:  52%|    | 4290/8192 [02:15<02:14, 28.93it/s, est. speed input: 32446.03 toks/s, output: 31.69 toks/s]
Processed prompts:  53%|    | 4354/8192 [02:17<02:13, 28.80it/s, est. speed input: 32392.52 toks/s, output: 31.63 toks/s]
Processed prompts:  54%|    | 4418/8192 [02:19<02:10, 28.92it/s, est. speed input: 32353.33 toks/s, output: 31.60 toks/s]
Processed prompts:  55%|    | 4482/8192 [02:22<02:08, 28.79it/s, est. speed input: 32303.02 toks/s, output: 31.55 toks/s]
Processed prompts:  55%|    | 4546/8192 [02:24<02:05, 29.05it/s, est. speed input: 32274.50 toks/s, output: 31.52 toks/s]
Processed prompts:  56%|    | 4610/8192 [02:26<02:03, 28.94it/s, est. speed input: 32230.38 toks/s, output: 31.47 toks/s]
Processed prompts:  57%|    | 4674/8192 [02:28<02:02, 28.78it/s, est. speed input: 32183.00 toks/s, output: 31.43 toks/s]
Processed prompts:  58%|    | 4738/8192 [02:30<01:59, 28.88it/s, est. speed input: 32148.65 toks/s, output: 31.40 toks/s]
Processed prompts:  59%|    | 4802/8192 [02:33<01:57, 28.83it/s, est. speed input: 32108.35 toks/s, output: 31.36 toks/s]
Processed prompts:  59%|    | 4866/8192 [02:35<01:55, 28.76it/s, est. speed input: 32067.79 toks/s, output: 31.32 toks/s]
Processed prompts:  60%|    | 4930/8192 [02:37<01:53, 28.76it/s, est. speed input: 32030.68 toks/s, output: 31.28 toks/s]
Processed prompts:  61%|    | 4994/8192 [02:39<01:50, 28.87it/s, est. speed input: 32000.60 toks/s, output: 31.25 toks/s]
Processed prompts:  62%|   | 5058/8192 [02:41<01:47, 29.08it/s, est. speed input: 31977.73 toks/s, output: 31.23 toks/s]
Processed prompts:  63%|   | 5122/8192 [02:44<01:46, 28.90it/s, est. speed input: 31939.15 toks/s, output: 31.19 toks/s]
Processed prompts:  63%|   | 5186/8192 [02:46<01:43, 29.09it/s, est. speed input: 31917.15 toks/s, output: 31.17 toks/s]
Processed prompts:  64%|   | 5250/8192 [02:48<01:40, 29.18it/s, est. speed input: 31893.72 toks/s, output: 31.15 toks/s]
Processed prompts:  65%|   | 5314/8192 [02:50<01:38, 29.30it/s, est. speed input: 31873.53 toks/s, output: 31.13 toks/s]
Processed prompts:  66%|   | 5378/8192 [02:52<01:36, 29.08it/s, est. speed input: 31839.67 toks/s, output: 31.09 toks/s]
Processed prompts:  66%|   | 5442/8192 [02:55<01:34, 29.06it/s, est. speed input: 31812.88 toks/s, output: 31.07 toks/s]
Processed prompts:  67%|   | 5506/8192 [02:57<01:32, 28.92it/s, est. speed input: 31780.79 toks/s, output: 31.04 toks/s]
Processed prompts:  68%|   | 5570/8192 [02:59<01:31, 28.75it/s, est. speed input: 31746.61 toks/s, output: 31.00 toks/s]
Processed prompts:  69%|   | 5634/8192 [03:01<01:28, 28.90it/s, est. speed input: 31724.97 toks/s, output: 30.98 toks/s]
Processed prompts:  70%|   | 5698/8192 [03:04<01:26, 28.95it/s, est. speed input: 31701.74 toks/s, output: 30.96 toks/s]
Processed prompts:  70%|   | 5762/8192 [03:06<01:24, 28.85it/s, est. speed input: 31672.87 toks/s, output: 30.93 toks/s]
Processed prompts:  71%|   | 5826/8192 [03:08<01:22, 28.80it/s, est. speed input: 31645.76 toks/s, output: 30.90 toks/s]
Processed prompts:  72%|  | 5890/8192 [03:10<01:19, 28.91it/s, est. speed input: 31625.24 toks/s, output: 30.88 toks/s]
Processed prompts:  73%|  | 5954/8192 [03:12<01:17, 28.77it/s, est. speed input: 31596.13 toks/s, output: 30.86 toks/s]
Processed prompts:  73%|  | 6018/8192 [03:15<01:15, 28.72it/s, est. speed input: 31569.88 toks/s, output: 30.83 toks/s]
Processed prompts:  74%|  | 6082/8192 [03:17<01:13, 28.66it/s, est. speed input: 31542.85 toks/s, output: 30.80 toks/s]
Processed prompts:  75%|  | 6146/8192 [03:19<01:10, 28.95it/s, est. speed input: 31530.10 toks/s, output: 30.79 toks/s]
Processed prompts:  76%|  | 6210/8192 [03:21<01:08, 28.85it/s, est. speed input: 31505.64 toks/s, output: 30.77 toks/s]
Processed prompts:  77%|  | 6274/8192 [03:24<01:06, 28.71it/s, est. speed input: 31478.81 toks/s, output: 30.74 toks/s]
Processed prompts:  77%|  | 6338/8192 [03:26<01:04, 28.83it/s, est. speed input: 31461.00 toks/s, output: 30.72 toks/s]
Processed prompts:  78%|  | 6402/8192 [03:28<01:02, 28.77it/s, est. speed input: 31438.00 toks/s, output: 30.70 toks/s]
Processed prompts:  79%|  | 6466/8192 [03:30<01:00, 28.67it/s, est. speed input: 31413.36 toks/s, output: 30.68 toks/s]
Processed prompts:  80%|  | 6530/8192 [03:32<00:57, 28.83it/s, est. speed input: 31397.67 toks/s, output: 30.66 toks/s]
Processed prompts:  80%|  | 6594/8192 [03:35<00:55, 28.76it/s, est. speed input: 31375.68 toks/s, output: 30.64 toks/s]
Processed prompts:  81%| | 6658/8192 [03:37<00:53, 28.87it/s, est. speed input: 31360.26 toks/s, output: 30.63 toks/s]
Processed prompts:  82%| | 6722/8192 [03:39<00:51, 28.75it/s, est. speed input: 31337.47 toks/s, output: 30.60 toks/s]
Processed prompts:  83%| | 6786/8192 [03:41<00:48, 28.75it/s, est. speed input: 31318.55 toks/s, output: 30.58 toks/s]
Processed prompts:  84%| | 6850/8192 [03:44<00:46, 28.71it/s, est. speed input: 31298.36 toks/s, output: 30.56 toks/s]
Processed prompts:  84%| | 6914/8192 [03:46<00:44, 28.73it/s, est. speed input: 31280.48 toks/s, output: 30.55 toks/s]
Processed prompts:  85%| | 6978/8192 [03:48<00:42, 28.85it/s, est. speed input: 31266.60 toks/s, output: 30.53 toks/s]
Processed prompts:  86%| | 7042/8192 [03:50<00:39, 28.81it/s, est. speed input: 31248.73 toks/s, output: 30.52 toks/s]
Processed prompts:  87%| | 7106/8192 [03:52<00:37, 29.18it/s, est. speed input: 31244.57 toks/s, output: 30.51 toks/s]
Processed prompts:  88%| | 7170/8192 [03:55<00:35, 29.01it/s, est. speed input: 31226.05 toks/s, output: 30.49 toks/s]
Processed prompts:  88%| | 7234/8192 [03:57<00:32, 29.06it/s, est. speed input: 31213.69 toks/s, output: 30.48 toks/s]
Processed prompts:  89%| | 7298/8192 [03:59<00:30, 28.93it/s, est. speed input: 31195.85 toks/s, output: 30.46 toks/s]
Processed prompts:  90%| | 7362/8192 [04:01<00:28, 28.98it/s, est. speed input: 31183.04 toks/s, output: 30.45 toks/s]
Processed prompts:  91%| | 7426/8192 [04:03<00:26, 28.88it/s, est. speed input: 31166.38 toks/s, output: 30.44 toks/s]
Processed prompts:  91%|| 7490/8192 [04:06<00:24, 29.11it/s, est. speed input: 31159.29 toks/s, output: 30.43 toks/s]
Processed prompts:  92%|| 7554/8192 [04:08<00:21, 29.25it/s, est. speed input: 31151.64 toks/s, output: 30.42 toks/s]
Processed prompts:  93%|| 7618/8192 [04:10<00:19, 29.48it/s, est. speed input: 31148.30 toks/s, output: 30.42 toks/s]
Processed prompts:  94%|| 7682/8192 [04:12<00:17, 29.22it/s, est. speed input: 31132.21 toks/s, output: 30.40 toks/s]
Processed prompts:  95%|| 7746/8192 [04:14<00:15, 29.00it/s, est. speed input: 31115.06 toks/s, output: 30.39 toks/s]
Processed prompts:  95%|| 7810/8192 [04:17<00:13, 28.86it/s, est. speed input: 31098.61 toks/s, output: 30.37 toks/s]
Processed prompts:  96%|| 7874/8192 [04:19<00:11, 28.74it/s, est. speed input: 31081.49 toks/s, output: 30.35 toks/s]
Processed prompts:  97%|| 7938/8192 [04:21<00:08, 28.70it/s, est. speed input: 31066.25 toks/s, output: 30.34 toks/s]
Processed prompts:  98%|| 8002/8192 [04:23<00:06, 28.70it/s, est. speed input: 31052.24 toks/s, output: 30.32 toks/s]
Processed prompts:  98%|| 8066/8192 [04:26<00:04, 28.86it/s, est. speed input: 31042.97 toks/s, output: 30.32 toks/s]
Processed prompts:  99%|| 8130/8192 [04:28<00:02, 28.96it/s, est. speed input: 31033.53 toks/s, output: 30.31 toks/s]
Processed prompts: 100%|| 8192/8192 [04:28<00:00, 28.96it/s, est. speed input: 31270.14 toks/s, output: 30.54 toks/s]
Processed prompts: 100%|| 8192/8192 [04:28<00:00, 30.54it/s, est. speed input: 31270.14 toks/s, output: 30.54 toks/s]
[rank0]:[W126 07:33:56.412873694 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 10:33:24
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:33:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:33:28 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1185985) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1185985) WARNING 01-26 10:34:07 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 23.00 requests/s, 11800.67 total tokens/s, 23.00 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 10:33:27] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:33:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:33:27] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:33:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:33:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:33:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:33:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:33:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:33:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:33:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:33:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:33:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:33:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:33:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:33:31] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:33:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:33:31] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:33:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:33:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:33:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:33:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:33:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:33:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:33:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:33:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:33:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:33:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:33:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1185985) [2026-01-26 10:33:32] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1185985) [2026-01-26 10:33:32] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1185985) [2026-01-26 10:33:32] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1185985) [2026-01-26 10:33:32] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1185985) [2026-01-26 10:33:32] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1185985) [2026-01-26 10:33:32] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1185985) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1185985) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.81s/it]
(EngineCore_DP0 pid=1185985) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.81s/it]
(EngineCore_DP0 pid=1185985) 
(EngineCore_DP0 pid=1185985) [2026-01-26 10:34:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1185985) [2026-01-26 10:34:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=1185985) [2026-01-26 10:34:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1185985) [2026-01-26 10:34:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10616832 bytes
(EngineCore_DP0 pid=1185985) [2026-01-26 10:34:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1185985) [2026-01-26 10:34:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56623104 bytes
(EngineCore_DP0 pid=1185985) [2026-01-26 10:34:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1185985) [2026-01-26 10:34:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28311552 bytes
(EngineCore_DP0 pid=1185985) 2026-01-26 10:34:06,825 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1185985) 2026-01-26 10:34:06,837 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  99%|| 127/128 [00:00<00:00, 1261.85it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1259.55it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 2/128 [00:00<00:08, 14.93it/s, est. speed input: 7644.48 toks/s, output: 14.93 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:06, 19.97it/s, est. speed input: 9828.35 toks/s, output: 19.19 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:05, 21.58it/s, est. speed input: 10557.95 toks/s, output: 20.62 toks/s]
Processed prompts:   9%|         | 11/128 [00:00<00:05, 22.49it/s, est. speed input: 10971.44 toks/s, output: 21.43 toks/s]
Processed prompts:  11%|         | 14/128 [00:00<00:05, 22.39it/s, est. speed input: 11053.94 toks/s, output: 21.59 toks/s]
Processed prompts:  13%|        | 17/128 [00:00<00:04, 22.56it/s, est. speed input: 11166.43 toks/s, output: 21.81 toks/s]
Processed prompts:  16%|        | 20/128 [00:00<00:04, 23.08it/s, est. speed input: 11334.38 toks/s, output: 22.14 toks/s]
Processed prompts:  18%|        | 23/128 [00:01<00:04, 23.25it/s, est. speed input: 11428.23 toks/s, output: 22.32 toks/s]
Processed prompts:  20%|        | 26/128 [00:01<00:04, 23.51it/s, est. speed input: 11525.48 toks/s, output: 22.51 toks/s]
Processed prompts:  23%|       | 29/128 [00:01<00:04, 23.74it/s, est. speed input: 11613.60 toks/s, output: 22.68 toks/s]
Processed prompts:  25%|       | 32/128 [00:01<00:04, 23.75it/s, est. speed input: 11663.61 toks/s, output: 22.78 toks/s]
Processed prompts:  27%|       | 35/128 [00:01<00:03, 23.91it/s, est. speed input: 11725.77 toks/s, output: 22.90 toks/s]
Processed prompts:  30%|       | 38/128 [00:01<00:03, 23.45it/s, est. speed input: 11707.26 toks/s, output: 22.87 toks/s]
Processed prompts:  32%|      | 41/128 [00:01<00:03, 23.55it/s, est. speed input: 11740.87 toks/s, output: 22.93 toks/s]
Processed prompts:  34%|      | 44/128 [00:01<00:03, 23.75it/s, est. speed input: 11783.07 toks/s, output: 23.01 toks/s]
Processed prompts:  37%|      | 47/128 [00:02<00:03, 23.88it/s, est. speed input: 11819.87 toks/s, output: 23.09 toks/s]
Processed prompts:  39%|      | 50/128 [00:02<00:03, 23.87it/s, est. speed input: 11842.69 toks/s, output: 23.13 toks/s]
Processed prompts:  41%|     | 53/128 [00:02<00:03, 23.72it/s, est. speed input: 11850.17 toks/s, output: 23.14 toks/s]
Processed prompts:  44%|     | 56/128 [00:02<00:03, 23.58it/s, est. speed input: 11853.02 toks/s, output: 23.15 toks/s]
Processed prompts:  46%|     | 59/128 [00:02<00:02, 23.78it/s, est. speed input: 11880.22 toks/s, output: 23.20 toks/s]
Processed prompts:  48%|     | 62/128 [00:02<00:02, 23.40it/s, est. speed input: 11864.11 toks/s, output: 23.17 toks/s]
Processed prompts:  51%|     | 65/128 [00:02<00:02, 23.58it/s, est. speed input: 11883.50 toks/s, output: 23.21 toks/s]
Processed prompts:  53%|    | 68/128 [00:02<00:02, 23.65it/s, est. speed input: 11896.94 toks/s, output: 23.24 toks/s]
Processed prompts:  55%|    | 71/128 [00:03<00:02, 23.78it/s, est. speed input: 11914.50 toks/s, output: 23.27 toks/s]
Processed prompts:  58%|    | 74/128 [00:03<00:02, 23.70it/s, est. speed input: 11919.87 toks/s, output: 23.28 toks/s]
Processed prompts:  60%|    | 77/128 [00:03<00:02, 23.73it/s, est. speed input: 11929.52 toks/s, output: 23.30 toks/s]
Processed prompts:  62%|   | 80/128 [00:03<00:02, 23.58it/s, est. speed input: 11928.32 toks/s, output: 23.30 toks/s]
Processed prompts:  65%|   | 83/128 [00:03<00:01, 23.48it/s, est. speed input: 11927.49 toks/s, output: 23.30 toks/s]
Processed prompts:  67%|   | 86/128 [00:03<00:01, 23.25it/s, est. speed input: 11917.19 toks/s, output: 23.28 toks/s]
Processed prompts:  70%|   | 89/128 [00:03<00:01, 23.30it/s, est. speed input: 11919.36 toks/s, output: 23.28 toks/s]
Processed prompts:  72%|  | 92/128 [00:03<00:01, 23.22it/s, est. speed input: 11915.54 toks/s, output: 23.27 toks/s]
Processed prompts:  74%|  | 95/128 [00:04<00:01, 23.30it/s, est. speed input: 11919.14 toks/s, output: 23.28 toks/s]
Processed prompts:  77%|  | 98/128 [00:04<00:01, 23.48it/s, est. speed input: 11928.75 toks/s, output: 23.30 toks/s]
Processed prompts:  79%|  | 101/128 [00:04<00:01, 23.69it/s, est. speed input: 11941.79 toks/s, output: 23.32 toks/s]
Processed prompts:  81%| | 104/128 [00:04<00:01, 23.76it/s, est. speed input: 11950.51 toks/s, output: 23.34 toks/s]
Processed prompts:  84%| | 107/128 [00:04<00:00, 23.78it/s, est. speed input: 11957.51 toks/s, output: 23.35 toks/s]
Processed prompts:  86%| | 110/128 [00:04<00:00, 23.87it/s, est. speed input: 11967.14 toks/s, output: 23.37 toks/s]
Processed prompts:  88%| | 113/128 [00:04<00:00, 23.55it/s, est. speed input: 11959.72 toks/s, output: 23.36 toks/s]
Processed prompts:  91%| | 116/128 [00:04<00:00, 23.70it/s, est. speed input: 11968.77 toks/s, output: 23.38 toks/s]
Processed prompts:  93%|| 119/128 [00:05<00:00, 23.79it/s, est. speed input: 11976.64 toks/s, output: 23.39 toks/s]
Processed prompts:  95%|| 122/128 [00:05<00:00, 23.93it/s, est. speed input: 11987.13 toks/s, output: 23.41 toks/s]
Processed prompts:  98%|| 125/128 [00:05<00:00, 23.87it/s, est. speed input: 11990.98 toks/s, output: 23.42 toks/s]
Processed prompts: 100%|| 128/128 [00:05<00:00, 23.94it/s, est. speed input: 11998.98 toks/s, output: 23.44 toks/s]
Processed prompts: 100%|| 128/128 [00:05<00:00, 23.94it/s, est. speed input: 11998.98 toks/s, output: 23.44 toks/s]
Processed prompts: 100%|| 128/128 [00:05<00:00, 23.43it/s, est. speed input: 11998.98 toks/s, output: 23.44 toks/s]
[rank0]:[W126 10:34:13.449557982 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 10:34:15
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:34:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:34:19 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1186906) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1186906) WARNING 01-26 10:34:58 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 12.65 requests/s, 12965.66 total tokens/s, 12.65 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 10:34:19] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:34:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:34:19] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:34:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:34:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:34:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:34:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:34:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:34:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:34:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:34:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:34:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:34:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:34:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:34:22] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:34:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:34:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:34:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:34:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:34:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:34:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:34:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:34:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:34:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:34:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:34:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:34:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:34:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1186906) [2026-01-26 10:34:23] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1186906) [2026-01-26 10:34:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1186906) [2026-01-26 10:34:23] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1186906) [2026-01-26 10:34:23] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1186906) [2026-01-26 10:34:23] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1186906) [2026-01-26 10:34:23] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1186906) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1186906) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.05s/it]
(EngineCore_DP0 pid=1186906) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.05s/it]
(EngineCore_DP0 pid=1186906) 
(EngineCore_DP0 pid=1186906) [2026-01-26 10:34:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1186906) [2026-01-26 10:34:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=1186906) [2026-01-26 10:34:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1186906) [2026-01-26 10:34:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10616832 bytes
(EngineCore_DP0 pid=1186906) [2026-01-26 10:34:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1186906) [2026-01-26 10:34:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56623104 bytes
(EngineCore_DP0 pid=1186906) [2026-01-26 10:34:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1186906) [2026-01-26 10:34:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28311552 bytes
(EngineCore_DP0 pid=1186906) 2026-01-26 10:34:57,508 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1186906) 2026-01-26 10:34:57,519 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  48%|     | 62/128 [00:00<00:00, 617.83it/s]
Adding requests:  97%|| 124/128 [00:00<00:00, 582.44it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 586.09it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 4/128 [00:00<00:05, 23.86it/s, est. speed input: 24434.67 toks/s, output: 23.86 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:07, 16.35it/s, est. speed input: 17695.61 toks/s, output: 17.28 toks/s]
Processed prompts:   7%|         | 9/128 [00:00<00:07, 15.04it/s, est. speed input: 16472.22 toks/s, output: 16.09 toks/s]
Processed prompts:   9%|         | 11/128 [00:00<00:08, 14.25it/s, est. speed input: 15739.11 toks/s, output: 15.37 toks/s]
Processed prompts:  10%|         | 13/128 [00:00<00:08, 13.79it/s, est. speed input: 15287.70 toks/s, output: 14.93 toks/s]
Processed prompts:  12%|        | 15/128 [00:01<00:08, 13.47it/s, est. speed input: 14956.62 toks/s, output: 14.61 toks/s]
Processed prompts:  13%|        | 17/128 [00:01<00:08, 13.13it/s, est. speed input: 14653.54 toks/s, output: 14.31 toks/s]
Processed prompts:  15%|        | 19/128 [00:01<00:08, 13.00it/s, est. speed input: 14460.72 toks/s, output: 14.12 toks/s]
Processed prompts:  16%|        | 21/128 [00:01<00:08, 12.99it/s, est. speed input: 14338.70 toks/s, output: 14.00 toks/s]
Processed prompts:  18%|        | 23/128 [00:01<00:08, 12.90it/s, est. speed input: 14211.54 toks/s, output: 13.88 toks/s]
Processed prompts:  20%|        | 25/128 [00:01<00:07, 12.97it/s, est. speed input: 14149.40 toks/s, output: 13.82 toks/s]
Processed prompts:  21%|        | 27/128 [00:01<00:07, 12.89it/s, est. speed input: 14057.85 toks/s, output: 13.73 toks/s]
Processed prompts:  23%|       | 29/128 [00:02<00:07, 12.88it/s, est. speed input: 13991.41 toks/s, output: 13.66 toks/s]
Processed prompts:  24%|       | 31/128 [00:02<00:07, 12.69it/s, est. speed input: 13891.02 toks/s, output: 13.57 toks/s]
Processed prompts:  26%|       | 33/128 [00:02<00:07, 12.69it/s, est. speed input: 13833.67 toks/s, output: 13.51 toks/s]
Processed prompts:  27%|       | 35/128 [00:02<00:07, 12.76it/s, est. speed input: 13798.26 toks/s, output: 13.47 toks/s]
Processed prompts:  29%|       | 37/128 [00:02<00:07, 12.79it/s, est. speed input: 13761.62 toks/s, output: 13.44 toks/s]
Processed prompts:  30%|       | 39/128 [00:02<00:06, 12.79it/s, est. speed input: 13726.39 toks/s, output: 13.40 toks/s]
Processed prompts:  32%|      | 41/128 [00:03<00:06, 12.77it/s, est. speed input: 13690.64 toks/s, output: 13.37 toks/s]
Processed prompts:  34%|      | 43/128 [00:03<00:06, 12.80it/s, est. speed input: 13665.02 toks/s, output: 13.34 toks/s]
Processed prompts:  35%|      | 45/128 [00:03<00:06, 12.60it/s, est. speed input: 13607.19 toks/s, output: 13.29 toks/s]
Processed prompts:  37%|      | 47/128 [00:03<00:06, 12.65it/s, est. speed input: 13583.10 toks/s, output: 13.26 toks/s]
Processed prompts:  38%|      | 49/128 [00:03<00:06, 12.77it/s, est. speed input: 13574.33 toks/s, output: 13.26 toks/s]
Processed prompts:  40%|      | 51/128 [00:03<00:06, 12.76it/s, est. speed input: 13552.02 toks/s, output: 13.23 toks/s]
Processed prompts:  41%|     | 53/128 [00:04<00:05, 12.78it/s, est. speed input: 13536.69 toks/s, output: 13.22 toks/s]
Processed prompts:  43%|     | 55/128 [00:04<00:05, 12.83it/s, est. speed input: 13526.13 toks/s, output: 13.21 toks/s]
Processed prompts:  45%|     | 57/128 [00:04<00:05, 12.68it/s, est. speed input: 13492.31 toks/s, output: 13.18 toks/s]
Processed prompts:  46%|     | 59/128 [00:04<00:05, 12.69it/s, est. speed input: 13476.60 toks/s, output: 13.16 toks/s]
Processed prompts:  48%|     | 61/128 [00:04<00:05, 12.75it/s, est. speed input: 13467.42 toks/s, output: 13.15 toks/s]
Processed prompts:  49%|     | 63/128 [00:04<00:05, 12.79it/s, est. speed input: 13457.89 toks/s, output: 13.14 toks/s]
Processed prompts:  51%|     | 65/128 [00:04<00:04, 12.78it/s, est. speed input: 13445.66 toks/s, output: 13.13 toks/s]
Processed prompts:  52%|    | 67/128 [00:05<00:04, 12.79it/s, est. speed input: 13435.29 toks/s, output: 13.12 toks/s]
Processed prompts:  54%|    | 69/128 [00:05<00:04, 12.84it/s, est. speed input: 13430.41 toks/s, output: 13.12 toks/s]
Processed prompts:  55%|    | 71/128 [00:05<00:04, 12.66it/s, est. speed input: 13404.71 toks/s, output: 13.09 toks/s]
Processed prompts:  57%|    | 73/128 [00:05<00:04, 12.66it/s, est. speed input: 13392.34 toks/s, output: 13.08 toks/s]
Processed prompts:  59%|    | 75/128 [00:05<00:04, 12.72it/s, est. speed input: 13386.36 toks/s, output: 13.07 toks/s]
Processed prompts:  60%|    | 77/128 [00:05<00:04, 12.67it/s, est. speed input: 13371.85 toks/s, output: 13.06 toks/s]
Processed prompts:  62%|   | 79/128 [00:06<00:03, 12.75it/s, est. speed input: 13368.63 toks/s, output: 13.06 toks/s]
Processed prompts:  63%|   | 81/128 [00:06<00:03, 12.79it/s, est. speed input: 13364.74 toks/s, output: 13.05 toks/s]
Processed prompts:  65%|   | 83/128 [00:06<00:03, 12.87it/s, est. speed input: 13365.06 toks/s, output: 13.05 toks/s]
Processed prompts:  66%|   | 85/128 [00:06<00:03, 12.71it/s, est. speed input: 13346.67 toks/s, output: 13.03 toks/s]
Processed prompts:  68%|   | 87/128 [00:06<00:03, 12.70it/s, est. speed input: 13338.41 toks/s, output: 13.03 toks/s]
Processed prompts:  70%|   | 89/128 [00:06<00:03, 12.81it/s, est. speed input: 13339.42 toks/s, output: 13.03 toks/s]
Processed prompts:  71%|   | 91/128 [00:06<00:02, 12.81it/s, est. speed input: 13334.12 toks/s, output: 13.02 toks/s]
Processed prompts:  73%|  | 93/128 [00:07<00:02, 12.77it/s, est. speed input: 13326.36 toks/s, output: 13.01 toks/s]
Processed prompts:  74%|  | 95/128 [00:07<00:02, 12.76it/s, est. speed input: 13320.46 toks/s, output: 13.01 toks/s]
Processed prompts:  76%|  | 97/128 [00:07<00:02, 12.66it/s, est. speed input: 13307.85 toks/s, output: 13.00 toks/s]
Processed prompts:  77%|  | 99/128 [00:07<00:02, 12.66it/s, est. speed input: 13300.41 toks/s, output: 12.99 toks/s]
Processed prompts:  79%|  | 101/128 [00:07<00:02, 12.66it/s, est. speed input: 13293.85 toks/s, output: 12.98 toks/s]
Processed prompts:  80%|  | 103/128 [00:07<00:01, 12.76it/s, est. speed input: 13294.44 toks/s, output: 12.98 toks/s]
Processed prompts:  82%| | 105/128 [00:08<00:01, 12.82it/s, est. speed input: 13293.90 toks/s, output: 12.98 toks/s]
Processed prompts:  84%| | 107/128 [00:08<00:01, 12.85it/s, est. speed input: 13292.38 toks/s, output: 12.98 toks/s]
Processed prompts:  85%| | 109/128 [00:08<00:01, 12.84it/s, est. speed input: 13289.13 toks/s, output: 12.98 toks/s]
Processed prompts:  87%| | 111/128 [00:08<00:01, 12.63it/s, est. speed input: 13273.42 toks/s, output: 12.96 toks/s]
Processed prompts:  88%| | 113/128 [00:08<00:01, 12.66it/s, est. speed input: 13269.40 toks/s, output: 12.96 toks/s]
Processed prompts:  90%| | 115/128 [00:08<00:01, 12.69it/s, est. speed input: 13265.74 toks/s, output: 12.95 toks/s]
Processed prompts:  91%|| 117/128 [00:09<00:00, 12.70it/s, est. speed input: 13261.75 toks/s, output: 12.95 toks/s]
Processed prompts:  93%|| 119/128 [00:09<00:00, 12.73it/s, est. speed input: 13259.06 toks/s, output: 12.95 toks/s]
Processed prompts:  95%|| 121/128 [00:09<00:00, 12.77it/s, est. speed input: 13257.71 toks/s, output: 12.95 toks/s]
Processed prompts:  96%|| 123/128 [00:09<00:00, 12.77it/s, est. speed input: 13254.80 toks/s, output: 12.94 toks/s]
Processed prompts:  98%|| 125/128 [00:09<00:00, 12.66it/s, est. speed input: 13245.83 toks/s, output: 12.94 toks/s]
Processed prompts:  99%|| 127/128 [00:09<00:00, 12.67it/s, est. speed input: 13241.69 toks/s, output: 12.93 toks/s]
Processed prompts: 100%|| 128/128 [00:09<00:00, 12.67it/s, est. speed input: 13239.93 toks/s, output: 12.93 toks/s]
Processed prompts: 100%|| 128/128 [00:09<00:00, 12.93it/s, est. speed input: 13239.93 toks/s, output: 12.93 toks/s]
[rank0]:[W126 10:35:08.592117247 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 10:35:10
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:35:14 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:35:14 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1187864) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1187864) WARNING 01-26 10:35:53 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 13.01 requests/s, 13339.57 total tokens/s, 13.01 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 10:35:14] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:35:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:35:14] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:35:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:35:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:35:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:35:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:35:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:35:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:35:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:35:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:35:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:35:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:35:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:35:18] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:35:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:35:18] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:35:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:35:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:35:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:35:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:35:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:35:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:35:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:35:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:35:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:35:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:35:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1187864) [2026-01-26 10:35:19] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1187864) [2026-01-26 10:35:19] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1187864) [2026-01-26 10:35:19] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1187864) [2026-01-26 10:35:19] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1187864) [2026-01-26 10:35:19] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1187864) [2026-01-26 10:35:19] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1187864) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1187864) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:26<00:00, 26.98s/it]
(EngineCore_DP0 pid=1187864) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:26<00:00, 26.98s/it]
(EngineCore_DP0 pid=1187864) 
(EngineCore_DP0 pid=1187864) [2026-01-26 10:35:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1187864) [2026-01-26 10:35:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=1187864) [2026-01-26 10:35:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1187864) [2026-01-26 10:35:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10616832 bytes
(EngineCore_DP0 pid=1187864) [2026-01-26 10:35:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1187864) [2026-01-26 10:35:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56623104 bytes
(EngineCore_DP0 pid=1187864) [2026-01-26 10:35:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1187864) [2026-01-26 10:35:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28311552 bytes
(EngineCore_DP0 pid=1187864) 2026-01-26 10:35:52,962 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1187864) 2026-01-26 10:35:52,972 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  22%|       | 57/256 [00:00<00:00, 559.49it/s]
Adding requests:  44%|     | 113/256 [00:00<00:00, 554.91it/s]
Adding requests:  66%|   | 169/256 [00:00<00:00, 550.39it/s]
Adding requests:  88%| | 226/256 [00:00<00:00, 554.43it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 554.93it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 6/256 [00:00<00:07, 34.07it/s, est. speed input: 34890.92 toks/s, output: 34.07 toks/s]
Processed prompts:   4%|         | 10/256 [00:00<00:12, 19.19it/s, est. speed input: 21327.21 toks/s, output: 20.83 toks/s]
Processed prompts:   5%|         | 13/256 [00:00<00:12, 19.39it/s, est. speed input: 21072.27 toks/s, output: 20.58 toks/s]
Processed prompts:   6%|         | 16/256 [00:00<00:16, 14.58it/s, est. speed input: 17400.16 toks/s, output: 16.99 toks/s]
Processed prompts:   7%|         | 18/256 [00:01<00:16, 14.26it/s, est. speed input: 16886.01 toks/s, output: 16.49 toks/s]
Processed prompts:   8%|         | 20/256 [00:01<00:16, 13.96it/s, est. speed input: 16466.08 toks/s, output: 16.08 toks/s]
Processed prompts:   9%|         | 22/256 [00:01<00:16, 13.78it/s, est. speed input: 16159.59 toks/s, output: 15.78 toks/s]
Processed prompts:   9%|         | 24/256 [00:01<00:16, 13.67it/s, est. speed input: 15920.83 toks/s, output: 15.55 toks/s]
Processed prompts:  10%|         | 26/256 [00:01<00:16, 13.56it/s, est. speed input: 15717.55 toks/s, output: 15.35 toks/s]
Processed prompts:  11%|         | 28/256 [00:01<00:17, 13.23it/s, est. speed input: 15463.76 toks/s, output: 15.10 toks/s]
Processed prompts:  12%|        | 30/256 [00:02<00:17, 13.22it/s, est. speed input: 15316.92 toks/s, output: 14.96 toks/s]
Processed prompts:  12%|        | 32/256 [00:02<00:16, 13.20it/s, est. speed input: 15184.34 toks/s, output: 14.83 toks/s]
Processed prompts:  13%|        | 34/256 [00:02<00:16, 13.25it/s, est. speed input: 15087.64 toks/s, output: 14.73 toks/s]
Processed prompts:  14%|        | 36/256 [00:02<00:16, 13.24it/s, est. speed input: 14992.54 toks/s, output: 14.64 toks/s]
Processed prompts:  15%|        | 38/256 [00:02<00:16, 13.25it/s, est. speed input: 14910.62 toks/s, output: 14.56 toks/s]
Processed prompts:  16%|        | 40/256 [00:02<00:16, 13.25it/s, est. speed input: 14838.88 toks/s, output: 14.49 toks/s]
Processed prompts:  16%|        | 42/256 [00:02<00:16, 13.11it/s, est. speed input: 14744.68 toks/s, output: 14.40 toks/s]
Processed prompts:  17%|        | 44/256 [00:03<00:16, 13.17it/s, est. speed input: 14689.86 toks/s, output: 14.35 toks/s]
Processed prompts:  18%|        | 46/256 [00:03<00:16, 13.12it/s, est. speed input: 14624.68 toks/s, output: 14.28 toks/s]
Processed prompts:  19%|        | 48/256 [00:03<00:15, 13.19it/s, est. speed input: 14582.40 toks/s, output: 14.24 toks/s]
Processed prompts:  20%|        | 50/256 [00:03<00:15, 13.21it/s, est. speed input: 14538.72 toks/s, output: 14.20 toks/s]
Processed prompts:  20%|        | 52/256 [00:03<00:15, 13.13it/s, est. speed input: 14485.51 toks/s, output: 14.15 toks/s]
Processed prompts:  21%|        | 54/256 [00:03<00:15, 13.13it/s, est. speed input: 14443.49 toks/s, output: 14.10 toks/s]
Processed prompts:  22%|       | 56/256 [00:03<00:15, 12.94it/s, est. speed input: 14378.23 toks/s, output: 14.04 toks/s]
Processed prompts:  23%|       | 58/256 [00:04<00:15, 13.03it/s, est. speed input: 14349.30 toks/s, output: 14.01 toks/s]
Processed prompts:  23%|       | 60/256 [00:04<00:14, 13.10it/s, est. speed input: 14321.98 toks/s, output: 13.99 toks/s]
Processed prompts:  24%|       | 62/256 [00:04<00:14, 13.10it/s, est. speed input: 14291.02 toks/s, output: 13.96 toks/s]
Processed prompts:  25%|       | 64/256 [00:04<00:14, 13.16it/s, est. speed input: 14268.91 toks/s, output: 13.93 toks/s]
Processed prompts:  26%|       | 66/256 [00:04<00:14, 13.21it/s, est. speed input: 14249.33 toks/s, output: 13.92 toks/s]
Processed prompts:  27%|       | 68/256 [00:04<00:14, 13.26it/s, est. speed input: 14232.91 toks/s, output: 13.90 toks/s]
Processed prompts:  27%|       | 70/256 [00:05<00:14, 13.07it/s, est. speed input: 14191.95 toks/s, output: 13.86 toks/s]
Processed prompts:  28%|       | 72/256 [00:05<00:14, 13.13it/s, est. speed input: 14174.70 toks/s, output: 13.84 toks/s]
Processed prompts:  29%|       | 74/256 [00:05<00:13, 13.17it/s, est. speed input: 14158.57 toks/s, output: 13.83 toks/s]
Processed prompts:  30%|       | 76/256 [00:05<00:13, 13.15it/s, est. speed input: 14137.31 toks/s, output: 13.81 toks/s]
Processed prompts:  30%|       | 78/256 [00:05<00:13, 13.12it/s, est. speed input: 14117.12 toks/s, output: 13.79 toks/s]
Processed prompts:  31%|      | 80/256 [00:05<00:13, 13.16it/s, est. speed input: 14102.69 toks/s, output: 13.77 toks/s]
Processed prompts:  32%|      | 82/256 [00:05<00:13, 13.08it/s, est. speed input: 14078.98 toks/s, output: 13.75 toks/s]
Processed prompts:  33%|      | 84/256 [00:06<00:13, 13.00it/s, est. speed input: 14055.34 toks/s, output: 13.73 toks/s]
Processed prompts:  34%|      | 86/256 [00:06<00:12, 13.08it/s, est. speed input: 14044.32 toks/s, output: 13.72 toks/s]
Processed prompts:  34%|      | 88/256 [00:06<00:12, 13.14it/s, est. speed input: 14033.87 toks/s, output: 13.70 toks/s]
Processed prompts:  35%|      | 90/256 [00:06<00:12, 13.10it/s, est. speed input: 14016.80 toks/s, output: 13.69 toks/s]
Processed prompts:  36%|      | 92/256 [00:06<00:12, 13.10it/s, est. speed input: 14003.26 toks/s, output: 13.68 toks/s]
Processed prompts:  37%|      | 94/256 [00:06<00:12, 13.15it/s, est. speed input: 13993.86 toks/s, output: 13.67 toks/s]
Processed prompts:  38%|      | 96/256 [00:07<00:12, 12.99it/s, est. speed input: 13970.39 toks/s, output: 13.64 toks/s]
Processed prompts:  38%|      | 98/256 [00:07<00:12, 12.91it/s, est. speed input: 13949.81 toks/s, output: 13.62 toks/s]
Processed prompts:  39%|      | 100/256 [00:07<00:11, 13.05it/s, est. speed input: 13945.03 toks/s, output: 13.62 toks/s]
Processed prompts:  40%|      | 102/256 [00:07<00:11, 13.07it/s, est. speed input: 13934.79 toks/s, output: 13.61 toks/s]
Processed prompts:  41%|      | 104/256 [00:07<00:11, 13.15it/s, est. speed input: 13929.11 toks/s, output: 13.60 toks/s]
Processed prompts:  41%|     | 106/256 [00:07<00:11, 13.20it/s, est. speed input: 13923.67 toks/s, output: 13.60 toks/s]
Processed prompts:  42%|     | 108/256 [00:07<00:11, 13.23it/s, est. speed input: 13917.62 toks/s, output: 13.59 toks/s]
Processed prompts:  43%|     | 110/256 [00:08<00:11, 13.01it/s, est. speed input: 13896.46 toks/s, output: 13.57 toks/s]
Processed prompts:  44%|     | 112/256 [00:08<00:11, 13.06it/s, est. speed input: 13889.07 toks/s, output: 13.56 toks/s]
Processed prompts:  45%|     | 114/256 [00:08<00:10, 13.10it/s, est. speed input: 13881.88 toks/s, output: 13.56 toks/s]
Processed prompts:  45%|     | 116/256 [00:08<00:10, 13.11it/s, est. speed input: 13874.68 toks/s, output: 13.55 toks/s]
Processed prompts:  46%|     | 118/256 [00:08<00:10, 13.13it/s, est. speed input: 13867.80 toks/s, output: 13.54 toks/s]
Processed prompts:  47%|     | 120/256 [00:08<00:10, 13.16it/s, est. speed input: 13862.31 toks/s, output: 13.54 toks/s]
Processed prompts:  48%|     | 122/256 [00:09<00:10, 13.14it/s, est. speed input: 13854.78 toks/s, output: 13.53 toks/s]
Processed prompts:  48%|     | 124/256 [00:09<00:10, 13.00it/s, est. speed input: 13839.86 toks/s, output: 13.52 toks/s]
Processed prompts:  49%|     | 126/256 [00:09<00:09, 13.01it/s, est. speed input: 13831.44 toks/s, output: 13.51 toks/s]
Processed prompts:  50%|     | 128/256 [00:09<00:09, 13.11it/s, est. speed input: 13828.97 toks/s, output: 13.50 toks/s]
Processed prompts:  51%|     | 130/256 [00:09<00:09, 13.11it/s, est. speed input: 13822.49 toks/s, output: 13.50 toks/s]
Processed prompts:  52%|    | 132/256 [00:09<00:09, 13.06it/s, est. speed input: 13813.79 toks/s, output: 13.49 toks/s]
Processed prompts:  52%|    | 134/256 [00:09<00:09, 13.13it/s, est. speed input: 13810.46 toks/s, output: 13.49 toks/s]
Processed prompts:  53%|    | 136/256 [00:10<00:09, 13.08it/s, est. speed input: 13802.28 toks/s, output: 13.48 toks/s]
Processed prompts:  54%|    | 138/256 [00:10<00:09, 12.86it/s, est. speed input: 13784.79 toks/s, output: 13.46 toks/s]
Processed prompts:  55%|    | 140/256 [00:10<00:09, 12.87it/s, est. speed input: 13776.13 toks/s, output: 13.45 toks/s]
Processed prompts:  55%|    | 142/256 [00:10<00:08, 12.96it/s, est. speed input: 13772.08 toks/s, output: 13.45 toks/s]
Processed prompts:  56%|    | 144/256 [00:10<00:08, 13.05it/s, est. speed input: 13769.07 toks/s, output: 13.45 toks/s]
Processed prompts:  57%|    | 146/256 [00:10<00:08, 13.01it/s, est. speed input: 13761.68 toks/s, output: 13.44 toks/s]
Processed prompts:  58%|    | 148/256 [00:11<00:08, 13.07it/s, est. speed input: 13758.26 toks/s, output: 13.44 toks/s]
Processed prompts:  59%|    | 150/256 [00:11<00:08, 13.14it/s, est. speed input: 13756.61 toks/s, output: 13.43 toks/s]
Processed prompts:  59%|    | 152/256 [00:11<00:08, 12.99it/s, est. speed input: 13745.25 toks/s, output: 13.42 toks/s]
Processed prompts:  60%|    | 154/256 [00:11<00:07, 13.01it/s, est. speed input: 13740.11 toks/s, output: 13.42 toks/s]
Processed prompts:  61%|    | 156/256 [00:11<00:07, 13.08it/s, est. speed input: 13738.04 toks/s, output: 13.42 toks/s]
Processed prompts:  62%|   | 158/256 [00:11<00:07, 13.03it/s, est. speed input: 13731.08 toks/s, output: 13.41 toks/s]
Processed prompts:  62%|   | 160/256 [00:11<00:07, 13.08it/s, est. speed input: 13728.60 toks/s, output: 13.41 toks/s]
Processed prompts:  63%|   | 162/256 [00:12<00:07, 12.98it/s, est. speed input: 13719.83 toks/s, output: 13.40 toks/s]
Processed prompts:  64%|   | 164/256 [00:12<00:07, 13.09it/s, est. speed input: 13719.17 toks/s, output: 13.40 toks/s]
Processed prompts:  65%|   | 166/256 [00:12<00:06, 12.89it/s, est. speed input: 13706.83 toks/s, output: 13.39 toks/s]
Processed prompts:  66%|   | 168/256 [00:12<00:06, 12.97it/s, est. speed input: 13703.93 toks/s, output: 13.38 toks/s]
Processed prompts:  66%|   | 170/256 [00:12<00:06, 13.07it/s, est. speed input: 13703.07 toks/s, output: 13.38 toks/s]
Processed prompts:  67%|   | 172/256 [00:12<00:06, 13.06it/s, est. speed input: 13698.61 toks/s, output: 13.38 toks/s]
Processed prompts:  68%|   | 174/256 [00:13<00:06, 13.11it/s, est. speed input: 13696.83 toks/s, output: 13.38 toks/s]
Processed prompts:  69%|   | 176/256 [00:13<00:06, 13.14it/s, est. speed input: 13694.81 toks/s, output: 13.37 toks/s]
Processed prompts:  70%|   | 178/256 [00:13<00:05, 13.06it/s, est. speed input: 13689.02 toks/s, output: 13.37 toks/s]
Processed prompts:  70%|   | 180/256 [00:13<00:05, 12.89it/s, est. speed input: 13678.46 toks/s, output: 13.36 toks/s]
Processed prompts:  71%|   | 182/256 [00:13<00:05, 12.89it/s, est. speed input: 13673.05 toks/s, output: 13.35 toks/s]
Processed prompts:  72%|  | 184/256 [00:13<00:05, 12.98it/s, est. speed input: 13671.34 toks/s, output: 13.35 toks/s]
Processed prompts:  73%|  | 186/256 [00:13<00:05, 13.04it/s, est. speed input: 13669.39 toks/s, output: 13.35 toks/s]
Processed prompts:  73%|  | 188/256 [00:14<00:05, 13.03it/s, est. speed input: 13665.82 toks/s, output: 13.35 toks/s]
Processed prompts:  74%|  | 190/256 [00:14<00:05, 13.09it/s, est. speed input: 13664.22 toks/s, output: 13.34 toks/s]
Processed prompts:  75%|  | 192/256 [00:14<00:04, 12.92it/s, est. speed input: 13655.20 toks/s, output: 13.34 toks/s]
Processed prompts:  76%|  | 194/256 [00:14<00:04, 12.81it/s, est. speed input: 13646.55 toks/s, output: 13.33 toks/s]
Processed prompts:  77%|  | 196/256 [00:14<00:04, 12.91it/s, est. speed input: 13644.85 toks/s, output: 13.32 toks/s]
Processed prompts:  77%|  | 198/256 [00:14<00:04, 13.04it/s, est. speed input: 13645.14 toks/s, output: 13.33 toks/s]
Processed prompts:  78%|  | 200/256 [00:15<00:04, 13.12it/s, est. speed input: 13645.03 toks/s, output: 13.33 toks/s]
Processed prompts:  79%|  | 202/256 [00:15<00:04, 13.09it/s, est. speed input: 13641.79 toks/s, output: 13.32 toks/s]
Processed prompts:  80%|  | 204/256 [00:15<00:03, 13.10it/s, est. speed input: 13639.73 toks/s, output: 13.32 toks/s]
Processed prompts:  80%|  | 206/256 [00:15<00:03, 13.03it/s, est. speed input: 13635.04 toks/s, output: 13.32 toks/s]
Processed prompts:  81%| | 208/256 [00:15<00:03, 13.10it/s, est. speed input: 13634.49 toks/s, output: 13.31 toks/s]
Processed prompts:  82%| | 210/256 [00:15<00:03, 13.16it/s, est. speed input: 13634.56 toks/s, output: 13.31 toks/s]
Processed prompts:  83%| | 212/256 [00:15<00:03, 13.20it/s, est. speed input: 13634.40 toks/s, output: 13.31 toks/s]
Processed prompts:  84%| | 214/256 [00:16<00:03, 13.14it/s, est. speed input: 13631.34 toks/s, output: 13.31 toks/s]
Processed prompts:  84%| | 216/256 [00:16<00:03, 13.10it/s, est. speed input: 13628.37 toks/s, output: 13.31 toks/s]
Processed prompts:  85%| | 218/256 [00:16<00:02, 13.17it/s, est. speed input: 13628.58 toks/s, output: 13.31 toks/s]
Processed prompts:  86%| | 220/256 [00:16<00:02, 12.96it/s, est. speed input: 13620.64 toks/s, output: 13.30 toks/s]
Processed prompts:  87%| | 222/256 [00:16<00:02, 13.01it/s, est. speed input: 13618.99 toks/s, output: 13.30 toks/s]
Processed prompts:  88%| | 224/256 [00:16<00:02, 13.01it/s, est. speed input: 13616.20 toks/s, output: 13.30 toks/s]
Processed prompts:  88%| | 226/256 [00:16<00:02, 13.10it/s, est. speed input: 13616.29 toks/s, output: 13.30 toks/s]
Processed prompts:  89%| | 228/256 [00:17<00:02, 13.15it/s, est. speed input: 13616.00 toks/s, output: 13.30 toks/s]
Processed prompts:  90%| | 230/256 [00:17<00:01, 13.13it/s, est. speed input: 13614.24 toks/s, output: 13.30 toks/s]
Processed prompts:  91%| | 232/256 [00:17<00:01, 13.15it/s, est. speed input: 13613.18 toks/s, output: 13.29 toks/s]
Processed prompts:  91%|| 234/256 [00:17<00:01, 12.99it/s, est. speed input: 13607.31 toks/s, output: 13.29 toks/s]
Processed prompts:  92%|| 236/256 [00:17<00:01, 13.02it/s, est. speed input: 13605.44 toks/s, output: 13.29 toks/s]
Processed prompts:  93%|| 238/256 [00:17<00:01, 13.10it/s, est. speed input: 13605.50 toks/s, output: 13.29 toks/s]
Processed prompts:  94%|| 240/256 [00:18<00:01, 13.14it/s, est. speed input: 13605.16 toks/s, output: 13.29 toks/s]
Processed prompts:  95%|| 242/256 [00:18<00:01, 13.12it/s, est. speed input: 13603.41 toks/s, output: 13.28 toks/s]
Processed prompts:  95%|| 244/256 [00:18<00:00, 13.20it/s, est. speed input: 13604.09 toks/s, output: 13.29 toks/s]
Processed prompts:  96%|| 246/256 [00:18<00:00, 13.24it/s, est. speed input: 13604.69 toks/s, output: 13.29 toks/s]
Processed prompts:  97%|| 248/256 [00:18<00:00, 12.96it/s, est. speed input: 13596.35 toks/s, output: 13.28 toks/s]
Processed prompts:  98%|| 250/256 [00:18<00:00, 13.06it/s, est. speed input: 13596.54 toks/s, output: 13.28 toks/s]
Processed prompts:  98%|| 252/256 [00:18<00:00, 13.06it/s, est. speed input: 13594.71 toks/s, output: 13.28 toks/s]
Processed prompts:  99%|| 254/256 [00:19<00:00, 13.12it/s, est. speed input: 13594.74 toks/s, output: 13.28 toks/s]
Processed prompts: 100%|| 256/256 [00:19<00:00, 13.12it/s, est. speed input: 13647.44 toks/s, output: 13.33 toks/s]
Processed prompts: 100%|| 256/256 [00:19<00:00, 13.33it/s, est. speed input: 13647.44 toks/s, output: 13.33 toks/s]
[rank0]:[W126 10:36:13.762053307 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 10:36:15
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:36:20 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:36:20 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1188967) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1188967) WARNING 01-26 10:37:00 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 12.41 requests/s, 12721.35 total tokens/s, 12.41 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 10:36:20] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:36:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:36:20] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:36:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:36:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:36:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:36:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:36:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:36:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:36:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:36:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:36:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:36:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:36:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:36:24] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:36:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:36:24] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:36:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:36:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:36:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:36:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:36:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:36:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:36:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:36:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:36:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:36:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:36:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1188967) [2026-01-26 10:36:25] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1188967) [2026-01-26 10:36:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1188967) [2026-01-26 10:36:25] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1188967) [2026-01-26 10:36:25] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1188967) [2026-01-26 10:36:25] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1188967) [2026-01-26 10:36:25] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1188967) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1188967) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.24s/it]
(EngineCore_DP0 pid=1188967) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.24s/it]
(EngineCore_DP0 pid=1188967) 
(EngineCore_DP0 pid=1188967) [2026-01-26 10:36:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1188967) [2026-01-26 10:36:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=1188967) [2026-01-26 10:36:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1188967) [2026-01-26 10:36:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10616832 bytes
(EngineCore_DP0 pid=1188967) [2026-01-26 10:36:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1188967) [2026-01-26 10:36:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56623104 bytes
(EngineCore_DP0 pid=1188967) [2026-01-26 10:36:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1188967) [2026-01-26 10:36:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28311552 bytes
(EngineCore_DP0 pid=1188967) 2026-01-26 10:36:59,217 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1188967) 2026-01-26 10:36:59,228 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  12%|        | 61/512 [00:00<00:00, 605.40it/s]
Adding requests:  24%|       | 122/512 [00:00<00:00, 579.49it/s]
Adding requests:  35%|      | 181/512 [00:00<00:00, 566.61it/s]
Adding requests:  47%|     | 240/512 [00:00<00:00, 573.19it/s]
Adding requests:  58%|    | 298/512 [00:00<00:00, 561.86it/s]
Adding requests:  69%|   | 355/512 [00:00<00:00, 559.98it/s]
Adding requests:  80%|  | 412/512 [00:00<00:00, 554.80it/s]
Adding requests:  92%|| 469/512 [00:00<00:00, 558.72it/s]
Adding requests: 100%|| 512/512 [00:00<00:00, 560.69it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 10/512 [00:00<00:11, 43.52it/s, est. speed input: 44565.67 toks/s, output: 43.52 toks/s]
Processed prompts:   3%|         | 15/512 [00:00<00:19, 24.86it/s, est. speed input: 27843.99 toks/s, output: 27.19 toks/s]
Processed prompts:   4%|         | 18/512 [00:00<00:28, 17.16it/s, est. speed input: 20990.05 toks/s, output: 20.50 toks/s]
Processed prompts:   4%|         | 22/512 [00:01<00:32, 15.29it/s, est. speed input: 18825.58 toks/s, output: 18.38 toks/s]
Processed prompts:   5%|         | 26/512 [00:01<00:33, 14.30it/s, est. speed input: 17583.74 toks/s, output: 17.17 toks/s]
Processed prompts:   6%|         | 30/512 [00:01<00:35, 13.74it/s, est. speed input: 16783.71 toks/s, output: 16.39 toks/s]
Processed prompts:   7%|         | 34/512 [00:02<00:36, 13.27it/s, est. speed input: 16161.70 toks/s, output: 15.78 toks/s]
Processed prompts:   7%|         | 38/512 [00:02<00:36, 13.03it/s, est. speed input: 15728.58 toks/s, output: 15.36 toks/s]
Processed prompts:   8%|         | 42/512 [00:02<00:36, 12.90it/s, est. speed input: 15407.83 toks/s, output: 15.05 toks/s]
Processed prompts:   9%|         | 46/512 [00:03<00:36, 12.74it/s, est. speed input: 15124.79 toks/s, output: 14.77 toks/s]
Processed prompts:  10%|         | 50/512 [00:03<00:36, 12.68it/s, est. speed input: 14913.22 toks/s, output: 14.56 toks/s]
Processed prompts:  11%|         | 54/512 [00:03<00:36, 12.65it/s, est. speed input: 14742.58 toks/s, output: 14.40 toks/s]
Processed prompts:  11%|        | 58/512 [00:04<00:36, 12.53it/s, est. speed input: 14566.83 toks/s, output: 14.23 toks/s]
Processed prompts:  12%|        | 62/512 [00:04<00:35, 12.51it/s, est. speed input: 14435.01 toks/s, output: 14.10 toks/s]
Processed prompts:  13%|        | 66/512 [00:04<00:35, 12.52it/s, est. speed input: 14326.38 toks/s, output: 13.99 toks/s]
Processed prompts:  14%|        | 70/512 [00:05<00:35, 12.49it/s, est. speed input: 14223.96 toks/s, output: 13.89 toks/s]
Processed prompts:  14%|        | 74/512 [00:05<00:35, 12.37it/s, est. speed input: 14111.53 toks/s, output: 13.78 toks/s]
Processed prompts:  15%|        | 78/512 [00:05<00:34, 12.42it/s, est. speed input: 14039.40 toks/s, output: 13.71 toks/s]
Processed prompts:  16%|        | 82/512 [00:06<00:34, 12.44it/s, est. speed input: 13973.77 toks/s, output: 13.65 toks/s]
Processed prompts:  17%|        | 86/512 [00:06<00:34, 12.42it/s, est. speed input: 13907.44 toks/s, output: 13.58 toks/s]
Processed prompts:  18%|        | 90/512 [00:06<00:33, 12.45it/s, est. speed input: 13855.19 toks/s, output: 13.53 toks/s]
Processed prompts:  18%|        | 94/512 [00:06<00:33, 12.48it/s, est. speed input: 13809.31 toks/s, output: 13.49 toks/s]
Processed prompts:  19%|        | 98/512 [00:07<00:33, 12.39it/s, est. speed input: 13749.01 toks/s, output: 13.43 toks/s]
Processed prompts:  20%|        | 102/512 [00:07<00:32, 12.43it/s, est. speed input: 13710.16 toks/s, output: 13.39 toks/s]
Processed prompts:  21%|        | 106/512 [00:07<00:32, 12.45it/s, est. speed input: 13673.65 toks/s, output: 13.35 toks/s]
Processed prompts:  21%|       | 110/512 [00:08<00:32, 12.49it/s, est. speed input: 13642.98 toks/s, output: 13.32 toks/s]
Processed prompts:  22%|       | 114/512 [00:08<00:31, 12.46it/s, est. speed input: 13607.61 toks/s, output: 13.29 toks/s]
Processed prompts:  23%|       | 118/512 [00:08<00:31, 12.44it/s, est. speed input: 13574.13 toks/s, output: 13.26 toks/s]
Processed prompts:  24%|       | 122/512 [00:09<00:31, 12.46it/s, est. speed input: 13547.78 toks/s, output: 13.23 toks/s]
Processed prompts:  25%|       | 126/512 [00:09<00:31, 12.38it/s, est. speed input: 13511.49 toks/s, output: 13.19 toks/s]
Processed prompts:  25%|       | 130/512 [00:09<00:30, 12.39it/s, est. speed input: 13485.52 toks/s, output: 13.17 toks/s]
Processed prompts:  26%|       | 134/512 [00:10<00:30, 12.46it/s, est. speed input: 13467.79 toks/s, output: 13.15 toks/s]
Processed prompts:  27%|       | 138/512 [00:10<00:30, 12.35it/s, est. speed input: 13434.43 toks/s, output: 13.12 toks/s]
Processed prompts:  28%|       | 142/512 [00:10<00:29, 12.40it/s, est. speed input: 13416.44 toks/s, output: 13.10 toks/s]
Processed prompts:  29%|       | 146/512 [00:11<00:29, 12.42it/s, est. speed input: 13397.96 toks/s, output: 13.08 toks/s]
Processed prompts:  29%|       | 150/512 [00:11<00:29, 12.38it/s, est. speed input: 13374.32 toks/s, output: 13.06 toks/s]
Processed prompts:  30%|       | 154/512 [00:11<00:28, 12.40it/s, est. speed input: 13357.40 toks/s, output: 13.04 toks/s]
Processed prompts:  31%|       | 158/512 [00:12<00:28, 12.43it/s, est. speed input: 13342.60 toks/s, output: 13.03 toks/s]
Processed prompts:  32%|      | 162/512 [00:12<00:28, 12.41it/s, est. speed input: 13325.10 toks/s, output: 13.01 toks/s]
Processed prompts:  32%|      | 166/512 [00:12<00:27, 12.37it/s, est. speed input: 13305.87 toks/s, output: 12.99 toks/s]
Processed prompts:  33%|      | 170/512 [00:13<00:27, 12.38it/s, est. speed input: 13291.02 toks/s, output: 12.98 toks/s]
Processed prompts:  34%|      | 174/512 [00:13<00:27, 12.42it/s, est. speed input: 13279.83 toks/s, output: 12.97 toks/s]
Processed prompts:  35%|      | 178/512 [00:13<00:27, 12.36it/s, est. speed input: 13261.69 toks/s, output: 12.95 toks/s]
Processed prompts:  36%|      | 182/512 [00:14<00:26, 12.40it/s, est. speed input: 13250.54 toks/s, output: 12.94 toks/s]
Processed prompts:  36%|      | 186/512 [00:14<00:26, 12.40it/s, est. speed input: 13238.27 toks/s, output: 12.93 toks/s]
Processed prompts:  37%|      | 190/512 [00:14<00:26, 12.37it/s, est. speed input: 13223.83 toks/s, output: 12.91 toks/s]
Processed prompts:  38%|      | 194/512 [00:15<00:25, 12.38it/s, est. speed input: 13213.14 toks/s, output: 12.90 toks/s]
Processed prompts:  39%|      | 198/512 [00:15<00:25, 12.40it/s, est. speed input: 13203.46 toks/s, output: 12.89 toks/s]
Processed prompts:  39%|      | 202/512 [00:15<00:24, 12.48it/s, est. speed input: 13198.76 toks/s, output: 12.89 toks/s]
Processed prompts:  40%|      | 206/512 [00:15<00:24, 12.42it/s, est. speed input: 13185.79 toks/s, output: 12.88 toks/s]
Processed prompts:  41%|      | 210/512 [00:16<00:24, 12.46it/s, est. speed input: 13179.86 toks/s, output: 12.87 toks/s]
Processed prompts:  42%|     | 214/512 [00:16<00:23, 12.49it/s, est. speed input: 13173.41 toks/s, output: 12.86 toks/s]
Processed prompts:  43%|     | 218/512 [00:16<00:23, 12.40it/s, est. speed input: 13160.11 toks/s, output: 12.85 toks/s]
Processed prompts:  43%|     | 222/512 [00:17<00:23, 12.46it/s, est. speed input: 13155.31 toks/s, output: 12.85 toks/s]
Processed prompts:  44%|     | 226/512 [00:17<00:23, 12.42it/s, est. speed input: 13145.59 toks/s, output: 12.84 toks/s]
Processed prompts:  45%|     | 230/512 [00:17<00:22, 12.35it/s, est. speed input: 13133.52 toks/s, output: 12.83 toks/s]
Processed prompts:  46%|     | 234/512 [00:18<00:22, 12.37it/s, est. speed input: 13126.17 toks/s, output: 12.82 toks/s]
Processed prompts:  46%|     | 238/512 [00:18<00:21, 12.46it/s, est. speed input: 13123.35 toks/s, output: 12.82 toks/s]
Processed prompts:  47%|     | 242/512 [00:18<00:21, 12.41it/s, est. speed input: 13114.05 toks/s, output: 12.81 toks/s]
Processed prompts:  48%|     | 246/512 [00:19<00:21, 12.43it/s, est. speed input: 13108.43 toks/s, output: 12.80 toks/s]
Processed prompts:  49%|     | 250/512 [00:19<00:21, 12.41it/s, est. speed input: 13101.35 toks/s, output: 12.79 toks/s]
Processed prompts:  50%|     | 254/512 [00:19<00:20, 12.41it/s, est. speed input: 13094.70 toks/s, output: 12.79 toks/s]
Processed prompts:  50%|     | 258/512 [00:20<00:20, 12.39it/s, est. speed input: 13087.52 toks/s, output: 12.78 toks/s]
Processed prompts:  51%|     | 262/512 [00:20<00:20, 12.44it/s, est. speed input: 13083.74 toks/s, output: 12.78 toks/s]
Processed prompts:  52%|    | 266/512 [00:20<00:19, 12.47it/s, est. speed input: 13080.13 toks/s, output: 12.77 toks/s]
Processed prompts:  53%|    | 270/512 [00:21<00:19, 12.43it/s, est. speed input: 13073.55 toks/s, output: 12.77 toks/s]
Processed prompts:  54%|    | 274/512 [00:21<00:19, 12.43it/s, est. speed input: 13068.30 toks/s, output: 12.76 toks/s]
Processed prompts:  54%|    | 278/512 [00:21<00:18, 12.45it/s, est. speed input: 13064.09 toks/s, output: 12.76 toks/s]
Processed prompts:  55%|    | 282/512 [00:22<00:18, 12.39it/s, est. speed input: 13056.32 toks/s, output: 12.75 toks/s]
Processed prompts:  56%|    | 286/512 [00:22<00:18, 12.41it/s, est. speed input: 13052.25 toks/s, output: 12.75 toks/s]
Processed prompts:  57%|    | 290/512 [00:22<00:17, 12.41it/s, est. speed input: 13047.18 toks/s, output: 12.74 toks/s]
Processed prompts:  57%|    | 294/512 [00:23<00:17, 12.40it/s, est. speed input: 13042.18 toks/s, output: 12.74 toks/s]
Processed prompts:  58%|    | 298/512 [00:23<00:17, 12.36it/s, est. speed input: 13035.46 toks/s, output: 12.73 toks/s]
Processed prompts:  59%|    | 302/512 [00:23<00:17, 12.35it/s, est. speed input: 13029.76 toks/s, output: 12.72 toks/s]
Processed prompts:  60%|    | 306/512 [00:24<00:16, 12.37it/s, est. speed input: 13025.63 toks/s, output: 12.72 toks/s]
Processed prompts:  61%|    | 310/512 [00:24<00:16, 12.31it/s, est. speed input: 13017.84 toks/s, output: 12.71 toks/s]
Processed prompts:  61%|   | 314/512 [00:24<00:16, 12.35it/s, est. speed input: 13014.20 toks/s, output: 12.71 toks/s]
Processed prompts:  62%|   | 318/512 [00:25<00:15, 12.38it/s, est. speed input: 13010.88 toks/s, output: 12.71 toks/s]
Processed prompts:  63%|   | 322/512 [00:25<00:15, 12.34it/s, est. speed input: 13005.07 toks/s, output: 12.70 toks/s]
Processed prompts:  64%|   | 326/512 [00:25<00:15, 12.39it/s, est. speed input: 13002.31 toks/s, output: 12.70 toks/s]
Processed prompts:  64%|   | 330/512 [00:25<00:14, 12.40it/s, est. speed input: 12999.01 toks/s, output: 12.69 toks/s]
Processed prompts:  65%|   | 334/512 [00:26<00:14, 12.35it/s, est. speed input: 12993.29 toks/s, output: 12.69 toks/s]
Processed prompts:  66%|   | 338/512 [00:26<00:14, 12.39it/s, est. speed input: 12990.46 toks/s, output: 12.69 toks/s]
Processed prompts:  67%|   | 342/512 [00:26<00:13, 13.00it/s, est. speed input: 13011.38 toks/s, output: 12.71 toks/s]
Processed prompts:  68%|   | 346/512 [00:27<00:12, 12.84it/s, est. speed input: 13008.73 toks/s, output: 12.70 toks/s]
Processed prompts:  68%|   | 350/512 [00:27<00:12, 12.65it/s, est. speed input: 13002.96 toks/s, output: 12.70 toks/s]
Processed prompts:  69%|   | 354/512 [00:27<00:12, 12.57it/s, est. speed input: 12999.28 toks/s, output: 12.69 toks/s]
Processed prompts:  70%|   | 358/512 [00:28<00:12, 12.58it/s, est. speed input: 12998.37 toks/s, output: 12.69 toks/s]
Processed prompts:  71%|   | 362/512 [00:28<00:12, 12.46it/s, est. speed input: 12992.36 toks/s, output: 12.69 toks/s]
Processed prompts:  71%|  | 366/512 [00:28<00:11, 12.47it/s, est. speed input: 12990.00 toks/s, output: 12.69 toks/s]
Processed prompts:  72%|  | 370/512 [00:29<00:11, 12.46it/s, est. speed input: 12987.24 toks/s, output: 12.68 toks/s]
Processed prompts:  73%|  | 374/512 [00:29<00:11, 12.37it/s, est. speed input: 12981.53 toks/s, output: 12.68 toks/s]
Processed prompts:  74%|  | 378/512 [00:29<00:10, 12.36it/s, est. speed input: 12977.70 toks/s, output: 12.67 toks/s]
Processed prompts:  75%|  | 382/512 [00:30<00:10, 12.40it/s, est. speed input: 12975.77 toks/s, output: 12.67 toks/s]
Processed prompts:  75%|  | 386/512 [00:30<00:10, 12.38it/s, est. speed input: 12971.92 toks/s, output: 12.67 toks/s]
Processed prompts:  76%|  | 390/512 [00:30<00:09, 12.32it/s, est. speed input: 12966.73 toks/s, output: 12.66 toks/s]
Processed prompts:  77%|  | 394/512 [00:31<00:09, 12.39it/s, est. speed input: 12965.64 toks/s, output: 12.66 toks/s]
Processed prompts:  78%|  | 398/512 [00:31<00:09, 12.38it/s, est. speed input: 12962.51 toks/s, output: 12.66 toks/s]
Processed prompts:  79%|  | 402/512 [00:31<00:08, 12.39it/s, est. speed input: 12959.76 toks/s, output: 12.66 toks/s]
Processed prompts:  79%|  | 406/512 [00:32<00:08, 12.40it/s, est. speed input: 12957.57 toks/s, output: 12.65 toks/s]
Processed prompts:  80%|  | 410/512 [00:32<00:08, 12.39it/s, est. speed input: 12954.43 toks/s, output: 12.65 toks/s]
Processed prompts:  81%|  | 414/512 [00:32<00:07, 12.39it/s, est. speed input: 12951.77 toks/s, output: 12.65 toks/s]
Processed prompts:  82%| | 418/512 [00:33<00:07, 12.40it/s, est. speed input: 12949.45 toks/s, output: 12.65 toks/s]
Processed prompts:  82%| | 422/512 [00:33<00:07, 12.44it/s, est. speed input: 12948.47 toks/s, output: 12.64 toks/s]
Processed prompts:  83%| | 426/512 [00:33<00:06, 12.41it/s, est. speed input: 12945.60 toks/s, output: 12.64 toks/s]
Processed prompts:  84%| | 430/512 [00:34<00:06, 12.43it/s, est. speed input: 12943.97 toks/s, output: 12.64 toks/s]
Processed prompts:  85%| | 434/512 [00:34<00:06, 12.42it/s, est. speed input: 12941.68 toks/s, output: 12.64 toks/s]
Processed prompts:  86%| | 438/512 [00:34<00:05, 12.48it/s, est. speed input: 12941.50 toks/s, output: 12.64 toks/s]
Processed prompts:  86%| | 442/512 [00:34<00:05, 12.40it/s, est. speed input: 12937.54 toks/s, output: 12.63 toks/s]
Processed prompts:  87%| | 446/512 [00:35<00:05, 12.44it/s, est. speed input: 12936.47 toks/s, output: 12.63 toks/s]
Processed prompts:  88%| | 450/512 [00:35<00:04, 13.16it/s, est. speed input: 12956.14 toks/s, output: 12.65 toks/s]
Processed prompts:  89%| | 454/512 [00:35<00:04, 12.90it/s, est. speed input: 12953.01 toks/s, output: 12.65 toks/s]
Processed prompts:  89%| | 458/512 [00:36<00:04, 12.79it/s, est. speed input: 12952.14 toks/s, output: 12.65 toks/s]
Processed prompts:  90%| | 462/512 [00:36<00:03, 12.75it/s, est. speed input: 12952.22 toks/s, output: 12.65 toks/s]
Processed prompts:  91%| | 466/512 [00:36<00:03, 12.58it/s, est. speed input: 12948.25 toks/s, output: 12.64 toks/s]
Processed prompts:  92%|| 470/512 [00:37<00:03, 12.52it/s, est. speed input: 12945.76 toks/s, output: 12.64 toks/s]
Processed prompts:  93%|| 474/512 [00:37<00:03, 12.49it/s, est. speed input: 12943.85 toks/s, output: 12.64 toks/s]
Processed prompts:  93%|| 478/512 [00:37<00:02, 12.44it/s, est. speed input: 12941.09 toks/s, output: 12.64 toks/s]
Processed prompts:  94%|| 482/512 [00:38<00:02, 12.42it/s, est. speed input: 12938.64 toks/s, output: 12.64 toks/s]
Processed prompts:  95%|| 486/512 [00:38<00:02, 12.38it/s, est. speed input: 12935.73 toks/s, output: 12.63 toks/s]
Processed prompts:  96%|| 490/512 [00:38<00:01, 12.39it/s, est. speed input: 12933.97 toks/s, output: 12.63 toks/s]
Processed prompts:  96%|| 494/512 [00:39<00:01, 12.32it/s, est. speed input: 12929.98 toks/s, output: 12.63 toks/s]
Processed prompts:  97%|| 498/512 [00:39<00:01, 12.34it/s, est. speed input: 12927.75 toks/s, output: 12.62 toks/s]
Processed prompts:  98%|| 502/512 [00:39<00:00, 12.39it/s, est. speed input: 12926.97 toks/s, output: 12.62 toks/s]
Processed prompts:  99%|| 506/512 [00:40<00:00, 12.34it/s, est. speed input: 12923.68 toks/s, output: 12.62 toks/s]
Processed prompts: 100%|| 510/512 [00:40<00:00, 13.30it/s, est. speed input: 12946.33 toks/s, output: 12.64 toks/s]
Processed prompts: 100%|| 512/512 [00:40<00:00, 13.30it/s, est. speed input: 12997.05 toks/s, output: 12.69 toks/s]
Processed prompts: 100%|| 512/512 [00:40<00:00, 12.69it/s, est. speed input: 12997.05 toks/s, output: 12.69 toks/s]
[rank0]:[W126 10:37:41.676860851 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 10:37:43
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:37:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:37:50 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1190387) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1190387) WARNING 01-26 10:38:29 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 12.30 requests/s, 12611.19 total tokens/s, 12.30 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 10:37:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:37:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:37:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:37:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:37:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:37:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:37:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:37:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:37:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:37:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:37:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:37:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:37:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:37:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:37:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:37:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:37:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:37:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:37:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:37:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:37:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:37:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:37:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:37:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:37:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:37:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:37:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:37:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1190387) [2026-01-26 10:37:54] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1190387) [2026-01-26 10:37:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1190387) [2026-01-26 10:37:54] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1190387) [2026-01-26 10:37:54] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1190387) [2026-01-26 10:37:54] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1190387) [2026-01-26 10:37:54] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1190387) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1190387) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:26<00:00, 26.94s/it]
(EngineCore_DP0 pid=1190387) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:26<00:00, 26.94s/it]
(EngineCore_DP0 pid=1190387) 
(EngineCore_DP0 pid=1190387) [2026-01-26 10:38:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1190387) [2026-01-26 10:38:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=1190387) [2026-01-26 10:38:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1190387) [2026-01-26 10:38:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10616832 bytes
(EngineCore_DP0 pid=1190387) [2026-01-26 10:38:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1190387) [2026-01-26 10:38:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56623104 bytes
(EngineCore_DP0 pid=1190387) [2026-01-26 10:38:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1190387) [2026-01-26 10:38:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28311552 bytes
(EngineCore_DP0 pid=1190387) 2026-01-26 10:38:28,272 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1190387) 2026-01-26 10:38:28,320 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   6%|         | 60/1024 [00:00<00:01, 599.00it/s]
Adding requests:  12%|        | 120/1024 [00:00<00:01, 571.89it/s]
Adding requests:  17%|        | 178/1024 [00:00<00:01, 544.39it/s]
Adding requests:  23%|       | 233/1024 [00:00<00:01, 533.19it/s]
Adding requests:  28%|       | 287/1024 [00:00<00:01, 534.29it/s]
Adding requests:  33%|      | 342/1024 [00:00<00:01, 537.44it/s]
Adding requests:  39%|      | 400/1024 [00:00<00:01, 547.25it/s]
Adding requests:  45%|     | 456/1024 [00:00<00:01, 550.88it/s]
Adding requests:  50%|     | 512/1024 [00:00<00:00, 543.26it/s]
Adding requests:  55%|    | 567/1024 [00:01<00:00, 540.57it/s]
Adding requests:  61%|    | 623/1024 [00:01<00:00, 544.11it/s]
Adding requests:  66%|   | 678/1024 [00:01<00:00, 529.43it/s]
Adding requests:  72%|  | 734/1024 [00:01<00:00, 537.20it/s]
Adding requests:  77%|  | 788/1024 [00:01<00:00, 532.95it/s]
Adding requests:  82%| | 842/1024 [00:01<00:00, 518.78it/s]
Adding requests:  88%| | 901/1024 [00:01<00:00, 537.32it/s]
Adding requests:  93%|| 956/1024 [00:01<00:00, 538.63it/s]
Adding requests:  99%|| 1012/1024 [00:01<00:00, 543.64it/s]
Adding requests: 100%|| 1024/1024 [00:01<00:00, 540.77it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 18/1024 [00:00<00:12, 78.43it/s, est. speed input: 80329.14 toks/s, output: 78.44 toks/s]
Processed prompts:   3%|         | 26/1024 [00:00<00:39, 25.41it/s, est. speed input: 30276.18 toks/s, output: 29.57 toks/s]
Processed prompts:   3%|         | 34/1024 [00:01<00:53, 18.56it/s, est. speed input: 22900.74 toks/s, output: 22.36 toks/s]
Processed prompts:   4%|         | 42/1024 [00:02<01:01, 15.87it/s, est. speed input: 19838.99 toks/s, output: 19.37 toks/s]
Processed prompts:   5%|         | 50/1024 [00:02<01:06, 14.54it/s, est. speed input: 18199.26 toks/s, output: 17.77 toks/s]
Processed prompts:   6%|         | 58/1024 [00:03<01:10, 13.73it/s, est. speed input: 17133.71 toks/s, output: 16.73 toks/s]
Processed prompts:   6%|         | 66/1024 [00:04<01:12, 13.25it/s, est. speed input: 16419.29 toks/s, output: 16.03 toks/s]
Processed prompts:   7%|         | 74/1024 [00:04<01:13, 13.00it/s, est. speed input: 15928.12 toks/s, output: 15.55 toks/s]
Processed prompts:   8%|         | 82/1024 [00:05<01:13, 12.78it/s, est. speed input: 15527.08 toks/s, output: 15.16 toks/s]
Processed prompts:   9%|         | 90/1024 [00:06<01:13, 12.64it/s, est. speed input: 15215.48 toks/s, output: 14.86 toks/s]
Processed prompts:  10%|         | 98/1024 [00:06<01:13, 12.54it/s, est. speed input: 14965.65 toks/s, output: 14.61 toks/s]
Processed prompts:  10%|         | 106/1024 [00:07<01:13, 12.46it/s, est. speed input: 14752.18 toks/s, output: 14.41 toks/s]
Processed prompts:  11%|         | 114/1024 [00:08<01:13, 12.43it/s, est. speed input: 14582.80 toks/s, output: 14.24 toks/s]
Processed prompts:  12%|        | 122/1024 [00:08<01:12, 12.37it/s, est. speed input: 14427.77 toks/s, output: 14.09 toks/s]
Processed prompts:  13%|        | 130/1024 [00:09<01:12, 12.37it/s, est. speed input: 14305.37 toks/s, output: 13.97 toks/s]
Processed prompts:  13%|        | 138/1024 [00:09<01:11, 12.31it/s, est. speed input: 14182.76 toks/s, output: 13.85 toks/s]
Processed prompts:  14%|        | 146/1024 [00:10<01:11, 12.29it/s, est. speed input: 14082.22 toks/s, output: 13.75 toks/s]
Processed prompts:  15%|        | 154/1024 [00:11<01:10, 12.32it/s, est. speed input: 14001.65 toks/s, output: 13.67 toks/s]
Processed prompts:  16%|        | 162/1024 [00:11<01:09, 12.32it/s, est. speed input: 13927.54 toks/s, output: 13.60 toks/s]
Processed prompts:  17%|        | 170/1024 [00:12<01:09, 12.32it/s, est. speed input: 13860.00 toks/s, output: 13.54 toks/s]
Processed prompts:  17%|        | 178/1024 [00:13<01:08, 12.32it/s, est. speed input: 13797.35 toks/s, output: 13.47 toks/s]
Processed prompts:  18%|        | 186/1024 [00:13<01:08, 12.31it/s, est. speed input: 13740.60 toks/s, output: 13.42 toks/s]
Processed prompts:  19%|        | 194/1024 [00:14<01:07, 12.29it/s, est. speed input: 13687.28 toks/s, output: 13.37 toks/s]
Processed prompts:  20%|        | 202/1024 [00:15<01:06, 12.29it/s, est. speed input: 13639.72 toks/s, output: 13.32 toks/s]
Processed prompts:  21%|        | 210/1024 [00:15<01:06, 12.26it/s, est. speed input: 13591.40 toks/s, output: 13.27 toks/s]
Processed prompts:  21%|       | 218/1024 [00:16<01:05, 12.29it/s, est. speed input: 13554.66 toks/s, output: 13.24 toks/s]
Processed prompts:  22%|       | 226/1024 [00:17<01:05, 12.26it/s, est. speed input: 13513.17 toks/s, output: 13.20 toks/s]
Processed prompts:  23%|       | 234/1024 [00:17<01:04, 12.28it/s, est. speed input: 13480.94 toks/s, output: 13.16 toks/s]
Processed prompts:  24%|       | 242/1024 [00:18<01:03, 12.28it/s, est. speed input: 13448.43 toks/s, output: 13.13 toks/s]
Processed prompts:  24%|       | 250/1024 [00:19<01:03, 12.27it/s, est. speed input: 13417.34 toks/s, output: 13.10 toks/s]
Processed prompts:  25%|       | 258/1024 [00:19<01:02, 12.29it/s, est. speed input: 13391.47 toks/s, output: 13.08 toks/s]
Processed prompts:  26%|       | 266/1024 [00:20<01:01, 12.27it/s, est. speed input: 13363.60 toks/s, output: 13.05 toks/s]
Processed prompts:  27%|       | 274/1024 [00:21<01:01, 12.25it/s, est. speed input: 13336.92 toks/s, output: 13.02 toks/s]
Processed prompts:  28%|       | 282/1024 [00:21<01:00, 12.30it/s, est. speed input: 13318.15 toks/s, output: 13.01 toks/s]
Processed prompts:  28%|       | 290/1024 [00:22<00:59, 12.31it/s, est. speed input: 13298.72 toks/s, output: 12.99 toks/s]
Processed prompts:  29%|       | 298/1024 [00:22<00:58, 12.35it/s, est. speed input: 13282.76 toks/s, output: 12.97 toks/s]
Processed prompts:  30%|       | 306/1024 [00:23<00:58, 12.34it/s, est. speed input: 13264.34 toks/s, output: 12.95 toks/s]
Processed prompts:  31%|       | 314/1024 [00:24<00:57, 12.32it/s, est. speed input: 13245.57 toks/s, output: 12.94 toks/s]
Processed prompts:  31%|      | 322/1024 [00:24<00:56, 12.32it/s, est. speed input: 13228.92 toks/s, output: 12.92 toks/s]
Processed prompts:  32%|      | 330/1024 [00:25<00:56, 12.28it/s, est. speed input: 13210.03 toks/s, output: 12.90 toks/s]
Processed prompts:  33%|      | 338/1024 [00:26<00:54, 12.63it/s, est. speed input: 13224.25 toks/s, output: 12.91 toks/s]
Processed prompts:  34%|      | 346/1024 [00:26<00:54, 12.49it/s, est. speed input: 13205.75 toks/s, output: 12.90 toks/s]
Processed prompts:  35%|      | 354/1024 [00:27<00:53, 12.44it/s, est. speed input: 13191.60 toks/s, output: 12.88 toks/s]
Processed prompts:  35%|      | 362/1024 [00:28<00:53, 12.42it/s, est. speed input: 13180.25 toks/s, output: 12.87 toks/s]
Processed prompts:  36%|      | 370/1024 [00:28<00:52, 12.37it/s, est. speed input: 13165.98 toks/s, output: 12.86 toks/s]
Processed prompts:  37%|      | 378/1024 [00:29<00:52, 12.37it/s, est. speed input: 13154.70 toks/s, output: 12.85 toks/s]
Processed prompts:  38%|      | 386/1024 [00:30<00:51, 12.32it/s, est. speed input: 13140.08 toks/s, output: 12.83 toks/s]
Processed prompts:  38%|      | 394/1024 [00:30<00:51, 12.29it/s, est. speed input: 13126.78 toks/s, output: 12.82 toks/s]
Processed prompts:  39%|      | 402/1024 [00:31<00:50, 12.29it/s, est. speed input: 13115.62 toks/s, output: 12.81 toks/s]
Processed prompts:  40%|      | 410/1024 [00:32<00:50, 12.27it/s, est. speed input: 13103.66 toks/s, output: 12.80 toks/s]
Processed prompts:  41%|      | 418/1024 [00:32<00:49, 12.24it/s, est. speed input: 13090.83 toks/s, output: 12.78 toks/s]
Processed prompts:  42%|     | 426/1024 [00:33<00:48, 12.27it/s, est. speed input: 13081.64 toks/s, output: 12.78 toks/s]
Processed prompts:  42%|     | 434/1024 [00:34<00:48, 12.25it/s, est. speed input: 13070.67 toks/s, output: 12.76 toks/s]
Processed prompts:  43%|     | 442/1024 [00:34<00:47, 12.28it/s, est. speed input: 13062.36 toks/s, output: 12.76 toks/s]
Processed prompts:  44%|     | 450/1024 [00:35<00:45, 12.66it/s, est. speed input: 13077.41 toks/s, output: 12.77 toks/s]
Processed prompts:  45%|     | 458/1024 [00:35<00:45, 12.52it/s, est. speed input: 13067.13 toks/s, output: 12.76 toks/s]
Processed prompts:  46%|     | 466/1024 [00:36<00:44, 12.47it/s, est. speed input: 13059.89 toks/s, output: 12.75 toks/s]
Processed prompts:  46%|     | 474/1024 [00:37<00:44, 12.41it/s, est. speed input: 13050.88 toks/s, output: 12.74 toks/s]
Processed prompts:  47%|     | 482/1024 [00:37<00:43, 12.37it/s, est. speed input: 13042.73 toks/s, output: 12.74 toks/s]
Processed prompts:  48%|     | 490/1024 [00:38<00:43, 12.32it/s, est. speed input: 13033.55 toks/s, output: 12.73 toks/s]
Processed prompts:  49%|     | 498/1024 [00:39<00:42, 12.30it/s, est. speed input: 13025.55 toks/s, output: 12.72 toks/s]
Processed prompts:  49%|     | 506/1024 [00:39<00:42, 12.32it/s, est. speed input: 13019.84 toks/s, output: 12.71 toks/s]
Processed prompts:  50%|     | 514/1024 [00:40<00:41, 12.31it/s, est. speed input: 13012.49 toks/s, output: 12.71 toks/s]
Processed prompts:  51%|     | 522/1024 [00:41<00:40, 12.31it/s, est. speed input: 13006.15 toks/s, output: 12.70 toks/s]
Processed prompts:  52%|    | 530/1024 [00:41<00:40, 12.27it/s, est. speed input: 12997.92 toks/s, output: 12.69 toks/s]
Processed prompts:  53%|    | 538/1024 [00:42<00:39, 12.26it/s, est. speed input: 12990.55 toks/s, output: 12.69 toks/s]
Processed prompts:  53%|    | 546/1024 [00:43<00:38, 12.27it/s, est. speed input: 12984.41 toks/s, output: 12.68 toks/s]
Processed prompts:  54%|    | 554/1024 [00:43<00:38, 12.29it/s, est. speed input: 12979.30 toks/s, output: 12.68 toks/s]
Processed prompts:  55%|    | 562/1024 [00:44<00:37, 12.29it/s, est. speed input: 12973.33 toks/s, output: 12.67 toks/s]
Processed prompts:  56%|    | 570/1024 [00:45<00:36, 12.30it/s, est. speed input: 12968.43 toks/s, output: 12.66 toks/s]
Processed prompts:  56%|    | 578/1024 [00:45<00:36, 12.28it/s, est. speed input: 12962.05 toks/s, output: 12.66 toks/s]
Processed prompts:  57%|    | 586/1024 [00:46<00:35, 12.29it/s, est. speed input: 12957.27 toks/s, output: 12.65 toks/s]
Processed prompts:  58%|    | 594/1024 [00:46<00:35, 12.26it/s, est. speed input: 12950.72 toks/s, output: 12.65 toks/s]
Processed prompts:  59%|    | 602/1024 [00:47<00:34, 12.23it/s, est. speed input: 12943.73 toks/s, output: 12.64 toks/s]
Processed prompts:  60%|    | 610/1024 [00:48<00:33, 12.28it/s, est. speed input: 12940.20 toks/s, output: 12.64 toks/s]
Processed prompts:  60%|    | 618/1024 [00:48<00:33, 12.24it/s, est. speed input: 12933.80 toks/s, output: 12.63 toks/s]
Processed prompts:  61%|    | 626/1024 [00:49<00:32, 12.25it/s, est. speed input: 12928.84 toks/s, output: 12.63 toks/s]
Processed prompts:  62%|   | 634/1024 [00:50<00:31, 12.24it/s, est. speed input: 12923.38 toks/s, output: 12.62 toks/s]
Processed prompts:  63%|   | 642/1024 [00:50<00:31, 12.23it/s, est. speed input: 12917.75 toks/s, output: 12.61 toks/s]
Processed prompts:  63%|   | 650/1024 [00:51<00:30, 12.26it/s, est. speed input: 12914.36 toks/s, output: 12.61 toks/s]
Processed prompts:  64%|   | 658/1024 [00:52<00:29, 12.24it/s, est. speed input: 12908.94 toks/s, output: 12.61 toks/s]
Processed prompts:  65%|   | 666/1024 [00:52<00:29, 12.24it/s, est. speed input: 12904.10 toks/s, output: 12.60 toks/s]
Processed prompts:  66%|   | 674/1024 [00:53<00:28, 12.26it/s, est. speed input: 12900.53 toks/s, output: 12.60 toks/s]
Processed prompts:  67%|   | 682/1024 [00:54<00:27, 12.26it/s, est. speed input: 12896.16 toks/s, output: 12.59 toks/s]
Processed prompts:  67%|   | 690/1024 [00:54<00:27, 12.28it/s, est. speed input: 12892.98 toks/s, output: 12.59 toks/s]
Processed prompts:  68%|   | 698/1024 [00:55<00:26, 12.26it/s, est. speed input: 12888.53 toks/s, output: 12.59 toks/s]
Processed prompts:  69%|   | 706/1024 [00:56<00:25, 12.26it/s, est. speed input: 12884.46 toks/s, output: 12.58 toks/s]
Processed prompts:  70%|   | 714/1024 [00:56<00:25, 12.32it/s, est. speed input: 12883.14 toks/s, output: 12.58 toks/s]
Processed prompts:  71%|   | 722/1024 [00:57<00:24, 12.27it/s, est. speed input: 12878.25 toks/s, output: 12.58 toks/s]
Processed prompts:  71%|  | 730/1024 [00:58<00:23, 12.29it/s, est. speed input: 12875.43 toks/s, output: 12.57 toks/s]
Processed prompts:  72%|  | 738/1024 [00:58<00:23, 12.26it/s, est. speed input: 12870.92 toks/s, output: 12.57 toks/s]
Processed prompts:  73%|  | 746/1024 [00:59<00:22, 12.24it/s, est. speed input: 12866.69 toks/s, output: 12.57 toks/s]
Processed prompts:  74%|  | 754/1024 [01:00<00:21, 12.28it/s, est. speed input: 12864.62 toks/s, output: 12.56 toks/s]
Processed prompts:  74%|  | 762/1024 [01:00<00:21, 12.27it/s, est. speed input: 12861.33 toks/s, output: 12.56 toks/s]
Processed prompts:  75%|  | 770/1024 [01:01<00:20, 12.25it/s, est. speed input: 12857.38 toks/s, output: 12.56 toks/s]
Processed prompts:  76%|  | 778/1024 [01:01<00:20, 12.25it/s, est. speed input: 12853.94 toks/s, output: 12.55 toks/s]
Processed prompts:  77%|  | 786/1024 [01:02<00:19, 12.24it/s, est. speed input: 12850.25 toks/s, output: 12.55 toks/s]
Processed prompts:  78%|  | 794/1024 [01:03<00:18, 12.27it/s, est. speed input: 12848.32 toks/s, output: 12.55 toks/s]
Processed prompts:  78%|  | 802/1024 [01:03<00:18, 12.27it/s, est. speed input: 12845.22 toks/s, output: 12.54 toks/s]
Processed prompts:  79%|  | 810/1024 [01:04<00:17, 12.26it/s, est. speed input: 12842.07 toks/s, output: 12.54 toks/s]
Processed prompts:  80%|  | 818/1024 [01:05<00:16, 12.28it/s, est. speed input: 12839.90 toks/s, output: 12.54 toks/s]
Processed prompts:  81%|  | 826/1024 [01:05<00:16, 12.27it/s, est. speed input: 12836.78 toks/s, output: 12.54 toks/s]
Processed prompts:  81%| | 834/1024 [01:06<00:15, 12.29it/s, est. speed input: 12834.88 toks/s, output: 12.53 toks/s]
Processed prompts:  82%| | 842/1024 [01:07<00:14, 12.28it/s, est. speed input: 12832.13 toks/s, output: 12.53 toks/s]
Processed prompts:  83%| | 850/1024 [01:07<00:14, 12.26it/s, est. speed input: 12828.88 toks/s, output: 12.53 toks/s]
Processed prompts:  84%| | 858/1024 [01:08<00:13, 12.26it/s, est. speed input: 12826.19 toks/s, output: 12.53 toks/s]
Processed prompts:  85%| | 866/1024 [01:09<00:12, 12.23it/s, est. speed input: 12822.82 toks/s, output: 12.52 toks/s]
Processed prompts:  85%| | 874/1024 [01:09<00:12, 12.21it/s, est. speed input: 12819.19 toks/s, output: 12.52 toks/s]
Processed prompts:  86%| | 882/1024 [01:10<00:11, 12.24it/s, est. speed input: 12817.17 toks/s, output: 12.52 toks/s]
Processed prompts:  87%| | 890/1024 [01:11<00:10, 12.23it/s, est. speed input: 12814.46 toks/s, output: 12.51 toks/s]
Processed prompts:  88%| | 898/1024 [01:11<00:10, 12.27it/s, est. speed input: 12813.05 toks/s, output: 12.51 toks/s]
Processed prompts:  88%| | 906/1024 [01:12<00:09, 12.24it/s, est. speed input: 12809.81 toks/s, output: 12.51 toks/s]
Processed prompts:  89%| | 914/1024 [01:13<00:08, 12.24it/s, est. speed input: 12807.46 toks/s, output: 12.51 toks/s]
Processed prompts:  90%| | 922/1024 [01:13<00:08, 12.26it/s, est. speed input: 12805.51 toks/s, output: 12.51 toks/s]
Processed prompts:  91%| | 930/1024 [01:14<00:07, 12.25it/s, est. speed input: 12803.15 toks/s, output: 12.50 toks/s]
Processed prompts:  92%|| 938/1024 [01:14<00:06, 12.72it/s, est. speed input: 12814.63 toks/s, output: 12.51 toks/s]
Processed prompts:  92%|| 946/1024 [01:15<00:06, 12.57it/s, est. speed input: 12811.96 toks/s, output: 12.51 toks/s]
Processed prompts:  93%|| 954/1024 [01:16<00:05, 12.45it/s, est. speed input: 12809.18 toks/s, output: 12.51 toks/s]
Processed prompts:  94%|| 962/1024 [01:16<00:04, 12.41it/s, est. speed input: 12807.45 toks/s, output: 12.51 toks/s]
Processed prompts:  95%|| 970/1024 [01:17<00:04, 12.38it/s, est. speed input: 12805.68 toks/s, output: 12.51 toks/s]
Processed prompts:  96%|| 978/1024 [01:18<00:03, 12.34it/s, est. speed input: 12803.54 toks/s, output: 12.50 toks/s]
Processed prompts:  96%|| 986/1024 [01:18<00:02, 12.76it/s, est. speed input: 12813.74 toks/s, output: 12.51 toks/s]
Processed prompts:  97%|| 994/1024 [01:19<00:02, 12.60it/s, est. speed input: 12811.37 toks/s, output: 12.51 toks/s]
Processed prompts:  98%|| 1002/1024 [01:20<00:01, 12.52it/s, est. speed input: 12809.98 toks/s, output: 12.51 toks/s]
Processed prompts:  99%|| 1010/1024 [01:20<00:01, 12.41it/s, est. speed input: 12807.02 toks/s, output: 12.51 toks/s]
Processed prompts:  99%|| 1018/1024 [01:21<00:00, 12.82it/s, est. speed input: 12817.00 toks/s, output: 12.52 toks/s]
Processed prompts: 100%|| 1024/1024 [01:21<00:00, 12.82it/s, est. speed input: 12892.52 toks/s, output: 12.59 toks/s]
Processed prompts: 100%|| 1024/1024 [01:21<00:00, 12.59it/s, est. speed input: 12892.52 toks/s, output: 12.59 toks/s]
[rank0]:[W126 10:39:52.058286379 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 10:39:55
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:40:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:40:04 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1192434) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1192434) WARNING 01-26 10:40:45 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 12.39 requests/s, 12695.71 total tokens/s, 12.39 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 10:40:04] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:40:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:40:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:40:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:40:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:40:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:40:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:40:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:40:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:40:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:40:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:40:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:40:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:40:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:40:07] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:40:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:40:07] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:40:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:40:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:40:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:40:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:40:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:40:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:40:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:40:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:40:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:40:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:40:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1192434) [2026-01-26 10:40:08] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1192434) [2026-01-26 10:40:08] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1192434) [2026-01-26 10:40:08] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1192434) [2026-01-26 10:40:08] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1192434) [2026-01-26 10:40:08] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1192434) [2026-01-26 10:40:08] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1192434) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1192434) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.02s/it]
(EngineCore_DP0 pid=1192434) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.02s/it]
(EngineCore_DP0 pid=1192434) 
(EngineCore_DP0 pid=1192434) [2026-01-26 10:40:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1192434) [2026-01-26 10:40:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=1192434) [2026-01-26 10:40:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1192434) [2026-01-26 10:40:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10616832 bytes
(EngineCore_DP0 pid=1192434) [2026-01-26 10:40:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1192434) [2026-01-26 10:40:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56623104 bytes
(EngineCore_DP0 pid=1192434) [2026-01-26 10:40:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1192434) [2026-01-26 10:40:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28311552 bytes
(EngineCore_DP0 pid=1192434) 2026-01-26 10:40:43,462 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1192434) 2026-01-26 10:40:43,583 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 60/2048 [00:00<00:03, 592.03it/s]
Adding requests:   6%|         | 120/2048 [00:00<00:03, 555.70it/s]
Adding requests:   9%|         | 176/2048 [00:00<00:03, 491.73it/s]
Adding requests:  11%|         | 226/2048 [00:00<00:03, 485.37it/s]
Adding requests:  14%|        | 280/2048 [00:00<00:03, 500.35it/s]
Adding requests:  16%|        | 335/2048 [00:00<00:03, 513.81it/s]
Adding requests:  19%|        | 390/2048 [00:00<00:03, 524.75it/s]
Adding requests:  22%|       | 443/2048 [00:00<00:03, 523.87it/s]
Adding requests:  24%|       | 497/2048 [00:00<00:02, 525.82it/s]
Adding requests:  27%|       | 550/2048 [00:01<00:02, 521.61it/s]
Adding requests:  29%|       | 603/2048 [00:01<00:02, 522.15it/s]
Adding requests:  32%|      | 660/2048 [00:01<00:02, 536.22it/s]
Adding requests:  35%|      | 716/2048 [00:01<00:02, 541.38it/s]
Adding requests:  38%|      | 771/2048 [00:01<00:02, 512.93it/s]
Adding requests:  40%|      | 823/2048 [00:01<00:02, 498.75it/s]
Adding requests:  43%|     | 874/2048 [00:02<00:05, 228.66it/s]
Adding requests:  45%|     | 927/2048 [00:02<00:04, 275.15it/s]
Adding requests:  48%|     | 979/2048 [00:02<00:03, 319.37it/s]
Adding requests:  50%|     | 1034/2048 [00:02<00:02, 366.87it/s]
Adding requests:  53%|    | 1085/2048 [00:02<00:02, 399.34it/s]
Adding requests:  56%|    | 1138/2048 [00:02<00:02, 430.93it/s]
Adding requests:  58%|    | 1193/2048 [00:02<00:01, 461.27it/s]
Adding requests:  61%|    | 1245/2048 [00:02<00:01, 469.76it/s]
Adding requests:  63%|   | 1296/2048 [00:02<00:01, 479.95it/s]
Adding requests:  66%|   | 1347/2048 [00:03<00:01, 486.92it/s]
Adding requests:  68%|   | 1399/2048 [00:03<00:01, 495.83it/s]
Adding requests:  71%|   | 1452/2048 [00:03<00:01, 503.99it/s]
Adding requests:  74%|  | 1509/2048 [00:03<00:01, 520.93it/s]
Adding requests:  76%|  | 1563/2048 [00:03<00:00, 526.50it/s]
Adding requests:  79%|  | 1619/2048 [00:03<00:00, 536.00it/s]
Adding requests:  82%| | 1673/2048 [00:03<00:00, 531.66it/s]
Adding requests:  84%| | 1729/2048 [00:03<00:00, 536.51it/s]
Adding requests:  87%| | 1783/2048 [00:03<00:00, 526.16it/s]
Adding requests:  90%| | 1836/2048 [00:03<00:00, 526.29it/s]
Adding requests:  92%|| 1889/2048 [00:04<00:00, 527.18it/s]
Adding requests:  95%|| 1942/2048 [00:04<00:00, 522.25it/s]
Adding requests:  97%|| 1995/2048 [00:04<00:00, 521.12it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 507.51it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 469.71it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 50/2048 [00:00<00:39, 50.52it/s, est. speed input: 51737.33 toks/s, output: 50.52 toks/s]
Processed prompts:   3%|         | 66/2048 [00:02<01:17, 25.67it/s, est. speed input: 29597.72 toks/s, output: 28.90 toks/s]
Processed prompts:   4%|         | 82/2048 [00:03<01:41, 19.31it/s, est. speed input: 23516.80 toks/s, output: 22.97 toks/s]
Processed prompts:   5%|         | 98/2048 [00:04<01:58, 16.47it/s, est. speed input: 20629.59 toks/s, output: 20.15 toks/s]
Processed prompts:   6%|         | 114/2048 [00:06<02:09, 14.96it/s, est. speed input: 18953.70 toks/s, output: 18.51 toks/s]
Processed prompts:   6%|         | 130/2048 [00:07<02:16, 14.06it/s, est. speed input: 17858.94 toks/s, output: 17.44 toks/s]
Processed prompts:   7%|         | 146/2048 [00:08<02:20, 13.51it/s, est. speed input: 17094.45 toks/s, output: 16.69 toks/s]
Processed prompts:   8%|         | 162/2048 [00:10<02:23, 13.14it/s, est. speed input: 16520.53 toks/s, output: 16.13 toks/s]
Processed prompts:   9%|         | 178/2048 [00:11<02:24, 12.90it/s, est. speed input: 16082.60 toks/s, output: 15.71 toks/s]
Processed prompts:   9%|         | 194/2048 [00:12<02:25, 12.73it/s, est. speed input: 15729.14 toks/s, output: 15.36 toks/s]
Processed prompts:  10%|         | 210/2048 [00:13<02:25, 12.62it/s, est. speed input: 15446.17 toks/s, output: 15.08 toks/s]
Processed prompts:  11%|         | 226/2048 [00:15<02:25, 12.54it/s, est. speed input: 15208.25 toks/s, output: 14.85 toks/s]
Processed prompts:  12%|        | 242/2048 [00:16<02:24, 12.50it/s, est. speed input: 15011.81 toks/s, output: 14.66 toks/s]
Processed prompts:  13%|        | 258/2048 [00:17<02:23, 12.46it/s, est. speed input: 14842.35 toks/s, output: 14.49 toks/s]
Processed prompts:  13%|        | 274/2048 [00:19<02:22, 12.43it/s, est. speed input: 14694.68 toks/s, output: 14.35 toks/s]
Processed prompts:  14%|        | 290/2048 [00:20<02:21, 12.42it/s, est. speed input: 14566.71 toks/s, output: 14.23 toks/s]
Processed prompts:  15%|        | 306/2048 [00:21<02:20, 12.40it/s, est. speed input: 14452.04 toks/s, output: 14.11 toks/s]
Processed prompts:  16%|        | 322/2048 [00:22<02:19, 12.40it/s, est. speed input: 14353.69 toks/s, output: 14.02 toks/s]
Processed prompts:  17%|        | 338/2048 [00:24<02:16, 12.56it/s, est. speed input: 14299.02 toks/s, output: 13.96 toks/s]
Processed prompts:  17%|        | 354/2048 [00:25<02:15, 12.49it/s, est. speed input: 14213.38 toks/s, output: 13.88 toks/s]
Processed prompts:  18%|        | 370/2048 [00:26<02:14, 12.46it/s, est. speed input: 14140.66 toks/s, output: 13.81 toks/s]
Processed prompts:  19%|        | 386/2048 [00:28<02:14, 12.35it/s, est. speed input: 14058.04 toks/s, output: 13.73 toks/s]
Processed prompts:  20%|        | 402/2048 [00:29<02:13, 12.36it/s, est. speed input: 13997.31 toks/s, output: 13.67 toks/s]
Processed prompts:  20%|        | 418/2048 [00:30<02:12, 12.34it/s, est. speed input: 13938.14 toks/s, output: 13.61 toks/s]
Processed prompts:  21%|        | 434/2048 [00:32<02:10, 12.35it/s, est. speed input: 13886.93 toks/s, output: 13.56 toks/s]
Processed prompts:  22%|       | 450/2048 [00:33<02:07, 12.54it/s, est. speed input: 13865.93 toks/s, output: 13.54 toks/s]
Processed prompts:  23%|       | 466/2048 [00:34<02:06, 12.49it/s, est. speed input: 13820.87 toks/s, output: 13.50 toks/s]
Processed prompts:  24%|       | 482/2048 [00:35<02:05, 12.46it/s, est. speed input: 13780.05 toks/s, output: 13.46 toks/s]
Processed prompts:  24%|       | 498/2048 [00:37<02:04, 12.43it/s, est. speed input: 13740.79 toks/s, output: 13.42 toks/s]
Processed prompts:  25%|       | 514/2048 [00:38<02:03, 12.42it/s, est. speed input: 13705.97 toks/s, output: 13.38 toks/s]
Processed prompts:  26%|       | 530/2048 [00:39<02:02, 12.40it/s, est. speed input: 13671.85 toks/s, output: 13.35 toks/s]
Processed prompts:  27%|       | 546/2048 [00:40<02:01, 12.41it/s, est. speed input: 13641.98 toks/s, output: 13.32 toks/s]
Processed prompts:  27%|       | 562/2048 [00:42<01:59, 12.40it/s, est. speed input: 13612.19 toks/s, output: 13.29 toks/s]
Processed prompts:  28%|       | 578/2048 [00:43<01:58, 12.38it/s, est. speed input: 13583.52 toks/s, output: 13.27 toks/s]
Processed prompts:  29%|       | 594/2048 [00:44<01:57, 12.36it/s, est. speed input: 13555.16 toks/s, output: 13.24 toks/s]
Processed prompts:  30%|       | 610/2048 [00:46<01:56, 12.37it/s, est. speed input: 13530.59 toks/s, output: 13.21 toks/s]
Processed prompts:  31%|       | 626/2048 [00:47<01:54, 12.37it/s, est. speed input: 13507.27 toks/s, output: 13.19 toks/s]
Processed prompts:  31%|      | 642/2048 [00:48<01:53, 12.35it/s, est. speed input: 13482.72 toks/s, output: 13.17 toks/s]
Processed prompts:  32%|      | 658/2048 [00:50<01:52, 12.36it/s, est. speed input: 13462.27 toks/s, output: 13.15 toks/s]
Processed prompts:  33%|      | 674/2048 [00:51<01:51, 12.36it/s, est. speed input: 13441.88 toks/s, output: 13.13 toks/s]
Processed prompts:  34%|      | 690/2048 [00:52<01:49, 12.36it/s, est. speed input: 13422.30 toks/s, output: 13.11 toks/s]
Processed prompts:  34%|      | 706/2048 [00:53<01:48, 12.36it/s, est. speed input: 13404.50 toks/s, output: 13.09 toks/s]
Processed prompts:  35%|      | 722/2048 [00:55<01:47, 12.35it/s, est. speed input: 13385.74 toks/s, output: 13.07 toks/s]
Processed prompts:  36%|      | 738/2048 [00:56<01:46, 12.35it/s, est. speed input: 13369.12 toks/s, output: 13.06 toks/s]
Processed prompts:  37%|      | 754/2048 [00:57<01:44, 12.35it/s, est. speed input: 13352.57 toks/s, output: 13.04 toks/s]
Processed prompts:  38%|      | 770/2048 [00:59<01:43, 12.34it/s, est. speed input: 13336.63 toks/s, output: 13.02 toks/s]
Processed prompts:  38%|      | 786/2048 [01:00<01:42, 12.34it/s, est. speed input: 13321.60 toks/s, output: 13.01 toks/s]
Processed prompts:  39%|      | 802/2048 [01:01<01:41, 12.33it/s, est. speed input: 13306.57 toks/s, output: 12.99 toks/s]
Processed prompts:  40%|      | 818/2048 [01:03<01:39, 12.36it/s, est. speed input: 13294.36 toks/s, output: 12.98 toks/s]
Processed prompts:  41%|      | 834/2048 [01:04<01:38, 12.36it/s, est. speed input: 13281.36 toks/s, output: 12.97 toks/s]
Processed prompts:  42%|     | 850/2048 [01:05<01:37, 12.34it/s, est. speed input: 13268.14 toks/s, output: 12.96 toks/s]
Processed prompts:  42%|     | 866/2048 [01:06<01:35, 12.34it/s, est. speed input: 13255.46 toks/s, output: 12.94 toks/s]
Processed prompts:  43%|     | 882/2048 [01:08<01:34, 12.34it/s, est. speed input: 13243.55 toks/s, output: 12.93 toks/s]
Processed prompts:  44%|     | 898/2048 [01:09<01:33, 12.34it/s, est. speed input: 13232.65 toks/s, output: 12.92 toks/s]
Processed prompts:  45%|     | 914/2048 [01:10<01:31, 12.34it/s, est. speed input: 13221.89 toks/s, output: 12.91 toks/s]
Processed prompts:  45%|     | 930/2048 [01:12<01:29, 12.55it/s, est. speed input: 13224.31 toks/s, output: 12.91 toks/s]
Processed prompts:  46%|     | 946/2048 [01:13<01:28, 12.48it/s, est. speed input: 13213.63 toks/s, output: 12.90 toks/s]
Processed prompts:  47%|     | 962/2048 [01:14<01:27, 12.44it/s, est. speed input: 13203.92 toks/s, output: 12.89 toks/s]
Processed prompts:  48%|     | 978/2048 [01:15<01:24, 12.61it/s, est. speed input: 13205.90 toks/s, output: 12.90 toks/s]
Processed prompts:  49%|     | 994/2048 [01:17<01:24, 12.54it/s, est. speed input: 13196.96 toks/s, output: 12.89 toks/s]
Processed prompts:  49%|     | 1010/2048 [01:18<01:23, 12.49it/s, est. speed input: 13188.51 toks/s, output: 12.88 toks/s]
Processed prompts:  50%|     | 1026/2048 [01:19<01:22, 12.45it/s, est. speed input: 13179.65 toks/s, output: 12.87 toks/s]
Processed prompts:  51%|     | 1042/2048 [01:21<01:20, 12.45it/s, est. speed input: 13172.73 toks/s, output: 12.86 toks/s]
Processed prompts:  52%|    | 1058/2048 [01:22<01:19, 12.42it/s, est. speed input: 13164.59 toks/s, output: 12.86 toks/s]
Processed prompts:  52%|    | 1074/2048 [01:23<01:18, 12.39it/s, est. speed input: 13156.08 toks/s, output: 12.85 toks/s]
Processed prompts:  53%|    | 1090/2048 [01:24<01:17, 12.37it/s, est. speed input: 13147.96 toks/s, output: 12.84 toks/s]
Processed prompts:  54%|    | 1106/2048 [01:26<01:16, 12.37it/s, est. speed input: 13140.43 toks/s, output: 12.83 toks/s]
Processed prompts:  55%|    | 1122/2048 [01:27<01:14, 12.36it/s, est. speed input: 13133.13 toks/s, output: 12.83 toks/s]
Processed prompts:  56%|    | 1138/2048 [01:28<01:13, 12.35it/s, est. speed input: 13125.87 toks/s, output: 12.82 toks/s]
Processed prompts:  56%|    | 1154/2048 [01:29<01:11, 12.57it/s, est. speed input: 13129.98 toks/s, output: 12.82 toks/s]
Processed prompts:  57%|    | 1170/2048 [01:31<01:10, 12.50it/s, est. speed input: 13122.90 toks/s, output: 12.82 toks/s]
Processed prompts:  58%|    | 1186/2048 [01:32<01:09, 12.46it/s, est. speed input: 13116.64 toks/s, output: 12.81 toks/s]
Processed prompts:  59%|    | 1202/2048 [01:33<01:08, 12.43it/s, est. speed input: 13110.13 toks/s, output: 12.80 toks/s]
Processed prompts:  59%|    | 1218/2048 [01:35<01:06, 12.39it/s, est. speed input: 13103.16 toks/s, output: 12.80 toks/s]
Processed prompts:  60%|    | 1234/2048 [01:36<01:05, 12.36it/s, est. speed input: 13096.18 toks/s, output: 12.79 toks/s]
Processed prompts:  61%|    | 1250/2048 [01:37<01:04, 12.35it/s, est. speed input: 13089.87 toks/s, output: 12.78 toks/s]
Processed prompts:  62%|   | 1266/2048 [01:39<01:02, 12.54it/s, est. speed input: 13092.82 toks/s, output: 12.79 toks/s]
Processed prompts:  63%|   | 1282/2048 [01:40<01:01, 12.49it/s, est. speed input: 13087.19 toks/s, output: 12.78 toks/s]
Processed prompts:  63%|   | 1298/2048 [01:41<01:00, 12.45it/s, est. speed input: 13081.77 toks/s, output: 12.78 toks/s]
Processed prompts:  64%|   | 1314/2048 [01:42<00:59, 12.41it/s, est. speed input: 13075.89 toks/s, output: 12.77 toks/s]
Processed prompts:  65%|   | 1330/2048 [01:44<00:57, 12.38it/s, est. speed input: 13070.16 toks/s, output: 12.76 toks/s]
Processed prompts:  66%|   | 1346/2048 [01:45<00:56, 12.38it/s, est. speed input: 13065.44 toks/s, output: 12.76 toks/s]
Processed prompts:  67%|   | 1362/2048 [01:46<00:55, 12.38it/s, est. speed input: 13060.56 toks/s, output: 12.75 toks/s]
Processed prompts:  67%|   | 1378/2048 [01:48<00:54, 12.37it/s, est. speed input: 13055.63 toks/s, output: 12.75 toks/s]
Processed prompts:  68%|   | 1394/2048 [01:49<00:52, 12.34it/s, est. speed input: 13049.86 toks/s, output: 12.74 toks/s]
Processed prompts:  69%|   | 1410/2048 [01:50<00:51, 12.34it/s, est. speed input: 13045.01 toks/s, output: 12.74 toks/s]
Processed prompts:  70%|   | 1426/2048 [01:51<00:50, 12.36it/s, est. speed input: 13040.86 toks/s, output: 12.74 toks/s]
Processed prompts:  70%|   | 1442/2048 [01:53<00:49, 12.35it/s, est. speed input: 13036.23 toks/s, output: 12.73 toks/s]
Processed prompts:  71%|   | 1458/2048 [01:54<00:47, 12.35it/s, est. speed input: 13031.66 toks/s, output: 12.73 toks/s]
Processed prompts:  72%|  | 1474/2048 [01:55<00:46, 12.34it/s, est. speed input: 13027.03 toks/s, output: 12.72 toks/s]
Processed prompts:  73%|  | 1490/2048 [01:57<00:45, 12.34it/s, est. speed input: 13022.85 toks/s, output: 12.72 toks/s]
Processed prompts:  74%|  | 1506/2048 [01:58<00:43, 12.34it/s, est. speed input: 13018.55 toks/s, output: 12.71 toks/s]
Processed prompts:  74%|  | 1522/2048 [01:59<00:42, 12.36it/s, est. speed input: 13015.14 toks/s, output: 12.71 toks/s]
Processed prompts:  75%|  | 1538/2048 [02:01<00:41, 12.33it/s, est. speed input: 13010.34 toks/s, output: 12.71 toks/s]
Processed prompts:  76%|  | 1554/2048 [02:02<00:40, 12.33it/s, est. speed input: 13006.29 toks/s, output: 12.70 toks/s]
Processed prompts:  77%|  | 1570/2048 [02:03<00:38, 12.36it/s, est. speed input: 13003.33 toks/s, output: 12.70 toks/s]
Processed prompts:  77%|  | 1586/2048 [02:04<00:36, 12.55it/s, est. speed input: 13006.42 toks/s, output: 12.70 toks/s]
Processed prompts:  78%|  | 1602/2048 [02:06<00:35, 12.50it/s, est. speed input: 13003.01 toks/s, output: 12.70 toks/s]
Processed prompts:  79%|  | 1618/2048 [02:07<00:34, 12.44it/s, est. speed input: 12998.88 toks/s, output: 12.69 toks/s]
Processed prompts:  80%|  | 1634/2048 [02:08<00:33, 12.43it/s, est. speed input: 12995.90 toks/s, output: 12.69 toks/s]
Processed prompts:  81%|  | 1650/2048 [02:10<00:32, 12.40it/s, est. speed input: 12992.18 toks/s, output: 12.69 toks/s]
Processed prompts:  81%| | 1666/2048 [02:11<00:30, 12.37it/s, est. speed input: 12988.45 toks/s, output: 12.68 toks/s]
Processed prompts:  82%| | 1682/2048 [02:12<00:29, 12.35it/s, est. speed input: 12984.66 toks/s, output: 12.68 toks/s]
Processed prompts:  83%| | 1698/2048 [02:13<00:28, 12.35it/s, est. speed input: 12981.33 toks/s, output: 12.68 toks/s]
Processed prompts:  84%| | 1714/2048 [02:15<00:27, 12.35it/s, est. speed input: 12977.99 toks/s, output: 12.67 toks/s]
Processed prompts:  84%| | 1730/2048 [02:16<00:25, 12.35it/s, est. speed input: 12974.96 toks/s, output: 12.67 toks/s]
Processed prompts:  85%| | 1746/2048 [02:17<00:24, 12.35it/s, est. speed input: 12971.87 toks/s, output: 12.67 toks/s]
Processed prompts:  86%| | 1762/2048 [02:19<00:23, 12.33it/s, est. speed input: 12968.28 toks/s, output: 12.66 toks/s]
Processed prompts:  87%| | 1778/2048 [02:20<00:21, 12.33it/s, est. speed input: 12965.15 toks/s, output: 12.66 toks/s]
Processed prompts:  88%| | 1794/2048 [02:21<00:20, 12.33it/s, est. speed input: 12961.86 toks/s, output: 12.66 toks/s]
Processed prompts:  88%| | 1810/2048 [02:23<00:19, 12.33it/s, est. speed input: 12958.91 toks/s, output: 12.66 toks/s]
Processed prompts:  89%| | 1826/2048 [02:24<00:17, 12.36it/s, est. speed input: 12956.72 toks/s, output: 12.65 toks/s]
Processed prompts:  90%| | 1842/2048 [02:25<00:16, 12.35it/s, est. speed input: 12953.78 toks/s, output: 12.65 toks/s]
Processed prompts:  91%| | 1858/2048 [02:26<00:15, 12.35it/s, est. speed input: 12951.22 toks/s, output: 12.65 toks/s]
Processed prompts:  92%|| 1874/2048 [02:28<00:13, 12.53it/s, est. speed input: 12953.94 toks/s, output: 12.65 toks/s]
Processed prompts:  92%|| 1890/2048 [02:29<00:12, 12.49it/s, est. speed input: 12951.75 toks/s, output: 12.65 toks/s]
Processed prompts:  93%|| 1906/2048 [02:30<00:11, 12.43it/s, est. speed input: 12948.67 toks/s, output: 12.65 toks/s]
Processed prompts:  94%|| 1922/2048 [02:32<00:10, 12.40it/s, est. speed input: 12945.85 toks/s, output: 12.64 toks/s]
Processed prompts:  95%|| 1938/2048 [02:33<00:08, 12.39it/s, est. speed input: 12943.42 toks/s, output: 12.64 toks/s]
Processed prompts:  95%|| 1954/2048 [02:34<00:07, 12.58it/s, est. speed input: 12946.73 toks/s, output: 12.64 toks/s]
Processed prompts:  96%|| 1970/2048 [02:35<00:06, 12.50it/s, est. speed input: 12943.89 toks/s, output: 12.64 toks/s]
Processed prompts:  97%|| 1986/2048 [02:37<00:05, 12.39it/s, est. speed input: 12939.63 toks/s, output: 12.64 toks/s]
Processed prompts:  98%|| 2002/2048 [02:38<00:03, 12.38it/s, est. speed input: 12937.20 toks/s, output: 12.63 toks/s]
Processed prompts:  99%|| 2018/2048 [02:39<00:02, 12.37it/s, est. speed input: 12934.75 toks/s, output: 12.63 toks/s]
Processed prompts:  99%|| 2034/2048 [02:40<00:01, 12.56it/s, est. speed input: 12937.92 toks/s, output: 12.63 toks/s]
Processed prompts: 100%|| 2048/2048 [02:40<00:00, 12.56it/s, est. speed input: 13026.96 toks/s, output: 12.72 toks/s]
Processed prompts: 100%|| 2048/2048 [02:40<00:00, 12.72it/s, est. speed input: 13026.96 toks/s, output: 12.72 toks/s]
[rank0]:[W126 10:43:30.119340137 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 10:43:33
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:43:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:43:48 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1195704) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1195704) WARNING 01-26 10:44:32 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 12.21 requests/s, 12511.93 total tokens/s, 12.21 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 10:43:48] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:43:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:43:48] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:43:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:43:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:43:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:43:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:43:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:43:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:43:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:43:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:43:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:43:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:43:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:43:51] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:43:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:43:51] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:43:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:43:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:43:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:43:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:43:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:43:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:43:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:43:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:43:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:43:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:43:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1195704) [2026-01-26 10:43:52] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1195704) [2026-01-26 10:43:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1195704) [2026-01-26 10:43:52] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1195704) [2026-01-26 10:43:52] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1195704) [2026-01-26 10:43:52] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1195704) [2026-01-26 10:43:52] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1195704) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1195704) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.18s/it]
(EngineCore_DP0 pid=1195704) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.18s/it]
(EngineCore_DP0 pid=1195704) 
(EngineCore_DP0 pid=1195704) [2026-01-26 10:44:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1195704) [2026-01-26 10:44:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=1195704) [2026-01-26 10:44:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1195704) [2026-01-26 10:44:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10616832 bytes
(EngineCore_DP0 pid=1195704) [2026-01-26 10:44:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1195704) [2026-01-26 10:44:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56623104 bytes
(EngineCore_DP0 pid=1195704) [2026-01-26 10:44:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1195704) [2026-01-26 10:44:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28311552 bytes
(EngineCore_DP0 pid=1195704) 2026-01-26 10:44:28,617 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1195704) 2026-01-26 10:44:29,024 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|         | 61/4096 [00:00<00:06, 608.45it/s]
Adding requests:   3%|         | 122/4096 [00:00<00:06, 572.53it/s]
Adding requests:   4%|         | 180/4096 [00:00<00:07, 556.72it/s]
Adding requests:   6%|         | 236/4096 [00:00<00:07, 542.78it/s]
Adding requests:   7%|         | 291/4096 [00:00<00:07, 539.09it/s]
Adding requests:   8%|         | 346/4096 [00:00<00:06, 540.59it/s]
Adding requests:  10%|         | 401/4096 [00:00<00:06, 541.94it/s]
Adding requests:  11%|         | 456/4096 [00:00<00:06, 541.32it/s]
Adding requests:  12%|        | 511/4096 [00:00<00:06, 526.13it/s]
Adding requests:  14%|        | 564/4096 [00:01<00:06, 516.87it/s]
Adding requests:  15%|        | 616/4096 [00:01<00:06, 515.22it/s]
Adding requests:  16%|        | 673/4096 [00:01<00:06, 531.22it/s]
Adding requests:  18%|        | 728/4096 [00:01<00:06, 534.78it/s]
Adding requests:  19%|        | 782/4096 [00:01<00:06, 530.43it/s]
Adding requests:  20%|        | 836/4096 [00:01<00:06, 512.82it/s]
Adding requests:  22%|       | 893/4096 [00:01<00:06, 529.24it/s]
Adding requests:  23%|       | 947/4096 [00:01<00:05, 531.29it/s]
Adding requests:  24%|       | 1001/4096 [00:01<00:05, 532.32it/s]
Adding requests:  26%|       | 1055/4096 [00:01<00:05, 534.15it/s]
Adding requests:  27%|       | 1109/4096 [00:02<00:05, 534.19it/s]
Adding requests:  28%|       | 1163/4096 [00:02<00:05, 535.43it/s]
Adding requests:  30%|       | 1217/4096 [00:02<00:05, 513.47it/s]
Adding requests:  31%|       | 1269/4096 [00:02<00:05, 515.20it/s]
Adding requests:  32%|      | 1321/4096 [00:02<00:05, 509.93it/s]
Adding requests:  34%|      | 1377/4096 [00:02<00:05, 523.00it/s]
Adding requests:  35%|      | 1433/4096 [00:02<00:05, 531.73it/s]
Adding requests:  36%|      | 1491/4096 [00:02<00:04, 542.92it/s]
Adding requests:  38%|      | 1546/4096 [00:02<00:04, 538.43it/s]
Adding requests:  39%|      | 1602/4096 [00:03<00:04, 541.53it/s]
Adding requests:  40%|      | 1657/4096 [00:03<00:04, 537.33it/s]
Adding requests:  42%|     | 1711/4096 [00:03<00:04, 535.17it/s]
Adding requests:  43%|     | 1765/4096 [00:03<00:04, 536.20it/s]
Adding requests:  44%|     | 1821/4096 [00:03<00:04, 543.03it/s]
Adding requests:  46%|     | 1876/4096 [00:03<00:04, 543.42it/s]
Adding requests:  47%|     | 1932/4096 [00:03<00:03, 547.74it/s]
Adding requests:  49%|     | 1987/4096 [00:03<00:03, 539.40it/s]
Adding requests:  50%|     | 2044/4096 [00:03<00:03, 546.25it/s]
Adding requests:  51%|     | 2099/4096 [00:03<00:03, 540.03it/s]
Adding requests:  53%|    | 2154/4096 [00:04<00:03, 533.79it/s]
Adding requests:  54%|    | 2208/4096 [00:04<00:03, 535.30it/s]
Adding requests:  55%|    | 2263/4096 [00:04<00:03, 539.28it/s]
Adding requests:  57%|    | 2319/4096 [00:04<00:03, 545.38it/s]
Adding requests:  58%|    | 2374/4096 [00:04<00:03, 536.25it/s]
Adding requests:  59%|    | 2428/4096 [00:04<00:03, 523.40it/s]
Adding requests:  61%|    | 2481/4096 [00:04<00:03, 520.24it/s]
Adding requests:  62%|   | 2536/4096 [00:04<00:02, 524.88it/s]
Adding requests:  63%|   | 2591/4096 [00:04<00:02, 531.24it/s]
Adding requests:  65%|   | 2648/4096 [00:04<00:02, 541.71it/s]
Adding requests:  66%|   | 2703/4096 [00:05<00:02, 537.07it/s]
Adding requests:  67%|   | 2759/4096 [00:05<00:02, 540.97it/s]
Adding requests:  69%|   | 2814/4096 [00:05<00:02, 536.20it/s]
Adding requests:  70%|   | 2869/4096 [00:05<00:02, 538.55it/s]
Adding requests:  71%|  | 2923/4096 [00:05<00:02, 536.30it/s]
Adding requests:  73%|  | 2977/4096 [00:05<00:02, 530.49it/s]
Adding requests:  74%|  | 3032/4096 [00:05<00:01, 534.76it/s]
Adding requests:  75%|  | 3088/4096 [00:05<00:01, 540.51it/s]
Adding requests:  77%|  | 3143/4096 [00:05<00:01, 530.15it/s]
Adding requests:  78%|  | 3199/4096 [00:05<00:01, 538.30it/s]
Adding requests:  79%|  | 3255/4096 [00:06<00:01, 543.17it/s]
Adding requests:  81%|  | 3311/4096 [00:06<00:01, 547.24it/s]
Adding requests:  82%| | 3366/4096 [00:06<00:01, 542.49it/s]
Adding requests:  84%| | 3422/4096 [00:06<00:01, 544.91it/s]
Adding requests:  85%| | 3477/4096 [00:06<00:01, 532.79it/s]
Adding requests:  86%| | 3531/4096 [00:06<00:01, 528.52it/s]
Adding requests:  88%| | 3585/4096 [00:06<00:00, 530.27it/s]
Adding requests:  89%| | 3640/4096 [00:06<00:00, 533.48it/s]
Adding requests:  90%| | 3697/4096 [00:06<00:00, 541.44it/s]
Adding requests:  92%|| 3753/4096 [00:07<00:00, 545.69it/s]
Adding requests:  93%|| 3808/4096 [00:07<00:00, 530.92it/s]
Adding requests:  94%|| 3865/4096 [00:07<00:00, 538.84it/s]
Adding requests:  96%|| 3919/4096 [00:07<00:00, 538.15it/s]
Adding requests:  97%|| 3975/4096 [00:07<00:00, 542.61it/s]
Adding requests:  98%|| 4030/4096 [00:07<00:00, 541.67it/s]
Adding requests: 100%|| 4085/4096 [00:07<00:00, 541.20it/s]
Adding requests: 100%|| 4096/4096 [00:07<00:00, 535.94it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 66/4096 [00:00<00:26, 154.33it/s, est. speed input: 158036.93 toks/s, output: 154.33 toks/s]
Processed prompts:   2%|         | 98/4096 [00:03<02:29, 26.78it/s, est. speed input: 32915.58 toks/s, output: 32.14 toks/s]   
Processed prompts:   3%|         | 130/4096 [00:05<03:33, 18.60it/s, est. speed input: 23485.00 toks/s, output: 22.93 toks/s]
Processed prompts:   4%|         | 162/4096 [00:08<04:10, 15.73it/s, est. speed input: 19993.52 toks/s, output: 19.52 toks/s]
Processed prompts:   5%|         | 194/4096 [00:10<04:31, 14.36it/s, est. speed input: 18189.57 toks/s, output: 17.76 toks/s]
Processed prompts:   6%|         | 226/4096 [00:13<04:44, 13.58it/s, est. speed input: 17082.76 toks/s, output: 16.68 toks/s]
Processed prompts:   6%|         | 258/4096 [00:16<04:52, 13.11it/s, est. speed input: 16338.17 toks/s, output: 15.96 toks/s]
Processed prompts:   7%|         | 290/4096 [00:18<04:57, 12.81it/s, est. speed input: 15798.28 toks/s, output: 15.43 toks/s]
Processed prompts:   8%|         | 322/4096 [00:21<04:57, 12.69it/s, est. speed input: 15427.49 toks/s, output: 15.07 toks/s]
Processed prompts:   9%|         | 354/4096 [00:23<04:58, 12.53it/s, est. speed input: 15105.34 toks/s, output: 14.75 toks/s]
Processed prompts:   9%|         | 386/4096 [00:26<05:05, 12.16it/s, est. speed input: 14743.06 toks/s, output: 14.40 toks/s]
Processed prompts:  10%|         | 418/4096 [00:29<05:02, 12.15it/s, est. speed input: 14536.69 toks/s, output: 14.20 toks/s]
Processed prompts:  11%|         | 450/4096 [00:32<04:57, 12.25it/s, est. speed input: 14395.85 toks/s, output: 14.06 toks/s]
Processed prompts:  12%|        | 482/4096 [00:34<04:55, 12.23it/s, est. speed input: 14249.90 toks/s, output: 13.92 toks/s]
Processed prompts:  13%|        | 514/4096 [00:37<04:53, 12.22it/s, est. speed input: 14126.00 toks/s, output: 13.79 toks/s]
Processed prompts:  13%|        | 546/4096 [00:39<04:50, 12.20it/s, est. speed input: 14015.83 toks/s, output: 13.69 toks/s]
Processed prompts:  14%|        | 578/4096 [00:42<04:48, 12.20it/s, est. speed input: 13920.85 toks/s, output: 13.59 toks/s]
Processed prompts:  15%|        | 610/4096 [00:45<04:46, 12.19it/s, est. speed input: 13835.70 toks/s, output: 13.51 toks/s]
Processed prompts:  16%|        | 642/4096 [00:47<04:43, 12.19it/s, est. speed input: 13761.52 toks/s, output: 13.44 toks/s]
Processed prompts:  16%|        | 674/4096 [00:50<04:40, 12.18it/s, est. speed input: 13692.80 toks/s, output: 13.37 toks/s]
Processed prompts:  17%|        | 706/4096 [00:53<04:38, 12.18it/s, est. speed input: 13633.06 toks/s, output: 13.31 toks/s]
Processed prompts:  18%|        | 738/4096 [00:55<04:35, 12.18it/s, est. speed input: 13578.51 toks/s, output: 13.26 toks/s]
Processed prompts:  19%|        | 770/4096 [00:58<04:34, 12.14it/s, est. speed input: 13520.91 toks/s, output: 13.20 toks/s]
Processed prompts:  20%|        | 802/4096 [01:00<04:31, 12.15it/s, est. speed input: 13475.70 toks/s, output: 13.16 toks/s]
Processed prompts:  20%|        | 834/4096 [01:03<04:28, 12.16it/s, est. speed input: 13433.69 toks/s, output: 13.12 toks/s]
Processed prompts:  21%|        | 866/4096 [01:06<04:25, 12.16it/s, est. speed input: 13395.32 toks/s, output: 13.08 toks/s]
Processed prompts:  22%|       | 898/4096 [01:08<04:23, 12.16it/s, est. speed input: 13359.09 toks/s, output: 13.05 toks/s]
Processed prompts:  23%|       | 930/4096 [01:11<04:18, 12.26it/s, est. speed input: 13339.28 toks/s, output: 13.03 toks/s]
Processed prompts:  23%|       | 962/4096 [01:13<04:14, 12.32it/s, est. speed input: 13319.22 toks/s, output: 13.01 toks/s]
Processed prompts:  24%|       | 994/4096 [01:16<04:12, 12.28it/s, est. speed input: 13290.52 toks/s, output: 12.98 toks/s]
Processed prompts:  25%|       | 1026/4096 [01:19<04:10, 12.24it/s, est. speed input: 13262.06 toks/s, output: 12.95 toks/s]
Processed prompts:  26%|       | 1058/4096 [01:21<04:08, 12.22it/s, est. speed input: 13236.64 toks/s, output: 12.93 toks/s]
Processed prompts:  27%|       | 1090/4096 [01:24<04:06, 12.19it/s, est. speed input: 13211.19 toks/s, output: 12.90 toks/s]
Processed prompts:  27%|       | 1122/4096 [01:27<04:03, 12.19it/s, est. speed input: 13189.28 toks/s, output: 12.88 toks/s]
Processed prompts:  28%|       | 1154/4096 [01:29<04:00, 12.26it/s, est. speed input: 13175.41 toks/s, output: 12.87 toks/s]
Processed prompts:  29%|       | 1186/4096 [01:32<03:58, 12.22it/s, est. speed input: 13154.20 toks/s, output: 12.85 toks/s]
Processed prompts:  30%|       | 1218/4096 [01:34<03:55, 12.21it/s, est. speed input: 13135.60 toks/s, output: 12.83 toks/s]
Processed prompts:  31%|       | 1250/4096 [01:37<03:51, 12.29it/s, est. speed input: 13125.97 toks/s, output: 12.82 toks/s]
Processed prompts:  31%|      | 1282/4096 [01:40<03:49, 12.26it/s, est. speed input: 13109.12 toks/s, output: 12.80 toks/s]
Processed prompts:  32%|      | 1314/4096 [01:42<03:47, 12.23it/s, est. speed input: 13092.36 toks/s, output: 12.79 toks/s]
Processed prompts:  33%|      | 1346/4096 [01:45<03:45, 12.22it/s, est. speed input: 13077.02 toks/s, output: 12.77 toks/s]
Processed prompts:  34%|      | 1378/4096 [01:48<03:42, 12.20it/s, est. speed input: 13061.85 toks/s, output: 12.76 toks/s]
Processed prompts:  34%|      | 1410/4096 [01:50<03:40, 12.19it/s, est. speed input: 13047.56 toks/s, output: 12.74 toks/s]
Processed prompts:  35%|      | 1442/4096 [01:53<03:37, 12.19it/s, est. speed input: 13034.18 toks/s, output: 12.73 toks/s]
Processed prompts:  36%|      | 1474/4096 [01:55<03:35, 12.18it/s, est. speed input: 13021.12 toks/s, output: 12.72 toks/s]
Processed prompts:  37%|      | 1506/4096 [01:58<03:32, 12.17it/s, est. speed input: 13008.19 toks/s, output: 12.70 toks/s]
Processed prompts:  38%|      | 1538/4096 [02:01<03:30, 12.16it/s, est. speed input: 12995.76 toks/s, output: 12.69 toks/s]
Processed prompts:  38%|      | 1570/4096 [02:03<03:26, 12.22it/s, est. speed input: 12988.74 toks/s, output: 12.68 toks/s]
Processed prompts:  39%|      | 1602/4096 [02:06<03:24, 12.20it/s, est. speed input: 12977.31 toks/s, output: 12.67 toks/s]
Processed prompts:  40%|      | 1634/4096 [02:09<03:21, 12.20it/s, est. speed input: 12967.41 toks/s, output: 12.66 toks/s]
Processed prompts:  41%|      | 1666/4096 [02:11<03:19, 12.18it/s, est. speed input: 12956.68 toks/s, output: 12.65 toks/s]
Processed prompts:  41%|     | 1698/4096 [02:14<03:16, 12.18it/s, est. speed input: 12947.29 toks/s, output: 12.64 toks/s]
Processed prompts:  42%|     | 1730/4096 [02:16<03:14, 12.18it/s, est. speed input: 12937.95 toks/s, output: 12.63 toks/s]
Processed prompts:  43%|     | 1762/4096 [02:19<03:11, 12.17it/s, est. speed input: 12928.81 toks/s, output: 12.63 toks/s]
Processed prompts:  44%|     | 1794/4096 [02:22<03:09, 12.17it/s, est. speed input: 12919.92 toks/s, output: 12.62 toks/s]
Processed prompts:  45%|     | 1826/4096 [02:24<03:06, 12.17it/s, est. speed input: 12911.78 toks/s, output: 12.61 toks/s]
Processed prompts:  45%|     | 1858/4096 [02:27<03:02, 12.26it/s, est. speed input: 12909.37 toks/s, output: 12.61 toks/s]
Processed prompts:  46%|     | 1890/4096 [02:30<03:00, 12.23it/s, est. speed input: 12901.63 toks/s, output: 12.60 toks/s]
Processed prompts:  47%|     | 1922/4096 [02:32<02:58, 12.21it/s, est. speed input: 12893.68 toks/s, output: 12.59 toks/s]
Processed prompts:  48%|     | 1954/4096 [02:35<02:54, 12.27it/s, est. speed input: 12890.68 toks/s, output: 12.59 toks/s]
Processed prompts:  48%|     | 1986/4096 [02:37<02:52, 12.24it/s, est. speed input: 12883.53 toks/s, output: 12.58 toks/s]
Processed prompts:  49%|     | 2018/4096 [02:40<02:50, 12.22it/s, est. speed input: 12876.82 toks/s, output: 12.58 toks/s]
Processed prompts:  50%|     | 2050/4096 [02:43<02:47, 12.22it/s, est. speed input: 12870.99 toks/s, output: 12.57 toks/s]
Processed prompts:  51%|     | 2082/4096 [02:45<02:45, 12.20it/s, est. speed input: 12864.18 toks/s, output: 12.56 toks/s]
Processed prompts:  52%|    | 2114/4096 [02:48<02:42, 12.20it/s, est. speed input: 12858.18 toks/s, output: 12.56 toks/s]
Processed prompts:  52%|    | 2146/4096 [02:50<02:40, 12.18it/s, est. speed input: 12851.90 toks/s, output: 12.55 toks/s]
Processed prompts:  53%|    | 2178/4096 [02:53<02:37, 12.19it/s, est. speed input: 12846.37 toks/s, output: 12.55 toks/s]
Processed prompts:  54%|    | 2210/4096 [02:56<02:32, 12.36it/s, est. speed input: 12849.89 toks/s, output: 12.55 toks/s]
Processed prompts:  55%|    | 2242/4096 [02:58<02:30, 12.30it/s, est. speed input: 12843.99 toks/s, output: 12.54 toks/s]
Processed prompts:  56%|    | 2274/4096 [03:01<02:27, 12.35it/s, est. speed input: 12842.94 toks/s, output: 12.54 toks/s]
Processed prompts:  56%|    | 2306/4096 [03:03<02:25, 12.30it/s, est. speed input: 12837.56 toks/s, output: 12.54 toks/s]
Processed prompts:  57%|    | 2338/4096 [03:06<02:22, 12.30it/s, est. speed input: 12834.31 toks/s, output: 12.53 toks/s]
Processed prompts:  58%|    | 2370/4096 [03:09<02:18, 12.45it/s, est. speed input: 12838.17 toks/s, output: 12.54 toks/s]
Processed prompts:  59%|    | 2402/4096 [03:11<02:16, 12.37it/s, est. speed input: 12833.35 toks/s, output: 12.53 toks/s]
Processed prompts:  59%|    | 2434/4096 [03:14<02:15, 12.31it/s, est. speed input: 12828.04 toks/s, output: 12.53 toks/s]
Processed prompts:  60%|    | 2466/4096 [03:16<02:12, 12.27it/s, est. speed input: 12823.37 toks/s, output: 12.52 toks/s]
Processed prompts:  61%|    | 2498/4096 [03:19<02:09, 12.33it/s, est. speed input: 12822.76 toks/s, output: 12.52 toks/s]
Processed prompts:  62%|   | 2530/4096 [03:22<02:07, 12.29it/s, est. speed input: 12818.30 toks/s, output: 12.52 toks/s]
Processed prompts:  63%|   | 2562/4096 [03:24<02:04, 12.35it/s, est. speed input: 12818.17 toks/s, output: 12.52 toks/s]
Processed prompts:  63%|   | 2594/4096 [03:27<02:02, 12.30it/s, est. speed input: 12813.63 toks/s, output: 12.51 toks/s]
Processed prompts:  64%|   | 2626/4096 [03:29<01:59, 12.26it/s, est. speed input: 12809.34 toks/s, output: 12.51 toks/s]
Processed prompts:  65%|   | 2658/4096 [03:32<01:57, 12.23it/s, est. speed input: 12804.92 toks/s, output: 12.50 toks/s]
Processed prompts:  66%|   | 2690/4096 [03:35<01:55, 12.22it/s, est. speed input: 12800.98 toks/s, output: 12.50 toks/s]
Processed prompts:  66%|   | 2722/4096 [03:37<01:52, 12.19it/s, est. speed input: 12796.47 toks/s, output: 12.50 toks/s]
Processed prompts:  67%|   | 2754/4096 [03:40<01:50, 12.15it/s, est. speed input: 12790.75 toks/s, output: 12.49 toks/s]
Processed prompts:  68%|   | 2786/4096 [03:43<01:47, 12.15it/s, est. speed input: 12786.67 toks/s, output: 12.49 toks/s]
Processed prompts:  69%|   | 2818/4096 [03:45<01:45, 12.15it/s, est. speed input: 12782.81 toks/s, output: 12.48 toks/s]
Processed prompts:  70%|   | 2850/4096 [03:48<01:42, 12.15it/s, est. speed input: 12778.90 toks/s, output: 12.48 toks/s]
Processed prompts:  70%|   | 2882/4096 [03:51<01:39, 12.16it/s, est. speed input: 12775.33 toks/s, output: 12.48 toks/s]
Processed prompts:  71%|   | 2914/4096 [03:53<01:37, 12.16it/s, est. speed input: 12771.60 toks/s, output: 12.47 toks/s]
Processed prompts:  72%|  | 2946/4096 [03:56<01:34, 12.16it/s, est. speed input: 12768.27 toks/s, output: 12.47 toks/s]
Processed prompts:  73%|  | 2978/4096 [03:58<01:31, 12.16it/s, est. speed input: 12764.86 toks/s, output: 12.47 toks/s]
Processed prompts:  73%|  | 3010/4096 [04:01<01:29, 12.17it/s, est. speed input: 12761.56 toks/s, output: 12.46 toks/s]
Processed prompts:  74%|  | 3042/4096 [04:04<01:26, 12.16it/s, est. speed input: 12758.24 toks/s, output: 12.46 toks/s]
Processed prompts:  75%|  | 3074/4096 [04:06<01:23, 12.17it/s, est. speed input: 12755.17 toks/s, output: 12.46 toks/s]
Processed prompts:  76%|  | 3106/4096 [04:09<01:21, 12.17it/s, est. speed input: 12752.01 toks/s, output: 12.45 toks/s]
Processed prompts:  77%|  | 3138/4096 [04:11<01:18, 12.24it/s, est. speed input: 12751.46 toks/s, output: 12.45 toks/s]
Processed prompts:  77%|  | 3170/4096 [04:14<01:15, 12.22it/s, est. speed input: 12748.49 toks/s, output: 12.45 toks/s]
Processed prompts:  78%|  | 3202/4096 [04:17<01:13, 12.20it/s, est. speed input: 12745.47 toks/s, output: 12.45 toks/s]
Processed prompts:  79%|  | 3234/4096 [04:19<01:10, 12.19it/s, est. speed input: 12742.65 toks/s, output: 12.44 toks/s]
Processed prompts:  80%|  | 3266/4096 [04:22<01:08, 12.18it/s, est. speed input: 12739.57 toks/s, output: 12.44 toks/s]
Processed prompts:  81%|  | 3298/4096 [04:25<01:05, 12.18it/s, est. speed input: 12737.04 toks/s, output: 12.44 toks/s]
Processed prompts:  81%| | 3330/4096 [04:27<01:02, 12.17it/s, est. speed input: 12734.18 toks/s, output: 12.44 toks/s]
Processed prompts:  82%| | 3362/4096 [04:30<01:00, 12.17it/s, est. speed input: 12731.60 toks/s, output: 12.43 toks/s]
Processed prompts:  83%| | 3394/4096 [04:33<00:57, 12.17it/s, est. speed input: 12728.80 toks/s, output: 12.43 toks/s]
Processed prompts:  84%| | 3426/4096 [04:35<00:55, 12.17it/s, est. speed input: 12726.21 toks/s, output: 12.43 toks/s]
Processed prompts:  84%| | 3458/4096 [04:38<00:52, 12.16it/s, est. speed input: 12723.46 toks/s, output: 12.43 toks/s]
Processed prompts:  85%| | 3490/4096 [04:40<00:49, 12.36it/s, est. speed input: 12727.41 toks/s, output: 12.43 toks/s]
Processed prompts:  86%| | 3522/4096 [04:43<00:46, 12.27it/s, est. speed input: 12723.91 toks/s, output: 12.43 toks/s]
Processed prompts:  87%| | 3554/4096 [04:46<00:44, 12.23it/s, est. speed input: 12721.26 toks/s, output: 12.42 toks/s]
Processed prompts:  88%| | 3586/4096 [04:48<00:41, 12.21it/s, est. speed input: 12718.71 toks/s, output: 12.42 toks/s]
Processed prompts:  88%| | 3618/4096 [04:51<00:39, 12.20it/s, est. speed input: 12716.45 toks/s, output: 12.42 toks/s]
Processed prompts:  89%| | 3650/4096 [04:53<00:36, 12.19it/s, est. speed input: 12714.25 toks/s, output: 12.42 toks/s]
Processed prompts:  90%| | 3682/4096 [04:56<00:33, 12.18it/s, est. speed input: 12711.78 toks/s, output: 12.41 toks/s]
Processed prompts:  91%| | 3714/4096 [04:59<00:31, 12.27it/s, est. speed input: 12712.50 toks/s, output: 12.41 toks/s]
Processed prompts:  91%|| 3746/4096 [05:01<00:28, 12.24it/s, est. speed input: 12710.25 toks/s, output: 12.41 toks/s]
Processed prompts:  92%|| 3778/4096 [05:04<00:26, 12.22it/s, est. speed input: 12708.12 toks/s, output: 12.41 toks/s]
Processed prompts:  93%|| 3810/4096 [05:07<00:23, 12.19it/s, est. speed input: 12705.73 toks/s, output: 12.41 toks/s]
Processed prompts:  94%|| 3842/4096 [05:09<00:20, 12.28it/s, est. speed input: 12706.25 toks/s, output: 12.41 toks/s]
Processed prompts:  95%|| 3874/4096 [05:12<00:18, 12.25it/s, est. speed input: 12704.30 toks/s, output: 12.41 toks/s]
Processed prompts:  95%|| 3906/4096 [05:14<00:15, 12.22it/s, est. speed input: 12702.25 toks/s, output: 12.40 toks/s]
Processed prompts:  96%|| 3938/4096 [05:17<00:12, 12.18it/s, est. speed input: 12699.57 toks/s, output: 12.40 toks/s]
Processed prompts:  97%|| 3970/4096 [05:20<00:10, 12.18it/s, est. speed input: 12697.61 toks/s, output: 12.40 toks/s]
Processed prompts:  98%|| 4002/4096 [05:22<00:07, 12.16it/s, est. speed input: 12695.36 toks/s, output: 12.40 toks/s]
Processed prompts:  98%|| 4034/4096 [05:25<00:05, 12.27it/s, est. speed input: 12696.31 toks/s, output: 12.40 toks/s]
Processed prompts:  99%|| 4066/4096 [05:27<00:02, 12.35it/s, est. speed input: 12697.47 toks/s, output: 12.40 toks/s]
Processed prompts: 100%|| 4096/4096 [05:27<00:00, 12.35it/s, est. speed input: 12791.14 toks/s, output: 12.49 toks/s]
Processed prompts: 100%|| 4096/4096 [05:27<00:00, 12.49it/s, est. speed input: 12791.14 toks/s, output: 12.49 toks/s]
[rank0]:[W126 10:50:08.442329695 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 10:50:10
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:50:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:50:36 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1201517) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1201517) WARNING 01-26 10:51:25 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 12.22 requests/s, 12530.28 total tokens/s, 12.22 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 10:50:36] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:50:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:50:36] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:50:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:50:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:50:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:50:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:50:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:50:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:50:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:50:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:50:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:50:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:50:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:50:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:50:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:50:40] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:50:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:50:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:50:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:50:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:50:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:50:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:50:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:50:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:50:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:50:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:50:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1201517) [2026-01-26 10:50:41] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1201517) [2026-01-26 10:50:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1201517) [2026-01-26 10:50:41] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1201517) [2026-01-26 10:50:41] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1201517) [2026-01-26 10:50:41] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1201517) [2026-01-26 10:50:41] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1201517) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1201517) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.08s/it]
(EngineCore_DP0 pid=1201517) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27<00:00, 27.08s/it]
(EngineCore_DP0 pid=1201517) 
(EngineCore_DP0 pid=1201517) [2026-01-26 10:51:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1201517) [2026-01-26 10:51:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=1201517) [2026-01-26 10:51:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1201517) [2026-01-26 10:51:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 10616832 bytes
(EngineCore_DP0 pid=1201517) [2026-01-26 10:51:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1201517) [2026-01-26 10:51:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 56623104 bytes
(EngineCore_DP0 pid=1201517) [2026-01-26 10:51:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1201517) [2026-01-26 10:51:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 28311552 bytes
(EngineCore_DP0 pid=1201517) 2026-01-26 10:51:19,523 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1201517) 2026-01-26 10:51:19,831 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 65/8192 [00:00<00:12, 647.39it/s]
Adding requests:   2%|         | 130/8192 [00:00<00:13, 577.96it/s]
Adding requests:   2%|         | 189/8192 [00:00<00:14, 549.72it/s]
Adding requests:   3%|         | 245/8192 [00:00<00:14, 545.67it/s]
Adding requests:   4%|         | 300/8192 [00:00<00:14, 544.89it/s]
Adding requests:   4%|         | 355/8192 [00:00<00:14, 541.17it/s]
Adding requests:   5%|         | 410/8192 [00:00<00:14, 541.28it/s]
Adding requests:   6%|         | 468/8192 [00:00<00:14, 551.65it/s]
Adding requests:   6%|         | 524/8192 [00:00<00:14, 522.62it/s]
Adding requests:   7%|         | 580/8192 [00:01<00:14, 532.73it/s]
Adding requests:   8%|         | 634/8192 [00:01<00:14, 533.06it/s]
Adding requests:   8%|         | 688/8192 [00:01<00:14, 522.57it/s]
Adding requests:   9%|         | 741/8192 [00:01<00:14, 519.25it/s]
Adding requests:  10%|         | 795/8192 [00:01<00:14, 522.46it/s]
Adding requests:  10%|         | 848/8192 [00:01<00:14, 523.18it/s]
Adding requests:  11%|         | 902/8192 [00:01<00:13, 524.88it/s]
Adding requests:  12%|        | 960/8192 [00:01<00:13, 540.04it/s]
Adding requests:  12%|        | 1015/8192 [00:01<00:13, 526.19it/s]
Adding requests:  13%|        | 1070/8192 [00:01<00:13, 529.22it/s]
Adding requests:  14%|        | 1124/8192 [00:02<00:13, 526.81it/s]
Adding requests:  14%|        | 1178/8192 [00:02<00:13, 530.31it/s]
Adding requests:  15%|        | 1233/8192 [00:02<00:13, 531.10it/s]
Adding requests:  16%|        | 1287/8192 [00:02<00:13, 529.49it/s]
Adding requests:  16%|        | 1342/8192 [00:02<00:12, 533.40it/s]
Adding requests:  17%|        | 1396/8192 [00:02<00:12, 528.57it/s]
Adding requests:  18%|        | 1455/8192 [00:02<00:12, 545.44it/s]
Adding requests:  18%|        | 1510/8192 [00:02<00:12, 539.89it/s]
Adding requests:  19%|        | 1567/8192 [00:02<00:12, 547.64it/s]
Adding requests:  20%|        | 1622/8192 [00:03<00:12, 533.16it/s]
Adding requests:  20%|        | 1676/8192 [00:03<00:12, 530.88it/s]
Adding requests:  21%|        | 1730/8192 [00:03<00:12, 529.52it/s]
Adding requests:  22%|       | 1783/8192 [00:03<00:12, 526.07it/s]
Adding requests:  22%|       | 1838/8192 [00:03<00:11, 532.73it/s]
Adding requests:  23%|       | 1892/8192 [00:03<00:12, 504.09it/s]
Adding requests:  24%|       | 1947/8192 [00:03<00:12, 515.18it/s]
Adding requests:  24%|       | 1999/8192 [00:03<00:12, 515.55it/s]
Adding requests:  25%|       | 2056/8192 [00:03<00:11, 531.07it/s]
Adding requests:  26%|       | 2110/8192 [00:03<00:11, 531.00it/s]
Adding requests:  26%|       | 2164/8192 [00:04<00:11, 525.43it/s]
Adding requests:  27%|       | 2217/8192 [00:04<00:11, 517.52it/s]
Adding requests:  28%|       | 2272/8192 [00:04<00:11, 525.11it/s]
Adding requests:  28%|       | 2327/8192 [00:04<00:11, 531.16it/s]
Adding requests:  29%|       | 2381/8192 [00:04<00:10, 529.78it/s]
Adding requests:  30%|       | 2440/8192 [00:04<00:10, 545.74it/s]
Adding requests:  30%|       | 2495/8192 [00:04<00:10, 531.88it/s]
Adding requests:  31%|       | 2554/8192 [00:04<00:10, 545.99it/s]
Adding requests:  32%|      | 2609/8192 [00:04<00:10, 532.00it/s]
Adding requests:  33%|      | 2666/8192 [00:05<00:10, 541.47it/s]
Adding requests:  33%|      | 2721/8192 [00:05<00:10, 532.03it/s]
Adding requests:  34%|      | 2776/8192 [00:05<00:10, 536.99it/s]
Adding requests:  35%|      | 2830/8192 [00:05<00:10, 533.79it/s]
Adding requests:  35%|      | 2884/8192 [00:05<00:10, 529.96it/s]
Adding requests:  36%|      | 2938/8192 [00:05<00:10, 525.19it/s]
Adding requests:  37%|      | 2991/8192 [00:05<00:10, 519.03it/s]
Adding requests:  37%|      | 3048/8192 [00:05<00:09, 531.05it/s]
Adding requests:  38%|      | 3102/8192 [00:05<00:09, 523.25it/s]
Adding requests:  39%|      | 3157/8192 [00:05<00:09, 529.34it/s]
Adding requests:  39%|      | 3210/8192 [00:06<00:09, 526.32it/s]
Adding requests:  40%|      | 3263/8192 [00:06<00:09, 496.23it/s]
Adding requests:  41%|      | 3319/8192 [00:06<00:09, 512.80it/s]
Adding requests:  41%|      | 3375/8192 [00:06<00:09, 523.84it/s]
Adding requests:  42%|     | 3432/8192 [00:06<00:08, 535.86it/s]
Adding requests:  43%|     | 3486/8192 [00:06<00:09, 521.41it/s]
Adding requests:  43%|     | 3543/8192 [00:06<00:08, 534.93it/s]
Adding requests:  44%|     | 3597/8192 [00:06<00:08, 522.98it/s]
Adding requests:  45%|     | 3653/8192 [00:06<00:08, 530.12it/s]
Adding requests:  45%|     | 3709/8192 [00:06<00:08, 538.66it/s]
Adding requests:  46%|     | 3764/8192 [00:07<00:08, 539.98it/s]
Adding requests:  47%|     | 3819/8192 [00:07<00:08, 542.79it/s]
Adding requests:  47%|     | 3876/8192 [00:07<00:07, 548.58it/s]
Adding requests:  48%|     | 3931/8192 [00:07<00:07, 547.74it/s]
Adding requests:  49%|     | 3986/8192 [00:07<00:07, 541.89it/s]
Adding requests:  49%|     | 4043/8192 [00:07<00:07, 548.24it/s]
Adding requests:  50%|     | 4098/8192 [00:07<00:07, 546.01it/s]
Adding requests:  51%|     | 4156/8192 [00:07<00:07, 555.59it/s]
Adding requests:  51%|    | 4212/8192 [00:07<00:07, 548.74it/s]
Adding requests:  52%|    | 4269/8192 [00:08<00:07, 553.44it/s]
Adding requests:  53%|    | 4325/8192 [00:08<00:07, 549.70it/s]
Adding requests:  53%|    | 4382/8192 [00:08<00:06, 555.59it/s]
Adding requests:  54%|    | 4438/8192 [00:08<00:06, 549.99it/s]
Adding requests:  55%|    | 4494/8192 [00:08<00:06, 547.37it/s]
Adding requests:  56%|    | 4549/8192 [00:08<00:06, 546.02it/s]
Adding requests:  56%|    | 4604/8192 [00:08<00:06, 515.52it/s]
Adding requests:  57%|    | 4658/8192 [00:08<00:06, 521.27it/s]
Adding requests:  58%|    | 4711/8192 [00:08<00:06, 516.51it/s]
Adding requests:  58%|    | 4763/8192 [00:08<00:06, 515.41it/s]
Adding requests:  59%|    | 4819/8192 [00:09<00:06, 526.62it/s]
Adding requests:  59%|    | 4872/8192 [00:09<00:06, 517.69it/s]
Adding requests:  60%|    | 4927/8192 [00:09<00:06, 526.25it/s]
Adding requests:  61%|    | 4981/8192 [00:09<00:06, 526.76it/s]
Adding requests:  61%|   | 5037/8192 [00:09<00:05, 535.14it/s]
Adding requests:  62%|   | 5091/8192 [00:09<00:05, 528.79it/s]
Adding requests:  63%|   | 5148/8192 [00:09<00:05, 539.56it/s]
Adding requests:  64%|   | 5203/8192 [00:09<00:05, 525.79it/s]
Adding requests:  64%|   | 5256/8192 [00:09<00:05, 519.02it/s]
Adding requests:  65%|   | 5309/8192 [00:09<00:05, 521.34it/s]
Adding requests:  65%|   | 5364/8192 [00:10<00:05, 528.53it/s]
Adding requests:  66%|   | 5419/8192 [00:10<00:05, 533.49it/s]
Adding requests:  67%|   | 5473/8192 [00:10<00:05, 533.91it/s]
Adding requests:  67%|   | 5527/8192 [00:10<00:05, 530.98it/s]
Adding requests:  68%|   | 5581/8192 [00:10<00:04, 523.50it/s]
Adding requests:  69%|   | 5639/8192 [00:10<00:04, 539.66it/s]
Adding requests:  70%|   | 5694/8192 [00:10<00:04, 526.72it/s]
Adding requests:  70%|   | 5753/8192 [00:10<00:04, 543.27it/s]
Adding requests:  71%|   | 5808/8192 [00:10<00:04, 533.29it/s]
Adding requests:  72%|  | 5865/8192 [00:11<00:04, 543.18it/s]
Adding requests:  72%|  | 5922/8192 [00:11<00:04, 548.70it/s]
Adding requests:  73%|  | 5977/8192 [00:11<00:04, 512.12it/s]
Adding requests:  74%|  | 6036/8192 [00:11<00:04, 532.27it/s]
Adding requests:  74%|  | 6094/8192 [00:11<00:03, 544.17it/s]
Adding requests:  75%|  | 6154/8192 [00:11<00:03, 559.18it/s]
Adding requests:  76%|  | 6211/8192 [00:11<00:03, 552.42it/s]
Adding requests:  77%|  | 6273/8192 [00:11<00:03, 571.99it/s]
Adding requests:  77%|  | 6331/8192 [00:11<00:03, 563.00it/s]
Adding requests:  78%|  | 6390/8192 [00:11<00:03, 567.82it/s]
Adding requests:  79%|  | 6448/8192 [00:12<00:03, 570.27it/s]
Adding requests:  79%|  | 6506/8192 [00:12<00:02, 567.82it/s]
Adding requests:  80%|  | 6566/8192 [00:12<00:02, 574.00it/s]
Adding requests:  81%|  | 6624/8192 [00:12<00:02, 573.62it/s]
Adding requests:  82%| | 6683/8192 [00:12<00:02, 575.90it/s]
Adding requests:  82%| | 6741/8192 [00:12<00:02, 559.81it/s]
Adding requests:  83%| | 6801/8192 [00:12<00:02, 569.64it/s]
Adding requests:  84%| | 6859/8192 [00:12<00:02, 552.94it/s]
Adding requests:  84%| | 6917/8192 [00:12<00:02, 559.48it/s]
Adding requests:  85%| | 6974/8192 [00:12<00:02, 550.00it/s]
Adding requests:  86%| | 7030/8192 [00:13<00:02, 537.93it/s]
Adding requests:  86%| | 7084/8192 [00:13<00:02, 538.49it/s]
Adding requests:  87%| | 7141/8192 [00:13<00:01, 544.72it/s]
Adding requests:  88%| | 7196/8192 [00:13<00:01, 545.38it/s]
Adding requests:  89%| | 7251/8192 [00:13<00:01, 538.86it/s]
Adding requests:  89%| | 7311/8192 [00:13<00:01, 556.48it/s]
Adding requests:  90%| | 7367/8192 [00:13<00:01, 503.29it/s]
Adding requests:  91%| | 7422/8192 [00:13<00:01, 514.90it/s]
Adding requests:  91%|| 7479/8192 [00:13<00:01, 529.39it/s]
Adding requests:  92%|| 7537/8192 [00:14<00:01, 541.87it/s]
Adding requests:  93%|| 7593/8192 [00:14<00:01, 546.78it/s]
Adding requests:  93%|| 7650/8192 [00:14<00:00, 551.88it/s]
Adding requests:  94%|| 7711/8192 [00:14<00:00, 565.32it/s]
Adding requests:  95%|| 7768/8192 [00:14<00:00, 559.38it/s]
Adding requests:  96%|| 7827/8192 [00:14<00:00, 567.36it/s]
Adding requests:  96%|| 7884/8192 [00:14<00:00, 557.39it/s]
Adding requests:  97%|| 7941/8192 [00:14<00:00, 558.58it/s]
Adding requests:  98%|| 7997/8192 [00:14<00:00, 552.10it/s]
Adding requests:  98%|| 8053/8192 [00:14<00:00, 551.54it/s]
Adding requests:  99%|| 8112/8192 [00:15<00:00, 560.52it/s]
Adding requests: 100%|| 8169/8192 [00:15<00:00, 557.10it/s]
Adding requests: 100%|| 8192/8192 [00:15<00:00, 538.44it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 130/8192 [00:00<00:46, 172.01it/s, est. speed input: 176152.59 toks/s, output: 172.02 toks/s]
Processed prompts:   2%|         | 194/8192 [00:06<04:58, 26.80it/s, est. speed input: 33056.28 toks/s, output: 32.28 toks/s]   
Processed prompts:   3%|         | 258/8192 [00:11<07:07, 18.55it/s, est. speed input: 23460.15 toks/s, output: 22.91 toks/s]
Processed prompts:   4%|         | 322/8192 [00:16<08:18, 15.79it/s, est. speed input: 20044.94 toks/s, output: 19.58 toks/s]
Processed prompts:   5%|         | 386/8192 [00:21<09:02, 14.38it/s, est. speed input: 18210.80 toks/s, output: 17.78 toks/s]
Processed prompts:   5%|         | 450/8192 [00:26<09:26, 13.66it/s, est. speed input: 17135.95 toks/s, output: 16.73 toks/s]
Processed prompts:   6%|         | 514/8192 [00:32<09:43, 13.16it/s, est. speed input: 16374.85 toks/s, output: 15.99 toks/s]
Processed prompts:   7%|         | 578/8192 [00:37<09:52, 12.84it/s, est. speed input: 15827.89 toks/s, output: 15.46 toks/s]
Processed prompts:   8%|         | 642/8192 [00:42<09:57, 12.63it/s, est. speed input: 15412.67 toks/s, output: 15.05 toks/s]
Processed prompts:   9%|         | 706/8192 [00:47<09:59, 12.48it/s, est. speed input: 15089.03 toks/s, output: 14.74 toks/s]
Processed prompts:   9%|         | 770/8192 [00:53<09:59, 12.39it/s, est. speed input: 14829.52 toks/s, output: 14.48 toks/s]
Processed prompts:  10%|         | 834/8192 [00:58<09:57, 12.32it/s, est. speed input: 14615.02 toks/s, output: 14.27 toks/s]
Processed prompts:  11%|         | 898/8192 [01:03<09:51, 12.33it/s, est. speed input: 14455.61 toks/s, output: 14.12 toks/s]
Processed prompts:  12%|        | 962/8192 [01:08<09:45, 12.34it/s, est. speed input: 14320.45 toks/s, output: 13.98 toks/s]
Processed prompts:  13%|        | 1026/8192 [01:14<09:43, 12.29it/s, est. speed input: 14189.31 toks/s, output: 13.86 toks/s]
Processed prompts:  13%|        | 1090/8192 [01:19<09:39, 12.26it/s, est. speed input: 14075.45 toks/s, output: 13.75 toks/s]
Processed prompts:  14%|        | 1154/8192 [01:24<09:33, 12.27it/s, est. speed input: 13984.91 toks/s, output: 13.66 toks/s]
Processed prompts:  15%|        | 1218/8192 [01:29<09:27, 12.29it/s, est. speed input: 13907.08 toks/s, output: 13.58 toks/s]
Processed prompts:  16%|        | 1282/8192 [01:34<09:23, 12.26it/s, est. speed input: 13827.74 toks/s, output: 13.50 toks/s]
Processed prompts:  16%|        | 1346/8192 [01:40<09:19, 12.23it/s, est. speed input: 13754.70 toks/s, output: 13.43 toks/s]
Processed prompts:  17%|        | 1410/8192 [01:45<09:15, 12.21it/s, est. speed input: 13689.74 toks/s, output: 13.37 toks/s]
Processed prompts:  18%|        | 1474/8192 [01:50<09:11, 12.19it/s, est. speed input: 13630.43 toks/s, output: 13.31 toks/s]
Processed prompts:  19%|        | 1538/8192 [01:55<09:03, 12.24it/s, est. speed input: 13586.42 toks/s, output: 13.27 toks/s]
Processed prompts:  20%|        | 1602/8192 [02:01<08:59, 12.22it/s, est. speed input: 13537.97 toks/s, output: 13.22 toks/s]
Processed prompts:  20%|        | 1666/8192 [02:06<08:54, 12.21it/s, est. speed input: 13493.60 toks/s, output: 13.18 toks/s]
Processed prompts:  21%|        | 1730/8192 [02:11<08:50, 12.19it/s, est. speed input: 13451.83 toks/s, output: 13.14 toks/s]
Processed prompts:  22%|       | 1794/8192 [02:16<08:45, 12.18it/s, est. speed input: 13413.50 toks/s, output: 13.10 toks/s]
Processed prompts:  23%|       | 1858/8192 [02:22<08:38, 12.23it/s, est. speed input: 13384.70 toks/s, output: 13.07 toks/s]
Processed prompts:  23%|       | 1922/8192 [02:27<08:31, 12.26it/s, est. speed input: 13358.44 toks/s, output: 13.05 toks/s]
Processed prompts:  24%|       | 1986/8192 [02:32<08:27, 12.23it/s, est. speed input: 13326.92 toks/s, output: 13.01 toks/s]
Processed prompts:  25%|       | 2050/8192 [02:37<08:23, 12.21it/s, est. speed input: 13297.72 toks/s, output: 12.99 toks/s]
Processed prompts:  26%|       | 2114/8192 [02:43<08:18, 12.20it/s, est. speed input: 13270.94 toks/s, output: 12.96 toks/s]
Processed prompts:  27%|       | 2178/8192 [02:48<08:09, 12.29it/s, est. speed input: 13256.55 toks/s, output: 12.95 toks/s]
Processed prompts:  27%|       | 2242/8192 [02:53<08:03, 12.30it/s, est. speed input: 13238.03 toks/s, output: 12.93 toks/s]
Processed prompts:  28%|       | 2306/8192 [02:58<07:57, 12.32it/s, est. speed input: 13221.03 toks/s, output: 12.91 toks/s]
Processed prompts:  29%|       | 2370/8192 [03:03<07:50, 12.38it/s, est. speed input: 13209.64 toks/s, output: 12.90 toks/s]
Processed prompts:  30%|       | 2434/8192 [03:08<07:47, 12.31it/s, est. speed input: 13188.31 toks/s, output: 12.88 toks/s]
Processed prompts:  30%|       | 2498/8192 [03:14<07:42, 12.32it/s, est. speed input: 13173.35 toks/s, output: 12.86 toks/s]
Processed prompts:  31%|      | 2562/8192 [03:19<07:36, 12.33it/s, est. speed input: 13159.85 toks/s, output: 12.85 toks/s]
Processed prompts:  32%|      | 2626/8192 [03:24<07:33, 12.29it/s, est. speed input: 13142.46 toks/s, output: 12.83 toks/s]
Processed prompts:  33%|      | 2690/8192 [03:29<07:29, 12.24it/s, est. speed input: 13124.79 toks/s, output: 12.82 toks/s]
Processed prompts:  34%|      | 2754/8192 [03:35<07:25, 12.22it/s, est. speed input: 13108.34 toks/s, output: 12.80 toks/s]
Processed prompts:  34%|      | 2818/8192 [03:40<07:20, 12.21it/s, est. speed input: 13093.02 toks/s, output: 12.79 toks/s]
Processed prompts:  35%|      | 2882/8192 [03:45<07:15, 12.19it/s, est. speed input: 13077.93 toks/s, output: 12.77 toks/s]
Processed prompts:  36%|      | 2946/8192 [03:50<07:10, 12.18it/s, est. speed input: 13063.97 toks/s, output: 12.76 toks/s]
Processed prompts:  37%|      | 3010/8192 [03:56<07:05, 12.18it/s, est. speed input: 13050.49 toks/s, output: 12.74 toks/s]
Processed prompts:  38%|      | 3074/8192 [04:01<07:00, 12.17it/s, est. speed input: 13037.07 toks/s, output: 12.73 toks/s]
Processed prompts:  38%|      | 3138/8192 [04:06<06:53, 12.22it/s, est. speed input: 13028.93 toks/s, output: 12.72 toks/s]
Processed prompts:  39%|      | 3202/8192 [04:11<06:48, 12.20it/s, est. speed input: 13016.78 toks/s, output: 12.71 toks/s]
Processed prompts:  40%|      | 3266/8192 [04:17<06:44, 12.19it/s, est. speed input: 13005.32 toks/s, output: 12.70 toks/s]
Processed prompts:  41%|      | 3330/8192 [04:22<06:39, 12.18it/s, est. speed input: 12993.97 toks/s, output: 12.69 toks/s]
Processed prompts:  41%|     | 3394/8192 [04:27<06:34, 12.18it/s, est. speed input: 12983.55 toks/s, output: 12.68 toks/s]
Processed prompts:  42%|     | 3458/8192 [04:32<06:25, 12.29it/s, est. speed input: 12981.59 toks/s, output: 12.68 toks/s]
Processed prompts:  43%|     | 3522/8192 [04:38<06:21, 12.26it/s, est. speed input: 12971.81 toks/s, output: 12.67 toks/s]
Processed prompts:  44%|     | 3586/8192 [04:43<06:16, 12.22it/s, est. speed input: 12961.72 toks/s, output: 12.66 toks/s]
Processed prompts:  45%|     | 3650/8192 [04:48<06:12, 12.21it/s, est. speed input: 12952.71 toks/s, output: 12.65 toks/s]
Processed prompts:  45%|     | 3714/8192 [04:53<06:05, 12.24it/s, est. speed input: 12946.92 toks/s, output: 12.64 toks/s]
Processed prompts:  46%|     | 3778/8192 [04:59<06:01, 12.22it/s, est. speed input: 12938.27 toks/s, output: 12.64 toks/s]
Processed prompts:  47%|     | 3842/8192 [05:04<05:56, 12.21it/s, est. speed input: 12930.09 toks/s, output: 12.63 toks/s]
Processed prompts:  48%|     | 3906/8192 [05:09<05:51, 12.19it/s, est. speed input: 12921.77 toks/s, output: 12.62 toks/s]
Processed prompts:  48%|     | 3970/8192 [05:14<05:46, 12.18it/s, est. speed input: 12914.09 toks/s, output: 12.61 toks/s]
Processed prompts:  49%|     | 4034/8192 [05:19<05:40, 12.23it/s, est. speed input: 12909.54 toks/s, output: 12.61 toks/s]
Processed prompts:  50%|     | 4098/8192 [05:25<05:35, 12.21it/s, est. speed input: 12902.43 toks/s, output: 12.60 toks/s]
Processed prompts:  51%|     | 4162/8192 [05:30<05:30, 12.20it/s, est. speed input: 12895.36 toks/s, output: 12.59 toks/s]
Processed prompts:  52%|    | 4226/8192 [05:35<05:22, 12.30it/s, est. speed input: 12894.66 toks/s, output: 12.59 toks/s]
Processed prompts:  52%|    | 4290/8192 [05:40<05:16, 12.32it/s, est. speed input: 12890.86 toks/s, output: 12.59 toks/s]
Processed prompts:  53%|    | 4354/8192 [05:46<05:12, 12.27it/s, est. speed input: 12884.03 toks/s, output: 12.58 toks/s]
Processed prompts:  54%|    | 4418/8192 [05:51<05:08, 12.24it/s, est. speed input: 12877.74 toks/s, output: 12.58 toks/s]
Processed prompts:  55%|    | 4482/8192 [05:56<05:03, 12.21it/s, est. speed input: 12871.44 toks/s, output: 12.57 toks/s]
Processed prompts:  55%|    | 4546/8192 [06:01<04:58, 12.20it/s, est. speed input: 12865.25 toks/s, output: 12.56 toks/s]
Processed prompts:  56%|    | 4610/8192 [06:07<04:53, 12.19it/s, est. speed input: 12859.33 toks/s, output: 12.56 toks/s]
Processed prompts:  57%|    | 4674/8192 [06:12<04:48, 12.18it/s, est. speed input: 12853.57 toks/s, output: 12.55 toks/s]
Processed prompts:  58%|    | 4738/8192 [06:17<04:42, 12.23it/s, est. speed input: 12850.66 toks/s, output: 12.55 toks/s]
Processed prompts:  59%|    | 4802/8192 [06:22<04:36, 12.26it/s, est. speed input: 12847.52 toks/s, output: 12.55 toks/s]
Processed prompts:  59%|    | 4866/8192 [06:28<04:32, 12.23it/s, est. speed input: 12842.05 toks/s, output: 12.54 toks/s]
Processed prompts:  60%|    | 4930/8192 [06:33<04:27, 12.20it/s, est. speed input: 12836.74 toks/s, output: 12.54 toks/s]
Processed prompts:  61%|    | 4994/8192 [06:38<04:19, 12.31it/s, est. speed input: 12837.00 toks/s, output: 12.54 toks/s]
Processed prompts:  62%|   | 5058/8192 [06:43<04:15, 12.27it/s, est. speed input: 12832.09 toks/s, output: 12.53 toks/s]
Processed prompts:  63%|   | 5122/8192 [06:48<04:10, 12.24it/s, est. speed input: 12827.43 toks/s, output: 12.53 toks/s]
Processed prompts:  63%|   | 5186/8192 [06:54<04:05, 12.27it/s, est. speed input: 12824.97 toks/s, output: 12.52 toks/s]
Processed prompts:  64%|   | 5250/8192 [06:59<04:00, 12.24it/s, est. speed input: 12820.36 toks/s, output: 12.52 toks/s]
Processed prompts:  65%|   | 5314/8192 [07:04<03:54, 12.27it/s, est. speed input: 12818.26 toks/s, output: 12.52 toks/s]
Processed prompts:  66%|   | 5378/8192 [07:09<03:48, 12.29it/s, est. speed input: 12816.11 toks/s, output: 12.52 toks/s]
Processed prompts:  66%|   | 5442/8192 [07:14<03:44, 12.25it/s, est. speed input: 12811.54 toks/s, output: 12.51 toks/s]
Processed prompts:  67%|   | 5506/8192 [07:20<03:38, 12.27it/s, est. speed input: 12809.35 toks/s, output: 12.51 toks/s]
Processed prompts:  68%|   | 5570/8192 [07:25<03:34, 12.24it/s, est. speed input: 12805.07 toks/s, output: 12.50 toks/s]
Processed prompts:  69%|   | 5634/8192 [07:30<03:28, 12.27it/s, est. speed input: 12803.25 toks/s, output: 12.50 toks/s]
Processed prompts:  70%|   | 5698/8192 [07:35<03:23, 12.24it/s, est. speed input: 12799.30 toks/s, output: 12.50 toks/s]
Processed prompts:  70%|   | 5762/8192 [07:41<03:18, 12.22it/s, est. speed input: 12795.51 toks/s, output: 12.50 toks/s]
Processed prompts:  71%|   | 5826/8192 [07:46<03:13, 12.20it/s, est. speed input: 12791.53 toks/s, output: 12.49 toks/s]
Processed prompts:  72%|  | 5890/8192 [07:51<03:08, 12.19it/s, est. speed input: 12787.80 toks/s, output: 12.49 toks/s]
Processed prompts:  73%|  | 5954/8192 [07:56<03:03, 12.18it/s, est. speed input: 12784.18 toks/s, output: 12.48 toks/s]
Processed prompts:  73%|  | 6018/8192 [08:02<02:58, 12.18it/s, est. speed input: 12780.78 toks/s, output: 12.48 toks/s]
Processed prompts:  74%|  | 6082/8192 [08:07<02:53, 12.17it/s, est. speed input: 12777.14 toks/s, output: 12.48 toks/s]
Processed prompts:  75%|  | 6146/8192 [08:12<02:48, 12.17it/s, est. speed input: 12773.56 toks/s, output: 12.47 toks/s]
Processed prompts:  76%|  | 6210/8192 [08:17<02:43, 12.16it/s, est. speed input: 12769.92 toks/s, output: 12.47 toks/s]
Processed prompts:  77%|  | 6274/8192 [08:23<02:37, 12.16it/s, est. speed input: 12766.49 toks/s, output: 12.47 toks/s]
Processed prompts:  77%|  | 6338/8192 [08:28<02:32, 12.16it/s, est. speed input: 12763.22 toks/s, output: 12.46 toks/s]
Processed prompts:  78%|  | 6402/8192 [08:33<02:27, 12.16it/s, est. speed input: 12760.05 toks/s, output: 12.46 toks/s]
Processed prompts:  79%|  | 6466/8192 [08:39<02:21, 12.16it/s, est. speed input: 12756.86 toks/s, output: 12.46 toks/s]
Processed prompts:  80%|  | 6530/8192 [08:44<02:16, 12.16it/s, est. speed input: 12753.78 toks/s, output: 12.45 toks/s]
Processed prompts:  80%|  | 6594/8192 [08:49<02:10, 12.21it/s, est. speed input: 12752.60 toks/s, output: 12.45 toks/s]
Processed prompts:  81%| | 6658/8192 [08:54<02:05, 12.25it/s, est. speed input: 12751.63 toks/s, output: 12.45 toks/s]
Processed prompts:  82%| | 6722/8192 [08:59<02:00, 12.23it/s, est. speed input: 12748.73 toks/s, output: 12.45 toks/s]
Processed prompts:  83%| | 6786/8192 [09:05<01:55, 12.20it/s, est. speed input: 12745.67 toks/s, output: 12.45 toks/s]
Processed prompts:  84%| | 6850/8192 [09:10<01:50, 12.19it/s, est. speed input: 12742.94 toks/s, output: 12.44 toks/s]
Processed prompts:  84%| | 6914/8192 [09:15<01:44, 12.18it/s, est. speed input: 12740.21 toks/s, output: 12.44 toks/s]
Processed prompts:  85%| | 6978/8192 [09:20<01:39, 12.17it/s, est. speed input: 12737.34 toks/s, output: 12.44 toks/s]
Processed prompts:  86%| | 7042/8192 [09:26<01:34, 12.17it/s, est. speed input: 12734.72 toks/s, output: 12.44 toks/s]
Processed prompts:  87%| | 7106/8192 [09:31<01:28, 12.22it/s, est. speed input: 12733.77 toks/s, output: 12.44 toks/s]
Processed prompts:  88%| | 7170/8192 [09:36<01:23, 12.21it/s, est. speed input: 12731.39 toks/s, output: 12.43 toks/s]
Processed prompts:  88%| | 7234/8192 [09:41<01:18, 12.25it/s, est. speed input: 12730.52 toks/s, output: 12.43 toks/s]
Processed prompts:  89%| | 7298/8192 [09:47<01:13, 12.22it/s, est. speed input: 12728.07 toks/s, output: 12.43 toks/s]
Processed prompts:  90%| | 7362/8192 [09:52<01:07, 12.21it/s, est. speed input: 12725.74 toks/s, output: 12.43 toks/s]
Processed prompts:  91%| | 7426/8192 [09:57<01:02, 12.25it/s, est. speed input: 12724.94 toks/s, output: 12.43 toks/s]
Processed prompts:  91%|| 7490/8192 [10:02<00:57, 12.22it/s, est. speed input: 12722.70 toks/s, output: 12.42 toks/s]
Processed prompts:  92%|| 7554/8192 [10:07<00:51, 12.32it/s, est. speed input: 12723.68 toks/s, output: 12.43 toks/s]
Processed prompts:  93%|| 7618/8192 [10:13<00:46, 12.27it/s, est. speed input: 12721.47 toks/s, output: 12.42 toks/s]
Processed prompts:  94%|| 7682/8192 [10:18<00:41, 12.29it/s, est. speed input: 12720.67 toks/s, output: 12.42 toks/s]
Processed prompts:  95%|| 7746/8192 [10:23<00:36, 12.25it/s, est. speed input: 12718.51 toks/s, output: 12.42 toks/s]
Processed prompts:  95%|| 7810/8192 [10:28<00:31, 12.23it/s, est. speed input: 12716.43 toks/s, output: 12.42 toks/s]
Processed prompts:  96%|| 7874/8192 [10:34<00:26, 12.22it/s, est. speed input: 12714.40 toks/s, output: 12.42 toks/s]
Processed prompts:  97%|| 7938/8192 [10:39<00:20, 12.25it/s, est. speed input: 12713.68 toks/s, output: 12.42 toks/s]
Processed prompts:  98%|| 8002/8192 [10:44<00:15, 12.22it/s, est. speed input: 12711.57 toks/s, output: 12.41 toks/s]
Processed prompts:  98%|| 8066/8192 [10:49<00:10, 12.26it/s, est. speed input: 12710.91 toks/s, output: 12.41 toks/s]
Processed prompts:  99%|| 8130/8192 [10:54<00:05, 12.34it/s, est. speed input: 12712.00 toks/s, output: 12.41 toks/s]
Processed prompts: 100%|| 8192/8192 [10:54<00:00, 12.34it/s, est. speed input: 12808.93 toks/s, output: 12.51 toks/s]
Processed prompts: 100%|| 8192/8192 [10:54<00:00, 12.51it/s, est. speed input: 12808.93 toks/s, output: 12.51 toks/s]
[rank0]:[W126 11:02:35.026935254 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 15:52:49
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:52:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 15:52:53 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1465220) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1465220) WARNING 01-26 15:54:11 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 10.32 requests/s, 5292.38 total tokens/s, 10.32 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 15:52:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:52:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:52:53] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:52:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:52:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:52:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:52:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:52:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:52:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:52:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:52:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:52:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:52:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:52:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:52:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:52:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:52:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:52:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:52:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:52:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:52:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:52:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:52:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:52:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:52:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:52:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:52:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:52:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1465220) [2026-01-26 15:52:57] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1465220) [2026-01-26 15:52:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1465220) [2026-01-26 15:52:57] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1465220) [2026-01-26 15:52:57] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1465220) [2026-01-26 15:52:57] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1465220) [2026-01-26 15:52:57] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1465220) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1465220) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.81s/it]
(EngineCore_DP0 pid=1465220) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:01<00:00, 31.03s/it]
(EngineCore_DP0 pid=1465220) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:01<00:00, 30.54s/it]
(EngineCore_DP0 pid=1465220) 
(EngineCore_DP0 pid=1465220) [2026-01-26 15:53:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1465220) [2026-01-26 15:53:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=1465220) [2026-01-26 15:53:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1465220) [2026-01-26 15:53:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=1465220) [2026-01-26 15:53:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1465220) [2026-01-26 15:53:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=1465220) [2026-01-26 15:53:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1465220) [2026-01-26 15:53:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=1465220) 2026-01-26 15:54:08,405 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1465220) 2026-01-26 15:54:08,501 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:   1%|          | 1/128 [00:00<01:28,  1.43it/s]
Adding requests:   2%|         | 2/128 [00:00<00:49,  2.52it/s]
Adding requests:   2%|         | 3/128 [00:01<00:34,  3.64it/s]
Adding requests:   4%|         | 5/128 [00:01<00:20,  5.92it/s]
Adding requests:   5%|         | 7/128 [00:01<00:14,  8.17it/s]
Adding requests:   7%|         | 9/128 [00:01<00:11, 10.50it/s]
Adding requests:   9%|         | 12/128 [00:01<00:08, 13.99it/s]
Adding requests:  13%|        | 17/128 [00:01<00:05, 20.86it/s]
Adding requests:  16%|        | 21/128 [00:01<00:04, 24.51it/s]
Adding requests:  21%|        | 27/128 [00:01<00:03, 32.79it/s]
Adding requests:  31%|      | 40/128 [00:02<00:01, 57.66it/s]
Adding requests:  60%|    | 77/128 [00:02<00:00, 141.01it/s]
Adding requests:  98%|| 126/128 [00:02<00:00, 236.40it/s]
Adding requests: 100%|| 128/128 [00:02<00:00, 57.75it/s] 

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  13%|        | 17/128 [00:00<00:01, 103.04it/s, est. speed input: 52765.10 toks/s, output: 103.04 toks/s]
Processed prompts:  22%|       | 28/128 [00:01<00:04, 20.88it/s, est. speed input: 12504.92 toks/s, output: 24.42 toks/s]  
Processed prompts:  26%|       | 33/128 [00:01<00:05, 17.39it/s, est. speed input: 10642.20 toks/s, output: 20.79 toks/s]
Processed prompts:  29%|       | 37/128 [00:01<00:05, 15.49it/s, est. speed input: 9713.95 toks/s, output: 18.97 toks/s] 
Processed prompts:  31%|      | 40/128 [00:02<00:06, 14.47it/s, est. speed input: 9237.11 toks/s, output: 18.04 toks/s]
Processed prompts:  33%|      | 42/128 [00:02<00:06, 13.89it/s, est. speed input: 8985.13 toks/s, output: 17.55 toks/s]
Processed prompts:  34%|      | 44/128 [00:02<00:06, 13.34it/s, est. speed input: 8762.63 toks/s, output: 17.11 toks/s]
Processed prompts:  36%|      | 46/128 [00:02<00:06, 12.89it/s, est. speed input: 8574.53 toks/s, output: 16.75 toks/s]
Processed prompts:  38%|      | 48/128 [00:02<00:06, 12.47it/s, est. speed input: 8400.79 toks/s, output: 16.41 toks/s]
Processed prompts:  39%|      | 50/128 [00:03<00:06, 12.07it/s, est. speed input: 8237.08 toks/s, output: 16.09 toks/s]
Processed prompts:  41%|      | 52/128 [00:03<00:06, 11.89it/s, est. speed input: 8108.74 toks/s, output: 15.84 toks/s]
Processed prompts:  42%|     | 54/128 [00:03<00:06, 11.70it/s, est. speed input: 7987.40 toks/s, output: 15.60 toks/s]
Processed prompts:  44%|     | 56/128 [00:03<00:06, 11.65it/s, est. speed input: 7887.90 toks/s, output: 15.41 toks/s]
Processed prompts:  45%|     | 58/128 [00:03<00:06, 11.57it/s, est. speed input: 7792.43 toks/s, output: 15.22 toks/s]
Processed prompts:  47%|     | 60/128 [00:03<00:05, 11.47it/s, est. speed input: 7701.63 toks/s, output: 15.04 toks/s]
Processed prompts:  48%|     | 62/128 [00:04<00:05, 11.27it/s, est. speed input: 7605.04 toks/s, output: 14.85 toks/s]
Processed prompts:  50%|     | 64/128 [00:04<00:05, 11.32it/s, est. speed input: 7534.77 toks/s, output: 14.72 toks/s]
Processed prompts:  52%|    | 66/128 [00:04<00:05, 11.32it/s, est. speed input: 7467.43 toks/s, output: 14.58 toks/s]
Processed prompts:  53%|    | 68/128 [00:04<00:05, 11.34it/s, est. speed input: 7405.85 toks/s, output: 14.46 toks/s]
Processed prompts:  55%|    | 70/128 [00:04<00:05, 11.33it/s, est. speed input: 7347.02 toks/s, output: 14.35 toks/s]
Processed prompts:  56%|    | 72/128 [00:05<00:04, 11.21it/s, est. speed input: 7284.09 toks/s, output: 14.23 toks/s]
Processed prompts:  58%|    | 74/128 [00:05<00:04, 11.18it/s, est. speed input: 7229.13 toks/s, output: 14.12 toks/s]
Processed prompts:  59%|    | 76/128 [00:05<00:04, 11.20it/s, est. speed input: 7180.91 toks/s, output: 14.03 toks/s]
Processed prompts:  61%|    | 78/128 [00:05<00:04, 11.21it/s, est. speed input: 7135.39 toks/s, output: 13.94 toks/s]
Processed prompts:  62%|   | 80/128 [00:05<00:04, 11.20it/s, est. speed input: 7091.88 toks/s, output: 13.85 toks/s]
Processed prompts:  64%|   | 82/128 [00:05<00:04, 11.20it/s, est. speed input: 7051.26 toks/s, output: 13.77 toks/s]
Processed prompts:  66%|   | 84/128 [00:06<00:03, 11.16it/s, est. speed input: 7010.53 toks/s, output: 13.69 toks/s]
Processed prompts:  67%|   | 86/128 [00:06<00:03, 11.14it/s, est. speed input: 6972.50 toks/s, output: 13.62 toks/s]
Processed prompts:  69%|   | 88/128 [00:06<00:03, 11.11it/s, est. speed input: 6935.80 toks/s, output: 13.55 toks/s]
Processed prompts:  70%|   | 90/128 [00:06<00:03, 11.20it/s, est. speed input: 6907.24 toks/s, output: 13.49 toks/s]
Processed prompts:  72%|  | 92/128 [00:06<00:03, 11.16it/s, est. speed input: 6874.64 toks/s, output: 13.43 toks/s]
Processed prompts:  73%|  | 94/128 [00:07<00:03, 11.16it/s, est. speed input: 6845.07 toks/s, output: 13.37 toks/s]
Processed prompts:  75%|  | 96/128 [00:07<00:02, 11.08it/s, est. speed input: 6812.68 toks/s, output: 13.31 toks/s]
Processed prompts:  77%|  | 98/128 [00:07<00:02, 11.14it/s, est. speed input: 6787.90 toks/s, output: 13.26 toks/s]
Processed prompts:  78%|  | 100/128 [00:07<00:02, 11.19it/s, est. speed input: 6764.42 toks/s, output: 13.21 toks/s]
Processed prompts:  80%|  | 102/128 [00:07<00:02, 11.23it/s, est. speed input: 6742.55 toks/s, output: 13.17 toks/s]
Processed prompts:  81%| | 104/128 [00:07<00:02, 11.23it/s, est. speed input: 6720.14 toks/s, output: 13.13 toks/s]
Processed prompts:  83%| | 106/128 [00:08<00:01, 11.21it/s, est. speed input: 6697.85 toks/s, output: 13.08 toks/s]
Processed prompts:  84%| | 108/128 [00:08<00:01, 11.09it/s, est. speed input: 6672.13 toks/s, output: 13.03 toks/s]
Processed prompts:  86%| | 110/128 [00:08<00:01, 11.11it/s, est. speed input: 6651.97 toks/s, output: 12.99 toks/s]
Processed prompts:  88%| | 112/128 [00:08<00:01, 11.15it/s, est. speed input: 6633.58 toks/s, output: 12.96 toks/s]
Processed prompts:  89%| | 114/128 [00:08<00:01, 11.16it/s, est. speed input: 6615.05 toks/s, output: 12.92 toks/s]
Processed prompts:  91%| | 116/128 [00:09<00:01, 11.18it/s, est. speed input: 6597.81 toks/s, output: 12.89 toks/s]
Processed prompts:  92%|| 118/128 [00:09<00:00, 11.19it/s, est. speed input: 6581.14 toks/s, output: 12.85 toks/s]
Processed prompts:  94%|| 120/128 [00:09<00:00, 11.07it/s, est. speed input: 6560.32 toks/s, output: 12.81 toks/s]
Processed prompts:  95%|| 122/128 [00:09<00:00, 11.12it/s, est. speed input: 6545.50 toks/s, output: 12.78 toks/s]
Processed prompts:  97%|| 124/128 [00:09<00:00, 11.12it/s, est. speed input: 6529.64 toks/s, output: 12.75 toks/s]
Processed prompts:  98%|| 126/128 [00:09<00:00, 11.10it/s, est. speed input: 6513.77 toks/s, output: 12.72 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 11.15it/s, est. speed input: 6500.52 toks/s, output: 12.70 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 11.15it/s, est. speed input: 6500.52 toks/s, output: 12.70 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 12.70it/s, est. speed input: 6500.52 toks/s, output: 12.70 toks/s]
[rank0]:[W126 15:54:24.782156294 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 15:54:39
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:54:43 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 15:54:43 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1466941) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1466941) WARNING 01-26 15:56:00 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.94 requests/s, 6084.76 total tokens/s, 5.94 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 15:54:43] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:54:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:54:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:54:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:54:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:54:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:54:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:54:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:54:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:54:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:54:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:54:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:54:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:54:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:54:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:54:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:54:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:54:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:54:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:54:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:54:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:54:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:54:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:54:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:54:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:54:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:54:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:54:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1466941) [2026-01-26 15:54:48] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1466941) [2026-01-26 15:54:48] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1466941) [2026-01-26 15:54:48] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1466941) [2026-01-26 15:54:48] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1466941) [2026-01-26 15:54:48] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1466941) [2026-01-26 15:54:48] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1466941) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1466941) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.56s/it]
(EngineCore_DP0 pid=1466941) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:02<00:00, 31.59s/it]
(EngineCore_DP0 pid=1466941) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:02<00:00, 31.14s/it]
(EngineCore_DP0 pid=1466941) 
(EngineCore_DP0 pid=1466941) [2026-01-26 15:55:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1466941) [2026-01-26 15:55:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=1466941) [2026-01-26 15:55:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1466941) [2026-01-26 15:55:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=1466941) [2026-01-26 15:55:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1466941) [2026-01-26 15:55:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=1466941) [2026-01-26 15:55:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1466941) [2026-01-26 15:55:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=1466941) 2026-01-26 15:55:59,722 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1466941) 2026-01-26 15:55:59,755 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  32%|      | 41/128 [00:00<00:00, 398.97it/s]
Adding requests:  63%|   | 81/128 [00:00<00:00, 370.26it/s]
Adding requests:  94%|| 120/128 [00:00<00:00, 377.09it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 378.06it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 2/128 [00:00<00:17,  7.28it/s, est. speed input: 7458.31 toks/s, output: 7.28 toks/s]
Processed prompts:   2%|         | 3/128 [00:00<00:23,  5.33it/s, est. speed input: 5767.21 toks/s, output: 5.63 toks/s]
Processed prompts:   3%|         | 4/128 [00:00<00:22,  5.53it/s, est. speed input: 5831.11 toks/s, output: 5.69 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:21,  5.73it/s, est. speed input: 5918.10 toks/s, output: 5.78 toks/s]
Processed prompts:   5%|         | 6/128 [00:01<00:20,  5.84it/s, est. speed input: 5969.04 toks/s, output: 5.83 toks/s]
Processed prompts:   5%|         | 7/128 [00:01<00:20,  5.93it/s, est. speed input: 6008.17 toks/s, output: 5.87 toks/s]
Processed prompts:   6%|         | 8/128 [00:01<00:20,  5.98it/s, est. speed input: 6039.13 toks/s, output: 5.90 toks/s]
Processed prompts:   7%|         | 9/128 [00:01<00:19,  6.02it/s, est. speed input: 6060.58 toks/s, output: 5.92 toks/s]
Processed prompts:   8%|         | 10/128 [00:01<00:19,  5.99it/s, est. speed input: 6061.93 toks/s, output: 5.92 toks/s]
Processed prompts:   9%|         | 11/128 [00:01<00:19,  5.98it/s, est. speed input: 6066.11 toks/s, output: 5.92 toks/s]
Processed prompts:   9%|         | 12/128 [00:02<00:19,  6.00it/s, est. speed input: 6076.88 toks/s, output: 5.93 toks/s]
Processed prompts:  10%|         | 13/128 [00:02<00:19,  6.03it/s, est. speed input: 6089.18 toks/s, output: 5.95 toks/s]
Processed prompts:  11%|         | 14/128 [00:02<00:18,  6.04it/s, est. speed input: 6097.46 toks/s, output: 5.95 toks/s]
Processed prompts:  12%|        | 15/128 [00:02<00:18,  6.04it/s, est. speed input: 6102.77 toks/s, output: 5.96 toks/s]
Processed prompts:  12%|        | 16/128 [00:02<00:18,  6.03it/s, est. speed input: 6105.26 toks/s, output: 5.96 toks/s]
Processed prompts:  13%|        | 17/128 [00:02<00:18,  6.00it/s, est. speed input: 6104.25 toks/s, output: 5.96 toks/s]
Processed prompts:  14%|        | 18/128 [00:03<00:18,  6.01it/s, est. speed input: 6108.47 toks/s, output: 5.97 toks/s]
Processed prompts:  15%|        | 19/128 [00:03<00:18,  6.04it/s, est. speed input: 6116.15 toks/s, output: 5.97 toks/s]
Processed prompts:  16%|        | 20/128 [00:03<00:17,  6.11it/s, est. speed input: 6131.27 toks/s, output: 5.99 toks/s]
Processed prompts:  16%|        | 21/128 [00:03<00:17,  6.13it/s, est. speed input: 6140.13 toks/s, output: 6.00 toks/s]
Processed prompts:  17%|        | 22/128 [00:03<00:17,  6.11it/s, est. speed input: 6142.50 toks/s, output: 6.00 toks/s]
Processed prompts:  18%|        | 23/128 [00:03<00:17,  6.06it/s, est. speed input: 6139.96 toks/s, output: 6.00 toks/s]
Processed prompts:  19%|        | 24/128 [00:04<00:17,  6.06it/s, est. speed input: 6142.50 toks/s, output: 6.00 toks/s]
Processed prompts:  20%|        | 25/128 [00:04<00:16,  6.07it/s, est. speed input: 6146.55 toks/s, output: 6.00 toks/s]
Processed prompts:  20%|        | 26/128 [00:04<00:16,  6.07it/s, est. speed input: 6149.10 toks/s, output: 6.00 toks/s]
Processed prompts:  21%|        | 27/128 [00:04<00:16,  6.07it/s, est. speed input: 6151.34 toks/s, output: 6.01 toks/s]
Processed prompts:  22%|       | 28/128 [00:04<00:16,  6.05it/s, est. speed input: 6151.64 toks/s, output: 6.01 toks/s]
Processed prompts:  23%|       | 29/128 [00:04<00:16,  6.05it/s, est. speed input: 6152.89 toks/s, output: 6.01 toks/s]
Processed prompts:  23%|       | 30/128 [00:04<00:16,  6.01it/s, est. speed input: 6149.37 toks/s, output: 6.01 toks/s]
Processed prompts:  24%|       | 31/128 [00:05<00:16,  6.04it/s, est. speed input: 6153.11 toks/s, output: 6.01 toks/s]
Processed prompts:  25%|       | 32/128 [00:05<00:15,  6.06it/s, est. speed input: 6156.26 toks/s, output: 6.01 toks/s]
Processed prompts:  26%|       | 33/128 [00:05<00:15,  6.07it/s, est. speed input: 6158.27 toks/s, output: 6.01 toks/s]
Processed prompts:  27%|       | 34/128 [00:05<00:15,  6.05it/s, est. speed input: 6158.58 toks/s, output: 6.01 toks/s]
Processed prompts:  27%|       | 35/128 [00:05<00:15,  6.05it/s, est. speed input: 6159.44 toks/s, output: 6.02 toks/s]
Processed prompts:  28%|       | 36/128 [00:05<00:15,  6.03it/s, est. speed input: 6158.26 toks/s, output: 6.01 toks/s]
Processed prompts:  29%|       | 37/128 [00:06<00:15,  6.06it/s, est. speed input: 6161.43 toks/s, output: 6.02 toks/s]
Processed prompts:  30%|       | 38/128 [00:06<00:14,  6.06it/s, est. speed input: 6162.84 toks/s, output: 6.02 toks/s]
Processed prompts:  30%|       | 39/128 [00:06<00:14,  6.04it/s, est. speed input: 6162.15 toks/s, output: 6.02 toks/s]
Processed prompts:  31%|      | 40/128 [00:06<00:14,  6.08it/s, est. speed input: 6165.81 toks/s, output: 6.02 toks/s]
Processed prompts:  32%|      | 41/128 [00:06<00:14,  6.10it/s, est. speed input: 6168.93 toks/s, output: 6.02 toks/s]
Processed prompts:  33%|      | 42/128 [00:06<00:14,  6.04it/s, est. speed input: 6166.04 toks/s, output: 6.02 toks/s]
Processed prompts:  34%|      | 43/128 [00:07<00:14,  6.04it/s, est. speed input: 6166.27 toks/s, output: 6.02 toks/s]
Processed prompts:  34%|      | 44/128 [00:07<00:13,  6.05it/s, est. speed input: 6167.39 toks/s, output: 6.02 toks/s]
Processed prompts:  35%|      | 45/128 [00:07<00:13,  6.04it/s, est. speed input: 6167.08 toks/s, output: 6.02 toks/s]
Processed prompts:  36%|      | 46/128 [00:07<00:13,  6.02it/s, est. speed input: 6166.27 toks/s, output: 6.02 toks/s]
Processed prompts:  37%|      | 47/128 [00:07<00:13,  6.06it/s, est. speed input: 6168.92 toks/s, output: 6.02 toks/s]
Processed prompts:  38%|      | 48/128 [00:07<00:13,  6.08it/s, est. speed input: 6171.05 toks/s, output: 6.03 toks/s]
Processed prompts:  38%|      | 49/128 [00:08<00:13,  6.03it/s, est. speed input: 6168.51 toks/s, output: 6.02 toks/s]
Processed prompts:  39%|      | 50/128 [00:08<00:12,  6.07it/s, est. speed input: 6171.71 toks/s, output: 6.03 toks/s]
Processed prompts:  40%|      | 51/128 [00:08<00:12,  6.06it/s, est. speed input: 6172.09 toks/s, output: 6.03 toks/s]
Processed prompts:  41%|      | 52/128 [00:08<00:12,  6.07it/s, est. speed input: 6173.19 toks/s, output: 6.03 toks/s]
Processed prompts:  41%|     | 53/128 [00:08<00:12,  6.10it/s, est. speed input: 6175.68 toks/s, output: 6.03 toks/s]
Processed prompts:  42%|     | 54/128 [00:08<00:12,  6.10it/s, est. speed input: 6177.25 toks/s, output: 6.03 toks/s]
Processed prompts:  43%|     | 55/128 [00:09<00:11,  6.08it/s, est. speed input: 6177.41 toks/s, output: 6.03 toks/s]
Processed prompts:  44%|     | 56/128 [00:09<00:11,  6.12it/s, est. speed input: 6180.74 toks/s, output: 6.04 toks/s]
Processed prompts:  45%|     | 57/128 [00:09<00:11,  6.13it/s, est. speed input: 6182.88 toks/s, output: 6.04 toks/s]
Processed prompts:  45%|     | 58/128 [00:09<00:11,  6.10it/s, est. speed input: 6182.62 toks/s, output: 6.04 toks/s]
Processed prompts:  46%|     | 59/128 [00:09<00:11,  6.09it/s, est. speed input: 6183.08 toks/s, output: 6.04 toks/s]
Processed prompts:  47%|     | 60/128 [00:09<00:11,  6.06it/s, est. speed input: 6182.14 toks/s, output: 6.04 toks/s]
Processed prompts:  48%|     | 61/128 [00:10<00:11,  5.99it/s, est. speed input: 6178.76 toks/s, output: 6.03 toks/s]
Processed prompts:  48%|     | 62/128 [00:10<00:10,  6.01it/s, est. speed input: 6179.26 toks/s, output: 6.03 toks/s]
Processed prompts:  49%|     | 63/128 [00:10<00:10,  6.04it/s, est. speed input: 6180.51 toks/s, output: 6.04 toks/s]
Processed prompts:  50%|     | 64/128 [00:10<00:10,  6.07it/s, est. speed input: 6181.95 toks/s, output: 6.04 toks/s]
Processed prompts:  51%|     | 65/128 [00:10<00:10,  6.06it/s, est. speed input: 6182.15 toks/s, output: 6.04 toks/s]
Processed prompts:  52%|    | 66/128 [00:10<00:10,  6.06it/s, est. speed input: 6182.27 toks/s, output: 6.04 toks/s]
Processed prompts:  52%|    | 67/128 [00:11<00:10,  6.05it/s, est. speed input: 6182.12 toks/s, output: 6.04 toks/s]
Processed prompts:  53%|    | 68/128 [00:11<00:10,  5.99it/s, est. speed input: 6179.50 toks/s, output: 6.03 toks/s]
Processed prompts:  54%|    | 69/128 [00:11<00:09,  6.01it/s, est. speed input: 6179.93 toks/s, output: 6.04 toks/s]
Processed prompts:  55%|    | 70/128 [00:11<00:09,  6.01it/s, est. speed input: 6179.41 toks/s, output: 6.03 toks/s]
Processed prompts:  55%|    | 71/128 [00:11<00:09,  6.03it/s, est. speed input: 6180.05 toks/s, output: 6.04 toks/s]
Processed prompts:  56%|    | 72/128 [00:11<00:09,  6.06it/s, est. speed input: 6181.22 toks/s, output: 6.04 toks/s]
Processed prompts:  57%|    | 73/128 [00:12<00:09,  6.06it/s, est. speed input: 6181.65 toks/s, output: 6.04 toks/s]
Processed prompts:  58%|    | 74/128 [00:12<00:08,  6.06it/s, est. speed input: 6181.87 toks/s, output: 6.04 toks/s]
Processed prompts:  59%|    | 75/128 [00:12<00:08,  6.09it/s, est. speed input: 6183.39 toks/s, output: 6.04 toks/s]
Processed prompts:  59%|    | 76/128 [00:12<00:08,  6.08it/s, est. speed input: 6183.78 toks/s, output: 6.04 toks/s]
Processed prompts:  60%|    | 77/128 [00:12<00:08,  6.08it/s, est. speed input: 6184.39 toks/s, output: 6.04 toks/s]
Processed prompts:  61%|    | 78/128 [00:12<00:08,  6.07it/s, est. speed input: 6184.23 toks/s, output: 6.04 toks/s]
Processed prompts:  62%|   | 79/128 [00:13<00:08,  6.07it/s, est. speed input: 6184.61 toks/s, output: 6.04 toks/s]
Processed prompts:  62%|   | 80/128 [00:13<00:08,  5.99it/s, est. speed input: 6181.50 toks/s, output: 6.04 toks/s]
Processed prompts:  63%|   | 81/128 [00:13<00:07,  6.01it/s, est. speed input: 6181.75 toks/s, output: 6.04 toks/s]
Processed prompts:  64%|   | 82/128 [00:13<00:07,  6.03it/s, est. speed input: 6182.18 toks/s, output: 6.04 toks/s]
Processed prompts:  65%|   | 83/128 [00:13<00:07,  6.05it/s, est. speed input: 6182.84 toks/s, output: 6.04 toks/s]
Processed prompts:  66%|   | 84/128 [00:13<00:07,  6.04it/s, est. speed input: 6182.68 toks/s, output: 6.04 toks/s]
Processed prompts:  66%|   | 85/128 [00:14<00:07,  6.02it/s, est. speed input: 6181.93 toks/s, output: 6.04 toks/s]
Processed prompts:  67%|   | 86/128 [00:14<00:06,  6.08it/s, est. speed input: 6183.94 toks/s, output: 6.04 toks/s]
Processed prompts:  68%|   | 87/128 [00:14<00:06,  5.99it/s, est. speed input: 6181.04 toks/s, output: 6.04 toks/s]
Processed prompts:  69%|   | 88/128 [00:14<00:06,  6.04it/s, est. speed input: 6182.23 toks/s, output: 6.04 toks/s]
Processed prompts:  70%|   | 89/128 [00:14<00:06,  6.08it/s, est. speed input: 6183.74 toks/s, output: 6.04 toks/s]
Processed prompts:  70%|   | 90/128 [00:14<00:06,  6.05it/s, est. speed input: 6183.38 toks/s, output: 6.04 toks/s]
Processed prompts:  71%|   | 91/128 [00:15<00:06,  6.03it/s, est. speed input: 6182.75 toks/s, output: 6.04 toks/s]
Processed prompts:  72%|  | 92/128 [00:15<00:05,  6.07it/s, est. speed input: 6184.06 toks/s, output: 6.04 toks/s]
Processed prompts:  73%|  | 93/128 [00:15<00:05,  6.02it/s, est. speed input: 6182.44 toks/s, output: 6.04 toks/s]
Processed prompts:  73%|  | 94/128 [00:15<00:05,  6.03it/s, est. speed input: 6182.66 toks/s, output: 6.04 toks/s]
Processed prompts:  74%|  | 95/128 [00:15<00:05,  6.04it/s, est. speed input: 6182.85 toks/s, output: 6.04 toks/s]
Processed prompts:  75%|  | 96/128 [00:15<00:05,  6.02it/s, est. speed input: 6182.30 toks/s, output: 6.04 toks/s]
Processed prompts:  76%|  | 97/128 [00:16<00:05,  5.99it/s, est. speed input: 6181.17 toks/s, output: 6.04 toks/s]
Processed prompts:  77%|  | 98/128 [00:16<00:04,  6.03it/s, est. speed input: 6181.99 toks/s, output: 6.04 toks/s]
Processed prompts:  77%|  | 99/128 [00:16<00:04,  5.99it/s, est. speed input: 6180.58 toks/s, output: 6.04 toks/s]
Processed prompts:  78%|  | 100/128 [00:16<00:04,  5.98it/s, est. speed input: 6179.85 toks/s, output: 6.04 toks/s]
Processed prompts:  79%|  | 101/128 [00:16<00:04,  6.00it/s, est. speed input: 6180.00 toks/s, output: 6.04 toks/s]
Processed prompts:  80%|  | 102/128 [00:16<00:04,  6.05it/s, est. speed input: 6181.23 toks/s, output: 6.04 toks/s]
Processed prompts:  80%|  | 103/128 [00:17<00:04,  6.05it/s, est. speed input: 6181.36 toks/s, output: 6.04 toks/s]
Processed prompts:  81%| | 104/128 [00:17<00:03,  6.07it/s, est. speed input: 6182.18 toks/s, output: 6.04 toks/s]
Processed prompts:  82%| | 105/128 [00:17<00:03,  6.08it/s, est. speed input: 6182.84 toks/s, output: 6.04 toks/s]
Processed prompts:  83%| | 106/128 [00:17<00:03,  6.02it/s, est. speed input: 6181.45 toks/s, output: 6.04 toks/s]
Processed prompts:  84%| | 107/128 [00:17<00:03,  6.02it/s, est. speed input: 6181.33 toks/s, output: 6.04 toks/s]
Processed prompts:  84%| | 108/128 [00:17<00:03,  6.05it/s, est. speed input: 6182.01 toks/s, output: 6.04 toks/s]
Processed prompts:  85%| | 109/128 [00:18<00:03,  6.02it/s, est. speed input: 6181.17 toks/s, output: 6.04 toks/s]
Processed prompts:  86%| | 110/128 [00:18<00:02,  6.02it/s, est. speed input: 6180.89 toks/s, output: 6.04 toks/s]
Processed prompts:  87%| | 111/128 [00:18<00:02,  6.05it/s, est. speed input: 6181.79 toks/s, output: 6.04 toks/s]
Processed prompts:  88%| | 112/128 [00:18<00:02,  5.99it/s, est. speed input: 6180.00 toks/s, output: 6.04 toks/s]
Processed prompts:  88%| | 113/128 [00:18<00:02,  6.01it/s, est. speed input: 6180.32 toks/s, output: 6.04 toks/s]
Processed prompts:  89%| | 114/128 [00:18<00:02,  6.03it/s, est. speed input: 6180.55 toks/s, output: 6.04 toks/s]
Processed prompts:  90%| | 115/128 [00:19<00:02,  6.02it/s, est. speed input: 6180.18 toks/s, output: 6.04 toks/s]
Processed prompts:  91%| | 116/128 [00:19<00:01,  6.03it/s, est. speed input: 6180.27 toks/s, output: 6.04 toks/s]
Processed prompts:  91%|| 117/128 [00:19<00:01,  6.03it/s, est. speed input: 6180.23 toks/s, output: 6.04 toks/s]
Processed prompts:  92%|| 118/128 [00:19<00:01,  5.99it/s, est. speed input: 6179.09 toks/s, output: 6.03 toks/s]
Processed prompts:  93%|| 119/128 [00:19<00:01,  5.98it/s, est. speed input: 6178.36 toks/s, output: 6.03 toks/s]
Processed prompts:  94%|| 120/128 [00:19<00:01,  6.01it/s, est. speed input: 6178.68 toks/s, output: 6.03 toks/s]
Processed prompts:  95%|| 121/128 [00:20<00:01,  6.01it/s, est. speed input: 6178.54 toks/s, output: 6.03 toks/s]
Processed prompts:  95%|| 122/128 [00:20<00:00,  6.02it/s, est. speed input: 6178.66 toks/s, output: 6.03 toks/s]
Processed prompts:  96%|| 123/128 [00:20<00:00,  6.02it/s, est. speed input: 6178.40 toks/s, output: 6.03 toks/s]
Processed prompts:  97%|| 124/128 [00:20<00:00,  6.02it/s, est. speed input: 6178.29 toks/s, output: 6.03 toks/s]
Processed prompts:  98%|| 125/128 [00:20<00:00,  5.96it/s, est. speed input: 6176.51 toks/s, output: 6.03 toks/s]
Processed prompts:  98%|| 126/128 [00:20<00:00,  5.98it/s, est. speed input: 6176.42 toks/s, output: 6.03 toks/s]
Processed prompts:  99%|| 127/128 [00:21<00:00,  5.99it/s, est. speed input: 6176.33 toks/s, output: 6.03 toks/s]
Processed prompts: 100%|| 128/128 [00:21<00:00,  5.99it/s, est. speed input: 6176.09 toks/s, output: 6.03 toks/s]
Processed prompts: 100%|| 128/128 [00:21<00:00,  5.99it/s, est. speed input: 6176.09 toks/s, output: 6.03 toks/s]
Processed prompts: 100%|| 128/128 [00:21<00:00,  6.03it/s, est. speed input: 6176.09 toks/s, output: 6.03 toks/s]
[rank0]:[W126 15:56:22.586268038 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 15:56:24
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:56:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 15:56:30 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1468625) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1468625) WARNING 01-26 15:57:46 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 6.09 requests/s, 6242.05 total tokens/s, 6.09 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 15:56:30] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:56:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:56:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:56:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:56:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:56:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:56:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:56:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:56:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:56:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:56:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:56:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:56:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:56:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:56:34] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:56:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:56:34] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:56:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:56:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:56:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:56:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:56:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:56:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:56:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:56:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:56:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:56:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:56:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1468625) [2026-01-26 15:56:35] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1468625) [2026-01-26 15:56:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1468625) [2026-01-26 15:56:35] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1468625) [2026-01-26 15:56:35] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1468625) [2026-01-26 15:56:35] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1468625) [2026-01-26 15:56:35] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1468625) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1468625) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.38s/it]
(EngineCore_DP0 pid=1468625) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:01<00:00, 31.17s/it]
(EngineCore_DP0 pid=1468625) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:01<00:00, 30.75s/it]
(EngineCore_DP0 pid=1468625) 
(EngineCore_DP0 pid=1468625) [2026-01-26 15:57:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1468625) [2026-01-26 15:57:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=1468625) [2026-01-26 15:57:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1468625) [2026-01-26 15:57:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=1468625) [2026-01-26 15:57:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1468625) [2026-01-26 15:57:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=1468625) [2026-01-26 15:57:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1468625) [2026-01-26 15:57:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=1468625) 2026-01-26 15:57:45,689 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1468625) 2026-01-26 15:57:45,726 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  19%|        | 49/256 [00:00<00:00, 484.93it/s]
Adding requests:  38%|      | 98/256 [00:00<00:00, 434.26it/s]
Adding requests:  55%|    | 142/256 [00:00<00:00, 420.73it/s]
Adding requests:  73%|  | 187/256 [00:00<00:00, 431.54it/s]
Adding requests:  90%| | 231/256 [00:00<00:00, 429.82it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 430.36it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 4/256 [00:00<00:21, 11.67it/s, est. speed input: 11954.93 toks/s, output: 11.67 toks/s]
Processed prompts:   2%|         | 6/256 [00:00<00:29,  8.51it/s, est. speed input: 9209.83 toks/s, output: 8.99 toks/s]  
Processed prompts:   3%|         | 8/256 [00:00<00:33,  7.48it/s, est. speed input: 8282.95 toks/s, output: 8.09 toks/s]
Processed prompts:   4%|         | 10/256 [00:01<00:35,  6.96it/s, est. speed input: 7792.71 toks/s, output: 7.61 toks/s]
Processed prompts:   5%|         | 12/256 [00:01<00:36,  6.63it/s, est. speed input: 7472.11 toks/s, output: 7.30 toks/s]
Processed prompts:   5%|         | 14/256 [00:01<00:37,  6.48it/s, est. speed input: 7286.77 toks/s, output: 7.12 toks/s]
Processed prompts:   6%|         | 16/256 [00:02<00:37,  6.38it/s, est. speed input: 7151.13 toks/s, output: 6.98 toks/s]
Processed prompts:   7%|         | 18/256 [00:02<00:37,  6.30it/s, est. speed input: 7041.00 toks/s, output: 6.88 toks/s]
Processed prompts:   8%|         | 20/256 [00:02<00:37,  6.26it/s, est. speed input: 6963.41 toks/s, output: 6.80 toks/s]
Processed prompts:   9%|         | 22/256 [00:03<00:37,  6.23it/s, est. speed input: 6895.65 toks/s, output: 6.73 toks/s]
Processed prompts:   9%|         | 24/256 [00:03<00:37,  6.17it/s, est. speed input: 6829.36 toks/s, output: 6.67 toks/s]
Processed prompts:  10%|         | 26/256 [00:03<00:37,  6.15it/s, est. speed input: 6782.84 toks/s, output: 6.62 toks/s]
Processed prompts:  11%|         | 28/256 [00:04<00:37,  6.16it/s, est. speed input: 6746.81 toks/s, output: 6.59 toks/s]
Processed prompts:  12%|        | 30/256 [00:04<00:36,  6.12it/s, est. speed input: 6706.97 toks/s, output: 6.55 toks/s]
Processed prompts:  12%|        | 32/256 [00:04<00:36,  6.14it/s, est. speed input: 6680.72 toks/s, output: 6.52 toks/s]
Processed prompts:  13%|        | 34/256 [00:05<00:36,  6.16it/s, est. speed input: 6661.11 toks/s, output: 6.50 toks/s]
Processed prompts:  14%|        | 36/256 [00:05<00:35,  6.16it/s, est. speed input: 6640.49 toks/s, output: 6.48 toks/s]
Processed prompts:  15%|        | 38/256 [00:05<00:35,  6.12it/s, est. speed input: 6614.87 toks/s, output: 6.46 toks/s]
Processed prompts:  16%|        | 40/256 [00:06<00:35,  6.11it/s, est. speed input: 6594.93 toks/s, output: 6.44 toks/s]
Processed prompts:  16%|        | 42/256 [00:06<00:34,  6.12it/s, est. speed input: 6579.23 toks/s, output: 6.43 toks/s]
Processed prompts:  17%|        | 44/256 [00:06<00:34,  6.09it/s, est. speed input: 6558.56 toks/s, output: 6.40 toks/s]
Processed prompts:  18%|        | 46/256 [00:07<00:34,  6.10it/s, est. speed input: 6546.25 toks/s, output: 6.39 toks/s]
Processed prompts:  19%|        | 48/256 [00:07<00:33,  6.12it/s, est. speed input: 6536.33 toks/s, output: 6.38 toks/s]
Processed prompts:  20%|        | 50/256 [00:07<00:33,  6.10it/s, est. speed input: 6521.67 toks/s, output: 6.37 toks/s]
Processed prompts:  20%|        | 52/256 [00:08<00:33,  6.12it/s, est. speed input: 6513.24 toks/s, output: 6.36 toks/s]
Processed prompts:  21%|        | 54/256 [00:08<00:32,  6.12it/s, est. speed input: 6504.52 toks/s, output: 6.35 toks/s]
Processed prompts:  22%|       | 56/256 [00:08<00:32,  6.11it/s, est. speed input: 6493.97 toks/s, output: 6.34 toks/s]
Processed prompts:  23%|       | 58/256 [00:09<00:32,  6.12it/s, est. speed input: 6486.88 toks/s, output: 6.33 toks/s]
Processed prompts:  23%|       | 60/256 [00:09<00:32,  6.12it/s, est. speed input: 6479.14 toks/s, output: 6.33 toks/s]
Processed prompts:  24%|       | 62/256 [00:09<00:31,  6.11it/s, est. speed input: 6471.34 toks/s, output: 6.32 toks/s]
Processed prompts:  25%|       | 64/256 [00:10<00:31,  6.11it/s, est. speed input: 6464.36 toks/s, output: 6.31 toks/s]
Processed prompts:  26%|       | 66/256 [00:10<00:31,  6.11it/s, est. speed input: 6457.40 toks/s, output: 6.31 toks/s]
Processed prompts:  27%|       | 68/256 [00:10<00:30,  6.11it/s, est. speed input: 6451.95 toks/s, output: 6.30 toks/s]
Processed prompts:  27%|       | 70/256 [00:11<00:30,  6.08it/s, est. speed input: 6443.27 toks/s, output: 6.29 toks/s]
Processed prompts:  28%|       | 72/256 [00:11<00:30,  6.10it/s, est. speed input: 6438.97 toks/s, output: 6.29 toks/s]
Processed prompts:  29%|       | 74/256 [00:11<00:29,  6.11it/s, est. speed input: 6434.39 toks/s, output: 6.28 toks/s]
Processed prompts:  30%|       | 76/256 [00:12<00:29,  6.08it/s, est. speed input: 6426.35 toks/s, output: 6.28 toks/s]
Processed prompts:  30%|       | 78/256 [00:12<00:29,  6.08it/s, est. speed input: 6421.60 toks/s, output: 6.27 toks/s]
Processed prompts:  31%|      | 80/256 [00:12<00:28,  6.09it/s, est. speed input: 6417.53 toks/s, output: 6.27 toks/s]
Processed prompts:  32%|      | 82/256 [00:13<00:28,  6.06it/s, est. speed input: 6410.58 toks/s, output: 6.26 toks/s]
Processed prompts:  33%|      | 84/256 [00:13<00:28,  6.08it/s, est. speed input: 6406.63 toks/s, output: 6.26 toks/s]
Processed prompts:  34%|      | 86/256 [00:13<00:27,  6.08it/s, est. speed input: 6402.92 toks/s, output: 6.25 toks/s]
Processed prompts:  34%|      | 88/256 [00:14<00:27,  6.07it/s, est. speed input: 6397.90 toks/s, output: 6.25 toks/s]
Processed prompts:  35%|      | 90/256 [00:14<00:27,  6.08it/s, est. speed input: 6394.75 toks/s, output: 6.24 toks/s]
Processed prompts:  36%|      | 92/256 [00:14<00:26,  6.11it/s, est. speed input: 6392.72 toks/s, output: 6.24 toks/s]
Processed prompts:  37%|      | 94/256 [00:15<00:26,  6.08it/s, est. speed input: 6388.06 toks/s, output: 6.24 toks/s]
Processed prompts:  38%|      | 96/256 [00:15<00:26,  6.10it/s, est. speed input: 6385.57 toks/s, output: 6.24 toks/s]
Processed prompts:  38%|      | 98/256 [00:15<00:25,  6.10it/s, est. speed input: 6383.13 toks/s, output: 6.23 toks/s]
Processed prompts:  39%|      | 100/256 [00:16<00:25,  6.10it/s, est. speed input: 6380.02 toks/s, output: 6.23 toks/s]
Processed prompts:  40%|      | 102/256 [00:16<00:25,  6.07it/s, est. speed input: 6375.56 toks/s, output: 6.23 toks/s]
Processed prompts:  41%|      | 104/256 [00:16<00:25,  6.07it/s, est. speed input: 6372.60 toks/s, output: 6.22 toks/s]
Processed prompts:  41%|     | 106/256 [00:17<00:24,  6.09it/s, est. speed input: 6370.68 toks/s, output: 6.22 toks/s]
Processed prompts:  42%|     | 108/256 [00:17<00:24,  6.05it/s, est. speed input: 6365.68 toks/s, output: 6.22 toks/s]
Processed prompts:  43%|     | 110/256 [00:17<00:24,  6.07it/s, est. speed input: 6363.92 toks/s, output: 6.21 toks/s]
Processed prompts:  44%|     | 112/256 [00:18<00:23,  6.09it/s, est. speed input: 6362.33 toks/s, output: 6.21 toks/s]
Processed prompts:  45%|     | 114/256 [00:18<00:23,  6.06it/s, est. speed input: 6358.44 toks/s, output: 6.21 toks/s]
Processed prompts:  45%|     | 116/256 [00:18<00:23,  6.07it/s, est. speed input: 6356.13 toks/s, output: 6.21 toks/s]
Processed prompts:  46%|     | 118/256 [00:19<00:22,  6.07it/s, est. speed input: 6353.77 toks/s, output: 6.20 toks/s]
Processed prompts:  47%|     | 120/256 [00:19<00:22,  6.04it/s, est. speed input: 6349.61 toks/s, output: 6.20 toks/s]
Processed prompts:  48%|     | 122/256 [00:19<00:22,  6.07it/s, est. speed input: 6348.80 toks/s, output: 6.20 toks/s]
Processed prompts:  48%|     | 124/256 [00:20<00:21,  6.08it/s, est. speed input: 6347.17 toks/s, output: 6.20 toks/s]
Processed prompts:  49%|     | 126/256 [00:20<00:21,  6.11it/s, est. speed input: 6346.57 toks/s, output: 6.20 toks/s]
Processed prompts:  50%|     | 128/256 [00:20<00:21,  6.09it/s, est. speed input: 6344.15 toks/s, output: 6.20 toks/s]
Processed prompts:  51%|     | 130/256 [00:20<00:20,  6.08it/s, est. speed input: 6342.12 toks/s, output: 6.19 toks/s]
Processed prompts:  52%|    | 132/256 [00:21<00:20,  6.08it/s, est. speed input: 6340.39 toks/s, output: 6.19 toks/s]
Processed prompts:  52%|    | 134/256 [00:21<00:20,  6.06it/s, est. speed input: 6337.49 toks/s, output: 6.19 toks/s]
Processed prompts:  53%|    | 136/256 [00:21<00:19,  6.07it/s, est. speed input: 6336.18 toks/s, output: 6.19 toks/s]
Processed prompts:  54%|    | 138/256 [00:22<00:19,  6.08it/s, est. speed input: 6334.57 toks/s, output: 6.19 toks/s]
Processed prompts:  55%|    | 140/256 [00:22<00:19,  6.09it/s, est. speed input: 6333.77 toks/s, output: 6.19 toks/s]
Processed prompts:  55%|    | 142/256 [00:22<00:18,  6.09it/s, est. speed input: 6332.45 toks/s, output: 6.18 toks/s]
Processed prompts:  56%|    | 144/256 [00:23<00:18,  6.08it/s, est. speed input: 6330.53 toks/s, output: 6.18 toks/s]
Processed prompts:  57%|    | 146/256 [00:23<00:18,  6.05it/s, est. speed input: 6327.35 toks/s, output: 6.18 toks/s]
Processed prompts:  58%|    | 148/256 [00:23<00:17,  6.06it/s, est. speed input: 6326.11 toks/s, output: 6.18 toks/s]
Processed prompts:  59%|    | 150/256 [00:24<00:17,  6.07it/s, est. speed input: 6325.18 toks/s, output: 6.18 toks/s]
Processed prompts:  59%|    | 152/256 [00:24<00:17,  6.05it/s, est. speed input: 6322.71 toks/s, output: 6.17 toks/s]
Processed prompts:  60%|    | 154/256 [00:24<00:16,  6.07it/s, est. speed input: 6322.00 toks/s, output: 6.17 toks/s]
Processed prompts:  61%|    | 156/256 [00:25<00:16,  6.08it/s, est. speed input: 6321.08 toks/s, output: 6.17 toks/s]
Processed prompts:  62%|   | 158/256 [00:25<00:16,  6.08it/s, est. speed input: 6319.74 toks/s, output: 6.17 toks/s]
Processed prompts:  62%|   | 160/256 [00:25<00:15,  6.07it/s, est. speed input: 6317.95 toks/s, output: 6.17 toks/s]
Processed prompts:  63%|   | 162/256 [00:26<00:15,  6.11it/s, est. speed input: 6318.54 toks/s, output: 6.17 toks/s]
Processed prompts:  64%|   | 164/256 [00:26<00:15,  6.11it/s, est. speed input: 6317.64 toks/s, output: 6.17 toks/s]
Processed prompts:  65%|   | 166/256 [00:26<00:14,  6.07it/s, est. speed input: 6315.32 toks/s, output: 6.17 toks/s]
Processed prompts:  66%|   | 168/256 [00:27<00:14,  6.07it/s, est. speed input: 6314.24 toks/s, output: 6.17 toks/s]
Processed prompts:  66%|   | 170/256 [00:27<00:14,  6.08it/s, est. speed input: 6313.28 toks/s, output: 6.17 toks/s]
Processed prompts:  67%|   | 172/256 [00:27<00:13,  6.06it/s, est. speed input: 6311.67 toks/s, output: 6.16 toks/s]
Processed prompts:  68%|   | 174/256 [00:28<00:13,  6.10it/s, est. speed input: 6311.92 toks/s, output: 6.16 toks/s]
Processed prompts:  69%|   | 176/256 [00:28<00:13,  6.09it/s, est. speed input: 6310.71 toks/s, output: 6.16 toks/s]
Processed prompts:  70%|   | 178/256 [00:28<00:12,  6.06it/s, est. speed input: 6308.55 toks/s, output: 6.16 toks/s]
Processed prompts:  70%|   | 180/256 [00:29<00:12,  6.07it/s, est. speed input: 6307.90 toks/s, output: 6.16 toks/s]
Processed prompts:  71%|   | 182/256 [00:29<00:12,  6.07it/s, est. speed input: 6306.77 toks/s, output: 6.16 toks/s]
Processed prompts:  72%|  | 184/256 [00:29<00:11,  6.05it/s, est. speed input: 6305.16 toks/s, output: 6.16 toks/s]
Processed prompts:  73%|  | 186/256 [00:30<00:11,  6.07it/s, est. speed input: 6304.66 toks/s, output: 6.16 toks/s]
Processed prompts:  73%|  | 188/256 [00:30<00:11,  6.09it/s, est. speed input: 6304.28 toks/s, output: 6.16 toks/s]
Processed prompts:  74%|  | 190/256 [00:30<00:10,  6.09it/s, est. speed input: 6303.76 toks/s, output: 6.16 toks/s]
Processed prompts:  75%|  | 192/256 [00:31<00:10,  6.06it/s, est. speed input: 6301.77 toks/s, output: 6.15 toks/s]
Processed prompts:  76%|  | 194/256 [00:31<00:10,  6.07it/s, est. speed input: 6301.32 toks/s, output: 6.15 toks/s]
Processed prompts:  77%|  | 196/256 [00:31<00:09,  6.09it/s, est. speed input: 6300.98 toks/s, output: 6.15 toks/s]
Processed prompts:  77%|  | 198/256 [00:32<00:09,  6.07it/s, est. speed input: 6299.71 toks/s, output: 6.15 toks/s]
Processed prompts:  78%|  | 200/256 [00:32<00:09,  6.08it/s, est. speed input: 6299.10 toks/s, output: 6.15 toks/s]
Processed prompts:  79%|  | 202/256 [00:32<00:07,  6.86it/s, est. speed input: 6322.31 toks/s, output: 6.17 toks/s]
Processed prompts:  80%|  | 204/256 [00:33<00:07,  6.57it/s, est. speed input: 6320.32 toks/s, output: 6.17 toks/s]
Processed prompts:  80%|  | 206/256 [00:33<00:07,  6.42it/s, est. speed input: 6319.52 toks/s, output: 6.17 toks/s]
Processed prompts:  81%| | 208/256 [00:33<00:07,  6.34it/s, est. speed input: 6319.49 toks/s, output: 6.17 toks/s]
Processed prompts:  82%| | 210/256 [00:34<00:07,  6.27it/s, est. speed input: 6318.87 toks/s, output: 6.17 toks/s]
Processed prompts:  83%| | 212/256 [00:34<00:07,  6.18it/s, est. speed input: 6317.10 toks/s, output: 6.17 toks/s]
Processed prompts:  84%| | 214/256 [00:34<00:06,  6.16it/s, est. speed input: 6316.43 toks/s, output: 6.17 toks/s]
Processed prompts:  84%| | 216/256 [00:35<00:06,  6.15it/s, est. speed input: 6315.97 toks/s, output: 6.17 toks/s]
Processed prompts:  85%| | 218/256 [00:35<00:06,  6.10it/s, est. speed input: 6314.39 toks/s, output: 6.17 toks/s]
Processed prompts:  86%| | 220/256 [00:35<00:05,  6.11it/s, est. speed input: 6313.92 toks/s, output: 6.17 toks/s]
Processed prompts:  87%| | 222/256 [00:36<00:05,  6.10it/s, est. speed input: 6312.99 toks/s, output: 6.17 toks/s]
Processed prompts:  88%| | 224/256 [00:36<00:05,  6.07it/s, est. speed input: 6311.45 toks/s, output: 6.16 toks/s]
Processed prompts:  88%| | 226/256 [00:36<00:04,  6.08it/s, est. speed input: 6311.06 toks/s, output: 6.16 toks/s]
Processed prompts:  89%| | 228/256 [00:36<00:04,  6.10it/s, est. speed input: 6310.84 toks/s, output: 6.16 toks/s]
Processed prompts:  90%| | 230/256 [00:37<00:04,  6.06it/s, est. speed input: 6309.13 toks/s, output: 6.16 toks/s]
Processed prompts:  91%| | 232/256 [00:37<00:03,  6.08it/s, est. speed input: 6308.83 toks/s, output: 6.16 toks/s]
Processed prompts:  91%|| 234/256 [00:37<00:03,  6.11it/s, est. speed input: 6308.96 toks/s, output: 6.16 toks/s]
Processed prompts:  92%|| 236/256 [00:38<00:03,  6.07it/s, est. speed input: 6307.36 toks/s, output: 6.16 toks/s]
Processed prompts:  93%|| 238/256 [00:38<00:02,  6.08it/s, est. speed input: 6306.90 toks/s, output: 6.16 toks/s]
Processed prompts:  94%|| 240/256 [00:38<00:02,  6.10it/s, est. speed input: 6306.68 toks/s, output: 6.16 toks/s]
Processed prompts:  95%|| 242/256 [00:39<00:02,  6.10it/s, est. speed input: 6306.23 toks/s, output: 6.16 toks/s]
Processed prompts:  95%|| 244/256 [00:39<00:01,  6.07it/s, est. speed input: 6304.86 toks/s, output: 6.16 toks/s]
Processed prompts:  96%|| 246/256 [00:39<00:01,  6.08it/s, est. speed input: 6304.40 toks/s, output: 6.16 toks/s]
Processed prompts:  97%|| 248/256 [00:40<00:01,  6.08it/s, est. speed input: 6303.87 toks/s, output: 6.16 toks/s]
Processed prompts:  98%|| 250/256 [00:40<00:00,  6.06it/s, est. speed input: 6302.72 toks/s, output: 6.15 toks/s]
Processed prompts:  98%|| 252/256 [00:40<00:00,  6.07it/s, est. speed input: 6302.07 toks/s, output: 6.15 toks/s]
Processed prompts:  99%|| 254/256 [00:41<00:00,  6.09it/s, est. speed input: 6301.85 toks/s, output: 6.15 toks/s]
Processed prompts: 100%|| 256/256 [00:41<00:00,  7.13it/s, est. speed input: 6325.66 toks/s, output: 6.18 toks/s]
Processed prompts: 100%|| 256/256 [00:41<00:00,  7.13it/s, est. speed input: 6325.66 toks/s, output: 6.18 toks/s]
Processed prompts: 100%|| 256/256 [00:41<00:00,  6.18it/s, est. speed input: 6325.66 toks/s, output: 6.18 toks/s]
[rank0]:[W126 15:58:28.103537693 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 15:58:32
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:58:39 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 15:58:40 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1470596) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1470596) WARNING 01-26 15:59:56 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.96 requests/s, 6110.87 total tokens/s, 5.96 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 15:58:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:58:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:58:39] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:58:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:58:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:58:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:58:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:58:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:58:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:58:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:58:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:58:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:58:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:58:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:58:43] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:58:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:58:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:58:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:58:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:58:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:58:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:58:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:58:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:58:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:58:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:58:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:58:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:58:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1470596) [2026-01-26 15:58:44] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1470596) [2026-01-26 15:58:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1470596) [2026-01-26 15:58:44] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1470596) [2026-01-26 15:58:44] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1470596) [2026-01-26 15:58:44] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1470596) [2026-01-26 15:58:44] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1470596) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1470596) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.29s/it]
(EngineCore_DP0 pid=1470596) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:01<00:00, 31.27s/it]
(EngineCore_DP0 pid=1470596) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:01<00:00, 30.82s/it]
(EngineCore_DP0 pid=1470596) 
(EngineCore_DP0 pid=1470596) [2026-01-26 15:59:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1470596) [2026-01-26 15:59:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=1470596) [2026-01-26 15:59:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1470596) [2026-01-26 15:59:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=1470596) [2026-01-26 15:59:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1470596) [2026-01-26 15:59:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=1470596) [2026-01-26 15:59:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1470596) [2026-01-26 15:59:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=1470596) 2026-01-26 15:59:55,325 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1470596) 2026-01-26 15:59:55,410 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   6%|         | 31/512 [00:00<00:01, 307.39it/s]
Adding requests:  13%|        | 69/512 [00:00<00:01, 348.33it/s]
Adding requests:  21%|       | 110/512 [00:00<00:01, 372.77it/s]
Adding requests:  29%|       | 150/512 [00:00<00:00, 382.71it/s]
Adding requests:  38%|      | 195/512 [00:00<00:00, 403.70it/s]
Adding requests:  47%|     | 239/512 [00:00<00:00, 414.86it/s]
Adding requests:  55%|    | 283/512 [00:00<00:00, 422.43it/s]
Adding requests:  64%|   | 328/512 [00:00<00:00, 430.06it/s]
Adding requests:  73%|  | 374/512 [00:00<00:00, 436.49it/s]
Adding requests:  82%| | 419/512 [00:01<00:00, 437.39it/s]
Adding requests:  90%| | 463/512 [00:01<00:00, 435.48it/s]
Adding requests: 100%|| 510/512 [00:01<00:00, 444.87it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 419.47it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 6/512 [00:00<00:33, 15.32it/s, est. speed input: 15685.96 toks/s, output: 15.32 toks/s]
Processed prompts:   2%|         | 10/512 [00:01<00:57,  8.71it/s, est. speed input: 9673.22 toks/s, output: 9.45 toks/s] 
Processed prompts:   3%|         | 14/512 [00:01<01:08,  7.30it/s, est. speed input: 8269.86 toks/s, output: 8.08 toks/s]
Processed prompts:   4%|         | 18/512 [00:02<01:13,  6.75it/s, est. speed input: 7673.92 toks/s, output: 7.49 toks/s]
Processed prompts:   4%|         | 22/512 [00:03<01:16,  6.43it/s, est. speed input: 7316.20 toks/s, output: 7.14 toks/s]
Processed prompts:   5%|         | 26/512 [00:03<01:17,  6.27it/s, est. speed input: 7100.20 toks/s, output: 6.93 toks/s]
Processed prompts:   6%|         | 30/512 [00:04<01:18,  6.17it/s, est. speed input: 6948.28 toks/s, output: 6.79 toks/s]
Processed prompts:   7%|         | 34/512 [00:05<01:18,  6.11it/s, est. speed input: 6840.58 toks/s, output: 6.68 toks/s]
Processed prompts:   7%|         | 38/512 [00:05<01:18,  6.06it/s, est. speed input: 6755.91 toks/s, output: 6.60 toks/s]
Processed prompts:   8%|         | 42/512 [00:06<01:17,  6.04it/s, est. speed input: 6690.84 toks/s, output: 6.53 toks/s]
Processed prompts:   9%|         | 46/512 [00:07<01:17,  6.01it/s, est. speed input: 6632.98 toks/s, output: 6.48 toks/s]
Processed prompts:  10%|         | 50/512 [00:07<01:16,  6.01it/s, est. speed input: 6593.61 toks/s, output: 6.44 toks/s]
Processed prompts:  11%|         | 54/512 [00:08<01:16,  6.01it/s, est. speed input: 6558.88 toks/s, output: 6.41 toks/s]
Processed prompts:  11%|        | 58/512 [00:09<01:15,  5.99it/s, est. speed input: 6523.04 toks/s, output: 6.37 toks/s]
Processed prompts:  12%|        | 62/512 [00:09<01:15,  5.99it/s, est. speed input: 6495.55 toks/s, output: 6.34 toks/s]
Processed prompts:  13%|        | 66/512 [00:10<01:14,  5.98it/s, est. speed input: 6471.00 toks/s, output: 6.32 toks/s]
Processed prompts:  14%|        | 70/512 [00:11<01:14,  5.97it/s, est. speed input: 6447.62 toks/s, output: 6.30 toks/s]
Processed prompts:  14%|        | 74/512 [00:11<01:13,  5.97it/s, est. speed input: 6429.76 toks/s, output: 6.28 toks/s]
Processed prompts:  15%|        | 78/512 [00:12<01:12,  5.96it/s, est. speed input: 6410.27 toks/s, output: 6.26 toks/s]
Processed prompts:  16%|        | 82/512 [00:13<01:12,  5.96it/s, est. speed input: 6393.68 toks/s, output: 6.24 toks/s]
Processed prompts:  17%|        | 86/512 [00:13<01:11,  5.96it/s, est. speed input: 6380.22 toks/s, output: 6.23 toks/s]
Processed prompts:  18%|        | 90/512 [00:14<01:10,  5.96it/s, est. speed input: 6366.83 toks/s, output: 6.22 toks/s]
Processed prompts:  18%|        | 94/512 [00:15<01:10,  5.96it/s, est. speed input: 6355.53 toks/s, output: 6.21 toks/s]
Processed prompts:  19%|        | 98/512 [00:15<01:09,  5.95it/s, est. speed input: 6343.73 toks/s, output: 6.20 toks/s]
Processed prompts:  20%|        | 102/512 [00:16<01:08,  5.95it/s, est. speed input: 6333.15 toks/s, output: 6.18 toks/s]
Processed prompts:  21%|        | 106/512 [00:17<01:08,  5.97it/s, est. speed input: 6326.17 toks/s, output: 6.18 toks/s]
Processed prompts:  21%|       | 110/512 [00:17<01:07,  5.96it/s, est. speed input: 6317.60 toks/s, output: 6.17 toks/s]
Processed prompts:  22%|       | 114/512 [00:18<01:06,  5.96it/s, est. speed input: 6309.77 toks/s, output: 6.16 toks/s]
Processed prompts:  23%|       | 118/512 [00:19<01:05,  5.98it/s, est. speed input: 6304.77 toks/s, output: 6.16 toks/s]
Processed prompts:  24%|       | 122/512 [00:19<01:05,  5.98it/s, est. speed input: 6298.43 toks/s, output: 6.15 toks/s]
Processed prompts:  25%|       | 126/512 [00:20<01:04,  5.98it/s, est. speed input: 6292.76 toks/s, output: 6.15 toks/s]
Processed prompts:  25%|       | 130/512 [00:21<01:03,  5.99it/s, est. speed input: 6288.23 toks/s, output: 6.14 toks/s]
Processed prompts:  26%|       | 134/512 [00:21<01:03,  5.96it/s, est. speed input: 6280.84 toks/s, output: 6.13 toks/s]
Processed prompts:  27%|       | 138/512 [00:22<01:02,  5.97it/s, est. speed input: 6276.57 toks/s, output: 6.13 toks/s]
Processed prompts:  28%|       | 142/512 [00:23<01:02,  5.96it/s, est. speed input: 6270.68 toks/s, output: 6.12 toks/s]
Processed prompts:  29%|       | 146/512 [00:23<01:01,  5.95it/s, est. speed input: 6265.32 toks/s, output: 6.12 toks/s]
Processed prompts:  29%|       | 150/512 [00:24<01:00,  5.97it/s, est. speed input: 6262.33 toks/s, output: 6.12 toks/s]
Processed prompts:  30%|       | 154/512 [00:25<01:00,  5.96it/s, est. speed input: 6257.76 toks/s, output: 6.11 toks/s]
Processed prompts:  31%|       | 158/512 [00:25<00:59,  5.95it/s, est. speed input: 6253.04 toks/s, output: 6.11 toks/s]
Processed prompts:  32%|      | 162/512 [00:26<00:58,  5.95it/s, est. speed input: 6248.89 toks/s, output: 6.10 toks/s]
Processed prompts:  32%|      | 166/512 [00:27<00:58,  5.95it/s, est. speed input: 6245.29 toks/s, output: 6.10 toks/s]
Processed prompts:  33%|      | 170/512 [00:27<00:57,  5.95it/s, est. speed input: 6241.33 toks/s, output: 6.10 toks/s]
Processed prompts:  34%|      | 174/512 [00:28<00:56,  5.95it/s, est. speed input: 6238.01 toks/s, output: 6.09 toks/s]
Processed prompts:  35%|      | 178/512 [00:29<00:56,  5.94it/s, est. speed input: 6233.53 toks/s, output: 6.09 toks/s]
Processed prompts:  36%|      | 182/512 [00:29<00:55,  5.95it/s, est. speed input: 6230.76 toks/s, output: 6.08 toks/s]
Processed prompts:  36%|      | 186/512 [00:30<00:54,  5.94it/s, est. speed input: 6227.47 toks/s, output: 6.08 toks/s]
Processed prompts:  37%|      | 190/512 [00:31<00:54,  5.94it/s, est. speed input: 6224.18 toks/s, output: 6.08 toks/s]
Processed prompts:  38%|      | 194/512 [00:31<00:53,  5.95it/s, est. speed input: 6222.26 toks/s, output: 6.08 toks/s]
Processed prompts:  39%|      | 198/512 [00:32<00:52,  5.94it/s, est. speed input: 6218.84 toks/s, output: 6.07 toks/s]
Processed prompts:  39%|      | 202/512 [00:33<00:49,  6.25it/s, est. speed input: 6237.05 toks/s, output: 6.09 toks/s]
Processed prompts:  40%|      | 206/512 [00:33<00:49,  6.18it/s, est. speed input: 6235.24 toks/s, output: 6.09 toks/s]
Processed prompts:  41%|      | 210/512 [00:34<00:49,  6.08it/s, est. speed input: 6231.02 toks/s, output: 6.08 toks/s]
Processed prompts:  42%|     | 214/512 [00:35<00:49,  6.06it/s, est. speed input: 6229.14 toks/s, output: 6.08 toks/s]
Processed prompts:  43%|     | 218/512 [00:35<00:48,  6.00it/s, est. speed input: 6225.30 toks/s, output: 6.08 toks/s]
Processed prompts:  43%|     | 222/512 [00:36<00:48,  5.98it/s, est. speed input: 6222.66 toks/s, output: 6.08 toks/s]
Processed prompts:  44%|     | 226/512 [00:37<00:47,  5.98it/s, est. speed input: 6220.97 toks/s, output: 6.08 toks/s]
Processed prompts:  45%|     | 230/512 [00:37<00:47,  5.96it/s, est. speed input: 6217.92 toks/s, output: 6.07 toks/s]
Processed prompts:  46%|     | 234/512 [00:38<00:46,  5.96it/s, est. speed input: 6215.93 toks/s, output: 6.07 toks/s]
Processed prompts:  46%|     | 238/512 [00:39<00:45,  5.96it/s, est. speed input: 6214.22 toks/s, output: 6.07 toks/s]
Processed prompts:  47%|     | 242/512 [00:39<00:45,  5.95it/s, est. speed input: 6211.86 toks/s, output: 6.07 toks/s]
Processed prompts:  48%|     | 246/512 [00:40<00:44,  5.97it/s, est. speed input: 6210.58 toks/s, output: 6.07 toks/s]
Processed prompts:  49%|     | 250/512 [00:41<00:44,  5.95it/s, est. speed input: 6208.26 toks/s, output: 6.06 toks/s]
Processed prompts:  50%|     | 254/512 [00:41<00:43,  5.93it/s, est. speed input: 6205.29 toks/s, output: 6.06 toks/s]
Processed prompts:  50%|     | 258/512 [00:42<00:42,  5.93it/s, est. speed input: 6203.34 toks/s, output: 6.06 toks/s]
Processed prompts:  51%|     | 262/512 [00:43<00:42,  5.93it/s, est. speed input: 6201.27 toks/s, output: 6.06 toks/s]
Processed prompts:  52%|    | 266/512 [00:43<00:41,  5.94it/s, est. speed input: 6199.52 toks/s, output: 6.05 toks/s]
Processed prompts:  53%|    | 270/512 [00:44<00:40,  5.95it/s, est. speed input: 6198.67 toks/s, output: 6.05 toks/s]
Processed prompts:  54%|    | 274/512 [00:45<00:40,  5.94it/s, est. speed input: 6196.60 toks/s, output: 6.05 toks/s]
Processed prompts:  54%|    | 278/512 [00:45<00:39,  5.94it/s, est. speed input: 6194.72 toks/s, output: 6.05 toks/s]
Processed prompts:  55%|    | 282/512 [00:46<00:38,  5.95it/s, est. speed input: 6193.57 toks/s, output: 6.05 toks/s]
Processed prompts:  56%|    | 286/512 [00:47<00:37,  5.95it/s, est. speed input: 6192.13 toks/s, output: 6.05 toks/s]
Processed prompts:  57%|    | 290/512 [00:47<00:37,  5.95it/s, est. speed input: 6190.96 toks/s, output: 6.05 toks/s]
Processed prompts:  57%|    | 294/512 [00:48<00:36,  5.94it/s, est. speed input: 6189.12 toks/s, output: 6.04 toks/s]
Processed prompts:  58%|    | 298/512 [00:49<00:36,  5.92it/s, est. speed input: 6186.87 toks/s, output: 6.04 toks/s]
Processed prompts:  59%|    | 302/512 [00:49<00:35,  5.94it/s, est. speed input: 6185.87 toks/s, output: 6.04 toks/s]
Processed prompts:  60%|    | 306/512 [00:50<00:32,  6.32it/s, est. speed input: 6201.18 toks/s, output: 6.06 toks/s]
Processed prompts:  61%|    | 310/512 [00:51<00:32,  6.22it/s, est. speed input: 6200.19 toks/s, output: 6.05 toks/s]
Processed prompts:  61%|   | 314/512 [00:51<00:32,  6.13it/s, est. speed input: 6198.75 toks/s, output: 6.05 toks/s]
Processed prompts:  62%|   | 318/512 [00:52<00:32,  6.05it/s, est. speed input: 6196.38 toks/s, output: 6.05 toks/s]
Processed prompts:  63%|   | 322/512 [00:53<00:31,  6.04it/s, est. speed input: 6195.64 toks/s, output: 6.05 toks/s]
Processed prompts:  64%|   | 326/512 [00:53<00:31,  6.00it/s, est. speed input: 6193.92 toks/s, output: 6.05 toks/s]
Processed prompts:  64%|   | 330/512 [00:54<00:30,  5.98it/s, est. speed input: 6192.30 toks/s, output: 6.05 toks/s]
Processed prompts:  65%|   | 334/512 [00:55<00:29,  5.97it/s, est. speed input: 6191.02 toks/s, output: 6.05 toks/s]
Processed prompts:  66%|   | 338/512 [00:55<00:29,  5.96it/s, est. speed input: 6189.74 toks/s, output: 6.04 toks/s]
Processed prompts:  67%|   | 342/512 [00:56<00:28,  5.94it/s, est. speed input: 6187.80 toks/s, output: 6.04 toks/s]
Processed prompts:  68%|   | 346/512 [00:57<00:27,  5.94it/s, est. speed input: 6186.72 toks/s, output: 6.04 toks/s]
Processed prompts:  68%|   | 350/512 [00:57<00:27,  5.93it/s, est. speed input: 6184.91 toks/s, output: 6.04 toks/s]
Processed prompts:  69%|   | 354/512 [00:58<00:26,  5.92it/s, est. speed input: 6183.28 toks/s, output: 6.04 toks/s]
Processed prompts:  70%|   | 358/512 [00:59<00:26,  5.92it/s, est. speed input: 6182.00 toks/s, output: 6.04 toks/s]
Processed prompts:  71%|   | 362/512 [00:59<00:25,  5.94it/s, est. speed input: 6181.24 toks/s, output: 6.04 toks/s]
Processed prompts:  71%|  | 366/512 [01:00<00:24,  5.92it/s, est. speed input: 6179.63 toks/s, output: 6.03 toks/s]
Processed prompts:  72%|  | 370/512 [01:01<00:23,  5.92it/s, est. speed input: 6178.11 toks/s, output: 6.03 toks/s]
Processed prompts:  73%|  | 374/512 [01:02<00:23,  5.91it/s, est. speed input: 6176.51 toks/s, output: 6.03 toks/s]
Processed prompts:  74%|  | 378/512 [01:02<00:22,  5.92it/s, est. speed input: 6175.69 toks/s, output: 6.03 toks/s]
Processed prompts:  75%|  | 382/512 [01:03<00:21,  5.91it/s, est. speed input: 6174.10 toks/s, output: 6.03 toks/s]
Processed prompts:  75%|  | 386/512 [01:04<00:21,  5.91it/s, est. speed input: 6172.78 toks/s, output: 6.03 toks/s]
Processed prompts:  76%|  | 390/512 [01:04<00:20,  5.95it/s, est. speed input: 6172.84 toks/s, output: 6.03 toks/s]
Processed prompts:  77%|  | 394/512 [01:05<00:19,  5.93it/s, est. speed input: 6171.51 toks/s, output: 6.03 toks/s]
Processed prompts:  78%|  | 398/512 [01:06<00:19,  5.93it/s, est. speed input: 6170.31 toks/s, output: 6.03 toks/s]
Processed prompts:  79%|  | 402/512 [01:06<00:18,  5.95it/s, est. speed input: 6169.97 toks/s, output: 6.03 toks/s]
Processed prompts:  79%|  | 406/512 [01:07<00:17,  5.93it/s, est. speed input: 6168.64 toks/s, output: 6.02 toks/s]
Processed prompts:  80%|  | 410/512 [01:08<00:17,  5.95it/s, est. speed input: 6168.39 toks/s, output: 6.02 toks/s]
Processed prompts:  81%|  | 414/512 [01:08<00:16,  5.93it/s, est. speed input: 6167.05 toks/s, output: 6.02 toks/s]
Processed prompts:  82%| | 418/512 [01:09<00:15,  5.92it/s, est. speed input: 6165.78 toks/s, output: 6.02 toks/s]
Processed prompts:  82%| | 422/512 [01:10<00:15,  5.93it/s, est. speed input: 6165.01 toks/s, output: 6.02 toks/s]
Processed prompts:  83%| | 426/512 [01:10<00:14,  5.90it/s, est. speed input: 6163.24 toks/s, output: 6.02 toks/s]
Processed prompts:  84%| | 430/512 [01:11<00:13,  5.90it/s, est. speed input: 6162.07 toks/s, output: 6.02 toks/s]
Processed prompts:  85%| | 434/512 [01:11<00:12,  6.31it/s, est. speed input: 6173.53 toks/s, output: 6.03 toks/s]
Processed prompts:  86%| | 438/512 [01:12<00:11,  6.18it/s, est. speed input: 6172.37 toks/s, output: 6.03 toks/s]
Processed prompts:  86%| | 442/512 [01:13<00:11,  6.13it/s, est. speed input: 6172.03 toks/s, output: 6.03 toks/s]
Processed prompts:  87%| | 446/512 [01:14<00:10,  6.05it/s, est. speed input: 6170.63 toks/s, output: 6.03 toks/s]
Processed prompts:  88%| | 450/512 [01:14<00:10,  6.01it/s, est. speed input: 6169.80 toks/s, output: 6.03 toks/s]
Processed prompts:  89%| | 454/512 [01:15<00:09,  6.01it/s, est. speed input: 6169.52 toks/s, output: 6.02 toks/s]
Processed prompts:  89%| | 458/512 [01:16<00:09,  5.97it/s, est. speed input: 6168.27 toks/s, output: 6.02 toks/s]
Processed prompts:  90%| | 462/512 [01:16<00:08,  5.96it/s, est. speed input: 6167.36 toks/s, output: 6.02 toks/s]
Processed prompts:  91%| | 466/512 [01:17<00:07,  5.96it/s, est. speed input: 6166.75 toks/s, output: 6.02 toks/s]
Processed prompts:  92%|| 470/512 [01:18<00:07,  5.94it/s, est. speed input: 6165.74 toks/s, output: 6.02 toks/s]
Processed prompts:  93%|| 474/512 [01:18<00:06,  5.92it/s, est. speed input: 6164.36 toks/s, output: 6.02 toks/s]
Processed prompts:  93%|| 478/512 [01:19<00:05,  5.94it/s, est. speed input: 6163.99 toks/s, output: 6.02 toks/s]
Processed prompts:  94%|| 482/512 [01:20<00:05,  5.93it/s, est. speed input: 6163.12 toks/s, output: 6.02 toks/s]
Processed prompts:  95%|| 486/512 [01:20<00:04,  5.92it/s, est. speed input: 6162.19 toks/s, output: 6.02 toks/s]
Processed prompts:  96%|| 490/512 [01:21<00:03,  5.92it/s, est. speed input: 6161.25 toks/s, output: 6.02 toks/s]
Processed prompts:  96%|| 494/512 [01:22<00:03,  5.91it/s, est. speed input: 6160.11 toks/s, output: 6.02 toks/s]
Processed prompts:  97%|| 498/512 [01:22<00:02,  5.93it/s, est. speed input: 6159.71 toks/s, output: 6.02 toks/s]
Processed prompts:  98%|| 502/512 [01:23<00:01,  5.91it/s, est. speed input: 6158.66 toks/s, output: 6.01 toks/s]
Processed prompts:  99%|| 506/512 [01:24<00:01,  5.91it/s, est. speed input: 6157.80 toks/s, output: 6.01 toks/s]
Processed prompts: 100%|| 510/512 [01:24<00:00,  6.38it/s, est. speed input: 6168.90 toks/s, output: 6.02 toks/s]
Processed prompts: 100%|| 512/512 [01:24<00:00,  6.38it/s, est. speed input: 6193.08 toks/s, output: 6.05 toks/s]
Processed prompts: 100%|| 512/512 [01:24<00:00,  6.05it/s, est. speed input: 6193.08 toks/s, output: 6.05 toks/s]
[rank0]:[W126 16:01:22.051937777 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 16:01:25
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 16:01:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 16:01:34 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1473191) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1473191) WARNING 01-26 16:02:52 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.65 requests/s, 5790.86 total tokens/s, 5.65 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 16:01:34] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:01:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:01:34] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:01:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:01:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:01:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:01:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:01:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:01:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:01:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:01:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:01:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:01:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:01:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 16:01:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:01:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:01:37] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:01:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:01:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:01:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:01:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:01:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:01:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:01:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:01:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:01:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:01:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:01:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1473191) [2026-01-26 16:01:38] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1473191) [2026-01-26 16:01:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1473191) [2026-01-26 16:01:38] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1473191) [2026-01-26 16:01:38] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1473191) [2026-01-26 16:01:38] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1473191) [2026-01-26 16:01:38] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1473191) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1473191) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.37s/it]
(EngineCore_DP0 pid=1473191) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:01<00:00, 31.45s/it]
(EngineCore_DP0 pid=1473191) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:01<00:00, 30.99s/it]
(EngineCore_DP0 pid=1473191) 
(EngineCore_DP0 pid=1473191) [2026-01-26 16:02:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1473191) [2026-01-26 16:02:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=1473191) [2026-01-26 16:02:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1473191) [2026-01-26 16:02:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=1473191) [2026-01-26 16:02:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1473191) [2026-01-26 16:02:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=1473191) [2026-01-26 16:02:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1473191) [2026-01-26 16:02:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=1473191) 2026-01-26 16:02:50,002 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1473191) 2026-01-26 16:02:50,309 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|         | 26/1024 [00:00<00:03, 257.91it/s]
Adding requests:   6%|         | 66/1024 [00:00<00:02, 339.82it/s]
Adding requests:  10%|         | 106/1024 [00:00<00:02, 364.45it/s]
Adding requests:  14%|        | 145/1024 [00:00<00:02, 374.23it/s]
Adding requests:  18%|        | 188/1024 [00:00<00:02, 393.63it/s]
Adding requests:  23%|       | 232/1024 [00:00<00:01, 406.86it/s]
Adding requests:  27%|       | 273/1024 [00:00<00:01, 405.67it/s]
Adding requests:  31%|       | 318/1024 [00:00<00:01, 418.49it/s]
Adding requests:  35%|      | 362/1024 [00:00<00:01, 423.29it/s]
Adding requests:  40%|      | 405/1024 [00:01<00:01, 422.88it/s]
Adding requests:  44%|     | 448/1024 [00:01<00:01, 421.60it/s]
Adding requests:  48%|     | 495/1024 [00:01<00:01, 435.92it/s]
Adding requests:  53%|    | 539/1024 [00:01<00:01, 432.90it/s]
Adding requests:  57%|    | 583/1024 [00:01<00:01, 427.17it/s]
Adding requests:  61%|    | 626/1024 [00:01<00:00, 422.69it/s]
Adding requests:  65%|   | 669/1024 [00:01<00:00, 422.12it/s]
Adding requests:  70%|   | 714/1024 [00:01<00:00, 430.10it/s]
Adding requests:  74%|  | 758/1024 [00:01<00:00, 423.48it/s]
Adding requests:  78%|  | 801/1024 [00:01<00:00, 422.77it/s]
Adding requests:  82%| | 844/1024 [00:02<00:00, 422.27it/s]
Adding requests:  87%| | 889/1024 [00:02<00:00, 429.40it/s]
Adding requests:  91%| | 932/1024 [00:02<00:00, 425.06it/s]
Adding requests:  95%|| 977/1024 [00:02<00:00, 431.50it/s]
Adding requests: 100%|| 1021/1024 [00:02<00:00, 430.08it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 416.53it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 10/1024 [00:00<01:01, 16.40it/s, est. speed input: 16796.97 toks/s, output: 16.40 toks/s]
Processed prompts:   2%|         | 18/1024 [00:02<02:02,  8.19it/s, est. speed input: 9152.06 toks/s, output: 8.94 toks/s]  
Processed prompts:   3%|         | 26/1024 [00:03<02:25,  6.87it/s, est. speed input: 7776.34 toks/s, output: 7.59 toks/s]
Processed prompts:   3%|         | 34/1024 [00:04<02:35,  6.35it/s, est. speed input: 7192.91 toks/s, output: 7.02 toks/s]
Processed prompts:   4%|         | 42/1024 [00:06<02:41,  6.09it/s, est. speed input: 6879.21 toks/s, output: 6.72 toks/s]
Processed prompts:   5%|         | 50/1024 [00:07<02:43,  5.95it/s, est. speed input: 6686.12 toks/s, output: 6.53 toks/s]
Processed prompts:   6%|         | 58/1024 [00:09<02:45,  5.85it/s, est. speed input: 6545.08 toks/s, output: 6.39 toks/s]
Processed prompts:   6%|         | 66/1024 [00:10<02:45,  5.79it/s, est. speed input: 6447.35 toks/s, output: 6.30 toks/s]
Processed prompts:   7%|         | 74/1024 [00:11<02:45,  5.75it/s, est. speed input: 6368.64 toks/s, output: 6.22 toks/s]
Processed prompts:   8%|         | 82/1024 [00:13<02:44,  5.71it/s, est. speed input: 6305.07 toks/s, output: 6.16 toks/s]
Processed prompts:   9%|         | 90/1024 [00:14<02:44,  5.69it/s, est. speed input: 6254.69 toks/s, output: 6.11 toks/s]
Processed prompts:  10%|         | 98/1024 [00:16<02:42,  5.69it/s, est. speed input: 6215.56 toks/s, output: 6.07 toks/s]
Processed prompts:  10%|         | 106/1024 [00:17<02:42,  5.66it/s, est. speed input: 6175.84 toks/s, output: 6.03 toks/s]
Processed prompts:  11%|         | 114/1024 [00:18<02:40,  5.66it/s, est. speed input: 6148.68 toks/s, output: 6.00 toks/s]
Processed prompts:  12%|        | 122/1024 [00:20<02:39,  5.65it/s, est. speed input: 6121.77 toks/s, output: 5.98 toks/s]
Processed prompts:  13%|        | 130/1024 [00:21<02:38,  5.65it/s, est. speed input: 6098.72 toks/s, output: 5.96 toks/s]
Processed prompts:  13%|        | 138/1024 [00:23<02:36,  5.66it/s, est. speed input: 6081.87 toks/s, output: 5.94 toks/s]
Processed prompts:  14%|        | 146/1024 [00:24<02:35,  5.66it/s, est. speed input: 6064.83 toks/s, output: 5.92 toks/s]
Processed prompts:  15%|        | 154/1024 [00:26<02:33,  5.66it/s, est. speed input: 6051.34 toks/s, output: 5.91 toks/s]
Processed prompts:  16%|        | 162/1024 [00:27<02:32,  5.66it/s, est. speed input: 6038.17 toks/s, output: 5.90 toks/s]
Processed prompts:  17%|        | 170/1024 [00:28<02:30,  5.66it/s, est. speed input: 6026.25 toks/s, output: 5.89 toks/s]
Processed prompts:  17%|        | 178/1024 [00:30<02:29,  5.66it/s, est. speed input: 6014.87 toks/s, output: 5.87 toks/s]
Processed prompts:  18%|        | 186/1024 [00:31<02:28,  5.66it/s, est. speed input: 6005.07 toks/s, output: 5.86 toks/s]
Processed prompts:  19%|        | 194/1024 [00:33<02:26,  5.65it/s, est. speed input: 5994.99 toks/s, output: 5.85 toks/s]
Processed prompts:  20%|        | 202/1024 [00:34<02:21,  5.82it/s, est. speed input: 6010.88 toks/s, output: 5.87 toks/s]
Processed prompts:  21%|        | 210/1024 [00:35<02:21,  5.77it/s, est. speed input: 6001.81 toks/s, output: 5.86 toks/s]
Processed prompts:  21%|       | 218/1024 [00:37<02:20,  5.73it/s, est. speed input: 5992.96 toks/s, output: 5.85 toks/s]
Processed prompts:  22%|       | 226/1024 [00:38<02:19,  5.70it/s, est. speed input: 5985.23 toks/s, output: 5.84 toks/s]
Processed prompts:  23%|       | 234/1024 [00:40<02:19,  5.68it/s, est. speed input: 5977.03 toks/s, output: 5.84 toks/s]
Processed prompts:  24%|       | 242/1024 [00:41<02:18,  5.65it/s, est. speed input: 5968.31 toks/s, output: 5.83 toks/s]
Processed prompts:  24%|       | 250/1024 [00:42<02:17,  5.64it/s, est. speed input: 5960.85 toks/s, output: 5.82 toks/s]
Processed prompts:  25%|       | 258/1024 [00:44<02:15,  5.64it/s, est. speed input: 5955.31 toks/s, output: 5.82 toks/s]
Processed prompts:  26%|       | 266/1024 [00:45<02:14,  5.63it/s, est. speed input: 5948.45 toks/s, output: 5.81 toks/s]
Processed prompts:  27%|       | 274/1024 [00:47<02:13,  5.63it/s, est. speed input: 5942.85 toks/s, output: 5.80 toks/s]
Processed prompts:  28%|       | 282/1024 [00:48<02:11,  5.64it/s, est. speed input: 5938.55 toks/s, output: 5.80 toks/s]
Processed prompts:  28%|       | 290/1024 [00:50<02:10,  5.64it/s, est. speed input: 5933.77 toks/s, output: 5.79 toks/s]
Processed prompts:  29%|       | 298/1024 [00:51<02:09,  5.63it/s, est. speed input: 5928.35 toks/s, output: 5.79 toks/s]
Processed prompts:  30%|       | 306/1024 [00:52<02:03,  5.82it/s, est. speed input: 5941.81 toks/s, output: 5.80 toks/s]
Processed prompts:  31%|       | 314/1024 [00:54<02:02,  5.77it/s, est. speed input: 5938.09 toks/s, output: 5.80 toks/s]
Processed prompts:  31%|      | 322/1024 [00:55<02:02,  5.73it/s, est. speed input: 5933.69 toks/s, output: 5.79 toks/s]
Processed prompts:  32%|      | 330/1024 [00:56<02:01,  5.71it/s, est. speed input: 5929.92 toks/s, output: 5.79 toks/s]
Processed prompts:  33%|      | 338/1024 [00:58<02:00,  5.69it/s, est. speed input: 5926.34 toks/s, output: 5.79 toks/s]
Processed prompts:  34%|      | 346/1024 [00:59<01:59,  5.66it/s, est. speed input: 5921.88 toks/s, output: 5.78 toks/s]
Processed prompts:  35%|      | 354/1024 [01:01<01:58,  5.65it/s, est. speed input: 5917.95 toks/s, output: 5.78 toks/s]
Processed prompts:  35%|      | 362/1024 [01:02<01:57,  5.65it/s, est. speed input: 5914.65 toks/s, output: 5.78 toks/s]
Processed prompts:  36%|      | 370/1024 [01:04<01:56,  5.63it/s, est. speed input: 5910.67 toks/s, output: 5.77 toks/s]
Processed prompts:  37%|      | 378/1024 [01:05<01:54,  5.63it/s, est. speed input: 5907.15 toks/s, output: 5.77 toks/s]
Processed prompts:  38%|      | 386/1024 [01:06<01:53,  5.63it/s, est. speed input: 5904.22 toks/s, output: 5.77 toks/s]
Processed prompts:  38%|      | 394/1024 [01:08<01:52,  5.62it/s, est. speed input: 5900.90 toks/s, output: 5.76 toks/s]
Processed prompts:  39%|      | 402/1024 [01:09<01:50,  5.63it/s, est. speed input: 5898.35 toks/s, output: 5.76 toks/s]
Processed prompts:  40%|      | 410/1024 [01:11<01:49,  5.62it/s, est. speed input: 5894.90 toks/s, output: 5.76 toks/s]
Processed prompts:  41%|      | 418/1024 [01:12<01:47,  5.62it/s, est. speed input: 5892.06 toks/s, output: 5.75 toks/s]
Processed prompts:  42%|     | 426/1024 [01:14<01:46,  5.62it/s, est. speed input: 5889.59 toks/s, output: 5.75 toks/s]
Processed prompts:  42%|     | 434/1024 [01:15<01:41,  5.80it/s, est. speed input: 5898.77 toks/s, output: 5.76 toks/s]
Processed prompts:  43%|     | 442/1024 [01:16<01:41,  5.74it/s, est. speed input: 5895.81 toks/s, output: 5.76 toks/s]
Processed prompts:  44%|     | 450/1024 [01:18<01:40,  5.70it/s, est. speed input: 5893.10 toks/s, output: 5.75 toks/s]
Processed prompts:  45%|     | 458/1024 [01:19<01:39,  5.69it/s, est. speed input: 5891.50 toks/s, output: 5.75 toks/s]
Processed prompts:  46%|     | 466/1024 [01:21<01:38,  5.67it/s, est. speed input: 5889.34 toks/s, output: 5.75 toks/s]
Processed prompts:  46%|     | 474/1024 [01:22<01:37,  5.67it/s, est. speed input: 5887.71 toks/s, output: 5.75 toks/s]
Processed prompts:  47%|     | 482/1024 [01:23<01:35,  5.66it/s, est. speed input: 5885.78 toks/s, output: 5.75 toks/s]
Processed prompts:  48%|     | 490/1024 [01:25<01:34,  5.64it/s, est. speed input: 5883.41 toks/s, output: 5.75 toks/s]
Processed prompts:  49%|     | 498/1024 [01:26<01:33,  5.64it/s, est. speed input: 5881.31 toks/s, output: 5.74 toks/s]
Processed prompts:  49%|     | 506/1024 [01:28<01:31,  5.65it/s, est. speed input: 5880.00 toks/s, output: 5.74 toks/s]
Processed prompts:  50%|     | 514/1024 [01:29<01:30,  5.64it/s, est. speed input: 5878.38 toks/s, output: 5.74 toks/s]
Processed prompts:  51%|     | 522/1024 [01:30<01:29,  5.63it/s, est. speed input: 5876.13 toks/s, output: 5.74 toks/s]
Processed prompts:  52%|    | 530/1024 [01:32<01:27,  5.62it/s, est. speed input: 5873.93 toks/s, output: 5.74 toks/s]
Processed prompts:  53%|    | 538/1024 [01:33<01:26,  5.62it/s, est. speed input: 5871.98 toks/s, output: 5.73 toks/s]
Processed prompts:  53%|    | 546/1024 [01:35<01:25,  5.62it/s, est. speed input: 5870.28 toks/s, output: 5.73 toks/s]
Processed prompts:  54%|    | 554/1024 [01:36<01:23,  5.64it/s, est. speed input: 5869.42 toks/s, output: 5.73 toks/s]
Processed prompts:  55%|    | 562/1024 [01:38<01:22,  5.63it/s, est. speed input: 5867.46 toks/s, output: 5.73 toks/s]
Processed prompts:  56%|    | 570/1024 [01:39<01:20,  5.63it/s, est. speed input: 5866.16 toks/s, output: 5.73 toks/s]
Processed prompts:  56%|    | 578/1024 [01:40<01:19,  5.63it/s, est. speed input: 5864.78 toks/s, output: 5.73 toks/s]
Processed prompts:  57%|    | 586/1024 [01:42<01:17,  5.63it/s, est. speed input: 5863.24 toks/s, output: 5.73 toks/s]
Processed prompts:  58%|    | 594/1024 [01:43<01:16,  5.62it/s, est. speed input: 5861.60 toks/s, output: 5.72 toks/s]
Processed prompts:  59%|    | 602/1024 [01:45<01:14,  5.63it/s, est. speed input: 5860.50 toks/s, output: 5.72 toks/s]
Processed prompts:  60%|    | 610/1024 [01:46<01:13,  5.62it/s, est. speed input: 5858.77 toks/s, output: 5.72 toks/s]
Processed prompts:  60%|    | 618/1024 [01:48<01:12,  5.61it/s, est. speed input: 5856.94 toks/s, output: 5.72 toks/s]
Processed prompts:  61%|    | 626/1024 [01:49<01:10,  5.62it/s, est. speed input: 5855.90 toks/s, output: 5.72 toks/s]
Processed prompts:  62%|   | 634/1024 [01:50<01:09,  5.61it/s, est. speed input: 5854.24 toks/s, output: 5.72 toks/s]
Processed prompts:  63%|   | 642/1024 [01:52<01:08,  5.61it/s, est. speed input: 5852.92 toks/s, output: 5.72 toks/s]
Processed prompts:  63%|   | 650/1024 [01:53<01:06,  5.62it/s, est. speed input: 5852.06 toks/s, output: 5.71 toks/s]
Processed prompts:  64%|   | 658/1024 [01:55<01:04,  5.63it/s, est. speed input: 5851.29 toks/s, output: 5.71 toks/s]
Processed prompts:  65%|   | 666/1024 [01:56<01:03,  5.63it/s, est. speed input: 5850.36 toks/s, output: 5.71 toks/s]
Processed prompts:  66%|   | 674/1024 [01:57<01:02,  5.63it/s, est. speed input: 5849.35 toks/s, output: 5.71 toks/s]
Processed prompts:  67%|   | 682/1024 [01:59<01:00,  5.64it/s, est. speed input: 5848.56 toks/s, output: 5.71 toks/s]
Processed prompts:  67%|   | 690/1024 [02:00<00:59,  5.64it/s, est. speed input: 5847.80 toks/s, output: 5.71 toks/s]
Processed prompts:  68%|   | 698/1024 [02:02<00:57,  5.65it/s, est. speed input: 5847.14 toks/s, output: 5.71 toks/s]
Processed prompts:  69%|   | 706/1024 [02:03<00:56,  5.64it/s, est. speed input: 5846.18 toks/s, output: 5.71 toks/s]
Processed prompts:  70%|   | 714/1024 [02:05<00:55,  5.64it/s, est. speed input: 5845.23 toks/s, output: 5.71 toks/s]
Processed prompts:  71%|   | 722/1024 [02:06<00:53,  5.62it/s, est. speed input: 5843.92 toks/s, output: 5.71 toks/s]
Processed prompts:  71%|  | 730/1024 [02:07<00:52,  5.62it/s, est. speed input: 5842.76 toks/s, output: 5.71 toks/s]
Processed prompts:  72%|  | 738/1024 [02:09<00:50,  5.63it/s, est. speed input: 5842.34 toks/s, output: 5.71 toks/s]
Processed prompts:  73%|  | 746/1024 [02:10<00:49,  5.63it/s, est. speed input: 5841.31 toks/s, output: 5.70 toks/s]
Processed prompts:  74%|  | 754/1024 [02:12<00:47,  5.63it/s, est. speed input: 5840.55 toks/s, output: 5.70 toks/s]
Processed prompts:  74%|  | 762/1024 [02:13<00:46,  5.63it/s, est. speed input: 5839.79 toks/s, output: 5.70 toks/s]
Processed prompts:  75%|  | 770/1024 [02:15<00:45,  5.62it/s, est. speed input: 5838.71 toks/s, output: 5.70 toks/s]
Processed prompts:  76%|  | 778/1024 [02:16<00:43,  5.64it/s, est. speed input: 5838.36 toks/s, output: 5.70 toks/s]
Processed prompts:  77%|  | 786/1024 [02:17<00:40,  5.82it/s, est. speed input: 5844.06 toks/s, output: 5.71 toks/s]
Processed prompts:  78%|  | 794/1024 [02:19<00:39,  5.77it/s, est. speed input: 5843.40 toks/s, output: 5.71 toks/s]
Processed prompts:  78%|  | 802/1024 [02:20<00:38,  5.71it/s, est. speed input: 5842.22 toks/s, output: 5.71 toks/s]
Processed prompts:  79%|  | 810/1024 [02:21<00:37,  5.69it/s, est. speed input: 5841.60 toks/s, output: 5.70 toks/s]
Processed prompts:  80%|  | 818/1024 [02:23<00:36,  5.67it/s, est. speed input: 5840.68 toks/s, output: 5.70 toks/s]
Processed prompts:  81%|  | 826/1024 [02:24<00:35,  5.65it/s, est. speed input: 5839.66 toks/s, output: 5.70 toks/s]
Processed prompts:  81%| | 834/1024 [02:26<00:33,  5.64it/s, est. speed input: 5838.76 toks/s, output: 5.70 toks/s]
Processed prompts:  82%| | 842/1024 [02:27<00:32,  5.63it/s, est. speed input: 5838.01 toks/s, output: 5.70 toks/s]
Processed prompts:  83%| | 850/1024 [02:29<00:30,  5.63it/s, est. speed input: 5837.14 toks/s, output: 5.70 toks/s]
Processed prompts:  84%| | 858/1024 [02:30<00:29,  5.62it/s, est. speed input: 5836.14 toks/s, output: 5.70 toks/s]
Processed prompts:  85%| | 866/1024 [02:31<00:28,  5.62it/s, est. speed input: 5835.57 toks/s, output: 5.70 toks/s]
Processed prompts:  85%| | 874/1024 [02:33<00:26,  5.63it/s, est. speed input: 5834.96 toks/s, output: 5.70 toks/s]
Processed prompts:  86%| | 882/1024 [02:34<00:25,  5.62it/s, est. speed input: 5834.19 toks/s, output: 5.70 toks/s]
Processed prompts:  87%| | 890/1024 [02:36<00:23,  5.63it/s, est. speed input: 5833.77 toks/s, output: 5.70 toks/s]
Processed prompts:  88%| | 898/1024 [02:37<00:22,  5.62it/s, est. speed input: 5832.80 toks/s, output: 5.70 toks/s]
Processed prompts:  88%| | 906/1024 [02:39<00:20,  5.63it/s, est. speed input: 5832.29 toks/s, output: 5.70 toks/s]
Processed prompts:  89%| | 914/1024 [02:40<00:19,  5.63it/s, est. speed input: 5831.77 toks/s, output: 5.70 toks/s]
Processed prompts:  90%| | 922/1024 [02:41<00:18,  5.63it/s, est. speed input: 5831.14 toks/s, output: 5.69 toks/s]
Processed prompts:  91%| | 930/1024 [02:43<00:16,  5.62it/s, est. speed input: 5830.33 toks/s, output: 5.69 toks/s]
Processed prompts:  92%|| 938/1024 [02:44<00:15,  5.62it/s, est. speed input: 5829.61 toks/s, output: 5.69 toks/s]
Processed prompts:  92%|| 946/1024 [02:46<00:13,  5.61it/s, est. speed input: 5828.85 toks/s, output: 5.69 toks/s]
Processed prompts:  93%|| 954/1024 [02:47<00:12,  5.64it/s, est. speed input: 5828.96 toks/s, output: 5.69 toks/s]
Processed prompts:  94%|| 962/1024 [02:49<00:11,  5.62it/s, est. speed input: 5828.04 toks/s, output: 5.69 toks/s]
Processed prompts:  95%|| 970/1024 [02:50<00:09,  5.63it/s, est. speed input: 5827.49 toks/s, output: 5.69 toks/s]
Processed prompts:  96%|| 978/1024 [02:51<00:08,  5.63it/s, est. speed input: 5827.19 toks/s, output: 5.69 toks/s]
Processed prompts:  96%|| 986/1024 [02:53<00:06,  5.63it/s, est. speed input: 5826.65 toks/s, output: 5.69 toks/s]
Processed prompts:  97%|| 994/1024 [02:54<00:05,  5.63it/s, est. speed input: 5825.98 toks/s, output: 5.69 toks/s]
Processed prompts:  98%|| 1002/1024 [02:56<00:03,  5.62it/s, est. speed input: 5825.24 toks/s, output: 5.69 toks/s]
Processed prompts:  99%|| 1010/1024 [02:57<00:02,  5.62it/s, est. speed input: 5824.85 toks/s, output: 5.69 toks/s]
Processed prompts:  99%|| 1018/1024 [02:58<00:01,  5.86it/s, est. speed input: 5830.45 toks/s, output: 5.69 toks/s]
Processed prompts: 100%|| 1024/1024 [02:58<00:00,  5.86it/s, est. speed input: 5864.81 toks/s, output: 5.73 toks/s]
Processed prompts: 100%|| 1024/1024 [02:58<00:00,  5.73it/s, est. speed input: 5864.81 toks/s, output: 5.73 toks/s]
[rank0]:[W126 16:05:53.872791678 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 16:05:56
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 16:06:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 16:06:06 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1477149) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1477149) WARNING 01-26 16:07:29 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 6.00 requests/s, 6145.03 total tokens/s, 6.00 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 16:06:06] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:06:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:06:06] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:06:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:06:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:06:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:06:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:06:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:06:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:06:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:06:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:06:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:06:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:06:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 16:06:10] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:06:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:06:10] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:06:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:06:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:06:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:06:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:06:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:06:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:06:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:06:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:06:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:06:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:06:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1477149) [2026-01-26 16:06:11] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1477149) [2026-01-26 16:06:11] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1477149) [2026-01-26 16:06:11] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1477149) [2026-01-26 16:06:11] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1477149) [2026-01-26 16:06:11] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1477149) [2026-01-26 16:06:11] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1477149) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1477149) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.50s/it]
(EngineCore_DP0 pid=1477149) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:02<00:00, 31.69s/it]
(EngineCore_DP0 pid=1477149) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:02<00:00, 31.21s/it]
(EngineCore_DP0 pid=1477149) 
(EngineCore_DP0 pid=1477149) [2026-01-26 16:07:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1477149) [2026-01-26 16:07:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=1477149) [2026-01-26 16:07:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1477149) [2026-01-26 16:07:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=1477149) [2026-01-26 16:07:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1477149) [2026-01-26 16:07:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=1477149) [2026-01-26 16:07:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1477149) [2026-01-26 16:07:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=1477149) 2026-01-26 16:07:24,100 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1477149) 2026-01-26 16:07:24,657 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|         | 33/2048 [00:00<00:06, 323.73it/s]
Adding requests:   3%|         | 69/2048 [00:00<00:05, 343.77it/s]
Adding requests:   5%|         | 111/2048 [00:00<00:05, 375.92it/s]
Adding requests:   7%|         | 152/2048 [00:00<00:04, 388.75it/s]
Adding requests:  10%|         | 198/2048 [00:00<00:04, 411.33it/s]
Adding requests:  12%|        | 242/2048 [00:00<00:04, 420.80it/s]
Adding requests:  14%|        | 285/2048 [00:00<00:04, 416.44it/s]
Adding requests:  16%|        | 328/2048 [00:00<00:04, 419.92it/s]
Adding requests:  18%|        | 374/2048 [00:00<00:03, 430.25it/s]
Adding requests:  20%|        | 419/2048 [00:01<00:03, 433.76it/s]
Adding requests:  23%|       | 464/2048 [00:01<00:03, 436.74it/s]
Adding requests:  25%|       | 513/2048 [00:01<00:03, 451.08it/s]
Adding requests:  28%|       | 564/2048 [00:01<00:03, 466.44it/s]
Adding requests:  30%|       | 611/2048 [00:01<00:03, 446.97it/s]
Adding requests:  32%|      | 656/2048 [00:01<00:03, 445.35it/s]
Adding requests:  34%|      | 701/2048 [00:01<00:03, 446.22it/s]
Adding requests:  36%|      | 746/2048 [00:01<00:02, 434.47it/s]
Adding requests:  39%|      | 790/2048 [00:01<00:03, 407.98it/s]
Adding requests:  41%|      | 836/2048 [00:01<00:02, 420.50it/s]
Adding requests:  43%|     | 879/2048 [00:02<00:05, 195.28it/s]
Adding requests:  45%|     | 922/2048 [00:02<00:04, 231.82it/s]
Adding requests:  47%|     | 966/2048 [00:02<00:04, 269.95it/s]
Adding requests:  49%|     | 1009/2048 [00:02<00:03, 301.96it/s]
Adding requests:  51%|    | 1052/2048 [00:02<00:03, 330.36it/s]
Adding requests:  53%|    | 1094/2048 [00:02<00:02, 351.48it/s]
Adding requests:  56%|    | 1140/2048 [00:03<00:02, 378.49it/s]
Adding requests:  58%|    | 1184/2048 [00:03<00:02, 392.35it/s]
Adding requests:  60%|    | 1228/2048 [00:03<00:02, 401.93it/s]
Adding requests:  62%|   | 1271/2048 [00:03<00:01, 405.51it/s]
Adding requests:  64%|   | 1314/2048 [00:03<00:01, 412.14it/s]
Adding requests:  66%|   | 1358/2048 [00:03<00:01, 418.10it/s]
Adding requests:  69%|   | 1403/2048 [00:03<00:01, 426.80it/s]
Adding requests:  71%|   | 1448/2048 [00:03<00:01, 431.81it/s]
Adding requests:  73%|  | 1496/2048 [00:03<00:01, 443.95it/s]
Adding requests:  75%|  | 1541/2048 [00:04<00:01, 442.13it/s]
Adding requests:  77%|  | 1586/2048 [00:04<00:01, 436.57it/s]
Adding requests:  80%|  | 1630/2048 [00:04<00:00, 432.32it/s]
Adding requests:  82%| | 1674/2048 [00:04<00:00, 421.52it/s]
Adding requests:  84%| | 1720/2048 [00:04<00:00, 430.13it/s]
Adding requests:  86%| | 1764/2048 [00:04<00:00, 422.77it/s]
Adding requests:  88%| | 1807/2048 [00:04<00:00, 421.39it/s]
Adding requests:  90%| | 1850/2048 [00:04<00:00, 414.76it/s]
Adding requests:  92%|| 1894/2048 [00:04<00:00, 420.79it/s]
Adding requests:  95%|| 1939/2048 [00:04<00:00, 426.69it/s]
Adding requests:  97%|| 1983/2048 [00:05<00:00, 428.36it/s]
Adding requests:  99%|| 2026/2048 [00:05<00:00, 400.41it/s]
Adding requests: 100%|| 2048/2048 [00:05<00:00, 391.17it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 18/2048 [00:00<00:45, 44.92it/s, est. speed input: 45996.15 toks/s, output: 44.92 toks/s]
Processed prompts:   2%|         | 34/2048 [00:03<03:28,  9.68it/s, est. speed input: 11324.15 toks/s, output: 11.06 toks/s]
Processed prompts:   2%|         | 50/2048 [00:05<04:22,  7.60it/s, est. speed input: 8911.31 toks/s, output: 8.70 toks/s]  
Processed prompts:   3%|         | 66/2048 [00:08<04:48,  6.87it/s, est. speed input: 8023.19 toks/s, output: 7.84 toks/s]
Processed prompts:   4%|         | 82/2048 [00:11<05:01,  6.53it/s, est. speed input: 7567.61 toks/s, output: 7.39 toks/s]
Processed prompts:   5%|         | 98/2048 [00:13<05:08,  6.33it/s, est. speed input: 7285.56 toks/s, output: 7.11 toks/s]
Processed prompts:   6%|         | 114/2048 [00:16<05:11,  6.21it/s, est. speed input: 7095.72 toks/s, output: 6.93 toks/s]
Processed prompts:   6%|         | 130/2048 [00:19<05:12,  6.13it/s, est. speed input: 6957.98 toks/s, output: 6.79 toks/s]
Processed prompts:   7%|         | 146/2048 [00:21<05:12,  6.08it/s, est. speed input: 6854.19 toks/s, output: 6.69 toks/s]
Processed prompts:   8%|         | 162/2048 [00:24<05:11,  6.05it/s, est. speed input: 6774.61 toks/s, output: 6.62 toks/s]
Processed prompts:   9%|         | 178/2048 [00:27<05:22,  5.80it/s, est. speed input: 6626.88 toks/s, output: 6.47 toks/s]
Processed prompts:   9%|         | 194/2048 [00:30<05:12,  5.94it/s, est. speed input: 6609.63 toks/s, output: 6.45 toks/s]
Processed prompts:  10%|         | 210/2048 [00:32<05:09,  5.94it/s, est. speed input: 6567.96 toks/s, output: 6.41 toks/s]
Processed prompts:  11%|         | 226/2048 [00:35<05:06,  5.95it/s, est. speed input: 6533.95 toks/s, output: 6.38 toks/s]
Processed prompts:  12%|        | 242/2048 [00:38<05:03,  5.96it/s, est. speed input: 6504.27 toks/s, output: 6.35 toks/s]
Processed prompts:  13%|        | 258/2048 [00:40<05:00,  5.96it/s, est. speed input: 6478.52 toks/s, output: 6.33 toks/s]
Processed prompts:  13%|        | 274/2048 [00:43<04:57,  5.97it/s, est. speed input: 6456.38 toks/s, output: 6.31 toks/s]
Processed prompts:  14%|        | 290/2048 [00:46<04:54,  5.96it/s, est. speed input: 6435.81 toks/s, output: 6.28 toks/s]
Processed prompts:  15%|        | 306/2048 [00:48<04:47,  6.06it/s, est. speed input: 6437.15 toks/s, output: 6.29 toks/s]
Processed prompts:  16%|        | 322/2048 [00:51<04:46,  6.03it/s, est. speed input: 6419.52 toks/s, output: 6.27 toks/s]
Processed prompts:  17%|        | 338/2048 [00:54<04:44,  6.01it/s, est. speed input: 6403.94 toks/s, output: 6.25 toks/s]
Processed prompts:  17%|        | 354/2048 [00:56<04:42,  5.99it/s, est. speed input: 6389.65 toks/s, output: 6.24 toks/s]
Processed prompts:  18%|        | 370/2048 [00:59<04:40,  5.98it/s, est. speed input: 6375.62 toks/s, output: 6.23 toks/s]
Processed prompts:  19%|        | 386/2048 [01:02<04:38,  5.97it/s, est. speed input: 6363.24 toks/s, output: 6.21 toks/s]
Processed prompts:  20%|        | 402/2048 [01:04<04:35,  5.97it/s, est. speed input: 6353.10 toks/s, output: 6.20 toks/s]
Processed prompts:  20%|        | 418/2048 [01:07<04:33,  5.96it/s, est. speed input: 6342.80 toks/s, output: 6.19 toks/s]
Processed prompts:  21%|        | 434/2048 [01:10<04:26,  6.06it/s, est. speed input: 6347.10 toks/s, output: 6.20 toks/s]
Processed prompts:  22%|       | 450/2048 [01:12<04:24,  6.03it/s, est. speed input: 6338.06 toks/s, output: 6.19 toks/s]
Processed prompts:  23%|       | 466/2048 [01:15<04:23,  6.01it/s, est. speed input: 6329.64 toks/s, output: 6.18 toks/s]
Processed prompts:  24%|       | 482/2048 [01:18<04:21,  6.00it/s, est. speed input: 6322.04 toks/s, output: 6.17 toks/s]
Processed prompts:  24%|       | 498/2048 [01:20<04:18,  5.99it/s, est. speed input: 6314.94 toks/s, output: 6.17 toks/s]
Processed prompts:  25%|       | 514/2048 [01:23<04:16,  5.98it/s, est. speed input: 6308.01 toks/s, output: 6.16 toks/s]
Processed prompts:  26%|       | 530/2048 [01:26<04:14,  5.97it/s, est. speed input: 6301.77 toks/s, output: 6.15 toks/s]
Processed prompts:  27%|       | 546/2048 [01:28<04:11,  5.97it/s, est. speed input: 6295.77 toks/s, output: 6.15 toks/s]
Processed prompts:  27%|       | 562/2048 [01:31<04:10,  5.94it/s, est. speed input: 6287.32 toks/s, output: 6.14 toks/s]
Processed prompts:  28%|       | 578/2048 [01:34<04:07,  5.95it/s, est. speed input: 6282.06 toks/s, output: 6.13 toks/s]
Processed prompts:  29%|       | 594/2048 [01:36<04:04,  5.95it/s, est. speed input: 6276.61 toks/s, output: 6.13 toks/s]
Processed prompts:  30%|       | 610/2048 [01:39<04:01,  5.95it/s, est. speed input: 6272.27 toks/s, output: 6.13 toks/s]
Processed prompts:  31%|       | 626/2048 [01:42<03:58,  5.96it/s, est. speed input: 6268.14 toks/s, output: 6.12 toks/s]
Processed prompts:  31%|      | 642/2048 [01:44<03:55,  5.96it/s, est. speed input: 6264.03 toks/s, output: 6.12 toks/s]
Processed prompts:  32%|      | 658/2048 [01:47<03:53,  5.96it/s, est. speed input: 6260.20 toks/s, output: 6.11 toks/s]
Processed prompts:  33%|      | 674/2048 [01:50<03:50,  5.97it/s, est. speed input: 6256.78 toks/s, output: 6.11 toks/s]
Processed prompts:  34%|      | 690/2048 [01:52<03:47,  5.96it/s, est. speed input: 6253.10 toks/s, output: 6.11 toks/s]
Processed prompts:  34%|      | 706/2048 [01:55<03:45,  5.96it/s, est. speed input: 6249.52 toks/s, output: 6.10 toks/s]
Processed prompts:  35%|      | 722/2048 [01:58<03:42,  5.96it/s, est. speed input: 6246.17 toks/s, output: 6.10 toks/s]
Processed prompts:  36%|      | 738/2048 [02:01<03:39,  5.96it/s, est. speed input: 6243.11 toks/s, output: 6.10 toks/s]
Processed prompts:  37%|      | 754/2048 [02:03<03:37,  5.95it/s, est. speed input: 6239.56 toks/s, output: 6.09 toks/s]
Processed prompts:  38%|      | 770/2048 [02:06<03:34,  5.96it/s, est. speed input: 6236.82 toks/s, output: 6.09 toks/s]
Processed prompts:  38%|      | 786/2048 [02:08<03:28,  6.06it/s, est. speed input: 6240.96 toks/s, output: 6.09 toks/s]
Processed prompts:  39%|      | 802/2048 [02:11<03:26,  6.03it/s, est. speed input: 6238.04 toks/s, output: 6.09 toks/s]
Processed prompts:  40%|      | 818/2048 [02:14<03:24,  6.01it/s, est. speed input: 6235.53 toks/s, output: 6.09 toks/s]
Processed prompts:  41%|      | 834/2048 [02:17<03:22,  5.99it/s, est. speed input: 6232.81 toks/s, output: 6.09 toks/s]
Processed prompts:  42%|     | 850/2048 [02:19<03:20,  5.98it/s, est. speed input: 6230.27 toks/s, output: 6.08 toks/s]
Processed prompts:  42%|     | 866/2048 [02:22<03:17,  5.98it/s, est. speed input: 6227.94 toks/s, output: 6.08 toks/s]
Processed prompts:  43%|     | 882/2048 [02:25<03:15,  5.97it/s, est. speed input: 6225.75 toks/s, output: 6.08 toks/s]
Processed prompts:  44%|     | 898/2048 [02:27<03:12,  5.97it/s, est. speed input: 6223.40 toks/s, output: 6.08 toks/s]
Processed prompts:  45%|     | 914/2048 [02:30<03:10,  5.97it/s, est. speed input: 6221.40 toks/s, output: 6.08 toks/s]
Processed prompts:  45%|     | 930/2048 [02:33<03:07,  5.96it/s, est. speed input: 6219.23 toks/s, output: 6.07 toks/s]
Processed prompts:  46%|     | 946/2048 [02:35<03:05,  5.95it/s, est. speed input: 6216.72 toks/s, output: 6.07 toks/s]
Processed prompts:  47%|     | 962/2048 [02:38<03:02,  5.96it/s, est. speed input: 6214.79 toks/s, output: 6.07 toks/s]
Processed prompts:  48%|     | 978/2048 [02:41<02:59,  5.96it/s, est. speed input: 6212.89 toks/s, output: 6.07 toks/s]
Processed prompts:  49%|     | 994/2048 [02:43<02:56,  5.96it/s, est. speed input: 6211.13 toks/s, output: 6.07 toks/s]
Processed prompts:  49%|     | 1010/2048 [02:46<02:54,  5.96it/s, est. speed input: 6209.33 toks/s, output: 6.06 toks/s]
Processed prompts:  50%|     | 1026/2048 [02:49<02:51,  5.96it/s, est. speed input: 6207.81 toks/s, output: 6.06 toks/s]
Processed prompts:  51%|     | 1042/2048 [02:51<02:48,  5.96it/s, est. speed input: 6206.12 toks/s, output: 6.06 toks/s]
Processed prompts:  52%|    | 1058/2048 [02:54<02:46,  5.96it/s, est. speed input: 6204.55 toks/s, output: 6.06 toks/s]
Processed prompts:  52%|    | 1074/2048 [02:57<02:43,  5.96it/s, est. speed input: 6203.04 toks/s, output: 6.06 toks/s]
Processed prompts:  53%|    | 1090/2048 [02:59<02:40,  5.96it/s, est. speed input: 6201.59 toks/s, output: 6.06 toks/s]
Processed prompts:  54%|    | 1106/2048 [03:02<02:38,  5.96it/s, est. speed input: 6200.17 toks/s, output: 6.05 toks/s]
Processed prompts:  55%|    | 1122/2048 [03:05<02:35,  5.97it/s, est. speed input: 6199.03 toks/s, output: 6.05 toks/s]
Processed prompts:  56%|    | 1138/2048 [03:08<02:32,  5.95it/s, est. speed input: 6197.14 toks/s, output: 6.05 toks/s]
Processed prompts:  56%|    | 1154/2048 [03:10<02:30,  5.95it/s, est. speed input: 6195.68 toks/s, output: 6.05 toks/s]
Processed prompts:  57%|    | 1170/2048 [03:13<02:27,  5.96it/s, est. speed input: 6194.58 toks/s, output: 6.05 toks/s]
Processed prompts:  58%|    | 1186/2048 [03:16<02:24,  5.95it/s, est. speed input: 6193.09 toks/s, output: 6.05 toks/s]
Processed prompts:  59%|    | 1202/2048 [03:18<02:19,  6.05it/s, est. speed input: 6196.42 toks/s, output: 6.05 toks/s]
Processed prompts:  59%|    | 1218/2048 [03:21<02:17,  6.02it/s, est. speed input: 6195.09 toks/s, output: 6.05 toks/s]
Processed prompts:  60%|    | 1234/2048 [03:23<02:13,  6.11it/s, est. speed input: 6198.54 toks/s, output: 6.05 toks/s]
Processed prompts:  61%|    | 1250/2048 [03:26<02:11,  6.07it/s, est. speed input: 6197.38 toks/s, output: 6.05 toks/s]
Processed prompts:  62%|   | 1266/2048 [03:29<02:09,  6.04it/s, est. speed input: 6196.24 toks/s, output: 6.05 toks/s]
Processed prompts:  63%|   | 1282/2048 [03:31<02:07,  6.01it/s, est. speed input: 6194.96 toks/s, output: 6.05 toks/s]
Processed prompts:  63%|   | 1298/2048 [03:34<02:04,  6.00it/s, est. speed input: 6194.03 toks/s, output: 6.05 toks/s]
Processed prompts:  64%|   | 1314/2048 [03:37<02:02,  5.99it/s, est. speed input: 6192.88 toks/s, output: 6.05 toks/s]
Processed prompts:  65%|   | 1330/2048 [03:39<01:58,  6.07it/s, est. speed input: 6195.35 toks/s, output: 6.05 toks/s]
Processed prompts:  66%|   | 1346/2048 [03:42<01:56,  6.03it/s, est. speed input: 6194.26 toks/s, output: 6.05 toks/s]
Processed prompts:  67%|   | 1362/2048 [03:45<01:54,  6.01it/s, est. speed input: 6193.23 toks/s, output: 6.05 toks/s]
Processed prompts:  67%|   | 1378/2048 [03:47<01:51,  5.99it/s, est. speed input: 6192.05 toks/s, output: 6.05 toks/s]
Processed prompts:  68%|   | 1394/2048 [03:50<01:49,  5.99it/s, est. speed input: 6191.11 toks/s, output: 6.05 toks/s]
Processed prompts:  69%|   | 1410/2048 [03:53<01:46,  5.97it/s, est. speed input: 6189.92 toks/s, output: 6.04 toks/s]
Processed prompts:  70%|   | 1426/2048 [03:55<01:44,  5.97it/s, est. speed input: 6189.05 toks/s, output: 6.04 toks/s]
Processed prompts:  70%|   | 1442/2048 [03:58<01:39,  6.06it/s, est. speed input: 6191.72 toks/s, output: 6.05 toks/s]
Processed prompts:  71%|   | 1458/2048 [04:01<01:36,  6.13it/s, est. speed input: 6194.38 toks/s, output: 6.05 toks/s]
Processed prompts:  72%|  | 1474/2048 [04:03<01:34,  6.07it/s, est. speed input: 6193.24 toks/s, output: 6.05 toks/s]
Processed prompts:  73%|  | 1490/2048 [04:06<01:32,  6.05it/s, est. speed input: 6192.44 toks/s, output: 6.05 toks/s]
Processed prompts:  74%|  | 1506/2048 [04:09<01:30,  6.01it/s, est. speed input: 6191.23 toks/s, output: 6.05 toks/s]
Processed prompts:  74%|  | 1522/2048 [04:11<01:26,  6.09it/s, est. speed input: 6193.74 toks/s, output: 6.05 toks/s]
Processed prompts:  75%|  | 1538/2048 [04:14<01:24,  6.05it/s, est. speed input: 6192.61 toks/s, output: 6.05 toks/s]
Processed prompts:  76%|  | 1554/2048 [04:16<01:20,  6.12it/s, est. speed input: 6195.25 toks/s, output: 6.05 toks/s]
Processed prompts:  77%|  | 1570/2048 [04:19<01:18,  6.07it/s, est. speed input: 6194.20 toks/s, output: 6.05 toks/s]
Processed prompts:  77%|  | 1586/2048 [04:22<01:16,  6.04it/s, est. speed input: 6193.35 toks/s, output: 6.05 toks/s]
Processed prompts:  78%|  | 1602/2048 [04:24<01:14,  6.02it/s, est. speed input: 6192.43 toks/s, output: 6.05 toks/s]
Processed prompts:  79%|  | 1618/2048 [04:27<01:10,  6.09it/s, est. speed input: 6194.72 toks/s, output: 6.05 toks/s]
Processed prompts:  80%|  | 1634/2048 [04:30<01:08,  6.05it/s, est. speed input: 6193.74 toks/s, output: 6.05 toks/s]
Processed prompts:  81%|  | 1650/2048 [04:32<01:06,  6.02it/s, est. speed input: 6192.91 toks/s, output: 6.05 toks/s]
Processed prompts:  81%| | 1666/2048 [04:35<01:03,  6.01it/s, est. speed input: 6192.10 toks/s, output: 6.05 toks/s]
Processed prompts:  82%| | 1682/2048 [04:38<01:01,  6.00it/s, est. speed input: 6191.33 toks/s, output: 6.05 toks/s]
Processed prompts:  83%| | 1698/2048 [04:40<00:58,  5.98it/s, est. speed input: 6190.47 toks/s, output: 6.05 toks/s]
Processed prompts:  84%| | 1714/2048 [04:43<00:55,  5.98it/s, est. speed input: 6189.69 toks/s, output: 6.04 toks/s]
Processed prompts:  84%| | 1730/2048 [04:46<00:52,  6.07it/s, est. speed input: 6191.97 toks/s, output: 6.05 toks/s]
Processed prompts:  85%| | 1746/2048 [04:48<00:48,  6.25it/s, est. speed input: 6197.56 toks/s, output: 6.05 toks/s]
Processed prompts:  86%| | 1762/2048 [04:51<00:46,  6.16it/s, est. speed input: 6196.69 toks/s, output: 6.05 toks/s]
Processed prompts:  87%| | 1778/2048 [04:53<00:44,  6.10it/s, est. speed input: 6195.90 toks/s, output: 6.05 toks/s]
Processed prompts:  88%| | 1794/2048 [04:56<00:41,  6.06it/s, est. speed input: 6195.00 toks/s, output: 6.05 toks/s]
Processed prompts:  88%| | 1810/2048 [04:59<00:39,  6.03it/s, est. speed input: 6194.32 toks/s, output: 6.05 toks/s]
Processed prompts:  89%| | 1826/2048 [05:01<00:36,  6.01it/s, est. speed input: 6193.59 toks/s, output: 6.05 toks/s]
Processed prompts:  90%| | 1842/2048 [05:04<00:34,  6.00it/s, est. speed input: 6192.82 toks/s, output: 6.05 toks/s]
Processed prompts:  91%| | 1858/2048 [05:07<00:31,  5.98it/s, est. speed input: 6191.97 toks/s, output: 6.05 toks/s]
Processed prompts:  92%|| 1874/2048 [05:09<00:29,  5.98it/s, est. speed input: 6191.28 toks/s, output: 6.05 toks/s]
Processed prompts:  92%|| 1890/2048 [05:12<00:26,  6.07it/s, est. speed input: 6193.23 toks/s, output: 6.05 toks/s]
Processed prompts:  93%|| 1906/2048 [05:15<00:23,  6.04it/s, est. speed input: 6192.53 toks/s, output: 6.05 toks/s]
Processed prompts:  94%|| 1922/2048 [05:17<00:21,  6.00it/s, est. speed input: 6191.32 toks/s, output: 6.05 toks/s]
Processed prompts:  95%|| 1938/2048 [05:20<00:18,  5.99it/s, est. speed input: 6190.66 toks/s, output: 6.05 toks/s]
Processed prompts:  95%|| 1954/2048 [05:23<00:15,  5.98it/s, est. speed input: 6189.79 toks/s, output: 6.04 toks/s]
Processed prompts:  96%|| 1970/2048 [05:25<00:13,  5.97it/s, est. speed input: 6189.02 toks/s, output: 6.04 toks/s]
Processed prompts:  97%|| 1986/2048 [05:28<00:10,  6.07it/s, est. speed input: 6191.09 toks/s, output: 6.05 toks/s]
Processed prompts:  98%|| 2002/2048 [05:31<00:07,  6.03it/s, est. speed input: 6190.27 toks/s, output: 6.05 toks/s]
Processed prompts:  99%|| 2018/2048 [05:33<00:04,  6.01it/s, est. speed input: 6189.64 toks/s, output: 6.04 toks/s]
Processed prompts:  99%|| 2034/2048 [05:36<00:02,  6.11it/s, est. speed input: 6192.00 toks/s, output: 6.05 toks/s]
Processed prompts: 100%|| 2048/2048 [05:36<00:00,  6.11it/s, est. speed input: 6234.61 toks/s, output: 6.09 toks/s]
Processed prompts: 100%|| 2048/2048 [05:36<00:00,  6.09it/s, est. speed input: 6234.61 toks/s, output: 6.09 toks/s]
[rank0]:[W126 16:13:11.578098012 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 16:13:14
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 16:13:33 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 16:13:34 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1483478) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1483478) WARNING 01-26 16:15:03 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.96 requests/s, 6110.22 total tokens/s, 5.96 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 16:13:33] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:13:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:13:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:13:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:13:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:13:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:13:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:13:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:13:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:13:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:13:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:13:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:13:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:13:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 16:13:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:13:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:13:37] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:13:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:13:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:13:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:13:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:13:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:13:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:13:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:13:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:13:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:13:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:13:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1483478) [2026-01-26 16:13:38] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1483478) [2026-01-26 16:13:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1483478) [2026-01-26 16:13:38] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1483478) [2026-01-26 16:13:38] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1483478) [2026-01-26 16:13:38] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1483478) [2026-01-26 16:13:38] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1483478) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1483478) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.52s/it]
(EngineCore_DP0 pid=1483478) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:03<00:00, 32.24s/it]
(EngineCore_DP0 pid=1483478) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:03<00:00, 31.68s/it]
(EngineCore_DP0 pid=1483478) 
(EngineCore_DP0 pid=1483478) [2026-01-26 16:14:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1483478) [2026-01-26 16:14:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=1483478) [2026-01-26 16:14:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1483478) [2026-01-26 16:14:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=1483478) [2026-01-26 16:14:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1483478) [2026-01-26 16:14:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=1483478) [2026-01-26 16:14:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1483478) [2026-01-26 16:14:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=1483478) 2026-01-26 16:14:54,823 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1483478) 2026-01-26 16:14:56,100 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 49/4096 [00:00<00:08, 484.49it/s]
Adding requests:   2%|         | 98/4096 [00:00<00:09, 441.41it/s]
Adding requests:   3%|         | 143/4096 [00:00<00:09, 410.96it/s]
Adding requests:   5%|         | 188/4096 [00:00<00:09, 422.95it/s]
Adding requests:   6%|         | 231/4096 [00:00<00:09, 416.00it/s]
Adding requests:   7%|         | 273/4096 [00:00<00:09, 414.45it/s]
Adding requests:   8%|         | 319/4096 [00:00<00:08, 428.53it/s]
Adding requests:   9%|         | 365/4096 [00:00<00:08, 436.09it/s]
Adding requests:  10%|         | 411/4096 [00:00<00:08, 442.94it/s]
Adding requests:  11%|         | 459/4096 [00:01<00:08, 452.47it/s]
Adding requests:  12%|        | 505/4096 [00:01<00:08, 441.41it/s]
Adding requests:  14%|        | 555/4096 [00:01<00:07, 456.85it/s]
Adding requests:  15%|        | 601/4096 [00:01<00:07, 442.54it/s]
Adding requests:  16%|        | 646/4096 [00:01<00:08, 426.20it/s]
Adding requests:  17%|        | 691/4096 [00:01<00:07, 430.62it/s]
Adding requests:  18%|        | 735/4096 [00:01<00:07, 424.77it/s]
Adding requests:  19%|        | 783/4096 [00:01<00:07, 440.41it/s]
Adding requests:  20%|        | 828/4096 [00:01<00:07, 423.15it/s]
Adding requests:  21%|       | 876/4096 [00:02<00:07, 438.87it/s]
Adding requests:  22%|       | 921/4096 [00:02<00:07, 430.26it/s]
Adding requests:  24%|       | 968/4096 [00:02<00:07, 440.69it/s]
Adding requests:  25%|       | 1013/4096 [00:02<00:07, 425.25it/s]
Adding requests:  26%|       | 1058/4096 [00:02<00:07, 430.03it/s]
Adding requests:  27%|       | 1102/4096 [00:02<00:06, 431.21it/s]
Adding requests:  28%|       | 1147/4096 [00:02<00:06, 434.54it/s]
Adding requests:  29%|       | 1192/4096 [00:02<00:06, 438.99it/s]
Adding requests:  30%|       | 1236/4096 [00:02<00:06, 420.23it/s]
Adding requests:  31%|       | 1279/4096 [00:02<00:06, 422.78it/s]
Adding requests:  32%|      | 1322/4096 [00:03<00:06, 416.12it/s]
Adding requests:  33%|      | 1368/4096 [00:03<00:06, 428.52it/s]
Adding requests:  34%|      | 1411/4096 [00:03<00:06, 418.31it/s]
Adding requests:  36%|      | 1458/4096 [00:03<00:06, 432.45it/s]
Adding requests:  37%|      | 1503/4096 [00:03<00:05, 435.49it/s]
Adding requests:  38%|      | 1548/4096 [00:03<00:05, 439.09it/s]
Adding requests:  39%|      | 1592/4096 [00:03<00:05, 433.55it/s]
Adding requests:  40%|      | 1636/4096 [00:03<00:05, 431.42it/s]
Adding requests:  41%|      | 1680/4096 [00:03<00:05, 433.32it/s]
Adding requests:  42%|     | 1724/4096 [00:03<00:05, 432.07it/s]
Adding requests:  43%|     | 1770/4096 [00:04<00:05, 438.97it/s]
Adding requests:  44%|     | 1814/4096 [00:04<00:05, 429.85it/s]
Adding requests:  45%|     | 1861/4096 [00:04<00:05, 441.26it/s]
Adding requests:  47%|     | 1906/4096 [00:04<00:04, 438.33it/s]
Adding requests:  48%|     | 1957/4096 [00:04<00:04, 458.60it/s]
Adding requests:  49%|     | 2003/4096 [00:04<00:04, 444.76it/s]
Adding requests:  50%|     | 2048/4096 [00:04<00:04, 444.08it/s]
Adding requests:  51%|     | 2093/4096 [00:04<00:04, 430.38it/s]
Adding requests:  52%|    | 2137/4096 [00:04<00:04, 428.09it/s]
Adding requests:  53%|    | 2180/4096 [00:05<00:04, 416.63it/s]
Adding requests:  54%|    | 2223/4096 [00:05<00:04, 418.52it/s]
Adding requests:  55%|    | 2266/4096 [00:05<00:04, 420.39it/s]
Adding requests:  56%|    | 2311/4096 [00:05<00:04, 428.72it/s]
Adding requests:  58%|    | 2359/4096 [00:05<00:03, 441.83it/s]
Adding requests:  59%|    | 2404/4096 [00:05<00:03, 443.35it/s]
Adding requests:  60%|    | 2449/4096 [00:05<00:03, 437.09it/s]
Adding requests:  61%|    | 2493/4096 [00:05<00:03, 433.40it/s]
Adding requests:  62%|   | 2545/4096 [00:05<00:03, 455.41it/s]
Adding requests:  63%|   | 2591/4096 [00:05<00:03, 446.84it/s]
Adding requests:  64%|   | 2636/4096 [00:06<00:03, 441.14it/s]
Adding requests:  65%|   | 2681/4096 [00:06<00:03, 436.87it/s]
Adding requests:  67%|   | 2725/4096 [00:06<00:03, 431.83it/s]
Adding requests:  68%|   | 2769/4096 [00:06<00:03, 433.06it/s]
Adding requests:  69%|   | 2813/4096 [00:06<00:02, 434.34it/s]
Adding requests:  70%|   | 2857/4096 [00:06<00:02, 431.73it/s]
Adding requests:  71%|   | 2901/4096 [00:06<00:02, 428.80it/s]
Adding requests:  72%|  | 2945/4096 [00:06<00:02, 431.25it/s]
Adding requests:  73%|  | 2989/4096 [00:06<00:02, 431.05it/s]
Adding requests:  74%|  | 3036/4096 [00:06<00:02, 441.84it/s]
Adding requests:  75%|  | 3081/4096 [00:07<00:02, 440.91it/s]
Adding requests:  76%|  | 3129/4096 [00:07<00:02, 451.42it/s]
Adding requests:  78%|  | 3175/4096 [00:07<00:02, 434.58it/s]
Adding requests:  79%|  | 3223/4096 [00:07<00:01, 446.19it/s]
Adding requests:  80%|  | 3268/4096 [00:07<00:01, 421.54it/s]
Adding requests:  81%|  | 3311/4096 [00:07<00:01, 406.66it/s]
Adding requests:  82%| | 3353/4096 [00:07<00:01, 410.19it/s]
Adding requests:  83%| | 3399/4096 [00:07<00:01, 422.20it/s]
Adding requests:  84%| | 3445/4096 [00:07<00:01, 432.35it/s]
Adding requests:  85%| | 3489/4096 [00:08<00:01, 424.24it/s]
Adding requests:  86%| | 3540/4096 [00:08<00:01, 447.72it/s]
Adding requests:  88%| | 3585/4096 [00:08<00:01, 440.14it/s]
Adding requests:  89%| | 3632/4096 [00:08<00:01, 448.19it/s]
Adding requests:  90%| | 3677/4096 [00:08<00:00, 434.49it/s]
Adding requests:  91%| | 3723/4096 [00:08<00:00, 437.55it/s]
Adding requests:  92%|| 3767/4096 [00:08<00:00, 416.49it/s]
Adding requests:  93%|| 3809/4096 [00:08<00:00, 412.85it/s]
Adding requests:  94%|| 3851/4096 [00:08<00:00, 395.65it/s]
Adding requests:  95%|| 3892/4096 [00:09<00:00, 397.90it/s]
Adding requests:  96%|| 3936/4096 [00:09<00:00, 408.95it/s]
Adding requests:  97%|| 3978/4096 [00:09<00:00, 406.70it/s]
Adding requests:  98%|| 4024/4096 [00:09<00:00, 421.27it/s]
Adding requests:  99%|| 4067/4096 [00:09<00:00, 411.81it/s]
Adding requests: 100%|| 4096/4096 [00:09<00:00, 430.66it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 38/4096 [00:02<03:59, 16.95it/s, est. speed input: 17358.97 toks/s, output: 16.95 toks/s]
Processed prompts:   2%|         | 70/4096 [00:07<07:57,  8.43it/s, est. speed input: 9405.28 toks/s, output: 9.18 toks/s]  
Processed prompts:   2%|         | 102/4096 [00:13<09:20,  7.13it/s, est. speed input: 8032.51 toks/s, output: 7.84 toks/s]
Processed prompts:   3%|         | 134/4096 [00:18<10:15,  6.44it/s, est. speed input: 7322.16 toks/s, output: 7.15 toks/s]
Processed prompts:   4%|         | 166/4096 [00:24<10:28,  6.25it/s, est. speed input: 7043.20 toks/s, output: 6.88 toks/s]
Processed prompts:   5%|         | 198/4096 [00:29<10:29,  6.19it/s, est. speed input: 6898.02 toks/s, output: 6.74 toks/s]
Processed prompts:   6%|         | 230/4096 [00:34<10:33,  6.11it/s, est. speed input: 6770.89 toks/s, output: 6.61 toks/s]
Processed prompts:   6%|         | 262/4096 [00:40<10:33,  6.05it/s, est. speed input: 6677.46 toks/s, output: 6.52 toks/s]
Processed prompts:   7%|         | 294/4096 [00:45<10:26,  6.06it/s, est. speed input: 6627.04 toks/s, output: 6.47 toks/s]
Processed prompts:   8%|         | 326/4096 [00:50<10:29,  5.98it/s, est. speed input: 6554.21 toks/s, output: 6.40 toks/s]
Processed prompts:   9%|         | 358/4096 [00:56<10:26,  5.97it/s, est. speed input: 6507.53 toks/s, output: 6.36 toks/s]
Processed prompts:  10%|         | 390/4096 [01:01<10:22,  5.95it/s, est. speed input: 6468.73 toks/s, output: 6.32 toks/s]
Processed prompts:  10%|         | 422/4096 [01:07<10:13,  5.99it/s, est. speed input: 6449.25 toks/s, output: 6.30 toks/s]
Processed prompts:  11%|         | 454/4096 [01:12<10:10,  5.97it/s, est. speed input: 6420.76 toks/s, output: 6.27 toks/s]
Processed prompts:  12%|        | 486/4096 [01:17<10:06,  5.95it/s, est. speed input: 6395.61 toks/s, output: 6.25 toks/s]
Processed prompts:  13%|        | 518/4096 [01:23<10:02,  5.94it/s, est. speed input: 6372.36 toks/s, output: 6.22 toks/s]
Processed prompts:  13%|        | 550/4096 [01:28<09:57,  5.93it/s, est. speed input: 6353.22 toks/s, output: 6.20 toks/s]
Processed prompts:  14%|        | 582/4096 [01:34<09:53,  5.92it/s, est. speed input: 6335.72 toks/s, output: 6.19 toks/s]
Processed prompts:  15%|        | 614/4096 [01:39<09:47,  5.92it/s, est. speed input: 6320.83 toks/s, output: 6.17 toks/s]
Processed prompts:  16%|        | 646/4096 [01:44<09:42,  5.92it/s, est. speed input: 6307.40 toks/s, output: 6.16 toks/s]
Processed prompts:  17%|        | 678/4096 [01:50<09:37,  5.92it/s, est. speed input: 6295.61 toks/s, output: 6.15 toks/s]
Processed prompts:  17%|        | 710/4096 [01:55<09:32,  5.92it/s, est. speed input: 6284.02 toks/s, output: 6.14 toks/s]
Processed prompts:  18%|        | 742/4096 [02:01<09:26,  5.92it/s, est. speed input: 6273.89 toks/s, output: 6.13 toks/s]
Processed prompts:  19%|        | 774/4096 [02:06<09:16,  5.97it/s, est. speed input: 6272.79 toks/s, output: 6.13 toks/s]
Processed prompts:  20%|        | 806/4096 [02:11<09:12,  5.95it/s, est. speed input: 6264.05 toks/s, output: 6.12 toks/s]
Processed prompts:  20%|        | 838/4096 [02:17<09:07,  5.95it/s, est. speed input: 6256.32 toks/s, output: 6.11 toks/s]
Processed prompts:  21%|        | 870/4096 [02:22<09:02,  5.94it/s, est. speed input: 6249.35 toks/s, output: 6.10 toks/s]
Processed prompts:  22%|       | 902/4096 [02:27<08:59,  5.93it/s, est. speed input: 6241.31 toks/s, output: 6.10 toks/s]
Processed prompts:  23%|       | 934/4096 [02:33<08:53,  5.92it/s, est. speed input: 6235.00 toks/s, output: 6.09 toks/s]
Processed prompts:  24%|       | 966/4096 [02:38<08:48,  5.92it/s, est. speed input: 6228.60 toks/s, output: 6.08 toks/s]
Processed prompts:  24%|       | 998/4096 [02:44<08:43,  5.92it/s, est. speed input: 6223.28 toks/s, output: 6.08 toks/s]
Processed prompts:  25%|       | 1030/4096 [02:49<08:37,  5.92it/s, est. speed input: 6218.17 toks/s, output: 6.07 toks/s]
Processed prompts:  26%|       | 1062/4096 [02:55<08:32,  5.92it/s, est. speed input: 6213.54 toks/s, output: 6.07 toks/s]
Processed prompts:  27%|       | 1094/4096 [03:00<08:27,  5.92it/s, est. speed input: 6208.92 toks/s, output: 6.06 toks/s]
Processed prompts:  27%|       | 1126/4096 [03:05<08:21,  5.92it/s, est. speed input: 6204.64 toks/s, output: 6.06 toks/s]
Processed prompts:  28%|       | 1158/4096 [03:11<08:16,  5.92it/s, est. speed input: 6200.79 toks/s, output: 6.06 toks/s]
Processed prompts:  29%|       | 1190/4096 [03:16<08:07,  5.97it/s, est. speed input: 6201.17 toks/s, output: 6.06 toks/s]
Processed prompts:  30%|       | 1222/4096 [03:21<07:59,  6.00it/s, est. speed input: 6201.69 toks/s, output: 6.06 toks/s]
Processed prompts:  31%|       | 1254/4096 [03:27<07:55,  5.98it/s, est. speed input: 6198.24 toks/s, output: 6.05 toks/s]
Processed prompts:  31%|      | 1286/4096 [03:32<07:52,  5.95it/s, est. speed input: 6194.08 toks/s, output: 6.05 toks/s]
Processed prompts:  32%|      | 1318/4096 [03:37<07:43,  5.99it/s, est. speed input: 6194.84 toks/s, output: 6.05 toks/s]
Processed prompts:  33%|      | 1350/4096 [03:43<07:40,  5.97it/s, est. speed input: 6191.60 toks/s, output: 6.05 toks/s]
Processed prompts:  34%|      | 1382/4096 [03:48<07:36,  5.95it/s, est. speed input: 6188.29 toks/s, output: 6.04 toks/s]
Processed prompts:  35%|      | 1414/4096 [03:53<07:27,  5.99it/s, est. speed input: 6189.21 toks/s, output: 6.04 toks/s]
Processed prompts:  35%|      | 1446/4096 [03:59<07:20,  6.01it/s, est. speed input: 6189.68 toks/s, output: 6.04 toks/s]
Processed prompts:  36%|      | 1478/4096 [04:04<07:17,  5.98it/s, est. speed input: 6186.76 toks/s, output: 6.04 toks/s]
Processed prompts:  37%|      | 1510/4096 [04:09<07:10,  6.01it/s, est. speed input: 6187.55 toks/s, output: 6.04 toks/s]
Processed prompts:  38%|      | 1542/4096 [04:15<07:03,  6.03it/s, est. speed input: 6188.51 toks/s, output: 6.04 toks/s]
Processed prompts:  38%|      | 1574/4096 [04:20<07:00,  6.00it/s, est. speed input: 6185.91 toks/s, output: 6.04 toks/s]
Processed prompts:  39%|      | 1606/4096 [04:25<06:53,  6.02it/s, est. speed input: 6186.60 toks/s, output: 6.04 toks/s]
Processed prompts:  40%|      | 1638/4096 [04:31<06:50,  5.99it/s, est. speed input: 6184.13 toks/s, output: 6.04 toks/s]
Processed prompts:  41%|      | 1670/4096 [04:36<06:46,  5.97it/s, est. speed input: 6181.76 toks/s, output: 6.04 toks/s]
Processed prompts:  42%|     | 1702/4096 [04:42<06:42,  5.95it/s, est. speed input: 6179.37 toks/s, output: 6.03 toks/s]
Processed prompts:  42%|     | 1734/4096 [04:47<06:27,  6.10it/s, est. speed input: 6186.78 toks/s, output: 6.04 toks/s]
Processed prompts:  43%|     | 1766/4096 [04:52<06:25,  6.04it/s, est. speed input: 6184.42 toks/s, output: 6.04 toks/s]
Processed prompts:  44%|     | 1798/4096 [04:57<06:22,  6.00it/s, est. speed input: 6182.07 toks/s, output: 6.04 toks/s]
Processed prompts:  45%|     | 1830/4096 [05:03<06:19,  5.97it/s, est. speed input: 6179.78 toks/s, output: 6.03 toks/s]
Processed prompts:  45%|     | 1862/4096 [05:08<06:11,  6.01it/s, est. speed input: 6180.71 toks/s, output: 6.04 toks/s]
Processed prompts:  46%|     | 1894/4096 [05:13<06:08,  5.98it/s, est. speed input: 6178.68 toks/s, output: 6.03 toks/s]
Processed prompts:  47%|     | 1926/4096 [05:19<06:03,  5.96it/s, est. speed input: 6176.72 toks/s, output: 6.03 toks/s]
Processed prompts:  48%|     | 1958/4096 [05:24<05:59,  5.95it/s, est. speed input: 6174.70 toks/s, output: 6.03 toks/s]
Processed prompts:  49%|     | 1990/4096 [05:29<05:51,  5.98it/s, est. speed input: 6175.37 toks/s, output: 6.03 toks/s]
Processed prompts:  49%|     | 2022/4096 [05:35<05:47,  5.97it/s, est. speed input: 6173.73 toks/s, output: 6.03 toks/s]
Processed prompts:  50%|     | 2054/4096 [05:40<05:40,  6.00it/s, est. speed input: 6174.56 toks/s, output: 6.03 toks/s]
Processed prompts:  51%|     | 2086/4096 [05:46<05:36,  5.98it/s, est. speed input: 6172.82 toks/s, output: 6.03 toks/s]
Processed prompts:  52%|    | 2118/4096 [05:51<05:32,  5.96it/s, est. speed input: 6170.96 toks/s, output: 6.03 toks/s]
Processed prompts:  52%|    | 2150/4096 [05:56<05:27,  5.95it/s, est. speed input: 6169.31 toks/s, output: 6.02 toks/s]
Processed prompts:  53%|    | 2182/4096 [06:02<05:19,  5.98it/s, est. speed input: 6170.00 toks/s, output: 6.03 toks/s]
Processed prompts:  54%|    | 2214/4096 [06:07<05:15,  5.96it/s, est. speed input: 6168.42 toks/s, output: 6.02 toks/s]
Processed prompts:  55%|    | 2246/4096 [06:12<05:10,  5.95it/s, est. speed input: 6166.93 toks/s, output: 6.02 toks/s]
Processed prompts:  56%|    | 2278/4096 [06:18<05:05,  5.95it/s, est. speed input: 6165.58 toks/s, output: 6.02 toks/s]
Processed prompts:  56%|    | 2310/4096 [06:23<05:00,  5.94it/s, est. speed input: 6164.12 toks/s, output: 6.02 toks/s]
Processed prompts:  57%|    | 2342/4096 [06:29<04:53,  5.98it/s, est. speed input: 6164.87 toks/s, output: 6.02 toks/s]
Processed prompts:  58%|    | 2374/4096 [06:34<04:48,  5.96it/s, est. speed input: 6163.46 toks/s, output: 6.02 toks/s]
Processed prompts:  59%|    | 2406/4096 [06:39<04:44,  5.95it/s, est. speed input: 6162.00 toks/s, output: 6.02 toks/s]
Processed prompts:  60%|    | 2438/4096 [06:45<04:39,  5.94it/s, est. speed input: 6160.69 toks/s, output: 6.02 toks/s]
Processed prompts:  60%|    | 2470/4096 [06:50<04:34,  5.93it/s, est. speed input: 6159.39 toks/s, output: 6.02 toks/s]
Processed prompts:  61%|    | 2502/4096 [06:56<04:28,  5.93it/s, est. speed input: 6158.11 toks/s, output: 6.01 toks/s]
Processed prompts:  62%|   | 2534/4096 [07:01<04:21,  5.97it/s, est. speed input: 6158.88 toks/s, output: 6.01 toks/s]
Processed prompts:  63%|   | 2566/4096 [07:06<04:17,  5.95it/s, est. speed input: 6157.53 toks/s, output: 6.01 toks/s]
Processed prompts:  63%|   | 2598/4096 [07:11<04:10,  5.99it/s, est. speed input: 6158.32 toks/s, output: 6.01 toks/s]
Processed prompts:  64%|   | 2630/4096 [07:17<04:05,  5.97it/s, est. speed input: 6157.07 toks/s, output: 6.01 toks/s]
Processed prompts:  65%|   | 2662/4096 [07:22<03:59,  6.00it/s, est. speed input: 6157.79 toks/s, output: 6.01 toks/s]
Processed prompts:  66%|   | 2694/4096 [07:28<03:54,  5.98it/s, est. speed input: 6156.78 toks/s, output: 6.01 toks/s]
Processed prompts:  67%|   | 2726/4096 [07:33<03:48,  6.01it/s, est. speed input: 6157.55 toks/s, output: 6.01 toks/s]
Processed prompts:  67%|   | 2758/4096 [07:38<03:43,  5.98it/s, est. speed input: 6156.39 toks/s, output: 6.01 toks/s]
Processed prompts:  68%|   | 2790/4096 [07:44<03:39,  5.96it/s, est. speed input: 6155.28 toks/s, output: 6.01 toks/s]
Processed prompts:  69%|   | 2822/4096 [07:49<03:34,  5.95it/s, est. speed input: 6154.25 toks/s, output: 6.01 toks/s]
Processed prompts:  70%|   | 2854/4096 [07:54<03:29,  5.94it/s, est. speed input: 6153.15 toks/s, output: 6.01 toks/s]
Processed prompts:  70%|   | 2886/4096 [08:00<03:20,  6.03it/s, est. speed input: 6155.92 toks/s, output: 6.01 toks/s]
Processed prompts:  71%|   | 2918/4096 [08:05<03:14,  6.05it/s, est. speed input: 6156.69 toks/s, output: 6.01 toks/s]
Processed prompts:  72%|  | 2950/4096 [08:10<03:10,  6.01it/s, est. speed input: 6155.57 toks/s, output: 6.01 toks/s]
Processed prompts:  73%|  | 2982/4096 [08:16<03:04,  6.03it/s, est. speed input: 6156.19 toks/s, output: 6.01 toks/s]
Processed prompts:  74%|  | 3014/4096 [08:21<03:00,  5.99it/s, est. speed input: 6155.18 toks/s, output: 6.01 toks/s]
Processed prompts:  74%|  | 3046/4096 [08:26<02:55,  5.97it/s, est. speed input: 6154.21 toks/s, output: 6.01 toks/s]
Processed prompts:  75%|  | 3078/4096 [08:32<02:50,  5.95it/s, est. speed input: 6153.20 toks/s, output: 6.01 toks/s]
Processed prompts:  76%|  | 3110/4096 [08:37<02:45,  5.94it/s, est. speed input: 6152.17 toks/s, output: 6.01 toks/s]
Processed prompts:  77%|  | 3142/4096 [08:43<02:40,  5.93it/s, est. speed input: 6151.19 toks/s, output: 6.01 toks/s]
Processed prompts:  77%|  | 3174/4096 [08:48<02:34,  5.98it/s, est. speed input: 6152.03 toks/s, output: 6.01 toks/s]
Processed prompts:  78%|  | 3206/4096 [08:53<02:29,  5.96it/s, est. speed input: 6151.06 toks/s, output: 6.01 toks/s]
Processed prompts:  79%|  | 3238/4096 [08:59<02:24,  5.95it/s, est. speed input: 6150.14 toks/s, output: 6.01 toks/s]
Processed prompts:  80%|  | 3270/4096 [09:04<02:19,  5.94it/s, est. speed input: 6149.32 toks/s, output: 6.01 toks/s]
Processed prompts:  81%|  | 3302/4096 [09:09<02:13,  5.94it/s, est. speed input: 6148.58 toks/s, output: 6.00 toks/s]
Processed prompts:  81%| | 3334/4096 [09:15<02:08,  5.93it/s, est. speed input: 6147.77 toks/s, output: 6.00 toks/s]
Processed prompts:  82%| | 3366/4096 [09:20<02:03,  5.93it/s, est. speed input: 6146.84 toks/s, output: 6.00 toks/s]
Processed prompts:  83%| | 3398/4096 [09:26<01:56,  5.97it/s, est. speed input: 6147.42 toks/s, output: 6.00 toks/s]
Processed prompts:  84%| | 3430/4096 [09:31<01:51,  5.95it/s, est. speed input: 6146.55 toks/s, output: 6.00 toks/s]
Processed prompts:  85%| | 3462/4096 [09:36<01:46,  5.94it/s, est. speed input: 6145.69 toks/s, output: 6.00 toks/s]
Processed prompts:  85%| | 3494/4096 [09:42<01:41,  5.94it/s, est. speed input: 6144.99 toks/s, output: 6.00 toks/s]
Processed prompts:  86%| | 3526/4096 [09:47<01:36,  5.93it/s, est. speed input: 6144.24 toks/s, output: 6.00 toks/s]
Processed prompts:  87%| | 3558/4096 [09:52<01:30,  5.97it/s, est. speed input: 6144.86 toks/s, output: 6.00 toks/s]
Processed prompts:  88%| | 3590/4096 [09:58<01:24,  5.96it/s, est. speed input: 6144.15 toks/s, output: 6.00 toks/s]
Processed prompts:  88%| | 3622/4096 [10:03<01:19,  5.95it/s, est. speed input: 6143.41 toks/s, output: 6.00 toks/s]
Processed prompts:  89%| | 3654/4096 [10:09<01:14,  5.94it/s, est. speed input: 6142.68 toks/s, output: 6.00 toks/s]
Processed prompts:  90%| | 3686/4096 [10:14<01:07,  6.04it/s, est. speed input: 6145.10 toks/s, output: 6.00 toks/s]
Processed prompts:  91%| | 3718/4096 [10:19<01:02,  6.00it/s, est. speed input: 6144.36 toks/s, output: 6.00 toks/s]
Processed prompts:  92%|| 3750/4096 [10:25<00:57,  5.98it/s, est. speed input: 6143.68 toks/s, output: 6.00 toks/s]
Processed prompts:  92%|| 3782/4096 [10:30<00:52,  5.96it/s, est. speed input: 6142.97 toks/s, output: 6.00 toks/s]
Processed prompts:  93%|| 3814/4096 [10:35<00:47,  5.95it/s, est. speed input: 6142.27 toks/s, output: 6.00 toks/s]
Processed prompts:  94%|| 3846/4096 [10:41<00:42,  5.94it/s, est. speed input: 6141.54 toks/s, output: 6.00 toks/s]
Processed prompts:  95%|| 3878/4096 [10:46<00:36,  5.93it/s, est. speed input: 6140.83 toks/s, output: 6.00 toks/s]
Processed prompts:  95%|| 3910/4096 [10:51<00:31,  5.97it/s, est. speed input: 6141.50 toks/s, output: 6.00 toks/s]
Processed prompts:  96%|| 3942/4096 [10:57<00:25,  6.00it/s, est. speed input: 6142.10 toks/s, output: 6.00 toks/s]
Processed prompts:  97%|| 3974/4096 [11:02<00:20,  5.97it/s, est. speed input: 6141.37 toks/s, output: 6.00 toks/s]
Processed prompts:  98%|| 4006/4096 [11:07<00:14,  6.00it/s, est. speed input: 6141.90 toks/s, output: 6.00 toks/s]
Processed prompts:  99%|| 4038/4096 [11:13<00:09,  6.02it/s, est. speed input: 6142.48 toks/s, output: 6.00 toks/s]
Processed prompts:  99%|| 4070/4096 [11:17<00:04,  6.34it/s, est. speed input: 6150.68 toks/s, output: 6.01 toks/s]
Processed prompts: 100%|| 4096/4096 [11:17<00:00,  6.34it/s, est. speed input: 6189.97 toks/s, output: 6.04 toks/s]
Processed prompts: 100%|| 4096/4096 [11:17<00:00,  6.04it/s, est. speed input: 6189.97 toks/s, output: 6.04 toks/s]
[rank0]:[W126 16:26:30.127628235 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 16:26:34
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 16:27:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 16:27:12 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1494901) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 303, in forward
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     hidden_states = self.mlp(hidden_states)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 108, in forward
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     x, _ = self.down_proj(x)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1405, in forward
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     output_parallel = self.quant_method.apply(self, input_parallel, bias_)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 349, in quant_slide_int8_triton
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]     out = torch.zeros(M_padded, K_out_padded, dtype=torch.int8, device=x.device)
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866] Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=1494901) ERROR 01-26 16:28:24 [core.py:866] 

STDERR:
[2026-01-26 16:27:11] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:27:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:27:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:27:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:27:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:27:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:27:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:27:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:27:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:27:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:27:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:27:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:27:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:27:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 16:27:15] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 16:27:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:27:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 16:27:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:27:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:27:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:27:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:27:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 16:27:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 16:27:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:27:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:27:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:27:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:27:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1494901) [2026-01-26 16:27:16] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1494901) [2026-01-26 16:27:16] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1494901) [2026-01-26 16:27:16] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1494901) [2026-01-26 16:27:16] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1494901) [2026-01-26 16:27:16] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1494901) [2026-01-26 16:27:16] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1494901) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1494901) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.75s/it]
(EngineCore_DP0 pid=1494901) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:03<00:00, 32.28s/it]
(EngineCore_DP0 pid=1494901) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:03<00:00, 31.75s/it]
(EngineCore_DP0 pid=1494901) 
(EngineCore_DP0 pid=1494901) [2026-01-26 16:28:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1494901) [2026-01-26 16:28:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=1494901) [2026-01-26 16:28:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1494901) [2026-01-26 16:28:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=1494901) [2026-01-26 16:28:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1494901) [2026-01-26 16:28:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=1494901) [2026-01-26 16:28:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1494901) [2026-01-26 16:28:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=1494901) Process EngineCore_DP0:
(EngineCore_DP0 pid=1494901) Traceback (most recent call last):
(EngineCore_DP0 pid=1494901)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=1494901)     self.run()
(EngineCore_DP0 pid=1494901)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=1494901)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=1494901)     raise e
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1494901)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1494901)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1494901)     super().__init__(
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1494901)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1494901)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1494901)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1494901)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1494901)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1494901)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1494901)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1494901)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1494901)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1494901)     self.model_runner.profile_run()
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1494901)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1494901)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1494901)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1494901)     outputs = self.model(
(EngineCore_DP0 pid=1494901)               ^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1494901)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1494901)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1494901)     hidden_states = self.model(
(EngineCore_DP0 pid=1494901)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=1494901)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=1494901)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=1494901)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1494901)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1494901)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 303, in forward
(EngineCore_DP0 pid=1494901)     hidden_states = self.mlp(hidden_states)
(EngineCore_DP0 pid=1494901)                     ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1494901)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1494901)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 108, in forward
(EngineCore_DP0 pid=1494901)     x, _ = self.down_proj(x)
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1494901)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1494901)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1405, in forward
(EngineCore_DP0 pid=1494901)     output_parallel = self.quant_method.apply(self, input_parallel, bias_)
(EngineCore_DP0 pid=1494901)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=1494901)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=1494901)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=1494901)     return self._linear_fn(
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=1494901)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=1494901)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=1494901)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=1494901)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=1494901)     return fn(input, L)
(EngineCore_DP0 pid=1494901)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 349, in quant_slide_int8_triton
(EngineCore_DP0 pid=1494901)     out = torch.zeros(M_padded, K_out_padded, dtype=torch.int8, device=x.device)
(EngineCore_DP0 pid=1494901)           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1494901) torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=1494901) Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=1494901) CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=1494901) For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=1494901) Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=1494901) 
[rank0]:[W126 16:28:24.806507815 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-27 02:27:59
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-14B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 02:28:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 02:28:06 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2006792) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2006792) WARNING 01-27 02:30:32 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.90 requests/s, 3025.21 total tokens/s, 5.90 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-27 02:28:06] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 02:28:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:28:06] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 02:28:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:28:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:28:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:28:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:28:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:28:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:28:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 02:28:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 02:28:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 02:28:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 02:28:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 02:28:09] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 02:28:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:28:09] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 02:28:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:28:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:28:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:28:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:28:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:28:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:28:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 02:28:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 02:28:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 02:28:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 02:28:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2006792) [2026-01-27 02:28:11] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2006792) [2026-01-27 02:28:11] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2006792) [2026-01-27 02:28:11] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2006792) [2026-01-27 02:28:11] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=2006792) [2026-01-27 02:28:11] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=2006792) [2026-01-27 02:28:11] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=2006792) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2006792) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.56s/it]
(EngineCore_DP0 pid=2006792) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:47<00:52, 26.20s/it]
(EngineCore_DP0 pid=2006792) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:18<00:28, 28.36s/it]
(EngineCore_DP0 pid=2006792) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:58<00:00, 33.19s/it]
(EngineCore_DP0 pid=2006792) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:58<00:00, 29.66s/it]
(EngineCore_DP0 pid=2006792) 
(EngineCore_DP0 pid=2006792) [2026-01-27 02:30:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=2006792) [2026-01-27 02:30:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 41287680 bytes
(EngineCore_DP0 pid=2006792) [2026-01-27 02:30:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=2006792) [2026-01-27 02:30:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 29491200 bytes
(EngineCore_DP0 pid=2006792) [2026-01-27 02:30:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=2006792) [2026-01-27 02:30:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 159252480 bytes
(EngineCore_DP0 pid=2006792) [2026-01-27 02:30:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=2006792) [2026-01-27 02:30:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 79626240 bytes
(EngineCore_DP0 pid=2006792) 2026-01-27 02:30:23,026 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2006792) 2026-01-27 02:30:23,380 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:   1%|          | 1/128 [00:00<01:41,  1.25it/s]
Adding requests:   2%|         | 2/128 [00:01<01:01,  2.05it/s]
Adding requests:   2%|         | 3/128 [00:01<00:41,  3.03it/s]
Adding requests:   3%|         | 4/128 [00:01<00:29,  4.14it/s]
Adding requests:   5%|         | 6/128 [00:01<00:18,  6.55it/s]
Adding requests:   6%|         | 8/128 [00:01<00:15,  7.93it/s]
Adding requests:   9%|         | 11/128 [00:01<00:09, 11.73it/s]
Adding requests:  11%|         | 14/128 [00:01<00:07, 14.42it/s]
Adding requests:  14%|        | 18/128 [00:02<00:05, 19.62it/s]
Adding requests:  16%|        | 21/128 [00:02<00:05, 21.35it/s]
Adding requests:  21%|        | 27/128 [00:02<00:03, 30.21it/s]
Adding requests:  34%|      | 44/128 [00:02<00:01, 65.69it/s]
Adding requests:  59%|    | 75/128 [00:02<00:00, 130.62it/s]
Adding requests:  98%|| 125/128 [00:02<00:00, 231.66it/s]
Adding requests: 100%|| 128/128 [00:02<00:00, 50.17it/s] 

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|         | 10/128 [00:00<00:01, 61.39it/s, est. speed input: 31437.00 toks/s, output: 61.39 toks/s]
Processed prompts:  13%|        | 17/128 [00:01<00:09, 11.34it/s, est. speed input: 6782.47 toks/s, output: 13.25 toks/s] 
Processed prompts:  16%|        | 20/128 [00:01<00:11,  9.54it/s, est. speed input: 5816.80 toks/s, output: 11.36 toks/s]
Processed prompts:  17%|        | 22/128 [00:02<00:12,  8.67it/s, est. speed input: 5402.47 toks/s, output: 10.55 toks/s]
Processed prompts:  19%|        | 24/128 [00:02<00:12,  8.04it/s, est. speed input: 5113.05 toks/s, output: 9.99 toks/s] 
Processed prompts:  20%|        | 26/128 [00:02<00:13,  7.58it/s, est. speed input: 4897.81 toks/s, output: 9.57 toks/s]
Processed prompts:  21%|        | 27/128 [00:02<00:13,  7.37it/s, est. speed input: 4805.86 toks/s, output: 9.39 toks/s]
Processed prompts:  22%|       | 28/128 [00:03<00:13,  7.18it/s, est. speed input: 4724.64 toks/s, output: 9.23 toks/s]
Processed prompts:  23%|       | 29/128 [00:03<00:14,  6.92it/s, est. speed input: 4638.74 toks/s, output: 9.06 toks/s]
Processed prompts:  23%|       | 30/128 [00:03<00:14,  6.77it/s, est. speed input: 4571.26 toks/s, output: 8.93 toks/s]
Processed prompts:  24%|       | 31/128 [00:03<00:14,  6.66it/s, est. speed input: 4511.44 toks/s, output: 8.81 toks/s]
Processed prompts:  25%|       | 32/128 [00:03<00:14,  6.59it/s, est. speed input: 4458.75 toks/s, output: 8.71 toks/s]
Processed prompts:  26%|       | 33/128 [00:03<00:14,  6.50it/s, est. speed input: 4406.17 toks/s, output: 8.61 toks/s]
Processed prompts:  27%|       | 34/128 [00:03<00:14,  6.42it/s, est. speed input: 4357.01 toks/s, output: 8.51 toks/s]
Processed prompts:  27%|       | 35/128 [00:04<00:14,  6.32it/s, est. speed input: 4307.99 toks/s, output: 8.41 toks/s]
Processed prompts:  28%|       | 36/128 [00:04<00:14,  6.31it/s, est. speed input: 4267.78 toks/s, output: 8.34 toks/s]
Processed prompts:  29%|       | 37/128 [00:04<00:14,  6.31it/s, est. speed input: 4230.99 toks/s, output: 8.26 toks/s]
Processed prompts:  30%|       | 38/128 [00:04<00:14,  6.30it/s, est. speed input: 4196.11 toks/s, output: 8.20 toks/s]
Processed prompts:  30%|       | 39/128 [00:04<00:14,  6.29it/s, est. speed input: 4163.04 toks/s, output: 8.13 toks/s]
Processed prompts:  31%|      | 40/128 [00:04<00:13,  6.29it/s, est. speed input: 4132.68 toks/s, output: 8.07 toks/s]
Processed prompts:  32%|      | 41/128 [00:05<00:13,  6.29it/s, est. speed input: 4104.72 toks/s, output: 8.02 toks/s]
Processed prompts:  33%|      | 42/128 [00:05<00:13,  6.23it/s, est. speed input: 4074.05 toks/s, output: 7.96 toks/s]
Processed prompts:  34%|      | 43/128 [00:05<00:13,  6.23it/s, est. speed input: 4047.58 toks/s, output: 7.91 toks/s]
Processed prompts:  34%|      | 44/128 [00:05<00:13,  6.22it/s, est. speed input: 4022.80 toks/s, output: 7.86 toks/s]
Processed prompts:  35%|      | 45/128 [00:05<00:13,  6.24it/s, est. speed input: 4000.50 toks/s, output: 7.81 toks/s]
Processed prompts:  36%|      | 46/128 [00:05<00:13,  6.23it/s, est. speed input: 3978.25 toks/s, output: 7.77 toks/s]
Processed prompts:  37%|      | 47/128 [00:06<00:12,  6.25it/s, est. speed input: 3958.44 toks/s, output: 7.73 toks/s]
Processed prompts:  38%|      | 48/128 [00:06<00:12,  6.21it/s, est. speed input: 3936.55 toks/s, output: 7.69 toks/s]
Processed prompts:  38%|      | 49/128 [00:06<00:12,  6.19it/s, est. speed input: 3916.77 toks/s, output: 7.65 toks/s]
Processed prompts:  39%|      | 50/128 [00:06<00:12,  6.26it/s, est. speed input: 3901.81 toks/s, output: 7.62 toks/s]
Processed prompts:  40%|      | 51/128 [00:06<00:12,  6.26it/s, est. speed input: 3885.06 toks/s, output: 7.59 toks/s]
Processed prompts:  41%|      | 52/128 [00:06<00:12,  6.27it/s, est. speed input: 3869.99 toks/s, output: 7.56 toks/s]
Processed prompts:  41%|     | 53/128 [00:07<00:11,  6.27it/s, est. speed input: 3854.80 toks/s, output: 7.53 toks/s]
Processed prompts:  42%|     | 54/128 [00:07<00:11,  6.25it/s, est. speed input: 3839.96 toks/s, output: 7.50 toks/s]
Processed prompts:  43%|     | 55/128 [00:07<00:11,  6.17it/s, est. speed input: 3822.23 toks/s, output: 7.47 toks/s]
Processed prompts:  44%|     | 56/128 [00:07<00:11,  6.21it/s, est. speed input: 3809.95 toks/s, output: 7.44 toks/s]
Processed prompts:  45%|     | 57/128 [00:07<00:11,  6.24it/s, est. speed input: 3797.88 toks/s, output: 7.42 toks/s]
Processed prompts:  45%|     | 58/128 [00:07<00:11,  6.24it/s, est. speed input: 3785.67 toks/s, output: 7.39 toks/s]
Processed prompts:  46%|     | 59/128 [00:08<00:11,  6.27it/s, est. speed input: 3774.80 toks/s, output: 7.37 toks/s]
Processed prompts:  47%|     | 60/128 [00:08<00:10,  6.28it/s, est. speed input: 3764.20 toks/s, output: 7.35 toks/s]
Processed prompts:  48%|     | 61/128 [00:08<00:10,  6.26it/s, est. speed input: 3753.03 toks/s, output: 7.33 toks/s]
Processed prompts:  48%|     | 62/128 [00:08<00:10,  6.20it/s, est. speed input: 3740.47 toks/s, output: 7.31 toks/s]
Processed prompts:  49%|     | 63/128 [00:08<00:10,  6.24it/s, est. speed input: 3731.44 toks/s, output: 7.29 toks/s]
Processed prompts:  50%|     | 64/128 [00:08<00:10,  6.20it/s, est. speed input: 3720.30 toks/s, output: 7.27 toks/s]
Processed prompts:  51%|     | 65/128 [00:08<00:10,  6.25it/s, est. speed input: 3712.00 toks/s, output: 7.25 toks/s]
Processed prompts:  52%|    | 66/128 [00:09<00:09,  6.27it/s, est. speed input: 3703.70 toks/s, output: 7.23 toks/s]
Processed prompts:  52%|    | 67/128 [00:09<00:09,  6.27it/s, est. speed input: 3695.36 toks/s, output: 7.22 toks/s]
Processed prompts:  53%|    | 68/128 [00:09<00:09,  6.16it/s, est. speed input: 3683.31 toks/s, output: 7.19 toks/s]
Processed prompts:  54%|    | 69/128 [00:09<00:09,  6.21it/s, est. speed input: 3676.03 toks/s, output: 7.18 toks/s]
Processed prompts:  55%|    | 70/128 [00:09<00:09,  6.20it/s, est. speed input: 3667.56 toks/s, output: 7.16 toks/s]
Processed prompts:  55%|    | 71/128 [00:09<00:09,  6.26it/s, est. speed input: 3661.42 toks/s, output: 7.15 toks/s]
Processed prompts:  56%|    | 72/128 [00:10<00:08,  6.28it/s, est. speed input: 3654.82 toks/s, output: 7.14 toks/s]
Processed prompts:  57%|    | 73/128 [00:10<00:08,  6.30it/s, est. speed input: 3648.61 toks/s, output: 7.13 toks/s]
Processed prompts:  58%|    | 74/128 [00:10<00:08,  6.30it/s, est. speed input: 3642.28 toks/s, output: 7.11 toks/s]
Processed prompts:  59%|    | 75/128 [00:10<00:08,  6.22it/s, est. speed input: 3633.63 toks/s, output: 7.10 toks/s]
Processed prompts:  59%|    | 76/128 [00:10<00:08,  6.23it/s, est. speed input: 3627.22 toks/s, output: 7.08 toks/s]
Processed prompts:  60%|    | 77/128 [00:10<00:08,  6.24it/s, est. speed input: 3621.13 toks/s, output: 7.07 toks/s]
Processed prompts:  61%|    | 78/128 [00:11<00:07,  6.27it/s, est. speed input: 3615.65 toks/s, output: 7.06 toks/s]
Processed prompts:  62%|   | 79/128 [00:11<00:07,  6.27it/s, est. speed input: 3609.83 toks/s, output: 7.05 toks/s]
Processed prompts:  62%|   | 80/128 [00:11<00:07,  6.25it/s, est. speed input: 3603.62 toks/s, output: 7.04 toks/s]
Processed prompts:  63%|   | 81/128 [00:11<00:07,  6.20it/s, est. speed input: 3596.73 toks/s, output: 7.02 toks/s]
Processed prompts:  64%|   | 82/128 [00:11<00:07,  6.22it/s, est. speed input: 3591.50 toks/s, output: 7.01 toks/s]
Processed prompts:  65%|   | 83/128 [00:11<00:07,  6.23it/s, est. speed input: 3586.09 toks/s, output: 7.00 toks/s]
Processed prompts:  66%|   | 84/128 [00:12<00:07,  6.24it/s, est. speed input: 3581.11 toks/s, output: 6.99 toks/s]
Processed prompts:  66%|   | 85/128 [00:12<00:06,  6.24it/s, est. speed input: 3576.14 toks/s, output: 6.98 toks/s]
Processed prompts:  67%|   | 86/128 [00:12<00:06,  6.27it/s, est. speed input: 3571.86 toks/s, output: 6.98 toks/s]
Processed prompts:  68%|   | 87/128 [00:12<00:06,  6.27it/s, est. speed input: 3567.24 toks/s, output: 6.97 toks/s]
Processed prompts:  69%|   | 88/128 [00:12<00:06,  6.18it/s, est. speed input: 3560.61 toks/s, output: 6.95 toks/s]
Processed prompts:  70%|   | 89/128 [00:12<00:06,  6.22it/s, est. speed input: 3556.49 toks/s, output: 6.95 toks/s]
Processed prompts:  70%|   | 90/128 [00:12<00:06,  6.23it/s, est. speed input: 3552.04 toks/s, output: 6.94 toks/s]
Processed prompts:  71%|   | 91/128 [00:13<00:05,  6.25it/s, est. speed input: 3548.10 toks/s, output: 6.93 toks/s]
Processed prompts:  72%|  | 92/128 [00:13<00:05,  6.26it/s, est. speed input: 3544.13 toks/s, output: 6.92 toks/s]
Processed prompts:  73%|  | 93/128 [00:13<00:05,  6.26it/s, est. speed input: 3540.05 toks/s, output: 6.91 toks/s]
Processed prompts:  73%|  | 94/128 [00:13<00:05,  6.18it/s, est. speed input: 3534.48 toks/s, output: 6.90 toks/s]
Processed prompts:  74%|  | 95/128 [00:13<00:05,  6.22it/s, est. speed input: 3530.95 toks/s, output: 6.90 toks/s]
Processed prompts:  75%|  | 96/128 [00:13<00:05,  6.23it/s, est. speed input: 3527.13 toks/s, output: 6.89 toks/s]
Processed prompts:  76%|  | 97/128 [00:14<00:04,  6.24it/s, est. speed input: 3523.53 toks/s, output: 6.88 toks/s]
Processed prompts:  77%|  | 98/128 [00:14<00:04,  6.26it/s, est. speed input: 3520.24 toks/s, output: 6.88 toks/s]
Processed prompts:  77%|  | 99/128 [00:14<00:04,  6.26it/s, est. speed input: 3516.77 toks/s, output: 6.87 toks/s]
Processed prompts:  78%|  | 100/128 [00:14<00:04,  6.27it/s, est. speed input: 3513.65 toks/s, output: 6.86 toks/s]
Processed prompts:  79%|  | 101/128 [00:14<00:04,  6.23it/s, est. speed input: 3509.57 toks/s, output: 6.85 toks/s]
Processed prompts:  80%|  | 102/128 [00:14<00:04,  6.27it/s, est. speed input: 3506.96 toks/s, output: 6.85 toks/s]
Processed prompts:  80%|  | 103/128 [00:15<00:03,  6.26it/s, est. speed input: 3503.57 toks/s, output: 6.84 toks/s]
Processed prompts:  81%| | 104/128 [00:15<00:03,  6.26it/s, est. speed input: 3500.51 toks/s, output: 6.84 toks/s]
Processed prompts:  82%| | 105/128 [00:15<00:03,  6.27it/s, est. speed input: 3497.56 toks/s, output: 6.83 toks/s]
Processed prompts:  83%| | 106/128 [00:15<00:03,  6.29it/s, est. speed input: 3494.99 toks/s, output: 6.83 toks/s]
Processed prompts:  84%| | 107/128 [00:15<00:03,  6.21it/s, est. speed input: 3490.77 toks/s, output: 6.82 toks/s]
Processed prompts:  84%| | 108/128 [00:15<00:03,  6.22it/s, est. speed input: 3487.77 toks/s, output: 6.81 toks/s]
Processed prompts:  85%| | 109/128 [00:16<00:03,  6.26it/s, est. speed input: 3485.53 toks/s, output: 6.81 toks/s]
Processed prompts:  86%| | 110/128 [00:16<00:02,  6.25it/s, est. speed input: 3482.53 toks/s, output: 6.80 toks/s]
Processed prompts:  87%| | 111/128 [00:16<00:02,  6.26it/s, est. speed input: 3479.96 toks/s, output: 6.80 toks/s]
Processed prompts:  88%| | 112/128 [00:16<00:02,  6.27it/s, est. speed input: 3477.41 toks/s, output: 6.79 toks/s]
Processed prompts:  88%| | 113/128 [00:16<00:02,  6.28it/s, est. speed input: 3474.99 toks/s, output: 6.79 toks/s]
Processed prompts:  89%| | 114/128 [00:16<00:02,  6.20it/s, est. speed input: 3471.11 toks/s, output: 6.78 toks/s]
Processed prompts:  90%| | 115/128 [00:16<00:02,  6.22it/s, est. speed input: 3468.69 toks/s, output: 6.77 toks/s]
Processed prompts:  91%| | 116/128 [00:17<00:01,  6.25it/s, est. speed input: 3466.47 toks/s, output: 6.77 toks/s]
Processed prompts:  91%|| 117/128 [00:17<00:01,  6.28it/s, est. speed input: 3464.55 toks/s, output: 6.77 toks/s]
Processed prompts:  92%|| 118/128 [00:17<00:01,  6.28it/s, est. speed input: 3462.30 toks/s, output: 6.76 toks/s]
Processed prompts:  93%|| 119/128 [00:17<00:01,  6.29it/s, est. speed input: 3460.16 toks/s, output: 6.76 toks/s]
Processed prompts:  94%|| 120/128 [00:17<00:01,  6.20it/s, est. speed input: 3456.60 toks/s, output: 6.75 toks/s]
Processed prompts:  95%|| 121/128 [00:17<00:01,  6.19it/s, est. speed input: 3453.87 toks/s, output: 6.75 toks/s]
Processed prompts:  95%|| 122/128 [00:18<00:00,  6.24it/s, est. speed input: 3452.07 toks/s, output: 6.74 toks/s]
Processed prompts:  96%|| 123/128 [00:18<00:00,  6.23it/s, est. speed input: 3449.69 toks/s, output: 6.74 toks/s]
Processed prompts:  97%|| 124/128 [00:18<00:00,  6.23it/s, est. speed input: 3447.45 toks/s, output: 6.73 toks/s]
Processed prompts:  98%|| 125/128 [00:18<00:00,  6.23it/s, est. speed input: 3445.27 toks/s, output: 6.73 toks/s]
Processed prompts:  98%|| 126/128 [00:18<00:00,  6.26it/s, est. speed input: 3443.57 toks/s, output: 6.73 toks/s]
Processed prompts:  99%|| 127/128 [00:18<00:00,  6.17it/s, est. speed input: 3440.12 toks/s, output: 6.72 toks/s]
Processed prompts: 100%|| 128/128 [00:19<00:00,  6.18it/s, est. speed input: 3437.85 toks/s, output: 6.71 toks/s]
Processed prompts: 100%|| 128/128 [00:19<00:00,  6.18it/s, est. speed input: 3437.85 toks/s, output: 6.71 toks/s]
Processed prompts: 100%|| 128/128 [00:19<00:00,  6.71it/s, est. speed input: 3437.85 toks/s, output: 6.71 toks/s]
[rank0]:[W127 02:30:55.110865482 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-27 02:31:10
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-14B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 02:31:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 02:31:16 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2009627) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2009627) WARNING 01-27 02:33:43 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.27 requests/s, 3355.87 total tokens/s, 3.27 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-27 02:31:16] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 02:31:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:31:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 02:31:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:31:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:31:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:31:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:31:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:31:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:31:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 02:31:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 02:31:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 02:31:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 02:31:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 02:31:20] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 02:31:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:31:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 02:31:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:31:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:31:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:31:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:31:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:31:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:31:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 02:31:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 02:31:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 02:31:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 02:31:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2009627) [2026-01-27 02:31:21] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2009627) [2026-01-27 02:31:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2009627) [2026-01-27 02:31:21] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2009627) [2026-01-27 02:31:21] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=2009627) [2026-01-27 02:31:21] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=2009627) [2026-01-27 02:31:21] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=2009627) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2009627) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.36s/it]
(EngineCore_DP0 pid=2009627) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:48<00:53, 26.85s/it]
(EngineCore_DP0 pid=2009627) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:18<00:28, 28.65s/it]
(EngineCore_DP0 pid=2009627) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:00<00:00, 33.72s/it]
(EngineCore_DP0 pid=2009627) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:00<00:00, 30.11s/it]
(EngineCore_DP0 pid=2009627) 
(EngineCore_DP0 pid=2009627) [2026-01-27 02:33:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=2009627) [2026-01-27 02:33:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 41287680 bytes
(EngineCore_DP0 pid=2009627) [2026-01-27 02:33:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=2009627) [2026-01-27 02:33:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 29491200 bytes
(EngineCore_DP0 pid=2009627) [2026-01-27 02:33:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=2009627) [2026-01-27 02:33:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 159252480 bytes
(EngineCore_DP0 pid=2009627) [2026-01-27 02:33:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=2009627) [2026-01-27 02:33:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 79626240 bytes
(EngineCore_DP0 pid=2009627) 2026-01-27 02:33:34,483 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2009627) 2026-01-27 02:33:34,889 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:   1%|          | 1/128 [00:01<02:36,  1.23s/it]
Adding requests:   2%|         | 2/128 [00:01<01:24,  1.49it/s]
Adding requests:   2%|         | 3/128 [00:01<00:55,  2.26it/s]
Adding requests:   3%|         | 4/128 [00:01<00:38,  3.20it/s]
Adding requests:   4%|         | 5/128 [00:01<00:29,  4.20it/s]
Adding requests:   5%|         | 7/128 [00:02<00:18,  6.54it/s]
Adding requests:   8%|         | 10/128 [00:02<00:11, 10.51it/s]
Adding requests:  10%|         | 13/128 [00:02<00:08, 13.87it/s]
Adding requests:  16%|        | 20/128 [00:02<00:04, 25.91it/s]
Adding requests:  34%|      | 44/128 [00:02<00:01, 76.01it/s]
Adding requests:  60%|    | 77/128 [00:02<00:00, 139.30it/s]
Adding requests:  92%|| 118/128 [00:02<00:00, 209.60it/s]
Adding requests: 100%|| 128/128 [00:02<00:00, 46.96it/s] 

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:06, 18.40it/s, est. speed input: 18840.01 toks/s, output: 18.40 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:17,  7.11it/s, est. speed input: 8379.73 toks/s, output: 8.18 toks/s]  
Processed prompts:   6%|         | 8/128 [00:01<00:20,  5.83it/s, est. speed input: 7149.82 toks/s, output: 6.98 toks/s]
Processed prompts:   7%|         | 9/128 [00:01<00:23,  5.05it/s, est. speed input: 6428.17 toks/s, output: 6.28 toks/s]
Processed prompts:   8%|         | 10/128 [00:01<00:26,  4.51it/s, est. speed input: 5927.83 toks/s, output: 5.79 toks/s]
Processed prompts:   9%|         | 11/128 [00:02<00:27,  4.20it/s, est. speed input: 5596.98 toks/s, output: 5.47 toks/s]
Processed prompts:   9%|         | 12/128 [00:02<00:29,  3.97it/s, est. speed input: 5339.24 toks/s, output: 5.21 toks/s]
Processed prompts:  10%|         | 13/128 [00:02<00:30,  3.80it/s, est. speed input: 5129.92 toks/s, output: 5.01 toks/s]
Processed prompts:  11%|         | 14/128 [00:02<00:30,  3.69it/s, est. speed input: 4966.88 toks/s, output: 4.85 toks/s]
Processed prompts:  12%|        | 15/128 [00:03<00:31,  3.62it/s, est. speed input: 4838.36 toks/s, output: 4.72 toks/s]
Processed prompts:  12%|        | 16/128 [00:03<00:31,  3.57it/s, est. speed input: 4731.12 toks/s, output: 4.62 toks/s]
Processed prompts:  13%|        | 17/128 [00:03<00:31,  3.52it/s, est. speed input: 4633.53 toks/s, output: 4.52 toks/s]
Processed prompts:  14%|        | 18/128 [00:04<00:31,  3.48it/s, est. speed input: 4549.75 toks/s, output: 4.44 toks/s]
Processed prompts:  15%|        | 19/128 [00:04<00:31,  3.48it/s, est. speed input: 4484.89 toks/s, output: 4.38 toks/s]
Processed prompts:  16%|        | 20/128 [00:04<00:31,  3.45it/s, est. speed input: 4419.26 toks/s, output: 4.32 toks/s]
Processed prompts:  16%|        | 21/128 [00:04<00:31,  3.45it/s, est. speed input: 4366.01 toks/s, output: 4.26 toks/s]
Processed prompts:  17%|        | 22/128 [00:05<00:30,  3.46it/s, est. speed input: 4321.57 toks/s, output: 4.22 toks/s]
Processed prompts:  18%|        | 23/128 [00:05<00:30,  3.46it/s, est. speed input: 4280.29 toks/s, output: 4.18 toks/s]
Processed prompts:  19%|        | 24/128 [00:05<00:30,  3.43it/s, est. speed input: 4238.68 toks/s, output: 4.14 toks/s]
Processed prompts:  20%|        | 25/128 [00:06<00:29,  3.44it/s, est. speed input: 4205.84 toks/s, output: 4.11 toks/s]
Processed prompts:  20%|        | 26/128 [00:06<00:29,  3.44it/s, est. speed input: 4175.32 toks/s, output: 4.08 toks/s]
Processed prompts:  21%|        | 27/128 [00:06<00:29,  3.45it/s, est. speed input: 4148.75 toks/s, output: 4.05 toks/s]
Processed prompts:  22%|       | 28/128 [00:06<00:29,  3.43it/s, est. speed input: 4119.94 toks/s, output: 4.02 toks/s]
Processed prompts:  23%|       | 29/128 [00:07<00:29,  3.41it/s, est. speed input: 4092.13 toks/s, output: 4.00 toks/s]
Processed prompts:  23%|       | 30/128 [00:07<00:28,  3.45it/s, est. speed input: 4074.09 toks/s, output: 3.98 toks/s]
Processed prompts:  24%|       | 31/128 [00:07<00:28,  3.43it/s, est. speed input: 4051.07 toks/s, output: 3.96 toks/s]
Processed prompts:  25%|       | 32/128 [00:08<00:27,  3.43it/s, est. speed input: 4032.18 toks/s, output: 3.94 toks/s]
Processed prompts:  26%|       | 33/128 [00:08<00:27,  3.44it/s, est. speed input: 4014.81 toks/s, output: 3.92 toks/s]
Processed prompts:  27%|       | 34/128 [00:08<00:27,  3.44it/s, est. speed input: 3998.82 toks/s, output: 3.91 toks/s]
Processed prompts:  27%|       | 35/128 [00:09<00:27,  3.42it/s, est. speed input: 3980.87 toks/s, output: 3.89 toks/s]
Processed prompts:  28%|       | 36/128 [00:09<00:26,  3.42it/s, est. speed input: 3965.76 toks/s, output: 3.87 toks/s]
Processed prompts:  29%|       | 37/128 [00:09<00:26,  3.43it/s, est. speed input: 3952.50 toks/s, output: 3.86 toks/s]
Processed prompts:  30%|       | 38/128 [00:09<00:26,  3.41it/s, est. speed input: 3937.65 toks/s, output: 3.85 toks/s]
Processed prompts:  30%|       | 39/128 [00:10<00:26,  3.41it/s, est. speed input: 3925.21 toks/s, output: 3.83 toks/s]
Processed prompts:  31%|      | 40/128 [00:10<00:25,  3.41it/s, est. speed input: 3913.14 toks/s, output: 3.82 toks/s]
Processed prompts:  32%|      | 41/128 [00:10<00:25,  3.42it/s, est. speed input: 3902.39 toks/s, output: 3.81 toks/s]
Processed prompts:  33%|      | 42/128 [00:11<00:25,  3.40it/s, est. speed input: 3890.12 toks/s, output: 3.80 toks/s]
Processed prompts:  34%|      | 43/128 [00:11<00:24,  3.41it/s, est. speed input: 3880.35 toks/s, output: 3.79 toks/s]
Processed prompts:  34%|      | 44/128 [00:11<00:24,  3.42it/s, est. speed input: 3871.30 toks/s, output: 3.78 toks/s]
Processed prompts:  35%|      | 45/128 [00:11<00:24,  3.42it/s, est. speed input: 3862.26 toks/s, output: 3.77 toks/s]
Processed prompts:  36%|      | 46/128 [00:12<00:24,  3.40it/s, est. speed input: 3851.71 toks/s, output: 3.76 toks/s]
Processed prompts:  37%|      | 47/128 [00:12<00:23,  3.41it/s, est. speed input: 3844.44 toks/s, output: 3.75 toks/s]
Processed prompts:  38%|      | 48/128 [00:12<00:23,  3.41it/s, est. speed input: 3836.43 toks/s, output: 3.75 toks/s]
Processed prompts:  38%|      | 49/128 [00:13<00:23,  3.40it/s, est. speed input: 3827.66 toks/s, output: 3.74 toks/s]
Processed prompts:  39%|      | 50/128 [00:13<00:22,  3.41it/s, est. speed input: 3820.53 toks/s, output: 3.73 toks/s]
Processed prompts:  40%|      | 51/128 [00:13<00:22,  3.41it/s, est. speed input: 3813.33 toks/s, output: 3.72 toks/s]
Processed prompts:  41%|      | 52/128 [00:13<00:22,  3.40it/s, est. speed input: 3806.04 toks/s, output: 3.72 toks/s]
Processed prompts:  41%|     | 53/128 [00:14<00:22,  3.39it/s, est. speed input: 3798.67 toks/s, output: 3.71 toks/s]
Processed prompts:  42%|     | 54/128 [00:14<00:21,  3.41it/s, est. speed input: 3793.15 toks/s, output: 3.70 toks/s]
Processed prompts:  43%|     | 55/128 [00:14<00:21,  3.42it/s, est. speed input: 3788.07 toks/s, output: 3.70 toks/s]
Processed prompts:  44%|     | 56/128 [00:15<00:21,  3.40it/s, est. speed input: 3781.44 toks/s, output: 3.69 toks/s]
Processed prompts:  45%|     | 57/128 [00:15<00:20,  3.42it/s, est. speed input: 3776.75 toks/s, output: 3.69 toks/s]
Processed prompts:  45%|     | 58/128 [00:15<00:20,  3.42it/s, est. speed input: 3771.55 toks/s, output: 3.68 toks/s]
Processed prompts:  46%|     | 59/128 [00:16<00:20,  3.43it/s, est. speed input: 3767.47 toks/s, output: 3.68 toks/s]
Processed prompts:  47%|     | 60/128 [00:16<00:19,  3.41it/s, est. speed input: 3761.35 toks/s, output: 3.67 toks/s]
Processed prompts:  48%|     | 61/128 [00:16<00:19,  3.41it/s, est. speed input: 3756.64 toks/s, output: 3.67 toks/s]
Processed prompts:  48%|     | 62/128 [00:16<00:19,  3.41it/s, est. speed input: 3752.15 toks/s, output: 3.66 toks/s]
Processed prompts:  49%|     | 63/128 [00:17<00:19,  3.41it/s, est. speed input: 3747.85 toks/s, output: 3.66 toks/s]
Processed prompts:  50%|     | 64/128 [00:17<00:18,  3.40it/s, est. speed input: 3742.61 toks/s, output: 3.65 toks/s]
Processed prompts:  51%|     | 65/128 [00:17<00:18,  3.42it/s, est. speed input: 3739.39 toks/s, output: 3.65 toks/s]
Processed prompts:  52%|    | 66/128 [00:18<00:18,  3.43it/s, est. speed input: 3736.26 toks/s, output: 3.65 toks/s]
Processed prompts:  52%|    | 67/128 [00:18<00:17,  3.42it/s, est. speed input: 3732.07 toks/s, output: 3.64 toks/s]
Processed prompts:  53%|    | 68/128 [00:18<00:17,  3.43it/s, est. speed input: 3729.13 toks/s, output: 3.64 toks/s]
Processed prompts:  54%|    | 69/128 [00:18<00:17,  3.44it/s, est. speed input: 3726.60 toks/s, output: 3.64 toks/s]
Processed prompts:  55%|    | 70/128 [00:19<00:16,  3.44it/s, est. speed input: 3723.47 toks/s, output: 3.64 toks/s]
Processed prompts:  55%|    | 71/128 [00:19<00:16,  3.43it/s, est. speed input: 3719.63 toks/s, output: 3.63 toks/s]
Processed prompts:  56%|    | 72/128 [00:19<00:16,  3.43it/s, est. speed input: 3716.70 toks/s, output: 3.63 toks/s]
Processed prompts:  57%|    | 73/128 [00:20<00:16,  3.42it/s, est. speed input: 3713.43 toks/s, output: 3.63 toks/s]
Processed prompts:  58%|    | 74/128 [00:20<00:15,  3.40it/s, est. speed input: 3709.40 toks/s, output: 3.62 toks/s]
Processed prompts:  59%|    | 75/128 [00:20<00:15,  3.42it/s, est. speed input: 3707.05 toks/s, output: 3.62 toks/s]
Processed prompts:  59%|    | 76/128 [00:21<00:15,  3.42it/s, est. speed input: 3704.30 toks/s, output: 3.62 toks/s]
Processed prompts:  60%|    | 77/128 [00:21<00:14,  3.43it/s, est. speed input: 3701.75 toks/s, output: 3.61 toks/s]
Processed prompts:  61%|    | 78/128 [00:21<00:14,  3.40it/s, est. speed input: 3698.02 toks/s, output: 3.61 toks/s]
Processed prompts:  62%|   | 79/128 [00:21<00:14,  3.41it/s, est. speed input: 3695.65 toks/s, output: 3.61 toks/s]
Processed prompts:  62%|   | 80/128 [00:22<00:14,  3.41it/s, est. speed input: 3693.03 toks/s, output: 3.61 toks/s]
Processed prompts:  63%|   | 81/128 [00:22<00:13,  3.43it/s, est. speed input: 3691.32 toks/s, output: 3.60 toks/s]
Processed prompts:  64%|   | 82/128 [00:22<00:13,  3.42it/s, est. speed input: 3688.55 toks/s, output: 3.60 toks/s]
Processed prompts:  65%|   | 83/128 [00:23<00:13,  3.42it/s, est. speed input: 3686.15 toks/s, output: 3.60 toks/s]
Processed prompts:  66%|   | 84/128 [00:23<00:12,  3.41it/s, est. speed input: 3683.52 toks/s, output: 3.60 toks/s]
Processed prompts:  66%|   | 85/128 [00:23<00:12,  3.38it/s, est. speed input: 3679.90 toks/s, output: 3.59 toks/s]
Processed prompts:  67%|   | 86/128 [00:23<00:12,  3.41it/s, est. speed input: 3678.37 toks/s, output: 3.59 toks/s]
Processed prompts:  68%|   | 87/128 [00:24<00:12,  3.41it/s, est. speed input: 3676.18 toks/s, output: 3.59 toks/s]
Processed prompts:  69%|   | 88/128 [00:24<00:11,  3.43it/s, est. speed input: 3674.65 toks/s, output: 3.59 toks/s]
Processed prompts:  70%|   | 89/128 [00:24<00:11,  3.41it/s, est. speed input: 3672.15 toks/s, output: 3.59 toks/s]
Processed prompts:  70%|   | 90/128 [00:25<00:11,  3.42it/s, est. speed input: 3670.31 toks/s, output: 3.58 toks/s]
Processed prompts:  71%|   | 91/128 [00:25<00:10,  3.42it/s, est. speed input: 3668.47 toks/s, output: 3.58 toks/s]
Processed prompts:  72%|  | 92/128 [00:25<00:10,  3.39it/s, est. speed input: 3665.32 toks/s, output: 3.58 toks/s]
Processed prompts:  73%|  | 93/128 [00:25<00:10,  3.40it/s, est. speed input: 3663.35 toks/s, output: 3.58 toks/s]
Processed prompts:  73%|  | 94/128 [00:26<00:10,  3.40it/s, est. speed input: 3661.37 toks/s, output: 3.58 toks/s]
Processed prompts:  74%|  | 95/128 [00:26<00:09,  3.40it/s, est. speed input: 3659.57 toks/s, output: 3.57 toks/s]
Processed prompts:  75%|  | 96/128 [00:26<00:09,  3.40it/s, est. speed input: 3657.37 toks/s, output: 3.57 toks/s]
Processed prompts:  76%|  | 97/128 [00:27<00:09,  3.40it/s, est. speed input: 3655.73 toks/s, output: 3.57 toks/s]
Processed prompts:  77%|  | 98/128 [00:27<00:08,  3.40it/s, est. speed input: 3653.90 toks/s, output: 3.57 toks/s]
Processed prompts:  77%|  | 99/128 [00:27<00:08,  3.39it/s, est. speed input: 3651.66 toks/s, output: 3.57 toks/s]
Processed prompts:  78%|  | 100/128 [00:28<00:08,  3.39it/s, est. speed input: 3649.55 toks/s, output: 3.56 toks/s]
Processed prompts:  79%|  | 101/128 [00:28<00:07,  3.40it/s, est. speed input: 3648.25 toks/s, output: 3.56 toks/s]
Processed prompts:  80%|  | 102/128 [00:28<00:07,  3.41it/s, est. speed input: 3646.95 toks/s, output: 3.56 toks/s]
Processed prompts:  80%|  | 103/128 [00:28<00:07,  3.40it/s, est. speed input: 3644.81 toks/s, output: 3.56 toks/s]
Processed prompts:  81%| | 104/128 [00:29<00:07,  3.41it/s, est. speed input: 3643.63 toks/s, output: 3.56 toks/s]
Processed prompts:  82%| | 105/128 [00:29<00:06,  3.42it/s, est. speed input: 3642.56 toks/s, output: 3.56 toks/s]
Processed prompts:  83%| | 106/128 [00:29<00:06,  3.42it/s, est. speed input: 3641.19 toks/s, output: 3.56 toks/s]
Processed prompts:  84%| | 107/128 [00:30<00:06,  3.40it/s, est. speed input: 3639.20 toks/s, output: 3.55 toks/s]
Processed prompts:  84%| | 108/128 [00:30<00:05,  3.41it/s, est. speed input: 3637.96 toks/s, output: 3.55 toks/s]
Processed prompts:  85%| | 109/128 [00:30<00:05,  3.39it/s, est. speed input: 3635.74 toks/s, output: 3.55 toks/s]
Processed prompts:  86%| | 110/128 [00:30<00:05,  3.41it/s, est. speed input: 3634.86 toks/s, output: 3.55 toks/s]
Processed prompts:  87%| | 111/128 [00:31<00:04,  3.41it/s, est. speed input: 3633.44 toks/s, output: 3.55 toks/s]
Processed prompts:  88%| | 112/128 [00:31<00:04,  3.41it/s, est. speed input: 3632.31 toks/s, output: 3.55 toks/s]
Processed prompts:  88%| | 113/128 [00:31<00:04,  3.41it/s, est. speed input: 3631.03 toks/s, output: 3.55 toks/s]
Processed prompts:  89%| | 114/128 [00:32<00:04,  3.41it/s, est. speed input: 3629.55 toks/s, output: 3.54 toks/s]
Processed prompts:  90%| | 115/128 [00:32<00:03,  3.41it/s, est. speed input: 3628.36 toks/s, output: 3.54 toks/s]
Processed prompts:  91%| | 116/128 [00:32<00:03,  3.42it/s, est. speed input: 3627.34 toks/s, output: 3.54 toks/s]
Processed prompts:  91%|| 117/128 [00:33<00:03,  3.39it/s, est. speed input: 3625.47 toks/s, output: 3.54 toks/s]
Processed prompts:  92%|| 118/128 [00:33<00:02,  3.40it/s, est. speed input: 3624.30 toks/s, output: 3.54 toks/s]
Processed prompts:  93%|| 119/128 [00:33<00:02,  3.42it/s, est. speed input: 3623.62 toks/s, output: 3.54 toks/s]
Processed prompts:  94%|| 120/128 [00:33<00:02,  3.44it/s, est. speed input: 3623.16 toks/s, output: 3.54 toks/s]
Processed prompts:  95%|| 121/128 [00:34<00:02,  3.42it/s, est. speed input: 3621.73 toks/s, output: 3.54 toks/s]
Processed prompts:  95%|| 122/128 [00:34<00:01,  3.42it/s, est. speed input: 3620.61 toks/s, output: 3.54 toks/s]
Processed prompts:  96%|| 123/128 [00:34<00:01,  3.42it/s, est. speed input: 3619.68 toks/s, output: 3.53 toks/s]
Processed prompts:  97%|| 124/128 [00:35<00:01,  3.40it/s, est. speed input: 3618.19 toks/s, output: 3.53 toks/s]
Processed prompts:  98%|| 125/128 [00:35<00:00,  3.40it/s, est. speed input: 3617.12 toks/s, output: 3.53 toks/s]
Processed prompts:  98%|| 126/128 [00:35<00:00,  3.40it/s, est. speed input: 3616.06 toks/s, output: 3.53 toks/s]
Processed prompts:  99%|| 127/128 [00:35<00:00,  3.42it/s, est. speed input: 3615.44 toks/s, output: 3.53 toks/s]
Processed prompts: 100%|| 128/128 [00:36<00:00,  3.40it/s, est. speed input: 3613.95 toks/s, output: 3.53 toks/s]
Processed prompts: 100%|| 128/128 [00:36<00:00,  3.40it/s, est. speed input: 3613.95 toks/s, output: 3.53 toks/s]
Processed prompts: 100%|| 128/128 [00:36<00:00,  3.53it/s, est. speed input: 3613.95 toks/s, output: 3.53 toks/s]
[rank0]:[W127 02:34:23.372364104 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-27 02:34:39
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-14B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 02:34:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 02:34:47 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2012754) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2012754) WARNING 01-27 02:37:14 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.25 requests/s, 3330.23 total tokens/s, 3.25 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-27 02:34:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 02:34:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:34:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 02:34:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:34:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:34:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:34:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:34:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:34:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:34:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 02:34:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 02:34:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 02:34:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 02:34:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 02:34:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 02:34:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:34:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 02:34:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:34:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:34:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:34:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:34:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:34:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:34:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 02:34:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 02:34:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 02:34:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 02:34:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2012754) [2026-01-27 02:34:51] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2012754) [2026-01-27 02:34:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2012754) [2026-01-27 02:34:51] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2012754) [2026-01-27 02:34:51] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=2012754) [2026-01-27 02:34:51] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=2012754) [2026-01-27 02:34:51] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=2012754) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2012754) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.56s/it]
(EngineCore_DP0 pid=2012754) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:48<00:53, 26.78s/it]
(EngineCore_DP0 pid=2012754) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:19<00:29, 29.05s/it]
(EngineCore_DP0 pid=2012754) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:01<00:00, 33.85s/it]
(EngineCore_DP0 pid=2012754) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:01<00:00, 30.26s/it]
(EngineCore_DP0 pid=2012754) 
(EngineCore_DP0 pid=2012754) [2026-01-27 02:36:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=2012754) [2026-01-27 02:36:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 41287680 bytes
(EngineCore_DP0 pid=2012754) [2026-01-27 02:36:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=2012754) [2026-01-27 02:36:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 29491200 bytes
(EngineCore_DP0 pid=2012754) [2026-01-27 02:36:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=2012754) [2026-01-27 02:36:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 159252480 bytes
(EngineCore_DP0 pid=2012754) [2026-01-27 02:36:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=2012754) [2026-01-27 02:36:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 79626240 bytes
(EngineCore_DP0 pid=2012754) 2026-01-27 02:37:05,927 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2012754) 2026-01-27 02:37:06,320 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/256 [00:00<03:37,  1.17it/s]
Adding requests:   1%|          | 2/256 [00:01<02:05,  2.02it/s]
Adding requests:   1%|          | 3/256 [00:01<01:24,  2.98it/s]
Adding requests:   2%|         | 4/256 [00:01<01:01,  4.09it/s]
Adding requests:   2%|         | 6/256 [00:01<00:39,  6.41it/s]
Adding requests:   3%|         | 8/256 [00:01<00:27,  8.94it/s]
Adding requests:   4%|         | 11/256 [00:01<00:18, 13.21it/s]
Adding requests:   5%|         | 14/256 [00:01<00:14, 16.31it/s]
Adding requests:  10%|         | 25/256 [00:01<00:06, 38.28it/s]
Adding requests:  16%|        | 41/256 [00:02<00:03, 68.86it/s]
Adding requests:  25%|       | 64/256 [00:02<00:01, 110.15it/s]
Adding requests:  36%|      | 92/256 [00:02<00:01, 156.02it/s]
Adding requests:  49%|     | 125/256 [00:02<00:00, 204.21it/s]
Adding requests:  63%|   | 162/256 [00:02<00:00, 250.42it/s]
Adding requests:  79%|  | 201/256 [00:02<00:00, 287.91it/s]
Adding requests:  90%| | 231/256 [00:02<00:00, 217.85it/s]
Adding requests: 100%|| 256/256 [00:02<00:00, 90.27it/s] 

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 6/256 [00:00<00:11, 22.71it/s, est. speed input: 23259.18 toks/s, output: 22.71 toks/s]
Processed prompts:   4%|         | 9/256 [00:00<00:27,  9.08it/s, est. speed input: 10570.28 toks/s, output: 10.32 toks/s]
Processed prompts:   4%|         | 11/256 [00:01<00:40,  6.08it/s, est. speed input: 7639.62 toks/s, output: 7.46 toks/s] 
Processed prompts:   5%|         | 12/256 [00:02<00:58,  4.19it/s, est. speed input: 5906.81 toks/s, output: 5.77 toks/s]
Processed prompts:   5%|         | 14/256 [00:02<01:02,  3.85it/s, est. speed input: 5336.01 toks/s, output: 5.21 toks/s]
Processed prompts:   6%|         | 16/256 [00:03<01:05,  3.66it/s, est. speed input: 4975.16 toks/s, output: 4.86 toks/s]
Processed prompts:   7%|         | 18/256 [00:03<01:07,  3.53it/s, est. speed input: 4722.49 toks/s, output: 4.61 toks/s]
Processed prompts:   8%|         | 20/256 [00:04<01:08,  3.47it/s, est. speed input: 4547.38 toks/s, output: 4.44 toks/s]
Processed prompts:   9%|         | 22/256 [00:05<01:08,  3.41it/s, est. speed input: 4408.67 toks/s, output: 4.31 toks/s]
Processed prompts:   9%|         | 24/256 [00:05<01:08,  3.38it/s, est. speed input: 4300.12 toks/s, output: 4.20 toks/s]
Processed prompts:  10%|         | 26/256 [00:06<01:08,  3.35it/s, est. speed input: 4210.81 toks/s, output: 4.11 toks/s]
Processed prompts:  11%|         | 28/256 [00:06<01:08,  3.34it/s, est. speed input: 4138.10 toks/s, output: 4.04 toks/s]
Processed prompts:  12%|        | 30/256 [00:07<01:08,  3.32it/s, est. speed input: 4074.82 toks/s, output: 3.98 toks/s]
Processed prompts:  12%|        | 32/256 [00:08<01:07,  3.31it/s, est. speed input: 4021.80 toks/s, output: 3.93 toks/s]
Processed prompts:  13%|        | 34/256 [00:08<01:06,  3.32it/s, est. speed input: 3979.91 toks/s, output: 3.89 toks/s]
Processed prompts:  14%|        | 36/256 [00:09<01:06,  3.30it/s, est. speed input: 3938.07 toks/s, output: 3.85 toks/s]
Processed prompts:  15%|        | 38/256 [00:09<01:06,  3.30it/s, est. speed input: 3904.40 toks/s, output: 3.81 toks/s]
Processed prompts:  16%|        | 40/256 [00:10<01:05,  3.30it/s, est. speed input: 3873.07 toks/s, output: 3.78 toks/s]
Processed prompts:  16%|        | 42/256 [00:11<01:05,  3.28it/s, est. speed input: 3843.14 toks/s, output: 3.75 toks/s]
Processed prompts:  17%|        | 44/256 [00:11<01:04,  3.28it/s, est. speed input: 3817.69 toks/s, output: 3.73 toks/s]
Processed prompts:  18%|        | 46/256 [00:12<01:04,  3.28it/s, est. speed input: 3795.01 toks/s, output: 3.71 toks/s]
Processed prompts:  19%|        | 48/256 [00:13<01:03,  3.29it/s, est. speed input: 3776.51 toks/s, output: 3.69 toks/s]
Processed prompts:  20%|        | 50/256 [00:13<01:02,  3.29it/s, est. speed input: 3757.64 toks/s, output: 3.67 toks/s]
Processed prompts:  20%|        | 52/256 [00:14<01:01,  3.30it/s, est. speed input: 3742.54 toks/s, output: 3.65 toks/s]
Processed prompts:  21%|        | 54/256 [00:14<01:01,  3.29it/s, est. speed input: 3726.30 toks/s, output: 3.64 toks/s]
Processed prompts:  22%|       | 56/256 [00:15<01:00,  3.29it/s, est. speed input: 3712.86 toks/s, output: 3.63 toks/s]
Processed prompts:  23%|       | 58/256 [00:16<01:00,  3.29it/s, est. speed input: 3700.10 toks/s, output: 3.61 toks/s]
Processed prompts:  23%|       | 60/256 [00:16<00:59,  3.29it/s, est. speed input: 3687.06 toks/s, output: 3.60 toks/s]
Processed prompts:  24%|       | 62/256 [00:17<00:58,  3.29it/s, est. speed input: 3676.42 toks/s, output: 3.59 toks/s]
Processed prompts:  25%|       | 64/256 [00:17<00:58,  3.29it/s, est. speed input: 3665.48 toks/s, output: 3.58 toks/s]
Processed prompts:  26%|       | 66/256 [00:18<00:57,  3.30it/s, est. speed input: 3656.80 toks/s, output: 3.57 toks/s]
Processed prompts:  27%|       | 68/256 [00:19<00:57,  3.29it/s, est. speed input: 3647.27 toks/s, output: 3.56 toks/s]
Processed prompts:  27%|       | 70/256 [00:19<00:56,  3.28it/s, est. speed input: 3637.58 toks/s, output: 3.55 toks/s]
Processed prompts:  28%|       | 72/256 [00:20<00:55,  3.29it/s, est. speed input: 3630.15 toks/s, output: 3.55 toks/s]
Processed prompts:  29%|       | 74/256 [00:20<00:55,  3.28it/s, est. speed input: 3621.89 toks/s, output: 3.54 toks/s]
Processed prompts:  30%|       | 76/256 [00:21<00:54,  3.29it/s, est. speed input: 3615.19 toks/s, output: 3.53 toks/s]
Processed prompts:  30%|       | 78/256 [00:22<00:54,  3.28it/s, est. speed input: 3607.89 toks/s, output: 3.52 toks/s]
Processed prompts:  31%|      | 80/256 [00:22<00:53,  3.29it/s, est. speed input: 3602.23 toks/s, output: 3.52 toks/s]
Processed prompts:  32%|      | 82/256 [00:23<00:52,  3.29it/s, est. speed input: 3595.70 toks/s, output: 3.51 toks/s]
Processed prompts:  33%|      | 84/256 [00:23<00:52,  3.28it/s, est. speed input: 3588.71 toks/s, output: 3.50 toks/s]
Processed prompts:  34%|      | 86/256 [00:24<00:51,  3.29it/s, est. speed input: 3583.98 toks/s, output: 3.50 toks/s]
Processed prompts:  34%|      | 88/256 [00:25<00:51,  3.28it/s, est. speed input: 3577.81 toks/s, output: 3.49 toks/s]
Processed prompts:  35%|      | 90/256 [00:25<00:50,  3.28it/s, est. speed input: 3573.10 toks/s, output: 3.49 toks/s]
Processed prompts:  36%|      | 92/256 [00:26<00:49,  3.28it/s, est. speed input: 3568.01 toks/s, output: 3.48 toks/s]
Processed prompts:  37%|      | 94/256 [00:27<00:49,  3.28it/s, est. speed input: 3563.52 toks/s, output: 3.48 toks/s]
Processed prompts:  38%|      | 96/256 [00:27<00:48,  3.28it/s, est. speed input: 3558.49 toks/s, output: 3.48 toks/s]
Processed prompts:  38%|      | 98/256 [00:28<00:48,  3.28it/s, est. speed input: 3554.09 toks/s, output: 3.47 toks/s]
Processed prompts:  39%|      | 100/256 [00:28<00:47,  3.28it/s, est. speed input: 3550.30 toks/s, output: 3.47 toks/s]
Processed prompts:  40%|      | 102/256 [00:29<00:47,  3.27it/s, est. speed input: 3545.59 toks/s, output: 3.46 toks/s]
Processed prompts:  41%|      | 104/256 [00:30<00:46,  3.28it/s, est. speed input: 3542.42 toks/s, output: 3.46 toks/s]
Processed prompts:  41%|     | 106/256 [00:30<00:45,  3.28it/s, est. speed input: 3538.73 toks/s, output: 3.46 toks/s]
Processed prompts:  42%|     | 108/256 [00:31<00:45,  3.29it/s, est. speed input: 3535.69 toks/s, output: 3.45 toks/s]
Processed prompts:  43%|     | 110/256 [00:31<00:44,  3.29it/s, est. speed input: 3532.42 toks/s, output: 3.45 toks/s]
Processed prompts:  44%|     | 112/256 [00:32<00:43,  3.28it/s, est. speed input: 3528.97 toks/s, output: 3.45 toks/s]
Processed prompts:  45%|     | 114/256 [00:33<00:43,  3.29it/s, est. speed input: 3526.19 toks/s, output: 3.44 toks/s]
Processed prompts:  45%|     | 116/256 [00:33<00:42,  3.28it/s, est. speed input: 3523.00 toks/s, output: 3.44 toks/s]
Processed prompts:  46%|     | 118/256 [00:34<00:41,  3.29it/s, est. speed input: 3520.60 toks/s, output: 3.44 toks/s]
Processed prompts:  47%|     | 120/256 [00:34<00:41,  3.28it/s, est. speed input: 3517.53 toks/s, output: 3.44 toks/s]
Processed prompts:  48%|     | 122/256 [00:35<00:40,  3.28it/s, est. speed input: 3514.66 toks/s, output: 3.43 toks/s]
Processed prompts:  48%|     | 124/256 [00:36<00:40,  3.29it/s, est. speed input: 3512.62 toks/s, output: 3.43 toks/s]
Processed prompts:  49%|     | 126/256 [00:36<00:39,  3.28it/s, est. speed input: 3509.51 toks/s, output: 3.43 toks/s]
Processed prompts:  50%|     | 128/256 [00:37<00:38,  3.28it/s, est. speed input: 3507.41 toks/s, output: 3.43 toks/s]
Processed prompts:  51%|     | 130/256 [00:37<00:38,  3.27it/s, est. speed input: 3504.40 toks/s, output: 3.42 toks/s]
Processed prompts:  52%|    | 132/256 [00:38<00:37,  3.28it/s, est. speed input: 3502.51 toks/s, output: 3.42 toks/s]
Processed prompts:  52%|    | 134/256 [00:39<00:37,  3.28it/s, est. speed input: 3500.11 toks/s, output: 3.42 toks/s]
Processed prompts:  53%|    | 136/256 [00:39<00:36,  3.28it/s, est. speed input: 3497.84 toks/s, output: 3.42 toks/s]
Processed prompts:  54%|    | 138/256 [00:40<00:35,  3.28it/s, est. speed input: 3496.04 toks/s, output: 3.41 toks/s]
Processed prompts:  55%|    | 140/256 [00:41<00:35,  3.28it/s, est. speed input: 3493.96 toks/s, output: 3.41 toks/s]
Processed prompts:  55%|    | 142/256 [00:41<00:34,  3.28it/s, est. speed input: 3492.17 toks/s, output: 3.41 toks/s]
Processed prompts:  56%|    | 144/256 [00:42<00:34,  3.28it/s, est. speed input: 3490.25 toks/s, output: 3.41 toks/s]
Processed prompts:  57%|    | 146/256 [00:42<00:33,  3.29it/s, est. speed input: 3488.64 toks/s, output: 3.41 toks/s]
Processed prompts:  58%|    | 148/256 [00:43<00:32,  3.28it/s, est. speed input: 3486.71 toks/s, output: 3.40 toks/s]
Processed prompts:  59%|    | 150/256 [00:44<00:32,  3.28it/s, est. speed input: 3484.85 toks/s, output: 3.40 toks/s]
Processed prompts:  59%|    | 152/256 [00:44<00:31,  3.29it/s, est. speed input: 3483.41 toks/s, output: 3.40 toks/s]
Processed prompts:  60%|    | 154/256 [00:45<00:31,  3.29it/s, est. speed input: 3481.78 toks/s, output: 3.40 toks/s]
Processed prompts:  61%|    | 156/256 [00:45<00:30,  3.29it/s, est. speed input: 3480.38 toks/s, output: 3.40 toks/s]
Processed prompts:  62%|   | 158/256 [00:46<00:29,  3.28it/s, est. speed input: 3478.71 toks/s, output: 3.40 toks/s]
Processed prompts:  62%|   | 160/256 [00:47<00:29,  3.28it/s, est. speed input: 3477.01 toks/s, output: 3.40 toks/s]
Processed prompts:  63%|   | 162/256 [00:47<00:28,  3.28it/s, est. speed input: 3475.51 toks/s, output: 3.39 toks/s]
Processed prompts:  64%|   | 164/256 [00:48<00:28,  3.28it/s, est. speed input: 3473.87 toks/s, output: 3.39 toks/s]
Processed prompts:  65%|   | 166/256 [00:48<00:27,  3.28it/s, est. speed input: 3472.65 toks/s, output: 3.39 toks/s]
Processed prompts:  66%|   | 168/256 [00:49<00:26,  3.27it/s, est. speed input: 3470.92 toks/s, output: 3.39 toks/s]
Processed prompts:  66%|   | 170/256 [00:50<00:26,  3.28it/s, est. speed input: 3469.80 toks/s, output: 3.39 toks/s]
Processed prompts:  67%|   | 172/256 [00:50<00:25,  3.27it/s, est. speed input: 3468.20 toks/s, output: 3.39 toks/s]
Processed prompts:  68%|   | 174/256 [00:51<00:25,  3.27it/s, est. speed input: 3466.57 toks/s, output: 3.39 toks/s]
Processed prompts:  69%|   | 176/256 [00:52<00:24,  3.27it/s, est. speed input: 3465.42 toks/s, output: 3.38 toks/s]
Processed prompts:  70%|   | 178/256 [00:52<00:23,  3.27it/s, est. speed input: 3463.83 toks/s, output: 3.38 toks/s]
Processed prompts:  70%|   | 180/256 [00:53<00:23,  3.28it/s, est. speed input: 3462.86 toks/s, output: 3.38 toks/s]
Processed prompts:  71%|   | 182/256 [00:53<00:22,  3.27it/s, est. speed input: 3461.32 toks/s, output: 3.38 toks/s]
Processed prompts:  72%|  | 184/256 [00:54<00:22,  3.27it/s, est. speed input: 3460.07 toks/s, output: 3.38 toks/s]
Processed prompts:  73%|  | 186/256 [00:55<00:21,  3.27it/s, est. speed input: 3458.73 toks/s, output: 3.38 toks/s]
Processed prompts:  73%|  | 188/256 [00:55<00:20,  3.26it/s, est. speed input: 3457.23 toks/s, output: 3.38 toks/s]
Processed prompts:  74%|  | 190/256 [00:56<00:20,  3.27it/s, est. speed input: 3456.46 toks/s, output: 3.38 toks/s]
Processed prompts:  75%|  | 192/256 [00:56<00:19,  3.27it/s, est. speed input: 3455.13 toks/s, output: 3.37 toks/s]
Processed prompts:  76%|  | 194/256 [00:57<00:18,  3.28it/s, est. speed input: 3454.24 toks/s, output: 3.37 toks/s]
Processed prompts:  77%|  | 196/256 [00:58<00:18,  3.26it/s, est. speed input: 3452.55 toks/s, output: 3.37 toks/s]
Processed prompts:  77%|  | 198/256 [00:58<00:17,  3.28it/s, est. speed input: 3452.07 toks/s, output: 3.37 toks/s]
Processed prompts:  78%|  | 200/256 [00:59<00:17,  3.29it/s, est. speed input: 3451.37 toks/s, output: 3.37 toks/s]
Processed prompts:  79%|  | 202/256 [00:59<00:14,  3.73it/s, est. speed input: 3464.53 toks/s, output: 3.38 toks/s]
Processed prompts:  80%|  | 204/256 [01:00<00:14,  3.58it/s, est. speed input: 3463.19 toks/s, output: 3.38 toks/s]
Processed prompts:  80%|  | 206/256 [01:00<00:14,  3.47it/s, est. speed input: 3461.89 toks/s, output: 3.38 toks/s]
Processed prompts:  81%| | 208/256 [01:01<00:14,  3.42it/s, est. speed input: 3461.03 toks/s, output: 3.38 toks/s]
Processed prompts:  82%| | 210/256 [01:02<00:13,  3.37it/s, est. speed input: 3459.81 toks/s, output: 3.38 toks/s]
Processed prompts:  83%| | 212/256 [01:02<00:13,  3.34it/s, est. speed input: 3458.92 toks/s, output: 3.38 toks/s]
Processed prompts:  84%| | 214/256 [01:03<00:12,  3.32it/s, est. speed input: 3457.72 toks/s, output: 3.38 toks/s]
Processed prompts:  84%| | 216/256 [01:03<00:12,  3.30it/s, est. speed input: 3456.71 toks/s, output: 3.38 toks/s]
Processed prompts:  85%| | 218/256 [01:04<00:11,  3.30it/s, est. speed input: 3455.96 toks/s, output: 3.37 toks/s]
Processed prompts:  86%| | 220/256 [01:05<00:10,  3.30it/s, est. speed input: 3455.05 toks/s, output: 3.37 toks/s]
Processed prompts:  87%| | 222/256 [01:05<00:10,  3.29it/s, est. speed input: 3454.22 toks/s, output: 3.37 toks/s]
Processed prompts:  88%| | 224/256 [01:06<00:09,  3.29it/s, est. speed input: 3453.33 toks/s, output: 3.37 toks/s]
Processed prompts:  88%| | 226/256 [01:07<00:09,  3.29it/s, est. speed input: 3452.73 toks/s, output: 3.37 toks/s]
Processed prompts:  89%| | 228/256 [01:07<00:08,  3.28it/s, est. speed input: 3451.54 toks/s, output: 3.37 toks/s]
Processed prompts:  90%| | 230/256 [01:08<00:07,  3.28it/s, est. speed input: 3450.65 toks/s, output: 3.37 toks/s]
Processed prompts:  91%| | 232/256 [01:08<00:07,  3.29it/s, est. speed input: 3450.09 toks/s, output: 3.37 toks/s]
Processed prompts:  91%|| 234/256 [01:09<00:06,  3.28it/s, est. speed input: 3449.12 toks/s, output: 3.37 toks/s]
Processed prompts:  92%|| 236/256 [01:10<00:06,  3.29it/s, est. speed input: 3448.63 toks/s, output: 3.37 toks/s]
Processed prompts:  93%|| 238/256 [01:10<00:05,  3.28it/s, est. speed input: 3447.70 toks/s, output: 3.37 toks/s]
Processed prompts:  94%|| 240/256 [01:11<00:04,  3.29it/s, est. speed input: 3447.10 toks/s, output: 3.37 toks/s]
Processed prompts:  95%|| 242/256 [01:11<00:04,  3.28it/s, est. speed input: 3446.16 toks/s, output: 3.37 toks/s]
Processed prompts:  95%|| 244/256 [01:12<00:03,  3.27it/s, est. speed input: 3445.25 toks/s, output: 3.36 toks/s]
Processed prompts:  96%|| 246/256 [01:13<00:03,  3.28it/s, est. speed input: 3444.81 toks/s, output: 3.36 toks/s]
Processed prompts:  97%|| 248/256 [01:13<00:02,  3.27it/s, est. speed input: 3443.75 toks/s, output: 3.36 toks/s]
Processed prompts:  98%|| 250/256 [01:14<00:01,  3.28it/s, est. speed input: 3443.31 toks/s, output: 3.36 toks/s]
Processed prompts:  98%|| 252/256 [01:14<00:01,  3.27it/s, est. speed input: 3442.30 toks/s, output: 3.36 toks/s]
Processed prompts:  99%|| 254/256 [01:15<00:00,  3.28it/s, est. speed input: 3441.83 toks/s, output: 3.36 toks/s]
Processed prompts: 100%|| 256/256 [01:15<00:00,  3.85it/s, est. speed input: 3454.80 toks/s, output: 3.37 toks/s]
Processed prompts: 100%|| 256/256 [01:15<00:00,  3.85it/s, est. speed input: 3454.80 toks/s, output: 3.37 toks/s]
Processed prompts: 100%|| 256/256 [01:15<00:00,  3.37it/s, est. speed input: 3454.80 toks/s, output: 3.37 toks/s]
[rank0]:[W127 02:38:33.755435703 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-27 02:38:46
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-14B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 02:38:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 02:38:55 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2016364) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2016364) WARNING 01-27 02:41:25 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.28 requests/s, 3358.29 total tokens/s, 3.28 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-27 02:38:55] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 02:38:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:38:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 02:38:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:38:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:38:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:38:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:38:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:38:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:38:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 02:38:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 02:38:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 02:38:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 02:38:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 02:38:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 02:38:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:38:59] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 02:38:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:38:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:38:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:38:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:38:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:38:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:38:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 02:38:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 02:38:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 02:38:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 02:38:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2016364) [2026-01-27 02:39:00] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2016364) [2026-01-27 02:39:00] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2016364) [2026-01-27 02:39:00] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2016364) [2026-01-27 02:39:00] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=2016364) [2026-01-27 02:39:00] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=2016364) [2026-01-27 02:39:00] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=2016364) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2016364) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.61s/it]
(EngineCore_DP0 pid=2016364) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:48<00:54, 27.06s/it]
(EngineCore_DP0 pid=2016364) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:20<00:29, 29.10s/it]
(EngineCore_DP0 pid=2016364) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:01<00:00, 33.97s/it]
(EngineCore_DP0 pid=2016364) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:01<00:00, 30.39s/it]
(EngineCore_DP0 pid=2016364) 
(EngineCore_DP0 pid=2016364) [2026-01-27 02:41:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=2016364) [2026-01-27 02:41:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 41287680 bytes
(EngineCore_DP0 pid=2016364) [2026-01-27 02:41:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=2016364) [2026-01-27 02:41:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 29491200 bytes
(EngineCore_DP0 pid=2016364) [2026-01-27 02:41:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=2016364) [2026-01-27 02:41:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 159252480 bytes
(EngineCore_DP0 pid=2016364) [2026-01-27 02:41:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=2016364) [2026-01-27 02:41:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 79626240 bytes
(EngineCore_DP0 pid=2016364) 2026-01-27 02:41:15,780 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2016364) 2026-01-27 02:41:16,476 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/512 [00:00<08:23,  1.02it/s]
Adding requests:   0%|          | 2/512 [00:01<04:29,  1.89it/s]
Adding requests:   1%|          | 3/512 [00:01<02:57,  2.87it/s]
Adding requests:   1%|          | 5/512 [00:01<01:47,  4.72it/s]
Adding requests:   1%|         | 7/512 [00:01<01:11,  7.04it/s]
Adding requests:   2%|         | 10/512 [00:01<00:46, 10.84it/s]
Adding requests:   3%|         | 13/512 [00:01<00:34, 14.50it/s]
Adding requests:   4%|         | 21/512 [00:01<00:16, 28.89it/s]
Adding requests:   8%|         | 40/512 [00:02<00:07, 67.05it/s]
Adding requests:  11%|        | 58/512 [00:02<00:04, 95.45it/s]
Adding requests:  17%|        | 89/512 [00:02<00:02, 152.17it/s]
Adding requests:  24%|       | 121/512 [00:02<00:01, 195.68it/s]
Adding requests:  31%|      | 160/512 [00:02<00:01, 248.46it/s]
Adding requests:  40%|      | 204/512 [00:02<00:01, 302.18it/s]
Adding requests:  47%|     | 242/512 [00:02<00:00, 323.32it/s]
Adding requests:  55%|    | 283/512 [00:02<00:00, 346.24it/s]
Adding requests:  64%|   | 326/512 [00:02<00:00, 368.76it/s]
Adding requests:  73%|  | 372/512 [00:03<00:00, 394.88it/s]
Adding requests:  82%| | 420/512 [00:03<00:00, 415.48it/s]
Adding requests:  91%| | 466/512 [00:03<00:00, 427.84it/s]
Adding requests: 100%|| 512/512 [00:03<00:00, 154.96it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 8/512 [00:01<01:11,  7.08it/s, est. speed input: 7246.23 toks/s, output: 7.08 toks/s]
Processed prompts:   2%|         | 12/512 [00:02<01:43,  4.82it/s, est. speed input: 5274.86 toks/s, output: 5.15 toks/s]
Processed prompts:   3%|         | 16/512 [00:03<02:00,  4.12it/s, est. speed input: 4633.68 toks/s, output: 4.53 toks/s]
Processed prompts:   4%|         | 20/512 [00:04<02:09,  3.79it/s, est. speed input: 4313.29 toks/s, output: 4.21 toks/s]
Processed prompts:   5%|         | 24/512 [00:05<02:14,  3.63it/s, est. speed input: 4131.99 toks/s, output: 4.04 toks/s]
Processed prompts:   5%|         | 28/512 [00:07<02:17,  3.52it/s, est. speed input: 4006.52 toks/s, output: 3.91 toks/s]
Processed prompts:   6%|         | 32/512 [00:08<02:19,  3.45it/s, est. speed input: 3918.57 toks/s, output: 3.83 toks/s]
Processed prompts:   7%|         | 36/512 [00:09<02:19,  3.41it/s, est. speed input: 3853.19 toks/s, output: 3.76 toks/s]
Processed prompts:   8%|         | 40/512 [00:10<02:19,  3.38it/s, est. speed input: 3802.23 toks/s, output: 3.71 toks/s]
Processed prompts:   9%|         | 44/512 [00:11<02:19,  3.36it/s, est. speed input: 3759.47 toks/s, output: 3.67 toks/s]
Processed prompts:   9%|         | 48/512 [00:13<02:19,  3.34it/s, est. speed input: 3723.85 toks/s, output: 3.64 toks/s]
Processed prompts:  10%|         | 52/512 [00:14<02:18,  3.33it/s, est. speed input: 3695.85 toks/s, output: 3.61 toks/s]
Processed prompts:  11%|         | 56/512 [00:15<02:17,  3.32it/s, est. speed input: 3671.43 toks/s, output: 3.59 toks/s]
Processed prompts:  12%|        | 60/512 [00:16<02:16,  3.31it/s, est. speed input: 3650.01 toks/s, output: 3.56 toks/s]
Processed prompts:  12%|        | 64/512 [00:18<02:15,  3.31it/s, est. speed input: 3632.58 toks/s, output: 3.55 toks/s]
Processed prompts:  13%|        | 68/512 [00:19<02:14,  3.31it/s, est. speed input: 3616.70 toks/s, output: 3.53 toks/s]
Processed prompts:  14%|        | 72/512 [00:20<02:13,  3.31it/s, est. speed input: 3602.78 toks/s, output: 3.52 toks/s]
Processed prompts:  15%|        | 76/512 [00:21<02:12,  3.30it/s, est. speed input: 3589.78 toks/s, output: 3.51 toks/s]
Processed prompts:  16%|        | 80/512 [00:22<02:10,  3.30it/s, est. speed input: 3578.82 toks/s, output: 3.49 toks/s]
Processed prompts:  16%|        | 84/512 [00:24<02:09,  3.31it/s, est. speed input: 3569.42 toks/s, output: 3.49 toks/s]
Processed prompts:  17%|        | 88/512 [00:25<02:08,  3.31it/s, est. speed input: 3560.82 toks/s, output: 3.48 toks/s]
Processed prompts:  18%|        | 92/512 [00:26<02:07,  3.30it/s, est. speed input: 3552.28 toks/s, output: 3.47 toks/s]
Processed prompts:  19%|        | 96/512 [00:27<02:05,  3.31it/s, est. speed input: 3545.41 toks/s, output: 3.46 toks/s]
Processed prompts:  20%|        | 100/512 [00:28<02:04,  3.30it/s, est. speed input: 3537.86 toks/s, output: 3.45 toks/s]
Processed prompts:  20%|        | 104/512 [00:30<02:03,  3.30it/s, est. speed input: 3530.98 toks/s, output: 3.45 toks/s]
Processed prompts:  21%|        | 108/512 [00:31<02:02,  3.29it/s, est. speed input: 3524.47 toks/s, output: 3.44 toks/s]
Processed prompts:  22%|       | 112/512 [00:32<02:01,  3.29it/s, est. speed input: 3518.77 toks/s, output: 3.44 toks/s]
Processed prompts:  23%|       | 116/512 [00:33<02:00,  3.30it/s, est. speed input: 3513.86 toks/s, output: 3.43 toks/s]
Processed prompts:  23%|       | 120/512 [00:35<01:58,  3.29it/s, est. speed input: 3508.87 toks/s, output: 3.43 toks/s]
Processed prompts:  24%|       | 124/512 [00:36<01:57,  3.29it/s, est. speed input: 3503.87 toks/s, output: 3.42 toks/s]
Processed prompts:  25%|       | 128/512 [00:37<01:56,  3.30it/s, est. speed input: 3500.07 toks/s, output: 3.42 toks/s]
Processed prompts:  26%|       | 132/512 [00:38<01:55,  3.29it/s, est. speed input: 3495.91 toks/s, output: 3.41 toks/s]
Processed prompts:  27%|       | 136/512 [00:39<01:54,  3.29it/s, est. speed input: 3491.77 toks/s, output: 3.41 toks/s]
Processed prompts:  27%|       | 140/512 [00:41<01:53,  3.29it/s, est. speed input: 3488.13 toks/s, output: 3.41 toks/s]
Processed prompts:  28%|       | 144/512 [00:42<01:51,  3.29it/s, est. speed input: 3484.68 toks/s, output: 3.40 toks/s]
Processed prompts:  29%|       | 148/512 [00:43<01:50,  3.29it/s, est. speed input: 3481.68 toks/s, output: 3.40 toks/s]
Processed prompts:  30%|       | 152/512 [00:44<01:49,  3.29it/s, est. speed input: 3478.39 toks/s, output: 3.40 toks/s]
Processed prompts:  30%|       | 156/512 [00:45<01:48,  3.29it/s, est. speed input: 3475.31 toks/s, output: 3.39 toks/s]
Processed prompts:  31%|      | 160/512 [00:47<01:47,  3.29it/s, est. speed input: 3472.33 toks/s, output: 3.39 toks/s]
Processed prompts:  32%|      | 164/512 [00:48<01:45,  3.29it/s, est. speed input: 3469.64 toks/s, output: 3.39 toks/s]
Processed prompts:  33%|      | 168/512 [00:49<01:44,  3.29it/s, est. speed input: 3467.01 toks/s, output: 3.39 toks/s]
Processed prompts:  34%|      | 172/512 [00:50<01:43,  3.28it/s, est. speed input: 3464.42 toks/s, output: 3.38 toks/s]
Processed prompts:  34%|      | 176/512 [00:52<01:42,  3.29it/s, est. speed input: 3462.18 toks/s, output: 3.38 toks/s]
Processed prompts:  35%|      | 180/512 [00:53<01:40,  3.29it/s, est. speed input: 3460.13 toks/s, output: 3.38 toks/s]
Processed prompts:  36%|      | 184/512 [00:54<01:39,  3.29it/s, est. speed input: 3458.30 toks/s, output: 3.38 toks/s]
Processed prompts:  37%|      | 188/512 [00:55<01:38,  3.30it/s, est. speed input: 3456.74 toks/s, output: 3.38 toks/s]
Processed prompts:  38%|      | 192/512 [00:56<01:37,  3.29it/s, est. speed input: 3454.77 toks/s, output: 3.37 toks/s]
Processed prompts:  38%|      | 196/512 [00:58<01:36,  3.29it/s, est. speed input: 3452.80 toks/s, output: 3.37 toks/s]
Processed prompts:  39%|      | 200/512 [00:59<01:29,  3.49it/s, est. speed input: 3464.81 toks/s, output: 3.38 toks/s]
Processed prompts:  40%|      | 204/512 [01:00<01:29,  3.43it/s, est. speed input: 3462.77 toks/s, output: 3.38 toks/s]
Processed prompts:  41%|      | 208/512 [01:01<01:30,  3.38it/s, est. speed input: 3460.29 toks/s, output: 3.38 toks/s]
Processed prompts:  41%|     | 212/512 [01:02<01:29,  3.35it/s, est. speed input: 3458.45 toks/s, output: 3.38 toks/s]
Processed prompts:  42%|     | 216/512 [01:03<01:28,  3.33it/s, est. speed input: 3456.69 toks/s, output: 3.38 toks/s]
Processed prompts:  43%|     | 220/512 [01:05<01:27,  3.32it/s, est. speed input: 3455.20 toks/s, output: 3.37 toks/s]
Processed prompts:  44%|     | 224/512 [01:06<01:27,  3.31it/s, est. speed input: 3453.49 toks/s, output: 3.37 toks/s]
Processed prompts:  45%|     | 228/512 [01:07<01:26,  3.30it/s, est. speed input: 3451.67 toks/s, output: 3.37 toks/s]
Processed prompts:  45%|     | 232/512 [01:08<01:25,  3.29it/s, est. speed input: 3449.95 toks/s, output: 3.37 toks/s]
Processed prompts:  46%|     | 236/512 [01:10<01:23,  3.29it/s, est. speed input: 3448.39 toks/s, output: 3.37 toks/s]
Processed prompts:  47%|     | 240/512 [01:11<01:22,  3.29it/s, est. speed input: 3446.99 toks/s, output: 3.37 toks/s]
Processed prompts:  48%|     | 244/512 [01:12<01:21,  3.29it/s, est. speed input: 3445.75 toks/s, output: 3.36 toks/s]
Processed prompts:  48%|     | 248/512 [01:13<01:20,  3.29it/s, est. speed input: 3444.61 toks/s, output: 3.36 toks/s]
Processed prompts:  49%|     | 252/512 [01:14<01:19,  3.29it/s, est. speed input: 3443.19 toks/s, output: 3.36 toks/s]
Processed prompts:  50%|     | 256/512 [01:16<01:17,  3.28it/s, est. speed input: 3441.78 toks/s, output: 3.36 toks/s]
Processed prompts:  51%|     | 260/512 [01:17<01:16,  3.28it/s, est. speed input: 3440.29 toks/s, output: 3.36 toks/s]
Processed prompts:  52%|    | 264/512 [01:18<01:15,  3.28it/s, est. speed input: 3439.16 toks/s, output: 3.36 toks/s]
Processed prompts:  52%|    | 268/512 [01:19<01:14,  3.28it/s, est. speed input: 3438.00 toks/s, output: 3.36 toks/s]
Processed prompts:  53%|    | 272/512 [01:21<01:13,  3.28it/s, est. speed input: 3436.72 toks/s, output: 3.36 toks/s]
Processed prompts:  54%|    | 276/512 [01:22<01:11,  3.28it/s, est. speed input: 3435.60 toks/s, output: 3.36 toks/s]
Processed prompts:  55%|    | 280/512 [01:23<01:10,  3.28it/s, est. speed input: 3434.48 toks/s, output: 3.35 toks/s]
Processed prompts:  55%|    | 284/512 [01:24<01:09,  3.28it/s, est. speed input: 3433.23 toks/s, output: 3.35 toks/s]
Processed prompts:  56%|    | 288/512 [01:25<01:08,  3.28it/s, est. speed input: 3432.08 toks/s, output: 3.35 toks/s]
Processed prompts:  57%|    | 292/512 [01:27<01:07,  3.28it/s, est. speed input: 3430.99 toks/s, output: 3.35 toks/s]
Processed prompts:  58%|    | 296/512 [01:28<01:05,  3.28it/s, est. speed input: 3430.05 toks/s, output: 3.35 toks/s]
Processed prompts:  59%|    | 300/512 [01:29<01:04,  3.28it/s, est. speed input: 3429.33 toks/s, output: 3.35 toks/s]
Processed prompts:  59%|    | 304/512 [01:30<00:59,  3.49it/s, est. speed input: 3437.67 toks/s, output: 3.36 toks/s]
Processed prompts:  60%|    | 308/512 [01:31<00:59,  3.43it/s, est. speed input: 3436.78 toks/s, output: 3.36 toks/s]
Processed prompts:  61%|    | 312/512 [01:32<00:59,  3.39it/s, est. speed input: 3435.93 toks/s, output: 3.36 toks/s]
Processed prompts:  62%|   | 316/512 [01:34<00:58,  3.35it/s, est. speed input: 3434.81 toks/s, output: 3.35 toks/s]
Processed prompts:  62%|   | 320/512 [01:35<00:57,  3.33it/s, est. speed input: 3433.97 toks/s, output: 3.35 toks/s]
Processed prompts:  63%|   | 324/512 [01:36<00:56,  3.32it/s, est. speed input: 3433.15 toks/s, output: 3.35 toks/s]
Processed prompts:  64%|   | 328/512 [01:37<00:55,  3.30it/s, est. speed input: 3431.83 toks/s, output: 3.35 toks/s]
Processed prompts:  65%|   | 332/512 [01:39<00:54,  3.30it/s, est. speed input: 3431.27 toks/s, output: 3.35 toks/s]
Processed prompts:  66%|   | 336/512 [01:40<00:53,  3.30it/s, est. speed input: 3430.46 toks/s, output: 3.35 toks/s]
Processed prompts:  66%|   | 340/512 [01:41<00:52,  3.29it/s, est. speed input: 3429.64 toks/s, output: 3.35 toks/s]
Processed prompts:  67%|   | 344/512 [01:42<00:51,  3.29it/s, est. speed input: 3428.66 toks/s, output: 3.35 toks/s]
Processed prompts:  68%|   | 348/512 [01:43<00:49,  3.29it/s, est. speed input: 3427.93 toks/s, output: 3.35 toks/s]
Processed prompts:  69%|   | 352/512 [01:45<00:48,  3.28it/s, est. speed input: 3426.99 toks/s, output: 3.35 toks/s]
Processed prompts:  70%|   | 356/512 [01:46<00:47,  3.28it/s, est. speed input: 3426.19 toks/s, output: 3.35 toks/s]
Processed prompts:  70%|   | 360/512 [01:47<00:46,  3.28it/s, est. speed input: 3425.34 toks/s, output: 3.35 toks/s]
Processed prompts:  71%|   | 364/512 [01:48<00:45,  3.28it/s, est. speed input: 3424.84 toks/s, output: 3.34 toks/s]
Processed prompts:  72%|  | 368/512 [01:50<00:43,  3.28it/s, est. speed input: 3424.06 toks/s, output: 3.34 toks/s]
Processed prompts:  73%|  | 372/512 [01:51<00:42,  3.28it/s, est. speed input: 3423.31 toks/s, output: 3.34 toks/s]
Processed prompts:  73%|  | 376/512 [01:52<00:41,  3.29it/s, est. speed input: 3422.86 toks/s, output: 3.34 toks/s]
Processed prompts:  74%|  | 380/512 [01:53<00:40,  3.29it/s, est. speed input: 3422.36 toks/s, output: 3.34 toks/s]
Processed prompts:  75%|  | 384/512 [01:54<00:38,  3.29it/s, est. speed input: 3421.72 toks/s, output: 3.34 toks/s]
Processed prompts:  76%|  | 388/512 [01:56<00:37,  3.29it/s, est. speed input: 3421.06 toks/s, output: 3.34 toks/s]
Processed prompts:  77%|  | 392/512 [01:57<00:36,  3.28it/s, est. speed input: 3420.40 toks/s, output: 3.34 toks/s]
Processed prompts:  77%|  | 396/512 [01:58<00:35,  3.29it/s, est. speed input: 3419.87 toks/s, output: 3.34 toks/s]
Processed prompts:  78%|  | 400/512 [01:59<00:34,  3.29it/s, est. speed input: 3419.29 toks/s, output: 3.34 toks/s]
Processed prompts:  79%|  | 404/512 [02:01<00:32,  3.28it/s, est. speed input: 3418.68 toks/s, output: 3.34 toks/s]
Processed prompts:  80%|  | 408/512 [02:02<00:31,  3.29it/s, est. speed input: 3418.23 toks/s, output: 3.34 toks/s]
Processed prompts:  80%|  | 412/512 [02:03<00:30,  3.28it/s, est. speed input: 3417.65 toks/s, output: 3.34 toks/s]
Processed prompts:  81%| | 416/512 [02:04<00:29,  3.28it/s, est. speed input: 3417.08 toks/s, output: 3.34 toks/s]
Processed prompts:  82%| | 420/512 [02:05<00:28,  3.28it/s, est. speed input: 3416.57 toks/s, output: 3.34 toks/s]
Processed prompts:  83%| | 424/512 [02:07<00:26,  3.29it/s, est. speed input: 3416.14 toks/s, output: 3.34 toks/s]
Processed prompts:  84%| | 428/512 [02:08<00:25,  3.29it/s, est. speed input: 3415.65 toks/s, output: 3.34 toks/s]
Processed prompts:  84%| | 432/512 [02:09<00:24,  3.28it/s, est. speed input: 3415.09 toks/s, output: 3.34 toks/s]
Processed prompts:  85%| | 436/512 [02:10<00:21,  3.50it/s, est. speed input: 3421.14 toks/s, output: 3.34 toks/s]
Processed prompts:  86%| | 440/512 [02:11<00:20,  3.43it/s, est. speed input: 3420.70 toks/s, output: 3.34 toks/s]
Processed prompts:  87%| | 444/512 [02:12<00:20,  3.39it/s, est. speed input: 3420.24 toks/s, output: 3.34 toks/s]
Processed prompts:  88%| | 448/512 [02:14<00:19,  3.36it/s, est. speed input: 3419.71 toks/s, output: 3.34 toks/s]
Processed prompts:  88%| | 452/512 [02:15<00:18,  3.33it/s, est. speed input: 3419.14 toks/s, output: 3.34 toks/s]
Processed prompts:  89%| | 456/512 [02:16<00:16,  3.32it/s, est. speed input: 3418.65 toks/s, output: 3.34 toks/s]
Processed prompts:  90%| | 460/512 [02:17<00:15,  3.31it/s, est. speed input: 3418.07 toks/s, output: 3.34 toks/s]
Processed prompts:  91%| | 464/512 [02:19<00:14,  3.30it/s, est. speed input: 3417.63 toks/s, output: 3.34 toks/s]
Processed prompts:  91%|| 468/512 [02:20<00:13,  3.29it/s, est. speed input: 3417.09 toks/s, output: 3.34 toks/s]
Processed prompts:  92%|| 472/512 [02:21<00:12,  3.29it/s, est. speed input: 3416.64 toks/s, output: 3.34 toks/s]
Processed prompts:  93%|| 476/512 [02:22<00:10,  3.28it/s, est. speed input: 3416.00 toks/s, output: 3.34 toks/s]
Processed prompts:  94%|| 480/512 [02:23<00:09,  3.28it/s, est. speed input: 3415.56 toks/s, output: 3.34 toks/s]
Processed prompts:  95%|| 484/512 [02:25<00:08,  3.28it/s, est. speed input: 3415.09 toks/s, output: 3.34 toks/s]
Processed prompts:  95%|| 488/512 [02:26<00:07,  3.28it/s, est. speed input: 3414.68 toks/s, output: 3.33 toks/s]
Processed prompts:  96%|| 492/512 [02:27<00:06,  3.29it/s, est. speed input: 3414.42 toks/s, output: 3.33 toks/s]
Processed prompts:  97%|| 496/512 [02:28<00:04,  3.29it/s, est. speed input: 3414.00 toks/s, output: 3.33 toks/s]
Processed prompts:  98%|| 500/512 [02:29<00:03,  3.29it/s, est. speed input: 3413.69 toks/s, output: 3.33 toks/s]
Processed prompts:  98%|| 504/512 [02:31<00:02,  3.29it/s, est. speed input: 3413.19 toks/s, output: 3.33 toks/s]
Processed prompts:  99%|| 508/512 [02:32<00:01,  3.29it/s, est. speed input: 3412.84 toks/s, output: 3.33 toks/s]
Processed prompts: 100%|| 512/512 [02:32<00:00,  4.24it/s, est. speed input: 3432.86 toks/s, output: 3.35 toks/s]
Processed prompts: 100%|| 512/512 [02:32<00:00,  4.24it/s, est. speed input: 3432.86 toks/s, output: 3.35 toks/s]
Processed prompts: 100%|| 512/512 [02:32<00:00,  3.35it/s, est. speed input: 3432.86 toks/s, output: 3.35 toks/s]
[rank0]:[W127 02:44:02.891633401 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-27 02:44:17
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-14B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 02:44:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 02:44:27 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2021124) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2021124) WARNING 01-27 02:46:58 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.29 requests/s, 3376.70 total tokens/s, 3.29 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-27 02:44:27] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 02:44:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:44:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 02:44:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:44:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:44:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:44:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:44:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:44:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:44:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 02:44:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 02:44:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 02:44:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 02:44:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 02:44:31] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 02:44:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:44:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 02:44:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:44:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:44:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:44:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:44:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:44:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:44:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 02:44:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 02:44:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 02:44:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 02:44:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2021124) [2026-01-27 02:44:32] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2021124) [2026-01-27 02:44:32] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2021124) [2026-01-27 02:44:32] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2021124) [2026-01-27 02:44:32] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=2021124) [2026-01-27 02:44:32] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=2021124) [2026-01-27 02:44:32] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=2021124) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2021124) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:26,  8.75s/it]
(EngineCore_DP0 pid=2021124) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:48<00:54, 27.23s/it]
(EngineCore_DP0 pid=2021124) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:20<00:29, 29.08s/it]
(EngineCore_DP0 pid=2021124) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:01<00:00, 33.76s/it]
(EngineCore_DP0 pid=2021124) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:01<00:00, 30.28s/it]
(EngineCore_DP0 pid=2021124) 
(EngineCore_DP0 pid=2021124) [2026-01-27 02:46:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=2021124) [2026-01-27 02:46:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 41287680 bytes
(EngineCore_DP0 pid=2021124) [2026-01-27 02:46:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=2021124) [2026-01-27 02:46:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 29491200 bytes
(EngineCore_DP0 pid=2021124) [2026-01-27 02:46:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=2021124) [2026-01-27 02:46:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 159252480 bytes
(EngineCore_DP0 pid=2021124) [2026-01-27 02:46:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=2021124) [2026-01-27 02:46:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 79626240 bytes
(EngineCore_DP0 pid=2021124) 2026-01-27 02:46:47,929 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2021124) 2026-01-27 02:46:49,183 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/1024 [00:00<12:31,  1.36it/s]
Adding requests:   0%|          | 2/1024 [00:00<06:46,  2.51it/s]
Adding requests:   0%|          | 4/1024 [00:01<03:19,  5.12it/s]
Adding requests:   1%|          | 7/1024 [00:01<01:45,  9.65it/s]
Adding requests:   1%|         | 13/1024 [00:01<00:51, 19.74it/s]
Adding requests:   3%|         | 27/1024 [00:01<00:21, 46.18it/s]
Adding requests:   4%|         | 44/1024 [00:01<00:12, 75.85it/s]
Adding requests:   7%|         | 72/1024 [00:01<00:07, 127.30it/s]
Adding requests:  11%|         | 109/1024 [00:01<00:04, 191.77it/s]
Adding requests:  15%|        | 150/1024 [00:01<00:03, 251.33it/s]
Adding requests:  19%|        | 197/1024 [00:01<00:02, 311.08it/s]
Adding requests:  24%|       | 244/1024 [00:01<00:02, 355.02it/s]
Adding requests:  28%|       | 291/1024 [00:02<00:01, 386.90it/s]
Adding requests:  33%|      | 340/1024 [00:02<00:01, 414.94it/s]
Adding requests:  38%|      | 387/1024 [00:02<00:01, 429.57it/s]
Adding requests:  42%|     | 435/1024 [00:02<00:01, 442.18it/s]
Adding requests:  47%|     | 481/1024 [00:02<00:01, 444.82it/s]
Adding requests:  52%|    | 534/1024 [00:02<00:01, 467.50it/s]
Adding requests:  57%|    | 582/1024 [00:02<00:00, 464.50it/s]
Adding requests:  61%|   | 629/1024 [00:02<00:00, 465.76it/s]
Adding requests:  66%|   | 676/1024 [00:02<00:00, 445.79it/s]
Adding requests:  71%|   | 723/1024 [00:03<00:00, 452.64it/s]
Adding requests:  75%|  | 769/1024 [00:03<00:00, 444.16it/s]
Adding requests:  80%|  | 817/1024 [00:03<00:00, 453.01it/s]
Adding requests:  84%| | 863/1024 [00:03<00:00, 454.48it/s]
Adding requests:  89%| | 909/1024 [00:03<00:00, 454.39it/s]
Adding requests:  93%|| 955/1024 [00:03<00:00, 442.95it/s]
Adding requests:  98%|| 1000/1024 [00:03<00:00, 441.27it/s]
Adding requests: 100%|| 1024/1024 [00:03<00:00, 277.72it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 8/1024 [00:01<03:37,  4.68it/s, est. speed input: 4790.52 toks/s, output: 4.68 toks/s]
Processed prompts:   2%|         | 16/1024 [00:04<04:27,  3.77it/s, est. speed input: 3979.79 toks/s, output: 3.89 toks/s]
Processed prompts:   2%|         | 24/1024 [00:06<04:42,  3.55it/s, est. speed input: 3760.59 toks/s, output: 3.67 toks/s]
Processed prompts:   3%|         | 32/1024 [00:08<04:47,  3.45it/s, est. speed input: 3661.98 toks/s, output: 3.58 toks/s]
Processed prompts:   4%|         | 40/1024 [00:11<04:49,  3.40it/s, est. speed input: 3606.37 toks/s, output: 3.52 toks/s]
Processed prompts:   5%|         | 48/1024 [00:13<04:49,  3.37it/s, est. speed input: 3567.51 toks/s, output: 3.48 toks/s]
Processed prompts:   5%|         | 56/1024 [00:16<04:48,  3.35it/s, est. speed input: 3543.50 toks/s, output: 3.46 toks/s]
Processed prompts:   6%|         | 64/1024 [00:18<04:47,  3.34it/s, est. speed input: 3523.52 toks/s, output: 3.44 toks/s]
Processed prompts:   7%|         | 72/1024 [00:21<04:45,  3.33it/s, est. speed input: 3507.59 toks/s, output: 3.43 toks/s]
Processed prompts:   8%|         | 80/1024 [00:23<04:44,  3.32it/s, est. speed input: 3494.41 toks/s, output: 3.41 toks/s]
Processed prompts:   9%|         | 88/1024 [00:25<04:42,  3.32it/s, est. speed input: 3484.46 toks/s, output: 3.40 toks/s]
Processed prompts:   9%|         | 96/1024 [00:28<04:40,  3.31it/s, est. speed input: 3474.57 toks/s, output: 3.39 toks/s]
Processed prompts:  10%|         | 104/1024 [00:30<04:38,  3.31it/s, est. speed input: 3466.91 toks/s, output: 3.39 toks/s]
Processed prompts:  11%|         | 112/1024 [00:33<04:35,  3.31it/s, est. speed input: 3461.31 toks/s, output: 3.38 toks/s]
Processed prompts:  12%|        | 120/1024 [00:35<04:33,  3.31it/s, est. speed input: 3456.00 toks/s, output: 3.38 toks/s]
Processed prompts:  12%|        | 128/1024 [00:37<04:31,  3.30it/s, est. speed input: 3451.15 toks/s, output: 3.37 toks/s]
Processed prompts:  13%|        | 136/1024 [00:40<04:28,  3.30it/s, est. speed input: 3446.90 toks/s, output: 3.37 toks/s]
Processed prompts:  14%|        | 144/1024 [00:42<04:26,  3.30it/s, est. speed input: 3443.17 toks/s, output: 3.36 toks/s]
Processed prompts:  15%|        | 152/1024 [00:45<04:24,  3.30it/s, est. speed input: 3439.54 toks/s, output: 3.36 toks/s]
Processed prompts:  16%|        | 160/1024 [00:47<04:21,  3.30it/s, est. speed input: 3436.20 toks/s, output: 3.36 toks/s]
Processed prompts:  16%|        | 168/1024 [00:50<04:19,  3.30it/s, est. speed input: 3433.73 toks/s, output: 3.35 toks/s]
Processed prompts:  17%|        | 176/1024 [00:52<04:16,  3.30it/s, est. speed input: 3431.47 toks/s, output: 3.35 toks/s]
Processed prompts:  18%|        | 184/1024 [00:54<04:14,  3.30it/s, est. speed input: 3429.02 toks/s, output: 3.35 toks/s]
Processed prompts:  19%|        | 192/1024 [00:57<04:12,  3.30it/s, est. speed input: 3426.99 toks/s, output: 3.35 toks/s]
Processed prompts:  20%|        | 200/1024 [00:59<04:02,  3.40it/s, est. speed input: 3438.56 toks/s, output: 3.36 toks/s]
Processed prompts:  20%|        | 208/1024 [01:01<04:02,  3.37it/s, est. speed input: 3436.39 toks/s, output: 3.36 toks/s]
Processed prompts:  21%|        | 216/1024 [01:04<04:01,  3.35it/s, est. speed input: 3434.08 toks/s, output: 3.35 toks/s]
Processed prompts:  22%|       | 224/1024 [01:06<04:00,  3.33it/s, est. speed input: 3431.97 toks/s, output: 3.35 toks/s]
Processed prompts:  23%|       | 232/1024 [01:09<03:58,  3.32it/s, est. speed input: 3430.26 toks/s, output: 3.35 toks/s]
Processed prompts:  23%|       | 240/1024 [01:11<03:56,  3.32it/s, est. speed input: 3428.44 toks/s, output: 3.35 toks/s]
Processed prompts:  24%|       | 248/1024 [01:14<03:54,  3.31it/s, est. speed input: 3426.62 toks/s, output: 3.35 toks/s]
Processed prompts:  25%|       | 256/1024 [01:16<03:52,  3.31it/s, est. speed input: 3425.10 toks/s, output: 3.34 toks/s]
Processed prompts:  26%|       | 264/1024 [01:18<03:50,  3.30it/s, est. speed input: 3423.67 toks/s, output: 3.34 toks/s]
Processed prompts:  27%|       | 272/1024 [01:21<03:47,  3.30it/s, est. speed input: 3422.48 toks/s, output: 3.34 toks/s]
Processed prompts:  27%|       | 280/1024 [01:23<03:45,  3.30it/s, est. speed input: 3421.32 toks/s, output: 3.34 toks/s]
Processed prompts:  28%|       | 288/1024 [01:26<03:42,  3.30it/s, est. speed input: 3420.07 toks/s, output: 3.34 toks/s]
Processed prompts:  29%|       | 296/1024 [01:28<03:40,  3.30it/s, est. speed input: 3418.87 toks/s, output: 3.34 toks/s]
Processed prompts:  30%|       | 304/1024 [01:30<03:31,  3.40it/s, est. speed input: 3426.61 toks/s, output: 3.35 toks/s]
Processed prompts:  30%|       | 312/1024 [01:33<03:31,  3.37it/s, est. speed input: 3425.35 toks/s, output: 3.35 toks/s]
Processed prompts:  31%|      | 320/1024 [01:35<03:30,  3.35it/s, est. speed input: 3424.38 toks/s, output: 3.34 toks/s]
Processed prompts:  32%|      | 328/1024 [01:38<03:28,  3.33it/s, est. speed input: 3423.07 toks/s, output: 3.34 toks/s]
Processed prompts:  33%|      | 336/1024 [01:40<03:27,  3.32it/s, est. speed input: 3421.89 toks/s, output: 3.34 toks/s]
Processed prompts:  34%|      | 344/1024 [01:42<03:25,  3.31it/s, est. speed input: 3420.88 toks/s, output: 3.34 toks/s]
Processed prompts:  34%|      | 352/1024 [01:45<03:23,  3.31it/s, est. speed input: 3419.89 toks/s, output: 3.34 toks/s]
Processed prompts:  35%|      | 360/1024 [01:47<03:20,  3.31it/s, est. speed input: 3418.91 toks/s, output: 3.34 toks/s]
Processed prompts:  36%|      | 368/1024 [01:50<03:18,  3.30it/s, est. speed input: 3418.04 toks/s, output: 3.34 toks/s]
Processed prompts:  37%|      | 376/1024 [01:52<03:16,  3.30it/s, est. speed input: 3417.20 toks/s, output: 3.34 toks/s]
Processed prompts:  38%|      | 384/1024 [01:55<03:13,  3.30it/s, est. speed input: 3416.21 toks/s, output: 3.34 toks/s]
Processed prompts:  38%|      | 392/1024 [01:57<03:11,  3.30it/s, est. speed input: 3415.43 toks/s, output: 3.34 toks/s]
Processed prompts:  39%|      | 400/1024 [01:59<03:09,  3.30it/s, est. speed input: 3414.79 toks/s, output: 3.33 toks/s]
Processed prompts:  40%|      | 408/1024 [02:02<03:06,  3.30it/s, est. speed input: 3413.75 toks/s, output: 3.33 toks/s]
Processed prompts:  41%|      | 416/1024 [02:04<03:04,  3.30it/s, est. speed input: 3413.17 toks/s, output: 3.33 toks/s]
Processed prompts:  41%|     | 424/1024 [02:07<03:01,  3.30it/s, est. speed input: 3412.48 toks/s, output: 3.33 toks/s]
Processed prompts:  42%|     | 432/1024 [02:09<02:54,  3.40it/s, est. speed input: 3418.28 toks/s, output: 3.34 toks/s]
Processed prompts:  43%|     | 440/1024 [02:11<02:53,  3.37it/s, est. speed input: 3417.52 toks/s, output: 3.34 toks/s]
Processed prompts:  44%|     | 448/1024 [02:14<02:52,  3.35it/s, est. speed input: 3416.67 toks/s, output: 3.34 toks/s]
Processed prompts:  45%|     | 456/1024 [02:16<02:50,  3.33it/s, est. speed input: 3415.96 toks/s, output: 3.34 toks/s]
Processed prompts:  45%|     | 464/1024 [02:19<02:48,  3.32it/s, est. speed input: 3415.20 toks/s, output: 3.34 toks/s]
Processed prompts:  46%|     | 472/1024 [02:21<02:46,  3.31it/s, est. speed input: 3414.36 toks/s, output: 3.33 toks/s]
Processed prompts:  47%|     | 480/1024 [02:23<02:44,  3.31it/s, est. speed input: 3413.78 toks/s, output: 3.33 toks/s]
Processed prompts:  48%|     | 488/1024 [02:26<02:42,  3.30it/s, est. speed input: 3413.16 toks/s, output: 3.33 toks/s]
Processed prompts:  48%|     | 496/1024 [02:28<02:39,  3.30it/s, est. speed input: 3412.48 toks/s, output: 3.33 toks/s]
Processed prompts:  49%|     | 504/1024 [02:31<02:37,  3.30it/s, est. speed input: 3411.82 toks/s, output: 3.33 toks/s]
Processed prompts:  50%|     | 512/1024 [02:33<02:35,  3.30it/s, est. speed input: 3411.28 toks/s, output: 3.33 toks/s]
Processed prompts:  51%|     | 520/1024 [02:36<02:32,  3.30it/s, est. speed input: 3410.63 toks/s, output: 3.33 toks/s]
Processed prompts:  52%|    | 528/1024 [02:38<02:30,  3.29it/s, est. speed input: 3409.99 toks/s, output: 3.33 toks/s]
Processed prompts:  52%|    | 536/1024 [02:40<02:28,  3.30it/s, est. speed input: 3409.51 toks/s, output: 3.33 toks/s]
Processed prompts:  53%|    | 544/1024 [02:43<02:25,  3.29it/s, est. speed input: 3408.95 toks/s, output: 3.33 toks/s]
Processed prompts:  54%|    | 552/1024 [02:45<02:23,  3.29it/s, est. speed input: 3408.35 toks/s, output: 3.33 toks/s]
Processed prompts:  55%|    | 560/1024 [02:48<02:20,  3.29it/s, est. speed input: 3407.86 toks/s, output: 3.33 toks/s]
Processed prompts:  55%|    | 568/1024 [02:50<02:18,  3.30it/s, est. speed input: 3407.49 toks/s, output: 3.33 toks/s]
Processed prompts:  56%|    | 576/1024 [02:53<02:16,  3.29it/s, est. speed input: 3406.87 toks/s, output: 3.33 toks/s]
Processed prompts:  57%|    | 584/1024 [02:55<02:13,  3.29it/s, est. speed input: 3406.40 toks/s, output: 3.33 toks/s]
Processed prompts:  58%|    | 592/1024 [02:57<02:11,  3.29it/s, est. speed input: 3405.95 toks/s, output: 3.33 toks/s]
Processed prompts:  59%|    | 600/1024 [03:00<02:08,  3.29it/s, est. speed input: 3405.48 toks/s, output: 3.33 toks/s]
Processed prompts:  59%|    | 608/1024 [03:02<02:06,  3.29it/s, est. speed input: 3404.99 toks/s, output: 3.33 toks/s]
Processed prompts:  60%|    | 616/1024 [03:05<02:03,  3.29it/s, est. speed input: 3404.63 toks/s, output: 3.32 toks/s]
Processed prompts:  61%|    | 624/1024 [03:07<02:01,  3.29it/s, est. speed input: 3404.22 toks/s, output: 3.32 toks/s]
Processed prompts:  62%|   | 632/1024 [03:10<01:59,  3.29it/s, est. speed input: 3403.65 toks/s, output: 3.32 toks/s]
Processed prompts:  62%|   | 640/1024 [03:12<01:56,  3.29it/s, est. speed input: 3403.27 toks/s, output: 3.32 toks/s]
Processed prompts:  63%|   | 648/1024 [03:14<01:54,  3.29it/s, est. speed input: 3402.89 toks/s, output: 3.32 toks/s]
Processed prompts:  64%|   | 656/1024 [03:17<01:51,  3.29it/s, est. speed input: 3402.38 toks/s, output: 3.32 toks/s]
Processed prompts:  65%|   | 664/1024 [03:19<01:49,  3.29it/s, est. speed input: 3401.93 toks/s, output: 3.32 toks/s]
Processed prompts:  66%|   | 672/1024 [03:22<01:46,  3.29it/s, est. speed input: 3401.68 toks/s, output: 3.32 toks/s]
Processed prompts:  66%|   | 680/1024 [03:24<01:44,  3.29it/s, est. speed input: 3401.30 toks/s, output: 3.32 toks/s]
Processed prompts:  67%|   | 688/1024 [03:27<01:42,  3.29it/s, est. speed input: 3400.87 toks/s, output: 3.32 toks/s]
Processed prompts:  68%|   | 696/1024 [03:29<01:39,  3.29it/s, est. speed input: 3400.50 toks/s, output: 3.32 toks/s]
Processed prompts:  69%|   | 704/1024 [03:32<01:37,  3.29it/s, est. speed input: 3400.18 toks/s, output: 3.32 toks/s]
Processed prompts:  70%|   | 712/1024 [03:34<01:34,  3.29it/s, est. speed input: 3399.71 toks/s, output: 3.32 toks/s]
Processed prompts:  70%|   | 720/1024 [03:36<01:32,  3.29it/s, est. speed input: 3399.32 toks/s, output: 3.32 toks/s]
Processed prompts:  71%|   | 728/1024 [03:39<01:29,  3.29it/s, est. speed input: 3399.03 toks/s, output: 3.32 toks/s]
Processed prompts:  72%|  | 736/1024 [03:41<01:27,  3.29it/s, est. speed input: 3398.66 toks/s, output: 3.32 toks/s]
Processed prompts:  73%|  | 744/1024 [03:44<01:25,  3.29it/s, est. speed input: 3398.40 toks/s, output: 3.32 toks/s]
Processed prompts:  73%|  | 752/1024 [03:46<01:22,  3.29it/s, est. speed input: 3398.08 toks/s, output: 3.32 toks/s]
Processed prompts:  74%|  | 760/1024 [03:49<01:20,  3.29it/s, est. speed input: 3397.72 toks/s, output: 3.32 toks/s]
Processed prompts:  75%|  | 768/1024 [03:51<01:17,  3.29it/s, est. speed input: 3397.46 toks/s, output: 3.32 toks/s]
Processed prompts:  76%|  | 776/1024 [03:53<01:15,  3.29it/s, est. speed input: 3397.15 toks/s, output: 3.32 toks/s]
Processed prompts:  77%|  | 784/1024 [03:56<01:10,  3.39it/s, est. speed input: 3400.35 toks/s, output: 3.32 toks/s]
Processed prompts:  77%|  | 792/1024 [03:58<01:09,  3.36it/s, est. speed input: 3399.95 toks/s, output: 3.32 toks/s]
Processed prompts:  78%|  | 800/1024 [04:00<01:07,  3.34it/s, est. speed input: 3399.58 toks/s, output: 3.32 toks/s]
Processed prompts:  79%|  | 808/1024 [04:03<01:05,  3.32it/s, est. speed input: 3399.24 toks/s, output: 3.32 toks/s]
Processed prompts:  80%|  | 816/1024 [04:05<01:02,  3.31it/s, est. speed input: 3398.88 toks/s, output: 3.32 toks/s]
Processed prompts:  80%|  | 824/1024 [04:08<01:00,  3.30it/s, est. speed input: 3398.51 toks/s, output: 3.32 toks/s]
Processed prompts:  81%| | 832/1024 [04:10<00:58,  3.30it/s, est. speed input: 3398.26 toks/s, output: 3.32 toks/s]
Processed prompts:  82%| | 840/1024 [04:13<00:55,  3.29it/s, est. speed input: 3397.93 toks/s, output: 3.32 toks/s]
Processed prompts:  83%| | 848/1024 [04:15<00:53,  3.29it/s, est. speed input: 3397.58 toks/s, output: 3.32 toks/s]
Processed prompts:  84%| | 856/1024 [04:18<00:51,  3.29it/s, est. speed input: 3397.28 toks/s, output: 3.32 toks/s]
Processed prompts:  84%| | 864/1024 [04:20<00:48,  3.29it/s, est. speed input: 3396.92 toks/s, output: 3.32 toks/s]
Processed prompts:  85%| | 872/1024 [04:22<00:46,  3.28it/s, est. speed input: 3396.56 toks/s, output: 3.32 toks/s]
Processed prompts:  86%| | 880/1024 [04:25<00:43,  3.29it/s, est. speed input: 3396.27 toks/s, output: 3.32 toks/s]
Processed prompts:  87%| | 888/1024 [04:27<00:41,  3.28it/s, est. speed input: 3395.96 toks/s, output: 3.32 toks/s]
Processed prompts:  88%| | 896/1024 [04:30<00:38,  3.29it/s, est. speed input: 3395.71 toks/s, output: 3.32 toks/s]
Processed prompts:  88%| | 904/1024 [04:32<00:36,  3.28it/s, est. speed input: 3395.34 toks/s, output: 3.32 toks/s]
Processed prompts:  89%| | 912/1024 [04:35<00:34,  3.28it/s, est. speed input: 3395.08 toks/s, output: 3.32 toks/s]
Processed prompts:  90%| | 920/1024 [04:37<00:31,  3.28it/s, est. speed input: 3394.80 toks/s, output: 3.32 toks/s]
Processed prompts:  91%| | 928/1024 [04:39<00:29,  3.28it/s, est. speed input: 3394.49 toks/s, output: 3.31 toks/s]
Processed prompts:  91%|| 936/1024 [04:42<00:26,  3.28it/s, est. speed input: 3394.17 toks/s, output: 3.31 toks/s]
Processed prompts:  92%|| 944/1024 [04:44<00:24,  3.28it/s, est. speed input: 3393.90 toks/s, output: 3.31 toks/s]
Processed prompts:  93%|| 952/1024 [04:47<00:21,  3.28it/s, est. speed input: 3393.58 toks/s, output: 3.31 toks/s]
Processed prompts:  94%|| 960/1024 [04:49<00:19,  3.28it/s, est. speed input: 3393.31 toks/s, output: 3.31 toks/s]
Processed prompts:  95%|| 968/1024 [04:52<00:17,  3.28it/s, est. speed input: 3393.04 toks/s, output: 3.31 toks/s]
Processed prompts:  95%|| 976/1024 [04:54<00:14,  3.28it/s, est. speed input: 3392.71 toks/s, output: 3.31 toks/s]
Processed prompts:  96%|| 984/1024 [04:57<00:12,  3.28it/s, est. speed input: 3392.47 toks/s, output: 3.31 toks/s]
Processed prompts:  97%|| 992/1024 [04:59<00:09,  3.28it/s, est. speed input: 3392.17 toks/s, output: 3.31 toks/s]
Processed prompts:  98%|| 1000/1024 [05:01<00:07,  3.28it/s, est. speed input: 3391.92 toks/s, output: 3.31 toks/s]
Processed prompts:  98%|| 1008/1024 [05:04<00:04,  3.28it/s, est. speed input: 3391.57 toks/s, output: 3.31 toks/s]
Processed prompts:  99%|| 1016/1024 [05:06<00:02,  3.28it/s, est. speed input: 3391.30 toks/s, output: 3.31 toks/s]
Processed prompts: 100%|| 1024/1024 [05:07<00:00,  4.45it/s, est. speed input: 3414.68 toks/s, output: 3.33 toks/s]
Processed prompts: 100%|| 1024/1024 [05:07<00:00,  4.45it/s, est. speed input: 3414.68 toks/s, output: 3.33 toks/s]
Processed prompts: 100%|| 1024/1024 [05:07<00:00,  3.33it/s, est. speed input: 3414.68 toks/s, output: 3.33 toks/s]
[rank0]:[W127 02:52:10.129093941 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-27 02:52:24
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-14B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 02:52:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 02:52:38 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2028108) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2028108) WARNING 01-27 02:55:14 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.29 requests/s, 3375.53 total tokens/s, 3.29 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-27 02:52:38] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 02:52:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:52:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 02:52:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:52:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:52:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:52:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:52:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:52:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:52:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 02:52:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 02:52:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 02:52:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 02:52:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 02:52:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 02:52:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:52:42] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 02:52:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:52:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:52:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:52:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:52:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 02:52:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 02:52:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 02:52:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 02:52:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 02:52:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 02:52:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2028108) [2026-01-27 02:52:43] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2028108) [2026-01-27 02:52:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2028108) [2026-01-27 02:52:43] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2028108) [2026-01-27 02:52:43] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=2028108) [2026-01-27 02:52:43] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=2028108) [2026-01-27 02:52:43] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=2028108) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2028108) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.63s/it]
(EngineCore_DP0 pid=2028108) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:48<00:54, 27.11s/it]
(EngineCore_DP0 pid=2028108) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:20<00:29, 29.15s/it]
(EngineCore_DP0 pid=2028108) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:01<00:00, 34.02s/it]
(EngineCore_DP0 pid=2028108) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:01<00:00, 30.43s/it]
(EngineCore_DP0 pid=2028108) 
(EngineCore_DP0 pid=2028108) [2026-01-27 02:54:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=2028108) [2026-01-27 02:54:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 41287680 bytes
(EngineCore_DP0 pid=2028108) [2026-01-27 02:54:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=2028108) [2026-01-27 02:54:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 29491200 bytes
(EngineCore_DP0 pid=2028108) [2026-01-27 02:54:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=2028108) [2026-01-27 02:54:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 159252480 bytes
(EngineCore_DP0 pid=2028108) [2026-01-27 02:54:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=2028108) [2026-01-27 02:54:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 79626240 bytes
(EngineCore_DP0 pid=2028108) 2026-01-27 02:55:01,417 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2028108) 2026-01-27 02:55:03,974 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/2048 [00:01<34:36,  1.01s/it]
Adding requests:   0%|          | 2/2048 [00:01<17:57,  1.90it/s]
Adding requests:   0%|          | 3/2048 [00:01<11:21,  3.00it/s]
Adding requests:   0%|          | 5/2048 [00:01<06:17,  5.41it/s]
Adding requests:   0%|          | 8/2048 [00:01<03:33,  9.55it/s]
Adding requests:   1%|          | 12/2048 [00:01<02:13, 15.30it/s]
Adding requests:   1%|          | 19/2048 [00:01<01:14, 27.16it/s]
Adding requests:   2%|         | 39/2048 [00:01<00:29, 67.53it/s]
Adding requests:   3%|         | 66/2048 [00:01<00:16, 117.20it/s]
Adding requests:   5%|         | 100/2048 [00:02<00:11, 175.35it/s]
Adding requests:   7%|         | 141/2048 [00:02<00:07, 239.06it/s]
Adding requests:   9%|         | 185/2048 [00:02<00:06, 295.15it/s]
Adding requests:  11%|         | 228/2048 [00:02<00:05, 332.80it/s]
Adding requests:  13%|        | 272/2048 [00:02<00:04, 362.02it/s]
Adding requests:  15%|        | 315/2048 [00:02<00:04, 380.95it/s]
Adding requests:  17%|        | 358/2048 [00:02<00:04, 392.10it/s]
Adding requests:  20%|        | 400/2048 [00:02<00:04, 398.20it/s]
Adding requests:  22%|       | 446/2048 [00:02<00:03, 414.46it/s]
Adding requests:  24%|       | 493/2048 [00:02<00:03, 428.15it/s]
Adding requests:  26%|       | 540/2048 [00:03<00:03, 438.57it/s]
Adding requests:  29%|       | 585/2048 [00:03<00:03, 429.27it/s]
Adding requests:  31%|       | 629/2048 [00:03<00:03, 428.84it/s]
Adding requests:  33%|      | 673/2048 [00:03<00:03, 425.17it/s]
Adding requests:  35%|      | 718/2048 [00:03<00:03, 430.21it/s]
Adding requests:  37%|      | 762/2048 [00:03<00:03, 419.44it/s]
Adding requests:  39%|      | 805/2048 [00:03<00:02, 415.52it/s]
Adding requests:  42%|     | 850/2048 [00:03<00:02, 423.94it/s]
Adding requests:  44%|     | 893/2048 [00:10<00:56, 20.31it/s] 
Adding requests:  46%|     | 936/2048 [00:10<00:39, 28.27it/s]
Adding requests:  48%|     | 979/2048 [00:10<00:27, 39.11it/s]
Adding requests:  50%|     | 1022/2048 [00:11<00:19, 53.60it/s]
Adding requests:  52%|    | 1064/2048 [00:11<00:13, 72.02it/s]
Adding requests:  54%|    | 1105/2048 [00:11<00:09, 94.67it/s]
Adding requests:  56%|    | 1149/2048 [00:11<00:07, 124.86it/s]
Adding requests:  58%|    | 1193/2048 [00:11<00:05, 159.72it/s]
Adding requests:  60%|    | 1235/2048 [00:11<00:04, 194.12it/s]
Adding requests:  62%|   | 1277/2048 [00:11<00:03, 229.02it/s]
Adding requests:  64%|   | 1320/2048 [00:11<00:02, 266.42it/s]
Adding requests:  67%|   | 1365/2048 [00:11<00:02, 304.03it/s]
Adding requests:  69%|   | 1408/2048 [00:12<00:01, 329.43it/s]
Adding requests:  71%|   | 1450/2048 [00:12<00:01, 342.14it/s]
Adding requests:  73%|  | 1495/2048 [00:12<00:01, 368.98it/s]
Adding requests:  75%|  | 1539/2048 [00:12<00:01, 386.53it/s]
Adding requests:  77%|  | 1582/2048 [00:12<00:01, 398.34it/s]
Adding requests:  79%|  | 1625/2048 [00:12<00:01, 403.25it/s]
Adding requests:  81%| | 1668/2048 [00:12<00:00, 404.96it/s]
Adding requests:  83%| | 1710/2048 [00:12<00:00, 401.66it/s]
Adding requests:  86%| | 1754/2048 [00:12<00:00, 411.34it/s]
Adding requests:  88%| | 1801/2048 [00:12<00:00, 426.59it/s]
Adding requests:  90%| | 1845/2048 [00:13<00:00, 427.29it/s]
Adding requests:  92%|| 1889/2048 [00:13<00:00, 426.12it/s]
Adding requests:  94%|| 1934/2048 [00:13<00:00, 431.80it/s]
Adding requests:  97%|| 1980/2048 [00:13<00:00, 439.97it/s]
Adding requests:  99%|| 2025/2048 [00:13<00:00, 412.92it/s]
Adding requests: 100%|| 2048/2048 [00:13<00:00, 151.28it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 38/2048 [00:03<03:13, 10.39it/s, est. speed input: 10639.91 toks/s, output: 10.39 toks/s]
Processed prompts:   3%|         | 54/2048 [00:08<05:46,  5.76it/s, est. speed input: 6512.10 toks/s, output: 6.36 toks/s]  
Processed prompts:   3%|         | 70/2048 [00:13<07:12,  4.58it/s, est. speed input: 5377.76 toks/s, output: 5.25 toks/s]
Processed prompts:   4%|         | 86/2048 [00:18<08:03,  4.06it/s, est. speed input: 4849.25 toks/s, output: 4.74 toks/s]
Processed prompts:   5%|         | 102/2048 [00:23<08:34,  3.78it/s, est. speed input: 4539.63 toks/s, output: 4.43 toks/s]
Processed prompts:   6%|         | 118/2048 [00:27<08:53,  3.62it/s, est. speed input: 4338.83 toks/s, output: 4.24 toks/s]
Processed prompts:   7%|         | 134/2048 [00:32<09:05,  3.51it/s, est. speed input: 4195.36 toks/s, output: 4.10 toks/s]
Processed prompts:   7%|         | 150/2048 [00:37<09:11,  3.44it/s, est. speed input: 4088.96 toks/s, output: 3.99 toks/s]
Processed prompts:   8%|         | 166/2048 [00:42<09:14,  3.40it/s, est. speed input: 4007.54 toks/s, output: 3.91 toks/s]
Processed prompts:   9%|         | 182/2048 [00:47<09:14,  3.36it/s, est. speed input: 3942.06 toks/s, output: 3.85 toks/s]
Processed prompts:  10%|         | 198/2048 [00:51<09:05,  3.39it/s, est. speed input: 3906.67 toks/s, output: 3.82 toks/s]
Processed prompts:  10%|         | 214/2048 [00:56<09:05,  3.36it/s, est. speed input: 3860.58 toks/s, output: 3.77 toks/s]
Processed prompts:  11%|         | 230/2048 [01:01<09:04,  3.34it/s, est. speed input: 3822.11 toks/s, output: 3.73 toks/s]
Processed prompts:  12%|        | 246/2048 [01:06<09:01,  3.33it/s, est. speed input: 3789.23 toks/s, output: 3.70 toks/s]
Processed prompts:  13%|        | 262/2048 [01:11<08:58,  3.32it/s, est. speed input: 3761.12 toks/s, output: 3.67 toks/s]
Processed prompts:  14%|        | 278/2048 [01:16<08:54,  3.31it/s, est. speed input: 3736.37 toks/s, output: 3.65 toks/s]
Processed prompts:  14%|        | 294/2048 [01:20<08:42,  3.36it/s, est. speed input: 3725.91 toks/s, output: 3.64 toks/s]
Processed prompts:  15%|        | 310/2048 [01:25<08:40,  3.34it/s, est. speed input: 3705.59 toks/s, output: 3.62 toks/s]
Processed prompts:  16%|        | 326/2048 [01:30<08:38,  3.32it/s, est. speed input: 3687.56 toks/s, output: 3.60 toks/s]
Processed prompts:  17%|        | 342/2048 [01:35<08:34,  3.31it/s, est. speed input: 3671.57 toks/s, output: 3.59 toks/s]
Processed prompts:  17%|        | 358/2048 [01:40<08:30,  3.31it/s, est. speed input: 3657.23 toks/s, output: 3.57 toks/s]
Processed prompts:  18%|        | 374/2048 [01:45<08:26,  3.30it/s, est. speed input: 3644.14 toks/s, output: 3.56 toks/s]
Processed prompts:  19%|        | 390/2048 [01:49<08:22,  3.30it/s, est. speed input: 3631.66 toks/s, output: 3.55 toks/s]
Processed prompts:  20%|        | 406/2048 [01:54<08:18,  3.30it/s, est. speed input: 3620.47 toks/s, output: 3.54 toks/s]
Processed prompts:  21%|        | 422/2048 [01:59<08:06,  3.34it/s, est. speed input: 3617.44 toks/s, output: 3.53 toks/s]
Processed prompts:  21%|       | 438/2048 [02:04<08:03,  3.33it/s, est. speed input: 3607.84 toks/s, output: 3.52 toks/s]
Processed prompts:  22%|       | 454/2048 [02:09<08:00,  3.32it/s, est. speed input: 3599.00 toks/s, output: 3.51 toks/s]
Processed prompts:  23%|       | 470/2048 [02:14<07:56,  3.31it/s, est. speed input: 3590.64 toks/s, output: 3.51 toks/s]
Processed prompts:  24%|       | 486/2048 [02:18<07:52,  3.30it/s, est. speed input: 3583.03 toks/s, output: 3.50 toks/s]
Processed prompts:  25%|       | 502/2048 [02:23<07:48,  3.30it/s, est. speed input: 3575.66 toks/s, output: 3.49 toks/s]
Processed prompts:  25%|       | 518/2048 [02:28<07:44,  3.30it/s, est. speed input: 3568.83 toks/s, output: 3.49 toks/s]
Processed prompts:  26%|       | 534/2048 [02:33<07:39,  3.29it/s, est. speed input: 3562.42 toks/s, output: 3.48 toks/s]
Processed prompts:  27%|       | 550/2048 [02:38<07:34,  3.29it/s, est. speed input: 3556.51 toks/s, output: 3.47 toks/s]
Processed prompts:  28%|       | 566/2048 [02:43<07:30,  3.29it/s, est. speed input: 3550.89 toks/s, output: 3.47 toks/s]
Processed prompts:  28%|       | 582/2048 [02:48<07:25,  3.29it/s, est. speed input: 3545.45 toks/s, output: 3.46 toks/s]
Processed prompts:  29%|       | 598/2048 [02:52<07:20,  3.29it/s, est. speed input: 3540.49 toks/s, output: 3.46 toks/s]
Processed prompts:  30%|       | 614/2048 [02:57<07:15,  3.29it/s, est. speed input: 3535.74 toks/s, output: 3.45 toks/s]
Processed prompts:  31%|       | 630/2048 [03:02<07:11,  3.29it/s, est. speed input: 3531.00 toks/s, output: 3.45 toks/s]
Processed prompts:  32%|      | 646/2048 [03:07<07:06,  3.29it/s, est. speed input: 3526.93 toks/s, output: 3.44 toks/s]
Processed prompts:  32%|      | 662/2048 [03:12<07:01,  3.29it/s, est. speed input: 3522.70 toks/s, output: 3.44 toks/s]
Processed prompts:  33%|      | 678/2048 [03:17<06:56,  3.29it/s, est. speed input: 3518.79 toks/s, output: 3.44 toks/s]
Processed prompts:  34%|      | 694/2048 [03:22<06:52,  3.29it/s, est. speed input: 3515.07 toks/s, output: 3.43 toks/s]
Processed prompts:  35%|      | 710/2048 [03:27<06:47,  3.28it/s, est. speed input: 3511.42 toks/s, output: 3.43 toks/s]
Processed prompts:  35%|      | 726/2048 [03:31<06:42,  3.28it/s, est. speed input: 3507.87 toks/s, output: 3.43 toks/s]
Processed prompts:  36%|      | 742/2048 [03:36<06:37,  3.28it/s, est. speed input: 3504.54 toks/s, output: 3.42 toks/s]
Processed prompts:  37%|      | 758/2048 [03:41<06:32,  3.28it/s, est. speed input: 3501.41 toks/s, output: 3.42 toks/s]
Processed prompts:  38%|      | 774/2048 [03:46<06:22,  3.33it/s, est. speed input: 3502.09 toks/s, output: 3.42 toks/s]
Processed prompts:  39%|      | 790/2048 [03:51<06:19,  3.31it/s, est. speed input: 3498.96 toks/s, output: 3.42 toks/s]
Processed prompts:  39%|      | 806/2048 [03:56<06:15,  3.31it/s, est. speed input: 3496.16 toks/s, output: 3.41 toks/s]
Processed prompts:  40%|      | 822/2048 [04:00<06:11,  3.30it/s, est. speed input: 3493.35 toks/s, output: 3.41 toks/s]
Processed prompts:  41%|      | 838/2048 [04:05<06:07,  3.29it/s, est. speed input: 3490.63 toks/s, output: 3.41 toks/s]
Processed prompts:  42%|     | 854/2048 [04:10<06:03,  3.29it/s, est. speed input: 3488.14 toks/s, output: 3.41 toks/s]
Processed prompts:  42%|     | 870/2048 [04:15<05:58,  3.29it/s, est. speed input: 3485.59 toks/s, output: 3.40 toks/s]
Processed prompts:  43%|     | 886/2048 [04:20<05:53,  3.28it/s, est. speed input: 3483.18 toks/s, output: 3.40 toks/s]
Processed prompts:  44%|     | 902/2048 [04:25<05:49,  3.28it/s, est. speed input: 3480.46 toks/s, output: 3.40 toks/s]
Processed prompts:  45%|     | 918/2048 [04:30<05:45,  3.27it/s, est. speed input: 3478.13 toks/s, output: 3.40 toks/s]
Processed prompts:  46%|     | 934/2048 [04:35<05:40,  3.28it/s, est. speed input: 3475.97 toks/s, output: 3.39 toks/s]
Processed prompts:  46%|     | 950/2048 [04:40<05:35,  3.28it/s, est. speed input: 3473.87 toks/s, output: 3.39 toks/s]
Processed prompts:  47%|     | 966/2048 [04:44<05:30,  3.27it/s, est. speed input: 3471.65 toks/s, output: 3.39 toks/s]
Processed prompts:  48%|     | 982/2048 [04:49<05:25,  3.27it/s, est. speed input: 3469.68 toks/s, output: 3.39 toks/s]
Processed prompts:  49%|     | 998/2048 [04:54<05:21,  3.27it/s, est. speed input: 3467.53 toks/s, output: 3.39 toks/s]
Processed prompts:  50%|     | 1014/2048 [04:59<05:16,  3.27it/s, est. speed input: 3465.53 toks/s, output: 3.38 toks/s]
Processed prompts:  50%|     | 1030/2048 [05:04<05:12,  3.26it/s, est. speed input: 3462.96 toks/s, output: 3.38 toks/s]
Processed prompts:  51%|     | 1046/2048 [05:09<05:07,  3.26it/s, est. speed input: 3461.07 toks/s, output: 3.38 toks/s]
Processed prompts:  52%|    | 1062/2048 [05:14<05:02,  3.26it/s, est. speed input: 3459.36 toks/s, output: 3.38 toks/s]
Processed prompts:  53%|    | 1078/2048 [05:19<04:56,  3.27it/s, est. speed input: 3457.93 toks/s, output: 3.38 toks/s]
Processed prompts:  53%|    | 1094/2048 [05:24<04:51,  3.27it/s, est. speed input: 3456.45 toks/s, output: 3.38 toks/s]
Processed prompts:  54%|    | 1110/2048 [05:28<04:46,  3.28it/s, est. speed input: 3455.13 toks/s, output: 3.37 toks/s]
Processed prompts:  55%|    | 1126/2048 [05:33<04:40,  3.28it/s, est. speed input: 3453.89 toks/s, output: 3.37 toks/s]
Processed prompts:  56%|    | 1142/2048 [05:38<04:35,  3.28it/s, est. speed input: 3452.65 toks/s, output: 3.37 toks/s]
Processed prompts:  57%|    | 1158/2048 [05:43<04:30,  3.29it/s, est. speed input: 3451.47 toks/s, output: 3.37 toks/s]
Processed prompts:  57%|    | 1174/2048 [05:48<04:25,  3.29it/s, est. speed input: 3450.34 toks/s, output: 3.37 toks/s]
Processed prompts:  58%|    | 1190/2048 [05:53<04:20,  3.29it/s, est. speed input: 3449.24 toks/s, output: 3.37 toks/s]
Processed prompts:  59%|    | 1206/2048 [05:57<04:12,  3.34it/s, est. speed input: 3450.46 toks/s, output: 3.37 toks/s]
Processed prompts:  60%|    | 1222/2048 [06:02<04:08,  3.33it/s, est. speed input: 3449.43 toks/s, output: 3.37 toks/s]
Processed prompts:  60%|    | 1238/2048 [06:07<04:04,  3.31it/s, est. speed input: 3448.37 toks/s, output: 3.37 toks/s]
Processed prompts:  61%|    | 1254/2048 [06:12<03:59,  3.31it/s, est. speed input: 3447.41 toks/s, output: 3.37 toks/s]
Processed prompts:  62%|   | 1270/2048 [06:17<03:55,  3.30it/s, est. speed input: 3446.37 toks/s, output: 3.37 toks/s]
Processed prompts:  63%|   | 1286/2048 [06:22<03:50,  3.30it/s, est. speed input: 3445.41 toks/s, output: 3.36 toks/s]
Processed prompts:  64%|   | 1302/2048 [06:27<03:46,  3.30it/s, est. speed input: 3444.52 toks/s, output: 3.36 toks/s]
Processed prompts:  64%|   | 1318/2048 [06:31<03:41,  3.30it/s, est. speed input: 3443.61 toks/s, output: 3.36 toks/s]
Processed prompts:  65%|   | 1334/2048 [06:36<03:36,  3.29it/s, est. speed input: 3442.66 toks/s, output: 3.36 toks/s]
Processed prompts:  66%|   | 1350/2048 [06:41<03:31,  3.29it/s, est. speed input: 3441.83 toks/s, output: 3.36 toks/s]
Processed prompts:  67%|   | 1366/2048 [06:46<03:27,  3.29it/s, est. speed input: 3440.95 toks/s, output: 3.36 toks/s]
Processed prompts:  67%|   | 1382/2048 [06:51<03:22,  3.29it/s, est. speed input: 3440.16 toks/s, output: 3.36 toks/s]
Processed prompts:  68%|   | 1398/2048 [06:56<03:17,  3.29it/s, est. speed input: 3439.33 toks/s, output: 3.36 toks/s]
Processed prompts:  69%|   | 1414/2048 [07:01<03:12,  3.29it/s, est. speed input: 3438.53 toks/s, output: 3.36 toks/s]
Processed prompts:  70%|   | 1430/2048 [07:05<03:07,  3.30it/s, est. speed input: 3437.92 toks/s, output: 3.36 toks/s]
Processed prompts:  71%|   | 1446/2048 [07:10<03:02,  3.29it/s, est. speed input: 3437.16 toks/s, output: 3.36 toks/s]
Processed prompts:  71%|  | 1462/2048 [07:15<02:57,  3.30it/s, est. speed input: 3436.48 toks/s, output: 3.36 toks/s]
Processed prompts:  72%|  | 1478/2048 [07:20<02:53,  3.29it/s, est. speed input: 3435.76 toks/s, output: 3.36 toks/s]
Processed prompts:  73%|  | 1494/2048 [07:25<02:48,  3.29it/s, est. speed input: 3435.07 toks/s, output: 3.35 toks/s]
Processed prompts:  74%|  | 1510/2048 [07:30<02:43,  3.29it/s, est. speed input: 3434.36 toks/s, output: 3.35 toks/s]
Processed prompts:  75%|  | 1526/2048 [07:35<02:38,  3.29it/s, est. speed input: 3433.69 toks/s, output: 3.35 toks/s]
Processed prompts:  75%|  | 1542/2048 [07:39<02:33,  3.29it/s, est. speed input: 3433.09 toks/s, output: 3.35 toks/s]
Processed prompts:  76%|  | 1558/2048 [07:44<02:26,  3.34it/s, est. speed input: 3434.20 toks/s, output: 3.35 toks/s]
Processed prompts:  77%|  | 1574/2048 [07:49<02:22,  3.33it/s, est. speed input: 3433.62 toks/s, output: 3.35 toks/s]
Processed prompts:  78%|  | 1590/2048 [07:54<02:18,  3.32it/s, est. speed input: 3432.97 toks/s, output: 3.35 toks/s]
Processed prompts:  78%|  | 1606/2048 [07:59<02:13,  3.31it/s, est. speed input: 3432.38 toks/s, output: 3.35 toks/s]
Processed prompts:  79%|  | 1622/2048 [08:03<02:06,  3.36it/s, est. speed input: 3433.47 toks/s, output: 3.35 toks/s]
Processed prompts:  80%|  | 1638/2048 [08:08<02:02,  3.34it/s, est. speed input: 3432.91 toks/s, output: 3.35 toks/s]
Processed prompts:  81%|  | 1654/2048 [08:13<01:58,  3.33it/s, est. speed input: 3432.34 toks/s, output: 3.35 toks/s]
Processed prompts:  82%| | 1670/2048 [08:18<01:54,  3.31it/s, est. speed input: 3431.50 toks/s, output: 3.35 toks/s]
Processed prompts:  82%| | 1686/2048 [08:23<01:49,  3.30it/s, est. speed input: 3430.91 toks/s, output: 3.35 toks/s]
Processed prompts:  83%| | 1702/2048 [08:28<01:44,  3.30it/s, est. speed input: 3430.32 toks/s, output: 3.35 toks/s]
Processed prompts:  84%| | 1718/2048 [08:32<01:40,  3.30it/s, est. speed input: 3429.74 toks/s, output: 3.35 toks/s]
Processed prompts:  85%| | 1734/2048 [08:37<01:35,  3.30it/s, est. speed input: 3429.19 toks/s, output: 3.35 toks/s]
Processed prompts:  85%| | 1750/2048 [08:42<01:29,  3.35it/s, est. speed input: 3430.32 toks/s, output: 3.35 toks/s]
Processed prompts:  86%| | 1766/2048 [08:47<01:24,  3.33it/s, est. speed input: 3429.78 toks/s, output: 3.35 toks/s]
Processed prompts:  87%| | 1782/2048 [08:52<01:20,  3.32it/s, est. speed input: 3429.23 toks/s, output: 3.35 toks/s]
Processed prompts:  88%| | 1798/2048 [08:56<01:15,  3.31it/s, est. speed input: 3428.78 toks/s, output: 3.35 toks/s]
Processed prompts:  89%| | 1814/2048 [09:01<01:10,  3.31it/s, est. speed input: 3428.25 toks/s, output: 3.35 toks/s]
Processed prompts:  89%| | 1830/2048 [09:06<01:05,  3.30it/s, est. speed input: 3427.78 toks/s, output: 3.35 toks/s]
Processed prompts:  90%| | 1846/2048 [09:11<01:01,  3.30it/s, est. speed input: 3427.30 toks/s, output: 3.35 toks/s]
Processed prompts:  91%| | 1862/2048 [09:16<00:56,  3.30it/s, est. speed input: 3426.91 toks/s, output: 3.35 toks/s]
Processed prompts:  92%|| 1878/2048 [09:21<00:51,  3.30it/s, est. speed input: 3426.55 toks/s, output: 3.35 toks/s]
Processed prompts:  92%|| 1894/2048 [09:26<00:46,  3.30it/s, est. speed input: 3426.11 toks/s, output: 3.35 toks/s]
Processed prompts:  93%|| 1910/2048 [09:30<00:41,  3.30it/s, est. speed input: 3425.71 toks/s, output: 3.35 toks/s]
Processed prompts:  94%|| 1926/2048 [09:35<00:36,  3.30it/s, est. speed input: 3425.28 toks/s, output: 3.34 toks/s]
Processed prompts:  95%|| 1942/2048 [09:40<00:32,  3.30it/s, est. speed input: 3424.88 toks/s, output: 3.34 toks/s]
Processed prompts:  96%|| 1958/2048 [09:45<00:27,  3.30it/s, est. speed input: 3424.45 toks/s, output: 3.34 toks/s]
Processed prompts:  96%|| 1974/2048 [09:50<00:22,  3.30it/s, est. speed input: 3424.03 toks/s, output: 3.34 toks/s]
Processed prompts:  97%|| 1990/2048 [09:55<00:17,  3.30it/s, est. speed input: 3423.63 toks/s, output: 3.34 toks/s]
Processed prompts:  98%|| 2006/2048 [10:00<00:12,  3.30it/s, est. speed input: 3423.26 toks/s, output: 3.34 toks/s]
Processed prompts:  99%|| 2022/2048 [10:04<00:07,  3.30it/s, est. speed input: 3422.87 toks/s, output: 3.34 toks/s]
Processed prompts: 100%|| 2038/2048 [10:08<00:02,  3.63it/s, est. speed input: 3430.84 toks/s, output: 3.35 toks/s]
Processed prompts: 100%|| 2048/2048 [10:08<00:00,  3.63it/s, est. speed input: 3447.67 toks/s, output: 3.37 toks/s]
Processed prompts: 100%|| 2048/2048 [10:08<00:00,  3.37it/s, est. speed input: 3447.67 toks/s, output: 3.37 toks/s]
[rank0]:[W127 03:05:38.343708979 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-27 03:05:46
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-14B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 03:06:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 03:06:07 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2040033) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2040033) WARNING 01-27 03:08:53 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.29 requests/s, 3371.17 total tokens/s, 3.29 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-27 03:06:06] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 03:06:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 03:06:06] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 03:06:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:06:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:06:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:06:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:06:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:06:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 03:06:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 03:06:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 03:06:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 03:06:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 03:06:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 03:06:10] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 03:06:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 03:06:10] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 03:06:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:06:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:06:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:06:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:06:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:06:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 03:06:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 03:06:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 03:06:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 03:06:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 03:06:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2040033) [2026-01-27 03:06:11] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2040033) [2026-01-27 03:06:11] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2040033) [2026-01-27 03:06:11] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2040033) [2026-01-27 03:06:11] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=2040033) [2026-01-27 03:06:11] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=2040033) [2026-01-27 03:06:11] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=2040033) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2040033) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.37s/it]
(EngineCore_DP0 pid=2040033) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:47<00:53, 26.72s/it]
(EngineCore_DP0 pid=2040033) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:19<00:28, 28.88s/it]
(EngineCore_DP0 pid=2040033) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:00<00:00, 33.79s/it]
(EngineCore_DP0 pid=2040033) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:00<00:00, 30.17s/it]
(EngineCore_DP0 pid=2040033) 
(EngineCore_DP0 pid=2040033) [2026-01-27 03:08:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=2040033) [2026-01-27 03:08:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 41287680 bytes
(EngineCore_DP0 pid=2040033) [2026-01-27 03:08:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=2040033) [2026-01-27 03:08:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 29491200 bytes
(EngineCore_DP0 pid=2040033) [2026-01-27 03:08:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=2040033) [2026-01-27 03:08:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 159252480 bytes
(EngineCore_DP0 pid=2040033) [2026-01-27 03:08:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=2040033) [2026-01-27 03:08:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 79626240 bytes
(EngineCore_DP0 pid=2040033) 2026-01-27 03:08:33,444 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2040033) 2026-01-27 03:08:38,190 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/4096 [00:00<49:17,  1.38it/s]
Adding requests:   0%|          | 2/4096 [00:00<28:21,  2.41it/s]
Adding requests:   0%|          | 3/4096 [00:01<19:18,  3.53it/s]
Adding requests:   0%|          | 5/4096 [00:01<11:24,  5.98it/s]
Adding requests:   0%|          | 8/4096 [00:01<06:46, 10.06it/s]
Adding requests:   0%|          | 12/4096 [00:01<04:22, 15.57it/s]
Adding requests:   0%|          | 19/4096 [00:01<02:28, 27.40it/s]
Adding requests:   1%|          | 45/4096 [00:01<00:48, 82.80it/s]
Adding requests:   2%|         | 79/4096 [00:01<00:27, 147.54it/s]
Adding requests:   3%|         | 118/4096 [00:01<00:18, 210.84it/s]
Adding requests:   4%|         | 160/4096 [00:01<00:14, 266.90it/s]
Adding requests:   5%|         | 205/4096 [00:02<00:12, 316.89it/s]
Adding requests:   6%|         | 247/4096 [00:02<00:11, 344.68it/s]
Adding requests:   7%|         | 290/4096 [00:02<00:10, 368.83it/s]
Adding requests:   8%|         | 329/4096 [00:02<00:10, 373.24it/s]
Adding requests:   9%|         | 373/4096 [00:02<00:09, 392.15it/s]
Adding requests:  10%|         | 419/4096 [00:02<00:08, 410.38it/s]
Adding requests:  11%|        | 464/4096 [00:02<00:08, 418.03it/s]
Adding requests:  12%|        | 512/4096 [00:02<00:08, 433.29it/s]
Adding requests:  14%|        | 559/4096 [00:02<00:07, 443.21it/s]
Adding requests:  15%|        | 604/4096 [00:02<00:08, 432.10it/s]
Adding requests:  16%|        | 648/4096 [00:03<00:08, 424.90it/s]
Adding requests:  17%|        | 691/4096 [00:03<00:07, 426.19it/s]
Adding requests:  18%|        | 734/4096 [00:03<00:08, 418.73it/s]
Adding requests:  19%|        | 777/4096 [00:03<00:07, 421.82it/s]
Adding requests:  20%|        | 822/4096 [00:03<00:07, 428.88it/s]
Adding requests:  21%|        | 870/4096 [00:03<00:07, 441.90it/s]
Adding requests:  22%|       | 915/4096 [00:03<00:07, 443.73it/s]
Adding requests:  23%|       | 960/4096 [00:03<00:07, 435.25it/s]
Adding requests:  25%|       | 1004/4096 [00:03<00:07, 434.45it/s]
Adding requests:  26%|       | 1048/4096 [00:04<00:07, 433.57it/s]
Adding requests:  27%|       | 1092/4096 [00:04<00:07, 422.68it/s]
Adding requests:  28%|       | 1135/4096 [00:04<00:06, 423.98it/s]
Adding requests:  29%|       | 1178/4096 [00:04<00:06, 420.99it/s]
Adding requests:  30%|       | 1221/4096 [00:04<00:07, 408.93it/s]
Adding requests:  31%|       | 1262/4096 [00:04<00:06, 407.84it/s]
Adding requests:  32%|      | 1304/4096 [00:04<00:06, 410.76it/s]
Adding requests:  33%|      | 1348/4096 [00:04<00:06, 419.03it/s]
Adding requests:  34%|      | 1390/4096 [00:04<00:06, 416.24it/s]
Adding requests:  35%|      | 1432/4096 [00:04<00:06, 410.63it/s]
Adding requests:  36%|      | 1475/4096 [00:05<00:06, 415.39it/s]
Adding requests:  37%|      | 1517/4096 [00:05<00:06, 410.03it/s]
Adding requests:  38%|      | 1559/4096 [00:05<00:06, 403.48it/s]
Adding requests:  39%|      | 1600/4096 [00:05<00:06, 400.86it/s]
Adding requests:  40%|      | 1644/4096 [00:05<00:05, 411.84it/s]
Adding requests:  41%|      | 1686/4096 [00:05<00:06, 399.99it/s]
Adding requests:  42%|     | 1730/4096 [00:05<00:05, 410.36it/s]
Adding requests:  43%|     | 1774/4096 [00:05<00:05, 416.55it/s]
Adding requests:  44%|     | 1816/4096 [00:05<00:05, 412.82it/s]
Adding requests:  45%|     | 1859/4096 [00:05<00:05, 415.09it/s]
Adding requests:  46%|     | 1903/4096 [00:06<00:05, 411.54it/s]
Adding requests:  48%|     | 1946/4096 [00:06<00:05, 415.02it/s]
Adding requests:  49%|     | 1988/4096 [00:06<00:05, 407.14it/s]
Adding requests:  50%|     | 2029/4096 [00:06<00:05, 404.93it/s]
Adding requests:  51%|     | 2072/4096 [00:06<00:04, 411.77it/s]
Adding requests:  52%|    | 2114/4096 [00:06<00:04, 399.75it/s]
Adding requests:  53%|    | 2157/4096 [00:06<00:04, 408.44it/s]
Adding requests:  54%|    | 2198/4096 [00:06<00:04, 403.97it/s]
Adding requests:  55%|    | 2239/4096 [00:06<00:04, 402.96it/s]
Adding requests:  56%|    | 2282/4096 [00:07<00:04, 408.20it/s]
Adding requests:  57%|    | 2326/4096 [00:07<00:04, 416.10it/s]
Adding requests:  58%|    | 2368/4096 [00:07<00:04, 412.04it/s]
Adding requests:  59%|    | 2415/4096 [00:07<00:03, 427.32it/s]
Adding requests:  60%|    | 2458/4096 [00:07<00:04, 405.28it/s]
Adding requests:  61%|    | 2503/4096 [00:07<00:03, 417.74it/s]
Adding requests:  62%|   | 2549/4096 [00:07<00:03, 428.84it/s]
Adding requests:  63%|   | 2595/4096 [00:07<00:03, 436.89it/s]
Adding requests:  64%|   | 2639/4096 [00:07<00:03, 429.14it/s]
Adding requests:  66%|   | 2683/4096 [00:07<00:03, 428.43it/s]
Adding requests:  67%|   | 2726/4096 [00:08<00:03, 425.97it/s]
Adding requests:  68%|   | 2773/4096 [00:08<00:03, 437.91it/s]
Adding requests:  69%|   | 2817/4096 [00:08<00:02, 431.30it/s]
Adding requests:  70%|   | 2861/4096 [00:08<00:02, 433.50it/s]
Adding requests:  71%|   | 2905/4096 [00:08<00:02, 433.21it/s]
Adding requests:  72%|  | 2951/4096 [00:08<00:02, 440.39it/s]
Adding requests:  73%|  | 2996/4096 [00:08<00:02, 434.85it/s]
Adding requests:  74%|  | 3040/4096 [00:08<00:02, 434.66it/s]
Adding requests:  75%|  | 3086/4096 [00:08<00:02, 441.63it/s]
Adding requests:  76%|  | 3131/4096 [00:08<00:02, 444.05it/s]
Adding requests:  78%|  | 3176/4096 [00:09<00:02, 432.81it/s]
Adding requests:  79%|  | 3220/4096 [00:09<00:02, 434.69it/s]
Adding requests:  80%|  | 3264/4096 [00:09<00:01, 434.43it/s]
Adding requests:  81%|  | 3308/4096 [00:09<00:01, 419.13it/s]
Adding requests:  82%| | 3352/4096 [00:09<00:01, 424.89it/s]
Adding requests:  83%| | 3395/4096 [00:09<00:01, 422.55it/s]
Adding requests:  84%| | 3440/4096 [00:09<00:01, 429.18it/s]
Adding requests:  85%| | 3483/4096 [00:09<00:01, 426.04it/s]
Adding requests:  86%| | 3529/4096 [00:09<00:01, 434.45it/s]
Adding requests:  87%| | 3573/4096 [00:10<00:01, 430.68it/s]
Adding requests:  88%| | 3617/4096 [00:10<00:01, 432.80it/s]
Adding requests:  89%| | 3661/4096 [00:10<00:01, 428.68it/s]
Adding requests:  90%| | 3705/4096 [00:10<00:00, 430.87it/s]
Adding requests:  92%|| 3749/4096 [00:10<00:00, 427.89it/s]
Adding requests:  93%|| 3792/4096 [00:10<00:00, 408.51it/s]
Adding requests:  94%|| 3834/4096 [00:10<00:00, 396.36it/s]
Adding requests:  95%|| 3880/4096 [00:10<00:00, 414.19it/s]
Adding requests:  96%|| 3922/4096 [00:10<00:00, 412.17it/s]
Adding requests:  97%|| 3964/4096 [00:10<00:00, 410.58it/s]
Adding requests:  98%|| 4007/4096 [00:11<00:00, 413.60it/s]
Adding requests:  99%|| 4049/4096 [00:11<00:00, 415.15it/s]
Adding requests: 100%|| 4091/4096 [00:11<00:00, 411.97it/s]
Adding requests: 100%|| 4096/4096 [00:11<00:00, 362.52it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 5/4096 [00:00<07:24,  9.20it/s, est. speed input: 9420.10 toks/s, output: 9.20 toks/s]
Processed prompts:   1%|          | 37/4096 [00:10<19:11,  3.52it/s, est. speed input: 3702.07 toks/s, output: 3.62 toks/s]
Processed prompts:   2%|         | 69/4096 [00:19<19:47,  3.39it/s, est. speed input: 3542.86 toks/s, output: 3.46 toks/s]
Processed prompts:   2%|         | 101/4096 [00:29<19:53,  3.35it/s, est. speed input: 3487.41 toks/s, output: 3.41 toks/s]
Processed prompts:   3%|         | 133/4096 [00:39<19:51,  3.33it/s, est. speed input: 3458.09 toks/s, output: 3.38 toks/s]
Processed prompts:   4%|         | 165/4096 [00:49<19:46,  3.31it/s, est. speed input: 3440.20 toks/s, output: 3.36 toks/s]
Processed prompts:   5%|         | 197/4096 [00:58<19:31,  3.33it/s, est. speed input: 3440.22 toks/s, output: 3.36 toks/s]
Processed prompts:   6%|         | 229/4096 [01:08<19:30,  3.30it/s, est. speed input: 3425.21 toks/s, output: 3.34 toks/s]
Processed prompts:   6%|         | 261/4096 [01:18<19:23,  3.29it/s, est. speed input: 3416.10 toks/s, output: 3.34 toks/s]
Processed prompts:   7%|         | 293/4096 [01:27<19:06,  3.32it/s, est. speed input: 3419.71 toks/s, output: 3.34 toks/s]
Processed prompts:   8%|         | 325/4096 [01:37<19:03,  3.30it/s, est. speed input: 3410.73 toks/s, output: 3.33 toks/s]
Processed prompts:   9%|         | 357/4096 [01:47<18:55,  3.29it/s, est. speed input: 3406.05 toks/s, output: 3.33 toks/s]
Processed prompts:   9%|         | 389/4096 [01:57<18:48,  3.29it/s, est. speed input: 3401.22 toks/s, output: 3.32 toks/s]
Processed prompts:  10%|         | 421/4096 [02:06<18:30,  3.31it/s, est. speed input: 3404.39 toks/s, output: 3.32 toks/s]
Processed prompts:  11%|         | 453/4096 [02:16<18:23,  3.30it/s, est. speed input: 3401.18 toks/s, output: 3.32 toks/s]
Processed prompts:  12%|        | 485/4096 [02:26<18:16,  3.29it/s, est. speed input: 3398.33 toks/s, output: 3.32 toks/s]
Processed prompts:  13%|        | 517/4096 [02:35<18:08,  3.29it/s, est. speed input: 3395.65 toks/s, output: 3.32 toks/s]
Processed prompts:  13%|        | 549/4096 [02:45<17:59,  3.29it/s, est. speed input: 3393.52 toks/s, output: 3.31 toks/s]
Processed prompts:  14%|        | 581/4096 [02:55<17:50,  3.28it/s, est. speed input: 3391.32 toks/s, output: 3.31 toks/s]
Processed prompts:  15%|        | 613/4096 [03:05<17:40,  3.28it/s, est. speed input: 3389.80 toks/s, output: 3.31 toks/s]
Processed prompts:  16%|        | 645/4096 [03:14<17:31,  3.28it/s, est. speed input: 3388.14 toks/s, output: 3.31 toks/s]
Processed prompts:  17%|        | 677/4096 [03:24<17:22,  3.28it/s, est. speed input: 3386.71 toks/s, output: 3.31 toks/s]
Processed prompts:  17%|        | 709/4096 [03:34<17:12,  3.28it/s, est. speed input: 3385.34 toks/s, output: 3.31 toks/s]
Processed prompts:  18%|        | 741/4096 [03:44<17:02,  3.28it/s, est. speed input: 3384.15 toks/s, output: 3.30 toks/s]
Processed prompts:  19%|        | 773/4096 [03:53<16:45,  3.30it/s, est. speed input: 3386.64 toks/s, output: 3.31 toks/s]
Processed prompts:  20%|        | 805/4096 [04:03<16:38,  3.30it/s, est. speed input: 3385.44 toks/s, output: 3.31 toks/s]
Processed prompts:  20%|        | 837/4096 [04:13<16:30,  3.29it/s, est. speed input: 3384.39 toks/s, output: 3.31 toks/s]
Processed prompts:  21%|        | 869/4096 [04:23<16:21,  3.29it/s, est. speed input: 3383.40 toks/s, output: 3.30 toks/s]
Processed prompts:  22%|       | 901/4096 [04:32<16:12,  3.29it/s, est. speed input: 3382.53 toks/s, output: 3.30 toks/s]
Processed prompts:  23%|       | 933/4096 [04:42<16:03,  3.28it/s, est. speed input: 3381.54 toks/s, output: 3.30 toks/s]
Processed prompts:  24%|       | 965/4096 [04:52<15:54,  3.28it/s, est. speed input: 3380.58 toks/s, output: 3.30 toks/s]
Processed prompts:  24%|       | 997/4096 [05:02<15:45,  3.28it/s, est. speed input: 3379.72 toks/s, output: 3.30 toks/s]
Processed prompts:  25%|       | 1029/4096 [05:11<15:35,  3.28it/s, est. speed input: 3378.94 toks/s, output: 3.30 toks/s]
Processed prompts:  26%|       | 1061/4096 [05:21<15:26,  3.28it/s, est. speed input: 3378.13 toks/s, output: 3.30 toks/s]
Processed prompts:  27%|       | 1093/4096 [05:31<15:17,  3.27it/s, est. speed input: 3377.25 toks/s, output: 3.30 toks/s]
Processed prompts:  27%|       | 1125/4096 [05:41<15:07,  3.27it/s, est. speed input: 3376.51 toks/s, output: 3.30 toks/s]
Processed prompts:  28%|       | 1157/4096 [05:50<14:57,  3.27it/s, est. speed input: 3375.80 toks/s, output: 3.30 toks/s]
Processed prompts:  29%|       | 1189/4096 [06:00<14:41,  3.30it/s, est. speed input: 3377.43 toks/s, output: 3.30 toks/s]
Processed prompts:  30%|       | 1221/4096 [06:10<14:33,  3.29it/s, est. speed input: 3376.70 toks/s, output: 3.30 toks/s]
Processed prompts:  31%|       | 1253/4096 [06:20<14:25,  3.29it/s, est. speed input: 3376.10 toks/s, output: 3.30 toks/s]
Processed prompts:  31%|      | 1285/4096 [06:29<14:16,  3.28it/s, est. speed input: 3375.48 toks/s, output: 3.30 toks/s]
Processed prompts:  32%|      | 1317/4096 [06:39<14:07,  3.28it/s, est. speed input: 3374.77 toks/s, output: 3.30 toks/s]
Processed prompts:  33%|      | 1349/4096 [06:49<13:58,  3.27it/s, est. speed input: 3374.11 toks/s, output: 3.30 toks/s]
Processed prompts:  34%|      | 1381/4096 [06:59<13:49,  3.27it/s, est. speed input: 3373.45 toks/s, output: 3.29 toks/s]
Processed prompts:  34%|      | 1413/4096 [07:08<13:40,  3.27it/s, est. speed input: 3372.88 toks/s, output: 3.29 toks/s]
Processed prompts:  35%|      | 1445/4096 [07:18<13:30,  3.27it/s, est. speed input: 3372.28 toks/s, output: 3.29 toks/s]
Processed prompts:  36%|      | 1477/4096 [07:28<13:21,  3.27it/s, est. speed input: 3371.62 toks/s, output: 3.29 toks/s]
Processed prompts:  37%|      | 1509/4096 [07:38<13:11,  3.27it/s, est. speed input: 3371.06 toks/s, output: 3.29 toks/s]
Processed prompts:  38%|      | 1541/4096 [07:47<12:56,  3.29it/s, est. speed input: 3372.27 toks/s, output: 3.29 toks/s]
Processed prompts:  38%|      | 1573/4096 [07:57<12:49,  3.28it/s, est. speed input: 3371.40 toks/s, output: 3.29 toks/s]
Processed prompts:  39%|      | 1605/4096 [08:07<12:35,  3.30it/s, est. speed input: 3372.45 toks/s, output: 3.29 toks/s]
Processed prompts:  40%|      | 1637/4096 [08:17<12:27,  3.29it/s, est. speed input: 3371.88 toks/s, output: 3.29 toks/s]
Processed prompts:  41%|      | 1669/4096 [08:26<12:20,  3.28it/s, est. speed input: 3371.16 toks/s, output: 3.29 toks/s]
Processed prompts:  42%|     | 1701/4096 [08:36<12:11,  3.27it/s, est. speed input: 3370.54 toks/s, output: 3.29 toks/s]
Processed prompts:  42%|     | 1733/4096 [08:46<11:57,  3.29it/s, est. speed input: 3371.50 toks/s, output: 3.29 toks/s]
Processed prompts:  43%|     | 1765/4096 [08:56<11:50,  3.28it/s, est. speed input: 3370.80 toks/s, output: 3.29 toks/s]
Processed prompts:  44%|     | 1797/4096 [09:05<11:41,  3.28it/s, est. speed input: 3370.22 toks/s, output: 3.29 toks/s]
Processed prompts:  45%|     | 1829/4096 [09:15<11:33,  3.27it/s, est. speed input: 3369.49 toks/s, output: 3.29 toks/s]
Processed prompts:  45%|     | 1861/4096 [09:25<11:24,  3.27it/s, est. speed input: 3368.97 toks/s, output: 3.29 toks/s]
Processed prompts:  46%|     | 1893/4096 [09:35<11:15,  3.26it/s, est. speed input: 3368.40 toks/s, output: 3.29 toks/s]
Processed prompts:  47%|     | 1925/4096 [09:45<11:05,  3.26it/s, est. speed input: 3367.84 toks/s, output: 3.29 toks/s]
Processed prompts:  48%|     | 1957/4096 [09:55<10:55,  3.26it/s, est. speed input: 3367.35 toks/s, output: 3.29 toks/s]
Processed prompts:  49%|     | 1989/4096 [10:04<10:46,  3.26it/s, est. speed input: 3366.83 toks/s, output: 3.29 toks/s]
Processed prompts:  49%|     | 2021/4096 [10:14<10:36,  3.26it/s, est. speed input: 3366.40 toks/s, output: 3.29 toks/s]
Processed prompts:  50%|     | 2053/4096 [10:24<10:26,  3.26it/s, est. speed input: 3366.09 toks/s, output: 3.29 toks/s]
Processed prompts:  51%|     | 2085/4096 [10:34<10:15,  3.27it/s, est. speed input: 3365.88 toks/s, output: 3.29 toks/s]
Processed prompts:  52%|    | 2117/4096 [10:44<10:05,  3.27it/s, est. speed input: 3365.78 toks/s, output: 3.29 toks/s]
Processed prompts:  52%|    | 2149/4096 [10:53<09:54,  3.27it/s, est. speed input: 3365.72 toks/s, output: 3.29 toks/s]
Processed prompts:  53%|    | 2181/4096 [11:03<09:40,  3.30it/s, est. speed input: 3366.90 toks/s, output: 3.29 toks/s]
Processed prompts:  54%|    | 2213/4096 [11:13<09:31,  3.30it/s, est. speed input: 3366.85 toks/s, output: 3.29 toks/s]
Processed prompts:  55%|    | 2245/4096 [11:22<09:22,  3.29it/s, est. speed input: 3366.80 toks/s, output: 3.29 toks/s]
Processed prompts:  56%|    | 2277/4096 [11:32<09:12,  3.29it/s, est. speed input: 3366.80 toks/s, output: 3.29 toks/s]
Processed prompts:  56%|    | 2309/4096 [11:42<09:03,  3.29it/s, est. speed input: 3366.79 toks/s, output: 3.29 toks/s]
Processed prompts:  57%|    | 2341/4096 [11:52<08:53,  3.29it/s, est. speed input: 3366.74 toks/s, output: 3.29 toks/s]
Processed prompts:  58%|    | 2373/4096 [12:01<08:43,  3.29it/s, est. speed input: 3366.75 toks/s, output: 3.29 toks/s]
Processed prompts:  59%|    | 2405/4096 [12:11<08:34,  3.29it/s, est. speed input: 3366.72 toks/s, output: 3.29 toks/s]
Processed prompts:  59%|    | 2437/4096 [12:21<08:24,  3.29it/s, est. speed input: 3366.72 toks/s, output: 3.29 toks/s]
Processed prompts:  60%|    | 2469/4096 [12:30<08:14,  3.29it/s, est. speed input: 3366.69 toks/s, output: 3.29 toks/s]
Processed prompts:  61%|    | 2501/4096 [12:40<08:05,  3.29it/s, est. speed input: 3366.75 toks/s, output: 3.29 toks/s]
Processed prompts:  62%|   | 2533/4096 [12:50<07:55,  3.29it/s, est. speed input: 3366.81 toks/s, output: 3.29 toks/s]
Processed prompts:  63%|   | 2565/4096 [13:00<07:45,  3.29it/s, est. speed input: 3366.86 toks/s, output: 3.29 toks/s]
Processed prompts:  63%|   | 2597/4096 [13:09<07:32,  3.32it/s, est. speed input: 3367.96 toks/s, output: 3.29 toks/s]
Processed prompts:  64%|   | 2629/4096 [13:19<07:23,  3.31it/s, est. speed input: 3367.97 toks/s, output: 3.29 toks/s]
Processed prompts:  65%|   | 2661/4096 [13:29<07:14,  3.30it/s, est. speed input: 3367.94 toks/s, output: 3.29 toks/s]
Processed prompts:  66%|   | 2693/4096 [13:38<07:05,  3.30it/s, est. speed input: 3367.95 toks/s, output: 3.29 toks/s]
Processed prompts:  67%|   | 2725/4096 [13:48<06:52,  3.32it/s, est. speed input: 3368.96 toks/s, output: 3.29 toks/s]
Processed prompts:  67%|   | 2757/4096 [13:58<06:44,  3.31it/s, est. speed input: 3368.93 toks/s, output: 3.29 toks/s]
Processed prompts:  68%|   | 2789/4096 [14:07<06:35,  3.31it/s, est. speed input: 3368.98 toks/s, output: 3.29 toks/s]
Processed prompts:  69%|   | 2821/4096 [14:17<06:26,  3.30it/s, est. speed input: 3368.97 toks/s, output: 3.29 toks/s]
Processed prompts:  70%|   | 2853/4096 [14:27<06:16,  3.30it/s, est. speed input: 3368.96 toks/s, output: 3.29 toks/s]
Processed prompts:  70%|   | 2885/4096 [14:36<06:04,  3.32it/s, est. speed input: 3369.91 toks/s, output: 3.29 toks/s]
Processed prompts:  71%|   | 2917/4096 [14:46<05:53,  3.34it/s, est. speed input: 3370.86 toks/s, output: 3.29 toks/s]
Processed prompts:  72%|  | 2949/4096 [14:55<05:45,  3.32it/s, est. speed input: 3370.84 toks/s, output: 3.29 toks/s]
Processed prompts:  73%|  | 2981/4096 [15:05<05:36,  3.31it/s, est. speed input: 3370.84 toks/s, output: 3.29 toks/s]
Processed prompts:  74%|  | 3013/4096 [15:15<05:27,  3.31it/s, est. speed input: 3370.81 toks/s, output: 3.29 toks/s]
Processed prompts:  74%|  | 3045/4096 [15:25<05:18,  3.30it/s, est. speed input: 3370.78 toks/s, output: 3.29 toks/s]
Processed prompts:  75%|  | 3077/4096 [15:34<05:08,  3.30it/s, est. speed input: 3370.77 toks/s, output: 3.29 toks/s]
Processed prompts:  76%|  | 3109/4096 [15:44<04:59,  3.30it/s, est. speed input: 3370.75 toks/s, output: 3.29 toks/s]
Processed prompts:  77%|  | 3141/4096 [15:54<04:49,  3.29it/s, est. speed input: 3370.72 toks/s, output: 3.29 toks/s]
Processed prompts:  77%|  | 3173/4096 [16:03<04:40,  3.29it/s, est. speed input: 3370.74 toks/s, output: 3.29 toks/s]
Processed prompts:  78%|  | 3205/4096 [16:13<04:30,  3.29it/s, est. speed input: 3370.74 toks/s, output: 3.29 toks/s]
Processed prompts:  79%|  | 3237/4096 [16:23<04:20,  3.29it/s, est. speed input: 3370.76 toks/s, output: 3.29 toks/s]
Processed prompts:  80%|  | 3269/4096 [16:33<04:11,  3.29it/s, est. speed input: 3370.79 toks/s, output: 3.29 toks/s]
Processed prompts:  81%|  | 3301/4096 [16:42<04:01,  3.29it/s, est. speed input: 3370.80 toks/s, output: 3.29 toks/s]
Processed prompts:  81%| | 3333/4096 [16:52<03:51,  3.29it/s, est. speed input: 3370.82 toks/s, output: 3.29 toks/s]
Processed prompts:  82%| | 3365/4096 [17:02<03:42,  3.29it/s, est. speed input: 3370.80 toks/s, output: 3.29 toks/s]
Processed prompts:  83%| | 3397/4096 [17:11<03:32,  3.29it/s, est. speed input: 3370.84 toks/s, output: 3.29 toks/s]
Processed prompts:  84%| | 3429/4096 [17:21<03:22,  3.29it/s, est. speed input: 3370.84 toks/s, output: 3.29 toks/s]
Processed prompts:  84%| | 3461/4096 [17:31<03:12,  3.29it/s, est. speed input: 3370.85 toks/s, output: 3.29 toks/s]
Processed prompts:  85%| | 3493/4096 [17:41<03:03,  3.29it/s, est. speed input: 3370.84 toks/s, output: 3.29 toks/s]
Processed prompts:  86%| | 3525/4096 [17:50<02:53,  3.29it/s, est. speed input: 3370.82 toks/s, output: 3.29 toks/s]
Processed prompts:  87%| | 3557/4096 [18:00<02:43,  3.29it/s, est. speed input: 3370.83 toks/s, output: 3.29 toks/s]
Processed prompts:  88%| | 3589/4096 [18:10<02:34,  3.29it/s, est. speed input: 3370.84 toks/s, output: 3.29 toks/s]
Processed prompts:  88%| | 3621/4096 [18:19<02:24,  3.29it/s, est. speed input: 3370.84 toks/s, output: 3.29 toks/s]
Processed prompts:  89%| | 3653/4096 [18:29<02:14,  3.29it/s, est. speed input: 3370.84 toks/s, output: 3.29 toks/s]
Processed prompts:  90%| | 3685/4096 [18:39<02:03,  3.32it/s, est. speed input: 3371.59 toks/s, output: 3.29 toks/s]
Processed prompts:  91%| | 3717/4096 [18:48<01:54,  3.31it/s, est. speed input: 3371.59 toks/s, output: 3.29 toks/s]
Processed prompts:  92%|| 3749/4096 [18:58<01:45,  3.30it/s, est. speed input: 3371.58 toks/s, output: 3.29 toks/s]
Processed prompts:  92%|| 3781/4096 [19:08<01:35,  3.30it/s, est. speed input: 3371.59 toks/s, output: 3.29 toks/s]
Processed prompts:  93%|| 3813/4096 [19:18<01:25,  3.30it/s, est. speed input: 3371.64 toks/s, output: 3.29 toks/s]
Processed prompts:  94%|| 3845/4096 [19:27<01:16,  3.30it/s, est. speed input: 3371.64 toks/s, output: 3.29 toks/s]
Processed prompts:  95%|| 3877/4096 [19:37<01:06,  3.30it/s, est. speed input: 3371.64 toks/s, output: 3.29 toks/s]
Processed prompts:  95%|| 3909/4096 [19:46<00:56,  3.32it/s, est. speed input: 3372.36 toks/s, output: 3.29 toks/s]
Processed prompts:  96%|| 3941/4096 [19:56<00:46,  3.31it/s, est. speed input: 3372.35 toks/s, output: 3.29 toks/s]
Processed prompts:  97%|| 3973/4096 [20:06<00:37,  3.31it/s, est. speed input: 3372.35 toks/s, output: 3.29 toks/s]
Processed prompts:  98%|| 4005/4096 [20:15<00:27,  3.33it/s, est. speed input: 3373.04 toks/s, output: 3.29 toks/s]
Processed prompts:  99%|| 4037/4096 [20:25<00:17,  3.32it/s, est. speed input: 3373.02 toks/s, output: 3.29 toks/s]
Processed prompts:  99%|| 4069/4096 [20:34<00:07,  3.44it/s, est. speed input: 3376.32 toks/s, output: 3.30 toks/s]
Processed prompts: 100%|| 4096/4096 [20:34<00:00,  3.44it/s, est. speed input: 3398.72 toks/s, output: 3.32 toks/s]
Processed prompts: 100%|| 4096/4096 [20:34<00:00,  3.32it/s, est. speed input: 3398.72 toks/s, output: 3.32 toks/s]
[rank0]:[W127 03:29:47.267854189 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-27 03:29:55
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-14B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 03:30:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 03:30:31 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2061049) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2061049) WARNING 01-27 03:33:44 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.30 requests/s, 3381.94 total tokens/s, 3.30 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-27 03:30:31] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 03:30:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 03:30:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 03:30:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:30:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:30:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:30:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:30:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:30:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 03:30:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 03:30:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 03:30:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 03:30:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 03:30:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 03:30:35] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 03:30:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 03:30:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 03:30:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:30:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:30:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:30:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:30:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 03:30:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 03:30:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 03:30:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 03:30:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 03:30:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 03:30:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2061049) [2026-01-27 03:30:36] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2061049) [2026-01-27 03:30:36] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2061049) [2026-01-27 03:30:36] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2061049) [2026-01-27 03:30:36] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=2061049) [2026-01-27 03:30:36] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=2061049) [2026-01-27 03:30:36] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=2061049) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2061049) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.52s/it]
(EngineCore_DP0 pid=2061049) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:48<00:53, 26.98s/it]
(EngineCore_DP0 pid=2061049) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:19<00:29, 29.03s/it]
(EngineCore_DP0 pid=2061049) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:00<00:00, 33.59s/it]
(EngineCore_DP0 pid=2061049) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:00<00:00, 30.12s/it]
(EngineCore_DP0 pid=2061049) 
(EngineCore_DP0 pid=2061049) [2026-01-27 03:32:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=2061049) [2026-01-27 03:32:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 41287680 bytes
(EngineCore_DP0 pid=2061049) [2026-01-27 03:32:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=2061049) [2026-01-27 03:32:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 29491200 bytes
(EngineCore_DP0 pid=2061049) [2026-01-27 03:32:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=2061049) [2026-01-27 03:32:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 159252480 bytes
(EngineCore_DP0 pid=2061049) [2026-01-27 03:32:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=2061049) [2026-01-27 03:32:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 79626240 bytes
(EngineCore_DP0 pid=2061049) 2026-01-27 03:33:10,119 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2061049) 2026-01-27 03:33:22,740 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/8192 [00:00<2:08:37,  1.06it/s]
Adding requests:   0%|          | 2/8192 [00:01<1:14:33,  1.83it/s]
Adding requests:   0%|          | 3/8192 [00:01<48:41,  2.80it/s]  
Adding requests:   0%|          | 4/8192 [00:01<34:51,  3.91it/s]
Adding requests:   0%|          | 6/8192 [00:01<21:14,  6.42it/s]
Adding requests:   0%|          | 9/8192 [00:01<13:31, 10.08it/s]
Adding requests:   0%|          | 12/8192 [00:01<09:41, 14.06it/s]
Adding requests:   0%|          | 17/8192 [00:01<06:18, 21.60it/s]
Adding requests:   0%|          | 29/8192 [00:02<03:03, 44.58it/s]
Adding requests:   1%|          | 44/8192 [00:02<01:54, 70.89it/s]
Adding requests:   1%|          | 58/8192 [00:02<01:31, 88.86it/s]
Adding requests:   1%|          | 76/8192 [00:02<01:11, 112.90it/s]
Adding requests:   1%|         | 104/8192 [00:02<00:51, 157.58it/s]
Adding requests:   2%|         | 133/8192 [00:02<00:41, 194.70it/s]
Adding requests:   2%|         | 165/8192 [00:02<00:35, 228.65it/s]
Adding requests:   2%|         | 200/8192 [00:02<00:30, 261.66it/s]
Adding requests:   3%|         | 234/8192 [00:02<00:28, 283.52it/s]
Adding requests:   3%|         | 272/8192 [00:02<00:25, 310.84it/s]
Adding requests:   4%|         | 308/8192 [00:03<00:24, 324.46it/s]
Adding requests:   4%|         | 347/8192 [00:03<00:22, 341.72it/s]
Adding requests:   5%|         | 393/8192 [00:03<00:20, 376.67it/s]
Adding requests:   5%|         | 436/8192 [00:03<00:19, 389.99it/s]
Adding requests:   6%|         | 481/8192 [00:03<00:18, 406.75it/s]
Adding requests:   6%|         | 530/8192 [00:03<00:17, 429.53it/s]
Adding requests:   7%|         | 577/8192 [00:03<00:17, 440.60it/s]
Adding requests:   8%|         | 622/8192 [00:03<00:17, 428.92it/s]
Adding requests:   8%|         | 666/8192 [00:03<00:17, 422.08it/s]
Adding requests:   9%|         | 709/8192 [00:03<00:17, 422.42it/s]
Adding requests:   9%|         | 752/8192 [00:04<00:17, 420.62it/s]
Adding requests:  10%|         | 798/8192 [00:04<00:17, 424.87it/s]
Adding requests:  10%|         | 842/8192 [00:04<00:17, 428.72it/s]
Adding requests:  11%|         | 888/8192 [00:04<00:16, 436.89it/s]
Adding requests:  11%|        | 932/8192 [00:04<00:17, 425.55it/s]
Adding requests:  12%|        | 975/8192 [00:04<00:16, 425.95it/s]
Adding requests:  12%|        | 1018/8192 [00:04<00:16, 425.91it/s]
Adding requests:  13%|        | 1061/8192 [00:04<00:17, 412.26it/s]
Adding requests:  13%|        | 1103/8192 [00:04<00:17, 409.66it/s]
Adding requests:  14%|        | 1148/8192 [00:05<00:16, 420.19it/s]
Adding requests:  15%|        | 1191/8192 [00:05<00:16, 420.09it/s]
Adding requests:  15%|        | 1235/8192 [00:05<00:16, 425.23it/s]
Adding requests:  16%|        | 1278/8192 [00:05<00:16, 419.45it/s]
Adding requests:  16%|        | 1321/8192 [00:05<00:16, 421.16it/s]
Adding requests:  17%|        | 1367/8192 [00:05<00:15, 431.05it/s]
Adding requests:  17%|        | 1411/8192 [00:05<00:16, 422.46it/s]
Adding requests:  18%|        | 1454/8192 [00:05<00:15, 424.48it/s]
Adding requests:  18%|        | 1497/8192 [00:05<00:16, 416.19it/s]
Adding requests:  19%|        | 1540/8192 [00:05<00:15, 417.59it/s]
Adding requests:  19%|        | 1582/8192 [00:06<00:15, 417.69it/s]
Adding requests:  20%|        | 1624/8192 [00:06<00:16, 399.45it/s]
Adding requests:  20%|        | 1668/8192 [00:06<00:15, 410.06it/s]
Adding requests:  21%|        | 1710/8192 [00:06<00:15, 407.60it/s]
Adding requests:  21%|       | 1755/8192 [00:06<00:15, 418.28it/s]
Adding requests:  22%|       | 1800/8192 [00:06<00:14, 426.23it/s]
Adding requests:  22%|       | 1843/8192 [00:06<00:14, 424.31it/s]
Adding requests:  23%|       | 1886/8192 [00:06<00:15, 419.57it/s]
Adding requests:  24%|       | 1929/8192 [00:06<00:15, 413.35it/s]
Adding requests:  24%|       | 1972/8192 [00:07<00:14, 417.11it/s]
Adding requests:  25%|       | 2014/8192 [00:07<00:14, 412.29it/s]
Adding requests:  25%|       | 2057/8192 [00:07<00:14, 416.26it/s]
Adding requests:  26%|       | 2099/8192 [00:07<00:14, 415.61it/s]
Adding requests:  26%|       | 2142/8192 [00:07<00:14, 418.77it/s]
Adding requests:  27%|       | 2184/8192 [00:07<00:14, 410.35it/s]
Adding requests:  27%|       | 2227/8192 [00:07<00:14, 415.34it/s]
Adding requests:  28%|       | 2270/8192 [00:07<00:14, 416.35it/s]
Adding requests:  28%|       | 2312/8192 [00:07<00:14, 413.42it/s]
Adding requests:  29%|       | 2356/8192 [00:07<00:13, 419.89it/s]
Adding requests:  29%|       | 2402/8192 [00:08<00:13, 430.13it/s]
Adding requests:  30%|       | 2446/8192 [00:08<00:13, 431.60it/s]
Adding requests:  30%|       | 2490/8192 [00:08<00:13, 427.22it/s]
Adding requests:  31%|       | 2537/8192 [00:08<00:12, 435.07it/s]
Adding requests:  32%|      | 2581/8192 [00:08<00:13, 424.24it/s]
Adding requests:  32%|      | 2629/8192 [00:08<00:12, 439.92it/s]
Adding requests:  33%|      | 2674/8192 [00:08<00:13, 417.37it/s]
Adding requests:  33%|      | 2719/8192 [00:08<00:12, 423.64it/s]
Adding requests:  34%|      | 2762/8192 [00:08<00:13, 415.78it/s]
Adding requests:  34%|      | 2809/8192 [00:08<00:12, 431.17it/s]
Adding requests:  35%|      | 2853/8192 [00:09<00:12, 422.04it/s]
Adding requests:  35%|      | 2896/8192 [00:09<00:12, 421.29it/s]
Adding requests:  36%|      | 2940/8192 [00:09<00:12, 426.21it/s]
Adding requests:  36%|      | 2989/8192 [00:09<00:11, 443.98it/s]
Adding requests:  37%|      | 3034/8192 [00:09<00:11, 445.47it/s]
Adding requests:  38%|      | 3079/8192 [00:09<00:11, 433.52it/s]
Adding requests:  38%|      | 3123/8192 [00:09<00:11, 433.86it/s]
Adding requests:  39%|      | 3167/8192 [00:09<00:11, 433.15it/s]
Adding requests:  39%|      | 3211/8192 [00:09<00:11, 426.57it/s]
Adding requests:  40%|      | 3254/8192 [00:10<00:11, 412.11it/s]
Adding requests:  40%|      | 3296/8192 [00:10<00:12, 401.22it/s]
Adding requests:  41%|      | 3337/8192 [00:10<00:12, 400.76it/s]
Adding requests:  41%|     | 3380/8192 [00:10<00:11, 408.56it/s]
Adding requests:  42%|     | 3424/8192 [00:10<00:11, 414.37it/s]
Adding requests:  42%|     | 3472/8192 [00:10<00:10, 432.87it/s]
Adding requests:  43%|     | 3516/8192 [00:10<00:11, 417.26it/s]
Adding requests:  44%|     | 3564/8192 [00:10<00:10, 433.37it/s]
Adding requests:  44%|     | 3608/8192 [00:10<00:11, 415.14it/s]
Adding requests:  45%|     | 3659/8192 [00:10<00:10, 440.89it/s]
Adding requests:  45%|     | 3704/8192 [00:11<00:10, 421.87it/s]
Adding requests:  46%|     | 3747/8192 [00:11<00:10, 421.50it/s]
Adding requests:  46%|     | 3790/8192 [00:11<00:11, 396.11it/s]
Adding requests:  47%|     | 3831/8192 [00:11<00:11, 396.15it/s]
Adding requests:  47%|     | 3875/8192 [00:11<00:10, 407.38it/s]
Adding requests:  48%|     | 3917/8192 [00:11<00:10, 398.58it/s]
Adding requests:  48%|     | 3961/8192 [00:11<00:10, 409.67it/s]
Adding requests:  49%|     | 4003/8192 [00:11<00:10, 403.18it/s]
Adding requests:  49%|     | 4045/8192 [00:11<00:10, 405.51it/s]
Adding requests:  50%|     | 4086/8192 [00:12<00:10, 401.83it/s]
Adding requests:  50%|     | 4134/8192 [00:12<00:09, 423.40it/s]
Adding requests:  51%|     | 4177/8192 [00:12<00:09, 406.86it/s]
Adding requests:  51%|    | 4218/8192 [00:12<00:09, 407.59it/s]
Adding requests:  52%|    | 4261/8192 [00:12<00:09, 412.87it/s]
Adding requests:  53%|    | 4308/8192 [00:12<00:09, 428.33it/s]
Adding requests:  53%|    | 4351/8192 [00:12<00:09, 413.80it/s]
Adding requests:  54%|    | 4396/8192 [00:12<00:08, 423.78it/s]
Adding requests:  54%|    | 4439/8192 [00:12<00:09, 411.90it/s]
Adding requests:  55%|    | 4488/8192 [00:12<00:08, 427.13it/s]
Adding requests:  55%|    | 4531/8192 [00:13<00:08, 410.74it/s]
Adding requests:  56%|    | 4573/8192 [00:13<00:08, 402.76it/s]
Adding requests:  56%|    | 4616/8192 [00:13<00:08, 403.82it/s]
Adding requests:  57%|    | 4657/8192 [00:13<00:08, 401.05it/s]
Adding requests:  57%|    | 4698/8192 [00:13<00:08, 402.77it/s]
Adding requests:  58%|    | 4741/8192 [00:13<00:08, 408.03it/s]
Adding requests:  58%|    | 4784/8192 [00:13<00:08, 412.28it/s]
Adding requests:  59%|    | 4826/8192 [00:13<00:08, 405.69it/s]
Adding requests:  59%|    | 4869/8192 [00:13<00:08, 409.36it/s]
Adding requests:  60%|    | 4911/8192 [00:14<00:07, 410.80it/s]
Adding requests:  61%|    | 4958/8192 [00:14<00:07, 427.21it/s]
Adding requests:  61%|    | 5001/8192 [00:14<00:07, 411.09it/s]
Adding requests:  62%|   | 5052/8192 [00:14<00:07, 436.87it/s]
Adding requests:  62%|   | 5096/8192 [00:14<00:07, 432.47it/s]
Adding requests:  63%|   | 5148/8192 [00:14<00:06, 457.71it/s]
Adding requests:  63%|   | 5194/8192 [00:14<00:06, 433.30it/s]
Adding requests:  64%|   | 5240/8192 [00:14<00:06, 439.14it/s]
Adding requests:  65%|   | 5285/8192 [00:14<00:06, 430.87it/s]
Adding requests:  65%|   | 5334/8192 [00:15<00:06, 444.27it/s]
Adding requests:  66%|   | 5379/8192 [00:15<00:06, 441.76it/s]
Adding requests:  66%|   | 5424/8192 [00:15<00:06, 427.02it/s]
Adding requests:  67%|   | 5472/8192 [00:15<00:06, 440.03it/s]
Adding requests:  67%|   | 5519/8192 [00:15<00:05, 447.91it/s]
Adding requests:  68%|   | 5564/8192 [00:15<00:05, 446.20it/s]
Adding requests:  68%|   | 5609/8192 [00:15<00:05, 431.96it/s]
Adding requests:  69%|   | 5658/8192 [00:15<00:05, 448.03it/s]
Adding requests:  70%|   | 5703/8192 [00:15<00:05, 431.44it/s]
Adding requests:  70%|   | 5747/8192 [00:15<00:05, 424.74it/s]
Adding requests:  71%|   | 5790/8192 [00:16<00:05, 416.16it/s]
Adding requests:  71%|  | 5839/8192 [00:16<00:05, 436.91it/s]
Adding requests:  72%|  | 5883/8192 [00:16<00:05, 422.16it/s]
Adding requests:  72%|  | 5928/8192 [00:16<00:05, 429.19it/s]
Adding requests:  73%|  | 5972/8192 [00:16<00:05, 423.02it/s]
Adding requests:  73%|  | 6018/8192 [00:16<00:05, 430.57it/s]
Adding requests:  74%|  | 6062/8192 [00:16<00:05, 413.99it/s]
Adding requests:  75%|  | 6104/8192 [00:16<00:05, 412.67it/s]
Adding requests:  75%|  | 6146/8192 [00:16<00:04, 412.26it/s]
Adding requests:  76%|  | 6193/8192 [00:17<00:04, 426.34it/s]
Adding requests:  76%|  | 6236/8192 [00:17<00:04, 423.65it/s]
Adding requests:  77%|  | 6279/8192 [00:17<00:04, 419.83it/s]
Adding requests:  77%|  | 6324/8192 [00:17<00:04, 426.99it/s]
Adding requests:  78%|  | 6368/8192 [00:17<00:04, 429.81it/s]
Adding requests:  78%|  | 6412/8192 [00:17<00:04, 426.88it/s]
Adding requests:  79%|  | 6455/8192 [00:17<00:04, 414.22it/s]
Adding requests:  79%|  | 6497/8192 [00:17<00:04, 415.38it/s]
Adding requests:  80%|  | 6541/8192 [00:17<00:03, 421.53it/s]
Adding requests:  80%|  | 6584/8192 [00:17<00:03, 418.27it/s]
Adding requests:  81%|  | 6626/8192 [00:18<00:03, 411.39it/s]
Adding requests:  81%| | 6671/8192 [00:18<00:03, 422.16it/s]
Adding requests:  82%| | 6714/8192 [00:18<00:03, 415.61it/s]
Adding requests:  83%| | 6760/8192 [00:18<00:03, 425.14it/s]
Adding requests:  83%| | 6803/8192 [00:18<00:03, 417.20it/s]
Adding requests:  84%| | 6847/8192 [00:18<00:03, 421.09it/s]
Adding requests:  84%| | 6890/8192 [00:18<00:03, 411.99it/s]
Adding requests:  85%| | 6934/8192 [00:18<00:02, 419.90it/s]
Adding requests:  85%| | 6977/8192 [00:18<00:02, 407.70it/s]
Adding requests:  86%| | 7030/8192 [00:18<00:02, 442.19it/s]
Adding requests:  86%| | 7075/8192 [00:19<00:02, 419.51it/s]
Adding requests:  87%| | 7118/8192 [00:19<00:02, 421.63it/s]
Adding requests:  87%| | 7161/8192 [00:19<00:02, 414.70it/s]
Adding requests:  88%| | 7207/8192 [00:19<00:02, 426.33it/s]
Adding requests:  89%| | 7252/8192 [00:19<00:02, 431.03it/s]
Adding requests:  89%| | 7296/8192 [00:19<00:02, 431.83it/s]
Adding requests:  90%| | 7341/8192 [00:19<00:01, 436.66it/s]
Adding requests:  90%| | 7386/8192 [00:19<00:01, 437.93it/s]
Adding requests:  91%| | 7430/8192 [00:19<00:01, 425.48it/s]
Adding requests:  91%| | 7473/8192 [00:20<00:01, 420.21it/s]
Adding requests:  92%|| 7516/8192 [00:20<00:01, 417.21it/s]
Adding requests:  92%|| 7558/8192 [00:20<00:01, 417.62it/s]
Adding requests:  93%|| 7600/8192 [00:20<00:01, 416.81it/s]
Adding requests:  93%|| 7642/8192 [00:20<00:01, 415.06it/s]
Adding requests:  94%|| 7690/8192 [00:20<00:01, 434.04it/s]
Adding requests:  94%|| 7734/8192 [00:20<00:01, 424.34it/s]
Adding requests:  95%|| 7777/8192 [00:20<00:00, 425.73it/s]
Adding requests:  95%|| 7820/8192 [00:20<00:00, 415.37it/s]
Adding requests:  96%|| 7863/8192 [00:20<00:00, 418.39it/s]
Adding requests:  96%|| 7905/8192 [00:21<00:00, 417.74it/s]
Adding requests:  97%|| 7952/8192 [00:21<00:00, 431.23it/s]
Adding requests:  98%|| 7996/8192 [00:21<00:00, 429.52it/s]
Adding requests:  98%|| 8041/8192 [00:21<00:00, 435.34it/s]
Adding requests:  99%|| 8085/8192 [00:21<00:00, 427.86it/s]
Adding requests:  99%|| 8128/8192 [00:21<00:00, 421.50it/s]
Adding requests: 100%|| 8172/8192 [00:21<00:00, 425.61it/s]
Adding requests: 100%|| 8192/8192 [00:21<00:00, 376.69it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 25/8192 [00:05<31:55,  4.26it/s, est. speed input: 4365.17 toks/s, output: 4.26 toks/s]
Processed prompts:   1%|          | 89/8192 [00:25<38:46,  3.48it/s, est. speed input: 3622.40 toks/s, output: 3.54 toks/s]
Processed prompts:   2%|         | 153/8192 [00:44<39:15,  3.41it/s, est. speed input: 3540.99 toks/s, output: 3.46 toks/s]
Processed prompts:   3%|         | 217/8192 [01:03<39:27,  3.37it/s, est. speed input: 3495.46 toks/s, output: 3.41 toks/s]
Processed prompts:   3%|         | 281/8192 [01:22<39:13,  3.36it/s, est. speed input: 3479.87 toks/s, output: 3.40 toks/s]
Processed prompts:   4%|         | 345/8192 [01:42<39:09,  3.34it/s, est. speed input: 3461.29 toks/s, output: 3.38 toks/s]
Processed prompts:   5%|         | 409/8192 [02:01<38:48,  3.34it/s, est. speed input: 3455.97 toks/s, output: 3.37 toks/s]
Processed prompts:   6%|         | 473/8192 [02:20<38:38,  3.33it/s, est. speed input: 3445.97 toks/s, output: 3.37 toks/s]
Processed prompts:   7%|         | 537/8192 [02:39<38:24,  3.32it/s, est. speed input: 3438.47 toks/s, output: 3.36 toks/s]
Processed prompts:   7%|         | 601/8192 [02:59<38:09,  3.32it/s, est. speed input: 3432.28 toks/s, output: 3.35 toks/s]
Processed prompts:   8%|         | 665/8192 [03:18<37:52,  3.31it/s, est. speed input: 3427.44 toks/s, output: 3.35 toks/s]
Processed prompts:   9%|         | 729/8192 [03:37<37:26,  3.32it/s, est. speed input: 3427.26 toks/s, output: 3.35 toks/s]
Processed prompts:  10%|         | 793/8192 [03:57<37:11,  3.32it/s, est. speed input: 3423.27 toks/s, output: 3.34 toks/s]
Processed prompts:  10%|         | 857/8192 [04:16<36:55,  3.31it/s, est. speed input: 3419.83 toks/s, output: 3.34 toks/s]
Processed prompts:  11%|         | 921/8192 [04:36<36:39,  3.31it/s, est. speed input: 3416.77 toks/s, output: 3.34 toks/s]
Processed prompts:  12%|        | 985/8192 [04:55<36:21,  3.30it/s, est. speed input: 3414.26 toks/s, output: 3.33 toks/s]
Processed prompts:  13%|        | 1049/8192 [05:14<36:02,  3.30it/s, est. speed input: 3412.08 toks/s, output: 3.33 toks/s]
Processed prompts:  14%|        | 1113/8192 [05:34<35:44,  3.30it/s, est. speed input: 3410.13 toks/s, output: 3.33 toks/s]
Processed prompts:  14%|        | 1177/8192 [05:53<35:16,  3.31it/s, est. speed input: 3410.79 toks/s, output: 3.33 toks/s]
Processed prompts:  15%|        | 1241/8192 [06:12<35:00,  3.31it/s, est. speed input: 3408.94 toks/s, output: 3.33 toks/s]
Processed prompts:  16%|        | 1305/8192 [06:32<34:43,  3.31it/s, est. speed input: 3407.35 toks/s, output: 3.33 toks/s]
Processed prompts:  17%|        | 1369/8192 [06:51<34:26,  3.30it/s, est. speed input: 3405.80 toks/s, output: 3.33 toks/s]
Processed prompts:  17%|        | 1433/8192 [07:11<34:07,  3.30it/s, est. speed input: 3404.47 toks/s, output: 3.32 toks/s]
Processed prompts:  18%|        | 1497/8192 [07:30<33:49,  3.30it/s, est. speed input: 3403.19 toks/s, output: 3.32 toks/s]
Processed prompts:  19%|        | 1561/8192 [07:49<33:23,  3.31it/s, est. speed input: 3403.76 toks/s, output: 3.32 toks/s]
Processed prompts:  20%|        | 1625/8192 [08:08<32:58,  3.32it/s, est. speed input: 3404.32 toks/s, output: 3.32 toks/s]
Processed prompts:  21%|        | 1689/8192 [08:28<32:43,  3.31it/s, est. speed input: 3403.14 toks/s, output: 3.32 toks/s]
Processed prompts:  21%|       | 1753/8192 [08:47<32:28,  3.30it/s, est. speed input: 3401.86 toks/s, output: 3.32 toks/s]
Processed prompts:  22%|       | 1817/8192 [09:07<32:11,  3.30it/s, est. speed input: 3400.76 toks/s, output: 3.32 toks/s]
Processed prompts:  23%|       | 1881/8192 [09:26<31:53,  3.30it/s, est. speed input: 3399.67 toks/s, output: 3.32 toks/s]
Processed prompts:  24%|       | 1945/8192 [09:46<31:35,  3.30it/s, est. speed input: 3398.72 toks/s, output: 3.32 toks/s]
Processed prompts:  25%|       | 2009/8192 [10:05<31:17,  3.29it/s, est. speed input: 3397.71 toks/s, output: 3.32 toks/s]
Processed prompts:  25%|       | 2073/8192 [10:24<30:58,  3.29it/s, est. speed input: 3396.79 toks/s, output: 3.32 toks/s]
Processed prompts:  26%|       | 2137/8192 [10:44<30:32,  3.30it/s, est. speed input: 3397.31 toks/s, output: 3.32 toks/s]
Processed prompts:  27%|       | 2201/8192 [11:03<30:14,  3.30it/s, est. speed input: 3396.60 toks/s, output: 3.32 toks/s]
Processed prompts:  28%|       | 2265/8192 [11:23<29:57,  3.30it/s, est. speed input: 3395.75 toks/s, output: 3.32 toks/s]
Processed prompts:  28%|       | 2329/8192 [11:42<29:39,  3.30it/s, est. speed input: 3395.02 toks/s, output: 3.32 toks/s]
Processed prompts:  29%|       | 2393/8192 [12:01<29:20,  3.29it/s, est. speed input: 3394.36 toks/s, output: 3.31 toks/s]
Processed prompts:  30%|       | 2457/8192 [12:21<29:01,  3.29it/s, est. speed input: 3393.73 toks/s, output: 3.31 toks/s]
Processed prompts:  31%|       | 2521/8192 [12:40<28:43,  3.29it/s, est. speed input: 3393.00 toks/s, output: 3.31 toks/s]
Processed prompts:  32%|      | 2585/8192 [13:00<28:17,  3.30it/s, est. speed input: 3393.46 toks/s, output: 3.31 toks/s]
Processed prompts:  32%|      | 2649/8192 [13:19<28:00,  3.30it/s, est. speed input: 3392.84 toks/s, output: 3.31 toks/s]
Processed prompts:  33%|      | 2713/8192 [13:38<27:35,  3.31it/s, est. speed input: 3393.32 toks/s, output: 3.31 toks/s]
Processed prompts:  34%|      | 2777/8192 [13:58<27:18,  3.30it/s, est. speed input: 3392.79 toks/s, output: 3.31 toks/s]
Processed prompts:  35%|      | 2841/8192 [14:17<27:01,  3.30it/s, est. speed input: 3392.22 toks/s, output: 3.31 toks/s]
Processed prompts:  35%|      | 2905/8192 [14:36<26:31,  3.32it/s, est. speed input: 3393.68 toks/s, output: 3.31 toks/s]
Processed prompts:  36%|      | 2969/8192 [14:55<26:16,  3.31it/s, est. speed input: 3393.16 toks/s, output: 3.31 toks/s]
Processed prompts:  37%|      | 3033/8192 [15:15<26:00,  3.31it/s, est. speed input: 3392.61 toks/s, output: 3.31 toks/s]
Processed prompts:  38%|      | 3097/8192 [15:34<25:43,  3.30it/s, est. speed input: 3392.11 toks/s, output: 3.31 toks/s]
Processed prompts:  39%|      | 3161/8192 [15:54<25:25,  3.30it/s, est. speed input: 3391.63 toks/s, output: 3.31 toks/s]
Processed prompts:  39%|      | 3225/8192 [16:13<25:07,  3.29it/s, est. speed input: 3391.15 toks/s, output: 3.31 toks/s]
Processed prompts:  40%|      | 3289/8192 [16:33<24:48,  3.29it/s, est. speed input: 3390.68 toks/s, output: 3.31 toks/s]
Processed prompts:  41%|      | 3353/8192 [16:52<24:29,  3.29it/s, est. speed input: 3390.26 toks/s, output: 3.31 toks/s]
Processed prompts:  42%|     | 3417/8192 [17:12<24:11,  3.29it/s, est. speed input: 3389.81 toks/s, output: 3.31 toks/s]
Processed prompts:  42%|     | 3481/8192 [17:31<23:51,  3.29it/s, est. speed input: 3389.42 toks/s, output: 3.31 toks/s]
Processed prompts:  43%|     | 3545/8192 [17:51<23:32,  3.29it/s, est. speed input: 3389.07 toks/s, output: 3.31 toks/s]
Processed prompts:  44%|     | 3609/8192 [18:10<23:13,  3.29it/s, est. speed input: 3388.68 toks/s, output: 3.31 toks/s]
Processed prompts:  45%|     | 3673/8192 [18:29<22:48,  3.30it/s, est. speed input: 3389.04 toks/s, output: 3.31 toks/s]
Processed prompts:  46%|     | 3737/8192 [18:49<22:31,  3.30it/s, est. speed input: 3388.65 toks/s, output: 3.31 toks/s]
Processed prompts:  46%|     | 3801/8192 [19:08<22:12,  3.30it/s, est. speed input: 3388.32 toks/s, output: 3.31 toks/s]
Processed prompts:  47%|     | 3865/8192 [19:28<21:53,  3.29it/s, est. speed input: 3388.03 toks/s, output: 3.31 toks/s]
Processed prompts:  48%|     | 3929/8192 [19:47<21:29,  3.31it/s, est. speed input: 3388.43 toks/s, output: 3.31 toks/s]
Processed prompts:  49%|     | 3993/8192 [20:06<21:12,  3.30it/s, est. speed input: 3388.10 toks/s, output: 3.31 toks/s]
Processed prompts:  50%|     | 4057/8192 [20:26<20:49,  3.31it/s, est. speed input: 3388.47 toks/s, output: 3.31 toks/s]
Processed prompts:  50%|     | 4121/8192 [20:45<20:32,  3.30it/s, est. speed input: 3388.16 toks/s, output: 3.31 toks/s]
Processed prompts:  51%|     | 4185/8192 [21:04<20:14,  3.30it/s, est. speed input: 3387.87 toks/s, output: 3.31 toks/s]
Processed prompts:  52%|    | 4249/8192 [21:24<19:55,  3.30it/s, est. speed input: 3387.60 toks/s, output: 3.31 toks/s]
Processed prompts:  53%|    | 4313/8192 [21:43<19:37,  3.30it/s, est. speed input: 3387.32 toks/s, output: 3.31 toks/s]
Processed prompts:  53%|    | 4377/8192 [22:03<19:18,  3.29it/s, est. speed input: 3387.03 toks/s, output: 3.31 toks/s]
Processed prompts:  54%|    | 4441/8192 [22:22<18:54,  3.31it/s, est. speed input: 3387.45 toks/s, output: 3.31 toks/s]
Processed prompts:  55%|    | 4505/8192 [22:41<18:32,  3.31it/s, est. speed input: 3387.84 toks/s, output: 3.31 toks/s]
Processed prompts:  56%|    | 4569/8192 [23:01<18:15,  3.31it/s, est. speed input: 3387.57 toks/s, output: 3.31 toks/s]
Processed prompts:  57%|    | 4633/8192 [23:20<17:57,  3.30it/s, est. speed input: 3387.35 toks/s, output: 3.31 toks/s]
Processed prompts:  57%|    | 4697/8192 [23:40<17:39,  3.30it/s, est. speed input: 3387.12 toks/s, output: 3.31 toks/s]
Processed prompts:  58%|    | 4761/8192 [23:59<17:20,  3.30it/s, est. speed input: 3386.86 toks/s, output: 3.31 toks/s]
Processed prompts:  59%|    | 4825/8192 [24:18<17:01,  3.29it/s, est. speed input: 3386.64 toks/s, output: 3.31 toks/s]
Processed prompts:  60%|    | 4889/8192 [24:38<16:42,  3.29it/s, est. speed input: 3386.43 toks/s, output: 3.31 toks/s]
Processed prompts:  60%|    | 4953/8192 [24:57<16:20,  3.30it/s, est. speed input: 3386.73 toks/s, output: 3.31 toks/s]
Processed prompts:  61%|    | 5017/8192 [25:17<16:02,  3.30it/s, est. speed input: 3386.48 toks/s, output: 3.31 toks/s]
Processed prompts:  62%|   | 5081/8192 [25:36<15:43,  3.30it/s, est. speed input: 3386.27 toks/s, output: 3.31 toks/s]
Processed prompts:  63%|   | 5145/8192 [25:55<15:21,  3.31it/s, est. speed input: 3386.62 toks/s, output: 3.31 toks/s]
Processed prompts:  64%|   | 5209/8192 [26:15<15:02,  3.30it/s, est. speed input: 3386.44 toks/s, output: 3.31 toks/s]
Processed prompts:  64%|   | 5273/8192 [26:34<14:40,  3.31it/s, est. speed input: 3386.81 toks/s, output: 3.31 toks/s]
Processed prompts:  65%|   | 5337/8192 [26:53<14:23,  3.31it/s, est. speed input: 3386.61 toks/s, output: 3.31 toks/s]
Processed prompts:  66%|   | 5401/8192 [27:13<14:05,  3.30it/s, est. speed input: 3386.43 toks/s, output: 3.31 toks/s]
Processed prompts:  67%|   | 5465/8192 [27:32<13:43,  3.31it/s, est. speed input: 3386.77 toks/s, output: 3.31 toks/s]
Processed prompts:  67%|   | 5529/8192 [27:51<13:22,  3.32it/s, est. speed input: 3387.06 toks/s, output: 3.31 toks/s]
Processed prompts:  68%|   | 5593/8192 [28:11<13:05,  3.31it/s, est. speed input: 3386.87 toks/s, output: 3.31 toks/s]
Processed prompts:  69%|   | 5657/8192 [28:30<12:47,  3.30it/s, est. speed input: 3386.66 toks/s, output: 3.31 toks/s]
Processed prompts:  70%|   | 5721/8192 [28:49<12:28,  3.30it/s, est. speed input: 3386.50 toks/s, output: 3.31 toks/s]
Processed prompts:  71%|   | 5785/8192 [29:09<12:10,  3.30it/s, est. speed input: 3386.29 toks/s, output: 3.31 toks/s]
Processed prompts:  71%|  | 5849/8192 [29:28<11:50,  3.30it/s, est. speed input: 3386.15 toks/s, output: 3.31 toks/s]
Processed prompts:  72%|  | 5913/8192 [29:47<11:28,  3.31it/s, est. speed input: 3386.46 toks/s, output: 3.31 toks/s]
Processed prompts:  73%|  | 5977/8192 [30:07<11:07,  3.32it/s, est. speed input: 3386.79 toks/s, output: 3.31 toks/s]
Processed prompts:  74%|  | 6041/8192 [30:26<10:49,  3.31it/s, est. speed input: 3386.63 toks/s, output: 3.31 toks/s]
Processed prompts:  75%|  | 6105/8192 [30:46<10:31,  3.30it/s, est. speed input: 3386.46 toks/s, output: 3.31 toks/s]
Processed prompts:  75%|  | 6169/8192 [31:05<10:13,  3.30it/s, est. speed input: 3386.28 toks/s, output: 3.31 toks/s]
Processed prompts:  76%|  | 6233/8192 [31:24<09:54,  3.30it/s, est. speed input: 3386.10 toks/s, output: 3.31 toks/s]
Processed prompts:  77%|  | 6297/8192 [31:44<09:35,  3.30it/s, est. speed input: 3385.95 toks/s, output: 3.31 toks/s]
Processed prompts:  78%|  | 6361/8192 [32:03<09:15,  3.29it/s, est. speed input: 3385.81 toks/s, output: 3.31 toks/s]
Processed prompts:  78%|  | 6425/8192 [32:23<08:56,  3.29it/s, est. speed input: 3385.62 toks/s, output: 3.31 toks/s]
Processed prompts:  79%|  | 6489/8192 [32:42<08:37,  3.29it/s, est. speed input: 3385.49 toks/s, output: 3.31 toks/s]
Processed prompts:  80%|  | 6553/8192 [33:02<08:17,  3.29it/s, est. speed input: 3385.36 toks/s, output: 3.31 toks/s]
Processed prompts:  81%|  | 6617/8192 [33:21<07:58,  3.29it/s, est. speed input: 3385.21 toks/s, output: 3.31 toks/s]
Processed prompts:  82%| | 6681/8192 [33:41<07:38,  3.29it/s, est. speed input: 3385.10 toks/s, output: 3.31 toks/s]
Processed prompts:  82%| | 6745/8192 [34:00<07:19,  3.29it/s, est. speed input: 3384.95 toks/s, output: 3.31 toks/s]
Processed prompts:  83%| | 6809/8192 [34:19<07:00,  3.29it/s, est. speed input: 3384.81 toks/s, output: 3.31 toks/s]
Processed prompts:  84%| | 6873/8192 [34:39<06:40,  3.29it/s, est. speed input: 3384.68 toks/s, output: 3.31 toks/s]
Processed prompts:  85%| | 6937/8192 [34:58<06:21,  3.29it/s, est. speed input: 3384.54 toks/s, output: 3.31 toks/s]
Processed prompts:  85%| | 7001/8192 [35:18<06:01,  3.29it/s, est. speed input: 3384.42 toks/s, output: 3.31 toks/s]
Processed prompts:  86%| | 7065/8192 [35:37<05:42,  3.29it/s, est. speed input: 3384.27 toks/s, output: 3.30 toks/s]
Processed prompts:  87%| | 7129/8192 [35:57<05:23,  3.29it/s, est. speed input: 3384.12 toks/s, output: 3.30 toks/s]
Processed prompts:  88%| | 7193/8192 [36:16<05:03,  3.29it/s, est. speed input: 3384.02 toks/s, output: 3.30 toks/s]
Processed prompts:  89%| | 7257/8192 [36:36<04:44,  3.29it/s, est. speed input: 3383.87 toks/s, output: 3.30 toks/s]
Processed prompts:  89%| | 7321/8192 [36:55<04:24,  3.29it/s, est. speed input: 3383.73 toks/s, output: 3.30 toks/s]
Processed prompts:  90%| | 7385/8192 [37:14<04:05,  3.29it/s, est. speed input: 3383.62 toks/s, output: 3.30 toks/s]
Processed prompts:  91%| | 7449/8192 [37:34<03:45,  3.29it/s, est. speed input: 3383.47 toks/s, output: 3.30 toks/s]
Processed prompts:  92%|| 7513/8192 [37:53<03:26,  3.29it/s, est. speed input: 3383.37 toks/s, output: 3.30 toks/s]
Processed prompts:  92%|| 7577/8192 [38:13<03:06,  3.29it/s, est. speed input: 3383.25 toks/s, output: 3.30 toks/s]
Processed prompts:  93%|| 7641/8192 [38:32<02:47,  3.29it/s, est. speed input: 3383.15 toks/s, output: 3.30 toks/s]
Processed prompts:  94%|| 7705/8192 [38:52<02:28,  3.29it/s, est. speed input: 3383.03 toks/s, output: 3.30 toks/s]
Processed prompts:  95%|| 7769/8192 [39:11<02:08,  3.29it/s, est. speed input: 3382.92 toks/s, output: 3.30 toks/s]
Processed prompts:  96%|| 7833/8192 [39:31<01:49,  3.29it/s, est. speed input: 3382.80 toks/s, output: 3.30 toks/s]
Processed prompts:  96%|| 7897/8192 [39:50<01:29,  3.29it/s, est. speed input: 3382.69 toks/s, output: 3.30 toks/s]
Processed prompts:  97%|| 7961/8192 [40:09<01:10,  3.29it/s, est. speed input: 3382.60 toks/s, output: 3.30 toks/s]
Processed prompts:  98%|| 8025/8192 [40:29<00:50,  3.29it/s, est. speed input: 3382.51 toks/s, output: 3.30 toks/s]
Processed prompts:  99%|| 8089/8192 [40:48<00:31,  3.29it/s, est. speed input: 3382.43 toks/s, output: 3.30 toks/s]
Processed prompts: 100%|| 8153/8192 [41:01<00:10,  3.71it/s, est. speed input: 3392.27 toks/s, output: 3.31 toks/s]
Processed prompts: 100%|| 8192/8192 [41:01<00:00,  3.71it/s, est. speed input: 3408.50 toks/s, output: 3.33 toks/s]
Processed prompts: 100%|| 8192/8192 [41:01<00:00,  3.33it/s, est. speed input: 3408.50 toks/s, output: 3.33 toks/s]
[rank0]:[W127 04:15:18.474322687 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

