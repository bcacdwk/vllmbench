
========== M=16 ==========
Time: 2026-01-25 18:39:44
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M16.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:39:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:39:47 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=289184) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=289184) 
(EngineCore_DP0 pid=289184) 
(EngineCore_DP0 pid=289184) ================================================================
(EngineCore_DP0 pid=289184) Internal Triton PTX codegen error
(EngineCore_DP0 pid=289184) `ptxas` stderr:
(EngineCore_DP0 pid=289184) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=289184) 
(EngineCore_DP0 pid=289184) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp8c3q7a1r.ptx -o /tmp/tmp8c3q7a1r.ptx.o
(EngineCore_DP0 pid=289184) 
(EngineCore_DP0 pid=289184) 
(EngineCore_DP0 pid=289184) //
(EngineCore_DP0 pid=289184) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=289184) //
(EngineCore_DP0 pid=289184) 
(EngineCore_DP0 pid=289184) .version 8.7
(EngineCore_DP0 pid=289184) .target sm_121a
(EngineCore_DP0 pid=289184) .address_size 64
(EngineCore_DP0 pid=289184) 
(EngineCore_DP0 pid=289184) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=289184) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=289184)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=289184) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=289184) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=289184) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=289184) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=289184) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=289184) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=289184) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=289184) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=289184) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=289184) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=289184) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=289184) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=289184) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=289184) )
(EngineCore_DP0 pid=289184) .reqntid 512
(EngineCore_DP0 pid=289184) {
(EngineCore_DP0 pid=289184) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=289184) 	.reg .b16 	%rs<32>;
(EngineCore_DP0 pid=289184) 	.reg .b32 	%r<122>;
(EngineCore_DP0 pid=289184) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=289184) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=289184) $L__func_begin0:
(EngineCore_DP0 pid=289184) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=289184) 
(EngineCore_DP0 pid=289184) // %bb.0:
(EngineCore_DP0 pid=289184) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=289184) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=289184) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=289184) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=289184) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=289184) $L__tmp0:
(EngineCore_DP0 pid=289184) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=289184) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=289184) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=289184) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=289184) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=289184) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=289184) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=289184) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=289184) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=289184) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=289184) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=289184) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=289184) 	mov.b32 	%r120, 0f2B8CBCCC;
(EngineCore_DP0 pid=289184) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=289184) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=289184) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=289184) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=289184) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=289184) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=289184) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=289184) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=289184) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=289184) 	add.s32 	%r44, %r34, %r33;
(EngineCore_DP0 pid=289184) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=289184) 	add.s32 	%r47, %r34, %r35;
(EngineCore_DP0 pid=289184) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=289184) 	mov.b32 	%r118, 0f00000000;
(EngineCore_DP0 pid=289184) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=289184) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=289184) 	mov.b32 	%r119, %r40;
(EngineCore_DP0 pid=289184) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=289184) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=289184) 	add.s32 	%r50, %r4, %r119;
(EngineCore_DP0 pid=289184) 	setp.lt.s32 	%p2, %r50, %r18;
(EngineCore_DP0 pid=289184) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=289184) 	mad.wide.s32 	%rd6, %r50, 2, %rd1;
(EngineCore_DP0 pid=289184) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=289184) 	// begin inline asm
(EngineCore_DP0 pid=289184) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=289184) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=289184) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=289184) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=289184) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=289184) 	// end inline asm
(EngineCore_DP0 pid=289184) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=289184) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=289184) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=289184) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=289184) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=289184) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=289184) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=289184) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=289184) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=289184) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=289184) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=289184) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=289184) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=289184) $L__tmp1:
(EngineCore_DP0 pid=289184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	bar.sync 	0;
(EngineCore_DP0 pid=289184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=289184) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=289184) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=289184) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=289184) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=289184) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=289184) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=289184) 	cvt.f32.bf16 	%r51, %rs23;
(EngineCore_DP0 pid=289184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	shfl.sync.bfly.b32 	%r52, %r51, 16, 31, -1;
(EngineCore_DP0 pid=289184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=289184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	shfl.sync.bfly.b32 	%r54, %r53, 8, 31, -1;
(EngineCore_DP0 pid=289184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=289184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	shfl.sync.bfly.b32 	%r56, %r55, 4, 31, -1;
(EngineCore_DP0 pid=289184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=289184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	shfl.sync.bfly.b32 	%r58, %r57, 2, 31, -1;
(EngineCore_DP0 pid=289184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=289184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	shfl.sync.bfly.b32 	%r60, %r59, 1, 31, -1;
(EngineCore_DP0 pid=289184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	max.f32 	%r45, %r59, %r60;
(EngineCore_DP0 pid=289184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	// begin inline asm
(EngineCore_DP0 pid=289184) 	@%p3 st.shared.b32 [ %r44 + 0 ], %r45;
(EngineCore_DP0 pid=289184) 	// end inline asm
(EngineCore_DP0 pid=289184) 	bar.sync 	0;
(EngineCore_DP0 pid=289184) 	// begin inline asm
(EngineCore_DP0 pid=289184) 	@%p4 ld.shared.b32 %r46, [ %r47 + 0 ];
(EngineCore_DP0 pid=289184) 	// end inline asm
(EngineCore_DP0 pid=289184) 	shfl.sync.bfly.b32 	%r61, %r46, 8, 31, -1;
(EngineCore_DP0 pid=289184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	max.f32 	%r62, %r46, %r61;
(EngineCore_DP0 pid=289184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	shfl.sync.bfly.b32 	%r63, %r62, 4, 31, -1;
(EngineCore_DP0 pid=289184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=289184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	shfl.sync.bfly.b32 	%r65, %r64, 2, 31, -1;
(EngineCore_DP0 pid=289184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=289184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	shfl.sync.bfly.b32 	%r67, %r66, 1, 31, -1;
(EngineCore_DP0 pid=289184) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	max.f32 	%r49, %r66, %r67;
(EngineCore_DP0 pid=289184) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289184) 	// begin inline asm
(EngineCore_DP0 pid=289184) 	@%p19 st.shared.b32 [ %r47 + 0 ], %r49;
(EngineCore_DP0 pid=289184) 	// end inline asm
(EngineCore_DP0 pid=289184) 	bar.sync 	0;
(EngineCore_DP0 pid=289184) 	ld.shared.b32 	%r68, [global_smem];
(EngineCore_DP0 pid=289184) $L__tmp2:
(EngineCore_DP0 pid=289184) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=289184) 	max.f32 	%r118, %r118, %r68;
(EngineCore_DP0 pid=289184) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=289184) 	add.s32 	%r119, %r119, 4096;
(EngineCore_DP0 pid=289184) 	setp.lt.s32 	%p6, %r119, %r19;
(EngineCore_DP0 pid=289184) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=289184) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=289184) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=289184) 	max.f32 	%r120, %r118, 0f2B8CBCCC;
(EngineCore_DP0 pid=289184) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=289184) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=289184) 	mov.b32 	%r70, 0f42FE0000;
(EngineCore_DP0 pid=289184) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=289184) 	div.full.f32 	%r71, %r120, %r70;
(EngineCore_DP0 pid=289184) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=289184) 	max.f32 	%r69, %r71, 0f37810204;
(EngineCore_DP0 pid=289184) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=289184) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=289184) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=289184) 	// begin inline asm
(EngineCore_DP0 pid=289184) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r69 };
(EngineCore_DP0 pid=289184) 	// end inline asm
(EngineCore_DP0 pid=289184) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=289184) 	shl.b32 	%r15, %r20, 1;
(EngineCore_DP0 pid=289184) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=289184) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=289184) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=289184) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=289184) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=289184) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=289184) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=289184) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=289184) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=289184) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=289184) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=289184) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=289184) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=289184) 	div.full.f32 	%r14, %r70, %r120;
(EngineCore_DP0 pid=289184) 	mov.b32 	%r121, 0;
(EngineCore_DP0 pid=289184) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=289184)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=289184) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=289184) 	add.s32 	%r75, %r3, %r121;
(EngineCore_DP0 pid=289184) 	setp.lt.s32 	%p13, %r75, %r15;
(EngineCore_DP0 pid=289184) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=289184) 	shr.u32 	%r76, %r75, 31;
(EngineCore_DP0 pid=289184) 	add.s32 	%r77, %r75, %r76;
(EngineCore_DP0 pid=289184) 	shr.u32 	%r78, %r77, 1;
(EngineCore_DP0 pid=289184) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=289184) 	and.b32 	%r79, %r77, 2147483646;
(EngineCore_DP0 pid=289184) 	sub.s32 	%r80, %r75, %r79;
(EngineCore_DP0 pid=289184) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=289184) 	shl.b32 	%r81, %r80, 1;
(EngineCore_DP0 pid=289184) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=289184) 	mad.lo.s32 	%r82, %r78, 6, %r81;
(EngineCore_DP0 pid=289184) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=289184) 	setp.lt.s32 	%p14, %r82, %r18;
(EngineCore_DP0 pid=289184) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=289184) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=289184) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=289184) 	mad.wide.s32 	%rd8, %r82, 2, %rd1;
(EngineCore_DP0 pid=289184) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=289184) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=289184) 	// begin inline asm
(EngineCore_DP0 pid=289184) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=289184) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=289184) 	// end inline asm
(EngineCore_DP0 pid=289184) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=289184) 	cvt.f32.bf16 	%r83, %rs24;
(EngineCore_DP0 pid=289184) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=289184) 	or.b32 	%r84, %r82, 1;
(EngineCore_DP0 pid=289184) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=289184) 	setp.lt.s32 	%p15, %r84, %r18;
(EngineCore_DP0 pid=289184) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=289184) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=289184) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=289184) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=289184) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=289184) 	// begin inline asm
(EngineCore_DP0 pid=289184) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=289184) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=289184) 	// end inline asm
(EngineCore_DP0 pid=289184) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=289184) 	cvt.f32.bf16 	%r85, %rs26;
(EngineCore_DP0 pid=289184) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=289184) 	add.s32 	%r86, %r82, 2;
(EngineCore_DP0 pid=289184) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=289184) 	setp.lt.s32 	%p16, %r86, %r18;
(EngineCore_DP0 pid=289184) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=289184) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=289184) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=289184) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=289184) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=289184) 	// begin inline asm
(EngineCore_DP0 pid=289184) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=289184) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=289184) 	// end inline asm
(EngineCore_DP0 pid=289184) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=289184) 	cvt.f32.bf16 	%r87, %rs28;
(EngineCore_DP0 pid=289184) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=289184) 	add.s32 	%r88, %r82, 3;
(EngineCore_DP0 pid=289184) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=289184) 	setp.lt.s32 	%p17, %r88, %r18;
(EngineCore_DP0 pid=289184) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=289184) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=289184) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=289184) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=289184) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=289184) 	// begin inline asm
(EngineCore_DP0 pid=289184) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=289184) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=289184) 	// end inline asm
(EngineCore_DP0 pid=289184) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=289184) 	cvt.f32.bf16 	%r89, %rs30;
(EngineCore_DP0 pid=289184) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=289184) 	mul.f32 	%r90, %r14, %r83;
(EngineCore_DP0 pid=289184) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=289184) 	cvt.rni.f32.f32 	%r91, %r90;
(EngineCore_DP0 pid=289184) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=289184) 	max.f32 	%r92, %r91, 0fC3000000;
(EngineCore_DP0 pid=289184) 	min.f32 	%r93, %r92, 0f42FE0000;
(EngineCore_DP0 pid=289184) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=289184) 	cvt.rzi.s32.f32 	%r94, %r93;
(EngineCore_DP0 pid=289184) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=289184) 	and.b32 	%r95, %r94, 255;
(EngineCore_DP0 pid=289184) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=289184) 	mul.f32 	%r96, %r14, %r85;
(EngineCore_DP0 pid=289184) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=289184) 	cvt.rni.f32.f32 	%r97, %r96;
(EngineCore_DP0 pid=289184) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=289184) 	mul.f32 	%r98, %r14, %r87;
(EngineCore_DP0 pid=289184) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=289184) 	cvt.rni.f32.f32 	%r99, %r98;
(EngineCore_DP0 pid=289184) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=289184) 	mul.f32 	%r100, %r14, %r89;
(EngineCore_DP0 pid=289184) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=289184) 	cvt.rni.f32.f32 	%r101, %r100;
(EngineCore_DP0 pid=289184) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=289184) 	max.f32 	%r102, %r101, 0fC3000000;
(EngineCore_DP0 pid=289184) 	min.f32 	%r103, %r102, 0f42FE0000;
(EngineCore_DP0 pid=289184) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=289184) 	cvt.rzi.s32.f32 	%r104, %r103;
(EngineCore_DP0 pid=289184) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=289184) 	max.f32 	%r105, %r99, 0fC3000000;
(EngineCore_DP0 pid=289184) 	max.f32 	%r106, %r97, 0fC3000000;
(EngineCore_DP0 pid=289184) 	min.f32 	%r107, %r106, 0f42FE0000;
(EngineCore_DP0 pid=289184) 	min.f32 	%r108, %r105, 0f42FE0000;
(EngineCore_DP0 pid=289184) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=289184) 	cvt.rzi.s32.f32 	%r109, %r108;
(EngineCore_DP0 pid=289184) 	cvt.rzi.s32.f32 	%r110, %r107;
(EngineCore_DP0 pid=289184) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=289184) 	shl.b32 	%r111, %r110, 8;
(EngineCore_DP0 pid=289184) 	shl.b32 	%r112, %r109, 16;
(EngineCore_DP0 pid=289184) 	and.b32 	%r113, %r112, 16711680;
(EngineCore_DP0 pid=289184) 	and.b32 	%r114, %r111, 65280;
(EngineCore_DP0 pid=289184) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=289184) 	or.b32 	%r115, %r114, %r95;
(EngineCore_DP0 pid=289184) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=289184) 	or.b32 	%r116, %r115, %r113;
(EngineCore_DP0 pid=289184) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=289184) 	shl.b32 	%r117, %r104, 24;
(EngineCore_DP0 pid=289184) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=289184) 	or.b32 	%r73, %r116, %r117;
(EngineCore_DP0 pid=289184) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=289184) 	mad.wide.s32 	%rd12, %r75, 4, %rd2;
(EngineCore_DP0 pid=289184) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=289184) 	// begin inline asm
(EngineCore_DP0 pid=289184) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r73 };
(EngineCore_DP0 pid=289184) 	// end inline asm
(EngineCore_DP0 pid=289184) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=289184) 	add.s32 	%r121, %r121, 512;
(EngineCore_DP0 pid=289184) 	setp.lt.s32 	%p18, %r121, %r15;
(EngineCore_DP0 pid=289184) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=289184) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=289184) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=289184) 	ret;
(EngineCore_DP0 pid=289184) $L__tmp3:
(EngineCore_DP0 pid=289184) $L__func_end0:
(EngineCore_DP0 pid=289184)                                         // -- End function
(EngineCore_DP0 pid=289184) }
(EngineCore_DP0 pid=289184) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=289184) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=289184) 	.section	.debug_abbrev
(EngineCore_DP0 pid=289184) 	{
(EngineCore_DP0 pid=289184) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=289184) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=289184) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=289184) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=289184) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=289184) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=289184) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=289184) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=289184) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=289184) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=289184) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=289184) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=289184) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=289184) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=289184) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=289184) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=289184) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=289184) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=289184) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=289184) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=289184) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=289184) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=289184) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=289184) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=289184) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=289184) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=289184) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=289184) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=289184) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=289184) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=289184) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=289184) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=289184) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=289184) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=289184) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=289184) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=289184) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=289184) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=289184) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=289184) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=289184) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=289184) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=289184) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=289184) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=289184) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=289184) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=289184) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=289184) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=289184) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=289184) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=289184) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=289184) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=289184) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=289184) 	}
(EngineCore_DP0 pid=289184) 	.section	.debug_info
(EngineCore_DP0 pid=289184) 	{
(EngineCore_DP0 pid=289184) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=289184) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=289184) .b8 0
(EngineCore_DP0 pid=289184) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=289184) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=289184) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=289184) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=289184) .b8 114
(EngineCore_DP0 pid=289184) .b8 105
(EngineCore_DP0 pid=289184) .b8 116
(EngineCore_DP0 pid=289184) .b8 111
(EngineCore_DP0 pid=289184) .b8 110
(EngineCore_DP0 pid=289184) .b8 0
(EngineCore_DP0 pid=289184) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=289184) .b8 0
(EngineCore_DP0 pid=289184) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=289184) .b8 117
(EngineCore_DP0 pid=289184) .b8 97
(EngineCore_DP0 pid=289184) .b8 110
(EngineCore_DP0 pid=289184) .b8 116
(EngineCore_DP0 pid=289184) .b8 95
(EngineCore_DP0 pid=289184) .b8 115
(EngineCore_DP0 pid=289184) .b8 108
(EngineCore_DP0 pid=289184) .b8 105
(EngineCore_DP0 pid=289184) .b8 100
(EngineCore_DP0 pid=289184) .b8 101
(EngineCore_DP0 pid=289184) .b8 95
(EngineCore_DP0 pid=289184) .b8 116
(EngineCore_DP0 pid=289184) .b8 117
(EngineCore_DP0 pid=289184) .b8 110
(EngineCore_DP0 pid=289184) .b8 101
(EngineCore_DP0 pid=289184) .b8 100
(EngineCore_DP0 pid=289184) .b8 95
(EngineCore_DP0 pid=289184) .b8 76
(EngineCore_DP0 pid=289184) .b8 108
(EngineCore_DP0 pid=289184) .b8 97
(EngineCore_DP0 pid=289184) .b8 109
(EngineCore_DP0 pid=289184) .b8 97
(EngineCore_DP0 pid=289184) .b8 51
(EngineCore_DP0 pid=289184) .b8 46
(EngineCore_DP0 pid=289184) .b8 50
(EngineCore_DP0 pid=289184) .b8 45
(EngineCore_DP0 pid=289184) .b8 49
(EngineCore_DP0 pid=289184) .b8 66
(EngineCore_DP0 pid=289184) .b8 46
(EngineCore_DP0 pid=289184) .b8 112
(EngineCore_DP0 pid=289184) .b8 121
(EngineCore_DP0 pid=289184) .b8 0
(EngineCore_DP0 pid=289184) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=289184) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=289184) .b8 114
(EngineCore_DP0 pid=289184) .b8 111
(EngineCore_DP0 pid=289184) .b8 111
(EngineCore_DP0 pid=289184) .b8 116
(EngineCore_DP0 pid=289184) .b8 47
(EngineCore_DP0 pid=289184) .b8 118
(EngineCore_DP0 pid=289184) .b8 108
(EngineCore_DP0 pid=289184) .b8 108
(EngineCore_DP0 pid=289184) .b8 109
(EngineCore_DP0 pid=289184) .b8 98
(EngineCore_DP0 pid=289184) .b8 101
(EngineCore_DP0 pid=289184) .b8 110
(EngineCore_DP0 pid=289184) .b8 99
(EngineCore_DP0 pid=289184) .b8 104
(EngineCore_DP0 pid=289184) .b8 47
(EngineCore_DP0 pid=289184) .b8 115
(EngineCore_DP0 pid=289184) .b8 108
(EngineCore_DP0 pid=289184) .b8 105
(EngineCore_DP0 pid=289184) .b8 100
(EngineCore_DP0 pid=289184) .b8 101
(EngineCore_DP0 pid=289184) .b8 115
(EngineCore_DP0 pid=289184) .b8 112
(EngineCore_DP0 pid=289184) .b8 97
(EngineCore_DP0 pid=289184) .b8 114
(EngineCore_DP0 pid=289184) .b8 115
(EngineCore_DP0 pid=289184) .b8 101
(EngineCore_DP0 pid=289184) .b8 47
(EngineCore_DP0 pid=289184) .b8 99
(EngineCore_DP0 pid=289184) .b8 115
(EngineCore_DP0 pid=289184) .b8 114
(EngineCore_DP0 pid=289184) .b8 99
(EngineCore_DP0 pid=289184) .b8 47
(EngineCore_DP0 pid=289184) .b8 102
(EngineCore_DP0 pid=289184) .b8 117
(EngineCore_DP0 pid=289184) .b8 115
(EngineCore_DP0 pid=289184) .b8 101
(EngineCore_DP0 pid=289184) .b8 100
(EngineCore_DP0 pid=289184) .b8 95
(EngineCore_DP0 pid=289184) .b8 113
(EngineCore_DP0 pid=289184) .b8 117
(EngineCore_DP0 pid=289184) .b8 97
(EngineCore_DP0 pid=289184) .b8 110
(EngineCore_DP0 pid=289184) .b8 116
(EngineCore_DP0 pid=289184) .b8 95
(EngineCore_DP0 pid=289184) .b8 115
(EngineCore_DP0 pid=289184) .b8 108
(EngineCore_DP0 pid=289184) .b8 105
(EngineCore_DP0 pid=289184) .b8 100
(EngineCore_DP0 pid=289184) .b8 101
(EngineCore_DP0 pid=289184) .b8 95
(EngineCore_DP0 pid=289184) .b8 116
(EngineCore_DP0 pid=289184) .b8 114
(EngineCore_DP0 pid=289184) .b8 105
(EngineCore_DP0 pid=289184) .b8 116
(EngineCore_DP0 pid=289184) .b8 111
(EngineCore_DP0 pid=289184) .b8 110
(EngineCore_DP0 pid=289184) .b8 47
(EngineCore_DP0 pid=289184) .b8 98
(EngineCore_DP0 pid=289184) .b8 117
(EngineCore_DP0 pid=289184) .b8 105
(EngineCore_DP0 pid=289184) .b8 108
(EngineCore_DP0 pid=289184) .b8 100
(EngineCore_DP0 pid=289184) .b8 47
(EngineCore_DP0 pid=289184) .b8 71
(EngineCore_DP0 pid=289184) .b8 66
(EngineCore_DP0 pid=289184) .b8 49
(EngineCore_DP0 pid=289184) .b8 48
(EngineCore_DP0 pid=289184) .b8 95
(EngineCore_DP0 pid=289184) .b8 99
(EngineCore_DP0 pid=289184) .b8 99
(EngineCore_DP0 pid=289184) .b8 49
(EngineCore_DP0 pid=289184) .b8 50
(EngineCore_DP0 pid=289184) .b8 49
(EngineCore_DP0 pid=289184) .b8 95
(EngineCore_DP0 pid=289184) .b8 112
(EngineCore_DP0 pid=289184) .b8 121
(EngineCore_DP0 pid=289184) .b8 51
(EngineCore_DP0 pid=289184) .b8 49
(EngineCore_DP0 pid=289184) .b8 50
(EngineCore_DP0 pid=289184) .b8 95
(EngineCore_DP0 pid=289184) .b8 99
(EngineCore_DP0 pid=289184) .b8 117
(EngineCore_DP0 pid=289184) .b8 49
(EngineCore_DP0 pid=289184) .b8 50
(EngineCore_DP0 pid=289184) .b8 57
(EngineCore_DP0 pid=289184) .b8 95
(EngineCore_DP0 pid=289184) .b8 97
(EngineCore_DP0 pid=289184) .b8 97
(EngineCore_DP0 pid=289184) .b8 114
(EngineCore_DP0 pid=289184) .b8 99
(EngineCore_DP0 pid=289184) .b8 104
(EngineCore_DP0 pid=289184) .b8 54
(EngineCore_DP0 pid=289184) .b8 52
(EngineCore_DP0 pid=289184) .b8 0
(EngineCore_DP0 pid=289184) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=289184) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=289184) .b8 113
(EngineCore_DP0 pid=289184) .b8 117
(EngineCore_DP0 pid=289184) .b8 97
(EngineCore_DP0 pid=289184) .b8 110
(EngineCore_DP0 pid=289184) .b8 116
(EngineCore_DP0 pid=289184) .b8 95
(EngineCore_DP0 pid=289184) .b8 115
(EngineCore_DP0 pid=289184) .b8 108
(EngineCore_DP0 pid=289184) .b8 105
(EngineCore_DP0 pid=289184) .b8 100
(EngineCore_DP0 pid=289184) .b8 101
(EngineCore_DP0 pid=289184) .b8 95
(EngineCore_DP0 pid=289184) .b8 105
(EngineCore_DP0 pid=289184) .b8 110
(EngineCore_DP0 pid=289184) .b8 116
(EngineCore_DP0 pid=289184) .b8 56
(EngineCore_DP0 pid=289184) .b8 95
(EngineCore_DP0 pid=289184) .b8 107
(EngineCore_DP0 pid=289184) .b8 101
(EngineCore_DP0 pid=289184) .b8 114
(EngineCore_DP0 pid=289184) .b8 110
(EngineCore_DP0 pid=289184) .b8 101
(EngineCore_DP0 pid=289184) .b8 108
(EngineCore_DP0 pid=289184) .b8 0
(EngineCore_DP0 pid=289184) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=289184) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=289184) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=289184) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=289184) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=289184) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=289184) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=289184) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=289184) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=289184) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=289184) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=289184) .b8 1
(EngineCore_DP0 pid=289184) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=289184) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=289184) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=289184) 	}
(EngineCore_DP0 pid=289184) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=289184) 
(EngineCore_DP0 pid=289184) ================================================================
(EngineCore_DP0 pid=289184) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=289184) 
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp8c3q7a1r.ptx', '-o', '/tmp/tmp8c3q7a1r.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866] 
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866] 
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866] 
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp8c3q7a1r.ptx -o /tmp/tmp8c3q7a1r.ptx.o
(EngineCore_DP0 pid=289184) ERROR 01-25 18:40:02 [core.py:866] 

STDERR:
[2026-01-25 18:39:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:39:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:39:47] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:39:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:39:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:39:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:39:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:39:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:39:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:39:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:39:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:39:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:39:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:39:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:39:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:39:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:39:50] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:39:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:39:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:39:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:39:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:39:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:39:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:39:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:39:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:39:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:39:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:39:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=289184) [2026-01-25 18:39:51] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=289184) [2026-01-25 18:39:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=289184) [2026-01-25 18:39:51] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=289184) [2026-01-25 18:39:51] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=289184) [2026-01-25 18:39:51] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=289184) [2026-01-25 18:39:51] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=289184) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=289184) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.30s/it]
(EngineCore_DP0 pid=289184) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.30s/it]
(EngineCore_DP0 pid=289184) 
(EngineCore_DP0 pid=289184) [2026-01-25 18:40:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=289184) [2026-01-25 18:40:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=289184) [2026-01-25 18:40:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=289184) [2026-01-25 18:40:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=289184) [2026-01-25 18:40:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=289184) [2026-01-25 18:40:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=289184) [2026-01-25 18:40:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=289184) [2026-01-25 18:40:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=289184) Process EngineCore_DP0:
(EngineCore_DP0 pid=289184) Traceback (most recent call last):
(EngineCore_DP0 pid=289184)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=289184)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=289184)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=289184)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=289184) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp8c3q7a1r.ptx', '-o', '/tmp/tmp8c3q7a1r.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=289184) 
(EngineCore_DP0 pid=289184) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=289184) 
(EngineCore_DP0 pid=289184) Traceback (most recent call last):
(EngineCore_DP0 pid=289184)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=289184)     self.run()
(EngineCore_DP0 pid=289184)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=289184)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=289184)     raise e
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=289184)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=289184)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=289184)     super().__init__(
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=289184)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=289184)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=289184)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=289184)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=289184)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=289184)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=289184)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=289184)     return func(*args, **kwargs)
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=289184)     return func(*args, **kwargs)
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=289184)     self.model_runner.profile_run()
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=289184)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=289184)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=289184)     return func(*args, **kwargs)
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=289184)     outputs = self.model(
(EngineCore_DP0 pid=289184)               ^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=289184)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=289184)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=289184)     model_output = self.model(
(EngineCore_DP0 pid=289184)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=289184)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=289184)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=289184)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=289184)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=289184)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=289184)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=289184)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=289184)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=289184)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=289184)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=289184)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=289184)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=289184)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=289184)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=289184)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=289184)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=289184)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=289184)     return self._linear_fn(
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=289184)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=289184)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=289184)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=289184)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=289184)     return fn(input, L)
(EngineCore_DP0 pid=289184)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=289184)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=289184)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=289184)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=289184)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=289184)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=289184)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=289184)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=289184)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=289184)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=289184)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=289184)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=289184)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289184)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=289184)     raise PTXASError(error)
(EngineCore_DP0 pid=289184) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=289184) `ptxas` stderr:
(EngineCore_DP0 pid=289184) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=289184) 
(EngineCore_DP0 pid=289184) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp8c3q7a1r.ptx -o /tmp/tmp8c3q7a1r.ptx.o
(EngineCore_DP0 pid=289184) 
[rank0]:[W125 18:40:03.289135748 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16

========== M=128 ==========
Time: 2026-01-25 18:40:04
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M128.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:40:08 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:40:08 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=289663) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=289663) 
(EngineCore_DP0 pid=289663) 
(EngineCore_DP0 pid=289663) ================================================================
(EngineCore_DP0 pid=289663) Internal Triton PTX codegen error
(EngineCore_DP0 pid=289663) `ptxas` stderr:
(EngineCore_DP0 pid=289663) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=289663) 
(EngineCore_DP0 pid=289663) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpyqy2e_wj.ptx -o /tmp/tmpyqy2e_wj.ptx.o
(EngineCore_DP0 pid=289663) 
(EngineCore_DP0 pid=289663) 
(EngineCore_DP0 pid=289663) //
(EngineCore_DP0 pid=289663) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=289663) //
(EngineCore_DP0 pid=289663) 
(EngineCore_DP0 pid=289663) .version 8.7
(EngineCore_DP0 pid=289663) .target sm_121a
(EngineCore_DP0 pid=289663) .address_size 64
(EngineCore_DP0 pid=289663) 
(EngineCore_DP0 pid=289663) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=289663) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=289663)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=289663) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=289663) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=289663) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=289663) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=289663) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=289663) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=289663) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=289663) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=289663) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=289663) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=289663) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=289663) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=289663) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=289663) )
(EngineCore_DP0 pid=289663) .reqntid 128
(EngineCore_DP0 pid=289663) {
(EngineCore_DP0 pid=289663) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=289663) 	.reg .b16 	%rs<64>;
(EngineCore_DP0 pid=289663) 	.reg .b32 	%r<165>;
(EngineCore_DP0 pid=289663) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=289663) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=289663) $L__func_begin0:
(EngineCore_DP0 pid=289663) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=289663) 
(EngineCore_DP0 pid=289663) // %bb.0:
(EngineCore_DP0 pid=289663) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=289663) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=289663) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=289663) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=289663) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=289663) $L__tmp0:
(EngineCore_DP0 pid=289663) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=289663) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=289663) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=289663) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=289663) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=289663) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=289663) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=289663) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=289663) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=289663) 	and.b32 	%r3, %r2, 127;
(EngineCore_DP0 pid=289663) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=289663) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=289663) 	mov.b32 	%r163, 0f2B8CBCCC;
(EngineCore_DP0 pid=289663) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=289663) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=289663) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=289663) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=289663) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=289663) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=289663) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=289663) 	and.b32 	%r34, %r33, 12;
(EngineCore_DP0 pid=289663) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=289663) 	add.s32 	%r53, %r35, %r34;
(EngineCore_DP0 pid=289663) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=289663) 	add.s32 	%r56, %r35, %r36;
(EngineCore_DP0 pid=289663) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=289663) 	mov.b32 	%r161, 0f00000000;
(EngineCore_DP0 pid=289663) 	setp.lt.u32 	%p5, %r2, 4;
(EngineCore_DP0 pid=289663) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=289663) 	mov.b32 	%r162, %r41;
(EngineCore_DP0 pid=289663) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=289663) 	.loc	1 299 19                        // quant_slide_tuned_Llama3.2-1B.py:299:19
(EngineCore_DP0 pid=289663) 	add.s32 	%r59, %r4, %r162;
(EngineCore_DP0 pid=289663) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=289663) 	add.s32 	%r60, %r59, 1024;
(EngineCore_DP0 pid=289663) 	setp.lt.s32 	%p2, %r59, %r19;
(EngineCore_DP0 pid=289663) 	setp.lt.s32 	%p3, %r60, %r19;
(EngineCore_DP0 pid=289663) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=289663) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=289663) 	add.s64 	%rd7, %rd6, 2048;
(EngineCore_DP0 pid=289663) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=289663) 	// begin inline asm
(EngineCore_DP0 pid=289663) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=289663) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=289663) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=289663) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=289663) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=289663) 	// end inline asm
(EngineCore_DP0 pid=289663) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=289663) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=289663) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=289663) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=289663) 	// begin inline asm
(EngineCore_DP0 pid=289663) 	mov.u32 %r45, %r41;
(EngineCore_DP0 pid=289663) 	mov.u32 %r46, %r41;
(EngineCore_DP0 pid=289663) 	mov.u32 %r47, %r41;
(EngineCore_DP0 pid=289663) 	mov.u32 %r48, %r41;
(EngineCore_DP0 pid=289663) 	@%p3 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=289663) 	// end inline asm
(EngineCore_DP0 pid=289663) 	mov.b32 	{%rs9, %rs10}, %r45;
(EngineCore_DP0 pid=289663) 	mov.b32 	{%rs11, %rs12}, %r46;
(EngineCore_DP0 pid=289663) 	mov.b32 	{%rs13, %rs14}, %r47;
(EngineCore_DP0 pid=289663) 	mov.b32 	{%rs15, %rs16}, %r48;
(EngineCore_DP0 pid=289663) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=289663) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=289663) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=289663) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=289663) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=289663) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=289663) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=289663) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=289663) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=289663) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=289663) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=289663) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=289663) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=289663) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=289663) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=289663) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=289663) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=289663) $L__tmp1:
(EngineCore_DP0 pid=289663) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289663) 	bar.sync 	0;
(EngineCore_DP0 pid=289663) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289663) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=289663) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=289663) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=289663) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=289663) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=289663) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=289663) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=289663) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=289663) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=289663) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=289663) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=289663) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=289663) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=289663) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=289663) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=289663) 	cvt.f32.bf16 	%r61, %rs47;
(EngineCore_DP0 pid=289663) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289663) 	shfl.sync.bfly.b32 	%r62, %r61, 16, 31, -1;
(EngineCore_DP0 pid=289663) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289663) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=289663) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289663) 	shfl.sync.bfly.b32 	%r64, %r63, 8, 31, -1;
(EngineCore_DP0 pid=289663) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289663) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=289663) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289663) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=289663) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289663) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=289663) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289663) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=289663) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289663) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=289663) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289663) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=289663) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289663) 	max.f32 	%r54, %r69, %r70;
(EngineCore_DP0 pid=289663) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289663) 	// begin inline asm
(EngineCore_DP0 pid=289663) 	@%p4 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=289663) 	// end inline asm
(EngineCore_DP0 pid=289663) 	bar.sync 	0;
(EngineCore_DP0 pid=289663) 	// begin inline asm
(EngineCore_DP0 pid=289663) 	@%p5 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=289663) 	// end inline asm
(EngineCore_DP0 pid=289663) 	shfl.sync.bfly.b32 	%r71, %r55, 2, 31, -1;
(EngineCore_DP0 pid=289663) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289663) 	max.f32 	%r72, %r55, %r71;
(EngineCore_DP0 pid=289663) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289663) 	shfl.sync.bfly.b32 	%r73, %r72, 1, 31, -1;
(EngineCore_DP0 pid=289663) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289663) 	max.f32 	%r58, %r72, %r73;
(EngineCore_DP0 pid=289663) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=289663) 	// begin inline asm
(EngineCore_DP0 pid=289663) 	@%p28 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=289663) 	// end inline asm
(EngineCore_DP0 pid=289663) 	bar.sync 	0;
(EngineCore_DP0 pid=289663) 	ld.shared.b32 	%r74, [global_smem];
(EngineCore_DP0 pid=289663) $L__tmp2:
(EngineCore_DP0 pid=289663) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=289663) 	max.f32 	%r161, %r161, %r74;
(EngineCore_DP0 pid=289663) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=289663) 	add.s32 	%r162, %r162, 2048;
(EngineCore_DP0 pid=289663) 	setp.lt.s32 	%p7, %r162, %r20;
(EngineCore_DP0 pid=289663) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=289663) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=289663) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=289663) 	max.f32 	%r163, %r161, 0f2B8CBCCC;
(EngineCore_DP0 pid=289663) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=289663) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=289663) 	mov.b32 	%r76, 0f42FE0000;
(EngineCore_DP0 pid=289663) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=289663) 	div.full.f32 	%r77, %r163, %r76;
(EngineCore_DP0 pid=289663) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=289663) 	max.f32 	%r75, %r77, 0f37810204;
(EngineCore_DP0 pid=289663) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=289663) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=289663) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=289663) 	// begin inline asm
(EngineCore_DP0 pid=289663) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r75 };
(EngineCore_DP0 pid=289663) 	// end inline asm
(EngineCore_DP0 pid=289663) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=289663) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=289663) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=289663) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=289663) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=289663) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=289663) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=289663) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=289663) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=289663) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=289663) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=289663) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=289663) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=289663) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=289663) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=289663) 	div.full.f32 	%r14, %r76, %r163;
(EngineCore_DP0 pid=289663) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=289663) 	mov.b32 	%r164, 0;
(EngineCore_DP0 pid=289663) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=289663)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=289663) 	.loc	1 313 31                        // quant_slide_tuned_Llama3.2-1B.py:313:31
(EngineCore_DP0 pid=289663) 	add.s32 	%r81, %r16, %r164;
(EngineCore_DP0 pid=289663) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=289663) 	add.s32 	%r82, %r164, 1;
(EngineCore_DP0 pid=289663) 	setp.lt.s32 	%p18, %r81, %r15;
(EngineCore_DP0 pid=289663) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=289663) 	shr.u32 	%r83, %r81, 1;
(EngineCore_DP0 pid=289663) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=289663) 	shr.u32 	%r84, %r82, 31;
(EngineCore_DP0 pid=289663) 	add.s32 	%r85, %r82, %r84;
(EngineCore_DP0 pid=289663) 	and.b32 	%r86, %r85, 2147483646;
(EngineCore_DP0 pid=289663) 	sub.s32 	%r87, %r82, %r86;
(EngineCore_DP0 pid=289663) 	.loc	1 319 22                        // quant_slide_tuned_Llama3.2-1B.py:319:22
(EngineCore_DP0 pid=289663) 	mul.lo.s32 	%r88, %r83, 6;
(EngineCore_DP0 pid=289663) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=289663) 	shl.b32 	%r89, %r87, 1;
(EngineCore_DP0 pid=289663) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=289663) 	add.s32 	%r90, %r88, %r89;
(EngineCore_DP0 pid=289663) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=289663) 	setp.lt.s32 	%p19, %r88, %r19;
(EngineCore_DP0 pid=289663) 	setp.lt.s32 	%p20, %r90, %r19;
(EngineCore_DP0 pid=289663) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=289663) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=289663) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=289663) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=289663) 	mad.wide.s32 	%rd9, %r88, 2, %rd1;
(EngineCore_DP0 pid=289663) 	mad.wide.s32 	%rd10, %r90, 2, %rd1;
(EngineCore_DP0 pid=289663) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=289663) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=289663) 	// begin inline asm
(EngineCore_DP0 pid=289663) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=289663) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=289663) 	// end inline asm
(EngineCore_DP0 pid=289663) 	// begin inline asm
(EngineCore_DP0 pid=289663) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=289663) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=289663) 	// end inline asm
(EngineCore_DP0 pid=289663) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=289663) 	cvt.f32.bf16 	%r91, %rs48;
(EngineCore_DP0 pid=289663) 	cvt.f32.bf16 	%r92, %rs50;
(EngineCore_DP0 pid=289663) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=289663) 	or.b32 	%r93, %r88, 1;
(EngineCore_DP0 pid=289663) 	or.b32 	%r94, %r90, 1;
(EngineCore_DP0 pid=289663) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=289663) 	setp.lt.s32 	%p21, %r93, %r19;
(EngineCore_DP0 pid=289663) 	setp.lt.s32 	%p22, %r94, %r19;
(EngineCore_DP0 pid=289663) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=289663) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=289663) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=289663) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=289663) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=289663) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=289663) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=289663) 	// begin inline asm
(EngineCore_DP0 pid=289663) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=289663) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=289663) 	// end inline asm
(EngineCore_DP0 pid=289663) 	// begin inline asm
(EngineCore_DP0 pid=289663) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=289663) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=289663) 	// end inline asm
(EngineCore_DP0 pid=289663) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=289663) 	cvt.f32.bf16 	%r95, %rs52;
(EngineCore_DP0 pid=289663) 	cvt.f32.bf16 	%r96, %rs54;
(EngineCore_DP0 pid=289663) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=289663) 	add.s32 	%r97, %r88, 2;
(EngineCore_DP0 pid=289663) 	add.s32 	%r98, %r90, 2;
(EngineCore_DP0 pid=289663) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=289663) 	setp.lt.s32 	%p23, %r97, %r19;
(EngineCore_DP0 pid=289663) 	setp.lt.s32 	%p24, %r98, %r19;
(EngineCore_DP0 pid=289663) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=289663) 	and.pred 	%p14, %p18, %p23;
(EngineCore_DP0 pid=289663) 	and.pred 	%p15, %p18, %p24;
(EngineCore_DP0 pid=289663) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=289663) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=289663) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=289663) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=289663) 	// begin inline asm
(EngineCore_DP0 pid=289663) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=289663) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=289663) 	// end inline asm
(EngineCore_DP0 pid=289663) 	// begin inline asm
(EngineCore_DP0 pid=289663) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=289663) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=289663) 	// end inline asm
(EngineCore_DP0 pid=289663) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=289663) 	cvt.f32.bf16 	%r99, %rs56;
(EngineCore_DP0 pid=289663) 	cvt.f32.bf16 	%r100, %rs58;
(EngineCore_DP0 pid=289663) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=289663) 	add.s32 	%r101, %r88, 3;
(EngineCore_DP0 pid=289663) 	add.s32 	%r102, %r90, 3;
(EngineCore_DP0 pid=289663) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=289663) 	setp.lt.s32 	%p25, %r101, %r19;
(EngineCore_DP0 pid=289663) 	setp.lt.s32 	%p26, %r102, %r19;
(EngineCore_DP0 pid=289663) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=289663) 	and.pred 	%p16, %p18, %p25;
(EngineCore_DP0 pid=289663) 	and.pred 	%p17, %p18, %p26;
(EngineCore_DP0 pid=289663) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=289663) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=289663) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=289663) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=289663) 	// begin inline asm
(EngineCore_DP0 pid=289663) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=289663) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=289663) 	// end inline asm
(EngineCore_DP0 pid=289663) 	// begin inline asm
(EngineCore_DP0 pid=289663) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=289663) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=289663) 	// end inline asm
(EngineCore_DP0 pid=289663) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=289663) 	cvt.f32.bf16 	%r103, %rs60;
(EngineCore_DP0 pid=289663) 	cvt.f32.bf16 	%r104, %rs62;
(EngineCore_DP0 pid=289663) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=289663) 	mul.f32 	%r105, %r14, %r91;
(EngineCore_DP0 pid=289663) 	mul.f32 	%r106, %r14, %r92;
(EngineCore_DP0 pid=289663) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=289663) 	cvt.rni.f32.f32 	%r107, %r105;
(EngineCore_DP0 pid=289663) 	cvt.rni.f32.f32 	%r108, %r106;
(EngineCore_DP0 pid=289663) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=289663) 	max.f32 	%r109, %r107, 0fC3000000;
(EngineCore_DP0 pid=289663) 	min.f32 	%r110, %r109, 0f42FE0000;
(EngineCore_DP0 pid=289663) 	max.f32 	%r111, %r108, 0fC3000000;
(EngineCore_DP0 pid=289663) 	min.f32 	%r112, %r111, 0f42FE0000;
(EngineCore_DP0 pid=289663) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=289663) 	cvt.rzi.s32.f32 	%r113, %r110;
(EngineCore_DP0 pid=289663) 	cvt.rzi.s32.f32 	%r114, %r112;
(EngineCore_DP0 pid=289663) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=289663) 	and.b32 	%r115, %r113, 255;
(EngineCore_DP0 pid=289663) 	and.b32 	%r116, %r114, 255;
(EngineCore_DP0 pid=289663) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=289663) 	mul.f32 	%r117, %r14, %r95;
(EngineCore_DP0 pid=289663) 	mul.f32 	%r118, %r14, %r96;
(EngineCore_DP0 pid=289663) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=289663) 	cvt.rni.f32.f32 	%r119, %r117;
(EngineCore_DP0 pid=289663) 	cvt.rni.f32.f32 	%r120, %r118;
(EngineCore_DP0 pid=289663) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=289663) 	mul.f32 	%r121, %r14, %r99;
(EngineCore_DP0 pid=289663) 	mul.f32 	%r122, %r14, %r100;
(EngineCore_DP0 pid=289663) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=289663) 	cvt.rni.f32.f32 	%r123, %r121;
(EngineCore_DP0 pid=289663) 	cvt.rni.f32.f32 	%r124, %r122;
(EngineCore_DP0 pid=289663) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=289663) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=289663) 	mul.f32 	%r126, %r14, %r104;
(EngineCore_DP0 pid=289663) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=289663) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=289663) 	cvt.rni.f32.f32 	%r128, %r126;
(EngineCore_DP0 pid=289663) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=289663) 	max.f32 	%r129, %r127, 0fC3000000;
(EngineCore_DP0 pid=289663) 	min.f32 	%r130, %r129, 0f42FE0000;
(EngineCore_DP0 pid=289663) 	max.f32 	%r131, %r128, 0fC3000000;
(EngineCore_DP0 pid=289663) 	min.f32 	%r132, %r131, 0f42FE0000;
(EngineCore_DP0 pid=289663) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=289663) 	cvt.rzi.s32.f32 	%r133, %r130;
(EngineCore_DP0 pid=289663) 	cvt.rzi.s32.f32 	%r134, %r132;
(EngineCore_DP0 pid=289663) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=289663) 	max.f32 	%r135, %r123, 0fC3000000;
(EngineCore_DP0 pid=289663) 	max.f32 	%r136, %r119, 0fC3000000;
(EngineCore_DP0 pid=289663) 	min.f32 	%r137, %r136, 0f42FE0000;
(EngineCore_DP0 pid=289663) 	min.f32 	%r138, %r135, 0f42FE0000;
(EngineCore_DP0 pid=289663) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=289663) 	cvt.rzi.s32.f32 	%r139, %r138;
(EngineCore_DP0 pid=289663) 	cvt.rzi.s32.f32 	%r140, %r137;
(EngineCore_DP0 pid=289663) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=289663) 	shl.b32 	%r141, %r140, 8;
(EngineCore_DP0 pid=289663) 	shl.b32 	%r142, %r139, 16;
(EngineCore_DP0 pid=289663) 	and.b32 	%r143, %r142, 16711680;
(EngineCore_DP0 pid=289663) 	and.b32 	%r144, %r141, 65280;
(EngineCore_DP0 pid=289663) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=289663) 	or.b32 	%r145, %r144, %r115;
(EngineCore_DP0 pid=289663) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=289663) 	max.f32 	%r146, %r124, 0fC3000000;
(EngineCore_DP0 pid=289663) 	max.f32 	%r147, %r120, 0fC3000000;
(EngineCore_DP0 pid=289663) 	min.f32 	%r148, %r147, 0f42FE0000;
(EngineCore_DP0 pid=289663) 	min.f32 	%r149, %r146, 0f42FE0000;
(EngineCore_DP0 pid=289663) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=289663) 	cvt.rzi.s32.f32 	%r150, %r149;
(EngineCore_DP0 pid=289663) 	cvt.rzi.s32.f32 	%r151, %r148;
(EngineCore_DP0 pid=289663) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=289663) 	shl.b32 	%r152, %r151, 8;
(EngineCore_DP0 pid=289663) 	shl.b32 	%r153, %r150, 16;
(EngineCore_DP0 pid=289663) 	and.b32 	%r154, %r153, 16711680;
(EngineCore_DP0 pid=289663) 	and.b32 	%r155, %r152, 65280;
(EngineCore_DP0 pid=289663) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=289663) 	or.b32 	%r156, %r155, %r116;
(EngineCore_DP0 pid=289663) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=289663) 	or.b32 	%r157, %r145, %r143;
(EngineCore_DP0 pid=289663) 	or.b32 	%r158, %r156, %r154;
(EngineCore_DP0 pid=289663) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=289663) 	shl.b32 	%r159, %r133, 24;
(EngineCore_DP0 pid=289663) 	shl.b32 	%r160, %r134, 24;
(EngineCore_DP0 pid=289663) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=289663) 	or.b32 	%r79, %r157, %r159;
(EngineCore_DP0 pid=289663) 	or.b32 	%r80, %r158, %r160;
(EngineCore_DP0 pid=289663) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=289663) 	mad.wide.s32 	%rd17, %r81, 4, %rd2;
(EngineCore_DP0 pid=289663) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=289663) 	// begin inline asm
(EngineCore_DP0 pid=289663) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r79, %r80 };
(EngineCore_DP0 pid=289663) 	// end inline asm
(EngineCore_DP0 pid=289663) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=289663) 	add.s32 	%r164, %r164, 256;
(EngineCore_DP0 pid=289663) 	setp.lt.s32 	%p27, %r164, %r15;
(EngineCore_DP0 pid=289663) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=289663) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=289663) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=289663) 	ret;
(EngineCore_DP0 pid=289663) $L__tmp3:
(EngineCore_DP0 pid=289663) $L__func_end0:
(EngineCore_DP0 pid=289663)                                         // -- End function
(EngineCore_DP0 pid=289663) }
(EngineCore_DP0 pid=289663) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=289663) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=289663) 	.section	.debug_abbrev
(EngineCore_DP0 pid=289663) 	{
(EngineCore_DP0 pid=289663) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=289663) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=289663) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=289663) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=289663) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=289663) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=289663) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=289663) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=289663) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=289663) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=289663) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=289663) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=289663) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=289663) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=289663) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=289663) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=289663) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=289663) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=289663) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=289663) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=289663) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=289663) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=289663) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=289663) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=289663) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=289663) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=289663) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=289663) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=289663) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=289663) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=289663) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=289663) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=289663) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=289663) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=289663) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=289663) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=289663) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=289663) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=289663) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=289663) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=289663) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=289663) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=289663) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=289663) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=289663) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=289663) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=289663) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=289663) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=289663) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=289663) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=289663) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=289663) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=289663) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=289663) 	}
(EngineCore_DP0 pid=289663) 	.section	.debug_info
(EngineCore_DP0 pid=289663) 	{
(EngineCore_DP0 pid=289663) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=289663) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=289663) .b8 0
(EngineCore_DP0 pid=289663) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=289663) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=289663) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=289663) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=289663) .b8 114
(EngineCore_DP0 pid=289663) .b8 105
(EngineCore_DP0 pid=289663) .b8 116
(EngineCore_DP0 pid=289663) .b8 111
(EngineCore_DP0 pid=289663) .b8 110
(EngineCore_DP0 pid=289663) .b8 0
(EngineCore_DP0 pid=289663) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=289663) .b8 0
(EngineCore_DP0 pid=289663) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=289663) .b8 117
(EngineCore_DP0 pid=289663) .b8 97
(EngineCore_DP0 pid=289663) .b8 110
(EngineCore_DP0 pid=289663) .b8 116
(EngineCore_DP0 pid=289663) .b8 95
(EngineCore_DP0 pid=289663) .b8 115
(EngineCore_DP0 pid=289663) .b8 108
(EngineCore_DP0 pid=289663) .b8 105
(EngineCore_DP0 pid=289663) .b8 100
(EngineCore_DP0 pid=289663) .b8 101
(EngineCore_DP0 pid=289663) .b8 95
(EngineCore_DP0 pid=289663) .b8 116
(EngineCore_DP0 pid=289663) .b8 117
(EngineCore_DP0 pid=289663) .b8 110
(EngineCore_DP0 pid=289663) .b8 101
(EngineCore_DP0 pid=289663) .b8 100
(EngineCore_DP0 pid=289663) .b8 95
(EngineCore_DP0 pid=289663) .b8 76
(EngineCore_DP0 pid=289663) .b8 108
(EngineCore_DP0 pid=289663) .b8 97
(EngineCore_DP0 pid=289663) .b8 109
(EngineCore_DP0 pid=289663) .b8 97
(EngineCore_DP0 pid=289663) .b8 51
(EngineCore_DP0 pid=289663) .b8 46
(EngineCore_DP0 pid=289663) .b8 50
(EngineCore_DP0 pid=289663) .b8 45
(EngineCore_DP0 pid=289663) .b8 49
(EngineCore_DP0 pid=289663) .b8 66
(EngineCore_DP0 pid=289663) .b8 46
(EngineCore_DP0 pid=289663) .b8 112
(EngineCore_DP0 pid=289663) .b8 121
(EngineCore_DP0 pid=289663) .b8 0
(EngineCore_DP0 pid=289663) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=289663) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=289663) .b8 114
(EngineCore_DP0 pid=289663) .b8 111
(EngineCore_DP0 pid=289663) .b8 111
(EngineCore_DP0 pid=289663) .b8 116
(EngineCore_DP0 pid=289663) .b8 47
(EngineCore_DP0 pid=289663) .b8 118
(EngineCore_DP0 pid=289663) .b8 108
(EngineCore_DP0 pid=289663) .b8 108
(EngineCore_DP0 pid=289663) .b8 109
(EngineCore_DP0 pid=289663) .b8 98
(EngineCore_DP0 pid=289663) .b8 101
(EngineCore_DP0 pid=289663) .b8 110
(EngineCore_DP0 pid=289663) .b8 99
(EngineCore_DP0 pid=289663) .b8 104
(EngineCore_DP0 pid=289663) .b8 47
(EngineCore_DP0 pid=289663) .b8 115
(EngineCore_DP0 pid=289663) .b8 108
(EngineCore_DP0 pid=289663) .b8 105
(EngineCore_DP0 pid=289663) .b8 100
(EngineCore_DP0 pid=289663) .b8 101
(EngineCore_DP0 pid=289663) .b8 115
(EngineCore_DP0 pid=289663) .b8 112
(EngineCore_DP0 pid=289663) .b8 97
(EngineCore_DP0 pid=289663) .b8 114
(EngineCore_DP0 pid=289663) .b8 115
(EngineCore_DP0 pid=289663) .b8 101
(EngineCore_DP0 pid=289663) .b8 47
(EngineCore_DP0 pid=289663) .b8 99
(EngineCore_DP0 pid=289663) .b8 115
(EngineCore_DP0 pid=289663) .b8 114
(EngineCore_DP0 pid=289663) .b8 99
(EngineCore_DP0 pid=289663) .b8 47
(EngineCore_DP0 pid=289663) .b8 102
(EngineCore_DP0 pid=289663) .b8 117
(EngineCore_DP0 pid=289663) .b8 115
(EngineCore_DP0 pid=289663) .b8 101
(EngineCore_DP0 pid=289663) .b8 100
(EngineCore_DP0 pid=289663) .b8 95
(EngineCore_DP0 pid=289663) .b8 113
(EngineCore_DP0 pid=289663) .b8 117
(EngineCore_DP0 pid=289663) .b8 97
(EngineCore_DP0 pid=289663) .b8 110
(EngineCore_DP0 pid=289663) .b8 116
(EngineCore_DP0 pid=289663) .b8 95
(EngineCore_DP0 pid=289663) .b8 115
(EngineCore_DP0 pid=289663) .b8 108
(EngineCore_DP0 pid=289663) .b8 105
(EngineCore_DP0 pid=289663) .b8 100
(EngineCore_DP0 pid=289663) .b8 101
(EngineCore_DP0 pid=289663) .b8 95
(EngineCore_DP0 pid=289663) .b8 116
(EngineCore_DP0 pid=289663) .b8 114
(EngineCore_DP0 pid=289663) .b8 105
(EngineCore_DP0 pid=289663) .b8 116
(EngineCore_DP0 pid=289663) .b8 111
(EngineCore_DP0 pid=289663) .b8 110
(EngineCore_DP0 pid=289663) .b8 47
(EngineCore_DP0 pid=289663) .b8 98
(EngineCore_DP0 pid=289663) .b8 117
(EngineCore_DP0 pid=289663) .b8 105
(EngineCore_DP0 pid=289663) .b8 108
(EngineCore_DP0 pid=289663) .b8 100
(EngineCore_DP0 pid=289663) .b8 47
(EngineCore_DP0 pid=289663) .b8 71
(EngineCore_DP0 pid=289663) .b8 66
(EngineCore_DP0 pid=289663) .b8 49
(EngineCore_DP0 pid=289663) .b8 48
(EngineCore_DP0 pid=289663) .b8 95
(EngineCore_DP0 pid=289663) .b8 99
(EngineCore_DP0 pid=289663) .b8 99
(EngineCore_DP0 pid=289663) .b8 49
(EngineCore_DP0 pid=289663) .b8 50
(EngineCore_DP0 pid=289663) .b8 49
(EngineCore_DP0 pid=289663) .b8 95
(EngineCore_DP0 pid=289663) .b8 112
(EngineCore_DP0 pid=289663) .b8 121
(EngineCore_DP0 pid=289663) .b8 51
(EngineCore_DP0 pid=289663) .b8 49
(EngineCore_DP0 pid=289663) .b8 50
(EngineCore_DP0 pid=289663) .b8 95
(EngineCore_DP0 pid=289663) .b8 99
(EngineCore_DP0 pid=289663) .b8 117
(EngineCore_DP0 pid=289663) .b8 49
(EngineCore_DP0 pid=289663) .b8 50
(EngineCore_DP0 pid=289663) .b8 57
(EngineCore_DP0 pid=289663) .b8 95
(EngineCore_DP0 pid=289663) .b8 97
(EngineCore_DP0 pid=289663) .b8 97
(EngineCore_DP0 pid=289663) .b8 114
(EngineCore_DP0 pid=289663) .b8 99
(EngineCore_DP0 pid=289663) .b8 104
(EngineCore_DP0 pid=289663) .b8 54
(EngineCore_DP0 pid=289663) .b8 52
(EngineCore_DP0 pid=289663) .b8 0
(EngineCore_DP0 pid=289663) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=289663) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=289663) .b8 113
(EngineCore_DP0 pid=289663) .b8 117
(EngineCore_DP0 pid=289663) .b8 97
(EngineCore_DP0 pid=289663) .b8 110
(EngineCore_DP0 pid=289663) .b8 116
(EngineCore_DP0 pid=289663) .b8 95
(EngineCore_DP0 pid=289663) .b8 115
(EngineCore_DP0 pid=289663) .b8 108
(EngineCore_DP0 pid=289663) .b8 105
(EngineCore_DP0 pid=289663) .b8 100
(EngineCore_DP0 pid=289663) .b8 101
(EngineCore_DP0 pid=289663) .b8 95
(EngineCore_DP0 pid=289663) .b8 105
(EngineCore_DP0 pid=289663) .b8 110
(EngineCore_DP0 pid=289663) .b8 116
(EngineCore_DP0 pid=289663) .b8 56
(EngineCore_DP0 pid=289663) .b8 95
(EngineCore_DP0 pid=289663) .b8 107
(EngineCore_DP0 pid=289663) .b8 101
(EngineCore_DP0 pid=289663) .b8 114
(EngineCore_DP0 pid=289663) .b8 110
(EngineCore_DP0 pid=289663) .b8 101
(EngineCore_DP0 pid=289663) .b8 108
(EngineCore_DP0 pid=289663) .b8 0
(EngineCore_DP0 pid=289663) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=289663) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=289663) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=289663) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=289663) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=289663) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=289663) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=289663) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=289663) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=289663) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=289663) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=289663) .b8 1
(EngineCore_DP0 pid=289663) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=289663) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=289663) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=289663) 	}
(EngineCore_DP0 pid=289663) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=289663) 
(EngineCore_DP0 pid=289663) ================================================================
(EngineCore_DP0 pid=289663) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=289663) 
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpyqy2e_wj.ptx', '-o', '/tmp/tmpyqy2e_wj.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866] 
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866] 
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866] 
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpyqy2e_wj.ptx -o /tmp/tmpyqy2e_wj.ptx.o
(EngineCore_DP0 pid=289663) ERROR 01-25 18:40:23 [core.py:866] 

STDERR:
[2026-01-25 18:40:08] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:40:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:40:08] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:40:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:40:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:40:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:40:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:40:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:40:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:40:11] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:40:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:40:11] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:40:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:40:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:40:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:40:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:40:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:40:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=289663) [2026-01-25 18:40:12] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=289663) [2026-01-25 18:40:12] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=289663) [2026-01-25 18:40:12] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=289663) [2026-01-25 18:40:12] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=289663) [2026-01-25 18:40:12] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=289663) [2026-01-25 18:40:12] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=289663) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=289663) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.15s/it]
(EngineCore_DP0 pid=289663) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.15s/it]
(EngineCore_DP0 pid=289663) 
(EngineCore_DP0 pid=289663) [2026-01-25 18:40:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=289663) [2026-01-25 18:40:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=289663) [2026-01-25 18:40:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=289663) [2026-01-25 18:40:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=289663) [2026-01-25 18:40:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=289663) [2026-01-25 18:40:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=289663) [2026-01-25 18:40:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=289663) [2026-01-25 18:40:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=289663) Process EngineCore_DP0:
(EngineCore_DP0 pid=289663) Traceback (most recent call last):
(EngineCore_DP0 pid=289663)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=289663)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=289663)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=289663)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=289663) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpyqy2e_wj.ptx', '-o', '/tmp/tmpyqy2e_wj.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=289663) 
(EngineCore_DP0 pid=289663) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=289663) 
(EngineCore_DP0 pid=289663) Traceback (most recent call last):
(EngineCore_DP0 pid=289663)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=289663)     self.run()
(EngineCore_DP0 pid=289663)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=289663)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=289663)     raise e
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=289663)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=289663)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=289663)     super().__init__(
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=289663)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=289663)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=289663)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=289663)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=289663)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=289663)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=289663)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=289663)     return func(*args, **kwargs)
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=289663)     return func(*args, **kwargs)
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=289663)     self.model_runner.profile_run()
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=289663)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=289663)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=289663)     return func(*args, **kwargs)
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=289663)     outputs = self.model(
(EngineCore_DP0 pid=289663)               ^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=289663)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=289663)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=289663)     model_output = self.model(
(EngineCore_DP0 pid=289663)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=289663)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=289663)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=289663)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=289663)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=289663)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=289663)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=289663)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=289663)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=289663)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=289663)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=289663)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=289663)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=289663)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=289663)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=289663)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=289663)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=289663)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=289663)     return self._linear_fn(
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=289663)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=289663)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=289663)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=289663)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=289663)     return fn(input, L)
(EngineCore_DP0 pid=289663)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=289663)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=289663)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=289663)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=289663)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=289663)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=289663)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=289663)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=289663)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=289663)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=289663)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=289663)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=289663)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=289663)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=289663)     raise PTXASError(error)
(EngineCore_DP0 pid=289663) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=289663) `ptxas` stderr:
(EngineCore_DP0 pid=289663) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=289663) 
(EngineCore_DP0 pid=289663) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpyqy2e_wj.ptx -o /tmp/tmpyqy2e_wj.ptx.o
(EngineCore_DP0 pid=289663) 
[rank0]:[W125 18:40:23.661261850 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=128

========== M=256 ==========
Time: 2026-01-25 18:40:25
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M256.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:40:28 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:40:28 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=290130) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=290130) 
(EngineCore_DP0 pid=290130) 
(EngineCore_DP0 pid=290130) ================================================================
(EngineCore_DP0 pid=290130) Internal Triton PTX codegen error
(EngineCore_DP0 pid=290130) `ptxas` stderr:
(EngineCore_DP0 pid=290130) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=290130) 
(EngineCore_DP0 pid=290130) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpr6txcne6.ptx -o /tmp/tmpr6txcne6.ptx.o
(EngineCore_DP0 pid=290130) 
(EngineCore_DP0 pid=290130) 
(EngineCore_DP0 pid=290130) //
(EngineCore_DP0 pid=290130) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=290130) //
(EngineCore_DP0 pid=290130) 
(EngineCore_DP0 pid=290130) .version 8.7
(EngineCore_DP0 pid=290130) .target sm_121a
(EngineCore_DP0 pid=290130) .address_size 64
(EngineCore_DP0 pid=290130) 
(EngineCore_DP0 pid=290130) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=290130) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=290130)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=290130) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=290130) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=290130) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=290130) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=290130) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=290130) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=290130) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=290130) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=290130) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=290130) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=290130) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=290130) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=290130) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=290130) )
(EngineCore_DP0 pid=290130) .reqntid 1024
(EngineCore_DP0 pid=290130) {
(EngineCore_DP0 pid=290130) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=290130) 	.reg .b16 	%rs<20>;
(EngineCore_DP0 pid=290130) 	.reg .b32 	%r<119>;
(EngineCore_DP0 pid=290130) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=290130) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=290130) $L__func_begin0:
(EngineCore_DP0 pid=290130) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=290130) 
(EngineCore_DP0 pid=290130) // %bb.0:
(EngineCore_DP0 pid=290130) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=290130) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=290130) 	ld.param.b32 	%r17, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=290130) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=290130) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=290130) $L__tmp0:
(EngineCore_DP0 pid=290130) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=290130) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=290130) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=290130) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=290130) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=290130) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=290130) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=290130) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=290130) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=290130) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=290130) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=290130) 	mov.b32 	%r117, 0f2B8CBCCC;
(EngineCore_DP0 pid=290130) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=290130) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=290130) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=290130) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=290130) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=290130) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=290130) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=290130) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=290130) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=290130) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=290130) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=290130) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=290130) 	mov.b32 	%r115, 0f00000000;
(EngineCore_DP0 pid=290130) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=290130) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=290130) 	mov.b32 	%r116, %r37;
(EngineCore_DP0 pid=290130) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=290130) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=290130) 	add.s32 	%r45, %r3, %r116;
(EngineCore_DP0 pid=290130) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=290130) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=290130) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=290130) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=290130) 	// begin inline asm
(EngineCore_DP0 pid=290130) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=290130) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=290130) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=290130) 	// end inline asm
(EngineCore_DP0 pid=290130) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=290130) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=290130) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=290130) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=290130) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=290130) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=290130) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=290130) $L__tmp1:
(EngineCore_DP0 pid=290130) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	bar.sync 	0;
(EngineCore_DP0 pid=290130) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=290130) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=290130) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=290130) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=290130) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=290130) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=290130) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=290130) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=290130) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=290130) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=290130) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=290130) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=290130) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=290130) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=290130) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	// begin inline asm
(EngineCore_DP0 pid=290130) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=290130) 	// end inline asm
(EngineCore_DP0 pid=290130) 	bar.sync 	0;
(EngineCore_DP0 pid=290130) 	// begin inline asm
(EngineCore_DP0 pid=290130) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=290130) 	// end inline asm
(EngineCore_DP0 pid=290130) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=290130) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=290130) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=290130) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=290130) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=290130) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=290130) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=290130) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=290130) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=290130) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=290130) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=290130) 	// begin inline asm
(EngineCore_DP0 pid=290130) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=290130) 	// end inline asm
(EngineCore_DP0 pid=290130) 	bar.sync 	0;
(EngineCore_DP0 pid=290130) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=290130) $L__tmp2:
(EngineCore_DP0 pid=290130) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=290130) 	max.f32 	%r115, %r115, %r65;
(EngineCore_DP0 pid=290130) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=290130) 	add.s32 	%r116, %r116, 4096;
(EngineCore_DP0 pid=290130) 	setp.lt.s32 	%p6, %r116, %r18;
(EngineCore_DP0 pid=290130) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=290130) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=290130) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=290130) 	max.f32 	%r117, %r115, 0f2B8CBCCC;
(EngineCore_DP0 pid=290130) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=290130) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=290130) 	mov.b32 	%r67, 0f42FE0000;
(EngineCore_DP0 pid=290130) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=290130) 	div.full.f32 	%r68, %r117, %r67;
(EngineCore_DP0 pid=290130) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=290130) 	max.f32 	%r66, %r68, 0f37810204;
(EngineCore_DP0 pid=290130) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=290130) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=290130) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=290130) 	// begin inline asm
(EngineCore_DP0 pid=290130) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=290130) 	// end inline asm
(EngineCore_DP0 pid=290130) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=290130) 	shl.b32 	%r14, %r19, 1;
(EngineCore_DP0 pid=290130) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=290130) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=290130) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=290130) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=290130) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=290130) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=290130) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=290130) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=290130) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=290130) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=290130) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=290130) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=290130) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=290130) 	div.full.f32 	%r13, %r67, %r117;
(EngineCore_DP0 pid=290130) 	mov.b32 	%r118, 0;
(EngineCore_DP0 pid=290130) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=290130)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=290130) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=290130) 	add.s32 	%r72, %r2, %r118;
(EngineCore_DP0 pid=290130) 	setp.lt.s32 	%p13, %r72, %r14;
(EngineCore_DP0 pid=290130) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=290130) 	shr.u32 	%r73, %r72, 31;
(EngineCore_DP0 pid=290130) 	add.s32 	%r74, %r72, %r73;
(EngineCore_DP0 pid=290130) 	shr.u32 	%r75, %r74, 1;
(EngineCore_DP0 pid=290130) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=290130) 	and.b32 	%r76, %r74, 2147483646;
(EngineCore_DP0 pid=290130) 	sub.s32 	%r77, %r72, %r76;
(EngineCore_DP0 pid=290130) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=290130) 	shl.b32 	%r78, %r77, 1;
(EngineCore_DP0 pid=290130) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=290130) 	mad.lo.s32 	%r79, %r75, 6, %r78;
(EngineCore_DP0 pid=290130) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=290130) 	setp.lt.s32 	%p14, %r79, %r17;
(EngineCore_DP0 pid=290130) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=290130) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=290130) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=290130) 	mad.wide.s32 	%rd8, %r79, 2, %rd1;
(EngineCore_DP0 pid=290130) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=290130) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=290130) 	// begin inline asm
(EngineCore_DP0 pid=290130) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=290130) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=290130) 	// end inline asm
(EngineCore_DP0 pid=290130) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=290130) 	cvt.f32.bf16 	%r80, %rs12;
(EngineCore_DP0 pid=290130) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=290130) 	or.b32 	%r81, %r79, 1;
(EngineCore_DP0 pid=290130) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=290130) 	setp.lt.s32 	%p15, %r81, %r17;
(EngineCore_DP0 pid=290130) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=290130) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=290130) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=290130) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=290130) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=290130) 	// begin inline asm
(EngineCore_DP0 pid=290130) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=290130) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=290130) 	// end inline asm
(EngineCore_DP0 pid=290130) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=290130) 	cvt.f32.bf16 	%r82, %rs14;
(EngineCore_DP0 pid=290130) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=290130) 	add.s32 	%r83, %r79, 2;
(EngineCore_DP0 pid=290130) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=290130) 	setp.lt.s32 	%p16, %r83, %r17;
(EngineCore_DP0 pid=290130) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=290130) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=290130) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=290130) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=290130) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=290130) 	// begin inline asm
(EngineCore_DP0 pid=290130) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=290130) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=290130) 	// end inline asm
(EngineCore_DP0 pid=290130) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=290130) 	cvt.f32.bf16 	%r84, %rs16;
(EngineCore_DP0 pid=290130) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=290130) 	add.s32 	%r85, %r79, 3;
(EngineCore_DP0 pid=290130) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=290130) 	setp.lt.s32 	%p17, %r85, %r17;
(EngineCore_DP0 pid=290130) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=290130) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=290130) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=290130) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=290130) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=290130) 	// begin inline asm
(EngineCore_DP0 pid=290130) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=290130) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=290130) 	// end inline asm
(EngineCore_DP0 pid=290130) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=290130) 	cvt.f32.bf16 	%r86, %rs18;
(EngineCore_DP0 pid=290130) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=290130) 	mul.f32 	%r87, %r13, %r80;
(EngineCore_DP0 pid=290130) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=290130) 	cvt.rni.f32.f32 	%r88, %r87;
(EngineCore_DP0 pid=290130) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=290130) 	max.f32 	%r89, %r88, 0fC3000000;
(EngineCore_DP0 pid=290130) 	min.f32 	%r90, %r89, 0f42FE0000;
(EngineCore_DP0 pid=290130) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=290130) 	cvt.rzi.s32.f32 	%r91, %r90;
(EngineCore_DP0 pid=290130) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=290130) 	and.b32 	%r92, %r91, 255;
(EngineCore_DP0 pid=290130) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=290130) 	mul.f32 	%r93, %r13, %r82;
(EngineCore_DP0 pid=290130) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=290130) 	cvt.rni.f32.f32 	%r94, %r93;
(EngineCore_DP0 pid=290130) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=290130) 	mul.f32 	%r95, %r13, %r84;
(EngineCore_DP0 pid=290130) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=290130) 	cvt.rni.f32.f32 	%r96, %r95;
(EngineCore_DP0 pid=290130) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=290130) 	mul.f32 	%r97, %r13, %r86;
(EngineCore_DP0 pid=290130) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=290130) 	cvt.rni.f32.f32 	%r98, %r97;
(EngineCore_DP0 pid=290130) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=290130) 	max.f32 	%r99, %r98, 0fC3000000;
(EngineCore_DP0 pid=290130) 	min.f32 	%r100, %r99, 0f42FE0000;
(EngineCore_DP0 pid=290130) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=290130) 	cvt.rzi.s32.f32 	%r101, %r100;
(EngineCore_DP0 pid=290130) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=290130) 	max.f32 	%r102, %r96, 0fC3000000;
(EngineCore_DP0 pid=290130) 	max.f32 	%r103, %r94, 0fC3000000;
(EngineCore_DP0 pid=290130) 	min.f32 	%r104, %r103, 0f42FE0000;
(EngineCore_DP0 pid=290130) 	min.f32 	%r105, %r102, 0f42FE0000;
(EngineCore_DP0 pid=290130) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=290130) 	cvt.rzi.s32.f32 	%r106, %r105;
(EngineCore_DP0 pid=290130) 	cvt.rzi.s32.f32 	%r107, %r104;
(EngineCore_DP0 pid=290130) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=290130) 	shl.b32 	%r108, %r107, 8;
(EngineCore_DP0 pid=290130) 	shl.b32 	%r109, %r106, 16;
(EngineCore_DP0 pid=290130) 	and.b32 	%r110, %r109, 16711680;
(EngineCore_DP0 pid=290130) 	and.b32 	%r111, %r108, 65280;
(EngineCore_DP0 pid=290130) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=290130) 	or.b32 	%r112, %r111, %r92;
(EngineCore_DP0 pid=290130) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=290130) 	or.b32 	%r113, %r112, %r110;
(EngineCore_DP0 pid=290130) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=290130) 	shl.b32 	%r114, %r101, 24;
(EngineCore_DP0 pid=290130) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=290130) 	or.b32 	%r70, %r113, %r114;
(EngineCore_DP0 pid=290130) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=290130) 	mad.wide.s32 	%rd12, %r72, 4, %rd2;
(EngineCore_DP0 pid=290130) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=290130) 	// begin inline asm
(EngineCore_DP0 pid=290130) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r70 };
(EngineCore_DP0 pid=290130) 	// end inline asm
(EngineCore_DP0 pid=290130) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=290130) 	add.s32 	%r118, %r118, 1024;
(EngineCore_DP0 pid=290130) 	setp.lt.s32 	%p18, %r118, %r14;
(EngineCore_DP0 pid=290130) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=290130) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=290130) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=290130) 	ret;
(EngineCore_DP0 pid=290130) $L__tmp3:
(EngineCore_DP0 pid=290130) $L__func_end0:
(EngineCore_DP0 pid=290130)                                         // -- End function
(EngineCore_DP0 pid=290130) }
(EngineCore_DP0 pid=290130) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=290130) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=290130) 	.section	.debug_abbrev
(EngineCore_DP0 pid=290130) 	{
(EngineCore_DP0 pid=290130) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=290130) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=290130) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=290130) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=290130) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=290130) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=290130) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=290130) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=290130) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=290130) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=290130) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=290130) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=290130) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=290130) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=290130) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=290130) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=290130) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=290130) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=290130) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=290130) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=290130) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=290130) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=290130) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=290130) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=290130) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=290130) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=290130) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=290130) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=290130) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=290130) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=290130) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=290130) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=290130) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=290130) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=290130) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=290130) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=290130) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=290130) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=290130) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=290130) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=290130) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=290130) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=290130) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=290130) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=290130) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=290130) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=290130) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=290130) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=290130) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=290130) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=290130) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=290130) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=290130) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=290130) 	}
(EngineCore_DP0 pid=290130) 	.section	.debug_info
(EngineCore_DP0 pid=290130) 	{
(EngineCore_DP0 pid=290130) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=290130) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=290130) .b8 0
(EngineCore_DP0 pid=290130) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=290130) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=290130) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=290130) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=290130) .b8 114
(EngineCore_DP0 pid=290130) .b8 105
(EngineCore_DP0 pid=290130) .b8 116
(EngineCore_DP0 pid=290130) .b8 111
(EngineCore_DP0 pid=290130) .b8 110
(EngineCore_DP0 pid=290130) .b8 0
(EngineCore_DP0 pid=290130) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=290130) .b8 0
(EngineCore_DP0 pid=290130) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=290130) .b8 117
(EngineCore_DP0 pid=290130) .b8 97
(EngineCore_DP0 pid=290130) .b8 110
(EngineCore_DP0 pid=290130) .b8 116
(EngineCore_DP0 pid=290130) .b8 95
(EngineCore_DP0 pid=290130) .b8 115
(EngineCore_DP0 pid=290130) .b8 108
(EngineCore_DP0 pid=290130) .b8 105
(EngineCore_DP0 pid=290130) .b8 100
(EngineCore_DP0 pid=290130) .b8 101
(EngineCore_DP0 pid=290130) .b8 95
(EngineCore_DP0 pid=290130) .b8 116
(EngineCore_DP0 pid=290130) .b8 117
(EngineCore_DP0 pid=290130) .b8 110
(EngineCore_DP0 pid=290130) .b8 101
(EngineCore_DP0 pid=290130) .b8 100
(EngineCore_DP0 pid=290130) .b8 95
(EngineCore_DP0 pid=290130) .b8 76
(EngineCore_DP0 pid=290130) .b8 108
(EngineCore_DP0 pid=290130) .b8 97
(EngineCore_DP0 pid=290130) .b8 109
(EngineCore_DP0 pid=290130) .b8 97
(EngineCore_DP0 pid=290130) .b8 51
(EngineCore_DP0 pid=290130) .b8 46
(EngineCore_DP0 pid=290130) .b8 50
(EngineCore_DP0 pid=290130) .b8 45
(EngineCore_DP0 pid=290130) .b8 49
(EngineCore_DP0 pid=290130) .b8 66
(EngineCore_DP0 pid=290130) .b8 46
(EngineCore_DP0 pid=290130) .b8 112
(EngineCore_DP0 pid=290130) .b8 121
(EngineCore_DP0 pid=290130) .b8 0
(EngineCore_DP0 pid=290130) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=290130) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=290130) .b8 114
(EngineCore_DP0 pid=290130) .b8 111
(EngineCore_DP0 pid=290130) .b8 111
(EngineCore_DP0 pid=290130) .b8 116
(EngineCore_DP0 pid=290130) .b8 47
(EngineCore_DP0 pid=290130) .b8 118
(EngineCore_DP0 pid=290130) .b8 108
(EngineCore_DP0 pid=290130) .b8 108
(EngineCore_DP0 pid=290130) .b8 109
(EngineCore_DP0 pid=290130) .b8 98
(EngineCore_DP0 pid=290130) .b8 101
(EngineCore_DP0 pid=290130) .b8 110
(EngineCore_DP0 pid=290130) .b8 99
(EngineCore_DP0 pid=290130) .b8 104
(EngineCore_DP0 pid=290130) .b8 47
(EngineCore_DP0 pid=290130) .b8 115
(EngineCore_DP0 pid=290130) .b8 108
(EngineCore_DP0 pid=290130) .b8 105
(EngineCore_DP0 pid=290130) .b8 100
(EngineCore_DP0 pid=290130) .b8 101
(EngineCore_DP0 pid=290130) .b8 115
(EngineCore_DP0 pid=290130) .b8 112
(EngineCore_DP0 pid=290130) .b8 97
(EngineCore_DP0 pid=290130) .b8 114
(EngineCore_DP0 pid=290130) .b8 115
(EngineCore_DP0 pid=290130) .b8 101
(EngineCore_DP0 pid=290130) .b8 47
(EngineCore_DP0 pid=290130) .b8 99
(EngineCore_DP0 pid=290130) .b8 115
(EngineCore_DP0 pid=290130) .b8 114
(EngineCore_DP0 pid=290130) .b8 99
(EngineCore_DP0 pid=290130) .b8 47
(EngineCore_DP0 pid=290130) .b8 102
(EngineCore_DP0 pid=290130) .b8 117
(EngineCore_DP0 pid=290130) .b8 115
(EngineCore_DP0 pid=290130) .b8 101
(EngineCore_DP0 pid=290130) .b8 100
(EngineCore_DP0 pid=290130) .b8 95
(EngineCore_DP0 pid=290130) .b8 113
(EngineCore_DP0 pid=290130) .b8 117
(EngineCore_DP0 pid=290130) .b8 97
(EngineCore_DP0 pid=290130) .b8 110
(EngineCore_DP0 pid=290130) .b8 116
(EngineCore_DP0 pid=290130) .b8 95
(EngineCore_DP0 pid=290130) .b8 115
(EngineCore_DP0 pid=290130) .b8 108
(EngineCore_DP0 pid=290130) .b8 105
(EngineCore_DP0 pid=290130) .b8 100
(EngineCore_DP0 pid=290130) .b8 101
(EngineCore_DP0 pid=290130) .b8 95
(EngineCore_DP0 pid=290130) .b8 116
(EngineCore_DP0 pid=290130) .b8 114
(EngineCore_DP0 pid=290130) .b8 105
(EngineCore_DP0 pid=290130) .b8 116
(EngineCore_DP0 pid=290130) .b8 111
(EngineCore_DP0 pid=290130) .b8 110
(EngineCore_DP0 pid=290130) .b8 47
(EngineCore_DP0 pid=290130) .b8 98
(EngineCore_DP0 pid=290130) .b8 117
(EngineCore_DP0 pid=290130) .b8 105
(EngineCore_DP0 pid=290130) .b8 108
(EngineCore_DP0 pid=290130) .b8 100
(EngineCore_DP0 pid=290130) .b8 47
(EngineCore_DP0 pid=290130) .b8 71
(EngineCore_DP0 pid=290130) .b8 66
(EngineCore_DP0 pid=290130) .b8 49
(EngineCore_DP0 pid=290130) .b8 48
(EngineCore_DP0 pid=290130) .b8 95
(EngineCore_DP0 pid=290130) .b8 99
(EngineCore_DP0 pid=290130) .b8 99
(EngineCore_DP0 pid=290130) .b8 49
(EngineCore_DP0 pid=290130) .b8 50
(EngineCore_DP0 pid=290130) .b8 49
(EngineCore_DP0 pid=290130) .b8 95
(EngineCore_DP0 pid=290130) .b8 112
(EngineCore_DP0 pid=290130) .b8 121
(EngineCore_DP0 pid=290130) .b8 51
(EngineCore_DP0 pid=290130) .b8 49
(EngineCore_DP0 pid=290130) .b8 50
(EngineCore_DP0 pid=290130) .b8 95
(EngineCore_DP0 pid=290130) .b8 99
(EngineCore_DP0 pid=290130) .b8 117
(EngineCore_DP0 pid=290130) .b8 49
(EngineCore_DP0 pid=290130) .b8 50
(EngineCore_DP0 pid=290130) .b8 57
(EngineCore_DP0 pid=290130) .b8 95
(EngineCore_DP0 pid=290130) .b8 97
(EngineCore_DP0 pid=290130) .b8 97
(EngineCore_DP0 pid=290130) .b8 114
(EngineCore_DP0 pid=290130) .b8 99
(EngineCore_DP0 pid=290130) .b8 104
(EngineCore_DP0 pid=290130) .b8 54
(EngineCore_DP0 pid=290130) .b8 52
(EngineCore_DP0 pid=290130) .b8 0
(EngineCore_DP0 pid=290130) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=290130) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=290130) .b8 113
(EngineCore_DP0 pid=290130) .b8 117
(EngineCore_DP0 pid=290130) .b8 97
(EngineCore_DP0 pid=290130) .b8 110
(EngineCore_DP0 pid=290130) .b8 116
(EngineCore_DP0 pid=290130) .b8 95
(EngineCore_DP0 pid=290130) .b8 115
(EngineCore_DP0 pid=290130) .b8 108
(EngineCore_DP0 pid=290130) .b8 105
(EngineCore_DP0 pid=290130) .b8 100
(EngineCore_DP0 pid=290130) .b8 101
(EngineCore_DP0 pid=290130) .b8 95
(EngineCore_DP0 pid=290130) .b8 105
(EngineCore_DP0 pid=290130) .b8 110
(EngineCore_DP0 pid=290130) .b8 116
(EngineCore_DP0 pid=290130) .b8 56
(EngineCore_DP0 pid=290130) .b8 95
(EngineCore_DP0 pid=290130) .b8 107
(EngineCore_DP0 pid=290130) .b8 101
(EngineCore_DP0 pid=290130) .b8 114
(EngineCore_DP0 pid=290130) .b8 110
(EngineCore_DP0 pid=290130) .b8 101
(EngineCore_DP0 pid=290130) .b8 108
(EngineCore_DP0 pid=290130) .b8 0
(EngineCore_DP0 pid=290130) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=290130) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=290130) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=290130) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=290130) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=290130) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=290130) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=290130) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=290130) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=290130) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=290130) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=290130) .b8 1
(EngineCore_DP0 pid=290130) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=290130) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=290130) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=290130) 	}
(EngineCore_DP0 pid=290130) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=290130) 
(EngineCore_DP0 pid=290130) ================================================================
(EngineCore_DP0 pid=290130) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=290130) 
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpr6txcne6.ptx', '-o', '/tmp/tmpr6txcne6.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866] 
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866] 
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866] 
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpr6txcne6.ptx -o /tmp/tmpr6txcne6.ptx.o
(EngineCore_DP0 pid=290130) ERROR 01-25 18:40:43 [core.py:866] 

STDERR:
[2026-01-25 18:40:28] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:40:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:40:28] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:40:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:40:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:40:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:40:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:40:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:40:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:40:31] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:40:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:40:31] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:40:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:40:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:40:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:40:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:40:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:40:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:40:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=290130) [2026-01-25 18:40:32] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=290130) [2026-01-25 18:40:32] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=290130) [2026-01-25 18:40:32] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=290130) [2026-01-25 18:40:32] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=290130) [2026-01-25 18:40:32] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=290130) [2026-01-25 18:40:32] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=290130) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=290130) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.29s/it]
(EngineCore_DP0 pid=290130) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.29s/it]
(EngineCore_DP0 pid=290130) 
(EngineCore_DP0 pid=290130) [2026-01-25 18:40:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=290130) [2026-01-25 18:40:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=290130) [2026-01-25 18:40:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=290130) [2026-01-25 18:40:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=290130) [2026-01-25 18:40:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=290130) [2026-01-25 18:40:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=290130) [2026-01-25 18:40:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=290130) [2026-01-25 18:40:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=290130) Process EngineCore_DP0:
(EngineCore_DP0 pid=290130) Traceback (most recent call last):
(EngineCore_DP0 pid=290130)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=290130)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=290130)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=290130)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=290130) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpr6txcne6.ptx', '-o', '/tmp/tmpr6txcne6.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=290130) 
(EngineCore_DP0 pid=290130) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=290130) 
(EngineCore_DP0 pid=290130) Traceback (most recent call last):
(EngineCore_DP0 pid=290130)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=290130)     self.run()
(EngineCore_DP0 pid=290130)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=290130)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=290130)     raise e
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=290130)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=290130)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=290130)     super().__init__(
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=290130)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=290130)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=290130)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=290130)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=290130)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=290130)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=290130)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=290130)     return func(*args, **kwargs)
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=290130)     return func(*args, **kwargs)
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=290130)     self.model_runner.profile_run()
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=290130)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=290130)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=290130)     return func(*args, **kwargs)
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=290130)     outputs = self.model(
(EngineCore_DP0 pid=290130)               ^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=290130)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=290130)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=290130)     model_output = self.model(
(EngineCore_DP0 pid=290130)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=290130)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=290130)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=290130)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=290130)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=290130)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=290130)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=290130)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=290130)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=290130)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=290130)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=290130)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=290130)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=290130)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=290130)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=290130)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=290130)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=290130)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=290130)     return self._linear_fn(
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=290130)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=290130)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=290130)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=290130)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=290130)     return fn(input, L)
(EngineCore_DP0 pid=290130)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=290130)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=290130)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=290130)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=290130)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=290130)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=290130)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=290130)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=290130)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=290130)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=290130)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=290130)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=290130)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=290130)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=290130)     raise PTXASError(error)
(EngineCore_DP0 pid=290130) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=290130) `ptxas` stderr:
(EngineCore_DP0 pid=290130) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=290130) 
(EngineCore_DP0 pid=290130) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpr6txcne6.ptx -o /tmp/tmpr6txcne6.ptx.o
(EngineCore_DP0 pid=290130) 
[rank0]:[W125 18:40:44.207561603 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=256

========== M=512 ==========
Time: 2026-01-25 18:58:53
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:58:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:58:56 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=315100) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=315100) 
(EngineCore_DP0 pid=315100) 
(EngineCore_DP0 pid=315100) ================================================================
(EngineCore_DP0 pid=315100) Internal Triton PTX codegen error
(EngineCore_DP0 pid=315100) `ptxas` stderr:
(EngineCore_DP0 pid=315100) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=315100) 
(EngineCore_DP0 pid=315100) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpr63qty_i.ptx -o /tmp/tmpr63qty_i.ptx.o
(EngineCore_DP0 pid=315100) 
(EngineCore_DP0 pid=315100) 
(EngineCore_DP0 pid=315100) //
(EngineCore_DP0 pid=315100) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=315100) //
(EngineCore_DP0 pid=315100) 
(EngineCore_DP0 pid=315100) .version 8.7
(EngineCore_DP0 pid=315100) .target sm_121a
(EngineCore_DP0 pid=315100) .address_size 64
(EngineCore_DP0 pid=315100) 
(EngineCore_DP0 pid=315100) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=315100) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=315100)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=315100) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=315100) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=315100) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=315100) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=315100) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=315100) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=315100) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=315100) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=315100) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=315100) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=315100) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=315100) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=315100) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=315100) )
(EngineCore_DP0 pid=315100) .reqntid 1024
(EngineCore_DP0 pid=315100) {
(EngineCore_DP0 pid=315100) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=315100) 	.reg .b16 	%rs<20>;
(EngineCore_DP0 pid=315100) 	.reg .b32 	%r<119>;
(EngineCore_DP0 pid=315100) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=315100) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=315100) $L__func_begin0:
(EngineCore_DP0 pid=315100) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=315100) 
(EngineCore_DP0 pid=315100) // %bb.0:
(EngineCore_DP0 pid=315100) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=315100) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=315100) 	ld.param.b32 	%r17, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=315100) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=315100) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=315100) $L__tmp0:
(EngineCore_DP0 pid=315100) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=315100) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=315100) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=315100) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=315100) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=315100) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=315100) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=315100) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=315100) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=315100) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=315100) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=315100) 	mov.b32 	%r117, 0f2B8CBCCC;
(EngineCore_DP0 pid=315100) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=315100) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=315100) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=315100) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=315100) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=315100) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=315100) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=315100) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=315100) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=315100) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=315100) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=315100) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=315100) 	mov.b32 	%r115, 0f00000000;
(EngineCore_DP0 pid=315100) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=315100) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=315100) 	mov.b32 	%r116, %r37;
(EngineCore_DP0 pid=315100) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=315100) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=315100) 	add.s32 	%r45, %r3, %r116;
(EngineCore_DP0 pid=315100) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=315100) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=315100) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=315100) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=315100) 	// begin inline asm
(EngineCore_DP0 pid=315100) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=315100) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=315100) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=315100) 	// end inline asm
(EngineCore_DP0 pid=315100) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=315100) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=315100) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=315100) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=315100) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=315100) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=315100) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=315100) $L__tmp1:
(EngineCore_DP0 pid=315100) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	bar.sync 	0;
(EngineCore_DP0 pid=315100) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=315100) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=315100) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=315100) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=315100) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=315100) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=315100) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=315100) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=315100) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=315100) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=315100) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=315100) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=315100) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=315100) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=315100) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	// begin inline asm
(EngineCore_DP0 pid=315100) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=315100) 	// end inline asm
(EngineCore_DP0 pid=315100) 	bar.sync 	0;
(EngineCore_DP0 pid=315100) 	// begin inline asm
(EngineCore_DP0 pid=315100) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=315100) 	// end inline asm
(EngineCore_DP0 pid=315100) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=315100) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=315100) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=315100) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=315100) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=315100) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=315100) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=315100) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=315100) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=315100) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=315100) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315100) 	// begin inline asm
(EngineCore_DP0 pid=315100) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=315100) 	// end inline asm
(EngineCore_DP0 pid=315100) 	bar.sync 	0;
(EngineCore_DP0 pid=315100) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=315100) $L__tmp2:
(EngineCore_DP0 pid=315100) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=315100) 	max.f32 	%r115, %r115, %r65;
(EngineCore_DP0 pid=315100) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=315100) 	add.s32 	%r116, %r116, 4096;
(EngineCore_DP0 pid=315100) 	setp.lt.s32 	%p6, %r116, %r18;
(EngineCore_DP0 pid=315100) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=315100) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=315100) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=315100) 	max.f32 	%r117, %r115, 0f2B8CBCCC;
(EngineCore_DP0 pid=315100) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=315100) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=315100) 	mov.b32 	%r67, 0f42FE0000;
(EngineCore_DP0 pid=315100) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=315100) 	div.full.f32 	%r68, %r117, %r67;
(EngineCore_DP0 pid=315100) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=315100) 	max.f32 	%r66, %r68, 0f37810204;
(EngineCore_DP0 pid=315100) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=315100) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=315100) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=315100) 	// begin inline asm
(EngineCore_DP0 pid=315100) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=315100) 	// end inline asm
(EngineCore_DP0 pid=315100) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=315100) 	shl.b32 	%r14, %r19, 1;
(EngineCore_DP0 pid=315100) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=315100) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=315100) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=315100) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=315100) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=315100) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=315100) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=315100) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=315100) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=315100) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=315100) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=315100) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=315100) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=315100) 	div.full.f32 	%r13, %r67, %r117;
(EngineCore_DP0 pid=315100) 	mov.b32 	%r118, 0;
(EngineCore_DP0 pid=315100) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=315100)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=315100) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=315100) 	add.s32 	%r72, %r2, %r118;
(EngineCore_DP0 pid=315100) 	setp.lt.s32 	%p13, %r72, %r14;
(EngineCore_DP0 pid=315100) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=315100) 	shr.u32 	%r73, %r72, 31;
(EngineCore_DP0 pid=315100) 	add.s32 	%r74, %r72, %r73;
(EngineCore_DP0 pid=315100) 	shr.u32 	%r75, %r74, 1;
(EngineCore_DP0 pid=315100) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=315100) 	and.b32 	%r76, %r74, 2147483646;
(EngineCore_DP0 pid=315100) 	sub.s32 	%r77, %r72, %r76;
(EngineCore_DP0 pid=315100) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=315100) 	shl.b32 	%r78, %r77, 1;
(EngineCore_DP0 pid=315100) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=315100) 	mad.lo.s32 	%r79, %r75, 6, %r78;
(EngineCore_DP0 pid=315100) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=315100) 	setp.lt.s32 	%p14, %r79, %r17;
(EngineCore_DP0 pid=315100) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=315100) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=315100) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=315100) 	mad.wide.s32 	%rd8, %r79, 2, %rd1;
(EngineCore_DP0 pid=315100) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=315100) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=315100) 	// begin inline asm
(EngineCore_DP0 pid=315100) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=315100) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=315100) 	// end inline asm
(EngineCore_DP0 pid=315100) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=315100) 	cvt.f32.bf16 	%r80, %rs12;
(EngineCore_DP0 pid=315100) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=315100) 	or.b32 	%r81, %r79, 1;
(EngineCore_DP0 pid=315100) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=315100) 	setp.lt.s32 	%p15, %r81, %r17;
(EngineCore_DP0 pid=315100) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=315100) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=315100) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=315100) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=315100) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=315100) 	// begin inline asm
(EngineCore_DP0 pid=315100) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=315100) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=315100) 	// end inline asm
(EngineCore_DP0 pid=315100) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=315100) 	cvt.f32.bf16 	%r82, %rs14;
(EngineCore_DP0 pid=315100) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=315100) 	add.s32 	%r83, %r79, 2;
(EngineCore_DP0 pid=315100) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=315100) 	setp.lt.s32 	%p16, %r83, %r17;
(EngineCore_DP0 pid=315100) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=315100) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=315100) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=315100) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=315100) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=315100) 	// begin inline asm
(EngineCore_DP0 pid=315100) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=315100) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=315100) 	// end inline asm
(EngineCore_DP0 pid=315100) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=315100) 	cvt.f32.bf16 	%r84, %rs16;
(EngineCore_DP0 pid=315100) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=315100) 	add.s32 	%r85, %r79, 3;
(EngineCore_DP0 pid=315100) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=315100) 	setp.lt.s32 	%p17, %r85, %r17;
(EngineCore_DP0 pid=315100) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=315100) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=315100) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=315100) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=315100) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=315100) 	// begin inline asm
(EngineCore_DP0 pid=315100) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=315100) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=315100) 	// end inline asm
(EngineCore_DP0 pid=315100) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=315100) 	cvt.f32.bf16 	%r86, %rs18;
(EngineCore_DP0 pid=315100) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=315100) 	mul.f32 	%r87, %r13, %r80;
(EngineCore_DP0 pid=315100) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=315100) 	cvt.rni.f32.f32 	%r88, %r87;
(EngineCore_DP0 pid=315100) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=315100) 	max.f32 	%r89, %r88, 0fC3000000;
(EngineCore_DP0 pid=315100) 	min.f32 	%r90, %r89, 0f42FE0000;
(EngineCore_DP0 pid=315100) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=315100) 	cvt.rzi.s32.f32 	%r91, %r90;
(EngineCore_DP0 pid=315100) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=315100) 	and.b32 	%r92, %r91, 255;
(EngineCore_DP0 pid=315100) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=315100) 	mul.f32 	%r93, %r13, %r82;
(EngineCore_DP0 pid=315100) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=315100) 	cvt.rni.f32.f32 	%r94, %r93;
(EngineCore_DP0 pid=315100) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=315100) 	mul.f32 	%r95, %r13, %r84;
(EngineCore_DP0 pid=315100) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=315100) 	cvt.rni.f32.f32 	%r96, %r95;
(EngineCore_DP0 pid=315100) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=315100) 	mul.f32 	%r97, %r13, %r86;
(EngineCore_DP0 pid=315100) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=315100) 	cvt.rni.f32.f32 	%r98, %r97;
(EngineCore_DP0 pid=315100) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=315100) 	max.f32 	%r99, %r98, 0fC3000000;
(EngineCore_DP0 pid=315100) 	min.f32 	%r100, %r99, 0f42FE0000;
(EngineCore_DP0 pid=315100) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=315100) 	cvt.rzi.s32.f32 	%r101, %r100;
(EngineCore_DP0 pid=315100) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=315100) 	max.f32 	%r102, %r96, 0fC3000000;
(EngineCore_DP0 pid=315100) 	max.f32 	%r103, %r94, 0fC3000000;
(EngineCore_DP0 pid=315100) 	min.f32 	%r104, %r103, 0f42FE0000;
(EngineCore_DP0 pid=315100) 	min.f32 	%r105, %r102, 0f42FE0000;
(EngineCore_DP0 pid=315100) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=315100) 	cvt.rzi.s32.f32 	%r106, %r105;
(EngineCore_DP0 pid=315100) 	cvt.rzi.s32.f32 	%r107, %r104;
(EngineCore_DP0 pid=315100) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=315100) 	shl.b32 	%r108, %r107, 8;
(EngineCore_DP0 pid=315100) 	shl.b32 	%r109, %r106, 16;
(EngineCore_DP0 pid=315100) 	and.b32 	%r110, %r109, 16711680;
(EngineCore_DP0 pid=315100) 	and.b32 	%r111, %r108, 65280;
(EngineCore_DP0 pid=315100) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=315100) 	or.b32 	%r112, %r111, %r92;
(EngineCore_DP0 pid=315100) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=315100) 	or.b32 	%r113, %r112, %r110;
(EngineCore_DP0 pid=315100) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=315100) 	shl.b32 	%r114, %r101, 24;
(EngineCore_DP0 pid=315100) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=315100) 	or.b32 	%r70, %r113, %r114;
(EngineCore_DP0 pid=315100) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=315100) 	mad.wide.s32 	%rd12, %r72, 4, %rd2;
(EngineCore_DP0 pid=315100) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=315100) 	// begin inline asm
(EngineCore_DP0 pid=315100) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r70 };
(EngineCore_DP0 pid=315100) 	// end inline asm
(EngineCore_DP0 pid=315100) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=315100) 	add.s32 	%r118, %r118, 1024;
(EngineCore_DP0 pid=315100) 	setp.lt.s32 	%p18, %r118, %r14;
(EngineCore_DP0 pid=315100) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=315100) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=315100) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=315100) 	ret;
(EngineCore_DP0 pid=315100) $L__tmp3:
(EngineCore_DP0 pid=315100) $L__func_end0:
(EngineCore_DP0 pid=315100)                                         // -- End function
(EngineCore_DP0 pid=315100) }
(EngineCore_DP0 pid=315100) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=315100) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=315100) 	.section	.debug_abbrev
(EngineCore_DP0 pid=315100) 	{
(EngineCore_DP0 pid=315100) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=315100) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=315100) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=315100) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=315100) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=315100) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=315100) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=315100) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=315100) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=315100) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=315100) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=315100) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=315100) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=315100) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=315100) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=315100) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=315100) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=315100) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=315100) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=315100) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=315100) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=315100) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=315100) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=315100) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=315100) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=315100) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=315100) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=315100) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=315100) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=315100) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=315100) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=315100) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=315100) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=315100) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=315100) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=315100) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=315100) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=315100) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=315100) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=315100) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=315100) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=315100) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=315100) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=315100) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=315100) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=315100) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=315100) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=315100) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=315100) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=315100) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=315100) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=315100) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=315100) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=315100) 	}
(EngineCore_DP0 pid=315100) 	.section	.debug_info
(EngineCore_DP0 pid=315100) 	{
(EngineCore_DP0 pid=315100) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=315100) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=315100) .b8 0
(EngineCore_DP0 pid=315100) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=315100) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=315100) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=315100) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=315100) .b8 114
(EngineCore_DP0 pid=315100) .b8 105
(EngineCore_DP0 pid=315100) .b8 116
(EngineCore_DP0 pid=315100) .b8 111
(EngineCore_DP0 pid=315100) .b8 110
(EngineCore_DP0 pid=315100) .b8 0
(EngineCore_DP0 pid=315100) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=315100) .b8 0
(EngineCore_DP0 pid=315100) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=315100) .b8 117
(EngineCore_DP0 pid=315100) .b8 97
(EngineCore_DP0 pid=315100) .b8 110
(EngineCore_DP0 pid=315100) .b8 116
(EngineCore_DP0 pid=315100) .b8 95
(EngineCore_DP0 pid=315100) .b8 115
(EngineCore_DP0 pid=315100) .b8 108
(EngineCore_DP0 pid=315100) .b8 105
(EngineCore_DP0 pid=315100) .b8 100
(EngineCore_DP0 pid=315100) .b8 101
(EngineCore_DP0 pid=315100) .b8 95
(EngineCore_DP0 pid=315100) .b8 116
(EngineCore_DP0 pid=315100) .b8 117
(EngineCore_DP0 pid=315100) .b8 110
(EngineCore_DP0 pid=315100) .b8 101
(EngineCore_DP0 pid=315100) .b8 100
(EngineCore_DP0 pid=315100) .b8 95
(EngineCore_DP0 pid=315100) .b8 76
(EngineCore_DP0 pid=315100) .b8 108
(EngineCore_DP0 pid=315100) .b8 97
(EngineCore_DP0 pid=315100) .b8 109
(EngineCore_DP0 pid=315100) .b8 97
(EngineCore_DP0 pid=315100) .b8 51
(EngineCore_DP0 pid=315100) .b8 46
(EngineCore_DP0 pid=315100) .b8 50
(EngineCore_DP0 pid=315100) .b8 45
(EngineCore_DP0 pid=315100) .b8 49
(EngineCore_DP0 pid=315100) .b8 66
(EngineCore_DP0 pid=315100) .b8 46
(EngineCore_DP0 pid=315100) .b8 112
(EngineCore_DP0 pid=315100) .b8 121
(EngineCore_DP0 pid=315100) .b8 0
(EngineCore_DP0 pid=315100) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=315100) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=315100) .b8 114
(EngineCore_DP0 pid=315100) .b8 111
(EngineCore_DP0 pid=315100) .b8 111
(EngineCore_DP0 pid=315100) .b8 116
(EngineCore_DP0 pid=315100) .b8 47
(EngineCore_DP0 pid=315100) .b8 118
(EngineCore_DP0 pid=315100) .b8 108
(EngineCore_DP0 pid=315100) .b8 108
(EngineCore_DP0 pid=315100) .b8 109
(EngineCore_DP0 pid=315100) .b8 98
(EngineCore_DP0 pid=315100) .b8 101
(EngineCore_DP0 pid=315100) .b8 110
(EngineCore_DP0 pid=315100) .b8 99
(EngineCore_DP0 pid=315100) .b8 104
(EngineCore_DP0 pid=315100) .b8 47
(EngineCore_DP0 pid=315100) .b8 115
(EngineCore_DP0 pid=315100) .b8 108
(EngineCore_DP0 pid=315100) .b8 105
(EngineCore_DP0 pid=315100) .b8 100
(EngineCore_DP0 pid=315100) .b8 101
(EngineCore_DP0 pid=315100) .b8 115
(EngineCore_DP0 pid=315100) .b8 112
(EngineCore_DP0 pid=315100) .b8 97
(EngineCore_DP0 pid=315100) .b8 114
(EngineCore_DP0 pid=315100) .b8 115
(EngineCore_DP0 pid=315100) .b8 101
(EngineCore_DP0 pid=315100) .b8 47
(EngineCore_DP0 pid=315100) .b8 99
(EngineCore_DP0 pid=315100) .b8 115
(EngineCore_DP0 pid=315100) .b8 114
(EngineCore_DP0 pid=315100) .b8 99
(EngineCore_DP0 pid=315100) .b8 47
(EngineCore_DP0 pid=315100) .b8 102
(EngineCore_DP0 pid=315100) .b8 117
(EngineCore_DP0 pid=315100) .b8 115
(EngineCore_DP0 pid=315100) .b8 101
(EngineCore_DP0 pid=315100) .b8 100
(EngineCore_DP0 pid=315100) .b8 95
(EngineCore_DP0 pid=315100) .b8 113
(EngineCore_DP0 pid=315100) .b8 117
(EngineCore_DP0 pid=315100) .b8 97
(EngineCore_DP0 pid=315100) .b8 110
(EngineCore_DP0 pid=315100) .b8 116
(EngineCore_DP0 pid=315100) .b8 95
(EngineCore_DP0 pid=315100) .b8 115
(EngineCore_DP0 pid=315100) .b8 108
(EngineCore_DP0 pid=315100) .b8 105
(EngineCore_DP0 pid=315100) .b8 100
(EngineCore_DP0 pid=315100) .b8 101
(EngineCore_DP0 pid=315100) .b8 95
(EngineCore_DP0 pid=315100) .b8 116
(EngineCore_DP0 pid=315100) .b8 114
(EngineCore_DP0 pid=315100) .b8 105
(EngineCore_DP0 pid=315100) .b8 116
(EngineCore_DP0 pid=315100) .b8 111
(EngineCore_DP0 pid=315100) .b8 110
(EngineCore_DP0 pid=315100) .b8 47
(EngineCore_DP0 pid=315100) .b8 98
(EngineCore_DP0 pid=315100) .b8 117
(EngineCore_DP0 pid=315100) .b8 105
(EngineCore_DP0 pid=315100) .b8 108
(EngineCore_DP0 pid=315100) .b8 100
(EngineCore_DP0 pid=315100) .b8 47
(EngineCore_DP0 pid=315100) .b8 71
(EngineCore_DP0 pid=315100) .b8 66
(EngineCore_DP0 pid=315100) .b8 49
(EngineCore_DP0 pid=315100) .b8 48
(EngineCore_DP0 pid=315100) .b8 95
(EngineCore_DP0 pid=315100) .b8 99
(EngineCore_DP0 pid=315100) .b8 99
(EngineCore_DP0 pid=315100) .b8 49
(EngineCore_DP0 pid=315100) .b8 50
(EngineCore_DP0 pid=315100) .b8 49
(EngineCore_DP0 pid=315100) .b8 95
(EngineCore_DP0 pid=315100) .b8 112
(EngineCore_DP0 pid=315100) .b8 121
(EngineCore_DP0 pid=315100) .b8 51
(EngineCore_DP0 pid=315100) .b8 49
(EngineCore_DP0 pid=315100) .b8 50
(EngineCore_DP0 pid=315100) .b8 95
(EngineCore_DP0 pid=315100) .b8 99
(EngineCore_DP0 pid=315100) .b8 117
(EngineCore_DP0 pid=315100) .b8 49
(EngineCore_DP0 pid=315100) .b8 50
(EngineCore_DP0 pid=315100) .b8 57
(EngineCore_DP0 pid=315100) .b8 95
(EngineCore_DP0 pid=315100) .b8 97
(EngineCore_DP0 pid=315100) .b8 97
(EngineCore_DP0 pid=315100) .b8 114
(EngineCore_DP0 pid=315100) .b8 99
(EngineCore_DP0 pid=315100) .b8 104
(EngineCore_DP0 pid=315100) .b8 54
(EngineCore_DP0 pid=315100) .b8 52
(EngineCore_DP0 pid=315100) .b8 0
(EngineCore_DP0 pid=315100) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=315100) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=315100) .b8 113
(EngineCore_DP0 pid=315100) .b8 117
(EngineCore_DP0 pid=315100) .b8 97
(EngineCore_DP0 pid=315100) .b8 110
(EngineCore_DP0 pid=315100) .b8 116
(EngineCore_DP0 pid=315100) .b8 95
(EngineCore_DP0 pid=315100) .b8 115
(EngineCore_DP0 pid=315100) .b8 108
(EngineCore_DP0 pid=315100) .b8 105
(EngineCore_DP0 pid=315100) .b8 100
(EngineCore_DP0 pid=315100) .b8 101
(EngineCore_DP0 pid=315100) .b8 95
(EngineCore_DP0 pid=315100) .b8 105
(EngineCore_DP0 pid=315100) .b8 110
(EngineCore_DP0 pid=315100) .b8 116
(EngineCore_DP0 pid=315100) .b8 56
(EngineCore_DP0 pid=315100) .b8 95
(EngineCore_DP0 pid=315100) .b8 107
(EngineCore_DP0 pid=315100) .b8 101
(EngineCore_DP0 pid=315100) .b8 114
(EngineCore_DP0 pid=315100) .b8 110
(EngineCore_DP0 pid=315100) .b8 101
(EngineCore_DP0 pid=315100) .b8 108
(EngineCore_DP0 pid=315100) .b8 0
(EngineCore_DP0 pid=315100) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=315100) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=315100) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=315100) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=315100) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=315100) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=315100) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=315100) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=315100) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=315100) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=315100) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=315100) .b8 1
(EngineCore_DP0 pid=315100) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=315100) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=315100) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=315100) 	}
(EngineCore_DP0 pid=315100) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=315100) 
(EngineCore_DP0 pid=315100) ================================================================
(EngineCore_DP0 pid=315100) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=315100) 
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpr63qty_i.ptx', '-o', '/tmp/tmpr63qty_i.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866] 
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866] 
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866] 
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpr63qty_i.ptx -o /tmp/tmpr63qty_i.ptx.o
(EngineCore_DP0 pid=315100) ERROR 01-25 18:59:11 [core.py:866] 

STDERR:
[2026-01-25 18:58:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:58:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:58:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:58:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:58:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:58:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:58:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:58:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:58:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:58:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:58:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:58:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:58:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:58:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:59:00] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:59:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:59:00] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:59:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:59:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:59:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:59:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:59:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:59:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=315100) [2026-01-25 18:59:01] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=315100) [2026-01-25 18:59:01] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=315100) [2026-01-25 18:59:01] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=315100) [2026-01-25 18:59:01] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=315100) [2026-01-25 18:59:01] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=315100) [2026-01-25 18:59:01] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=315100) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=315100) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.05s/it]
(EngineCore_DP0 pid=315100) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.05s/it]
(EngineCore_DP0 pid=315100) 
(EngineCore_DP0 pid=315100) [2026-01-25 18:59:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=315100) [2026-01-25 18:59:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=315100) [2026-01-25 18:59:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=315100) [2026-01-25 18:59:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=315100) [2026-01-25 18:59:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=315100) [2026-01-25 18:59:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=315100) [2026-01-25 18:59:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=315100) [2026-01-25 18:59:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=315100) Process EngineCore_DP0:
(EngineCore_DP0 pid=315100) Traceback (most recent call last):
(EngineCore_DP0 pid=315100)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=315100)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=315100)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=315100)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=315100) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpr63qty_i.ptx', '-o', '/tmp/tmpr63qty_i.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=315100) 
(EngineCore_DP0 pid=315100) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=315100) 
(EngineCore_DP0 pid=315100) Traceback (most recent call last):
(EngineCore_DP0 pid=315100)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=315100)     self.run()
(EngineCore_DP0 pid=315100)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=315100)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=315100)     raise e
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=315100)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=315100)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=315100)     super().__init__(
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=315100)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=315100)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=315100)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=315100)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=315100)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=315100)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=315100)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=315100)     return func(*args, **kwargs)
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=315100)     return func(*args, **kwargs)
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=315100)     self.model_runner.profile_run()
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=315100)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=315100)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=315100)     return func(*args, **kwargs)
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=315100)     outputs = self.model(
(EngineCore_DP0 pid=315100)               ^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=315100)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=315100)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=315100)     model_output = self.model(
(EngineCore_DP0 pid=315100)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=315100)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=315100)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=315100)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=315100)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=315100)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=315100)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=315100)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=315100)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=315100)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=315100)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=315100)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=315100)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=315100)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=315100)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=315100)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=315100)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=315100)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=315100)     return self._linear_fn(
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=315100)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=315100)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=315100)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=315100)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=315100)     return fn(input, L)
(EngineCore_DP0 pid=315100)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=315100)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=315100)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=315100)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=315100)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=315100)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=315100)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=315100)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=315100)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=315100)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=315100)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=315100)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=315100)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315100)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=315100)     raise PTXASError(error)
(EngineCore_DP0 pid=315100) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=315100) `ptxas` stderr:
(EngineCore_DP0 pid=315100) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=315100) 
(EngineCore_DP0 pid=315100) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpr63qty_i.ptx -o /tmp/tmpr63qty_i.ptx.o
(EngineCore_DP0 pid=315100) 
[rank0]:[W125 18:59:11.168688707 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 18:59:13
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:59:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:59:17 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=315574) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=315574) 
(EngineCore_DP0 pid=315574) 
(EngineCore_DP0 pid=315574) ================================================================
(EngineCore_DP0 pid=315574) Internal Triton PTX codegen error
(EngineCore_DP0 pid=315574) `ptxas` stderr:
(EngineCore_DP0 pid=315574) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=315574) 
(EngineCore_DP0 pid=315574) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp10m_dy16.ptx -o /tmp/tmp10m_dy16.ptx.o
(EngineCore_DP0 pid=315574) 
(EngineCore_DP0 pid=315574) 
(EngineCore_DP0 pid=315574) //
(EngineCore_DP0 pid=315574) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=315574) //
(EngineCore_DP0 pid=315574) 
(EngineCore_DP0 pid=315574) .version 8.7
(EngineCore_DP0 pid=315574) .target sm_121a
(EngineCore_DP0 pid=315574) .address_size 64
(EngineCore_DP0 pid=315574) 
(EngineCore_DP0 pid=315574) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=315574) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=315574)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=315574) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=315574) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=315574) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=315574) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=315574) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=315574) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=315574) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=315574) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=315574) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=315574) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=315574) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=315574) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=315574) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=315574) )
(EngineCore_DP0 pid=315574) .reqntid 512
(EngineCore_DP0 pid=315574) {
(EngineCore_DP0 pid=315574) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=315574) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=315574) 	.reg .b32 	%r<131>;
(EngineCore_DP0 pid=315574) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=315574) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=315574) $L__func_begin0:
(EngineCore_DP0 pid=315574) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=315574) 
(EngineCore_DP0 pid=315574) // %bb.0:
(EngineCore_DP0 pid=315574) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=315574) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=315574) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=315574) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=315574) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=315574) $L__tmp0:
(EngineCore_DP0 pid=315574) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=315574) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=315574) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=315574) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=315574) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=315574) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=315574) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=315574) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=315574) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=315574) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=315574) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=315574) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=315574) 	mov.b32 	%r129, 0f2B8CBCCC;
(EngineCore_DP0 pid=315574) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=315574) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=315574) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=315574) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=315574) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=315574) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=315574) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=315574) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=315574) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=315574) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=315574) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=315574) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=315574) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=315574) 	mov.b32 	%r127, 0f00000000;
(EngineCore_DP0 pid=315574) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=315574) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=315574) 	mov.b32 	%r128, %r40;
(EngineCore_DP0 pid=315574) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=315574) 	.loc	1 299 19                        // quant_slide_tuned_Llama3.2-1B.py:299:19
(EngineCore_DP0 pid=315574) 	add.s32 	%r58, %r4, %r128;
(EngineCore_DP0 pid=315574) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=315574) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=315574) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=315574) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=315574) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=315574) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=315574) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=315574) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=315574) 	// begin inline asm
(EngineCore_DP0 pid=315574) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=315574) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=315574) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=315574) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=315574) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=315574) 	// end inline asm
(EngineCore_DP0 pid=315574) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=315574) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=315574) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=315574) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=315574) 	// begin inline asm
(EngineCore_DP0 pid=315574) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=315574) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=315574) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=315574) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=315574) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=315574) 	// end inline asm
(EngineCore_DP0 pid=315574) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=315574) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=315574) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=315574) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=315574) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=315574) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=315574) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=315574) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=315574) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=315574) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=315574) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=315574) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=315574) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=315574) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=315574) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=315574) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=315574) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=315574) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=315574) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=315574) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=315574) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=315574) $L__tmp1:
(EngineCore_DP0 pid=315574) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	bar.sync 	0;
(EngineCore_DP0 pid=315574) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=315574) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=315574) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=315574) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=315574) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=315574) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=315574) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=315574) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=315574) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=315574) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=315574) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=315574) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=315574) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=315574) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=315574) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=315574) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=315574) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=315574) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=315574) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=315574) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=315574) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=315574) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=315574) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=315574) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=315574) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=315574) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=315574) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	// begin inline asm
(EngineCore_DP0 pid=315574) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=315574) 	// end inline asm
(EngineCore_DP0 pid=315574) 	bar.sync 	0;
(EngineCore_DP0 pid=315574) 	// begin inline asm
(EngineCore_DP0 pid=315574) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=315574) 	// end inline asm
(EngineCore_DP0 pid=315574) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=315574) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=315574) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=315574) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=315574) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=315574) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=315574) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=315574) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=315574) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=315574) 	// begin inline asm
(EngineCore_DP0 pid=315574) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=315574) 	// end inline asm
(EngineCore_DP0 pid=315574) 	bar.sync 	0;
(EngineCore_DP0 pid=315574) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=315574) $L__tmp2:
(EngineCore_DP0 pid=315574) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=315574) 	max.f32 	%r127, %r127, %r77;
(EngineCore_DP0 pid=315574) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=315574) 	add.s32 	%r128, %r128, 8192;
(EngineCore_DP0 pid=315574) 	setp.lt.s32 	%p7, %r128, %r19;
(EngineCore_DP0 pid=315574) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=315574) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=315574) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=315574) 	max.f32 	%r129, %r127, 0f2B8CBCCC;
(EngineCore_DP0 pid=315574) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=315574) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=315574) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=315574) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=315574) 	div.full.f32 	%r80, %r129, %r79;
(EngineCore_DP0 pid=315574) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=315574) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=315574) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=315574) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=315574) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=315574) 	// begin inline asm
(EngineCore_DP0 pid=315574) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=315574) 	// end inline asm
(EngineCore_DP0 pid=315574) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=315574) 	shl.b32 	%r15, %r20, 1;
(EngineCore_DP0 pid=315574) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=315574) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=315574) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=315574) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=315574) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=315574) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=315574) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=315574) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=315574) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=315574) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=315574) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=315574) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=315574) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=315574) 	div.full.f32 	%r14, %r79, %r129;
(EngineCore_DP0 pid=315574) 	mov.b32 	%r130, 0;
(EngineCore_DP0 pid=315574) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=315574)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=315574) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=315574) 	add.s32 	%r84, %r3, %r130;
(EngineCore_DP0 pid=315574) 	setp.lt.s32 	%p14, %r84, %r15;
(EngineCore_DP0 pid=315574) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=315574) 	shr.u32 	%r85, %r84, 31;
(EngineCore_DP0 pid=315574) 	add.s32 	%r86, %r84, %r85;
(EngineCore_DP0 pid=315574) 	shr.u32 	%r87, %r86, 1;
(EngineCore_DP0 pid=315574) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=315574) 	and.b32 	%r88, %r86, 2147483646;
(EngineCore_DP0 pid=315574) 	sub.s32 	%r89, %r84, %r88;
(EngineCore_DP0 pid=315574) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=315574) 	shl.b32 	%r90, %r89, 1;
(EngineCore_DP0 pid=315574) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=315574) 	mad.lo.s32 	%r91, %r87, 6, %r90;
(EngineCore_DP0 pid=315574) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=315574) 	setp.lt.s32 	%p15, %r91, %r18;
(EngineCore_DP0 pid=315574) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=315574) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=315574) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=315574) 	mad.wide.s32 	%rd9, %r91, 2, %rd1;
(EngineCore_DP0 pid=315574) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=315574) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=315574) 	// begin inline asm
(EngineCore_DP0 pid=315574) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=315574) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=315574) 	// end inline asm
(EngineCore_DP0 pid=315574) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=315574) 	cvt.f32.bf16 	%r92, %rs48;
(EngineCore_DP0 pid=315574) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=315574) 	or.b32 	%r93, %r91, 1;
(EngineCore_DP0 pid=315574) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=315574) 	setp.lt.s32 	%p16, %r93, %r18;
(EngineCore_DP0 pid=315574) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=315574) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=315574) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=315574) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=315574) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=315574) 	// begin inline asm
(EngineCore_DP0 pid=315574) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=315574) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=315574) 	// end inline asm
(EngineCore_DP0 pid=315574) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=315574) 	cvt.f32.bf16 	%r94, %rs50;
(EngineCore_DP0 pid=315574) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=315574) 	add.s32 	%r95, %r91, 2;
(EngineCore_DP0 pid=315574) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=315574) 	setp.lt.s32 	%p17, %r95, %r18;
(EngineCore_DP0 pid=315574) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=315574) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=315574) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=315574) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=315574) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=315574) 	// begin inline asm
(EngineCore_DP0 pid=315574) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=315574) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=315574) 	// end inline asm
(EngineCore_DP0 pid=315574) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=315574) 	cvt.f32.bf16 	%r96, %rs52;
(EngineCore_DP0 pid=315574) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=315574) 	add.s32 	%r97, %r91, 3;
(EngineCore_DP0 pid=315574) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=315574) 	setp.lt.s32 	%p18, %r97, %r18;
(EngineCore_DP0 pid=315574) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=315574) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=315574) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=315574) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=315574) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=315574) 	// begin inline asm
(EngineCore_DP0 pid=315574) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=315574) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=315574) 	// end inline asm
(EngineCore_DP0 pid=315574) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=315574) 	cvt.f32.bf16 	%r98, %rs54;
(EngineCore_DP0 pid=315574) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=315574) 	mul.f32 	%r99, %r14, %r92;
(EngineCore_DP0 pid=315574) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=315574) 	cvt.rni.f32.f32 	%r100, %r99;
(EngineCore_DP0 pid=315574) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=315574) 	max.f32 	%r101, %r100, 0fC3000000;
(EngineCore_DP0 pid=315574) 	min.f32 	%r102, %r101, 0f42FE0000;
(EngineCore_DP0 pid=315574) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=315574) 	cvt.rzi.s32.f32 	%r103, %r102;
(EngineCore_DP0 pid=315574) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=315574) 	and.b32 	%r104, %r103, 255;
(EngineCore_DP0 pid=315574) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=315574) 	mul.f32 	%r105, %r14, %r94;
(EngineCore_DP0 pid=315574) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=315574) 	cvt.rni.f32.f32 	%r106, %r105;
(EngineCore_DP0 pid=315574) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=315574) 	mul.f32 	%r107, %r14, %r96;
(EngineCore_DP0 pid=315574) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=315574) 	cvt.rni.f32.f32 	%r108, %r107;
(EngineCore_DP0 pid=315574) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=315574) 	mul.f32 	%r109, %r14, %r98;
(EngineCore_DP0 pid=315574) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=315574) 	cvt.rni.f32.f32 	%r110, %r109;
(EngineCore_DP0 pid=315574) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=315574) 	max.f32 	%r111, %r110, 0fC3000000;
(EngineCore_DP0 pid=315574) 	min.f32 	%r112, %r111, 0f42FE0000;
(EngineCore_DP0 pid=315574) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=315574) 	cvt.rzi.s32.f32 	%r113, %r112;
(EngineCore_DP0 pid=315574) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=315574) 	max.f32 	%r114, %r108, 0fC3000000;
(EngineCore_DP0 pid=315574) 	max.f32 	%r115, %r106, 0fC3000000;
(EngineCore_DP0 pid=315574) 	min.f32 	%r116, %r115, 0f42FE0000;
(EngineCore_DP0 pid=315574) 	min.f32 	%r117, %r114, 0f42FE0000;
(EngineCore_DP0 pid=315574) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=315574) 	cvt.rzi.s32.f32 	%r118, %r117;
(EngineCore_DP0 pid=315574) 	cvt.rzi.s32.f32 	%r119, %r116;
(EngineCore_DP0 pid=315574) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=315574) 	shl.b32 	%r120, %r119, 8;
(EngineCore_DP0 pid=315574) 	shl.b32 	%r121, %r118, 16;
(EngineCore_DP0 pid=315574) 	and.b32 	%r122, %r121, 16711680;
(EngineCore_DP0 pid=315574) 	and.b32 	%r123, %r120, 65280;
(EngineCore_DP0 pid=315574) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=315574) 	or.b32 	%r124, %r123, %r104;
(EngineCore_DP0 pid=315574) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=315574) 	or.b32 	%r125, %r124, %r122;
(EngineCore_DP0 pid=315574) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=315574) 	shl.b32 	%r126, %r113, 24;
(EngineCore_DP0 pid=315574) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=315574) 	or.b32 	%r82, %r125, %r126;
(EngineCore_DP0 pid=315574) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=315574) 	mad.wide.s32 	%rd13, %r84, 4, %rd2;
(EngineCore_DP0 pid=315574) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=315574) 	// begin inline asm
(EngineCore_DP0 pid=315574) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r82 };
(EngineCore_DP0 pid=315574) 	// end inline asm
(EngineCore_DP0 pid=315574) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=315574) 	add.s32 	%r130, %r130, 512;
(EngineCore_DP0 pid=315574) 	setp.lt.s32 	%p19, %r130, %r15;
(EngineCore_DP0 pid=315574) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=315574) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=315574) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=315574) 	ret;
(EngineCore_DP0 pid=315574) $L__tmp3:
(EngineCore_DP0 pid=315574) $L__func_end0:
(EngineCore_DP0 pid=315574)                                         // -- End function
(EngineCore_DP0 pid=315574) }
(EngineCore_DP0 pid=315574) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=315574) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=315574) 	.section	.debug_abbrev
(EngineCore_DP0 pid=315574) 	{
(EngineCore_DP0 pid=315574) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=315574) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=315574) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=315574) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=315574) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=315574) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=315574) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=315574) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=315574) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=315574) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=315574) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=315574) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=315574) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=315574) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=315574) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=315574) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=315574) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=315574) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=315574) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=315574) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=315574) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=315574) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=315574) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=315574) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=315574) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=315574) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=315574) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=315574) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=315574) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=315574) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=315574) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=315574) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=315574) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=315574) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=315574) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=315574) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=315574) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=315574) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=315574) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=315574) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=315574) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=315574) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=315574) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=315574) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=315574) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=315574) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=315574) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=315574) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=315574) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=315574) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=315574) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=315574) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=315574) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=315574) 	}
(EngineCore_DP0 pid=315574) 	.section	.debug_info
(EngineCore_DP0 pid=315574) 	{
(EngineCore_DP0 pid=315574) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=315574) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=315574) .b8 0
(EngineCore_DP0 pid=315574) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=315574) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=315574) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=315574) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=315574) .b8 114
(EngineCore_DP0 pid=315574) .b8 105
(EngineCore_DP0 pid=315574) .b8 116
(EngineCore_DP0 pid=315574) .b8 111
(EngineCore_DP0 pid=315574) .b8 110
(EngineCore_DP0 pid=315574) .b8 0
(EngineCore_DP0 pid=315574) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=315574) .b8 0
(EngineCore_DP0 pid=315574) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=315574) .b8 117
(EngineCore_DP0 pid=315574) .b8 97
(EngineCore_DP0 pid=315574) .b8 110
(EngineCore_DP0 pid=315574) .b8 116
(EngineCore_DP0 pid=315574) .b8 95
(EngineCore_DP0 pid=315574) .b8 115
(EngineCore_DP0 pid=315574) .b8 108
(EngineCore_DP0 pid=315574) .b8 105
(EngineCore_DP0 pid=315574) .b8 100
(EngineCore_DP0 pid=315574) .b8 101
(EngineCore_DP0 pid=315574) .b8 95
(EngineCore_DP0 pid=315574) .b8 116
(EngineCore_DP0 pid=315574) .b8 117
(EngineCore_DP0 pid=315574) .b8 110
(EngineCore_DP0 pid=315574) .b8 101
(EngineCore_DP0 pid=315574) .b8 100
(EngineCore_DP0 pid=315574) .b8 95
(EngineCore_DP0 pid=315574) .b8 76
(EngineCore_DP0 pid=315574) .b8 108
(EngineCore_DP0 pid=315574) .b8 97
(EngineCore_DP0 pid=315574) .b8 109
(EngineCore_DP0 pid=315574) .b8 97
(EngineCore_DP0 pid=315574) .b8 51
(EngineCore_DP0 pid=315574) .b8 46
(EngineCore_DP0 pid=315574) .b8 50
(EngineCore_DP0 pid=315574) .b8 45
(EngineCore_DP0 pid=315574) .b8 49
(EngineCore_DP0 pid=315574) .b8 66
(EngineCore_DP0 pid=315574) .b8 46
(EngineCore_DP0 pid=315574) .b8 112
(EngineCore_DP0 pid=315574) .b8 121
(EngineCore_DP0 pid=315574) .b8 0
(EngineCore_DP0 pid=315574) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=315574) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=315574) .b8 114
(EngineCore_DP0 pid=315574) .b8 111
(EngineCore_DP0 pid=315574) .b8 111
(EngineCore_DP0 pid=315574) .b8 116
(EngineCore_DP0 pid=315574) .b8 47
(EngineCore_DP0 pid=315574) .b8 118
(EngineCore_DP0 pid=315574) .b8 108
(EngineCore_DP0 pid=315574) .b8 108
(EngineCore_DP0 pid=315574) .b8 109
(EngineCore_DP0 pid=315574) .b8 98
(EngineCore_DP0 pid=315574) .b8 101
(EngineCore_DP0 pid=315574) .b8 110
(EngineCore_DP0 pid=315574) .b8 99
(EngineCore_DP0 pid=315574) .b8 104
(EngineCore_DP0 pid=315574) .b8 47
(EngineCore_DP0 pid=315574) .b8 115
(EngineCore_DP0 pid=315574) .b8 108
(EngineCore_DP0 pid=315574) .b8 105
(EngineCore_DP0 pid=315574) .b8 100
(EngineCore_DP0 pid=315574) .b8 101
(EngineCore_DP0 pid=315574) .b8 115
(EngineCore_DP0 pid=315574) .b8 112
(EngineCore_DP0 pid=315574) .b8 97
(EngineCore_DP0 pid=315574) .b8 114
(EngineCore_DP0 pid=315574) .b8 115
(EngineCore_DP0 pid=315574) .b8 101
(EngineCore_DP0 pid=315574) .b8 47
(EngineCore_DP0 pid=315574) .b8 99
(EngineCore_DP0 pid=315574) .b8 115
(EngineCore_DP0 pid=315574) .b8 114
(EngineCore_DP0 pid=315574) .b8 99
(EngineCore_DP0 pid=315574) .b8 47
(EngineCore_DP0 pid=315574) .b8 102
(EngineCore_DP0 pid=315574) .b8 117
(EngineCore_DP0 pid=315574) .b8 115
(EngineCore_DP0 pid=315574) .b8 101
(EngineCore_DP0 pid=315574) .b8 100
(EngineCore_DP0 pid=315574) .b8 95
(EngineCore_DP0 pid=315574) .b8 113
(EngineCore_DP0 pid=315574) .b8 117
(EngineCore_DP0 pid=315574) .b8 97
(EngineCore_DP0 pid=315574) .b8 110
(EngineCore_DP0 pid=315574) .b8 116
(EngineCore_DP0 pid=315574) .b8 95
(EngineCore_DP0 pid=315574) .b8 115
(EngineCore_DP0 pid=315574) .b8 108
(EngineCore_DP0 pid=315574) .b8 105
(EngineCore_DP0 pid=315574) .b8 100
(EngineCore_DP0 pid=315574) .b8 101
(EngineCore_DP0 pid=315574) .b8 95
(EngineCore_DP0 pid=315574) .b8 116
(EngineCore_DP0 pid=315574) .b8 114
(EngineCore_DP0 pid=315574) .b8 105
(EngineCore_DP0 pid=315574) .b8 116
(EngineCore_DP0 pid=315574) .b8 111
(EngineCore_DP0 pid=315574) .b8 110
(EngineCore_DP0 pid=315574) .b8 47
(EngineCore_DP0 pid=315574) .b8 98
(EngineCore_DP0 pid=315574) .b8 117
(EngineCore_DP0 pid=315574) .b8 105
(EngineCore_DP0 pid=315574) .b8 108
(EngineCore_DP0 pid=315574) .b8 100
(EngineCore_DP0 pid=315574) .b8 47
(EngineCore_DP0 pid=315574) .b8 71
(EngineCore_DP0 pid=315574) .b8 66
(EngineCore_DP0 pid=315574) .b8 49
(EngineCore_DP0 pid=315574) .b8 48
(EngineCore_DP0 pid=315574) .b8 95
(EngineCore_DP0 pid=315574) .b8 99
(EngineCore_DP0 pid=315574) .b8 99
(EngineCore_DP0 pid=315574) .b8 49
(EngineCore_DP0 pid=315574) .b8 50
(EngineCore_DP0 pid=315574) .b8 49
(EngineCore_DP0 pid=315574) .b8 95
(EngineCore_DP0 pid=315574) .b8 112
(EngineCore_DP0 pid=315574) .b8 121
(EngineCore_DP0 pid=315574) .b8 51
(EngineCore_DP0 pid=315574) .b8 49
(EngineCore_DP0 pid=315574) .b8 50
(EngineCore_DP0 pid=315574) .b8 95
(EngineCore_DP0 pid=315574) .b8 99
(EngineCore_DP0 pid=315574) .b8 117
(EngineCore_DP0 pid=315574) .b8 49
(EngineCore_DP0 pid=315574) .b8 50
(EngineCore_DP0 pid=315574) .b8 57
(EngineCore_DP0 pid=315574) .b8 95
(EngineCore_DP0 pid=315574) .b8 97
(EngineCore_DP0 pid=315574) .b8 97
(EngineCore_DP0 pid=315574) .b8 114
(EngineCore_DP0 pid=315574) .b8 99
(EngineCore_DP0 pid=315574) .b8 104
(EngineCore_DP0 pid=315574) .b8 54
(EngineCore_DP0 pid=315574) .b8 52
(EngineCore_DP0 pid=315574) .b8 0
(EngineCore_DP0 pid=315574) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=315574) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=315574) .b8 113
(EngineCore_DP0 pid=315574) .b8 117
(EngineCore_DP0 pid=315574) .b8 97
(EngineCore_DP0 pid=315574) .b8 110
(EngineCore_DP0 pid=315574) .b8 116
(EngineCore_DP0 pid=315574) .b8 95
(EngineCore_DP0 pid=315574) .b8 115
(EngineCore_DP0 pid=315574) .b8 108
(EngineCore_DP0 pid=315574) .b8 105
(EngineCore_DP0 pid=315574) .b8 100
(EngineCore_DP0 pid=315574) .b8 101
(EngineCore_DP0 pid=315574) .b8 95
(EngineCore_DP0 pid=315574) .b8 105
(EngineCore_DP0 pid=315574) .b8 110
(EngineCore_DP0 pid=315574) .b8 116
(EngineCore_DP0 pid=315574) .b8 56
(EngineCore_DP0 pid=315574) .b8 95
(EngineCore_DP0 pid=315574) .b8 107
(EngineCore_DP0 pid=315574) .b8 101
(EngineCore_DP0 pid=315574) .b8 114
(EngineCore_DP0 pid=315574) .b8 110
(EngineCore_DP0 pid=315574) .b8 101
(EngineCore_DP0 pid=315574) .b8 108
(EngineCore_DP0 pid=315574) .b8 0
(EngineCore_DP0 pid=315574) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=315574) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=315574) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=315574) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=315574) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=315574) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=315574) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=315574) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=315574) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=315574) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=315574) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=315574) .b8 1
(EngineCore_DP0 pid=315574) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=315574) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=315574) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=315574) 	}
(EngineCore_DP0 pid=315574) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=315574) 
(EngineCore_DP0 pid=315574) ================================================================
(EngineCore_DP0 pid=315574) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=315574) 
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp10m_dy16.ptx', '-o', '/tmp/tmp10m_dy16.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866] 
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866] 
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866] 
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp10m_dy16.ptx -o /tmp/tmp10m_dy16.ptx.o
(EngineCore_DP0 pid=315574) ERROR 01-25 18:59:32 [core.py:866] 

STDERR:
[2026-01-25 18:59:17] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:59:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:59:17] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:59:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:59:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:59:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:59:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:59:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:59:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:59:20] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:59:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:59:20] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:59:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:59:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:59:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:59:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:59:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:59:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=315574) [2026-01-25 18:59:21] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=315574) [2026-01-25 18:59:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=315574) [2026-01-25 18:59:21] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=315574) [2026-01-25 18:59:21] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=315574) [2026-01-25 18:59:21] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=315574) [2026-01-25 18:59:21] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=315574) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=315574) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.15s/it]
(EngineCore_DP0 pid=315574) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.15s/it]
(EngineCore_DP0 pid=315574) 
(EngineCore_DP0 pid=315574) [2026-01-25 18:59:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=315574) [2026-01-25 18:59:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=315574) [2026-01-25 18:59:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=315574) [2026-01-25 18:59:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=315574) [2026-01-25 18:59:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=315574) [2026-01-25 18:59:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=315574) [2026-01-25 18:59:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=315574) [2026-01-25 18:59:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=315574) Process EngineCore_DP0:
(EngineCore_DP0 pid=315574) Traceback (most recent call last):
(EngineCore_DP0 pid=315574)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=315574)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=315574)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=315574)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=315574) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp10m_dy16.ptx', '-o', '/tmp/tmp10m_dy16.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=315574) 
(EngineCore_DP0 pid=315574) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=315574) 
(EngineCore_DP0 pid=315574) Traceback (most recent call last):
(EngineCore_DP0 pid=315574)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=315574)     self.run()
(EngineCore_DP0 pid=315574)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=315574)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=315574)     raise e
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=315574)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=315574)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=315574)     super().__init__(
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=315574)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=315574)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=315574)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=315574)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=315574)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=315574)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=315574)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=315574)     return func(*args, **kwargs)
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=315574)     return func(*args, **kwargs)
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=315574)     self.model_runner.profile_run()
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=315574)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=315574)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=315574)     return func(*args, **kwargs)
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=315574)     outputs = self.model(
(EngineCore_DP0 pid=315574)               ^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=315574)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=315574)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=315574)     model_output = self.model(
(EngineCore_DP0 pid=315574)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=315574)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=315574)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=315574)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=315574)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=315574)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=315574)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=315574)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=315574)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=315574)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=315574)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=315574)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=315574)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=315574)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=315574)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=315574)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=315574)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=315574)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=315574)     return self._linear_fn(
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=315574)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=315574)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=315574)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=315574)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=315574)     return fn(input, L)
(EngineCore_DP0 pid=315574)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=315574)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=315574)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=315574)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=315574)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=315574)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=315574)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=315574)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=315574)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=315574)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=315574)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=315574)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=315574)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=315574)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=315574)     raise PTXASError(error)
(EngineCore_DP0 pid=315574) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=315574) `ptxas` stderr:
(EngineCore_DP0 pid=315574) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=315574) 
(EngineCore_DP0 pid=315574) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp10m_dy16.ptx -o /tmp/tmp10m_dy16.ptx.o
(EngineCore_DP0 pid=315574) 
[rank0]:[W125 18:59:32.791277229 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 18:59:34
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:59:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:59:38 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=316048) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=316048) 
(EngineCore_DP0 pid=316048) 
(EngineCore_DP0 pid=316048) ================================================================
(EngineCore_DP0 pid=316048) Internal Triton PTX codegen error
(EngineCore_DP0 pid=316048) `ptxas` stderr:
(EngineCore_DP0 pid=316048) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=316048) 
(EngineCore_DP0 pid=316048) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmprvc1dc1q.ptx -o /tmp/tmprvc1dc1q.ptx.o
(EngineCore_DP0 pid=316048) 
(EngineCore_DP0 pid=316048) 
(EngineCore_DP0 pid=316048) //
(EngineCore_DP0 pid=316048) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=316048) //
(EngineCore_DP0 pid=316048) 
(EngineCore_DP0 pid=316048) .version 8.7
(EngineCore_DP0 pid=316048) .target sm_121a
(EngineCore_DP0 pid=316048) .address_size 64
(EngineCore_DP0 pid=316048) 
(EngineCore_DP0 pid=316048) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=316048) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=316048)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=316048) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=316048) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=316048) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=316048) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=316048) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=316048) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=316048) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=316048) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=316048) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=316048) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=316048) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=316048) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=316048) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=316048) )
(EngineCore_DP0 pid=316048) .reqntid 512
(EngineCore_DP0 pid=316048) {
(EngineCore_DP0 pid=316048) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=316048) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=316048) 	.reg .b32 	%r<131>;
(EngineCore_DP0 pid=316048) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=316048) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=316048) $L__func_begin0:
(EngineCore_DP0 pid=316048) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=316048) 
(EngineCore_DP0 pid=316048) // %bb.0:
(EngineCore_DP0 pid=316048) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=316048) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=316048) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=316048) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=316048) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=316048) $L__tmp0:
(EngineCore_DP0 pid=316048) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=316048) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=316048) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=316048) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=316048) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=316048) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=316048) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=316048) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=316048) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=316048) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=316048) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=316048) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=316048) 	mov.b32 	%r129, 0f2B8CBCCC;
(EngineCore_DP0 pid=316048) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=316048) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=316048) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=316048) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=316048) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=316048) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=316048) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=316048) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=316048) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=316048) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=316048) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=316048) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=316048) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=316048) 	mov.b32 	%r127, 0f00000000;
(EngineCore_DP0 pid=316048) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=316048) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=316048) 	mov.b32 	%r128, %r40;
(EngineCore_DP0 pid=316048) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=316048) 	.loc	1 299 19                        // quant_slide_tuned_Llama3.2-1B.py:299:19
(EngineCore_DP0 pid=316048) 	add.s32 	%r58, %r4, %r128;
(EngineCore_DP0 pid=316048) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=316048) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=316048) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=316048) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=316048) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=316048) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=316048) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=316048) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=316048) 	// begin inline asm
(EngineCore_DP0 pid=316048) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=316048) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=316048) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=316048) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=316048) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=316048) 	// end inline asm
(EngineCore_DP0 pid=316048) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=316048) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=316048) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=316048) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=316048) 	// begin inline asm
(EngineCore_DP0 pid=316048) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=316048) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=316048) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=316048) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=316048) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=316048) 	// end inline asm
(EngineCore_DP0 pid=316048) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=316048) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=316048) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=316048) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=316048) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=316048) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=316048) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=316048) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=316048) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=316048) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=316048) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=316048) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=316048) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=316048) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=316048) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=316048) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=316048) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=316048) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=316048) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=316048) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=316048) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=316048) $L__tmp1:
(EngineCore_DP0 pid=316048) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	bar.sync 	0;
(EngineCore_DP0 pid=316048) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=316048) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=316048) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=316048) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=316048) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=316048) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=316048) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=316048) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=316048) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=316048) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=316048) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=316048) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=316048) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=316048) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=316048) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=316048) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=316048) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=316048) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=316048) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=316048) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=316048) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=316048) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=316048) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=316048) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=316048) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=316048) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=316048) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	// begin inline asm
(EngineCore_DP0 pid=316048) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=316048) 	// end inline asm
(EngineCore_DP0 pid=316048) 	bar.sync 	0;
(EngineCore_DP0 pid=316048) 	// begin inline asm
(EngineCore_DP0 pid=316048) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=316048) 	// end inline asm
(EngineCore_DP0 pid=316048) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=316048) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=316048) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=316048) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=316048) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=316048) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=316048) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=316048) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=316048) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316048) 	// begin inline asm
(EngineCore_DP0 pid=316048) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=316048) 	// end inline asm
(EngineCore_DP0 pid=316048) 	bar.sync 	0;
(EngineCore_DP0 pid=316048) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=316048) $L__tmp2:
(EngineCore_DP0 pid=316048) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=316048) 	max.f32 	%r127, %r127, %r77;
(EngineCore_DP0 pid=316048) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=316048) 	add.s32 	%r128, %r128, 8192;
(EngineCore_DP0 pid=316048) 	setp.lt.s32 	%p7, %r128, %r19;
(EngineCore_DP0 pid=316048) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=316048) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=316048) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=316048) 	max.f32 	%r129, %r127, 0f2B8CBCCC;
(EngineCore_DP0 pid=316048) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=316048) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=316048) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=316048) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=316048) 	div.full.f32 	%r80, %r129, %r79;
(EngineCore_DP0 pid=316048) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=316048) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=316048) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=316048) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=316048) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=316048) 	// begin inline asm
(EngineCore_DP0 pid=316048) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=316048) 	// end inline asm
(EngineCore_DP0 pid=316048) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=316048) 	shl.b32 	%r15, %r20, 1;
(EngineCore_DP0 pid=316048) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=316048) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=316048) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=316048) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=316048) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=316048) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=316048) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=316048) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=316048) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=316048) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=316048) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=316048) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=316048) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=316048) 	div.full.f32 	%r14, %r79, %r129;
(EngineCore_DP0 pid=316048) 	mov.b32 	%r130, 0;
(EngineCore_DP0 pid=316048) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=316048)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=316048) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=316048) 	add.s32 	%r84, %r3, %r130;
(EngineCore_DP0 pid=316048) 	setp.lt.s32 	%p14, %r84, %r15;
(EngineCore_DP0 pid=316048) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=316048) 	shr.u32 	%r85, %r84, 31;
(EngineCore_DP0 pid=316048) 	add.s32 	%r86, %r84, %r85;
(EngineCore_DP0 pid=316048) 	shr.u32 	%r87, %r86, 1;
(EngineCore_DP0 pid=316048) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=316048) 	and.b32 	%r88, %r86, 2147483646;
(EngineCore_DP0 pid=316048) 	sub.s32 	%r89, %r84, %r88;
(EngineCore_DP0 pid=316048) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=316048) 	shl.b32 	%r90, %r89, 1;
(EngineCore_DP0 pid=316048) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=316048) 	mad.lo.s32 	%r91, %r87, 6, %r90;
(EngineCore_DP0 pid=316048) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=316048) 	setp.lt.s32 	%p15, %r91, %r18;
(EngineCore_DP0 pid=316048) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=316048) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=316048) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=316048) 	mad.wide.s32 	%rd9, %r91, 2, %rd1;
(EngineCore_DP0 pid=316048) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=316048) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=316048) 	// begin inline asm
(EngineCore_DP0 pid=316048) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=316048) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=316048) 	// end inline asm
(EngineCore_DP0 pid=316048) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=316048) 	cvt.f32.bf16 	%r92, %rs48;
(EngineCore_DP0 pid=316048) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=316048) 	or.b32 	%r93, %r91, 1;
(EngineCore_DP0 pid=316048) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=316048) 	setp.lt.s32 	%p16, %r93, %r18;
(EngineCore_DP0 pid=316048) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=316048) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=316048) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=316048) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=316048) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=316048) 	// begin inline asm
(EngineCore_DP0 pid=316048) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=316048) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=316048) 	// end inline asm
(EngineCore_DP0 pid=316048) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=316048) 	cvt.f32.bf16 	%r94, %rs50;
(EngineCore_DP0 pid=316048) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=316048) 	add.s32 	%r95, %r91, 2;
(EngineCore_DP0 pid=316048) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=316048) 	setp.lt.s32 	%p17, %r95, %r18;
(EngineCore_DP0 pid=316048) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=316048) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=316048) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=316048) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=316048) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=316048) 	// begin inline asm
(EngineCore_DP0 pid=316048) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=316048) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=316048) 	// end inline asm
(EngineCore_DP0 pid=316048) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=316048) 	cvt.f32.bf16 	%r96, %rs52;
(EngineCore_DP0 pid=316048) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=316048) 	add.s32 	%r97, %r91, 3;
(EngineCore_DP0 pid=316048) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=316048) 	setp.lt.s32 	%p18, %r97, %r18;
(EngineCore_DP0 pid=316048) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=316048) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=316048) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=316048) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=316048) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=316048) 	// begin inline asm
(EngineCore_DP0 pid=316048) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=316048) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=316048) 	// end inline asm
(EngineCore_DP0 pid=316048) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=316048) 	cvt.f32.bf16 	%r98, %rs54;
(EngineCore_DP0 pid=316048) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=316048) 	mul.f32 	%r99, %r14, %r92;
(EngineCore_DP0 pid=316048) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=316048) 	cvt.rni.f32.f32 	%r100, %r99;
(EngineCore_DP0 pid=316048) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=316048) 	max.f32 	%r101, %r100, 0fC3000000;
(EngineCore_DP0 pid=316048) 	min.f32 	%r102, %r101, 0f42FE0000;
(EngineCore_DP0 pid=316048) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=316048) 	cvt.rzi.s32.f32 	%r103, %r102;
(EngineCore_DP0 pid=316048) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=316048) 	and.b32 	%r104, %r103, 255;
(EngineCore_DP0 pid=316048) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=316048) 	mul.f32 	%r105, %r14, %r94;
(EngineCore_DP0 pid=316048) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=316048) 	cvt.rni.f32.f32 	%r106, %r105;
(EngineCore_DP0 pid=316048) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=316048) 	mul.f32 	%r107, %r14, %r96;
(EngineCore_DP0 pid=316048) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=316048) 	cvt.rni.f32.f32 	%r108, %r107;
(EngineCore_DP0 pid=316048) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=316048) 	mul.f32 	%r109, %r14, %r98;
(EngineCore_DP0 pid=316048) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=316048) 	cvt.rni.f32.f32 	%r110, %r109;
(EngineCore_DP0 pid=316048) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=316048) 	max.f32 	%r111, %r110, 0fC3000000;
(EngineCore_DP0 pid=316048) 	min.f32 	%r112, %r111, 0f42FE0000;
(EngineCore_DP0 pid=316048) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=316048) 	cvt.rzi.s32.f32 	%r113, %r112;
(EngineCore_DP0 pid=316048) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=316048) 	max.f32 	%r114, %r108, 0fC3000000;
(EngineCore_DP0 pid=316048) 	max.f32 	%r115, %r106, 0fC3000000;
(EngineCore_DP0 pid=316048) 	min.f32 	%r116, %r115, 0f42FE0000;
(EngineCore_DP0 pid=316048) 	min.f32 	%r117, %r114, 0f42FE0000;
(EngineCore_DP0 pid=316048) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=316048) 	cvt.rzi.s32.f32 	%r118, %r117;
(EngineCore_DP0 pid=316048) 	cvt.rzi.s32.f32 	%r119, %r116;
(EngineCore_DP0 pid=316048) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=316048) 	shl.b32 	%r120, %r119, 8;
(EngineCore_DP0 pid=316048) 	shl.b32 	%r121, %r118, 16;
(EngineCore_DP0 pid=316048) 	and.b32 	%r122, %r121, 16711680;
(EngineCore_DP0 pid=316048) 	and.b32 	%r123, %r120, 65280;
(EngineCore_DP0 pid=316048) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=316048) 	or.b32 	%r124, %r123, %r104;
(EngineCore_DP0 pid=316048) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=316048) 	or.b32 	%r125, %r124, %r122;
(EngineCore_DP0 pid=316048) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=316048) 	shl.b32 	%r126, %r113, 24;
(EngineCore_DP0 pid=316048) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=316048) 	or.b32 	%r82, %r125, %r126;
(EngineCore_DP0 pid=316048) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=316048) 	mad.wide.s32 	%rd13, %r84, 4, %rd2;
(EngineCore_DP0 pid=316048) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=316048) 	// begin inline asm
(EngineCore_DP0 pid=316048) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r82 };
(EngineCore_DP0 pid=316048) 	// end inline asm
(EngineCore_DP0 pid=316048) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=316048) 	add.s32 	%r130, %r130, 512;
(EngineCore_DP0 pid=316048) 	setp.lt.s32 	%p19, %r130, %r15;
(EngineCore_DP0 pid=316048) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=316048) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=316048) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=316048) 	ret;
(EngineCore_DP0 pid=316048) $L__tmp3:
(EngineCore_DP0 pid=316048) $L__func_end0:
(EngineCore_DP0 pid=316048)                                         // -- End function
(EngineCore_DP0 pid=316048) }
(EngineCore_DP0 pid=316048) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=316048) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=316048) 	.section	.debug_abbrev
(EngineCore_DP0 pid=316048) 	{
(EngineCore_DP0 pid=316048) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=316048) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=316048) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=316048) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=316048) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=316048) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=316048) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=316048) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=316048) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=316048) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=316048) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=316048) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=316048) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=316048) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=316048) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=316048) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=316048) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=316048) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=316048) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=316048) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=316048) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=316048) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=316048) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=316048) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=316048) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=316048) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=316048) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=316048) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=316048) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=316048) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=316048) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=316048) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=316048) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=316048) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=316048) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=316048) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=316048) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=316048) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=316048) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=316048) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=316048) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=316048) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=316048) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=316048) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=316048) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=316048) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=316048) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=316048) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=316048) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=316048) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=316048) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=316048) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=316048) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=316048) 	}
(EngineCore_DP0 pid=316048) 	.section	.debug_info
(EngineCore_DP0 pid=316048) 	{
(EngineCore_DP0 pid=316048) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=316048) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=316048) .b8 0
(EngineCore_DP0 pid=316048) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=316048) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=316048) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=316048) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=316048) .b8 114
(EngineCore_DP0 pid=316048) .b8 105
(EngineCore_DP0 pid=316048) .b8 116
(EngineCore_DP0 pid=316048) .b8 111
(EngineCore_DP0 pid=316048) .b8 110
(EngineCore_DP0 pid=316048) .b8 0
(EngineCore_DP0 pid=316048) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=316048) .b8 0
(EngineCore_DP0 pid=316048) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=316048) .b8 117
(EngineCore_DP0 pid=316048) .b8 97
(EngineCore_DP0 pid=316048) .b8 110
(EngineCore_DP0 pid=316048) .b8 116
(EngineCore_DP0 pid=316048) .b8 95
(EngineCore_DP0 pid=316048) .b8 115
(EngineCore_DP0 pid=316048) .b8 108
(EngineCore_DP0 pid=316048) .b8 105
(EngineCore_DP0 pid=316048) .b8 100
(EngineCore_DP0 pid=316048) .b8 101
(EngineCore_DP0 pid=316048) .b8 95
(EngineCore_DP0 pid=316048) .b8 116
(EngineCore_DP0 pid=316048) .b8 117
(EngineCore_DP0 pid=316048) .b8 110
(EngineCore_DP0 pid=316048) .b8 101
(EngineCore_DP0 pid=316048) .b8 100
(EngineCore_DP0 pid=316048) .b8 95
(EngineCore_DP0 pid=316048) .b8 76
(EngineCore_DP0 pid=316048) .b8 108
(EngineCore_DP0 pid=316048) .b8 97
(EngineCore_DP0 pid=316048) .b8 109
(EngineCore_DP0 pid=316048) .b8 97
(EngineCore_DP0 pid=316048) .b8 51
(EngineCore_DP0 pid=316048) .b8 46
(EngineCore_DP0 pid=316048) .b8 50
(EngineCore_DP0 pid=316048) .b8 45
(EngineCore_DP0 pid=316048) .b8 49
(EngineCore_DP0 pid=316048) .b8 66
(EngineCore_DP0 pid=316048) .b8 46
(EngineCore_DP0 pid=316048) .b8 112
(EngineCore_DP0 pid=316048) .b8 121
(EngineCore_DP0 pid=316048) .b8 0
(EngineCore_DP0 pid=316048) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=316048) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=316048) .b8 114
(EngineCore_DP0 pid=316048) .b8 111
(EngineCore_DP0 pid=316048) .b8 111
(EngineCore_DP0 pid=316048) .b8 116
(EngineCore_DP0 pid=316048) .b8 47
(EngineCore_DP0 pid=316048) .b8 118
(EngineCore_DP0 pid=316048) .b8 108
(EngineCore_DP0 pid=316048) .b8 108
(EngineCore_DP0 pid=316048) .b8 109
(EngineCore_DP0 pid=316048) .b8 98
(EngineCore_DP0 pid=316048) .b8 101
(EngineCore_DP0 pid=316048) .b8 110
(EngineCore_DP0 pid=316048) .b8 99
(EngineCore_DP0 pid=316048) .b8 104
(EngineCore_DP0 pid=316048) .b8 47
(EngineCore_DP0 pid=316048) .b8 115
(EngineCore_DP0 pid=316048) .b8 108
(EngineCore_DP0 pid=316048) .b8 105
(EngineCore_DP0 pid=316048) .b8 100
(EngineCore_DP0 pid=316048) .b8 101
(EngineCore_DP0 pid=316048) .b8 115
(EngineCore_DP0 pid=316048) .b8 112
(EngineCore_DP0 pid=316048) .b8 97
(EngineCore_DP0 pid=316048) .b8 114
(EngineCore_DP0 pid=316048) .b8 115
(EngineCore_DP0 pid=316048) .b8 101
(EngineCore_DP0 pid=316048) .b8 47
(EngineCore_DP0 pid=316048) .b8 99
(EngineCore_DP0 pid=316048) .b8 115
(EngineCore_DP0 pid=316048) .b8 114
(EngineCore_DP0 pid=316048) .b8 99
(EngineCore_DP0 pid=316048) .b8 47
(EngineCore_DP0 pid=316048) .b8 102
(EngineCore_DP0 pid=316048) .b8 117
(EngineCore_DP0 pid=316048) .b8 115
(EngineCore_DP0 pid=316048) .b8 101
(EngineCore_DP0 pid=316048) .b8 100
(EngineCore_DP0 pid=316048) .b8 95
(EngineCore_DP0 pid=316048) .b8 113
(EngineCore_DP0 pid=316048) .b8 117
(EngineCore_DP0 pid=316048) .b8 97
(EngineCore_DP0 pid=316048) .b8 110
(EngineCore_DP0 pid=316048) .b8 116
(EngineCore_DP0 pid=316048) .b8 95
(EngineCore_DP0 pid=316048) .b8 115
(EngineCore_DP0 pid=316048) .b8 108
(EngineCore_DP0 pid=316048) .b8 105
(EngineCore_DP0 pid=316048) .b8 100
(EngineCore_DP0 pid=316048) .b8 101
(EngineCore_DP0 pid=316048) .b8 95
(EngineCore_DP0 pid=316048) .b8 116
(EngineCore_DP0 pid=316048) .b8 114
(EngineCore_DP0 pid=316048) .b8 105
(EngineCore_DP0 pid=316048) .b8 116
(EngineCore_DP0 pid=316048) .b8 111
(EngineCore_DP0 pid=316048) .b8 110
(EngineCore_DP0 pid=316048) .b8 47
(EngineCore_DP0 pid=316048) .b8 98
(EngineCore_DP0 pid=316048) .b8 117
(EngineCore_DP0 pid=316048) .b8 105
(EngineCore_DP0 pid=316048) .b8 108
(EngineCore_DP0 pid=316048) .b8 100
(EngineCore_DP0 pid=316048) .b8 47
(EngineCore_DP0 pid=316048) .b8 71
(EngineCore_DP0 pid=316048) .b8 66
(EngineCore_DP0 pid=316048) .b8 49
(EngineCore_DP0 pid=316048) .b8 48
(EngineCore_DP0 pid=316048) .b8 95
(EngineCore_DP0 pid=316048) .b8 99
(EngineCore_DP0 pid=316048) .b8 99
(EngineCore_DP0 pid=316048) .b8 49
(EngineCore_DP0 pid=316048) .b8 50
(EngineCore_DP0 pid=316048) .b8 49
(EngineCore_DP0 pid=316048) .b8 95
(EngineCore_DP0 pid=316048) .b8 112
(EngineCore_DP0 pid=316048) .b8 121
(EngineCore_DP0 pid=316048) .b8 51
(EngineCore_DP0 pid=316048) .b8 49
(EngineCore_DP0 pid=316048) .b8 50
(EngineCore_DP0 pid=316048) .b8 95
(EngineCore_DP0 pid=316048) .b8 99
(EngineCore_DP0 pid=316048) .b8 117
(EngineCore_DP0 pid=316048) .b8 49
(EngineCore_DP0 pid=316048) .b8 50
(EngineCore_DP0 pid=316048) .b8 57
(EngineCore_DP0 pid=316048) .b8 95
(EngineCore_DP0 pid=316048) .b8 97
(EngineCore_DP0 pid=316048) .b8 97
(EngineCore_DP0 pid=316048) .b8 114
(EngineCore_DP0 pid=316048) .b8 99
(EngineCore_DP0 pid=316048) .b8 104
(EngineCore_DP0 pid=316048) .b8 54
(EngineCore_DP0 pid=316048) .b8 52
(EngineCore_DP0 pid=316048) .b8 0
(EngineCore_DP0 pid=316048) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=316048) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=316048) .b8 113
(EngineCore_DP0 pid=316048) .b8 117
(EngineCore_DP0 pid=316048) .b8 97
(EngineCore_DP0 pid=316048) .b8 110
(EngineCore_DP0 pid=316048) .b8 116
(EngineCore_DP0 pid=316048) .b8 95
(EngineCore_DP0 pid=316048) .b8 115
(EngineCore_DP0 pid=316048) .b8 108
(EngineCore_DP0 pid=316048) .b8 105
(EngineCore_DP0 pid=316048) .b8 100
(EngineCore_DP0 pid=316048) .b8 101
(EngineCore_DP0 pid=316048) .b8 95
(EngineCore_DP0 pid=316048) .b8 105
(EngineCore_DP0 pid=316048) .b8 110
(EngineCore_DP0 pid=316048) .b8 116
(EngineCore_DP0 pid=316048) .b8 56
(EngineCore_DP0 pid=316048) .b8 95
(EngineCore_DP0 pid=316048) .b8 107
(EngineCore_DP0 pid=316048) .b8 101
(EngineCore_DP0 pid=316048) .b8 114
(EngineCore_DP0 pid=316048) .b8 110
(EngineCore_DP0 pid=316048) .b8 101
(EngineCore_DP0 pid=316048) .b8 108
(EngineCore_DP0 pid=316048) .b8 0
(EngineCore_DP0 pid=316048) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=316048) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=316048) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=316048) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=316048) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=316048) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=316048) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=316048) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=316048) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=316048) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=316048) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=316048) .b8 1
(EngineCore_DP0 pid=316048) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=316048) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=316048) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=316048) 	}
(EngineCore_DP0 pid=316048) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=316048) 
(EngineCore_DP0 pid=316048) ================================================================
(EngineCore_DP0 pid=316048) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=316048) 
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmprvc1dc1q.ptx', '-o', '/tmp/tmprvc1dc1q.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866] 
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866] 
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866] 
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmprvc1dc1q.ptx -o /tmp/tmprvc1dc1q.ptx.o
(EngineCore_DP0 pid=316048) ERROR 01-25 18:59:53 [core.py:866] 

STDERR:
[2026-01-25 18:59:38] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:59:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:59:38] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:59:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:59:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:59:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:59:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:59:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:59:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:59:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:59:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:59:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:59:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:59:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:59:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:59:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:59:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:59:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:59:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=316048) [2026-01-25 18:59:42] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=316048) [2026-01-25 18:59:42] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=316048) [2026-01-25 18:59:42] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=316048) [2026-01-25 18:59:42] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=316048) [2026-01-25 18:59:42] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=316048) [2026-01-25 18:59:42] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=316048) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=316048) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.24s/it]
(EngineCore_DP0 pid=316048) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.24s/it]
(EngineCore_DP0 pid=316048) 
(EngineCore_DP0 pid=316048) [2026-01-25 18:59:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=316048) [2026-01-25 18:59:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=316048) [2026-01-25 18:59:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=316048) [2026-01-25 18:59:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=316048) [2026-01-25 18:59:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=316048) [2026-01-25 18:59:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=316048) [2026-01-25 18:59:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=316048) [2026-01-25 18:59:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=316048) Process EngineCore_DP0:
(EngineCore_DP0 pid=316048) Traceback (most recent call last):
(EngineCore_DP0 pid=316048)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=316048)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=316048)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=316048)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=316048) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmprvc1dc1q.ptx', '-o', '/tmp/tmprvc1dc1q.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=316048) 
(EngineCore_DP0 pid=316048) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=316048) 
(EngineCore_DP0 pid=316048) Traceback (most recent call last):
(EngineCore_DP0 pid=316048)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=316048)     self.run()
(EngineCore_DP0 pid=316048)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=316048)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=316048)     raise e
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=316048)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=316048)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=316048)     super().__init__(
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=316048)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=316048)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=316048)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=316048)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=316048)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=316048)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=316048)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=316048)     return func(*args, **kwargs)
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=316048)     return func(*args, **kwargs)
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=316048)     self.model_runner.profile_run()
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=316048)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=316048)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=316048)     return func(*args, **kwargs)
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=316048)     outputs = self.model(
(EngineCore_DP0 pid=316048)               ^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=316048)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=316048)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=316048)     model_output = self.model(
(EngineCore_DP0 pid=316048)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=316048)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=316048)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=316048)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=316048)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=316048)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=316048)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=316048)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=316048)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=316048)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=316048)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=316048)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=316048)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=316048)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=316048)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=316048)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=316048)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=316048)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=316048)     return self._linear_fn(
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=316048)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=316048)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=316048)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=316048)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=316048)     return fn(input, L)
(EngineCore_DP0 pid=316048)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=316048)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=316048)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=316048)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=316048)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=316048)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=316048)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=316048)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=316048)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=316048)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=316048)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=316048)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=316048)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316048)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=316048)     raise PTXASError(error)
(EngineCore_DP0 pid=316048) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=316048) `ptxas` stderr:
(EngineCore_DP0 pid=316048) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=316048) 
(EngineCore_DP0 pid=316048) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmprvc1dc1q.ptx -o /tmp/tmprvc1dc1q.ptx.o
(EngineCore_DP0 pid=316048) 
[rank0]:[W125 18:59:53.987131548 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 18:59:55
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:00:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:00:00 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=316526) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=316526) 
(EngineCore_DP0 pid=316526) 
(EngineCore_DP0 pid=316526) ================================================================
(EngineCore_DP0 pid=316526) Internal Triton PTX codegen error
(EngineCore_DP0 pid=316526) `ptxas` stderr:
(EngineCore_DP0 pid=316526) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=316526) 
(EngineCore_DP0 pid=316526) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpyjcwn_om.ptx -o /tmp/tmpyjcwn_om.ptx.o
(EngineCore_DP0 pid=316526) 
(EngineCore_DP0 pid=316526) 
(EngineCore_DP0 pid=316526) //
(EngineCore_DP0 pid=316526) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=316526) //
(EngineCore_DP0 pid=316526) 
(EngineCore_DP0 pid=316526) .version 8.7
(EngineCore_DP0 pid=316526) .target sm_121a
(EngineCore_DP0 pid=316526) .address_size 64
(EngineCore_DP0 pid=316526) 
(EngineCore_DP0 pid=316526) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=316526) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=316526)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=316526) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=316526) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=316526) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=316526) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=316526) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=316526) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=316526) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=316526) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=316526) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=316526) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=316526) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=316526) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=316526) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=316526) )
(EngineCore_DP0 pid=316526) .reqntid 512
(EngineCore_DP0 pid=316526) {
(EngineCore_DP0 pid=316526) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=316526) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=316526) 	.reg .b32 	%r<131>;
(EngineCore_DP0 pid=316526) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=316526) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=316526) $L__func_begin0:
(EngineCore_DP0 pid=316526) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=316526) 
(EngineCore_DP0 pid=316526) // %bb.0:
(EngineCore_DP0 pid=316526) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=316526) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=316526) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=316526) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=316526) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=316526) $L__tmp0:
(EngineCore_DP0 pid=316526) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=316526) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=316526) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=316526) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=316526) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=316526) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=316526) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=316526) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=316526) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=316526) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=316526) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=316526) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=316526) 	mov.b32 	%r129, 0f2B8CBCCC;
(EngineCore_DP0 pid=316526) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=316526) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=316526) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=316526) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=316526) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=316526) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=316526) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=316526) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=316526) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=316526) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=316526) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=316526) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=316526) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=316526) 	mov.b32 	%r127, 0f00000000;
(EngineCore_DP0 pid=316526) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=316526) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=316526) 	mov.b32 	%r128, %r40;
(EngineCore_DP0 pid=316526) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=316526) 	.loc	1 299 19                        // quant_slide_tuned_Llama3.2-1B.py:299:19
(EngineCore_DP0 pid=316526) 	add.s32 	%r58, %r4, %r128;
(EngineCore_DP0 pid=316526) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=316526) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=316526) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=316526) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=316526) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=316526) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=316526) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=316526) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=316526) 	// begin inline asm
(EngineCore_DP0 pid=316526) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=316526) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=316526) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=316526) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=316526) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=316526) 	// end inline asm
(EngineCore_DP0 pid=316526) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=316526) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=316526) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=316526) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=316526) 	// begin inline asm
(EngineCore_DP0 pid=316526) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=316526) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=316526) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=316526) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=316526) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=316526) 	// end inline asm
(EngineCore_DP0 pid=316526) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=316526) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=316526) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=316526) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=316526) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=316526) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=316526) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=316526) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=316526) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=316526) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=316526) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=316526) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=316526) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=316526) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=316526) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=316526) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=316526) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=316526) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=316526) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=316526) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=316526) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=316526) $L__tmp1:
(EngineCore_DP0 pid=316526) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	bar.sync 	0;
(EngineCore_DP0 pid=316526) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=316526) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=316526) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=316526) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=316526) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=316526) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=316526) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=316526) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=316526) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=316526) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=316526) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=316526) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=316526) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=316526) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=316526) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=316526) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=316526) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=316526) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=316526) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=316526) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=316526) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=316526) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=316526) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=316526) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=316526) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=316526) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=316526) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	// begin inline asm
(EngineCore_DP0 pid=316526) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=316526) 	// end inline asm
(EngineCore_DP0 pid=316526) 	bar.sync 	0;
(EngineCore_DP0 pid=316526) 	// begin inline asm
(EngineCore_DP0 pid=316526) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=316526) 	// end inline asm
(EngineCore_DP0 pid=316526) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=316526) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=316526) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=316526) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=316526) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=316526) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=316526) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=316526) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=316526) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=316526) 	// begin inline asm
(EngineCore_DP0 pid=316526) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=316526) 	// end inline asm
(EngineCore_DP0 pid=316526) 	bar.sync 	0;
(EngineCore_DP0 pid=316526) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=316526) $L__tmp2:
(EngineCore_DP0 pid=316526) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=316526) 	max.f32 	%r127, %r127, %r77;
(EngineCore_DP0 pid=316526) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=316526) 	add.s32 	%r128, %r128, 8192;
(EngineCore_DP0 pid=316526) 	setp.lt.s32 	%p7, %r128, %r19;
(EngineCore_DP0 pid=316526) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=316526) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=316526) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=316526) 	max.f32 	%r129, %r127, 0f2B8CBCCC;
(EngineCore_DP0 pid=316526) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=316526) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=316526) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=316526) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=316526) 	div.full.f32 	%r80, %r129, %r79;
(EngineCore_DP0 pid=316526) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=316526) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=316526) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=316526) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=316526) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=316526) 	// begin inline asm
(EngineCore_DP0 pid=316526) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=316526) 	// end inline asm
(EngineCore_DP0 pid=316526) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=316526) 	shl.b32 	%r15, %r20, 1;
(EngineCore_DP0 pid=316526) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=316526) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=316526) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=316526) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=316526) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=316526) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=316526) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=316526) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=316526) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=316526) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=316526) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=316526) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=316526) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=316526) 	div.full.f32 	%r14, %r79, %r129;
(EngineCore_DP0 pid=316526) 	mov.b32 	%r130, 0;
(EngineCore_DP0 pid=316526) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=316526)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=316526) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=316526) 	add.s32 	%r84, %r3, %r130;
(EngineCore_DP0 pid=316526) 	setp.lt.s32 	%p14, %r84, %r15;
(EngineCore_DP0 pid=316526) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=316526) 	shr.u32 	%r85, %r84, 31;
(EngineCore_DP0 pid=316526) 	add.s32 	%r86, %r84, %r85;
(EngineCore_DP0 pid=316526) 	shr.u32 	%r87, %r86, 1;
(EngineCore_DP0 pid=316526) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=316526) 	and.b32 	%r88, %r86, 2147483646;
(EngineCore_DP0 pid=316526) 	sub.s32 	%r89, %r84, %r88;
(EngineCore_DP0 pid=316526) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=316526) 	shl.b32 	%r90, %r89, 1;
(EngineCore_DP0 pid=316526) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=316526) 	mad.lo.s32 	%r91, %r87, 6, %r90;
(EngineCore_DP0 pid=316526) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=316526) 	setp.lt.s32 	%p15, %r91, %r18;
(EngineCore_DP0 pid=316526) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=316526) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=316526) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=316526) 	mad.wide.s32 	%rd9, %r91, 2, %rd1;
(EngineCore_DP0 pid=316526) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=316526) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=316526) 	// begin inline asm
(EngineCore_DP0 pid=316526) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=316526) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=316526) 	// end inline asm
(EngineCore_DP0 pid=316526) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=316526) 	cvt.f32.bf16 	%r92, %rs48;
(EngineCore_DP0 pid=316526) 	.loc	1 324 48                        // quant_slide_tuned_Llama3.2-1B.py:324:48
(EngineCore_DP0 pid=316526) 	or.b32 	%r93, %r91, 1;
(EngineCore_DP0 pid=316526) 	.loc	1 324 53                        // quant_slide_tuned_Llama3.2-1B.py:324:53
(EngineCore_DP0 pid=316526) 	setp.lt.s32 	%p16, %r93, %r18;
(EngineCore_DP0 pid=316526) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=316526) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=316526) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=316526) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=316526) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=316526) 	// begin inline asm
(EngineCore_DP0 pid=316526) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=316526) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=316526) 	// end inline asm
(EngineCore_DP0 pid=316526) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=316526) 	cvt.f32.bf16 	%r94, %rs50;
(EngineCore_DP0 pid=316526) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=316526) 	add.s32 	%r95, %r91, 2;
(EngineCore_DP0 pid=316526) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=316526) 	setp.lt.s32 	%p17, %r95, %r18;
(EngineCore_DP0 pid=316526) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=316526) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=316526) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=316526) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=316526) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=316526) 	// begin inline asm
(EngineCore_DP0 pid=316526) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=316526) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=316526) 	// end inline asm
(EngineCore_DP0 pid=316526) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=316526) 	cvt.f32.bf16 	%r96, %rs52;
(EngineCore_DP0 pid=316526) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=316526) 	add.s32 	%r97, %r91, 3;
(EngineCore_DP0 pid=316526) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=316526) 	setp.lt.s32 	%p18, %r97, %r18;
(EngineCore_DP0 pid=316526) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=316526) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=316526) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=316526) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=316526) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=316526) 	// begin inline asm
(EngineCore_DP0 pid=316526) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=316526) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=316526) 	// end inline asm
(EngineCore_DP0 pid=316526) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=316526) 	cvt.f32.bf16 	%r98, %rs54;
(EngineCore_DP0 pid=316526) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=316526) 	mul.f32 	%r99, %r14, %r92;
(EngineCore_DP0 pid=316526) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=316526) 	cvt.rni.f32.f32 	%r100, %r99;
(EngineCore_DP0 pid=316526) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=316526) 	max.f32 	%r101, %r100, 0fC3000000;
(EngineCore_DP0 pid=316526) 	min.f32 	%r102, %r101, 0f42FE0000;
(EngineCore_DP0 pid=316526) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=316526) 	cvt.rzi.s32.f32 	%r103, %r102;
(EngineCore_DP0 pid=316526) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=316526) 	and.b32 	%r104, %r103, 255;
(EngineCore_DP0 pid=316526) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=316526) 	mul.f32 	%r105, %r14, %r94;
(EngineCore_DP0 pid=316526) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=316526) 	cvt.rni.f32.f32 	%r106, %r105;
(EngineCore_DP0 pid=316526) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=316526) 	mul.f32 	%r107, %r14, %r96;
(EngineCore_DP0 pid=316526) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=316526) 	cvt.rni.f32.f32 	%r108, %r107;
(EngineCore_DP0 pid=316526) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=316526) 	mul.f32 	%r109, %r14, %r98;
(EngineCore_DP0 pid=316526) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=316526) 	cvt.rni.f32.f32 	%r110, %r109;
(EngineCore_DP0 pid=316526) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=316526) 	max.f32 	%r111, %r110, 0fC3000000;
(EngineCore_DP0 pid=316526) 	min.f32 	%r112, %r111, 0f42FE0000;
(EngineCore_DP0 pid=316526) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=316526) 	cvt.rzi.s32.f32 	%r113, %r112;
(EngineCore_DP0 pid=316526) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=316526) 	max.f32 	%r114, %r108, 0fC3000000;
(EngineCore_DP0 pid=316526) 	max.f32 	%r115, %r106, 0fC3000000;
(EngineCore_DP0 pid=316526) 	min.f32 	%r116, %r115, 0f42FE0000;
(EngineCore_DP0 pid=316526) 	min.f32 	%r117, %r114, 0f42FE0000;
(EngineCore_DP0 pid=316526) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=316526) 	cvt.rzi.s32.f32 	%r118, %r117;
(EngineCore_DP0 pid=316526) 	cvt.rzi.s32.f32 	%r119, %r116;
(EngineCore_DP0 pid=316526) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=316526) 	shl.b32 	%r120, %r119, 8;
(EngineCore_DP0 pid=316526) 	shl.b32 	%r121, %r118, 16;
(EngineCore_DP0 pid=316526) 	and.b32 	%r122, %r121, 16711680;
(EngineCore_DP0 pid=316526) 	and.b32 	%r123, %r120, 65280;
(EngineCore_DP0 pid=316526) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=316526) 	or.b32 	%r124, %r123, %r104;
(EngineCore_DP0 pid=316526) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=316526) 	or.b32 	%r125, %r124, %r122;
(EngineCore_DP0 pid=316526) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=316526) 	shl.b32 	%r126, %r113, 24;
(EngineCore_DP0 pid=316526) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=316526) 	or.b32 	%r82, %r125, %r126;
(EngineCore_DP0 pid=316526) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=316526) 	mad.wide.s32 	%rd13, %r84, 4, %rd2;
(EngineCore_DP0 pid=316526) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=316526) 	// begin inline asm
(EngineCore_DP0 pid=316526) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r82 };
(EngineCore_DP0 pid=316526) 	// end inline asm
(EngineCore_DP0 pid=316526) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=316526) 	add.s32 	%r130, %r130, 512;
(EngineCore_DP0 pid=316526) 	setp.lt.s32 	%p19, %r130, %r15;
(EngineCore_DP0 pid=316526) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=316526) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=316526) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=316526) 	ret;
(EngineCore_DP0 pid=316526) $L__tmp3:
(EngineCore_DP0 pid=316526) $L__func_end0:
(EngineCore_DP0 pid=316526)                                         // -- End function
(EngineCore_DP0 pid=316526) }
(EngineCore_DP0 pid=316526) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=316526) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=316526) 	.section	.debug_abbrev
(EngineCore_DP0 pid=316526) 	{
(EngineCore_DP0 pid=316526) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=316526) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=316526) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=316526) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=316526) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=316526) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=316526) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=316526) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=316526) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=316526) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=316526) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=316526) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=316526) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=316526) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=316526) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=316526) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=316526) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=316526) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=316526) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=316526) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=316526) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=316526) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=316526) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=316526) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=316526) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=316526) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=316526) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=316526) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=316526) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=316526) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=316526) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=316526) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=316526) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=316526) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=316526) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=316526) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=316526) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=316526) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=316526) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=316526) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=316526) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=316526) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=316526) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=316526) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=316526) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=316526) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=316526) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=316526) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=316526) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=316526) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=316526) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=316526) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=316526) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=316526) 	}
(EngineCore_DP0 pid=316526) 	.section	.debug_info
(EngineCore_DP0 pid=316526) 	{
(EngineCore_DP0 pid=316526) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=316526) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=316526) .b8 0
(EngineCore_DP0 pid=316526) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=316526) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=316526) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=316526) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=316526) .b8 114
(EngineCore_DP0 pid=316526) .b8 105
(EngineCore_DP0 pid=316526) .b8 116
(EngineCore_DP0 pid=316526) .b8 111
(EngineCore_DP0 pid=316526) .b8 110
(EngineCore_DP0 pid=316526) .b8 0
(EngineCore_DP0 pid=316526) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=316526) .b8 0
(EngineCore_DP0 pid=316526) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=316526) .b8 117
(EngineCore_DP0 pid=316526) .b8 97
(EngineCore_DP0 pid=316526) .b8 110
(EngineCore_DP0 pid=316526) .b8 116
(EngineCore_DP0 pid=316526) .b8 95
(EngineCore_DP0 pid=316526) .b8 115
(EngineCore_DP0 pid=316526) .b8 108
(EngineCore_DP0 pid=316526) .b8 105
(EngineCore_DP0 pid=316526) .b8 100
(EngineCore_DP0 pid=316526) .b8 101
(EngineCore_DP0 pid=316526) .b8 95
(EngineCore_DP0 pid=316526) .b8 116
(EngineCore_DP0 pid=316526) .b8 117
(EngineCore_DP0 pid=316526) .b8 110
(EngineCore_DP0 pid=316526) .b8 101
(EngineCore_DP0 pid=316526) .b8 100
(EngineCore_DP0 pid=316526) .b8 95
(EngineCore_DP0 pid=316526) .b8 76
(EngineCore_DP0 pid=316526) .b8 108
(EngineCore_DP0 pid=316526) .b8 97
(EngineCore_DP0 pid=316526) .b8 109
(EngineCore_DP0 pid=316526) .b8 97
(EngineCore_DP0 pid=316526) .b8 51
(EngineCore_DP0 pid=316526) .b8 46
(EngineCore_DP0 pid=316526) .b8 50
(EngineCore_DP0 pid=316526) .b8 45
(EngineCore_DP0 pid=316526) .b8 49
(EngineCore_DP0 pid=316526) .b8 66
(EngineCore_DP0 pid=316526) .b8 46
(EngineCore_DP0 pid=316526) .b8 112
(EngineCore_DP0 pid=316526) .b8 121
(EngineCore_DP0 pid=316526) .b8 0
(EngineCore_DP0 pid=316526) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=316526) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=316526) .b8 114
(EngineCore_DP0 pid=316526) .b8 111
(EngineCore_DP0 pid=316526) .b8 111
(EngineCore_DP0 pid=316526) .b8 116
(EngineCore_DP0 pid=316526) .b8 47
(EngineCore_DP0 pid=316526) .b8 118
(EngineCore_DP0 pid=316526) .b8 108
(EngineCore_DP0 pid=316526) .b8 108
(EngineCore_DP0 pid=316526) .b8 109
(EngineCore_DP0 pid=316526) .b8 98
(EngineCore_DP0 pid=316526) .b8 101
(EngineCore_DP0 pid=316526) .b8 110
(EngineCore_DP0 pid=316526) .b8 99
(EngineCore_DP0 pid=316526) .b8 104
(EngineCore_DP0 pid=316526) .b8 47
(EngineCore_DP0 pid=316526) .b8 115
(EngineCore_DP0 pid=316526) .b8 108
(EngineCore_DP0 pid=316526) .b8 105
(EngineCore_DP0 pid=316526) .b8 100
(EngineCore_DP0 pid=316526) .b8 101
(EngineCore_DP0 pid=316526) .b8 115
(EngineCore_DP0 pid=316526) .b8 112
(EngineCore_DP0 pid=316526) .b8 97
(EngineCore_DP0 pid=316526) .b8 114
(EngineCore_DP0 pid=316526) .b8 115
(EngineCore_DP0 pid=316526) .b8 101
(EngineCore_DP0 pid=316526) .b8 47
(EngineCore_DP0 pid=316526) .b8 99
(EngineCore_DP0 pid=316526) .b8 115
(EngineCore_DP0 pid=316526) .b8 114
(EngineCore_DP0 pid=316526) .b8 99
(EngineCore_DP0 pid=316526) .b8 47
(EngineCore_DP0 pid=316526) .b8 102
(EngineCore_DP0 pid=316526) .b8 117
(EngineCore_DP0 pid=316526) .b8 115
(EngineCore_DP0 pid=316526) .b8 101
(EngineCore_DP0 pid=316526) .b8 100
(EngineCore_DP0 pid=316526) .b8 95
(EngineCore_DP0 pid=316526) .b8 113
(EngineCore_DP0 pid=316526) .b8 117
(EngineCore_DP0 pid=316526) .b8 97
(EngineCore_DP0 pid=316526) .b8 110
(EngineCore_DP0 pid=316526) .b8 116
(EngineCore_DP0 pid=316526) .b8 95
(EngineCore_DP0 pid=316526) .b8 115
(EngineCore_DP0 pid=316526) .b8 108
(EngineCore_DP0 pid=316526) .b8 105
(EngineCore_DP0 pid=316526) .b8 100
(EngineCore_DP0 pid=316526) .b8 101
(EngineCore_DP0 pid=316526) .b8 95
(EngineCore_DP0 pid=316526) .b8 116
(EngineCore_DP0 pid=316526) .b8 114
(EngineCore_DP0 pid=316526) .b8 105
(EngineCore_DP0 pid=316526) .b8 116
(EngineCore_DP0 pid=316526) .b8 111
(EngineCore_DP0 pid=316526) .b8 110
(EngineCore_DP0 pid=316526) .b8 47
(EngineCore_DP0 pid=316526) .b8 98
(EngineCore_DP0 pid=316526) .b8 117
(EngineCore_DP0 pid=316526) .b8 105
(EngineCore_DP0 pid=316526) .b8 108
(EngineCore_DP0 pid=316526) .b8 100
(EngineCore_DP0 pid=316526) .b8 47
(EngineCore_DP0 pid=316526) .b8 71
(EngineCore_DP0 pid=316526) .b8 66
(EngineCore_DP0 pid=316526) .b8 49
(EngineCore_DP0 pid=316526) .b8 48
(EngineCore_DP0 pid=316526) .b8 95
(EngineCore_DP0 pid=316526) .b8 99
(EngineCore_DP0 pid=316526) .b8 99
(EngineCore_DP0 pid=316526) .b8 49
(EngineCore_DP0 pid=316526) .b8 50
(EngineCore_DP0 pid=316526) .b8 49
(EngineCore_DP0 pid=316526) .b8 95
(EngineCore_DP0 pid=316526) .b8 112
(EngineCore_DP0 pid=316526) .b8 121
(EngineCore_DP0 pid=316526) .b8 51
(EngineCore_DP0 pid=316526) .b8 49
(EngineCore_DP0 pid=316526) .b8 50
(EngineCore_DP0 pid=316526) .b8 95
(EngineCore_DP0 pid=316526) .b8 99
(EngineCore_DP0 pid=316526) .b8 117
(EngineCore_DP0 pid=316526) .b8 49
(EngineCore_DP0 pid=316526) .b8 50
(EngineCore_DP0 pid=316526) .b8 57
(EngineCore_DP0 pid=316526) .b8 95
(EngineCore_DP0 pid=316526) .b8 97
(EngineCore_DP0 pid=316526) .b8 97
(EngineCore_DP0 pid=316526) .b8 114
(EngineCore_DP0 pid=316526) .b8 99
(EngineCore_DP0 pid=316526) .b8 104
(EngineCore_DP0 pid=316526) .b8 54
(EngineCore_DP0 pid=316526) .b8 52
(EngineCore_DP0 pid=316526) .b8 0
(EngineCore_DP0 pid=316526) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=316526) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=316526) .b8 113
(EngineCore_DP0 pid=316526) .b8 117
(EngineCore_DP0 pid=316526) .b8 97
(EngineCore_DP0 pid=316526) .b8 110
(EngineCore_DP0 pid=316526) .b8 116
(EngineCore_DP0 pid=316526) .b8 95
(EngineCore_DP0 pid=316526) .b8 115
(EngineCore_DP0 pid=316526) .b8 108
(EngineCore_DP0 pid=316526) .b8 105
(EngineCore_DP0 pid=316526) .b8 100
(EngineCore_DP0 pid=316526) .b8 101
(EngineCore_DP0 pid=316526) .b8 95
(EngineCore_DP0 pid=316526) .b8 105
(EngineCore_DP0 pid=316526) .b8 110
(EngineCore_DP0 pid=316526) .b8 116
(EngineCore_DP0 pid=316526) .b8 56
(EngineCore_DP0 pid=316526) .b8 95
(EngineCore_DP0 pid=316526) .b8 107
(EngineCore_DP0 pid=316526) .b8 101
(EngineCore_DP0 pid=316526) .b8 114
(EngineCore_DP0 pid=316526) .b8 110
(EngineCore_DP0 pid=316526) .b8 101
(EngineCore_DP0 pid=316526) .b8 108
(EngineCore_DP0 pid=316526) .b8 0
(EngineCore_DP0 pid=316526) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=316526) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=316526) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=316526) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=316526) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=316526) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=316526) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=316526) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=316526) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=316526) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=316526) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=316526) .b8 1
(EngineCore_DP0 pid=316526) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=316526) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=316526) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=316526) 	}
(EngineCore_DP0 pid=316526) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=316526) 
(EngineCore_DP0 pid=316526) ================================================================
(EngineCore_DP0 pid=316526) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=316526) 
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpyjcwn_om.ptx', '-o', '/tmp/tmpyjcwn_om.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866] 
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866] 
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866] 
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpyjcwn_om.ptx -o /tmp/tmpyjcwn_om.ptx.o
(EngineCore_DP0 pid=316526) ERROR 01-25 19:00:15 [core.py:866] 

STDERR:
[2026-01-25 19:00:00] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:00:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:00:00] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:00:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:00:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:00:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:00:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:00:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:00:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:00:03] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:00:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:00:03] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:00:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:00:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:00:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:00:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:00:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:00:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=316526) [2026-01-25 19:00:04] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=316526) [2026-01-25 19:00:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=316526) [2026-01-25 19:00:04] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=316526) [2026-01-25 19:00:04] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=316526) [2026-01-25 19:00:04] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=316526) [2026-01-25 19:00:04] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=316526) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=316526) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.21s/it]
(EngineCore_DP0 pid=316526) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.21s/it]
(EngineCore_DP0 pid=316526) 
(EngineCore_DP0 pid=316526) [2026-01-25 19:00:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=316526) [2026-01-25 19:00:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=316526) [2026-01-25 19:00:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=316526) [2026-01-25 19:00:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=316526) [2026-01-25 19:00:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=316526) [2026-01-25 19:00:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=316526) [2026-01-25 19:00:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=316526) [2026-01-25 19:00:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=316526) Process EngineCore_DP0:
(EngineCore_DP0 pid=316526) Traceback (most recent call last):
(EngineCore_DP0 pid=316526)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=316526)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=316526)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=316526)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=316526) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpyjcwn_om.ptx', '-o', '/tmp/tmpyjcwn_om.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=316526) 
(EngineCore_DP0 pid=316526) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=316526) 
(EngineCore_DP0 pid=316526) Traceback (most recent call last):
(EngineCore_DP0 pid=316526)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=316526)     self.run()
(EngineCore_DP0 pid=316526)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=316526)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=316526)     raise e
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=316526)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=316526)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=316526)     super().__init__(
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=316526)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=316526)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=316526)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=316526)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=316526)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=316526)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=316526)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=316526)     return func(*args, **kwargs)
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=316526)     return func(*args, **kwargs)
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=316526)     self.model_runner.profile_run()
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=316526)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=316526)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=316526)     return func(*args, **kwargs)
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=316526)     outputs = self.model(
(EngineCore_DP0 pid=316526)               ^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=316526)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=316526)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=316526)     model_output = self.model(
(EngineCore_DP0 pid=316526)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=316526)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=316526)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=316526)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=316526)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=316526)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=316526)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=316526)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=316526)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=316526)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=316526)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=316526)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=316526)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=316526)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=316526)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=316526)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=316526)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=316526)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=316526)     return self._linear_fn(
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=316526)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=316526)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=316526)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=316526)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=316526)     return fn(input, L)
(EngineCore_DP0 pid=316526)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=316526)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=316526)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=316526)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=316526)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=316526)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=316526)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=316526)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=316526)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=316526)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=316526)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=316526)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=316526)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=316526)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=316526)     raise PTXASError(error)
(EngineCore_DP0 pid=316526) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=316526) `ptxas` stderr:
(EngineCore_DP0 pid=316526) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=316526) 
(EngineCore_DP0 pid=316526) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpyjcwn_om.ptx -o /tmp/tmpyjcwn_om.ptx.o
(EngineCore_DP0 pid=316526) 
[rank0]:[W125 19:00:15.740659359 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 19:00:17
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:00:23 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:00:23 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=317053) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=317053) 
(EngineCore_DP0 pid=317053) 
(EngineCore_DP0 pid=317053) ================================================================
(EngineCore_DP0 pid=317053) Internal Triton PTX codegen error
(EngineCore_DP0 pid=317053) `ptxas` stderr:
(EngineCore_DP0 pid=317053) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=317053) 
(EngineCore_DP0 pid=317053) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpe0ed_c52.ptx -o /tmp/tmpe0ed_c52.ptx.o
(EngineCore_DP0 pid=317053) 
(EngineCore_DP0 pid=317053) 
(EngineCore_DP0 pid=317053) //
(EngineCore_DP0 pid=317053) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=317053) //
(EngineCore_DP0 pid=317053) 
(EngineCore_DP0 pid=317053) .version 8.7
(EngineCore_DP0 pid=317053) .target sm_121a
(EngineCore_DP0 pid=317053) .address_size 64
(EngineCore_DP0 pid=317053) 
(EngineCore_DP0 pid=317053) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=317053) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=317053)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=317053) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=317053) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=317053) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=317053) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=317053) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=317053) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=317053) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=317053) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=317053) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=317053) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=317053) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=317053) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=317053) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=317053) )
(EngineCore_DP0 pid=317053) .reqntid 512
(EngineCore_DP0 pid=317053) {
(EngineCore_DP0 pid=317053) 	.reg .pred 	%p<45>;
(EngineCore_DP0 pid=317053) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=317053) 	.reg .b32 	%r<244>;
(EngineCore_DP0 pid=317053) 	.reg .b64 	%rd<26>;
(EngineCore_DP0 pid=317053) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=317053) $L__func_begin0:
(EngineCore_DP0 pid=317053) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=317053) 
(EngineCore_DP0 pid=317053) // %bb.0:
(EngineCore_DP0 pid=317053) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=317053) 	ld.param.b32 	%r28, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=317053) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=317053) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=317053) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=317053) $L__tmp0:
(EngineCore_DP0 pid=317053) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=317053) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=317053) 	ld.param.b32 	%r31, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=317053) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=317053) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=317053) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=317053) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=317053) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=317053) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=317053) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=317053) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=317053) 	mov.b32 	%r242, 0f2B8CBCCC;
(EngineCore_DP0 pid=317053) 	setp.eq.b32 	%p44, %r2, 0;
(EngineCore_DP0 pid=317053) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=317053) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=317053) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=317053) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=317053) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=317053) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=317053) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=317053) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=317053) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=317053) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=317053) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=317053) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=317053) 	mov.b32 	%r240, 0f00000000;
(EngineCore_DP0 pid=317053) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=317053) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=317053) 	mov.b32 	%r241, %r49;
(EngineCore_DP0 pid=317053) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=317053) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=317053) 	add.s32 	%r59, %r4, %r241;
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=317053) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=317053) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=317053) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=317053) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=317053) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=317053) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=317053) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=317053) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=317053) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=317053) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=317053) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=317053) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=317053) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=317053) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=317053) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=317053) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=317053) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=317053) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=317053) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=317053) $L__tmp1:
(EngineCore_DP0 pid=317053) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	bar.sync 	0;
(EngineCore_DP0 pid=317053) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=317053) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=317053) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=317053) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=317053) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=317053) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=317053) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=317053) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=317053) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=317053) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=317053) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=317053) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=317053) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=317053) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=317053) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=317053) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=317053) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=317053) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=317053) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	bar.sync 	0;
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=317053) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=317053) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=317053) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=317053) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=317053) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=317053) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=317053) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=317053) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	@%p44 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	bar.sync 	0;
(EngineCore_DP0 pid=317053) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=317053) $L__tmp2:
(EngineCore_DP0 pid=317053) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=317053) 	max.f32 	%r240, %r240, %r77;
(EngineCore_DP0 pid=317053) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=317053) 	add.s32 	%r241, %r241, 4096;
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p6, %r241, %r28;
(EngineCore_DP0 pid=317053) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=317053) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=317053) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=317053) 	max.f32 	%r242, %r240, 0f2B8CBCCC;
(EngineCore_DP0 pid=317053) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=317053) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=317053) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=317053) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=317053) 	div.full.f32 	%r80, %r242, %r79;
(EngineCore_DP0 pid=317053) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=317053) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=317053) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=317053) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=317053) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	@%p44 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=317053) 	shl.b32 	%r15, %r29, 1;
(EngineCore_DP0 pid=317053) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=317053) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=317053) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=317053) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=317053) 	ld.param.b32 	%r33, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=317053) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=317053) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=317053) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=317053) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=317053) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=317053) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=317053) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=317053) 	div.full.f32 	%r14, %r79, %r242;
(EngineCore_DP0 pid=317053) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=317053) 	mov.b32 	%r243, 0;
(EngineCore_DP0 pid=317053) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=317053)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=317053) 	.loc	1 313 31                        // quant_slide_tuned_Llama3.2-1B.py:313:31
(EngineCore_DP0 pid=317053) 	add.s32 	%r86, %r16, %r243;
(EngineCore_DP0 pid=317053) 	add.s32 	%r87, %r243, 1;
(EngineCore_DP0 pid=317053) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=317053) 	add.s32 	%r88, %r86, 2;
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p25, %r86, %r15;
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p26, %r88, %r15;
(EngineCore_DP0 pid=317053) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=317053) 	shr.u32 	%r89, %r86, 1;
(EngineCore_DP0 pid=317053) 	shr.u32 	%r90, %r88, 1;
(EngineCore_DP0 pid=317053) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=317053) 	shr.u32 	%r91, %r87, 31;
(EngineCore_DP0 pid=317053) 	add.s32 	%r92, %r87, %r91;
(EngineCore_DP0 pid=317053) 	and.b32 	%r93, %r92, 2147483646;
(EngineCore_DP0 pid=317053) 	sub.s32 	%r94, %r87, %r93;
(EngineCore_DP0 pid=317053) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=317053) 	shl.b32 	%r95, %r94, 1;
(EngineCore_DP0 pid=317053) 	.loc	1 319 22                        // quant_slide_tuned_Llama3.2-1B.py:319:22
(EngineCore_DP0 pid=317053) 	mul.lo.s32 	%r96, %r89, 6;
(EngineCore_DP0 pid=317053) 	mul.lo.s32 	%r97, %r90, 6;
(EngineCore_DP0 pid=317053) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=317053) 	add.s32 	%r98, %r96, %r95;
(EngineCore_DP0 pid=317053) 	add.s32 	%r99, %r97, %r95;
(EngineCore_DP0 pid=317053) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p27, %r96, %r27;
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p28, %r98, %r27;
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p29, %r97, %r27;
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p30, %r99, %r27;
(EngineCore_DP0 pid=317053) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=317053) 	and.pred 	%p9, %p25, %p27;
(EngineCore_DP0 pid=317053) 	and.pred 	%p10, %p25, %p28;
(EngineCore_DP0 pid=317053) 	and.pred 	%p11, %p26, %p29;
(EngineCore_DP0 pid=317053) 	and.pred 	%p12, %p26, %p30;
(EngineCore_DP0 pid=317053) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=317053) 	mad.wide.s32 	%rd8, %r96, 2, %rd1;
(EngineCore_DP0 pid=317053) 	mad.wide.s32 	%rd9, %r98, 2, %rd1;
(EngineCore_DP0 pid=317053) 	mad.wide.s32 	%rd10, %r97, 2, %rd1;
(EngineCore_DP0 pid=317053) 	mad.wide.s32 	%rd11, %r99, 2, %rd1;
(EngineCore_DP0 pid=317053) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=317053) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=317053) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=317053) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=317053) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=317053) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=317053) 	cvt.f32.bf16 	%r100, %rs24;
(EngineCore_DP0 pid=317053) 	cvt.f32.bf16 	%r101, %rs26;
(EngineCore_DP0 pid=317053) 	cvt.f32.bf16 	%r102, %rs28;
(EngineCore_DP0 pid=317053) 	cvt.f32.bf16 	%r103, %rs30;
(EngineCore_DP0 pid=317053) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=317053) 	or.b32 	%r104, %r98, 1;
(EngineCore_DP0 pid=317053) 	or.b32 	%r105, %r99, 1;
(EngineCore_DP0 pid=317053) 	or.b32 	%r106, %r99, 2;
(EngineCore_DP0 pid=317053) 	or.b32 	%r107, %r99, 3;
(EngineCore_DP0 pid=317053) 	or.b32 	%r108, %r96, 1;
(EngineCore_DP0 pid=317053) 	or.b32 	%r109, %r97, 1;
(EngineCore_DP0 pid=317053) 	or.b32 	%r110, %r96, 2;
(EngineCore_DP0 pid=317053) 	or.b32 	%r111, %r96, 3;
(EngineCore_DP0 pid=317053) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p31, %r107, %r27;
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p32, %r106, %r27;
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p33, %r105, %r27;
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p34, %r104, %r27;
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p35, %r111, %r27;
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p36, %r110, %r27;
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p37, %r109, %r27;
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p38, %r108, %r27;
(EngineCore_DP0 pid=317053) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=317053) 	and.pred 	%p13, %p25, %p38;
(EngineCore_DP0 pid=317053) 	and.pred 	%p14, %p25, %p34;
(EngineCore_DP0 pid=317053) 	and.pred 	%p15, %p26, %p37;
(EngineCore_DP0 pid=317053) 	and.pred 	%p16, %p26, %p33;
(EngineCore_DP0 pid=317053) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=317053) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=317053) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=317053) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=317053) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=317053) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=317053) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=317053) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=317053) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=317053) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=317053) 	cvt.f32.bf16 	%r112, %rs32;
(EngineCore_DP0 pid=317053) 	cvt.f32.bf16 	%r113, %rs34;
(EngineCore_DP0 pid=317053) 	cvt.f32.bf16 	%r114, %rs36;
(EngineCore_DP0 pid=317053) 	cvt.f32.bf16 	%r115, %rs38;
(EngineCore_DP0 pid=317053) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=317053) 	add.s32 	%r116, %r98, 2;
(EngineCore_DP0 pid=317053) 	add.s32 	%r117, %r97, 2;
(EngineCore_DP0 pid=317053) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p39, %r116, %r27;
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p40, %r117, %r27;
(EngineCore_DP0 pid=317053) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=317053) 	and.pred 	%p17, %p25, %p36;
(EngineCore_DP0 pid=317053) 	and.pred 	%p18, %p25, %p39;
(EngineCore_DP0 pid=317053) 	and.pred 	%p19, %p26, %p40;
(EngineCore_DP0 pid=317053) 	and.pred 	%p20, %p26, %p32;
(EngineCore_DP0 pid=317053) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=317053) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=317053) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=317053) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=317053) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=317053) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=317053) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=317053) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=317053) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=317053) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=317053) 	cvt.f32.bf16 	%r118, %rs40;
(EngineCore_DP0 pid=317053) 	cvt.f32.bf16 	%r119, %rs42;
(EngineCore_DP0 pid=317053) 	cvt.f32.bf16 	%r120, %rs44;
(EngineCore_DP0 pid=317053) 	cvt.f32.bf16 	%r121, %rs46;
(EngineCore_DP0 pid=317053) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=317053) 	add.s32 	%r122, %r98, 3;
(EngineCore_DP0 pid=317053) 	add.s32 	%r123, %r97, 3;
(EngineCore_DP0 pid=317053) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p41, %r122, %r27;
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p42, %r123, %r27;
(EngineCore_DP0 pid=317053) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=317053) 	and.pred 	%p21, %p25, %p35;
(EngineCore_DP0 pid=317053) 	and.pred 	%p22, %p25, %p41;
(EngineCore_DP0 pid=317053) 	and.pred 	%p23, %p26, %p42;
(EngineCore_DP0 pid=317053) 	and.pred 	%p24, %p26, %p31;
(EngineCore_DP0 pid=317053) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=317053) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=317053) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=317053) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=317053) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=317053) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=317053) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=317053) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=317053) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=317053) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=317053) 	cvt.f32.bf16 	%r124, %rs48;
(EngineCore_DP0 pid=317053) 	cvt.f32.bf16 	%r125, %rs50;
(EngineCore_DP0 pid=317053) 	cvt.f32.bf16 	%r126, %rs52;
(EngineCore_DP0 pid=317053) 	cvt.f32.bf16 	%r127, %rs54;
(EngineCore_DP0 pid=317053) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=317053) 	mul.f32 	%r128, %r14, %r100;
(EngineCore_DP0 pid=317053) 	mul.f32 	%r129, %r14, %r101;
(EngineCore_DP0 pid=317053) 	mul.f32 	%r130, %r14, %r102;
(EngineCore_DP0 pid=317053) 	mul.f32 	%r131, %r14, %r103;
(EngineCore_DP0 pid=317053) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=317053) 	cvt.rni.f32.f32 	%r132, %r128;
(EngineCore_DP0 pid=317053) 	cvt.rni.f32.f32 	%r133, %r129;
(EngineCore_DP0 pid=317053) 	cvt.rni.f32.f32 	%r134, %r130;
(EngineCore_DP0 pid=317053) 	cvt.rni.f32.f32 	%r135, %r131;
(EngineCore_DP0 pid=317053) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=317053) 	max.f32 	%r136, %r132, 0fC3000000;
(EngineCore_DP0 pid=317053) 	min.f32 	%r137, %r136, 0f42FE0000;
(EngineCore_DP0 pid=317053) 	max.f32 	%r138, %r133, 0fC3000000;
(EngineCore_DP0 pid=317053) 	min.f32 	%r139, %r138, 0f42FE0000;
(EngineCore_DP0 pid=317053) 	max.f32 	%r140, %r134, 0fC3000000;
(EngineCore_DP0 pid=317053) 	min.f32 	%r141, %r140, 0f42FE0000;
(EngineCore_DP0 pid=317053) 	max.f32 	%r142, %r135, 0fC3000000;
(EngineCore_DP0 pid=317053) 	min.f32 	%r143, %r142, 0f42FE0000;
(EngineCore_DP0 pid=317053) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=317053) 	cvt.rzi.s32.f32 	%r144, %r137;
(EngineCore_DP0 pid=317053) 	cvt.rzi.s32.f32 	%r145, %r139;
(EngineCore_DP0 pid=317053) 	cvt.rzi.s32.f32 	%r146, %r141;
(EngineCore_DP0 pid=317053) 	cvt.rzi.s32.f32 	%r147, %r143;
(EngineCore_DP0 pid=317053) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=317053) 	and.b32 	%r148, %r144, 255;
(EngineCore_DP0 pid=317053) 	and.b32 	%r149, %r145, 255;
(EngineCore_DP0 pid=317053) 	and.b32 	%r150, %r146, 255;
(EngineCore_DP0 pid=317053) 	and.b32 	%r151, %r147, 255;
(EngineCore_DP0 pid=317053) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=317053) 	mul.f32 	%r152, %r14, %r112;
(EngineCore_DP0 pid=317053) 	mul.f32 	%r153, %r14, %r113;
(EngineCore_DP0 pid=317053) 	mul.f32 	%r154, %r14, %r114;
(EngineCore_DP0 pid=317053) 	mul.f32 	%r155, %r14, %r115;
(EngineCore_DP0 pid=317053) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=317053) 	cvt.rni.f32.f32 	%r156, %r152;
(EngineCore_DP0 pid=317053) 	cvt.rni.f32.f32 	%r157, %r153;
(EngineCore_DP0 pid=317053) 	cvt.rni.f32.f32 	%r158, %r154;
(EngineCore_DP0 pid=317053) 	cvt.rni.f32.f32 	%r159, %r155;
(EngineCore_DP0 pid=317053) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=317053) 	mul.f32 	%r160, %r14, %r118;
(EngineCore_DP0 pid=317053) 	mul.f32 	%r161, %r14, %r119;
(EngineCore_DP0 pid=317053) 	mul.f32 	%r162, %r14, %r120;
(EngineCore_DP0 pid=317053) 	mul.f32 	%r163, %r14, %r121;
(EngineCore_DP0 pid=317053) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=317053) 	cvt.rni.f32.f32 	%r164, %r160;
(EngineCore_DP0 pid=317053) 	cvt.rni.f32.f32 	%r165, %r161;
(EngineCore_DP0 pid=317053) 	cvt.rni.f32.f32 	%r166, %r162;
(EngineCore_DP0 pid=317053) 	cvt.rni.f32.f32 	%r167, %r163;
(EngineCore_DP0 pid=317053) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=317053) 	mul.f32 	%r168, %r14, %r124;
(EngineCore_DP0 pid=317053) 	mul.f32 	%r169, %r14, %r125;
(EngineCore_DP0 pid=317053) 	mul.f32 	%r170, %r14, %r126;
(EngineCore_DP0 pid=317053) 	mul.f32 	%r171, %r14, %r127;
(EngineCore_DP0 pid=317053) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=317053) 	cvt.rni.f32.f32 	%r172, %r168;
(EngineCore_DP0 pid=317053) 	cvt.rni.f32.f32 	%r173, %r169;
(EngineCore_DP0 pid=317053) 	cvt.rni.f32.f32 	%r174, %r170;
(EngineCore_DP0 pid=317053) 	cvt.rni.f32.f32 	%r175, %r171;
(EngineCore_DP0 pid=317053) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=317053) 	max.f32 	%r176, %r172, 0fC3000000;
(EngineCore_DP0 pid=317053) 	min.f32 	%r177, %r176, 0f42FE0000;
(EngineCore_DP0 pid=317053) 	max.f32 	%r178, %r173, 0fC3000000;
(EngineCore_DP0 pid=317053) 	min.f32 	%r179, %r178, 0f42FE0000;
(EngineCore_DP0 pid=317053) 	max.f32 	%r180, %r174, 0fC3000000;
(EngineCore_DP0 pid=317053) 	min.f32 	%r181, %r180, 0f42FE0000;
(EngineCore_DP0 pid=317053) 	max.f32 	%r182, %r175, 0fC3000000;
(EngineCore_DP0 pid=317053) 	min.f32 	%r183, %r182, 0f42FE0000;
(EngineCore_DP0 pid=317053) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=317053) 	cvt.rzi.s32.f32 	%r184, %r177;
(EngineCore_DP0 pid=317053) 	cvt.rzi.s32.f32 	%r185, %r179;
(EngineCore_DP0 pid=317053) 	cvt.rzi.s32.f32 	%r186, %r181;
(EngineCore_DP0 pid=317053) 	cvt.rzi.s32.f32 	%r187, %r183;
(EngineCore_DP0 pid=317053) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=317053) 	max.f32 	%r188, %r164, 0fC3000000;
(EngineCore_DP0 pid=317053) 	max.f32 	%r189, %r156, 0fC3000000;
(EngineCore_DP0 pid=317053) 	min.f32 	%r190, %r189, 0f42FE0000;
(EngineCore_DP0 pid=317053) 	min.f32 	%r191, %r188, 0f42FE0000;
(EngineCore_DP0 pid=317053) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=317053) 	cvt.rzi.s32.f32 	%r192, %r191;
(EngineCore_DP0 pid=317053) 	cvt.rzi.s32.f32 	%r193, %r190;
(EngineCore_DP0 pid=317053) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=317053) 	shl.b32 	%r194, %r193, 8;
(EngineCore_DP0 pid=317053) 	shl.b32 	%r195, %r192, 16;
(EngineCore_DP0 pid=317053) 	and.b32 	%r196, %r195, 16711680;
(EngineCore_DP0 pid=317053) 	and.b32 	%r197, %r194, 65280;
(EngineCore_DP0 pid=317053) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=317053) 	or.b32 	%r198, %r197, %r148;
(EngineCore_DP0 pid=317053) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=317053) 	max.f32 	%r199, %r165, 0fC3000000;
(EngineCore_DP0 pid=317053) 	max.f32 	%r200, %r157, 0fC3000000;
(EngineCore_DP0 pid=317053) 	min.f32 	%r201, %r200, 0f42FE0000;
(EngineCore_DP0 pid=317053) 	min.f32 	%r202, %r199, 0f42FE0000;
(EngineCore_DP0 pid=317053) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=317053) 	cvt.rzi.s32.f32 	%r203, %r202;
(EngineCore_DP0 pid=317053) 	cvt.rzi.s32.f32 	%r204, %r201;
(EngineCore_DP0 pid=317053) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=317053) 	shl.b32 	%r205, %r204, 8;
(EngineCore_DP0 pid=317053) 	shl.b32 	%r206, %r203, 16;
(EngineCore_DP0 pid=317053) 	and.b32 	%r207, %r206, 16711680;
(EngineCore_DP0 pid=317053) 	and.b32 	%r208, %r205, 65280;
(EngineCore_DP0 pid=317053) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=317053) 	or.b32 	%r209, %r208, %r149;
(EngineCore_DP0 pid=317053) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=317053) 	max.f32 	%r210, %r166, 0fC3000000;
(EngineCore_DP0 pid=317053) 	max.f32 	%r211, %r158, 0fC3000000;
(EngineCore_DP0 pid=317053) 	min.f32 	%r212, %r211, 0f42FE0000;
(EngineCore_DP0 pid=317053) 	min.f32 	%r213, %r210, 0f42FE0000;
(EngineCore_DP0 pid=317053) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=317053) 	cvt.rzi.s32.f32 	%r214, %r213;
(EngineCore_DP0 pid=317053) 	cvt.rzi.s32.f32 	%r215, %r212;
(EngineCore_DP0 pid=317053) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=317053) 	shl.b32 	%r216, %r215, 8;
(EngineCore_DP0 pid=317053) 	shl.b32 	%r217, %r214, 16;
(EngineCore_DP0 pid=317053) 	and.b32 	%r218, %r217, 16711680;
(EngineCore_DP0 pid=317053) 	and.b32 	%r219, %r216, 65280;
(EngineCore_DP0 pid=317053) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=317053) 	or.b32 	%r220, %r219, %r150;
(EngineCore_DP0 pid=317053) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=317053) 	max.f32 	%r221, %r167, 0fC3000000;
(EngineCore_DP0 pid=317053) 	max.f32 	%r222, %r159, 0fC3000000;
(EngineCore_DP0 pid=317053) 	min.f32 	%r223, %r222, 0f42FE0000;
(EngineCore_DP0 pid=317053) 	min.f32 	%r224, %r221, 0f42FE0000;
(EngineCore_DP0 pid=317053) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=317053) 	cvt.rzi.s32.f32 	%r225, %r224;
(EngineCore_DP0 pid=317053) 	cvt.rzi.s32.f32 	%r226, %r223;
(EngineCore_DP0 pid=317053) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=317053) 	shl.b32 	%r227, %r226, 8;
(EngineCore_DP0 pid=317053) 	shl.b32 	%r228, %r225, 16;
(EngineCore_DP0 pid=317053) 	and.b32 	%r229, %r228, 16711680;
(EngineCore_DP0 pid=317053) 	and.b32 	%r230, %r227, 65280;
(EngineCore_DP0 pid=317053) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=317053) 	or.b32 	%r231, %r230, %r151;
(EngineCore_DP0 pid=317053) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=317053) 	or.b32 	%r232, %r198, %r196;
(EngineCore_DP0 pid=317053) 	or.b32 	%r233, %r209, %r207;
(EngineCore_DP0 pid=317053) 	or.b32 	%r234, %r220, %r218;
(EngineCore_DP0 pid=317053) 	or.b32 	%r235, %r231, %r229;
(EngineCore_DP0 pid=317053) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=317053) 	shl.b32 	%r236, %r184, 24;
(EngineCore_DP0 pid=317053) 	shl.b32 	%r237, %r185, 24;
(EngineCore_DP0 pid=317053) 	shl.b32 	%r238, %r186, 24;
(EngineCore_DP0 pid=317053) 	shl.b32 	%r239, %r187, 24;
(EngineCore_DP0 pid=317053) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=317053) 	or.b32 	%r82, %r232, %r236;
(EngineCore_DP0 pid=317053) 	or.b32 	%r83, %r233, %r237;
(EngineCore_DP0 pid=317053) 	or.b32 	%r84, %r234, %r238;
(EngineCore_DP0 pid=317053) 	or.b32 	%r85, %r235, %r239;
(EngineCore_DP0 pid=317053) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=317053) 	mad.wide.s32 	%rd24, %r86, 4, %rd2;
(EngineCore_DP0 pid=317053) 	add.s64 	%rd25, %rd24, 8;
(EngineCore_DP0 pid=317053) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	@%p25 st.global.v2.b32 [ %rd24 + 0 ], { %r82, %r83 };
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	// begin inline asm
(EngineCore_DP0 pid=317053) 	@%p26 st.global.v2.b32 [ %rd25 + 0 ], { %r84, %r85 };
(EngineCore_DP0 pid=317053) 	// end inline asm
(EngineCore_DP0 pid=317053) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=317053) 	add.s32 	%r243, %r243, 2048;
(EngineCore_DP0 pid=317053) 	setp.lt.s32 	%p43, %r243, %r15;
(EngineCore_DP0 pid=317053) 	@%p43 bra 	$L__BB0_6;
(EngineCore_DP0 pid=317053) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=317053) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=317053) 	ret;
(EngineCore_DP0 pid=317053) $L__tmp3:
(EngineCore_DP0 pid=317053) $L__func_end0:
(EngineCore_DP0 pid=317053)                                         // -- End function
(EngineCore_DP0 pid=317053) }
(EngineCore_DP0 pid=317053) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=317053) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=317053) 	.section	.debug_abbrev
(EngineCore_DP0 pid=317053) 	{
(EngineCore_DP0 pid=317053) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=317053) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=317053) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=317053) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=317053) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=317053) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=317053) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=317053) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=317053) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=317053) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=317053) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=317053) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=317053) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=317053) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=317053) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=317053) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=317053) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=317053) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=317053) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=317053) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=317053) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=317053) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=317053) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=317053) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=317053) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=317053) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=317053) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=317053) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=317053) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=317053) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=317053) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=317053) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=317053) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=317053) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=317053) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=317053) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=317053) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=317053) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=317053) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=317053) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=317053) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=317053) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=317053) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=317053) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=317053) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=317053) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=317053) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=317053) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=317053) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=317053) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=317053) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=317053) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=317053) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=317053) 	}
(EngineCore_DP0 pid=317053) 	.section	.debug_info
(EngineCore_DP0 pid=317053) 	{
(EngineCore_DP0 pid=317053) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=317053) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=317053) .b8 0
(EngineCore_DP0 pid=317053) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=317053) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=317053) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=317053) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=317053) .b8 114
(EngineCore_DP0 pid=317053) .b8 105
(EngineCore_DP0 pid=317053) .b8 116
(EngineCore_DP0 pid=317053) .b8 111
(EngineCore_DP0 pid=317053) .b8 110
(EngineCore_DP0 pid=317053) .b8 0
(EngineCore_DP0 pid=317053) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=317053) .b8 0
(EngineCore_DP0 pid=317053) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=317053) .b8 117
(EngineCore_DP0 pid=317053) .b8 97
(EngineCore_DP0 pid=317053) .b8 110
(EngineCore_DP0 pid=317053) .b8 116
(EngineCore_DP0 pid=317053) .b8 95
(EngineCore_DP0 pid=317053) .b8 115
(EngineCore_DP0 pid=317053) .b8 108
(EngineCore_DP0 pid=317053) .b8 105
(EngineCore_DP0 pid=317053) .b8 100
(EngineCore_DP0 pid=317053) .b8 101
(EngineCore_DP0 pid=317053) .b8 95
(EngineCore_DP0 pid=317053) .b8 116
(EngineCore_DP0 pid=317053) .b8 117
(EngineCore_DP0 pid=317053) .b8 110
(EngineCore_DP0 pid=317053) .b8 101
(EngineCore_DP0 pid=317053) .b8 100
(EngineCore_DP0 pid=317053) .b8 95
(EngineCore_DP0 pid=317053) .b8 76
(EngineCore_DP0 pid=317053) .b8 108
(EngineCore_DP0 pid=317053) .b8 97
(EngineCore_DP0 pid=317053) .b8 109
(EngineCore_DP0 pid=317053) .b8 97
(EngineCore_DP0 pid=317053) .b8 51
(EngineCore_DP0 pid=317053) .b8 46
(EngineCore_DP0 pid=317053) .b8 50
(EngineCore_DP0 pid=317053) .b8 45
(EngineCore_DP0 pid=317053) .b8 49
(EngineCore_DP0 pid=317053) .b8 66
(EngineCore_DP0 pid=317053) .b8 46
(EngineCore_DP0 pid=317053) .b8 112
(EngineCore_DP0 pid=317053) .b8 121
(EngineCore_DP0 pid=317053) .b8 0
(EngineCore_DP0 pid=317053) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=317053) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=317053) .b8 114
(EngineCore_DP0 pid=317053) .b8 111
(EngineCore_DP0 pid=317053) .b8 111
(EngineCore_DP0 pid=317053) .b8 116
(EngineCore_DP0 pid=317053) .b8 47
(EngineCore_DP0 pid=317053) .b8 118
(EngineCore_DP0 pid=317053) .b8 108
(EngineCore_DP0 pid=317053) .b8 108
(EngineCore_DP0 pid=317053) .b8 109
(EngineCore_DP0 pid=317053) .b8 98
(EngineCore_DP0 pid=317053) .b8 101
(EngineCore_DP0 pid=317053) .b8 110
(EngineCore_DP0 pid=317053) .b8 99
(EngineCore_DP0 pid=317053) .b8 104
(EngineCore_DP0 pid=317053) .b8 47
(EngineCore_DP0 pid=317053) .b8 115
(EngineCore_DP0 pid=317053) .b8 108
(EngineCore_DP0 pid=317053) .b8 105
(EngineCore_DP0 pid=317053) .b8 100
(EngineCore_DP0 pid=317053) .b8 101
(EngineCore_DP0 pid=317053) .b8 115
(EngineCore_DP0 pid=317053) .b8 112
(EngineCore_DP0 pid=317053) .b8 97
(EngineCore_DP0 pid=317053) .b8 114
(EngineCore_DP0 pid=317053) .b8 115
(EngineCore_DP0 pid=317053) .b8 101
(EngineCore_DP0 pid=317053) .b8 47
(EngineCore_DP0 pid=317053) .b8 99
(EngineCore_DP0 pid=317053) .b8 115
(EngineCore_DP0 pid=317053) .b8 114
(EngineCore_DP0 pid=317053) .b8 99
(EngineCore_DP0 pid=317053) .b8 47
(EngineCore_DP0 pid=317053) .b8 102
(EngineCore_DP0 pid=317053) .b8 117
(EngineCore_DP0 pid=317053) .b8 115
(EngineCore_DP0 pid=317053) .b8 101
(EngineCore_DP0 pid=317053) .b8 100
(EngineCore_DP0 pid=317053) .b8 95
(EngineCore_DP0 pid=317053) .b8 113
(EngineCore_DP0 pid=317053) .b8 117
(EngineCore_DP0 pid=317053) .b8 97
(EngineCore_DP0 pid=317053) .b8 110
(EngineCore_DP0 pid=317053) .b8 116
(EngineCore_DP0 pid=317053) .b8 95
(EngineCore_DP0 pid=317053) .b8 115
(EngineCore_DP0 pid=317053) .b8 108
(EngineCore_DP0 pid=317053) .b8 105
(EngineCore_DP0 pid=317053) .b8 100
(EngineCore_DP0 pid=317053) .b8 101
(EngineCore_DP0 pid=317053) .b8 95
(EngineCore_DP0 pid=317053) .b8 116
(EngineCore_DP0 pid=317053) .b8 114
(EngineCore_DP0 pid=317053) .b8 105
(EngineCore_DP0 pid=317053) .b8 116
(EngineCore_DP0 pid=317053) .b8 111
(EngineCore_DP0 pid=317053) .b8 110
(EngineCore_DP0 pid=317053) .b8 47
(EngineCore_DP0 pid=317053) .b8 98
(EngineCore_DP0 pid=317053) .b8 117
(EngineCore_DP0 pid=317053) .b8 105
(EngineCore_DP0 pid=317053) .b8 108
(EngineCore_DP0 pid=317053) .b8 100
(EngineCore_DP0 pid=317053) .b8 47
(EngineCore_DP0 pid=317053) .b8 71
(EngineCore_DP0 pid=317053) .b8 66
(EngineCore_DP0 pid=317053) .b8 49
(EngineCore_DP0 pid=317053) .b8 48
(EngineCore_DP0 pid=317053) .b8 95
(EngineCore_DP0 pid=317053) .b8 99
(EngineCore_DP0 pid=317053) .b8 99
(EngineCore_DP0 pid=317053) .b8 49
(EngineCore_DP0 pid=317053) .b8 50
(EngineCore_DP0 pid=317053) .b8 49
(EngineCore_DP0 pid=317053) .b8 95
(EngineCore_DP0 pid=317053) .b8 112
(EngineCore_DP0 pid=317053) .b8 121
(EngineCore_DP0 pid=317053) .b8 51
(EngineCore_DP0 pid=317053) .b8 49
(EngineCore_DP0 pid=317053) .b8 50
(EngineCore_DP0 pid=317053) .b8 95
(EngineCore_DP0 pid=317053) .b8 99
(EngineCore_DP0 pid=317053) .b8 117
(EngineCore_DP0 pid=317053) .b8 49
(EngineCore_DP0 pid=317053) .b8 50
(EngineCore_DP0 pid=317053) .b8 57
(EngineCore_DP0 pid=317053) .b8 95
(EngineCore_DP0 pid=317053) .b8 97
(EngineCore_DP0 pid=317053) .b8 97
(EngineCore_DP0 pid=317053) .b8 114
(EngineCore_DP0 pid=317053) .b8 99
(EngineCore_DP0 pid=317053) .b8 104
(EngineCore_DP0 pid=317053) .b8 54
(EngineCore_DP0 pid=317053) .b8 52
(EngineCore_DP0 pid=317053) .b8 0
(EngineCore_DP0 pid=317053) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=317053) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=317053) .b8 113
(EngineCore_DP0 pid=317053) .b8 117
(EngineCore_DP0 pid=317053) .b8 97
(EngineCore_DP0 pid=317053) .b8 110
(EngineCore_DP0 pid=317053) .b8 116
(EngineCore_DP0 pid=317053) .b8 95
(EngineCore_DP0 pid=317053) .b8 115
(EngineCore_DP0 pid=317053) .b8 108
(EngineCore_DP0 pid=317053) .b8 105
(EngineCore_DP0 pid=317053) .b8 100
(EngineCore_DP0 pid=317053) .b8 101
(EngineCore_DP0 pid=317053) .b8 95
(EngineCore_DP0 pid=317053) .b8 105
(EngineCore_DP0 pid=317053) .b8 110
(EngineCore_DP0 pid=317053) .b8 116
(EngineCore_DP0 pid=317053) .b8 56
(EngineCore_DP0 pid=317053) .b8 95
(EngineCore_DP0 pid=317053) .b8 107
(EngineCore_DP0 pid=317053) .b8 101
(EngineCore_DP0 pid=317053) .b8 114
(EngineCore_DP0 pid=317053) .b8 110
(EngineCore_DP0 pid=317053) .b8 101
(EngineCore_DP0 pid=317053) .b8 108
(EngineCore_DP0 pid=317053) .b8 0
(EngineCore_DP0 pid=317053) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=317053) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=317053) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=317053) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=317053) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=317053) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=317053) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=317053) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=317053) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=317053) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=317053) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=317053) .b8 1
(EngineCore_DP0 pid=317053) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=317053) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=317053) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=317053) 	}
(EngineCore_DP0 pid=317053) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=317053) 
(EngineCore_DP0 pid=317053) ================================================================
(EngineCore_DP0 pid=317053) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=317053) 
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpe0ed_c52.ptx', '-o', '/tmp/tmpe0ed_c52.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866] 
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866] 
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866] 
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpe0ed_c52.ptx -o /tmp/tmpe0ed_c52.ptx.o
(EngineCore_DP0 pid=317053) ERROR 01-25 19:00:38 [core.py:866] 

STDERR:
[2026-01-25 19:00:23] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:00:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:00:23] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:00:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:00:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:00:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:00:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:00:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:00:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:00:26] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:00:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:00:26] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:00:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:00:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:00:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:00:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:00:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:00:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=317053) [2026-01-25 19:00:27] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=317053) [2026-01-25 19:00:27] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=317053) [2026-01-25 19:00:27] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=317053) [2026-01-25 19:00:27] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=317053) [2026-01-25 19:00:27] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=317053) [2026-01-25 19:00:27] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=317053) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=317053) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.33s/it]
(EngineCore_DP0 pid=317053) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.33s/it]
(EngineCore_DP0 pid=317053) 
(EngineCore_DP0 pid=317053) [2026-01-25 19:00:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=317053) [2026-01-25 19:00:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=317053) [2026-01-25 19:00:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=317053) [2026-01-25 19:00:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=317053) [2026-01-25 19:00:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=317053) [2026-01-25 19:00:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=317053) [2026-01-25 19:00:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=317053) [2026-01-25 19:00:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=317053) Process EngineCore_DP0:
(EngineCore_DP0 pid=317053) Traceback (most recent call last):
(EngineCore_DP0 pid=317053)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=317053)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=317053)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=317053)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=317053) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpe0ed_c52.ptx', '-o', '/tmp/tmpe0ed_c52.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=317053) 
(EngineCore_DP0 pid=317053) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=317053) 
(EngineCore_DP0 pid=317053) Traceback (most recent call last):
(EngineCore_DP0 pid=317053)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=317053)     self.run()
(EngineCore_DP0 pid=317053)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=317053)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=317053)     raise e
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=317053)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=317053)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=317053)     super().__init__(
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=317053)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=317053)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=317053)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=317053)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=317053)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=317053)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=317053)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=317053)     return func(*args, **kwargs)
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=317053)     return func(*args, **kwargs)
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=317053)     self.model_runner.profile_run()
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=317053)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=317053)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=317053)     return func(*args, **kwargs)
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=317053)     outputs = self.model(
(EngineCore_DP0 pid=317053)               ^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=317053)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=317053)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=317053)     model_output = self.model(
(EngineCore_DP0 pid=317053)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=317053)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=317053)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=317053)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=317053)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=317053)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=317053)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=317053)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=317053)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=317053)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=317053)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=317053)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=317053)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=317053)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=317053)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=317053)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=317053)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=317053)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=317053)     return self._linear_fn(
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=317053)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=317053)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=317053)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=317053)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=317053)     return fn(input, L)
(EngineCore_DP0 pid=317053)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=317053)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=317053)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=317053)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=317053)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=317053)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=317053)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=317053)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=317053)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=317053)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=317053)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=317053)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=317053)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317053)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=317053)     raise PTXASError(error)
(EngineCore_DP0 pid=317053) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=317053) `ptxas` stderr:
(EngineCore_DP0 pid=317053) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=317053) 
(EngineCore_DP0 pid=317053) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpe0ed_c52.ptx -o /tmp/tmpe0ed_c52.ptx.o
(EngineCore_DP0 pid=317053) 
[rank0]:[W125 19:00:39.194235381 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 19:00:40
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:00:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:00:49 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=317610) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=317610) 
(EngineCore_DP0 pid=317610) 
(EngineCore_DP0 pid=317610) ================================================================
(EngineCore_DP0 pid=317610) Internal Triton PTX codegen error
(EngineCore_DP0 pid=317610) `ptxas` stderr:
(EngineCore_DP0 pid=317610) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=317610) 
(EngineCore_DP0 pid=317610) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpchmthwyb.ptx -o /tmp/tmpchmthwyb.ptx.o
(EngineCore_DP0 pid=317610) 
(EngineCore_DP0 pid=317610) 
(EngineCore_DP0 pid=317610) //
(EngineCore_DP0 pid=317610) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=317610) //
(EngineCore_DP0 pid=317610) 
(EngineCore_DP0 pid=317610) .version 8.7
(EngineCore_DP0 pid=317610) .target sm_121a
(EngineCore_DP0 pid=317610) .address_size 64
(EngineCore_DP0 pid=317610) 
(EngineCore_DP0 pid=317610) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=317610) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=317610)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=317610) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=317610) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=317610) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=317610) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=317610) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=317610) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=317610) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=317610) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=317610) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=317610) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=317610) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=317610) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=317610) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=317610) )
(EngineCore_DP0 pid=317610) .reqntid 512
(EngineCore_DP0 pid=317610) {
(EngineCore_DP0 pid=317610) 	.reg .pred 	%p<45>;
(EngineCore_DP0 pid=317610) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=317610) 	.reg .b32 	%r<244>;
(EngineCore_DP0 pid=317610) 	.reg .b64 	%rd<26>;
(EngineCore_DP0 pid=317610) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=317610) $L__func_begin0:
(EngineCore_DP0 pid=317610) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=317610) 
(EngineCore_DP0 pid=317610) // %bb.0:
(EngineCore_DP0 pid=317610) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=317610) 	ld.param.b32 	%r28, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=317610) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=317610) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=317610) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=317610) $L__tmp0:
(EngineCore_DP0 pid=317610) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=317610) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=317610) 	ld.param.b32 	%r31, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=317610) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=317610) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=317610) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=317610) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=317610) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=317610) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=317610) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=317610) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=317610) 	mov.b32 	%r242, 0f2B8CBCCC;
(EngineCore_DP0 pid=317610) 	setp.eq.b32 	%p44, %r2, 0;
(EngineCore_DP0 pid=317610) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=317610) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=317610) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=317610) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=317610) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=317610) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=317610) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=317610) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=317610) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=317610) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=317610) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=317610) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=317610) 	mov.b32 	%r240, 0f00000000;
(EngineCore_DP0 pid=317610) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=317610) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=317610) 	mov.b32 	%r241, %r49;
(EngineCore_DP0 pid=317610) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=317610) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=317610) 	add.s32 	%r59, %r4, %r241;
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=317610) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=317610) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=317610) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=317610) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=317610) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=317610) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=317610) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=317610) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=317610) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=317610) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=317610) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=317610) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=317610) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=317610) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=317610) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=317610) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=317610) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=317610) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=317610) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=317610) $L__tmp1:
(EngineCore_DP0 pid=317610) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	bar.sync 	0;
(EngineCore_DP0 pid=317610) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=317610) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=317610) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=317610) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=317610) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=317610) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=317610) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=317610) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=317610) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=317610) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=317610) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=317610) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=317610) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=317610) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=317610) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=317610) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=317610) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=317610) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=317610) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	bar.sync 	0;
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=317610) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=317610) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=317610) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=317610) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=317610) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=317610) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=317610) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=317610) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	@%p44 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	bar.sync 	0;
(EngineCore_DP0 pid=317610) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=317610) $L__tmp2:
(EngineCore_DP0 pid=317610) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=317610) 	max.f32 	%r240, %r240, %r77;
(EngineCore_DP0 pid=317610) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=317610) 	add.s32 	%r241, %r241, 4096;
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p6, %r241, %r28;
(EngineCore_DP0 pid=317610) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=317610) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=317610) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=317610) 	max.f32 	%r242, %r240, 0f2B8CBCCC;
(EngineCore_DP0 pid=317610) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=317610) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=317610) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=317610) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=317610) 	div.full.f32 	%r80, %r242, %r79;
(EngineCore_DP0 pid=317610) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=317610) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=317610) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=317610) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=317610) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	@%p44 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=317610) 	shl.b32 	%r15, %r29, 1;
(EngineCore_DP0 pid=317610) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=317610) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=317610) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=317610) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=317610) 	ld.param.b32 	%r33, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=317610) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=317610) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=317610) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=317610) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=317610) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=317610) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=317610) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=317610) 	div.full.f32 	%r14, %r79, %r242;
(EngineCore_DP0 pid=317610) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=317610) 	mov.b32 	%r243, 0;
(EngineCore_DP0 pid=317610) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=317610)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=317610) 	.loc	1 313 31                        // quant_slide_tuned_Llama3.2-1B.py:313:31
(EngineCore_DP0 pid=317610) 	add.s32 	%r86, %r16, %r243;
(EngineCore_DP0 pid=317610) 	add.s32 	%r87, %r243, 1;
(EngineCore_DP0 pid=317610) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=317610) 	add.s32 	%r88, %r86, 2;
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p25, %r86, %r15;
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p26, %r88, %r15;
(EngineCore_DP0 pid=317610) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=317610) 	shr.u32 	%r89, %r86, 1;
(EngineCore_DP0 pid=317610) 	shr.u32 	%r90, %r88, 1;
(EngineCore_DP0 pid=317610) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=317610) 	shr.u32 	%r91, %r87, 31;
(EngineCore_DP0 pid=317610) 	add.s32 	%r92, %r87, %r91;
(EngineCore_DP0 pid=317610) 	and.b32 	%r93, %r92, 2147483646;
(EngineCore_DP0 pid=317610) 	sub.s32 	%r94, %r87, %r93;
(EngineCore_DP0 pid=317610) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=317610) 	shl.b32 	%r95, %r94, 1;
(EngineCore_DP0 pid=317610) 	.loc	1 319 22                        // quant_slide_tuned_Llama3.2-1B.py:319:22
(EngineCore_DP0 pid=317610) 	mul.lo.s32 	%r96, %r89, 6;
(EngineCore_DP0 pid=317610) 	mul.lo.s32 	%r97, %r90, 6;
(EngineCore_DP0 pid=317610) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=317610) 	add.s32 	%r98, %r96, %r95;
(EngineCore_DP0 pid=317610) 	add.s32 	%r99, %r97, %r95;
(EngineCore_DP0 pid=317610) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p27, %r96, %r27;
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p28, %r98, %r27;
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p29, %r97, %r27;
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p30, %r99, %r27;
(EngineCore_DP0 pid=317610) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=317610) 	and.pred 	%p9, %p25, %p27;
(EngineCore_DP0 pid=317610) 	and.pred 	%p10, %p25, %p28;
(EngineCore_DP0 pid=317610) 	and.pred 	%p11, %p26, %p29;
(EngineCore_DP0 pid=317610) 	and.pred 	%p12, %p26, %p30;
(EngineCore_DP0 pid=317610) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=317610) 	mad.wide.s32 	%rd8, %r96, 2, %rd1;
(EngineCore_DP0 pid=317610) 	mad.wide.s32 	%rd9, %r98, 2, %rd1;
(EngineCore_DP0 pid=317610) 	mad.wide.s32 	%rd10, %r97, 2, %rd1;
(EngineCore_DP0 pid=317610) 	mad.wide.s32 	%rd11, %r99, 2, %rd1;
(EngineCore_DP0 pid=317610) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=317610) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=317610) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=317610) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=317610) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=317610) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=317610) 	cvt.f32.bf16 	%r100, %rs24;
(EngineCore_DP0 pid=317610) 	cvt.f32.bf16 	%r101, %rs26;
(EngineCore_DP0 pid=317610) 	cvt.f32.bf16 	%r102, %rs28;
(EngineCore_DP0 pid=317610) 	cvt.f32.bf16 	%r103, %rs30;
(EngineCore_DP0 pid=317610) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=317610) 	or.b32 	%r104, %r98, 1;
(EngineCore_DP0 pid=317610) 	or.b32 	%r105, %r99, 1;
(EngineCore_DP0 pid=317610) 	or.b32 	%r106, %r99, 2;
(EngineCore_DP0 pid=317610) 	or.b32 	%r107, %r99, 3;
(EngineCore_DP0 pid=317610) 	or.b32 	%r108, %r96, 1;
(EngineCore_DP0 pid=317610) 	or.b32 	%r109, %r97, 1;
(EngineCore_DP0 pid=317610) 	or.b32 	%r110, %r96, 2;
(EngineCore_DP0 pid=317610) 	or.b32 	%r111, %r96, 3;
(EngineCore_DP0 pid=317610) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p31, %r107, %r27;
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p32, %r106, %r27;
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p33, %r105, %r27;
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p34, %r104, %r27;
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p35, %r111, %r27;
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p36, %r110, %r27;
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p37, %r109, %r27;
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p38, %r108, %r27;
(EngineCore_DP0 pid=317610) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=317610) 	and.pred 	%p13, %p25, %p38;
(EngineCore_DP0 pid=317610) 	and.pred 	%p14, %p25, %p34;
(EngineCore_DP0 pid=317610) 	and.pred 	%p15, %p26, %p37;
(EngineCore_DP0 pid=317610) 	and.pred 	%p16, %p26, %p33;
(EngineCore_DP0 pid=317610) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=317610) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=317610) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=317610) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=317610) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=317610) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=317610) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=317610) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=317610) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=317610) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=317610) 	cvt.f32.bf16 	%r112, %rs32;
(EngineCore_DP0 pid=317610) 	cvt.f32.bf16 	%r113, %rs34;
(EngineCore_DP0 pid=317610) 	cvt.f32.bf16 	%r114, %rs36;
(EngineCore_DP0 pid=317610) 	cvt.f32.bf16 	%r115, %rs38;
(EngineCore_DP0 pid=317610) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=317610) 	add.s32 	%r116, %r98, 2;
(EngineCore_DP0 pid=317610) 	add.s32 	%r117, %r97, 2;
(EngineCore_DP0 pid=317610) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p39, %r116, %r27;
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p40, %r117, %r27;
(EngineCore_DP0 pid=317610) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=317610) 	and.pred 	%p17, %p25, %p36;
(EngineCore_DP0 pid=317610) 	and.pred 	%p18, %p25, %p39;
(EngineCore_DP0 pid=317610) 	and.pred 	%p19, %p26, %p40;
(EngineCore_DP0 pid=317610) 	and.pred 	%p20, %p26, %p32;
(EngineCore_DP0 pid=317610) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=317610) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=317610) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=317610) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=317610) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=317610) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=317610) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=317610) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=317610) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=317610) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=317610) 	cvt.f32.bf16 	%r118, %rs40;
(EngineCore_DP0 pid=317610) 	cvt.f32.bf16 	%r119, %rs42;
(EngineCore_DP0 pid=317610) 	cvt.f32.bf16 	%r120, %rs44;
(EngineCore_DP0 pid=317610) 	cvt.f32.bf16 	%r121, %rs46;
(EngineCore_DP0 pid=317610) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=317610) 	add.s32 	%r122, %r98, 3;
(EngineCore_DP0 pid=317610) 	add.s32 	%r123, %r97, 3;
(EngineCore_DP0 pid=317610) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p41, %r122, %r27;
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p42, %r123, %r27;
(EngineCore_DP0 pid=317610) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=317610) 	and.pred 	%p21, %p25, %p35;
(EngineCore_DP0 pid=317610) 	and.pred 	%p22, %p25, %p41;
(EngineCore_DP0 pid=317610) 	and.pred 	%p23, %p26, %p42;
(EngineCore_DP0 pid=317610) 	and.pred 	%p24, %p26, %p31;
(EngineCore_DP0 pid=317610) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=317610) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=317610) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=317610) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=317610) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=317610) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=317610) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=317610) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=317610) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=317610) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=317610) 	cvt.f32.bf16 	%r124, %rs48;
(EngineCore_DP0 pid=317610) 	cvt.f32.bf16 	%r125, %rs50;
(EngineCore_DP0 pid=317610) 	cvt.f32.bf16 	%r126, %rs52;
(EngineCore_DP0 pid=317610) 	cvt.f32.bf16 	%r127, %rs54;
(EngineCore_DP0 pid=317610) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=317610) 	mul.f32 	%r128, %r14, %r100;
(EngineCore_DP0 pid=317610) 	mul.f32 	%r129, %r14, %r101;
(EngineCore_DP0 pid=317610) 	mul.f32 	%r130, %r14, %r102;
(EngineCore_DP0 pid=317610) 	mul.f32 	%r131, %r14, %r103;
(EngineCore_DP0 pid=317610) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=317610) 	cvt.rni.f32.f32 	%r132, %r128;
(EngineCore_DP0 pid=317610) 	cvt.rni.f32.f32 	%r133, %r129;
(EngineCore_DP0 pid=317610) 	cvt.rni.f32.f32 	%r134, %r130;
(EngineCore_DP0 pid=317610) 	cvt.rni.f32.f32 	%r135, %r131;
(EngineCore_DP0 pid=317610) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=317610) 	max.f32 	%r136, %r132, 0fC3000000;
(EngineCore_DP0 pid=317610) 	min.f32 	%r137, %r136, 0f42FE0000;
(EngineCore_DP0 pid=317610) 	max.f32 	%r138, %r133, 0fC3000000;
(EngineCore_DP0 pid=317610) 	min.f32 	%r139, %r138, 0f42FE0000;
(EngineCore_DP0 pid=317610) 	max.f32 	%r140, %r134, 0fC3000000;
(EngineCore_DP0 pid=317610) 	min.f32 	%r141, %r140, 0f42FE0000;
(EngineCore_DP0 pid=317610) 	max.f32 	%r142, %r135, 0fC3000000;
(EngineCore_DP0 pid=317610) 	min.f32 	%r143, %r142, 0f42FE0000;
(EngineCore_DP0 pid=317610) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=317610) 	cvt.rzi.s32.f32 	%r144, %r137;
(EngineCore_DP0 pid=317610) 	cvt.rzi.s32.f32 	%r145, %r139;
(EngineCore_DP0 pid=317610) 	cvt.rzi.s32.f32 	%r146, %r141;
(EngineCore_DP0 pid=317610) 	cvt.rzi.s32.f32 	%r147, %r143;
(EngineCore_DP0 pid=317610) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=317610) 	and.b32 	%r148, %r144, 255;
(EngineCore_DP0 pid=317610) 	and.b32 	%r149, %r145, 255;
(EngineCore_DP0 pid=317610) 	and.b32 	%r150, %r146, 255;
(EngineCore_DP0 pid=317610) 	and.b32 	%r151, %r147, 255;
(EngineCore_DP0 pid=317610) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=317610) 	mul.f32 	%r152, %r14, %r112;
(EngineCore_DP0 pid=317610) 	mul.f32 	%r153, %r14, %r113;
(EngineCore_DP0 pid=317610) 	mul.f32 	%r154, %r14, %r114;
(EngineCore_DP0 pid=317610) 	mul.f32 	%r155, %r14, %r115;
(EngineCore_DP0 pid=317610) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=317610) 	cvt.rni.f32.f32 	%r156, %r152;
(EngineCore_DP0 pid=317610) 	cvt.rni.f32.f32 	%r157, %r153;
(EngineCore_DP0 pid=317610) 	cvt.rni.f32.f32 	%r158, %r154;
(EngineCore_DP0 pid=317610) 	cvt.rni.f32.f32 	%r159, %r155;
(EngineCore_DP0 pid=317610) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=317610) 	mul.f32 	%r160, %r14, %r118;
(EngineCore_DP0 pid=317610) 	mul.f32 	%r161, %r14, %r119;
(EngineCore_DP0 pid=317610) 	mul.f32 	%r162, %r14, %r120;
(EngineCore_DP0 pid=317610) 	mul.f32 	%r163, %r14, %r121;
(EngineCore_DP0 pid=317610) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=317610) 	cvt.rni.f32.f32 	%r164, %r160;
(EngineCore_DP0 pid=317610) 	cvt.rni.f32.f32 	%r165, %r161;
(EngineCore_DP0 pid=317610) 	cvt.rni.f32.f32 	%r166, %r162;
(EngineCore_DP0 pid=317610) 	cvt.rni.f32.f32 	%r167, %r163;
(EngineCore_DP0 pid=317610) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=317610) 	mul.f32 	%r168, %r14, %r124;
(EngineCore_DP0 pid=317610) 	mul.f32 	%r169, %r14, %r125;
(EngineCore_DP0 pid=317610) 	mul.f32 	%r170, %r14, %r126;
(EngineCore_DP0 pid=317610) 	mul.f32 	%r171, %r14, %r127;
(EngineCore_DP0 pid=317610) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=317610) 	cvt.rni.f32.f32 	%r172, %r168;
(EngineCore_DP0 pid=317610) 	cvt.rni.f32.f32 	%r173, %r169;
(EngineCore_DP0 pid=317610) 	cvt.rni.f32.f32 	%r174, %r170;
(EngineCore_DP0 pid=317610) 	cvt.rni.f32.f32 	%r175, %r171;
(EngineCore_DP0 pid=317610) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=317610) 	max.f32 	%r176, %r172, 0fC3000000;
(EngineCore_DP0 pid=317610) 	min.f32 	%r177, %r176, 0f42FE0000;
(EngineCore_DP0 pid=317610) 	max.f32 	%r178, %r173, 0fC3000000;
(EngineCore_DP0 pid=317610) 	min.f32 	%r179, %r178, 0f42FE0000;
(EngineCore_DP0 pid=317610) 	max.f32 	%r180, %r174, 0fC3000000;
(EngineCore_DP0 pid=317610) 	min.f32 	%r181, %r180, 0f42FE0000;
(EngineCore_DP0 pid=317610) 	max.f32 	%r182, %r175, 0fC3000000;
(EngineCore_DP0 pid=317610) 	min.f32 	%r183, %r182, 0f42FE0000;
(EngineCore_DP0 pid=317610) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=317610) 	cvt.rzi.s32.f32 	%r184, %r177;
(EngineCore_DP0 pid=317610) 	cvt.rzi.s32.f32 	%r185, %r179;
(EngineCore_DP0 pid=317610) 	cvt.rzi.s32.f32 	%r186, %r181;
(EngineCore_DP0 pid=317610) 	cvt.rzi.s32.f32 	%r187, %r183;
(EngineCore_DP0 pid=317610) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=317610) 	max.f32 	%r188, %r164, 0fC3000000;
(EngineCore_DP0 pid=317610) 	max.f32 	%r189, %r156, 0fC3000000;
(EngineCore_DP0 pid=317610) 	min.f32 	%r190, %r189, 0f42FE0000;
(EngineCore_DP0 pid=317610) 	min.f32 	%r191, %r188, 0f42FE0000;
(EngineCore_DP0 pid=317610) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=317610) 	cvt.rzi.s32.f32 	%r192, %r191;
(EngineCore_DP0 pid=317610) 	cvt.rzi.s32.f32 	%r193, %r190;
(EngineCore_DP0 pid=317610) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=317610) 	shl.b32 	%r194, %r193, 8;
(EngineCore_DP0 pid=317610) 	shl.b32 	%r195, %r192, 16;
(EngineCore_DP0 pid=317610) 	and.b32 	%r196, %r195, 16711680;
(EngineCore_DP0 pid=317610) 	and.b32 	%r197, %r194, 65280;
(EngineCore_DP0 pid=317610) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=317610) 	or.b32 	%r198, %r197, %r148;
(EngineCore_DP0 pid=317610) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=317610) 	max.f32 	%r199, %r165, 0fC3000000;
(EngineCore_DP0 pid=317610) 	max.f32 	%r200, %r157, 0fC3000000;
(EngineCore_DP0 pid=317610) 	min.f32 	%r201, %r200, 0f42FE0000;
(EngineCore_DP0 pid=317610) 	min.f32 	%r202, %r199, 0f42FE0000;
(EngineCore_DP0 pid=317610) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=317610) 	cvt.rzi.s32.f32 	%r203, %r202;
(EngineCore_DP0 pid=317610) 	cvt.rzi.s32.f32 	%r204, %r201;
(EngineCore_DP0 pid=317610) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=317610) 	shl.b32 	%r205, %r204, 8;
(EngineCore_DP0 pid=317610) 	shl.b32 	%r206, %r203, 16;
(EngineCore_DP0 pid=317610) 	and.b32 	%r207, %r206, 16711680;
(EngineCore_DP0 pid=317610) 	and.b32 	%r208, %r205, 65280;
(EngineCore_DP0 pid=317610) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=317610) 	or.b32 	%r209, %r208, %r149;
(EngineCore_DP0 pid=317610) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=317610) 	max.f32 	%r210, %r166, 0fC3000000;
(EngineCore_DP0 pid=317610) 	max.f32 	%r211, %r158, 0fC3000000;
(EngineCore_DP0 pid=317610) 	min.f32 	%r212, %r211, 0f42FE0000;
(EngineCore_DP0 pid=317610) 	min.f32 	%r213, %r210, 0f42FE0000;
(EngineCore_DP0 pid=317610) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=317610) 	cvt.rzi.s32.f32 	%r214, %r213;
(EngineCore_DP0 pid=317610) 	cvt.rzi.s32.f32 	%r215, %r212;
(EngineCore_DP0 pid=317610) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=317610) 	shl.b32 	%r216, %r215, 8;
(EngineCore_DP0 pid=317610) 	shl.b32 	%r217, %r214, 16;
(EngineCore_DP0 pid=317610) 	and.b32 	%r218, %r217, 16711680;
(EngineCore_DP0 pid=317610) 	and.b32 	%r219, %r216, 65280;
(EngineCore_DP0 pid=317610) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=317610) 	or.b32 	%r220, %r219, %r150;
(EngineCore_DP0 pid=317610) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=317610) 	max.f32 	%r221, %r167, 0fC3000000;
(EngineCore_DP0 pid=317610) 	max.f32 	%r222, %r159, 0fC3000000;
(EngineCore_DP0 pid=317610) 	min.f32 	%r223, %r222, 0f42FE0000;
(EngineCore_DP0 pid=317610) 	min.f32 	%r224, %r221, 0f42FE0000;
(EngineCore_DP0 pid=317610) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=317610) 	cvt.rzi.s32.f32 	%r225, %r224;
(EngineCore_DP0 pid=317610) 	cvt.rzi.s32.f32 	%r226, %r223;
(EngineCore_DP0 pid=317610) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=317610) 	shl.b32 	%r227, %r226, 8;
(EngineCore_DP0 pid=317610) 	shl.b32 	%r228, %r225, 16;
(EngineCore_DP0 pid=317610) 	and.b32 	%r229, %r228, 16711680;
(EngineCore_DP0 pid=317610) 	and.b32 	%r230, %r227, 65280;
(EngineCore_DP0 pid=317610) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=317610) 	or.b32 	%r231, %r230, %r151;
(EngineCore_DP0 pid=317610) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=317610) 	or.b32 	%r232, %r198, %r196;
(EngineCore_DP0 pid=317610) 	or.b32 	%r233, %r209, %r207;
(EngineCore_DP0 pid=317610) 	or.b32 	%r234, %r220, %r218;
(EngineCore_DP0 pid=317610) 	or.b32 	%r235, %r231, %r229;
(EngineCore_DP0 pid=317610) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=317610) 	shl.b32 	%r236, %r184, 24;
(EngineCore_DP0 pid=317610) 	shl.b32 	%r237, %r185, 24;
(EngineCore_DP0 pid=317610) 	shl.b32 	%r238, %r186, 24;
(EngineCore_DP0 pid=317610) 	shl.b32 	%r239, %r187, 24;
(EngineCore_DP0 pid=317610) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=317610) 	or.b32 	%r82, %r232, %r236;
(EngineCore_DP0 pid=317610) 	or.b32 	%r83, %r233, %r237;
(EngineCore_DP0 pid=317610) 	or.b32 	%r84, %r234, %r238;
(EngineCore_DP0 pid=317610) 	or.b32 	%r85, %r235, %r239;
(EngineCore_DP0 pid=317610) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=317610) 	mad.wide.s32 	%rd24, %r86, 4, %rd2;
(EngineCore_DP0 pid=317610) 	add.s64 	%rd25, %rd24, 8;
(EngineCore_DP0 pid=317610) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	@%p25 st.global.v2.b32 [ %rd24 + 0 ], { %r82, %r83 };
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	// begin inline asm
(EngineCore_DP0 pid=317610) 	@%p26 st.global.v2.b32 [ %rd25 + 0 ], { %r84, %r85 };
(EngineCore_DP0 pid=317610) 	// end inline asm
(EngineCore_DP0 pid=317610) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=317610) 	add.s32 	%r243, %r243, 2048;
(EngineCore_DP0 pid=317610) 	setp.lt.s32 	%p43, %r243, %r15;
(EngineCore_DP0 pid=317610) 	@%p43 bra 	$L__BB0_6;
(EngineCore_DP0 pid=317610) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=317610) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=317610) 	ret;
(EngineCore_DP0 pid=317610) $L__tmp3:
(EngineCore_DP0 pid=317610) $L__func_end0:
(EngineCore_DP0 pid=317610)                                         // -- End function
(EngineCore_DP0 pid=317610) }
(EngineCore_DP0 pid=317610) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=317610) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=317610) 	.section	.debug_abbrev
(EngineCore_DP0 pid=317610) 	{
(EngineCore_DP0 pid=317610) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=317610) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=317610) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=317610) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=317610) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=317610) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=317610) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=317610) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=317610) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=317610) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=317610) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=317610) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=317610) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=317610) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=317610) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=317610) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=317610) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=317610) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=317610) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=317610) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=317610) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=317610) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=317610) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=317610) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=317610) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=317610) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=317610) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=317610) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=317610) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=317610) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=317610) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=317610) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=317610) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=317610) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=317610) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=317610) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=317610) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=317610) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=317610) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=317610) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=317610) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=317610) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=317610) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=317610) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=317610) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=317610) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=317610) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=317610) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=317610) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=317610) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=317610) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=317610) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=317610) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=317610) 	}
(EngineCore_DP0 pid=317610) 	.section	.debug_info
(EngineCore_DP0 pid=317610) 	{
(EngineCore_DP0 pid=317610) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=317610) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=317610) .b8 0
(EngineCore_DP0 pid=317610) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=317610) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=317610) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=317610) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=317610) .b8 114
(EngineCore_DP0 pid=317610) .b8 105
(EngineCore_DP0 pid=317610) .b8 116
(EngineCore_DP0 pid=317610) .b8 111
(EngineCore_DP0 pid=317610) .b8 110
(EngineCore_DP0 pid=317610) .b8 0
(EngineCore_DP0 pid=317610) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=317610) .b8 0
(EngineCore_DP0 pid=317610) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=317610) .b8 117
(EngineCore_DP0 pid=317610) .b8 97
(EngineCore_DP0 pid=317610) .b8 110
(EngineCore_DP0 pid=317610) .b8 116
(EngineCore_DP0 pid=317610) .b8 95
(EngineCore_DP0 pid=317610) .b8 115
(EngineCore_DP0 pid=317610) .b8 108
(EngineCore_DP0 pid=317610) .b8 105
(EngineCore_DP0 pid=317610) .b8 100
(EngineCore_DP0 pid=317610) .b8 101
(EngineCore_DP0 pid=317610) .b8 95
(EngineCore_DP0 pid=317610) .b8 116
(EngineCore_DP0 pid=317610) .b8 117
(EngineCore_DP0 pid=317610) .b8 110
(EngineCore_DP0 pid=317610) .b8 101
(EngineCore_DP0 pid=317610) .b8 100
(EngineCore_DP0 pid=317610) .b8 95
(EngineCore_DP0 pid=317610) .b8 76
(EngineCore_DP0 pid=317610) .b8 108
(EngineCore_DP0 pid=317610) .b8 97
(EngineCore_DP0 pid=317610) .b8 109
(EngineCore_DP0 pid=317610) .b8 97
(EngineCore_DP0 pid=317610) .b8 51
(EngineCore_DP0 pid=317610) .b8 46
(EngineCore_DP0 pid=317610) .b8 50
(EngineCore_DP0 pid=317610) .b8 45
(EngineCore_DP0 pid=317610) .b8 49
(EngineCore_DP0 pid=317610) .b8 66
(EngineCore_DP0 pid=317610) .b8 46
(EngineCore_DP0 pid=317610) .b8 112
(EngineCore_DP0 pid=317610) .b8 121
(EngineCore_DP0 pid=317610) .b8 0
(EngineCore_DP0 pid=317610) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=317610) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=317610) .b8 114
(EngineCore_DP0 pid=317610) .b8 111
(EngineCore_DP0 pid=317610) .b8 111
(EngineCore_DP0 pid=317610) .b8 116
(EngineCore_DP0 pid=317610) .b8 47
(EngineCore_DP0 pid=317610) .b8 118
(EngineCore_DP0 pid=317610) .b8 108
(EngineCore_DP0 pid=317610) .b8 108
(EngineCore_DP0 pid=317610) .b8 109
(EngineCore_DP0 pid=317610) .b8 98
(EngineCore_DP0 pid=317610) .b8 101
(EngineCore_DP0 pid=317610) .b8 110
(EngineCore_DP0 pid=317610) .b8 99
(EngineCore_DP0 pid=317610) .b8 104
(EngineCore_DP0 pid=317610) .b8 47
(EngineCore_DP0 pid=317610) .b8 115
(EngineCore_DP0 pid=317610) .b8 108
(EngineCore_DP0 pid=317610) .b8 105
(EngineCore_DP0 pid=317610) .b8 100
(EngineCore_DP0 pid=317610) .b8 101
(EngineCore_DP0 pid=317610) .b8 115
(EngineCore_DP0 pid=317610) .b8 112
(EngineCore_DP0 pid=317610) .b8 97
(EngineCore_DP0 pid=317610) .b8 114
(EngineCore_DP0 pid=317610) .b8 115
(EngineCore_DP0 pid=317610) .b8 101
(EngineCore_DP0 pid=317610) .b8 47
(EngineCore_DP0 pid=317610) .b8 99
(EngineCore_DP0 pid=317610) .b8 115
(EngineCore_DP0 pid=317610) .b8 114
(EngineCore_DP0 pid=317610) .b8 99
(EngineCore_DP0 pid=317610) .b8 47
(EngineCore_DP0 pid=317610) .b8 102
(EngineCore_DP0 pid=317610) .b8 117
(EngineCore_DP0 pid=317610) .b8 115
(EngineCore_DP0 pid=317610) .b8 101
(EngineCore_DP0 pid=317610) .b8 100
(EngineCore_DP0 pid=317610) .b8 95
(EngineCore_DP0 pid=317610) .b8 113
(EngineCore_DP0 pid=317610) .b8 117
(EngineCore_DP0 pid=317610) .b8 97
(EngineCore_DP0 pid=317610) .b8 110
(EngineCore_DP0 pid=317610) .b8 116
(EngineCore_DP0 pid=317610) .b8 95
(EngineCore_DP0 pid=317610) .b8 115
(EngineCore_DP0 pid=317610) .b8 108
(EngineCore_DP0 pid=317610) .b8 105
(EngineCore_DP0 pid=317610) .b8 100
(EngineCore_DP0 pid=317610) .b8 101
(EngineCore_DP0 pid=317610) .b8 95
(EngineCore_DP0 pid=317610) .b8 116
(EngineCore_DP0 pid=317610) .b8 114
(EngineCore_DP0 pid=317610) .b8 105
(EngineCore_DP0 pid=317610) .b8 116
(EngineCore_DP0 pid=317610) .b8 111
(EngineCore_DP0 pid=317610) .b8 110
(EngineCore_DP0 pid=317610) .b8 47
(EngineCore_DP0 pid=317610) .b8 98
(EngineCore_DP0 pid=317610) .b8 117
(EngineCore_DP0 pid=317610) .b8 105
(EngineCore_DP0 pid=317610) .b8 108
(EngineCore_DP0 pid=317610) .b8 100
(EngineCore_DP0 pid=317610) .b8 47
(EngineCore_DP0 pid=317610) .b8 71
(EngineCore_DP0 pid=317610) .b8 66
(EngineCore_DP0 pid=317610) .b8 49
(EngineCore_DP0 pid=317610) .b8 48
(EngineCore_DP0 pid=317610) .b8 95
(EngineCore_DP0 pid=317610) .b8 99
(EngineCore_DP0 pid=317610) .b8 99
(EngineCore_DP0 pid=317610) .b8 49
(EngineCore_DP0 pid=317610) .b8 50
(EngineCore_DP0 pid=317610) .b8 49
(EngineCore_DP0 pid=317610) .b8 95
(EngineCore_DP0 pid=317610) .b8 112
(EngineCore_DP0 pid=317610) .b8 121
(EngineCore_DP0 pid=317610) .b8 51
(EngineCore_DP0 pid=317610) .b8 49
(EngineCore_DP0 pid=317610) .b8 50
(EngineCore_DP0 pid=317610) .b8 95
(EngineCore_DP0 pid=317610) .b8 99
(EngineCore_DP0 pid=317610) .b8 117
(EngineCore_DP0 pid=317610) .b8 49
(EngineCore_DP0 pid=317610) .b8 50
(EngineCore_DP0 pid=317610) .b8 57
(EngineCore_DP0 pid=317610) .b8 95
(EngineCore_DP0 pid=317610) .b8 97
(EngineCore_DP0 pid=317610) .b8 97
(EngineCore_DP0 pid=317610) .b8 114
(EngineCore_DP0 pid=317610) .b8 99
(EngineCore_DP0 pid=317610) .b8 104
(EngineCore_DP0 pid=317610) .b8 54
(EngineCore_DP0 pid=317610) .b8 52
(EngineCore_DP0 pid=317610) .b8 0
(EngineCore_DP0 pid=317610) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=317610) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=317610) .b8 113
(EngineCore_DP0 pid=317610) .b8 117
(EngineCore_DP0 pid=317610) .b8 97
(EngineCore_DP0 pid=317610) .b8 110
(EngineCore_DP0 pid=317610) .b8 116
(EngineCore_DP0 pid=317610) .b8 95
(EngineCore_DP0 pid=317610) .b8 115
(EngineCore_DP0 pid=317610) .b8 108
(EngineCore_DP0 pid=317610) .b8 105
(EngineCore_DP0 pid=317610) .b8 100
(EngineCore_DP0 pid=317610) .b8 101
(EngineCore_DP0 pid=317610) .b8 95
(EngineCore_DP0 pid=317610) .b8 105
(EngineCore_DP0 pid=317610) .b8 110
(EngineCore_DP0 pid=317610) .b8 116
(EngineCore_DP0 pid=317610) .b8 56
(EngineCore_DP0 pid=317610) .b8 95
(EngineCore_DP0 pid=317610) .b8 107
(EngineCore_DP0 pid=317610) .b8 101
(EngineCore_DP0 pid=317610) .b8 114
(EngineCore_DP0 pid=317610) .b8 110
(EngineCore_DP0 pid=317610) .b8 101
(EngineCore_DP0 pid=317610) .b8 108
(EngineCore_DP0 pid=317610) .b8 0
(EngineCore_DP0 pid=317610) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=317610) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=317610) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=317610) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=317610) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=317610) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=317610) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=317610) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=317610) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=317610) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=317610) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=317610) .b8 1
(EngineCore_DP0 pid=317610) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=317610) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=317610) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=317610) 	}
(EngineCore_DP0 pid=317610) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=317610) 
(EngineCore_DP0 pid=317610) ================================================================
(EngineCore_DP0 pid=317610) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=317610) 
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpchmthwyb.ptx', '-o', '/tmp/tmpchmthwyb.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866] 
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866] 
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866] 
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpchmthwyb.ptx -o /tmp/tmpchmthwyb.ptx.o
(EngineCore_DP0 pid=317610) ERROR 01-25 19:01:04 [core.py:866] 

STDERR:
[2026-01-25 19:00:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:00:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:00:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:00:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:00:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:00:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:00:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:00:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:00:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:00:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:00:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:00:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:00:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:00:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:00:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:00:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:00:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:00:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:00:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=317610) [2026-01-25 19:00:54] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=317610) [2026-01-25 19:00:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=317610) [2026-01-25 19:00:54] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=317610) [2026-01-25 19:00:54] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=317610) [2026-01-25 19:00:54] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=317610) [2026-01-25 19:00:54] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=317610) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=317610) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.24s/it]
(EngineCore_DP0 pid=317610) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.24s/it]
(EngineCore_DP0 pid=317610) 
(EngineCore_DP0 pid=317610) [2026-01-25 19:01:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=317610) [2026-01-25 19:01:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=317610) [2026-01-25 19:01:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=317610) [2026-01-25 19:01:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=317610) [2026-01-25 19:01:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=317610) [2026-01-25 19:01:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=317610) [2026-01-25 19:01:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=317610) [2026-01-25 19:01:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=317610) Process EngineCore_DP0:
(EngineCore_DP0 pid=317610) Traceback (most recent call last):
(EngineCore_DP0 pid=317610)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=317610)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=317610)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=317610)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=317610) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpchmthwyb.ptx', '-o', '/tmp/tmpchmthwyb.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=317610) 
(EngineCore_DP0 pid=317610) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=317610) 
(EngineCore_DP0 pid=317610) Traceback (most recent call last):
(EngineCore_DP0 pid=317610)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=317610)     self.run()
(EngineCore_DP0 pid=317610)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=317610)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=317610)     raise e
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=317610)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=317610)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=317610)     super().__init__(
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=317610)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=317610)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=317610)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=317610)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=317610)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=317610)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=317610)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=317610)     return func(*args, **kwargs)
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=317610)     return func(*args, **kwargs)
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=317610)     self.model_runner.profile_run()
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=317610)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=317610)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=317610)     return func(*args, **kwargs)
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=317610)     outputs = self.model(
(EngineCore_DP0 pid=317610)               ^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=317610)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=317610)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=317610)     model_output = self.model(
(EngineCore_DP0 pid=317610)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=317610)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=317610)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=317610)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=317610)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=317610)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=317610)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=317610)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=317610)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=317610)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=317610)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=317610)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=317610)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=317610)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=317610)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=317610)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=317610)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=317610)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=317610)     return self._linear_fn(
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=317610)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=317610)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=317610)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=317610)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=317610)     return fn(input, L)
(EngineCore_DP0 pid=317610)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=317610)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=317610)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=317610)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=317610)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=317610)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=317610)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=317610)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=317610)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=317610)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=317610)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=317610)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=317610)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=317610)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=317610)     raise PTXASError(error)
(EngineCore_DP0 pid=317610) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=317610) `ptxas` stderr:
(EngineCore_DP0 pid=317610) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=317610) 
(EngineCore_DP0 pid=317610) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpchmthwyb.ptx -o /tmp/tmpchmthwyb.ptx.o
(EngineCore_DP0 pid=317610) 
[rank0]:[W125 19:01:05.394899796 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 19:01:06
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:01:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:01:21 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=318245) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=318245) 
(EngineCore_DP0 pid=318245) 
(EngineCore_DP0 pid=318245) ================================================================
(EngineCore_DP0 pid=318245) Internal Triton PTX codegen error
(EngineCore_DP0 pid=318245) `ptxas` stderr:
(EngineCore_DP0 pid=318245) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=318245) 
(EngineCore_DP0 pid=318245) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmppjkfwpkv.ptx -o /tmp/tmppjkfwpkv.ptx.o
(EngineCore_DP0 pid=318245) 
(EngineCore_DP0 pid=318245) 
(EngineCore_DP0 pid=318245) //
(EngineCore_DP0 pid=318245) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=318245) //
(EngineCore_DP0 pid=318245) 
(EngineCore_DP0 pid=318245) .version 8.7
(EngineCore_DP0 pid=318245) .target sm_121a
(EngineCore_DP0 pid=318245) .address_size 64
(EngineCore_DP0 pid=318245) 
(EngineCore_DP0 pid=318245) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=318245) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=318245)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=318245) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=318245) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=318245) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=318245) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=318245) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=318245) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=318245) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=318245) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=318245) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=318245) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=318245) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=318245) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=318245) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=318245) )
(EngineCore_DP0 pid=318245) .reqntid 512
(EngineCore_DP0 pid=318245) {
(EngineCore_DP0 pid=318245) 	.reg .pred 	%p<45>;
(EngineCore_DP0 pid=318245) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=318245) 	.reg .b32 	%r<244>;
(EngineCore_DP0 pid=318245) 	.reg .b64 	%rd<26>;
(EngineCore_DP0 pid=318245) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=318245) $L__func_begin0:
(EngineCore_DP0 pid=318245) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=318245) 
(EngineCore_DP0 pid=318245) // %bb.0:
(EngineCore_DP0 pid=318245) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=318245) 	ld.param.b32 	%r28, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=318245) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=318245) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=318245) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=318245) $L__tmp0:
(EngineCore_DP0 pid=318245) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=318245) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=318245) 	ld.param.b32 	%r31, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=318245) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=318245) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=318245) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=318245) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=318245) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=318245) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=318245) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=318245) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=318245) 	mov.b32 	%r242, 0f2B8CBCCC;
(EngineCore_DP0 pid=318245) 	setp.eq.b32 	%p44, %r2, 0;
(EngineCore_DP0 pid=318245) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=318245) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=318245) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=318245) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=318245) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=318245) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=318245) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=318245) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=318245) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=318245) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=318245) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=318245) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=318245) 	mov.b32 	%r240, 0f00000000;
(EngineCore_DP0 pid=318245) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=318245) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=318245) 	mov.b32 	%r241, %r49;
(EngineCore_DP0 pid=318245) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=318245) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=318245) 	add.s32 	%r59, %r4, %r241;
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=318245) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=318245) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=318245) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=318245) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=318245) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=318245) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=318245) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=318245) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=318245) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=318245) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=318245) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=318245) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=318245) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=318245) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=318245) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=318245) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=318245) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=318245) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=318245) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=318245) $L__tmp1:
(EngineCore_DP0 pid=318245) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	bar.sync 	0;
(EngineCore_DP0 pid=318245) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=318245) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=318245) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=318245) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=318245) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=318245) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=318245) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=318245) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=318245) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=318245) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=318245) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=318245) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=318245) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=318245) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=318245) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=318245) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=318245) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=318245) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=318245) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	bar.sync 	0;
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=318245) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=318245) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=318245) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=318245) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=318245) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=318245) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=318245) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=318245) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	@%p44 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	bar.sync 	0;
(EngineCore_DP0 pid=318245) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=318245) $L__tmp2:
(EngineCore_DP0 pid=318245) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=318245) 	max.f32 	%r240, %r240, %r77;
(EngineCore_DP0 pid=318245) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=318245) 	add.s32 	%r241, %r241, 4096;
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p6, %r241, %r28;
(EngineCore_DP0 pid=318245) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=318245) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=318245) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=318245) 	max.f32 	%r242, %r240, 0f2B8CBCCC;
(EngineCore_DP0 pid=318245) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=318245) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=318245) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=318245) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=318245) 	div.full.f32 	%r80, %r242, %r79;
(EngineCore_DP0 pid=318245) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=318245) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=318245) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=318245) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=318245) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	@%p44 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=318245) 	shl.b32 	%r15, %r29, 1;
(EngineCore_DP0 pid=318245) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=318245) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=318245) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=318245) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=318245) 	ld.param.b32 	%r33, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=318245) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=318245) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=318245) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=318245) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=318245) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=318245) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=318245) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=318245) 	div.full.f32 	%r14, %r79, %r242;
(EngineCore_DP0 pid=318245) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=318245) 	mov.b32 	%r243, 0;
(EngineCore_DP0 pid=318245) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=318245)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=318245) 	.loc	1 313 31                        // quant_slide_tuned_Llama3.2-1B.py:313:31
(EngineCore_DP0 pid=318245) 	add.s32 	%r86, %r16, %r243;
(EngineCore_DP0 pid=318245) 	add.s32 	%r87, %r243, 1;
(EngineCore_DP0 pid=318245) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=318245) 	add.s32 	%r88, %r86, 2;
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p25, %r86, %r15;
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p26, %r88, %r15;
(EngineCore_DP0 pid=318245) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=318245) 	shr.u32 	%r89, %r86, 1;
(EngineCore_DP0 pid=318245) 	shr.u32 	%r90, %r88, 1;
(EngineCore_DP0 pid=318245) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=318245) 	shr.u32 	%r91, %r87, 31;
(EngineCore_DP0 pid=318245) 	add.s32 	%r92, %r87, %r91;
(EngineCore_DP0 pid=318245) 	and.b32 	%r93, %r92, 2147483646;
(EngineCore_DP0 pid=318245) 	sub.s32 	%r94, %r87, %r93;
(EngineCore_DP0 pid=318245) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=318245) 	shl.b32 	%r95, %r94, 1;
(EngineCore_DP0 pid=318245) 	.loc	1 319 22                        // quant_slide_tuned_Llama3.2-1B.py:319:22
(EngineCore_DP0 pid=318245) 	mul.lo.s32 	%r96, %r89, 6;
(EngineCore_DP0 pid=318245) 	mul.lo.s32 	%r97, %r90, 6;
(EngineCore_DP0 pid=318245) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=318245) 	add.s32 	%r98, %r96, %r95;
(EngineCore_DP0 pid=318245) 	add.s32 	%r99, %r97, %r95;
(EngineCore_DP0 pid=318245) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p27, %r96, %r27;
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p28, %r98, %r27;
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p29, %r97, %r27;
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p30, %r99, %r27;
(EngineCore_DP0 pid=318245) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=318245) 	and.pred 	%p9, %p25, %p27;
(EngineCore_DP0 pid=318245) 	and.pred 	%p10, %p25, %p28;
(EngineCore_DP0 pid=318245) 	and.pred 	%p11, %p26, %p29;
(EngineCore_DP0 pid=318245) 	and.pred 	%p12, %p26, %p30;
(EngineCore_DP0 pid=318245) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=318245) 	mad.wide.s32 	%rd8, %r96, 2, %rd1;
(EngineCore_DP0 pid=318245) 	mad.wide.s32 	%rd9, %r98, 2, %rd1;
(EngineCore_DP0 pid=318245) 	mad.wide.s32 	%rd10, %r97, 2, %rd1;
(EngineCore_DP0 pid=318245) 	mad.wide.s32 	%rd11, %r99, 2, %rd1;
(EngineCore_DP0 pid=318245) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=318245) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=318245) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=318245) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=318245) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=318245) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=318245) 	cvt.f32.bf16 	%r100, %rs24;
(EngineCore_DP0 pid=318245) 	cvt.f32.bf16 	%r101, %rs26;
(EngineCore_DP0 pid=318245) 	cvt.f32.bf16 	%r102, %rs28;
(EngineCore_DP0 pid=318245) 	cvt.f32.bf16 	%r103, %rs30;
(EngineCore_DP0 pid=318245) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=318245) 	or.b32 	%r104, %r98, 1;
(EngineCore_DP0 pid=318245) 	or.b32 	%r105, %r99, 1;
(EngineCore_DP0 pid=318245) 	or.b32 	%r106, %r99, 2;
(EngineCore_DP0 pid=318245) 	or.b32 	%r107, %r99, 3;
(EngineCore_DP0 pid=318245) 	or.b32 	%r108, %r96, 1;
(EngineCore_DP0 pid=318245) 	or.b32 	%r109, %r97, 1;
(EngineCore_DP0 pid=318245) 	or.b32 	%r110, %r96, 2;
(EngineCore_DP0 pid=318245) 	or.b32 	%r111, %r96, 3;
(EngineCore_DP0 pid=318245) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p31, %r107, %r27;
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p32, %r106, %r27;
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p33, %r105, %r27;
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p34, %r104, %r27;
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p35, %r111, %r27;
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p36, %r110, %r27;
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p37, %r109, %r27;
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p38, %r108, %r27;
(EngineCore_DP0 pid=318245) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=318245) 	and.pred 	%p13, %p25, %p38;
(EngineCore_DP0 pid=318245) 	and.pred 	%p14, %p25, %p34;
(EngineCore_DP0 pid=318245) 	and.pred 	%p15, %p26, %p37;
(EngineCore_DP0 pid=318245) 	and.pred 	%p16, %p26, %p33;
(EngineCore_DP0 pid=318245) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=318245) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=318245) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=318245) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=318245) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=318245) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=318245) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=318245) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=318245) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=318245) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=318245) 	cvt.f32.bf16 	%r112, %rs32;
(EngineCore_DP0 pid=318245) 	cvt.f32.bf16 	%r113, %rs34;
(EngineCore_DP0 pid=318245) 	cvt.f32.bf16 	%r114, %rs36;
(EngineCore_DP0 pid=318245) 	cvt.f32.bf16 	%r115, %rs38;
(EngineCore_DP0 pid=318245) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=318245) 	add.s32 	%r116, %r98, 2;
(EngineCore_DP0 pid=318245) 	add.s32 	%r117, %r97, 2;
(EngineCore_DP0 pid=318245) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p39, %r116, %r27;
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p40, %r117, %r27;
(EngineCore_DP0 pid=318245) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=318245) 	and.pred 	%p17, %p25, %p36;
(EngineCore_DP0 pid=318245) 	and.pred 	%p18, %p25, %p39;
(EngineCore_DP0 pid=318245) 	and.pred 	%p19, %p26, %p40;
(EngineCore_DP0 pid=318245) 	and.pred 	%p20, %p26, %p32;
(EngineCore_DP0 pid=318245) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=318245) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=318245) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=318245) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=318245) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=318245) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=318245) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=318245) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=318245) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=318245) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=318245) 	cvt.f32.bf16 	%r118, %rs40;
(EngineCore_DP0 pid=318245) 	cvt.f32.bf16 	%r119, %rs42;
(EngineCore_DP0 pid=318245) 	cvt.f32.bf16 	%r120, %rs44;
(EngineCore_DP0 pid=318245) 	cvt.f32.bf16 	%r121, %rs46;
(EngineCore_DP0 pid=318245) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=318245) 	add.s32 	%r122, %r98, 3;
(EngineCore_DP0 pid=318245) 	add.s32 	%r123, %r97, 3;
(EngineCore_DP0 pid=318245) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p41, %r122, %r27;
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p42, %r123, %r27;
(EngineCore_DP0 pid=318245) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=318245) 	and.pred 	%p21, %p25, %p35;
(EngineCore_DP0 pid=318245) 	and.pred 	%p22, %p25, %p41;
(EngineCore_DP0 pid=318245) 	and.pred 	%p23, %p26, %p42;
(EngineCore_DP0 pid=318245) 	and.pred 	%p24, %p26, %p31;
(EngineCore_DP0 pid=318245) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=318245) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=318245) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=318245) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=318245) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=318245) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=318245) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=318245) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=318245) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=318245) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=318245) 	cvt.f32.bf16 	%r124, %rs48;
(EngineCore_DP0 pid=318245) 	cvt.f32.bf16 	%r125, %rs50;
(EngineCore_DP0 pid=318245) 	cvt.f32.bf16 	%r126, %rs52;
(EngineCore_DP0 pid=318245) 	cvt.f32.bf16 	%r127, %rs54;
(EngineCore_DP0 pid=318245) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=318245) 	mul.f32 	%r128, %r14, %r100;
(EngineCore_DP0 pid=318245) 	mul.f32 	%r129, %r14, %r101;
(EngineCore_DP0 pid=318245) 	mul.f32 	%r130, %r14, %r102;
(EngineCore_DP0 pid=318245) 	mul.f32 	%r131, %r14, %r103;
(EngineCore_DP0 pid=318245) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=318245) 	cvt.rni.f32.f32 	%r132, %r128;
(EngineCore_DP0 pid=318245) 	cvt.rni.f32.f32 	%r133, %r129;
(EngineCore_DP0 pid=318245) 	cvt.rni.f32.f32 	%r134, %r130;
(EngineCore_DP0 pid=318245) 	cvt.rni.f32.f32 	%r135, %r131;
(EngineCore_DP0 pid=318245) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=318245) 	max.f32 	%r136, %r132, 0fC3000000;
(EngineCore_DP0 pid=318245) 	min.f32 	%r137, %r136, 0f42FE0000;
(EngineCore_DP0 pid=318245) 	max.f32 	%r138, %r133, 0fC3000000;
(EngineCore_DP0 pid=318245) 	min.f32 	%r139, %r138, 0f42FE0000;
(EngineCore_DP0 pid=318245) 	max.f32 	%r140, %r134, 0fC3000000;
(EngineCore_DP0 pid=318245) 	min.f32 	%r141, %r140, 0f42FE0000;
(EngineCore_DP0 pid=318245) 	max.f32 	%r142, %r135, 0fC3000000;
(EngineCore_DP0 pid=318245) 	min.f32 	%r143, %r142, 0f42FE0000;
(EngineCore_DP0 pid=318245) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=318245) 	cvt.rzi.s32.f32 	%r144, %r137;
(EngineCore_DP0 pid=318245) 	cvt.rzi.s32.f32 	%r145, %r139;
(EngineCore_DP0 pid=318245) 	cvt.rzi.s32.f32 	%r146, %r141;
(EngineCore_DP0 pid=318245) 	cvt.rzi.s32.f32 	%r147, %r143;
(EngineCore_DP0 pid=318245) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=318245) 	and.b32 	%r148, %r144, 255;
(EngineCore_DP0 pid=318245) 	and.b32 	%r149, %r145, 255;
(EngineCore_DP0 pid=318245) 	and.b32 	%r150, %r146, 255;
(EngineCore_DP0 pid=318245) 	and.b32 	%r151, %r147, 255;
(EngineCore_DP0 pid=318245) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=318245) 	mul.f32 	%r152, %r14, %r112;
(EngineCore_DP0 pid=318245) 	mul.f32 	%r153, %r14, %r113;
(EngineCore_DP0 pid=318245) 	mul.f32 	%r154, %r14, %r114;
(EngineCore_DP0 pid=318245) 	mul.f32 	%r155, %r14, %r115;
(EngineCore_DP0 pid=318245) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=318245) 	cvt.rni.f32.f32 	%r156, %r152;
(EngineCore_DP0 pid=318245) 	cvt.rni.f32.f32 	%r157, %r153;
(EngineCore_DP0 pid=318245) 	cvt.rni.f32.f32 	%r158, %r154;
(EngineCore_DP0 pid=318245) 	cvt.rni.f32.f32 	%r159, %r155;
(EngineCore_DP0 pid=318245) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=318245) 	mul.f32 	%r160, %r14, %r118;
(EngineCore_DP0 pid=318245) 	mul.f32 	%r161, %r14, %r119;
(EngineCore_DP0 pid=318245) 	mul.f32 	%r162, %r14, %r120;
(EngineCore_DP0 pid=318245) 	mul.f32 	%r163, %r14, %r121;
(EngineCore_DP0 pid=318245) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=318245) 	cvt.rni.f32.f32 	%r164, %r160;
(EngineCore_DP0 pid=318245) 	cvt.rni.f32.f32 	%r165, %r161;
(EngineCore_DP0 pid=318245) 	cvt.rni.f32.f32 	%r166, %r162;
(EngineCore_DP0 pid=318245) 	cvt.rni.f32.f32 	%r167, %r163;
(EngineCore_DP0 pid=318245) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=318245) 	mul.f32 	%r168, %r14, %r124;
(EngineCore_DP0 pid=318245) 	mul.f32 	%r169, %r14, %r125;
(EngineCore_DP0 pid=318245) 	mul.f32 	%r170, %r14, %r126;
(EngineCore_DP0 pid=318245) 	mul.f32 	%r171, %r14, %r127;
(EngineCore_DP0 pid=318245) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=318245) 	cvt.rni.f32.f32 	%r172, %r168;
(EngineCore_DP0 pid=318245) 	cvt.rni.f32.f32 	%r173, %r169;
(EngineCore_DP0 pid=318245) 	cvt.rni.f32.f32 	%r174, %r170;
(EngineCore_DP0 pid=318245) 	cvt.rni.f32.f32 	%r175, %r171;
(EngineCore_DP0 pid=318245) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=318245) 	max.f32 	%r176, %r172, 0fC3000000;
(EngineCore_DP0 pid=318245) 	min.f32 	%r177, %r176, 0f42FE0000;
(EngineCore_DP0 pid=318245) 	max.f32 	%r178, %r173, 0fC3000000;
(EngineCore_DP0 pid=318245) 	min.f32 	%r179, %r178, 0f42FE0000;
(EngineCore_DP0 pid=318245) 	max.f32 	%r180, %r174, 0fC3000000;
(EngineCore_DP0 pid=318245) 	min.f32 	%r181, %r180, 0f42FE0000;
(EngineCore_DP0 pid=318245) 	max.f32 	%r182, %r175, 0fC3000000;
(EngineCore_DP0 pid=318245) 	min.f32 	%r183, %r182, 0f42FE0000;
(EngineCore_DP0 pid=318245) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=318245) 	cvt.rzi.s32.f32 	%r184, %r177;
(EngineCore_DP0 pid=318245) 	cvt.rzi.s32.f32 	%r185, %r179;
(EngineCore_DP0 pid=318245) 	cvt.rzi.s32.f32 	%r186, %r181;
(EngineCore_DP0 pid=318245) 	cvt.rzi.s32.f32 	%r187, %r183;
(EngineCore_DP0 pid=318245) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=318245) 	max.f32 	%r188, %r164, 0fC3000000;
(EngineCore_DP0 pid=318245) 	max.f32 	%r189, %r156, 0fC3000000;
(EngineCore_DP0 pid=318245) 	min.f32 	%r190, %r189, 0f42FE0000;
(EngineCore_DP0 pid=318245) 	min.f32 	%r191, %r188, 0f42FE0000;
(EngineCore_DP0 pid=318245) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=318245) 	cvt.rzi.s32.f32 	%r192, %r191;
(EngineCore_DP0 pid=318245) 	cvt.rzi.s32.f32 	%r193, %r190;
(EngineCore_DP0 pid=318245) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=318245) 	shl.b32 	%r194, %r193, 8;
(EngineCore_DP0 pid=318245) 	shl.b32 	%r195, %r192, 16;
(EngineCore_DP0 pid=318245) 	and.b32 	%r196, %r195, 16711680;
(EngineCore_DP0 pid=318245) 	and.b32 	%r197, %r194, 65280;
(EngineCore_DP0 pid=318245) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=318245) 	or.b32 	%r198, %r197, %r148;
(EngineCore_DP0 pid=318245) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=318245) 	max.f32 	%r199, %r165, 0fC3000000;
(EngineCore_DP0 pid=318245) 	max.f32 	%r200, %r157, 0fC3000000;
(EngineCore_DP0 pid=318245) 	min.f32 	%r201, %r200, 0f42FE0000;
(EngineCore_DP0 pid=318245) 	min.f32 	%r202, %r199, 0f42FE0000;
(EngineCore_DP0 pid=318245) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=318245) 	cvt.rzi.s32.f32 	%r203, %r202;
(EngineCore_DP0 pid=318245) 	cvt.rzi.s32.f32 	%r204, %r201;
(EngineCore_DP0 pid=318245) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=318245) 	shl.b32 	%r205, %r204, 8;
(EngineCore_DP0 pid=318245) 	shl.b32 	%r206, %r203, 16;
(EngineCore_DP0 pid=318245) 	and.b32 	%r207, %r206, 16711680;
(EngineCore_DP0 pid=318245) 	and.b32 	%r208, %r205, 65280;
(EngineCore_DP0 pid=318245) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=318245) 	or.b32 	%r209, %r208, %r149;
(EngineCore_DP0 pid=318245) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=318245) 	max.f32 	%r210, %r166, 0fC3000000;
(EngineCore_DP0 pid=318245) 	max.f32 	%r211, %r158, 0fC3000000;
(EngineCore_DP0 pid=318245) 	min.f32 	%r212, %r211, 0f42FE0000;
(EngineCore_DP0 pid=318245) 	min.f32 	%r213, %r210, 0f42FE0000;
(EngineCore_DP0 pid=318245) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=318245) 	cvt.rzi.s32.f32 	%r214, %r213;
(EngineCore_DP0 pid=318245) 	cvt.rzi.s32.f32 	%r215, %r212;
(EngineCore_DP0 pid=318245) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=318245) 	shl.b32 	%r216, %r215, 8;
(EngineCore_DP0 pid=318245) 	shl.b32 	%r217, %r214, 16;
(EngineCore_DP0 pid=318245) 	and.b32 	%r218, %r217, 16711680;
(EngineCore_DP0 pid=318245) 	and.b32 	%r219, %r216, 65280;
(EngineCore_DP0 pid=318245) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=318245) 	or.b32 	%r220, %r219, %r150;
(EngineCore_DP0 pid=318245) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=318245) 	max.f32 	%r221, %r167, 0fC3000000;
(EngineCore_DP0 pid=318245) 	max.f32 	%r222, %r159, 0fC3000000;
(EngineCore_DP0 pid=318245) 	min.f32 	%r223, %r222, 0f42FE0000;
(EngineCore_DP0 pid=318245) 	min.f32 	%r224, %r221, 0f42FE0000;
(EngineCore_DP0 pid=318245) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=318245) 	cvt.rzi.s32.f32 	%r225, %r224;
(EngineCore_DP0 pid=318245) 	cvt.rzi.s32.f32 	%r226, %r223;
(EngineCore_DP0 pid=318245) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=318245) 	shl.b32 	%r227, %r226, 8;
(EngineCore_DP0 pid=318245) 	shl.b32 	%r228, %r225, 16;
(EngineCore_DP0 pid=318245) 	and.b32 	%r229, %r228, 16711680;
(EngineCore_DP0 pid=318245) 	and.b32 	%r230, %r227, 65280;
(EngineCore_DP0 pid=318245) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=318245) 	or.b32 	%r231, %r230, %r151;
(EngineCore_DP0 pid=318245) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=318245) 	or.b32 	%r232, %r198, %r196;
(EngineCore_DP0 pid=318245) 	or.b32 	%r233, %r209, %r207;
(EngineCore_DP0 pid=318245) 	or.b32 	%r234, %r220, %r218;
(EngineCore_DP0 pid=318245) 	or.b32 	%r235, %r231, %r229;
(EngineCore_DP0 pid=318245) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=318245) 	shl.b32 	%r236, %r184, 24;
(EngineCore_DP0 pid=318245) 	shl.b32 	%r237, %r185, 24;
(EngineCore_DP0 pid=318245) 	shl.b32 	%r238, %r186, 24;
(EngineCore_DP0 pid=318245) 	shl.b32 	%r239, %r187, 24;
(EngineCore_DP0 pid=318245) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=318245) 	or.b32 	%r82, %r232, %r236;
(EngineCore_DP0 pid=318245) 	or.b32 	%r83, %r233, %r237;
(EngineCore_DP0 pid=318245) 	or.b32 	%r84, %r234, %r238;
(EngineCore_DP0 pid=318245) 	or.b32 	%r85, %r235, %r239;
(EngineCore_DP0 pid=318245) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=318245) 	mad.wide.s32 	%rd24, %r86, 4, %rd2;
(EngineCore_DP0 pid=318245) 	add.s64 	%rd25, %rd24, 8;
(EngineCore_DP0 pid=318245) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	@%p25 st.global.v2.b32 [ %rd24 + 0 ], { %r82, %r83 };
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	// begin inline asm
(EngineCore_DP0 pid=318245) 	@%p26 st.global.v2.b32 [ %rd25 + 0 ], { %r84, %r85 };
(EngineCore_DP0 pid=318245) 	// end inline asm
(EngineCore_DP0 pid=318245) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=318245) 	add.s32 	%r243, %r243, 2048;
(EngineCore_DP0 pid=318245) 	setp.lt.s32 	%p43, %r243, %r15;
(EngineCore_DP0 pid=318245) 	@%p43 bra 	$L__BB0_6;
(EngineCore_DP0 pid=318245) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=318245) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=318245) 	ret;
(EngineCore_DP0 pid=318245) $L__tmp3:
(EngineCore_DP0 pid=318245) $L__func_end0:
(EngineCore_DP0 pid=318245)                                         // -- End function
(EngineCore_DP0 pid=318245) }
(EngineCore_DP0 pid=318245) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=318245) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=318245) 	.section	.debug_abbrev
(EngineCore_DP0 pid=318245) 	{
(EngineCore_DP0 pid=318245) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=318245) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=318245) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=318245) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=318245) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=318245) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=318245) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=318245) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=318245) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=318245) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=318245) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=318245) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=318245) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=318245) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=318245) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=318245) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=318245) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=318245) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=318245) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=318245) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=318245) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=318245) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=318245) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=318245) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=318245) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=318245) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=318245) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=318245) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=318245) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=318245) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=318245) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=318245) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=318245) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=318245) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=318245) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=318245) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=318245) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=318245) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=318245) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=318245) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=318245) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=318245) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=318245) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=318245) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=318245) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=318245) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=318245) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=318245) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=318245) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=318245) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=318245) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=318245) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=318245) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=318245) 	}
(EngineCore_DP0 pid=318245) 	.section	.debug_info
(EngineCore_DP0 pid=318245) 	{
(EngineCore_DP0 pid=318245) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=318245) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=318245) .b8 0
(EngineCore_DP0 pid=318245) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=318245) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=318245) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=318245) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=318245) .b8 114
(EngineCore_DP0 pid=318245) .b8 105
(EngineCore_DP0 pid=318245) .b8 116
(EngineCore_DP0 pid=318245) .b8 111
(EngineCore_DP0 pid=318245) .b8 110
(EngineCore_DP0 pid=318245) .b8 0
(EngineCore_DP0 pid=318245) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=318245) .b8 0
(EngineCore_DP0 pid=318245) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=318245) .b8 117
(EngineCore_DP0 pid=318245) .b8 97
(EngineCore_DP0 pid=318245) .b8 110
(EngineCore_DP0 pid=318245) .b8 116
(EngineCore_DP0 pid=318245) .b8 95
(EngineCore_DP0 pid=318245) .b8 115
(EngineCore_DP0 pid=318245) .b8 108
(EngineCore_DP0 pid=318245) .b8 105
(EngineCore_DP0 pid=318245) .b8 100
(EngineCore_DP0 pid=318245) .b8 101
(EngineCore_DP0 pid=318245) .b8 95
(EngineCore_DP0 pid=318245) .b8 116
(EngineCore_DP0 pid=318245) .b8 117
(EngineCore_DP0 pid=318245) .b8 110
(EngineCore_DP0 pid=318245) .b8 101
(EngineCore_DP0 pid=318245) .b8 100
(EngineCore_DP0 pid=318245) .b8 95
(EngineCore_DP0 pid=318245) .b8 76
(EngineCore_DP0 pid=318245) .b8 108
(EngineCore_DP0 pid=318245) .b8 97
(EngineCore_DP0 pid=318245) .b8 109
(EngineCore_DP0 pid=318245) .b8 97
(EngineCore_DP0 pid=318245) .b8 51
(EngineCore_DP0 pid=318245) .b8 46
(EngineCore_DP0 pid=318245) .b8 50
(EngineCore_DP0 pid=318245) .b8 45
(EngineCore_DP0 pid=318245) .b8 49
(EngineCore_DP0 pid=318245) .b8 66
(EngineCore_DP0 pid=318245) .b8 46
(EngineCore_DP0 pid=318245) .b8 112
(EngineCore_DP0 pid=318245) .b8 121
(EngineCore_DP0 pid=318245) .b8 0
(EngineCore_DP0 pid=318245) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=318245) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=318245) .b8 114
(EngineCore_DP0 pid=318245) .b8 111
(EngineCore_DP0 pid=318245) .b8 111
(EngineCore_DP0 pid=318245) .b8 116
(EngineCore_DP0 pid=318245) .b8 47
(EngineCore_DP0 pid=318245) .b8 118
(EngineCore_DP0 pid=318245) .b8 108
(EngineCore_DP0 pid=318245) .b8 108
(EngineCore_DP0 pid=318245) .b8 109
(EngineCore_DP0 pid=318245) .b8 98
(EngineCore_DP0 pid=318245) .b8 101
(EngineCore_DP0 pid=318245) .b8 110
(EngineCore_DP0 pid=318245) .b8 99
(EngineCore_DP0 pid=318245) .b8 104
(EngineCore_DP0 pid=318245) .b8 47
(EngineCore_DP0 pid=318245) .b8 115
(EngineCore_DP0 pid=318245) .b8 108
(EngineCore_DP0 pid=318245) .b8 105
(EngineCore_DP0 pid=318245) .b8 100
(EngineCore_DP0 pid=318245) .b8 101
(EngineCore_DP0 pid=318245) .b8 115
(EngineCore_DP0 pid=318245) .b8 112
(EngineCore_DP0 pid=318245) .b8 97
(EngineCore_DP0 pid=318245) .b8 114
(EngineCore_DP0 pid=318245) .b8 115
(EngineCore_DP0 pid=318245) .b8 101
(EngineCore_DP0 pid=318245) .b8 47
(EngineCore_DP0 pid=318245) .b8 99
(EngineCore_DP0 pid=318245) .b8 115
(EngineCore_DP0 pid=318245) .b8 114
(EngineCore_DP0 pid=318245) .b8 99
(EngineCore_DP0 pid=318245) .b8 47
(EngineCore_DP0 pid=318245) .b8 102
(EngineCore_DP0 pid=318245) .b8 117
(EngineCore_DP0 pid=318245) .b8 115
(EngineCore_DP0 pid=318245) .b8 101
(EngineCore_DP0 pid=318245) .b8 100
(EngineCore_DP0 pid=318245) .b8 95
(EngineCore_DP0 pid=318245) .b8 113
(EngineCore_DP0 pid=318245) .b8 117
(EngineCore_DP0 pid=318245) .b8 97
(EngineCore_DP0 pid=318245) .b8 110
(EngineCore_DP0 pid=318245) .b8 116
(EngineCore_DP0 pid=318245) .b8 95
(EngineCore_DP0 pid=318245) .b8 115
(EngineCore_DP0 pid=318245) .b8 108
(EngineCore_DP0 pid=318245) .b8 105
(EngineCore_DP0 pid=318245) .b8 100
(EngineCore_DP0 pid=318245) .b8 101
(EngineCore_DP0 pid=318245) .b8 95
(EngineCore_DP0 pid=318245) .b8 116
(EngineCore_DP0 pid=318245) .b8 114
(EngineCore_DP0 pid=318245) .b8 105
(EngineCore_DP0 pid=318245) .b8 116
(EngineCore_DP0 pid=318245) .b8 111
(EngineCore_DP0 pid=318245) .b8 110
(EngineCore_DP0 pid=318245) .b8 47
(EngineCore_DP0 pid=318245) .b8 98
(EngineCore_DP0 pid=318245) .b8 117
(EngineCore_DP0 pid=318245) .b8 105
(EngineCore_DP0 pid=318245) .b8 108
(EngineCore_DP0 pid=318245) .b8 100
(EngineCore_DP0 pid=318245) .b8 47
(EngineCore_DP0 pid=318245) .b8 71
(EngineCore_DP0 pid=318245) .b8 66
(EngineCore_DP0 pid=318245) .b8 49
(EngineCore_DP0 pid=318245) .b8 48
(EngineCore_DP0 pid=318245) .b8 95
(EngineCore_DP0 pid=318245) .b8 99
(EngineCore_DP0 pid=318245) .b8 99
(EngineCore_DP0 pid=318245) .b8 49
(EngineCore_DP0 pid=318245) .b8 50
(EngineCore_DP0 pid=318245) .b8 49
(EngineCore_DP0 pid=318245) .b8 95
(EngineCore_DP0 pid=318245) .b8 112
(EngineCore_DP0 pid=318245) .b8 121
(EngineCore_DP0 pid=318245) .b8 51
(EngineCore_DP0 pid=318245) .b8 49
(EngineCore_DP0 pid=318245) .b8 50
(EngineCore_DP0 pid=318245) .b8 95
(EngineCore_DP0 pid=318245) .b8 99
(EngineCore_DP0 pid=318245) .b8 117
(EngineCore_DP0 pid=318245) .b8 49
(EngineCore_DP0 pid=318245) .b8 50
(EngineCore_DP0 pid=318245) .b8 57
(EngineCore_DP0 pid=318245) .b8 95
(EngineCore_DP0 pid=318245) .b8 97
(EngineCore_DP0 pid=318245) .b8 97
(EngineCore_DP0 pid=318245) .b8 114
(EngineCore_DP0 pid=318245) .b8 99
(EngineCore_DP0 pid=318245) .b8 104
(EngineCore_DP0 pid=318245) .b8 54
(EngineCore_DP0 pid=318245) .b8 52
(EngineCore_DP0 pid=318245) .b8 0
(EngineCore_DP0 pid=318245) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=318245) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=318245) .b8 113
(EngineCore_DP0 pid=318245) .b8 117
(EngineCore_DP0 pid=318245) .b8 97
(EngineCore_DP0 pid=318245) .b8 110
(EngineCore_DP0 pid=318245) .b8 116
(EngineCore_DP0 pid=318245) .b8 95
(EngineCore_DP0 pid=318245) .b8 115
(EngineCore_DP0 pid=318245) .b8 108
(EngineCore_DP0 pid=318245) .b8 105
(EngineCore_DP0 pid=318245) .b8 100
(EngineCore_DP0 pid=318245) .b8 101
(EngineCore_DP0 pid=318245) .b8 95
(EngineCore_DP0 pid=318245) .b8 105
(EngineCore_DP0 pid=318245) .b8 110
(EngineCore_DP0 pid=318245) .b8 116
(EngineCore_DP0 pid=318245) .b8 56
(EngineCore_DP0 pid=318245) .b8 95
(EngineCore_DP0 pid=318245) .b8 107
(EngineCore_DP0 pid=318245) .b8 101
(EngineCore_DP0 pid=318245) .b8 114
(EngineCore_DP0 pid=318245) .b8 110
(EngineCore_DP0 pid=318245) .b8 101
(EngineCore_DP0 pid=318245) .b8 108
(EngineCore_DP0 pid=318245) .b8 0
(EngineCore_DP0 pid=318245) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=318245) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=318245) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=318245) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=318245) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=318245) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=318245) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=318245) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=318245) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=318245) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=318245) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=318245) .b8 1
(EngineCore_DP0 pid=318245) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=318245) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=318245) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=318245) 	}
(EngineCore_DP0 pid=318245) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=318245) 
(EngineCore_DP0 pid=318245) ================================================================
(EngineCore_DP0 pid=318245) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=318245) 
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmppjkfwpkv.ptx', '-o', '/tmp/tmppjkfwpkv.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866] 
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866] 
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866] 
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmppjkfwpkv.ptx -o /tmp/tmppjkfwpkv.ptx.o
(EngineCore_DP0 pid=318245) ERROR 01-25 19:01:36 [core.py:866] 

STDERR:
[2026-01-25 19:01:21] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:01:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:01:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:01:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:01:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:01:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:01:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:01:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:01:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:01:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:01:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:01:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:01:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:01:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:01:24] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:01:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:01:24] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:01:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:01:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:01:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:01:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:01:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:01:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:01:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:01:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:01:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:01:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:01:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=318245) [2026-01-25 19:01:25] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=318245) [2026-01-25 19:01:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=318245) [2026-01-25 19:01:25] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=318245) [2026-01-25 19:01:25] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=318245) [2026-01-25 19:01:25] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=318245) [2026-01-25 19:01:25] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=318245) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=318245) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.26s/it]
(EngineCore_DP0 pid=318245) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.26s/it]
(EngineCore_DP0 pid=318245) 
(EngineCore_DP0 pid=318245) [2026-01-25 19:01:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=318245) [2026-01-25 19:01:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=318245) [2026-01-25 19:01:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=318245) [2026-01-25 19:01:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=318245) [2026-01-25 19:01:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=318245) [2026-01-25 19:01:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=318245) [2026-01-25 19:01:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=318245) [2026-01-25 19:01:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=318245) Process EngineCore_DP0:
(EngineCore_DP0 pid=318245) Traceback (most recent call last):
(EngineCore_DP0 pid=318245)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=318245)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=318245)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=318245)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=318245) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmppjkfwpkv.ptx', '-o', '/tmp/tmppjkfwpkv.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=318245) 
(EngineCore_DP0 pid=318245) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=318245) 
(EngineCore_DP0 pid=318245) Traceback (most recent call last):
(EngineCore_DP0 pid=318245)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=318245)     self.run()
(EngineCore_DP0 pid=318245)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=318245)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=318245)     raise e
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=318245)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=318245)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=318245)     super().__init__(
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=318245)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=318245)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=318245)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=318245)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=318245)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=318245)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=318245)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=318245)     return func(*args, **kwargs)
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=318245)     return func(*args, **kwargs)
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=318245)     self.model_runner.profile_run()
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=318245)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=318245)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=318245)     return func(*args, **kwargs)
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=318245)     outputs = self.model(
(EngineCore_DP0 pid=318245)               ^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=318245)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=318245)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=318245)     model_output = self.model(
(EngineCore_DP0 pid=318245)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=318245)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=318245)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=318245)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=318245)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=318245)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=318245)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=318245)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=318245)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=318245)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=318245)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=318245)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=318245)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=318245)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=318245)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=318245)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=318245)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=318245)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=318245)     return self._linear_fn(
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=318245)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=318245)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=318245)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=318245)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=318245)     return fn(input, L)
(EngineCore_DP0 pid=318245)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=318245)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=318245)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=318245)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=318245)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=318245)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=318245)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=318245)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=318245)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=318245)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=318245)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=318245)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=318245)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=318245)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=318245)     raise PTXASError(error)
(EngineCore_DP0 pid=318245) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=318245) `ptxas` stderr:
(EngineCore_DP0 pid=318245) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=318245) 
(EngineCore_DP0 pid=318245) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmppjkfwpkv.ptx -o /tmp/tmppjkfwpkv.ptx.o
(EngineCore_DP0 pid=318245) 
[rank0]:[W125 19:01:37.249939357 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 19:01:38
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:02:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:02:04 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=319025) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=319025) 
(EngineCore_DP0 pid=319025) 
(EngineCore_DP0 pid=319025) ================================================================
(EngineCore_DP0 pid=319025) Internal Triton PTX codegen error
(EngineCore_DP0 pid=319025) `ptxas` stderr:
(EngineCore_DP0 pid=319025) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=319025) 
(EngineCore_DP0 pid=319025) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpja0n_8w3.ptx -o /tmp/tmpja0n_8w3.ptx.o
(EngineCore_DP0 pid=319025) 
(EngineCore_DP0 pid=319025) 
(EngineCore_DP0 pid=319025) //
(EngineCore_DP0 pid=319025) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=319025) //
(EngineCore_DP0 pid=319025) 
(EngineCore_DP0 pid=319025) .version 8.7
(EngineCore_DP0 pid=319025) .target sm_121a
(EngineCore_DP0 pid=319025) .address_size 64
(EngineCore_DP0 pid=319025) 
(EngineCore_DP0 pid=319025) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=319025) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=319025)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=319025) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=319025) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=319025) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=319025) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=319025) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=319025) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=319025) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=319025) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=319025) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=319025) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=319025) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=319025) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=319025) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=319025) )
(EngineCore_DP0 pid=319025) .reqntid 512
(EngineCore_DP0 pid=319025) {
(EngineCore_DP0 pid=319025) 	.reg .pred 	%p<45>;
(EngineCore_DP0 pid=319025) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=319025) 	.reg .b32 	%r<244>;
(EngineCore_DP0 pid=319025) 	.reg .b64 	%rd<26>;
(EngineCore_DP0 pid=319025) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=319025) $L__func_begin0:
(EngineCore_DP0 pid=319025) 	.loc	1 278 0                         // quant_slide_tuned_Llama3.2-1B.py:278:0
(EngineCore_DP0 pid=319025) 
(EngineCore_DP0 pid=319025) // %bb.0:
(EngineCore_DP0 pid=319025) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=319025) 	ld.param.b32 	%r28, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=319025) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=319025) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=319025) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=319025) $L__tmp0:
(EngineCore_DP0 pid=319025) 	.loc	1 288 24                        // quant_slide_tuned_Llama3.2-1B.py:288:24
(EngineCore_DP0 pid=319025) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=319025) 	ld.param.b32 	%r31, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=319025) 	.loc	1 293 26                        // quant_slide_tuned_Llama3.2-1B.py:293:26
(EngineCore_DP0 pid=319025) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=319025) 	.loc	1 293 20                        // quant_slide_tuned_Llama3.2-1B.py:293:20
(EngineCore_DP0 pid=319025) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=319025) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=319025) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=319025) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=319025) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=319025) 	mov.b32 	%r242, 0f2B8CBCCC;
(EngineCore_DP0 pid=319025) 	setp.eq.b32 	%p44, %r2, 0;
(EngineCore_DP0 pid=319025) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=319025) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=319025) 	.loc	1 299 32                        // quant_slide_tuned_Llama3.2-1B.py:299:32
(EngineCore_DP0 pid=319025) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=319025) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=319025) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=319025) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=319025) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=319025) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=319025) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=319025) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=319025) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=319025) 	mov.b32 	%r240, 0f00000000;
(EngineCore_DP0 pid=319025) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=319025) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=319025) 	mov.b32 	%r241, %r49;
(EngineCore_DP0 pid=319025) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=319025) 	.loc	1 300 22                        // quant_slide_tuned_Llama3.2-1B.py:300:22
(EngineCore_DP0 pid=319025) 	add.s32 	%r59, %r4, %r241;
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=319025) 	.loc	1 301 29                        // quant_slide_tuned_Llama3.2-1B.py:301:29
(EngineCore_DP0 pid=319025) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=319025) 	.loc	1 301 21                        // quant_slide_tuned_Llama3.2-1B.py:301:21
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=319025) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=319025) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=319025) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=319025) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=319025) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=319025) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=319025) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=319025) 	.loc	1 302 50                        // quant_slide_tuned_Llama3.2-1B.py:302:50
(EngineCore_DP0 pid=319025) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=319025) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=319025) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=319025) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=319025) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=319025) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=319025) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=319025) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=319025) $L__tmp1:
(EngineCore_DP0 pid=319025) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	bar.sync 	0;
(EngineCore_DP0 pid=319025) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=319025) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=319025) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=319025) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=319025) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=319025) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=319025) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=319025) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=319025) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=319025) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=319025) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=319025) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=319025) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=319025) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=319025) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=319025) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=319025) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=319025) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=319025) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	bar.sync 	0;
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=319025) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=319025) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=319025) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=319025) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=319025) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=319025) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=319025) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=319025) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:302:43 ]
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	@%p44 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	bar.sync 	0;
(EngineCore_DP0 pid=319025) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=319025) $L__tmp2:
(EngineCore_DP0 pid=319025) 	.loc	1 302 36                        // quant_slide_tuned_Llama3.2-1B.py:302:36
(EngineCore_DP0 pid=319025) 	max.f32 	%r240, %r240, %r77;
(EngineCore_DP0 pid=319025) 	.loc	1 298 35                        // quant_slide_tuned_Llama3.2-1B.py:298:35
(EngineCore_DP0 pid=319025) 	add.s32 	%r241, %r241, 4096;
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p6, %r241, %r28;
(EngineCore_DP0 pid=319025) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=319025) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=319025) 	.loc	1 304 32                        // quant_slide_tuned_Llama3.2-1B.py:304:32
(EngineCore_DP0 pid=319025) 	max.f32 	%r242, %r240, 0f2B8CBCCC;
(EngineCore_DP0 pid=319025) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=319025) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=319025) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=319025) 	.loc	1 305 32                        // quant_slide_tuned_Llama3.2-1B.py:305:32
(EngineCore_DP0 pid=319025) 	div.full.f32 	%r80, %r242, %r79;
(EngineCore_DP0 pid=319025) 	.loc	1 305 42                        // quant_slide_tuned_Llama3.2-1B.py:305:42
(EngineCore_DP0 pid=319025) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=319025) 	.loc	1 307 25                        // quant_slide_tuned_Llama3.2-1B.py:307:25
(EngineCore_DP0 pid=319025) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=319025) 	.loc	1 307 30                        // quant_slide_tuned_Llama3.2-1B.py:307:30
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	@%p44 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	.loc	1 310 29                        // quant_slide_tuned_Llama3.2-1B.py:310:29
(EngineCore_DP0 pid=319025) 	shl.b32 	%r15, %r29, 1;
(EngineCore_DP0 pid=319025) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=319025) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=319025) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=319025) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=319025) 	ld.param.b32 	%r33, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=319025) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=319025) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=319025) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=319025) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=319025) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=319025) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=319025) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=319025) 	div.full.f32 	%r14, %r79, %r242;
(EngineCore_DP0 pid=319025) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=319025) 	mov.b32 	%r243, 0;
(EngineCore_DP0 pid=319025) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=319025)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=319025) 	.loc	1 313 31                        // quant_slide_tuned_Llama3.2-1B.py:313:31
(EngineCore_DP0 pid=319025) 	add.s32 	%r86, %r16, %r243;
(EngineCore_DP0 pid=319025) 	add.s32 	%r87, %r243, 1;
(EngineCore_DP0 pid=319025) 	.loc	1 314 30                        // quant_slide_tuned_Llama3.2-1B.py:314:30
(EngineCore_DP0 pid=319025) 	add.s32 	%r88, %r86, 2;
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p25, %r86, %r15;
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p26, %r88, %r15;
(EngineCore_DP0 pid=319025) 	.loc	1 317 24                        // quant_slide_tuned_Llama3.2-1B.py:317:24
(EngineCore_DP0 pid=319025) 	shr.u32 	%r89, %r86, 1;
(EngineCore_DP0 pid=319025) 	shr.u32 	%r90, %r88, 1;
(EngineCore_DP0 pid=319025) 	.loc	1 318 23                        // quant_slide_tuned_Llama3.2-1B.py:318:23
(EngineCore_DP0 pid=319025) 	shr.u32 	%r91, %r87, 31;
(EngineCore_DP0 pid=319025) 	add.s32 	%r92, %r87, %r91;
(EngineCore_DP0 pid=319025) 	and.b32 	%r93, %r92, 2147483646;
(EngineCore_DP0 pid=319025) 	sub.s32 	%r94, %r87, %r93;
(EngineCore_DP0 pid=319025) 	.loc	1 319 30                        // quant_slide_tuned_Llama3.2-1B.py:319:30
(EngineCore_DP0 pid=319025) 	shl.b32 	%r95, %r94, 1;
(EngineCore_DP0 pid=319025) 	.loc	1 319 22                        // quant_slide_tuned_Llama3.2-1B.py:319:22
(EngineCore_DP0 pid=319025) 	mul.lo.s32 	%r96, %r89, 6;
(EngineCore_DP0 pid=319025) 	mul.lo.s32 	%r97, %r90, 6;
(EngineCore_DP0 pid=319025) 	.loc	1 319 26                        // quant_slide_tuned_Llama3.2-1B.py:319:26
(EngineCore_DP0 pid=319025) 	add.s32 	%r98, %r96, %r95;
(EngineCore_DP0 pid=319025) 	add.s32 	%r99, %r97, %r95;
(EngineCore_DP0 pid=319025) 	.loc	1 322 53                        // quant_slide_tuned_Llama3.2-1B.py:322:53
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p27, %r96, %r27;
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p28, %r98, %r27;
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p29, %r97, %r27;
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p30, %r99, %r27;
(EngineCore_DP0 pid=319025) 	.loc	1 322 37                        // quant_slide_tuned_Llama3.2-1B.py:322:37
(EngineCore_DP0 pid=319025) 	and.pred 	%p9, %p25, %p27;
(EngineCore_DP0 pid=319025) 	and.pred 	%p10, %p25, %p28;
(EngineCore_DP0 pid=319025) 	and.pred 	%p11, %p26, %p29;
(EngineCore_DP0 pid=319025) 	and.pred 	%p12, %p26, %p30;
(EngineCore_DP0 pid=319025) 	.loc	1 321 29                        // quant_slide_tuned_Llama3.2-1B.py:321:29
(EngineCore_DP0 pid=319025) 	mad.wide.s32 	%rd8, %r96, 2, %rd1;
(EngineCore_DP0 pid=319025) 	mad.wide.s32 	%rd9, %r98, 2, %rd1;
(EngineCore_DP0 pid=319025) 	mad.wide.s32 	%rd10, %r97, 2, %rd1;
(EngineCore_DP0 pid=319025) 	mad.wide.s32 	%rd11, %r99, 2, %rd1;
(EngineCore_DP0 pid=319025) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=319025) 	.loc	1 321 21                        // quant_slide_tuned_Llama3.2-1B.py:321:21
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=319025) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=319025) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=319025) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=319025) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	.loc	1 322 79                        // quant_slide_tuned_Llama3.2-1B.py:322:79
(EngineCore_DP0 pid=319025) 	cvt.f32.bf16 	%r100, %rs24;
(EngineCore_DP0 pid=319025) 	cvt.f32.bf16 	%r101, %rs26;
(EngineCore_DP0 pid=319025) 	cvt.f32.bf16 	%r102, %rs28;
(EngineCore_DP0 pid=319025) 	cvt.f32.bf16 	%r103, %rs30;
(EngineCore_DP0 pid=319025) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=319025) 	or.b32 	%r104, %r98, 1;
(EngineCore_DP0 pid=319025) 	or.b32 	%r105, %r99, 1;
(EngineCore_DP0 pid=319025) 	or.b32 	%r106, %r99, 2;
(EngineCore_DP0 pid=319025) 	or.b32 	%r107, %r99, 3;
(EngineCore_DP0 pid=319025) 	or.b32 	%r108, %r96, 1;
(EngineCore_DP0 pid=319025) 	or.b32 	%r109, %r97, 1;
(EngineCore_DP0 pid=319025) 	or.b32 	%r110, %r96, 2;
(EngineCore_DP0 pid=319025) 	or.b32 	%r111, %r96, 3;
(EngineCore_DP0 pid=319025) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p31, %r107, %r27;
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p32, %r106, %r27;
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p33, %r105, %r27;
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p34, %r104, %r27;
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p35, %r111, %r27;
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p36, %r110, %r27;
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p37, %r109, %r27;
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p38, %r108, %r27;
(EngineCore_DP0 pid=319025) 	.loc	1 324 37                        // quant_slide_tuned_Llama3.2-1B.py:324:37
(EngineCore_DP0 pid=319025) 	and.pred 	%p13, %p25, %p38;
(EngineCore_DP0 pid=319025) 	and.pred 	%p14, %p25, %p34;
(EngineCore_DP0 pid=319025) 	and.pred 	%p15, %p26, %p37;
(EngineCore_DP0 pid=319025) 	and.pred 	%p16, %p26, %p33;
(EngineCore_DP0 pid=319025) 	.loc	1 323 39                        // quant_slide_tuned_Llama3.2-1B.py:323:39
(EngineCore_DP0 pid=319025) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=319025) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=319025) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=319025) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=319025) 	.loc	1 323 21                        // quant_slide_tuned_Llama3.2-1B.py:323:21
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=319025) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=319025) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=319025) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=319025) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	.loc	1 324 79                        // quant_slide_tuned_Llama3.2-1B.py:324:79
(EngineCore_DP0 pid=319025) 	cvt.f32.bf16 	%r112, %rs32;
(EngineCore_DP0 pid=319025) 	cvt.f32.bf16 	%r113, %rs34;
(EngineCore_DP0 pid=319025) 	cvt.f32.bf16 	%r114, %rs36;
(EngineCore_DP0 pid=319025) 	cvt.f32.bf16 	%r115, %rs38;
(EngineCore_DP0 pid=319025) 	.loc	1 326 48                        // quant_slide_tuned_Llama3.2-1B.py:326:48
(EngineCore_DP0 pid=319025) 	add.s32 	%r116, %r98, 2;
(EngineCore_DP0 pid=319025) 	add.s32 	%r117, %r97, 2;
(EngineCore_DP0 pid=319025) 	.loc	1 326 53                        // quant_slide_tuned_Llama3.2-1B.py:326:53
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p39, %r116, %r27;
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p40, %r117, %r27;
(EngineCore_DP0 pid=319025) 	.loc	1 326 37                        // quant_slide_tuned_Llama3.2-1B.py:326:37
(EngineCore_DP0 pid=319025) 	and.pred 	%p17, %p25, %p36;
(EngineCore_DP0 pid=319025) 	and.pred 	%p18, %p25, %p39;
(EngineCore_DP0 pid=319025) 	and.pred 	%p19, %p26, %p40;
(EngineCore_DP0 pid=319025) 	and.pred 	%p20, %p26, %p32;
(EngineCore_DP0 pid=319025) 	.loc	1 325 39                        // quant_slide_tuned_Llama3.2-1B.py:325:39
(EngineCore_DP0 pid=319025) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=319025) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=319025) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=319025) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=319025) 	.loc	1 325 21                        // quant_slide_tuned_Llama3.2-1B.py:325:21
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=319025) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=319025) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=319025) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=319025) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	.loc	1 326 79                        // quant_slide_tuned_Llama3.2-1B.py:326:79
(EngineCore_DP0 pid=319025) 	cvt.f32.bf16 	%r118, %rs40;
(EngineCore_DP0 pid=319025) 	cvt.f32.bf16 	%r119, %rs42;
(EngineCore_DP0 pid=319025) 	cvt.f32.bf16 	%r120, %rs44;
(EngineCore_DP0 pid=319025) 	cvt.f32.bf16 	%r121, %rs46;
(EngineCore_DP0 pid=319025) 	.loc	1 328 48                        // quant_slide_tuned_Llama3.2-1B.py:328:48
(EngineCore_DP0 pid=319025) 	add.s32 	%r122, %r98, 3;
(EngineCore_DP0 pid=319025) 	add.s32 	%r123, %r97, 3;
(EngineCore_DP0 pid=319025) 	.loc	1 328 53                        // quant_slide_tuned_Llama3.2-1B.py:328:53
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p41, %r122, %r27;
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p42, %r123, %r27;
(EngineCore_DP0 pid=319025) 	.loc	1 328 37                        // quant_slide_tuned_Llama3.2-1B.py:328:37
(EngineCore_DP0 pid=319025) 	and.pred 	%p21, %p25, %p35;
(EngineCore_DP0 pid=319025) 	and.pred 	%p22, %p25, %p41;
(EngineCore_DP0 pid=319025) 	and.pred 	%p23, %p26, %p42;
(EngineCore_DP0 pid=319025) 	and.pred 	%p24, %p26, %p31;
(EngineCore_DP0 pid=319025) 	.loc	1 327 39                        // quant_slide_tuned_Llama3.2-1B.py:327:39
(EngineCore_DP0 pid=319025) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=319025) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=319025) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=319025) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=319025) 	.loc	1 327 21                        // quant_slide_tuned_Llama3.2-1B.py:327:21
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=319025) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=319025) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=319025) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=319025) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	.loc	1 328 79                        // quant_slide_tuned_Llama3.2-1B.py:328:79
(EngineCore_DP0 pid=319025) 	cvt.f32.bf16 	%r124, %rs48;
(EngineCore_DP0 pid=319025) 	cvt.f32.bf16 	%r125, %rs50;
(EngineCore_DP0 pid=319025) 	cvt.f32.bf16 	%r126, %rs52;
(EngineCore_DP0 pid=319025) 	cvt.f32.bf16 	%r127, %rs54;
(EngineCore_DP0 pid=319025) 	.loc	1 330 56                        // quant_slide_tuned_Llama3.2-1B.py:330:56
(EngineCore_DP0 pid=319025) 	mul.f32 	%r128, %r14, %r100;
(EngineCore_DP0 pid=319025) 	mul.f32 	%r129, %r14, %r101;
(EngineCore_DP0 pid=319025) 	mul.f32 	%r130, %r14, %r102;
(EngineCore_DP0 pid=319025) 	mul.f32 	%r131, %r14, %r103;
(EngineCore_DP0 pid=319025) 	.loc	1 330 51                        // quant_slide_tuned_Llama3.2-1B.py:330:51
(EngineCore_DP0 pid=319025) 	cvt.rni.f32.f32 	%r132, %r128;
(EngineCore_DP0 pid=319025) 	cvt.rni.f32.f32 	%r133, %r129;
(EngineCore_DP0 pid=319025) 	cvt.rni.f32.f32 	%r134, %r130;
(EngineCore_DP0 pid=319025) 	cvt.rni.f32.f32 	%r135, %r131;
(EngineCore_DP0 pid=319025) 	.loc	1 330 76                        // quant_slide_tuned_Llama3.2-1B.py:330:76
(EngineCore_DP0 pid=319025) 	max.f32 	%r136, %r132, 0fC3000000;
(EngineCore_DP0 pid=319025) 	min.f32 	%r137, %r136, 0f42FE0000;
(EngineCore_DP0 pid=319025) 	max.f32 	%r138, %r133, 0fC3000000;
(EngineCore_DP0 pid=319025) 	min.f32 	%r139, %r138, 0f42FE0000;
(EngineCore_DP0 pid=319025) 	max.f32 	%r140, %r134, 0fC3000000;
(EngineCore_DP0 pid=319025) 	min.f32 	%r141, %r140, 0f42FE0000;
(EngineCore_DP0 pid=319025) 	max.f32 	%r142, %r135, 0fC3000000;
(EngineCore_DP0 pid=319025) 	min.f32 	%r143, %r142, 0f42FE0000;
(EngineCore_DP0 pid=319025) 	.loc	1 330 86                        // quant_slide_tuned_Llama3.2-1B.py:330:86
(EngineCore_DP0 pid=319025) 	cvt.rzi.s32.f32 	%r144, %r137;
(EngineCore_DP0 pid=319025) 	cvt.rzi.s32.f32 	%r145, %r139;
(EngineCore_DP0 pid=319025) 	cvt.rzi.s32.f32 	%r146, %r141;
(EngineCore_DP0 pid=319025) 	cvt.rzi.s32.f32 	%r147, %r143;
(EngineCore_DP0 pid=319025) 	.loc	1 330 98                        // quant_slide_tuned_Llama3.2-1B.py:330:98
(EngineCore_DP0 pid=319025) 	and.b32 	%r148, %r144, 255;
(EngineCore_DP0 pid=319025) 	and.b32 	%r149, %r145, 255;
(EngineCore_DP0 pid=319025) 	and.b32 	%r150, %r146, 255;
(EngineCore_DP0 pid=319025) 	and.b32 	%r151, %r147, 255;
(EngineCore_DP0 pid=319025) 	.loc	1 331 56                        // quant_slide_tuned_Llama3.2-1B.py:331:56
(EngineCore_DP0 pid=319025) 	mul.f32 	%r152, %r14, %r112;
(EngineCore_DP0 pid=319025) 	mul.f32 	%r153, %r14, %r113;
(EngineCore_DP0 pid=319025) 	mul.f32 	%r154, %r14, %r114;
(EngineCore_DP0 pid=319025) 	mul.f32 	%r155, %r14, %r115;
(EngineCore_DP0 pid=319025) 	.loc	1 331 51                        // quant_slide_tuned_Llama3.2-1B.py:331:51
(EngineCore_DP0 pid=319025) 	cvt.rni.f32.f32 	%r156, %r152;
(EngineCore_DP0 pid=319025) 	cvt.rni.f32.f32 	%r157, %r153;
(EngineCore_DP0 pid=319025) 	cvt.rni.f32.f32 	%r158, %r154;
(EngineCore_DP0 pid=319025) 	cvt.rni.f32.f32 	%r159, %r155;
(EngineCore_DP0 pid=319025) 	.loc	1 332 56                        // quant_slide_tuned_Llama3.2-1B.py:332:56
(EngineCore_DP0 pid=319025) 	mul.f32 	%r160, %r14, %r118;
(EngineCore_DP0 pid=319025) 	mul.f32 	%r161, %r14, %r119;
(EngineCore_DP0 pid=319025) 	mul.f32 	%r162, %r14, %r120;
(EngineCore_DP0 pid=319025) 	mul.f32 	%r163, %r14, %r121;
(EngineCore_DP0 pid=319025) 	.loc	1 332 51                        // quant_slide_tuned_Llama3.2-1B.py:332:51
(EngineCore_DP0 pid=319025) 	cvt.rni.f32.f32 	%r164, %r160;
(EngineCore_DP0 pid=319025) 	cvt.rni.f32.f32 	%r165, %r161;
(EngineCore_DP0 pid=319025) 	cvt.rni.f32.f32 	%r166, %r162;
(EngineCore_DP0 pid=319025) 	cvt.rni.f32.f32 	%r167, %r163;
(EngineCore_DP0 pid=319025) 	.loc	1 333 56                        // quant_slide_tuned_Llama3.2-1B.py:333:56
(EngineCore_DP0 pid=319025) 	mul.f32 	%r168, %r14, %r124;
(EngineCore_DP0 pid=319025) 	mul.f32 	%r169, %r14, %r125;
(EngineCore_DP0 pid=319025) 	mul.f32 	%r170, %r14, %r126;
(EngineCore_DP0 pid=319025) 	mul.f32 	%r171, %r14, %r127;
(EngineCore_DP0 pid=319025) 	.loc	1 333 51                        // quant_slide_tuned_Llama3.2-1B.py:333:51
(EngineCore_DP0 pid=319025) 	cvt.rni.f32.f32 	%r172, %r168;
(EngineCore_DP0 pid=319025) 	cvt.rni.f32.f32 	%r173, %r169;
(EngineCore_DP0 pid=319025) 	cvt.rni.f32.f32 	%r174, %r170;
(EngineCore_DP0 pid=319025) 	cvt.rni.f32.f32 	%r175, %r171;
(EngineCore_DP0 pid=319025) 	.loc	1 333 76                        // quant_slide_tuned_Llama3.2-1B.py:333:76
(EngineCore_DP0 pid=319025) 	max.f32 	%r176, %r172, 0fC3000000;
(EngineCore_DP0 pid=319025) 	min.f32 	%r177, %r176, 0f42FE0000;
(EngineCore_DP0 pid=319025) 	max.f32 	%r178, %r173, 0fC3000000;
(EngineCore_DP0 pid=319025) 	min.f32 	%r179, %r178, 0f42FE0000;
(EngineCore_DP0 pid=319025) 	max.f32 	%r180, %r174, 0fC3000000;
(EngineCore_DP0 pid=319025) 	min.f32 	%r181, %r180, 0f42FE0000;
(EngineCore_DP0 pid=319025) 	max.f32 	%r182, %r175, 0fC3000000;
(EngineCore_DP0 pid=319025) 	min.f32 	%r183, %r182, 0f42FE0000;
(EngineCore_DP0 pid=319025) 	.loc	1 333 86                        // quant_slide_tuned_Llama3.2-1B.py:333:86
(EngineCore_DP0 pid=319025) 	cvt.rzi.s32.f32 	%r184, %r177;
(EngineCore_DP0 pid=319025) 	cvt.rzi.s32.f32 	%r185, %r179;
(EngineCore_DP0 pid=319025) 	cvt.rzi.s32.f32 	%r186, %r181;
(EngineCore_DP0 pid=319025) 	cvt.rzi.s32.f32 	%r187, %r183;
(EngineCore_DP0 pid=319025) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=319025) 	max.f32 	%r188, %r164, 0fC3000000;
(EngineCore_DP0 pid=319025) 	max.f32 	%r189, %r156, 0fC3000000;
(EngineCore_DP0 pid=319025) 	min.f32 	%r190, %r189, 0f42FE0000;
(EngineCore_DP0 pid=319025) 	min.f32 	%r191, %r188, 0f42FE0000;
(EngineCore_DP0 pid=319025) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=319025) 	cvt.rzi.s32.f32 	%r192, %r191;
(EngineCore_DP0 pid=319025) 	cvt.rzi.s32.f32 	%r193, %r190;
(EngineCore_DP0 pid=319025) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=319025) 	shl.b32 	%r194, %r193, 8;
(EngineCore_DP0 pid=319025) 	shl.b32 	%r195, %r192, 16;
(EngineCore_DP0 pid=319025) 	and.b32 	%r196, %r195, 16711680;
(EngineCore_DP0 pid=319025) 	and.b32 	%r197, %r194, 65280;
(EngineCore_DP0 pid=319025) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=319025) 	or.b32 	%r198, %r197, %r148;
(EngineCore_DP0 pid=319025) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=319025) 	max.f32 	%r199, %r165, 0fC3000000;
(EngineCore_DP0 pid=319025) 	max.f32 	%r200, %r157, 0fC3000000;
(EngineCore_DP0 pid=319025) 	min.f32 	%r201, %r200, 0f42FE0000;
(EngineCore_DP0 pid=319025) 	min.f32 	%r202, %r199, 0f42FE0000;
(EngineCore_DP0 pid=319025) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=319025) 	cvt.rzi.s32.f32 	%r203, %r202;
(EngineCore_DP0 pid=319025) 	cvt.rzi.s32.f32 	%r204, %r201;
(EngineCore_DP0 pid=319025) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=319025) 	shl.b32 	%r205, %r204, 8;
(EngineCore_DP0 pid=319025) 	shl.b32 	%r206, %r203, 16;
(EngineCore_DP0 pid=319025) 	and.b32 	%r207, %r206, 16711680;
(EngineCore_DP0 pid=319025) 	and.b32 	%r208, %r205, 65280;
(EngineCore_DP0 pid=319025) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=319025) 	or.b32 	%r209, %r208, %r149;
(EngineCore_DP0 pid=319025) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=319025) 	max.f32 	%r210, %r166, 0fC3000000;
(EngineCore_DP0 pid=319025) 	max.f32 	%r211, %r158, 0fC3000000;
(EngineCore_DP0 pid=319025) 	min.f32 	%r212, %r211, 0f42FE0000;
(EngineCore_DP0 pid=319025) 	min.f32 	%r213, %r210, 0f42FE0000;
(EngineCore_DP0 pid=319025) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=319025) 	cvt.rzi.s32.f32 	%r214, %r213;
(EngineCore_DP0 pid=319025) 	cvt.rzi.s32.f32 	%r215, %r212;
(EngineCore_DP0 pid=319025) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=319025) 	shl.b32 	%r216, %r215, 8;
(EngineCore_DP0 pid=319025) 	shl.b32 	%r217, %r214, 16;
(EngineCore_DP0 pid=319025) 	and.b32 	%r218, %r217, 16711680;
(EngineCore_DP0 pid=319025) 	and.b32 	%r219, %r216, 65280;
(EngineCore_DP0 pid=319025) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=319025) 	or.b32 	%r220, %r219, %r150;
(EngineCore_DP0 pid=319025) 	.loc	1 331 76                        // quant_slide_tuned_Llama3.2-1B.py:331:76
(EngineCore_DP0 pid=319025) 	max.f32 	%r221, %r167, 0fC3000000;
(EngineCore_DP0 pid=319025) 	max.f32 	%r222, %r159, 0fC3000000;
(EngineCore_DP0 pid=319025) 	min.f32 	%r223, %r222, 0f42FE0000;
(EngineCore_DP0 pid=319025) 	min.f32 	%r224, %r221, 0f42FE0000;
(EngineCore_DP0 pid=319025) 	.loc	1 331 86                        // quant_slide_tuned_Llama3.2-1B.py:331:86
(EngineCore_DP0 pid=319025) 	cvt.rzi.s32.f32 	%r225, %r224;
(EngineCore_DP0 pid=319025) 	cvt.rzi.s32.f32 	%r226, %r223;
(EngineCore_DP0 pid=319025) 	.loc	1 335 30                        // quant_slide_tuned_Llama3.2-1B.py:335:30
(EngineCore_DP0 pid=319025) 	shl.b32 	%r227, %r226, 8;
(EngineCore_DP0 pid=319025) 	shl.b32 	%r228, %r225, 16;
(EngineCore_DP0 pid=319025) 	and.b32 	%r229, %r228, 16711680;
(EngineCore_DP0 pid=319025) 	and.b32 	%r230, %r227, 65280;
(EngineCore_DP0 pid=319025) 	.loc	1 335 24                        // quant_slide_tuned_Llama3.2-1B.py:335:24
(EngineCore_DP0 pid=319025) 	or.b32 	%r231, %r230, %r151;
(EngineCore_DP0 pid=319025) 	.loc	1 335 36                        // quant_slide_tuned_Llama3.2-1B.py:335:36
(EngineCore_DP0 pid=319025) 	or.b32 	%r232, %r198, %r196;
(EngineCore_DP0 pid=319025) 	or.b32 	%r233, %r209, %r207;
(EngineCore_DP0 pid=319025) 	or.b32 	%r234, %r220, %r218;
(EngineCore_DP0 pid=319025) 	or.b32 	%r235, %r231, %r229;
(EngineCore_DP0 pid=319025) 	.loc	1 335 55                        // quant_slide_tuned_Llama3.2-1B.py:335:55
(EngineCore_DP0 pid=319025) 	shl.b32 	%r236, %r184, 24;
(EngineCore_DP0 pid=319025) 	shl.b32 	%r237, %r185, 24;
(EngineCore_DP0 pid=319025) 	shl.b32 	%r238, %r186, 24;
(EngineCore_DP0 pid=319025) 	shl.b32 	%r239, %r187, 24;
(EngineCore_DP0 pid=319025) 	.loc	1 335 49                        // quant_slide_tuned_Llama3.2-1B.py:335:49
(EngineCore_DP0 pid=319025) 	or.b32 	%r82, %r232, %r236;
(EngineCore_DP0 pid=319025) 	or.b32 	%r83, %r233, %r237;
(EngineCore_DP0 pid=319025) 	or.b32 	%r84, %r234, %r238;
(EngineCore_DP0 pid=319025) 	or.b32 	%r85, %r235, %r239;
(EngineCore_DP0 pid=319025) 	.loc	1 336 29                        // quant_slide_tuned_Llama3.2-1B.py:336:29
(EngineCore_DP0 pid=319025) 	mad.wide.s32 	%rd24, %r86, 4, %rd2;
(EngineCore_DP0 pid=319025) 	add.s64 	%rd25, %rd24, 8;
(EngineCore_DP0 pid=319025) 	.loc	1 336 39                        // quant_slide_tuned_Llama3.2-1B.py:336:39
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	@%p25 st.global.v2.b32 [ %rd24 + 0 ], { %r82, %r83 };
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	// begin inline asm
(EngineCore_DP0 pid=319025) 	@%p26 st.global.v2.b32 [ %rd25 + 0 ], { %r84, %r85 };
(EngineCore_DP0 pid=319025) 	// end inline asm
(EngineCore_DP0 pid=319025) 	.loc	1 312 41                        // quant_slide_tuned_Llama3.2-1B.py:312:41
(EngineCore_DP0 pid=319025) 	add.s32 	%r243, %r243, 2048;
(EngineCore_DP0 pid=319025) 	setp.lt.s32 	%p43, %r243, %r15;
(EngineCore_DP0 pid=319025) 	@%p43 bra 	$L__BB0_6;
(EngineCore_DP0 pid=319025) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=319025) 	.loc	1 312 4                         // quant_slide_tuned_Llama3.2-1B.py:312:4
(EngineCore_DP0 pid=319025) 	ret;
(EngineCore_DP0 pid=319025) $L__tmp3:
(EngineCore_DP0 pid=319025) $L__func_end0:
(EngineCore_DP0 pid=319025)                                         // -- End function
(EngineCore_DP0 pid=319025) }
(EngineCore_DP0 pid=319025) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=319025) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=319025) 	.section	.debug_abbrev
(EngineCore_DP0 pid=319025) 	{
(EngineCore_DP0 pid=319025) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=319025) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=319025) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=319025) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=319025) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=319025) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=319025) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=319025) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=319025) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=319025) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=319025) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=319025) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=319025) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=319025) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=319025) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=319025) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=319025) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=319025) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=319025) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=319025) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=319025) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=319025) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=319025) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=319025) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=319025) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=319025) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=319025) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=319025) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=319025) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=319025) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=319025) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=319025) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=319025) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=319025) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=319025) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=319025) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=319025) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=319025) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=319025) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=319025) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=319025) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=319025) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=319025) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=319025) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=319025) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=319025) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=319025) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=319025) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=319025) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=319025) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=319025) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=319025) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=319025) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=319025) 	}
(EngineCore_DP0 pid=319025) 	.section	.debug_info
(EngineCore_DP0 pid=319025) 	{
(EngineCore_DP0 pid=319025) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=319025) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=319025) .b8 0
(EngineCore_DP0 pid=319025) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=319025) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=319025) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=319025) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=319025) .b8 114
(EngineCore_DP0 pid=319025) .b8 105
(EngineCore_DP0 pid=319025) .b8 116
(EngineCore_DP0 pid=319025) .b8 111
(EngineCore_DP0 pid=319025) .b8 110
(EngineCore_DP0 pid=319025) .b8 0
(EngineCore_DP0 pid=319025) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=319025) .b8 0
(EngineCore_DP0 pid=319025) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=319025) .b8 117
(EngineCore_DP0 pid=319025) .b8 97
(EngineCore_DP0 pid=319025) .b8 110
(EngineCore_DP0 pid=319025) .b8 116
(EngineCore_DP0 pid=319025) .b8 95
(EngineCore_DP0 pid=319025) .b8 115
(EngineCore_DP0 pid=319025) .b8 108
(EngineCore_DP0 pid=319025) .b8 105
(EngineCore_DP0 pid=319025) .b8 100
(EngineCore_DP0 pid=319025) .b8 101
(EngineCore_DP0 pid=319025) .b8 95
(EngineCore_DP0 pid=319025) .b8 116
(EngineCore_DP0 pid=319025) .b8 117
(EngineCore_DP0 pid=319025) .b8 110
(EngineCore_DP0 pid=319025) .b8 101
(EngineCore_DP0 pid=319025) .b8 100
(EngineCore_DP0 pid=319025) .b8 95
(EngineCore_DP0 pid=319025) .b8 76
(EngineCore_DP0 pid=319025) .b8 108
(EngineCore_DP0 pid=319025) .b8 97
(EngineCore_DP0 pid=319025) .b8 109
(EngineCore_DP0 pid=319025) .b8 97
(EngineCore_DP0 pid=319025) .b8 51
(EngineCore_DP0 pid=319025) .b8 46
(EngineCore_DP0 pid=319025) .b8 50
(EngineCore_DP0 pid=319025) .b8 45
(EngineCore_DP0 pid=319025) .b8 49
(EngineCore_DP0 pid=319025) .b8 66
(EngineCore_DP0 pid=319025) .b8 46
(EngineCore_DP0 pid=319025) .b8 112
(EngineCore_DP0 pid=319025) .b8 121
(EngineCore_DP0 pid=319025) .b8 0
(EngineCore_DP0 pid=319025) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=319025) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=319025) .b8 114
(EngineCore_DP0 pid=319025) .b8 111
(EngineCore_DP0 pid=319025) .b8 111
(EngineCore_DP0 pid=319025) .b8 116
(EngineCore_DP0 pid=319025) .b8 47
(EngineCore_DP0 pid=319025) .b8 118
(EngineCore_DP0 pid=319025) .b8 108
(EngineCore_DP0 pid=319025) .b8 108
(EngineCore_DP0 pid=319025) .b8 109
(EngineCore_DP0 pid=319025) .b8 98
(EngineCore_DP0 pid=319025) .b8 101
(EngineCore_DP0 pid=319025) .b8 110
(EngineCore_DP0 pid=319025) .b8 99
(EngineCore_DP0 pid=319025) .b8 104
(EngineCore_DP0 pid=319025) .b8 47
(EngineCore_DP0 pid=319025) .b8 115
(EngineCore_DP0 pid=319025) .b8 108
(EngineCore_DP0 pid=319025) .b8 105
(EngineCore_DP0 pid=319025) .b8 100
(EngineCore_DP0 pid=319025) .b8 101
(EngineCore_DP0 pid=319025) .b8 115
(EngineCore_DP0 pid=319025) .b8 112
(EngineCore_DP0 pid=319025) .b8 97
(EngineCore_DP0 pid=319025) .b8 114
(EngineCore_DP0 pid=319025) .b8 115
(EngineCore_DP0 pid=319025) .b8 101
(EngineCore_DP0 pid=319025) .b8 47
(EngineCore_DP0 pid=319025) .b8 99
(EngineCore_DP0 pid=319025) .b8 115
(EngineCore_DP0 pid=319025) .b8 114
(EngineCore_DP0 pid=319025) .b8 99
(EngineCore_DP0 pid=319025) .b8 47
(EngineCore_DP0 pid=319025) .b8 102
(EngineCore_DP0 pid=319025) .b8 117
(EngineCore_DP0 pid=319025) .b8 115
(EngineCore_DP0 pid=319025) .b8 101
(EngineCore_DP0 pid=319025) .b8 100
(EngineCore_DP0 pid=319025) .b8 95
(EngineCore_DP0 pid=319025) .b8 113
(EngineCore_DP0 pid=319025) .b8 117
(EngineCore_DP0 pid=319025) .b8 97
(EngineCore_DP0 pid=319025) .b8 110
(EngineCore_DP0 pid=319025) .b8 116
(EngineCore_DP0 pid=319025) .b8 95
(EngineCore_DP0 pid=319025) .b8 115
(EngineCore_DP0 pid=319025) .b8 108
(EngineCore_DP0 pid=319025) .b8 105
(EngineCore_DP0 pid=319025) .b8 100
(EngineCore_DP0 pid=319025) .b8 101
(EngineCore_DP0 pid=319025) .b8 95
(EngineCore_DP0 pid=319025) .b8 116
(EngineCore_DP0 pid=319025) .b8 114
(EngineCore_DP0 pid=319025) .b8 105
(EngineCore_DP0 pid=319025) .b8 116
(EngineCore_DP0 pid=319025) .b8 111
(EngineCore_DP0 pid=319025) .b8 110
(EngineCore_DP0 pid=319025) .b8 47
(EngineCore_DP0 pid=319025) .b8 98
(EngineCore_DP0 pid=319025) .b8 117
(EngineCore_DP0 pid=319025) .b8 105
(EngineCore_DP0 pid=319025) .b8 108
(EngineCore_DP0 pid=319025) .b8 100
(EngineCore_DP0 pid=319025) .b8 47
(EngineCore_DP0 pid=319025) .b8 71
(EngineCore_DP0 pid=319025) .b8 66
(EngineCore_DP0 pid=319025) .b8 49
(EngineCore_DP0 pid=319025) .b8 48
(EngineCore_DP0 pid=319025) .b8 95
(EngineCore_DP0 pid=319025) .b8 99
(EngineCore_DP0 pid=319025) .b8 99
(EngineCore_DP0 pid=319025) .b8 49
(EngineCore_DP0 pid=319025) .b8 50
(EngineCore_DP0 pid=319025) .b8 49
(EngineCore_DP0 pid=319025) .b8 95
(EngineCore_DP0 pid=319025) .b8 112
(EngineCore_DP0 pid=319025) .b8 121
(EngineCore_DP0 pid=319025) .b8 51
(EngineCore_DP0 pid=319025) .b8 49
(EngineCore_DP0 pid=319025) .b8 50
(EngineCore_DP0 pid=319025) .b8 95
(EngineCore_DP0 pid=319025) .b8 99
(EngineCore_DP0 pid=319025) .b8 117
(EngineCore_DP0 pid=319025) .b8 49
(EngineCore_DP0 pid=319025) .b8 50
(EngineCore_DP0 pid=319025) .b8 57
(EngineCore_DP0 pid=319025) .b8 95
(EngineCore_DP0 pid=319025) .b8 97
(EngineCore_DP0 pid=319025) .b8 97
(EngineCore_DP0 pid=319025) .b8 114
(EngineCore_DP0 pid=319025) .b8 99
(EngineCore_DP0 pid=319025) .b8 104
(EngineCore_DP0 pid=319025) .b8 54
(EngineCore_DP0 pid=319025) .b8 52
(EngineCore_DP0 pid=319025) .b8 0
(EngineCore_DP0 pid=319025) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=319025) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=319025) .b8 113
(EngineCore_DP0 pid=319025) .b8 117
(EngineCore_DP0 pid=319025) .b8 97
(EngineCore_DP0 pid=319025) .b8 110
(EngineCore_DP0 pid=319025) .b8 116
(EngineCore_DP0 pid=319025) .b8 95
(EngineCore_DP0 pid=319025) .b8 115
(EngineCore_DP0 pid=319025) .b8 108
(EngineCore_DP0 pid=319025) .b8 105
(EngineCore_DP0 pid=319025) .b8 100
(EngineCore_DP0 pid=319025) .b8 101
(EngineCore_DP0 pid=319025) .b8 95
(EngineCore_DP0 pid=319025) .b8 105
(EngineCore_DP0 pid=319025) .b8 110
(EngineCore_DP0 pid=319025) .b8 116
(EngineCore_DP0 pid=319025) .b8 56
(EngineCore_DP0 pid=319025) .b8 95
(EngineCore_DP0 pid=319025) .b8 107
(EngineCore_DP0 pid=319025) .b8 101
(EngineCore_DP0 pid=319025) .b8 114
(EngineCore_DP0 pid=319025) .b8 110
(EngineCore_DP0 pid=319025) .b8 101
(EngineCore_DP0 pid=319025) .b8 108
(EngineCore_DP0 pid=319025) .b8 0
(EngineCore_DP0 pid=319025) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=319025) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=319025) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=319025) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=319025) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=319025) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=319025) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=319025) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=319025) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=319025) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=319025) .b8 46                                  // DW_AT_call_line
(EngineCore_DP0 pid=319025) .b8 1
(EngineCore_DP0 pid=319025) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=319025) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=319025) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=319025) 	}
(EngineCore_DP0 pid=319025) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=319025) 
(EngineCore_DP0 pid=319025) ================================================================
(EngineCore_DP0 pid=319025) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=319025) 
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpja0n_8w3.ptx', '-o', '/tmp/tmpja0n_8w3.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866] 
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866] 
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866] 
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpja0n_8w3.ptx -o /tmp/tmpja0n_8w3.ptx.o
(EngineCore_DP0 pid=319025) ERROR 01-25 19:02:19 [core.py:866] 

STDERR:
[2026-01-25 19:02:04] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:02:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:02:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:02:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:02:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:02:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:02:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:02:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:02:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:02:07] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:02:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 19:02:07] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 19:02:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 19:02:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 19:02:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:02:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:02:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:02:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:02:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=319025) [2026-01-25 19:02:08] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=319025) [2026-01-25 19:02:08] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=319025) [2026-01-25 19:02:08] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=319025) [2026-01-25 19:02:08] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=319025) [2026-01-25 19:02:08] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=319025) [2026-01-25 19:02:08] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=319025) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=319025) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.25s/it]
(EngineCore_DP0 pid=319025) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.25s/it]
(EngineCore_DP0 pid=319025) 
(EngineCore_DP0 pid=319025) [2026-01-25 19:02:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=319025) [2026-01-25 19:02:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=319025) [2026-01-25 19:02:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=319025) [2026-01-25 19:02:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=319025) [2026-01-25 19:02:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=319025) [2026-01-25 19:02:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=319025) [2026-01-25 19:02:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=319025) [2026-01-25 19:02:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=319025) Process EngineCore_DP0:
(EngineCore_DP0 pid=319025) Traceback (most recent call last):
(EngineCore_DP0 pid=319025)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=319025)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=319025)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=319025)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=319025) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpja0n_8w3.ptx', '-o', '/tmp/tmpja0n_8w3.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=319025) 
(EngineCore_DP0 pid=319025) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=319025) 
(EngineCore_DP0 pid=319025) Traceback (most recent call last):
(EngineCore_DP0 pid=319025)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=319025)     self.run()
(EngineCore_DP0 pid=319025)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=319025)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=319025)     raise e
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=319025)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=319025)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=319025)     super().__init__(
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=319025)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=319025)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=319025)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=319025)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=319025)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=319025)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=319025)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=319025)     return func(*args, **kwargs)
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=319025)     return func(*args, **kwargs)
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=319025)     self.model_runner.profile_run()
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=319025)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=319025)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=319025)     return func(*args, **kwargs)
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=319025)     outputs = self.model(
(EngineCore_DP0 pid=319025)               ^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=319025)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=319025)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=319025)     model_output = self.model(
(EngineCore_DP0 pid=319025)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=319025)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=319025)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=319025)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=319025)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=319025)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=319025)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=319025)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=319025)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=319025)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=319025)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=319025)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=319025)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=319025)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=319025)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=319025)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=319025)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=319025)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=319025)     return self._linear_fn(
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=319025)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=319025)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=319025)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=319025)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=319025)     return fn(input, L)
(EngineCore_DP0 pid=319025)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 365, in quant_slide_int8_triton
(EngineCore_DP0 pid=319025)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=319025)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=319025)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=319025)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=319025)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=319025)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=319025)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=319025)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=319025)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=319025)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=319025)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=319025)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=319025)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=319025)     raise PTXASError(error)
(EngineCore_DP0 pid=319025) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=319025) `ptxas` stderr:
(EngineCore_DP0 pid=319025) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=319025) 
(EngineCore_DP0 pid=319025) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpja0n_8w3.ptx -o /tmp/tmpja0n_8w3.ptx.o
(EngineCore_DP0 pid=319025) 
[rank0]:[W125 19:02:20.326029426 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-25 19:37:24
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:37:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:37:27 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=362425) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=362425) 
(EngineCore_DP0 pid=362425) 
(EngineCore_DP0 pid=362425) ================================================================
(EngineCore_DP0 pid=362425) Internal Triton PTX codegen error
(EngineCore_DP0 pid=362425) `ptxas` stderr:
(EngineCore_DP0 pid=362425) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=362425) 
(EngineCore_DP0 pid=362425) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmph68fzxby.ptx -o /tmp/tmph68fzxby.ptx.o
(EngineCore_DP0 pid=362425) 
(EngineCore_DP0 pid=362425) 
(EngineCore_DP0 pid=362425) //
(EngineCore_DP0 pid=362425) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=362425) //
(EngineCore_DP0 pid=362425) 
(EngineCore_DP0 pid=362425) .version 8.7
(EngineCore_DP0 pid=362425) .target sm_121a
(EngineCore_DP0 pid=362425) .address_size 64
(EngineCore_DP0 pid=362425) 
(EngineCore_DP0 pid=362425) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=362425) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=362425)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=362425) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=362425) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=362425) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=362425) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=362425) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=362425) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=362425) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=362425) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=362425) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=362425) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=362425) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=362425) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=362425) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=362425) )
(EngineCore_DP0 pid=362425) .reqntid 1024
(EngineCore_DP0 pid=362425) {
(EngineCore_DP0 pid=362425) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=362425) 	.reg .b16 	%rs<20>;
(EngineCore_DP0 pid=362425) 	.reg .b32 	%r<119>;
(EngineCore_DP0 pid=362425) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=362425) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=362425) $L__func_begin0:
(EngineCore_DP0 pid=362425) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=362425) 
(EngineCore_DP0 pid=362425) // %bb.0:
(EngineCore_DP0 pid=362425) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=362425) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=362425) 	ld.param.b32 	%r17, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=362425) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=362425) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=362425) $L__tmp0:
(EngineCore_DP0 pid=362425) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=362425) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=362425) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=362425) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=362425) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=362425) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=362425) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=362425) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=362425) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=362425) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=362425) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=362425) 	mov.b32 	%r117, 0f2B8CBCCC;
(EngineCore_DP0 pid=362425) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=362425) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=362425) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=362425) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=362425) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=362425) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=362425) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=362425) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=362425) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=362425) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=362425) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=362425) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=362425) 	mov.b32 	%r115, 0f00000000;
(EngineCore_DP0 pid=362425) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=362425) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=362425) 	mov.b32 	%r116, %r37;
(EngineCore_DP0 pid=362425) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=362425) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=362425) 	add.s32 	%r45, %r3, %r116;
(EngineCore_DP0 pid=362425) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=362425) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=362425) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=362425) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=362425) 	// begin inline asm
(EngineCore_DP0 pid=362425) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=362425) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=362425) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=362425) 	// end inline asm
(EngineCore_DP0 pid=362425) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=362425) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=362425) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=362425) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=362425) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=362425) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=362425) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=362425) $L__tmp1:
(EngineCore_DP0 pid=362425) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	bar.sync 	0;
(EngineCore_DP0 pid=362425) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=362425) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=362425) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=362425) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=362425) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=362425) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=362425) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=362425) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=362425) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=362425) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=362425) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=362425) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=362425) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=362425) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=362425) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	// begin inline asm
(EngineCore_DP0 pid=362425) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=362425) 	// end inline asm
(EngineCore_DP0 pid=362425) 	bar.sync 	0;
(EngineCore_DP0 pid=362425) 	// begin inline asm
(EngineCore_DP0 pid=362425) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=362425) 	// end inline asm
(EngineCore_DP0 pid=362425) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=362425) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=362425) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=362425) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=362425) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=362425) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=362425) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=362425) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=362425) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=362425) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=362425) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=362425) 	// begin inline asm
(EngineCore_DP0 pid=362425) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=362425) 	// end inline asm
(EngineCore_DP0 pid=362425) 	bar.sync 	0;
(EngineCore_DP0 pid=362425) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=362425) $L__tmp2:
(EngineCore_DP0 pid=362425) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=362425) 	max.f32 	%r115, %r115, %r65;
(EngineCore_DP0 pid=362425) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=362425) 	add.s32 	%r116, %r116, 4096;
(EngineCore_DP0 pid=362425) 	setp.lt.s32 	%p6, %r116, %r18;
(EngineCore_DP0 pid=362425) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=362425) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=362425) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=362425) 	max.f32 	%r117, %r115, 0f2B8CBCCC;
(EngineCore_DP0 pid=362425) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=362425) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=362425) 	mov.b32 	%r67, 0f42FE0000;
(EngineCore_DP0 pid=362425) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=362425) 	div.full.f32 	%r68, %r117, %r67;
(EngineCore_DP0 pid=362425) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=362425) 	max.f32 	%r66, %r68, 0f37810204;
(EngineCore_DP0 pid=362425) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=362425) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=362425) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=362425) 	// begin inline asm
(EngineCore_DP0 pid=362425) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=362425) 	// end inline asm
(EngineCore_DP0 pid=362425) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=362425) 	shl.b32 	%r14, %r19, 1;
(EngineCore_DP0 pid=362425) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=362425) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=362425) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=362425) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=362425) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=362425) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=362425) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=362425) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=362425) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=362425) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=362425) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=362425) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=362425) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=362425) 	div.full.f32 	%r13, %r67, %r117;
(EngineCore_DP0 pid=362425) 	mov.b32 	%r118, 0;
(EngineCore_DP0 pid=362425) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=362425)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=362425) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=362425) 	add.s32 	%r72, %r2, %r118;
(EngineCore_DP0 pid=362425) 	setp.lt.s32 	%p13, %r72, %r14;
(EngineCore_DP0 pid=362425) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=362425) 	shr.u32 	%r73, %r72, 31;
(EngineCore_DP0 pid=362425) 	add.s32 	%r74, %r72, %r73;
(EngineCore_DP0 pid=362425) 	shr.u32 	%r75, %r74, 1;
(EngineCore_DP0 pid=362425) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=362425) 	and.b32 	%r76, %r74, 2147483646;
(EngineCore_DP0 pid=362425) 	sub.s32 	%r77, %r72, %r76;
(EngineCore_DP0 pid=362425) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=362425) 	shl.b32 	%r78, %r77, 1;
(EngineCore_DP0 pid=362425) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=362425) 	mad.lo.s32 	%r79, %r75, 6, %r78;
(EngineCore_DP0 pid=362425) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=362425) 	setp.lt.s32 	%p14, %r79, %r17;
(EngineCore_DP0 pid=362425) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=362425) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=362425) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=362425) 	mad.wide.s32 	%rd8, %r79, 2, %rd1;
(EngineCore_DP0 pid=362425) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=362425) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=362425) 	// begin inline asm
(EngineCore_DP0 pid=362425) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=362425) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=362425) 	// end inline asm
(EngineCore_DP0 pid=362425) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=362425) 	cvt.f32.bf16 	%r80, %rs12;
(EngineCore_DP0 pid=362425) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=362425) 	or.b32 	%r81, %r79, 1;
(EngineCore_DP0 pid=362425) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=362425) 	setp.lt.s32 	%p15, %r81, %r17;
(EngineCore_DP0 pid=362425) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=362425) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=362425) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=362425) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=362425) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=362425) 	// begin inline asm
(EngineCore_DP0 pid=362425) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=362425) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=362425) 	// end inline asm
(EngineCore_DP0 pid=362425) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=362425) 	cvt.f32.bf16 	%r82, %rs14;
(EngineCore_DP0 pid=362425) 	.loc	1 340 48                        // quant_slide_tuned_Llama3.2-3B.py:340:48
(EngineCore_DP0 pid=362425) 	add.s32 	%r83, %r79, 2;
(EngineCore_DP0 pid=362425) 	.loc	1 340 53                        // quant_slide_tuned_Llama3.2-3B.py:340:53
(EngineCore_DP0 pid=362425) 	setp.lt.s32 	%p16, %r83, %r17;
(EngineCore_DP0 pid=362425) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=362425) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=362425) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=362425) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=362425) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=362425) 	// begin inline asm
(EngineCore_DP0 pid=362425) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=362425) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=362425) 	// end inline asm
(EngineCore_DP0 pid=362425) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=362425) 	cvt.f32.bf16 	%r84, %rs16;
(EngineCore_DP0 pid=362425) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=362425) 	add.s32 	%r85, %r79, 3;
(EngineCore_DP0 pid=362425) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=362425) 	setp.lt.s32 	%p17, %r85, %r17;
(EngineCore_DP0 pid=362425) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=362425) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=362425) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=362425) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=362425) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=362425) 	// begin inline asm
(EngineCore_DP0 pid=362425) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=362425) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=362425) 	// end inline asm
(EngineCore_DP0 pid=362425) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=362425) 	cvt.f32.bf16 	%r86, %rs18;
(EngineCore_DP0 pid=362425) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=362425) 	mul.f32 	%r87, %r13, %r80;
(EngineCore_DP0 pid=362425) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=362425) 	cvt.rni.f32.f32 	%r88, %r87;
(EngineCore_DP0 pid=362425) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=362425) 	max.f32 	%r89, %r88, 0fC3000000;
(EngineCore_DP0 pid=362425) 	min.f32 	%r90, %r89, 0f42FE0000;
(EngineCore_DP0 pid=362425) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=362425) 	cvt.rzi.s32.f32 	%r91, %r90;
(EngineCore_DP0 pid=362425) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=362425) 	and.b32 	%r92, %r91, 255;
(EngineCore_DP0 pid=362425) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=362425) 	mul.f32 	%r93, %r13, %r82;
(EngineCore_DP0 pid=362425) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=362425) 	cvt.rni.f32.f32 	%r94, %r93;
(EngineCore_DP0 pid=362425) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=362425) 	mul.f32 	%r95, %r13, %r84;
(EngineCore_DP0 pid=362425) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=362425) 	cvt.rni.f32.f32 	%r96, %r95;
(EngineCore_DP0 pid=362425) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=362425) 	mul.f32 	%r97, %r13, %r86;
(EngineCore_DP0 pid=362425) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=362425) 	cvt.rni.f32.f32 	%r98, %r97;
(EngineCore_DP0 pid=362425) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=362425) 	max.f32 	%r99, %r98, 0fC3000000;
(EngineCore_DP0 pid=362425) 	min.f32 	%r100, %r99, 0f42FE0000;
(EngineCore_DP0 pid=362425) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=362425) 	cvt.rzi.s32.f32 	%r101, %r100;
(EngineCore_DP0 pid=362425) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=362425) 	max.f32 	%r102, %r96, 0fC3000000;
(EngineCore_DP0 pid=362425) 	max.f32 	%r103, %r94, 0fC3000000;
(EngineCore_DP0 pid=362425) 	min.f32 	%r104, %r103, 0f42FE0000;
(EngineCore_DP0 pid=362425) 	min.f32 	%r105, %r102, 0f42FE0000;
(EngineCore_DP0 pid=362425) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=362425) 	cvt.rzi.s32.f32 	%r106, %r105;
(EngineCore_DP0 pid=362425) 	cvt.rzi.s32.f32 	%r107, %r104;
(EngineCore_DP0 pid=362425) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=362425) 	shl.b32 	%r108, %r107, 8;
(EngineCore_DP0 pid=362425) 	shl.b32 	%r109, %r106, 16;
(EngineCore_DP0 pid=362425) 	and.b32 	%r110, %r109, 16711680;
(EngineCore_DP0 pid=362425) 	and.b32 	%r111, %r108, 65280;
(EngineCore_DP0 pid=362425) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=362425) 	or.b32 	%r112, %r111, %r92;
(EngineCore_DP0 pid=362425) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=362425) 	or.b32 	%r113, %r112, %r110;
(EngineCore_DP0 pid=362425) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=362425) 	shl.b32 	%r114, %r101, 24;
(EngineCore_DP0 pid=362425) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=362425) 	or.b32 	%r70, %r113, %r114;
(EngineCore_DP0 pid=362425) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=362425) 	mad.wide.s32 	%rd12, %r72, 4, %rd2;
(EngineCore_DP0 pid=362425) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=362425) 	// begin inline asm
(EngineCore_DP0 pid=362425) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r70 };
(EngineCore_DP0 pid=362425) 	// end inline asm
(EngineCore_DP0 pid=362425) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=362425) 	add.s32 	%r118, %r118, 1024;
(EngineCore_DP0 pid=362425) 	setp.lt.s32 	%p18, %r118, %r14;
(EngineCore_DP0 pid=362425) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=362425) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=362425) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=362425) 	ret;
(EngineCore_DP0 pid=362425) $L__tmp3:
(EngineCore_DP0 pid=362425) $L__func_end0:
(EngineCore_DP0 pid=362425)                                         // -- End function
(EngineCore_DP0 pid=362425) }
(EngineCore_DP0 pid=362425) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=362425) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=362425) 	.section	.debug_abbrev
(EngineCore_DP0 pid=362425) 	{
(EngineCore_DP0 pid=362425) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=362425) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=362425) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=362425) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=362425) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=362425) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=362425) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=362425) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=362425) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=362425) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=362425) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=362425) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=362425) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=362425) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=362425) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=362425) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=362425) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=362425) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=362425) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=362425) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=362425) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=362425) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=362425) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=362425) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=362425) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=362425) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=362425) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=362425) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=362425) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=362425) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=362425) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=362425) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=362425) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=362425) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=362425) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=362425) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=362425) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=362425) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=362425) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=362425) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=362425) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=362425) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=362425) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=362425) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=362425) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=362425) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=362425) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=362425) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=362425) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=362425) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=362425) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=362425) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=362425) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=362425) 	}
(EngineCore_DP0 pid=362425) 	.section	.debug_info
(EngineCore_DP0 pid=362425) 	{
(EngineCore_DP0 pid=362425) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=362425) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=362425) .b8 0
(EngineCore_DP0 pid=362425) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=362425) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=362425) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=362425) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=362425) .b8 114
(EngineCore_DP0 pid=362425) .b8 105
(EngineCore_DP0 pid=362425) .b8 116
(EngineCore_DP0 pid=362425) .b8 111
(EngineCore_DP0 pid=362425) .b8 110
(EngineCore_DP0 pid=362425) .b8 0
(EngineCore_DP0 pid=362425) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=362425) .b8 0
(EngineCore_DP0 pid=362425) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=362425) .b8 117
(EngineCore_DP0 pid=362425) .b8 97
(EngineCore_DP0 pid=362425) .b8 110
(EngineCore_DP0 pid=362425) .b8 116
(EngineCore_DP0 pid=362425) .b8 95
(EngineCore_DP0 pid=362425) .b8 115
(EngineCore_DP0 pid=362425) .b8 108
(EngineCore_DP0 pid=362425) .b8 105
(EngineCore_DP0 pid=362425) .b8 100
(EngineCore_DP0 pid=362425) .b8 101
(EngineCore_DP0 pid=362425) .b8 95
(EngineCore_DP0 pid=362425) .b8 116
(EngineCore_DP0 pid=362425) .b8 117
(EngineCore_DP0 pid=362425) .b8 110
(EngineCore_DP0 pid=362425) .b8 101
(EngineCore_DP0 pid=362425) .b8 100
(EngineCore_DP0 pid=362425) .b8 95
(EngineCore_DP0 pid=362425) .b8 76
(EngineCore_DP0 pid=362425) .b8 108
(EngineCore_DP0 pid=362425) .b8 97
(EngineCore_DP0 pid=362425) .b8 109
(EngineCore_DP0 pid=362425) .b8 97
(EngineCore_DP0 pid=362425) .b8 51
(EngineCore_DP0 pid=362425) .b8 46
(EngineCore_DP0 pid=362425) .b8 50
(EngineCore_DP0 pid=362425) .b8 45
(EngineCore_DP0 pid=362425) .b8 51
(EngineCore_DP0 pid=362425) .b8 66
(EngineCore_DP0 pid=362425) .b8 46
(EngineCore_DP0 pid=362425) .b8 112
(EngineCore_DP0 pid=362425) .b8 121
(EngineCore_DP0 pid=362425) .b8 0
(EngineCore_DP0 pid=362425) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=362425) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=362425) .b8 114
(EngineCore_DP0 pid=362425) .b8 111
(EngineCore_DP0 pid=362425) .b8 111
(EngineCore_DP0 pid=362425) .b8 116
(EngineCore_DP0 pid=362425) .b8 47
(EngineCore_DP0 pid=362425) .b8 118
(EngineCore_DP0 pid=362425) .b8 108
(EngineCore_DP0 pid=362425) .b8 108
(EngineCore_DP0 pid=362425) .b8 109
(EngineCore_DP0 pid=362425) .b8 98
(EngineCore_DP0 pid=362425) .b8 101
(EngineCore_DP0 pid=362425) .b8 110
(EngineCore_DP0 pid=362425) .b8 99
(EngineCore_DP0 pid=362425) .b8 104
(EngineCore_DP0 pid=362425) .b8 47
(EngineCore_DP0 pid=362425) .b8 115
(EngineCore_DP0 pid=362425) .b8 108
(EngineCore_DP0 pid=362425) .b8 105
(EngineCore_DP0 pid=362425) .b8 100
(EngineCore_DP0 pid=362425) .b8 101
(EngineCore_DP0 pid=362425) .b8 115
(EngineCore_DP0 pid=362425) .b8 112
(EngineCore_DP0 pid=362425) .b8 97
(EngineCore_DP0 pid=362425) .b8 114
(EngineCore_DP0 pid=362425) .b8 115
(EngineCore_DP0 pid=362425) .b8 101
(EngineCore_DP0 pid=362425) .b8 47
(EngineCore_DP0 pid=362425) .b8 99
(EngineCore_DP0 pid=362425) .b8 115
(EngineCore_DP0 pid=362425) .b8 114
(EngineCore_DP0 pid=362425) .b8 99
(EngineCore_DP0 pid=362425) .b8 47
(EngineCore_DP0 pid=362425) .b8 102
(EngineCore_DP0 pid=362425) .b8 117
(EngineCore_DP0 pid=362425) .b8 115
(EngineCore_DP0 pid=362425) .b8 101
(EngineCore_DP0 pid=362425) .b8 100
(EngineCore_DP0 pid=362425) .b8 95
(EngineCore_DP0 pid=362425) .b8 113
(EngineCore_DP0 pid=362425) .b8 117
(EngineCore_DP0 pid=362425) .b8 97
(EngineCore_DP0 pid=362425) .b8 110
(EngineCore_DP0 pid=362425) .b8 116
(EngineCore_DP0 pid=362425) .b8 95
(EngineCore_DP0 pid=362425) .b8 115
(EngineCore_DP0 pid=362425) .b8 108
(EngineCore_DP0 pid=362425) .b8 105
(EngineCore_DP0 pid=362425) .b8 100
(EngineCore_DP0 pid=362425) .b8 101
(EngineCore_DP0 pid=362425) .b8 95
(EngineCore_DP0 pid=362425) .b8 116
(EngineCore_DP0 pid=362425) .b8 114
(EngineCore_DP0 pid=362425) .b8 105
(EngineCore_DP0 pid=362425) .b8 116
(EngineCore_DP0 pid=362425) .b8 111
(EngineCore_DP0 pid=362425) .b8 110
(EngineCore_DP0 pid=362425) .b8 47
(EngineCore_DP0 pid=362425) .b8 98
(EngineCore_DP0 pid=362425) .b8 117
(EngineCore_DP0 pid=362425) .b8 105
(EngineCore_DP0 pid=362425) .b8 108
(EngineCore_DP0 pid=362425) .b8 100
(EngineCore_DP0 pid=362425) .b8 47
(EngineCore_DP0 pid=362425) .b8 71
(EngineCore_DP0 pid=362425) .b8 66
(EngineCore_DP0 pid=362425) .b8 49
(EngineCore_DP0 pid=362425) .b8 48
(EngineCore_DP0 pid=362425) .b8 95
(EngineCore_DP0 pid=362425) .b8 99
(EngineCore_DP0 pid=362425) .b8 99
(EngineCore_DP0 pid=362425) .b8 49
(EngineCore_DP0 pid=362425) .b8 50
(EngineCore_DP0 pid=362425) .b8 49
(EngineCore_DP0 pid=362425) .b8 95
(EngineCore_DP0 pid=362425) .b8 112
(EngineCore_DP0 pid=362425) .b8 121
(EngineCore_DP0 pid=362425) .b8 51
(EngineCore_DP0 pid=362425) .b8 49
(EngineCore_DP0 pid=362425) .b8 50
(EngineCore_DP0 pid=362425) .b8 95
(EngineCore_DP0 pid=362425) .b8 99
(EngineCore_DP0 pid=362425) .b8 117
(EngineCore_DP0 pid=362425) .b8 49
(EngineCore_DP0 pid=362425) .b8 50
(EngineCore_DP0 pid=362425) .b8 57
(EngineCore_DP0 pid=362425) .b8 95
(EngineCore_DP0 pid=362425) .b8 97
(EngineCore_DP0 pid=362425) .b8 97
(EngineCore_DP0 pid=362425) .b8 114
(EngineCore_DP0 pid=362425) .b8 99
(EngineCore_DP0 pid=362425) .b8 104
(EngineCore_DP0 pid=362425) .b8 54
(EngineCore_DP0 pid=362425) .b8 52
(EngineCore_DP0 pid=362425) .b8 0
(EngineCore_DP0 pid=362425) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=362425) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=362425) .b8 113
(EngineCore_DP0 pid=362425) .b8 117
(EngineCore_DP0 pid=362425) .b8 97
(EngineCore_DP0 pid=362425) .b8 110
(EngineCore_DP0 pid=362425) .b8 116
(EngineCore_DP0 pid=362425) .b8 95
(EngineCore_DP0 pid=362425) .b8 115
(EngineCore_DP0 pid=362425) .b8 108
(EngineCore_DP0 pid=362425) .b8 105
(EngineCore_DP0 pid=362425) .b8 100
(EngineCore_DP0 pid=362425) .b8 101
(EngineCore_DP0 pid=362425) .b8 95
(EngineCore_DP0 pid=362425) .b8 105
(EngineCore_DP0 pid=362425) .b8 110
(EngineCore_DP0 pid=362425) .b8 116
(EngineCore_DP0 pid=362425) .b8 56
(EngineCore_DP0 pid=362425) .b8 95
(EngineCore_DP0 pid=362425) .b8 107
(EngineCore_DP0 pid=362425) .b8 101
(EngineCore_DP0 pid=362425) .b8 114
(EngineCore_DP0 pid=362425) .b8 110
(EngineCore_DP0 pid=362425) .b8 101
(EngineCore_DP0 pid=362425) .b8 108
(EngineCore_DP0 pid=362425) .b8 0
(EngineCore_DP0 pid=362425) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=362425) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=362425) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=362425) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=362425) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=362425) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=362425) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=362425) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=362425) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=362425) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=362425) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=362425) .b8 1
(EngineCore_DP0 pid=362425) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=362425) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=362425) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=362425) 	}
(EngineCore_DP0 pid=362425) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=362425) 
(EngineCore_DP0 pid=362425) ================================================================
(EngineCore_DP0 pid=362425) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=362425) 
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmph68fzxby.ptx', '-o', '/tmp/tmph68fzxby.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866] 
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866] 
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866] 
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmph68fzxby.ptx -o /tmp/tmph68fzxby.ptx.o
(EngineCore_DP0 pid=362425) ERROR 01-25 19:37:59 [core.py:866] 

STDERR:
[2026-01-25 19:37:27] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:37:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:37:27] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:37:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:37:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:37:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:37:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:37:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:37:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:37:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:37:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:37:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:37:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:37:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:37:31] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:37:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:37:31] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:37:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:37:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:37:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:37:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:37:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:37:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:37:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:37:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:37:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:37:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:37:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=362425) [2026-01-25 19:37:31] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=362425) [2026-01-25 19:37:31] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=362425) [2026-01-25 19:37:31] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=362425) [2026-01-25 19:37:31] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=362425) [2026-01-25 19:37:31] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=362425) [2026-01-25 19:37:31] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=362425) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=362425) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.58s/it]
(EngineCore_DP0 pid=362425) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.58s/it]
(EngineCore_DP0 pid=362425) 
(EngineCore_DP0 pid=362425) [2026-01-25 19:37:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=362425) [2026-01-25 19:37:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=362425) [2026-01-25 19:37:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=362425) [2026-01-25 19:37:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9437184 bytes
(EngineCore_DP0 pid=362425) [2026-01-25 19:37:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=362425) [2026-01-25 19:37:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50331648 bytes
(EngineCore_DP0 pid=362425) [2026-01-25 19:37:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=362425) [2026-01-25 19:37:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25264128 bytes
(EngineCore_DP0 pid=362425) Process EngineCore_DP0:
(EngineCore_DP0 pid=362425) Traceback (most recent call last):
(EngineCore_DP0 pid=362425)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=362425)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=362425)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=362425)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=362425) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmph68fzxby.ptx', '-o', '/tmp/tmph68fzxby.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=362425) 
(EngineCore_DP0 pid=362425) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=362425) 
(EngineCore_DP0 pid=362425) Traceback (most recent call last):
(EngineCore_DP0 pid=362425)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=362425)     self.run()
(EngineCore_DP0 pid=362425)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=362425)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=362425)     raise e
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=362425)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=362425)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=362425)     super().__init__(
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=362425)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=362425)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=362425)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=362425)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=362425)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=362425)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=362425)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=362425)     return func(*args, **kwargs)
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=362425)     return func(*args, **kwargs)
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=362425)     self.model_runner.profile_run()
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=362425)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=362425)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=362425)     return func(*args, **kwargs)
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=362425)     outputs = self.model(
(EngineCore_DP0 pid=362425)               ^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=362425)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=362425)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=362425)     model_output = self.model(
(EngineCore_DP0 pid=362425)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=362425)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=362425)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=362425)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=362425)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=362425)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=362425)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=362425)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=362425)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=362425)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=362425)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=362425)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=362425)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=362425)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=362425)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=362425)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=362425)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=362425)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=362425)     return self._linear_fn(
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=362425)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=362425)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=362425)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=362425)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=362425)     return fn(input, L)
(EngineCore_DP0 pid=362425)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=362425)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=362425)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=362425)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=362425)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=362425)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=362425)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=362425)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=362425)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=362425)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=362425)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=362425)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=362425)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=362425)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=362425)     raise PTXASError(error)
(EngineCore_DP0 pid=362425) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=362425) `ptxas` stderr:
(EngineCore_DP0 pid=362425) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=362425) 
(EngineCore_DP0 pid=362425) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmph68fzxby.ptx -o /tmp/tmph68fzxby.ptx.o
(EngineCore_DP0 pid=362425) 
[rank0]:[W125 19:38:00.321536014 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 19:38:01
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:38:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:38:05 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=363121) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=363121) 
(EngineCore_DP0 pid=363121) 
(EngineCore_DP0 pid=363121) ================================================================
(EngineCore_DP0 pid=363121) Internal Triton PTX codegen error
(EngineCore_DP0 pid=363121) `ptxas` stderr:
(EngineCore_DP0 pid=363121) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=363121) 
(EngineCore_DP0 pid=363121) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmptiiwszag.ptx -o /tmp/tmptiiwszag.ptx.o
(EngineCore_DP0 pid=363121) 
(EngineCore_DP0 pid=363121) 
(EngineCore_DP0 pid=363121) //
(EngineCore_DP0 pid=363121) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=363121) //
(EngineCore_DP0 pid=363121) 
(EngineCore_DP0 pid=363121) .version 8.7
(EngineCore_DP0 pid=363121) .target sm_121a
(EngineCore_DP0 pid=363121) .address_size 64
(EngineCore_DP0 pid=363121) 
(EngineCore_DP0 pid=363121) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=363121) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=363121)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=363121) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=363121) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=363121) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=363121) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=363121) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=363121) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=363121) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=363121) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=363121) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=363121) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=363121) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=363121) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=363121) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=363121) )
(EngineCore_DP0 pid=363121) .reqntid 512
(EngineCore_DP0 pid=363121) {
(EngineCore_DP0 pid=363121) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=363121) 	.reg .b16 	%rs<32>;
(EngineCore_DP0 pid=363121) 	.reg .b32 	%r<122>;
(EngineCore_DP0 pid=363121) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=363121) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=363121) $L__func_begin0:
(EngineCore_DP0 pid=363121) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=363121) 
(EngineCore_DP0 pid=363121) // %bb.0:
(EngineCore_DP0 pid=363121) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=363121) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=363121) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=363121) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=363121) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=363121) $L__tmp0:
(EngineCore_DP0 pid=363121) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=363121) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=363121) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=363121) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=363121) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=363121) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=363121) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=363121) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=363121) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=363121) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=363121) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=363121) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=363121) 	mov.b32 	%r120, 0f2B8CBCCC;
(EngineCore_DP0 pid=363121) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=363121) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=363121) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=363121) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=363121) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=363121) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=363121) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=363121) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=363121) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=363121) 	add.s32 	%r44, %r34, %r33;
(EngineCore_DP0 pid=363121) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=363121) 	add.s32 	%r47, %r34, %r35;
(EngineCore_DP0 pid=363121) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=363121) 	mov.b32 	%r118, 0f00000000;
(EngineCore_DP0 pid=363121) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=363121) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=363121) 	mov.b32 	%r119, %r40;
(EngineCore_DP0 pid=363121) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=363121) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=363121) 	add.s32 	%r50, %r4, %r119;
(EngineCore_DP0 pid=363121) 	setp.lt.s32 	%p2, %r50, %r18;
(EngineCore_DP0 pid=363121) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=363121) 	mad.wide.s32 	%rd6, %r50, 2, %rd1;
(EngineCore_DP0 pid=363121) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=363121) 	// begin inline asm
(EngineCore_DP0 pid=363121) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=363121) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=363121) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=363121) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=363121) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=363121) 	// end inline asm
(EngineCore_DP0 pid=363121) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=363121) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=363121) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=363121) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=363121) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=363121) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=363121) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=363121) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=363121) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=363121) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=363121) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=363121) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=363121) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=363121) $L__tmp1:
(EngineCore_DP0 pid=363121) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	bar.sync 	0;
(EngineCore_DP0 pid=363121) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=363121) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=363121) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=363121) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=363121) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=363121) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=363121) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=363121) 	cvt.f32.bf16 	%r51, %rs23;
(EngineCore_DP0 pid=363121) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	shfl.sync.bfly.b32 	%r52, %r51, 16, 31, -1;
(EngineCore_DP0 pid=363121) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=363121) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	shfl.sync.bfly.b32 	%r54, %r53, 8, 31, -1;
(EngineCore_DP0 pid=363121) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=363121) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	shfl.sync.bfly.b32 	%r56, %r55, 4, 31, -1;
(EngineCore_DP0 pid=363121) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=363121) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	shfl.sync.bfly.b32 	%r58, %r57, 2, 31, -1;
(EngineCore_DP0 pid=363121) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=363121) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	shfl.sync.bfly.b32 	%r60, %r59, 1, 31, -1;
(EngineCore_DP0 pid=363121) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	max.f32 	%r45, %r59, %r60;
(EngineCore_DP0 pid=363121) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	// begin inline asm
(EngineCore_DP0 pid=363121) 	@%p3 st.shared.b32 [ %r44 + 0 ], %r45;
(EngineCore_DP0 pid=363121) 	// end inline asm
(EngineCore_DP0 pid=363121) 	bar.sync 	0;
(EngineCore_DP0 pid=363121) 	// begin inline asm
(EngineCore_DP0 pid=363121) 	@%p4 ld.shared.b32 %r46, [ %r47 + 0 ];
(EngineCore_DP0 pid=363121) 	// end inline asm
(EngineCore_DP0 pid=363121) 	shfl.sync.bfly.b32 	%r61, %r46, 8, 31, -1;
(EngineCore_DP0 pid=363121) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	max.f32 	%r62, %r46, %r61;
(EngineCore_DP0 pid=363121) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	shfl.sync.bfly.b32 	%r63, %r62, 4, 31, -1;
(EngineCore_DP0 pid=363121) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=363121) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	shfl.sync.bfly.b32 	%r65, %r64, 2, 31, -1;
(EngineCore_DP0 pid=363121) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=363121) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	shfl.sync.bfly.b32 	%r67, %r66, 1, 31, -1;
(EngineCore_DP0 pid=363121) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	max.f32 	%r49, %r66, %r67;
(EngineCore_DP0 pid=363121) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363121) 	// begin inline asm
(EngineCore_DP0 pid=363121) 	@%p19 st.shared.b32 [ %r47 + 0 ], %r49;
(EngineCore_DP0 pid=363121) 	// end inline asm
(EngineCore_DP0 pid=363121) 	bar.sync 	0;
(EngineCore_DP0 pid=363121) 	ld.shared.b32 	%r68, [global_smem];
(EngineCore_DP0 pid=363121) $L__tmp2:
(EngineCore_DP0 pid=363121) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=363121) 	max.f32 	%r118, %r118, %r68;
(EngineCore_DP0 pid=363121) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=363121) 	add.s32 	%r119, %r119, 4096;
(EngineCore_DP0 pid=363121) 	setp.lt.s32 	%p6, %r119, %r19;
(EngineCore_DP0 pid=363121) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=363121) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=363121) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=363121) 	max.f32 	%r120, %r118, 0f2B8CBCCC;
(EngineCore_DP0 pid=363121) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=363121) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=363121) 	mov.b32 	%r70, 0f42FE0000;
(EngineCore_DP0 pid=363121) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=363121) 	div.full.f32 	%r71, %r120, %r70;
(EngineCore_DP0 pid=363121) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=363121) 	max.f32 	%r69, %r71, 0f37810204;
(EngineCore_DP0 pid=363121) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=363121) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=363121) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=363121) 	// begin inline asm
(EngineCore_DP0 pid=363121) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r69 };
(EngineCore_DP0 pid=363121) 	// end inline asm
(EngineCore_DP0 pid=363121) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=363121) 	shl.b32 	%r15, %r20, 1;
(EngineCore_DP0 pid=363121) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=363121) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=363121) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=363121) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=363121) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=363121) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=363121) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=363121) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=363121) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=363121) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=363121) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=363121) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=363121) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=363121) 	div.full.f32 	%r14, %r70, %r120;
(EngineCore_DP0 pid=363121) 	mov.b32 	%r121, 0;
(EngineCore_DP0 pid=363121) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=363121)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=363121) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=363121) 	add.s32 	%r75, %r3, %r121;
(EngineCore_DP0 pid=363121) 	setp.lt.s32 	%p13, %r75, %r15;
(EngineCore_DP0 pid=363121) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=363121) 	shr.u32 	%r76, %r75, 31;
(EngineCore_DP0 pid=363121) 	add.s32 	%r77, %r75, %r76;
(EngineCore_DP0 pid=363121) 	shr.u32 	%r78, %r77, 1;
(EngineCore_DP0 pid=363121) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=363121) 	and.b32 	%r79, %r77, 2147483646;
(EngineCore_DP0 pid=363121) 	sub.s32 	%r80, %r75, %r79;
(EngineCore_DP0 pid=363121) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=363121) 	shl.b32 	%r81, %r80, 1;
(EngineCore_DP0 pid=363121) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=363121) 	mad.lo.s32 	%r82, %r78, 6, %r81;
(EngineCore_DP0 pid=363121) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=363121) 	setp.lt.s32 	%p14, %r82, %r18;
(EngineCore_DP0 pid=363121) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=363121) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=363121) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=363121) 	mad.wide.s32 	%rd8, %r82, 2, %rd1;
(EngineCore_DP0 pid=363121) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=363121) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=363121) 	// begin inline asm
(EngineCore_DP0 pid=363121) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=363121) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=363121) 	// end inline asm
(EngineCore_DP0 pid=363121) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=363121) 	cvt.f32.bf16 	%r83, %rs24;
(EngineCore_DP0 pid=363121) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=363121) 	or.b32 	%r84, %r82, 1;
(EngineCore_DP0 pid=363121) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=363121) 	setp.lt.s32 	%p15, %r84, %r18;
(EngineCore_DP0 pid=363121) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=363121) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=363121) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=363121) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=363121) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=363121) 	// begin inline asm
(EngineCore_DP0 pid=363121) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=363121) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=363121) 	// end inline asm
(EngineCore_DP0 pid=363121) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=363121) 	cvt.f32.bf16 	%r85, %rs26;
(EngineCore_DP0 pid=363121) 	.loc	1 340 48                        // quant_slide_tuned_Llama3.2-3B.py:340:48
(EngineCore_DP0 pid=363121) 	add.s32 	%r86, %r82, 2;
(EngineCore_DP0 pid=363121) 	.loc	1 340 53                        // quant_slide_tuned_Llama3.2-3B.py:340:53
(EngineCore_DP0 pid=363121) 	setp.lt.s32 	%p16, %r86, %r18;
(EngineCore_DP0 pid=363121) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=363121) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=363121) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=363121) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=363121) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=363121) 	// begin inline asm
(EngineCore_DP0 pid=363121) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=363121) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=363121) 	// end inline asm
(EngineCore_DP0 pid=363121) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=363121) 	cvt.f32.bf16 	%r87, %rs28;
(EngineCore_DP0 pid=363121) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=363121) 	add.s32 	%r88, %r82, 3;
(EngineCore_DP0 pid=363121) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=363121) 	setp.lt.s32 	%p17, %r88, %r18;
(EngineCore_DP0 pid=363121) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=363121) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=363121) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=363121) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=363121) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=363121) 	// begin inline asm
(EngineCore_DP0 pid=363121) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=363121) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=363121) 	// end inline asm
(EngineCore_DP0 pid=363121) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=363121) 	cvt.f32.bf16 	%r89, %rs30;
(EngineCore_DP0 pid=363121) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=363121) 	mul.f32 	%r90, %r14, %r83;
(EngineCore_DP0 pid=363121) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=363121) 	cvt.rni.f32.f32 	%r91, %r90;
(EngineCore_DP0 pid=363121) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=363121) 	max.f32 	%r92, %r91, 0fC3000000;
(EngineCore_DP0 pid=363121) 	min.f32 	%r93, %r92, 0f42FE0000;
(EngineCore_DP0 pid=363121) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=363121) 	cvt.rzi.s32.f32 	%r94, %r93;
(EngineCore_DP0 pid=363121) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=363121) 	and.b32 	%r95, %r94, 255;
(EngineCore_DP0 pid=363121) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=363121) 	mul.f32 	%r96, %r14, %r85;
(EngineCore_DP0 pid=363121) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=363121) 	cvt.rni.f32.f32 	%r97, %r96;
(EngineCore_DP0 pid=363121) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=363121) 	mul.f32 	%r98, %r14, %r87;
(EngineCore_DP0 pid=363121) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=363121) 	cvt.rni.f32.f32 	%r99, %r98;
(EngineCore_DP0 pid=363121) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=363121) 	mul.f32 	%r100, %r14, %r89;
(EngineCore_DP0 pid=363121) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=363121) 	cvt.rni.f32.f32 	%r101, %r100;
(EngineCore_DP0 pid=363121) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=363121) 	max.f32 	%r102, %r101, 0fC3000000;
(EngineCore_DP0 pid=363121) 	min.f32 	%r103, %r102, 0f42FE0000;
(EngineCore_DP0 pid=363121) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=363121) 	cvt.rzi.s32.f32 	%r104, %r103;
(EngineCore_DP0 pid=363121) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=363121) 	max.f32 	%r105, %r99, 0fC3000000;
(EngineCore_DP0 pid=363121) 	max.f32 	%r106, %r97, 0fC3000000;
(EngineCore_DP0 pid=363121) 	min.f32 	%r107, %r106, 0f42FE0000;
(EngineCore_DP0 pid=363121) 	min.f32 	%r108, %r105, 0f42FE0000;
(EngineCore_DP0 pid=363121) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=363121) 	cvt.rzi.s32.f32 	%r109, %r108;
(EngineCore_DP0 pid=363121) 	cvt.rzi.s32.f32 	%r110, %r107;
(EngineCore_DP0 pid=363121) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=363121) 	shl.b32 	%r111, %r110, 8;
(EngineCore_DP0 pid=363121) 	shl.b32 	%r112, %r109, 16;
(EngineCore_DP0 pid=363121) 	and.b32 	%r113, %r112, 16711680;
(EngineCore_DP0 pid=363121) 	and.b32 	%r114, %r111, 65280;
(EngineCore_DP0 pid=363121) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=363121) 	or.b32 	%r115, %r114, %r95;
(EngineCore_DP0 pid=363121) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=363121) 	or.b32 	%r116, %r115, %r113;
(EngineCore_DP0 pid=363121) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=363121) 	shl.b32 	%r117, %r104, 24;
(EngineCore_DP0 pid=363121) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=363121) 	or.b32 	%r73, %r116, %r117;
(EngineCore_DP0 pid=363121) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=363121) 	mad.wide.s32 	%rd12, %r75, 4, %rd2;
(EngineCore_DP0 pid=363121) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=363121) 	// begin inline asm
(EngineCore_DP0 pid=363121) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r73 };
(EngineCore_DP0 pid=363121) 	// end inline asm
(EngineCore_DP0 pid=363121) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=363121) 	add.s32 	%r121, %r121, 512;
(EngineCore_DP0 pid=363121) 	setp.lt.s32 	%p18, %r121, %r15;
(EngineCore_DP0 pid=363121) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=363121) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=363121) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=363121) 	ret;
(EngineCore_DP0 pid=363121) $L__tmp3:
(EngineCore_DP0 pid=363121) $L__func_end0:
(EngineCore_DP0 pid=363121)                                         // -- End function
(EngineCore_DP0 pid=363121) }
(EngineCore_DP0 pid=363121) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=363121) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=363121) 	.section	.debug_abbrev
(EngineCore_DP0 pid=363121) 	{
(EngineCore_DP0 pid=363121) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=363121) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=363121) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=363121) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=363121) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=363121) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=363121) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=363121) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=363121) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=363121) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=363121) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=363121) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=363121) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=363121) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=363121) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=363121) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=363121) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=363121) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=363121) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=363121) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=363121) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=363121) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=363121) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=363121) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=363121) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=363121) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=363121) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=363121) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=363121) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=363121) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=363121) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=363121) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=363121) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=363121) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=363121) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=363121) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=363121) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=363121) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=363121) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=363121) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=363121) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=363121) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=363121) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=363121) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=363121) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=363121) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=363121) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=363121) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=363121) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=363121) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=363121) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=363121) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=363121) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=363121) 	}
(EngineCore_DP0 pid=363121) 	.section	.debug_info
(EngineCore_DP0 pid=363121) 	{
(EngineCore_DP0 pid=363121) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=363121) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=363121) .b8 0
(EngineCore_DP0 pid=363121) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=363121) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=363121) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=363121) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=363121) .b8 114
(EngineCore_DP0 pid=363121) .b8 105
(EngineCore_DP0 pid=363121) .b8 116
(EngineCore_DP0 pid=363121) .b8 111
(EngineCore_DP0 pid=363121) .b8 110
(EngineCore_DP0 pid=363121) .b8 0
(EngineCore_DP0 pid=363121) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=363121) .b8 0
(EngineCore_DP0 pid=363121) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=363121) .b8 117
(EngineCore_DP0 pid=363121) .b8 97
(EngineCore_DP0 pid=363121) .b8 110
(EngineCore_DP0 pid=363121) .b8 116
(EngineCore_DP0 pid=363121) .b8 95
(EngineCore_DP0 pid=363121) .b8 115
(EngineCore_DP0 pid=363121) .b8 108
(EngineCore_DP0 pid=363121) .b8 105
(EngineCore_DP0 pid=363121) .b8 100
(EngineCore_DP0 pid=363121) .b8 101
(EngineCore_DP0 pid=363121) .b8 95
(EngineCore_DP0 pid=363121) .b8 116
(EngineCore_DP0 pid=363121) .b8 117
(EngineCore_DP0 pid=363121) .b8 110
(EngineCore_DP0 pid=363121) .b8 101
(EngineCore_DP0 pid=363121) .b8 100
(EngineCore_DP0 pid=363121) .b8 95
(EngineCore_DP0 pid=363121) .b8 76
(EngineCore_DP0 pid=363121) .b8 108
(EngineCore_DP0 pid=363121) .b8 97
(EngineCore_DP0 pid=363121) .b8 109
(EngineCore_DP0 pid=363121) .b8 97
(EngineCore_DP0 pid=363121) .b8 51
(EngineCore_DP0 pid=363121) .b8 46
(EngineCore_DP0 pid=363121) .b8 50
(EngineCore_DP0 pid=363121) .b8 45
(EngineCore_DP0 pid=363121) .b8 51
(EngineCore_DP0 pid=363121) .b8 66
(EngineCore_DP0 pid=363121) .b8 46
(EngineCore_DP0 pid=363121) .b8 112
(EngineCore_DP0 pid=363121) .b8 121
(EngineCore_DP0 pid=363121) .b8 0
(EngineCore_DP0 pid=363121) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=363121) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=363121) .b8 114
(EngineCore_DP0 pid=363121) .b8 111
(EngineCore_DP0 pid=363121) .b8 111
(EngineCore_DP0 pid=363121) .b8 116
(EngineCore_DP0 pid=363121) .b8 47
(EngineCore_DP0 pid=363121) .b8 118
(EngineCore_DP0 pid=363121) .b8 108
(EngineCore_DP0 pid=363121) .b8 108
(EngineCore_DP0 pid=363121) .b8 109
(EngineCore_DP0 pid=363121) .b8 98
(EngineCore_DP0 pid=363121) .b8 101
(EngineCore_DP0 pid=363121) .b8 110
(EngineCore_DP0 pid=363121) .b8 99
(EngineCore_DP0 pid=363121) .b8 104
(EngineCore_DP0 pid=363121) .b8 47
(EngineCore_DP0 pid=363121) .b8 115
(EngineCore_DP0 pid=363121) .b8 108
(EngineCore_DP0 pid=363121) .b8 105
(EngineCore_DP0 pid=363121) .b8 100
(EngineCore_DP0 pid=363121) .b8 101
(EngineCore_DP0 pid=363121) .b8 115
(EngineCore_DP0 pid=363121) .b8 112
(EngineCore_DP0 pid=363121) .b8 97
(EngineCore_DP0 pid=363121) .b8 114
(EngineCore_DP0 pid=363121) .b8 115
(EngineCore_DP0 pid=363121) .b8 101
(EngineCore_DP0 pid=363121) .b8 47
(EngineCore_DP0 pid=363121) .b8 99
(EngineCore_DP0 pid=363121) .b8 115
(EngineCore_DP0 pid=363121) .b8 114
(EngineCore_DP0 pid=363121) .b8 99
(EngineCore_DP0 pid=363121) .b8 47
(EngineCore_DP0 pid=363121) .b8 102
(EngineCore_DP0 pid=363121) .b8 117
(EngineCore_DP0 pid=363121) .b8 115
(EngineCore_DP0 pid=363121) .b8 101
(EngineCore_DP0 pid=363121) .b8 100
(EngineCore_DP0 pid=363121) .b8 95
(EngineCore_DP0 pid=363121) .b8 113
(EngineCore_DP0 pid=363121) .b8 117
(EngineCore_DP0 pid=363121) .b8 97
(EngineCore_DP0 pid=363121) .b8 110
(EngineCore_DP0 pid=363121) .b8 116
(EngineCore_DP0 pid=363121) .b8 95
(EngineCore_DP0 pid=363121) .b8 115
(EngineCore_DP0 pid=363121) .b8 108
(EngineCore_DP0 pid=363121) .b8 105
(EngineCore_DP0 pid=363121) .b8 100
(EngineCore_DP0 pid=363121) .b8 101
(EngineCore_DP0 pid=363121) .b8 95
(EngineCore_DP0 pid=363121) .b8 116
(EngineCore_DP0 pid=363121) .b8 114
(EngineCore_DP0 pid=363121) .b8 105
(EngineCore_DP0 pid=363121) .b8 116
(EngineCore_DP0 pid=363121) .b8 111
(EngineCore_DP0 pid=363121) .b8 110
(EngineCore_DP0 pid=363121) .b8 47
(EngineCore_DP0 pid=363121) .b8 98
(EngineCore_DP0 pid=363121) .b8 117
(EngineCore_DP0 pid=363121) .b8 105
(EngineCore_DP0 pid=363121) .b8 108
(EngineCore_DP0 pid=363121) .b8 100
(EngineCore_DP0 pid=363121) .b8 47
(EngineCore_DP0 pid=363121) .b8 71
(EngineCore_DP0 pid=363121) .b8 66
(EngineCore_DP0 pid=363121) .b8 49
(EngineCore_DP0 pid=363121) .b8 48
(EngineCore_DP0 pid=363121) .b8 95
(EngineCore_DP0 pid=363121) .b8 99
(EngineCore_DP0 pid=363121) .b8 99
(EngineCore_DP0 pid=363121) .b8 49
(EngineCore_DP0 pid=363121) .b8 50
(EngineCore_DP0 pid=363121) .b8 49
(EngineCore_DP0 pid=363121) .b8 95
(EngineCore_DP0 pid=363121) .b8 112
(EngineCore_DP0 pid=363121) .b8 121
(EngineCore_DP0 pid=363121) .b8 51
(EngineCore_DP0 pid=363121) .b8 49
(EngineCore_DP0 pid=363121) .b8 50
(EngineCore_DP0 pid=363121) .b8 95
(EngineCore_DP0 pid=363121) .b8 99
(EngineCore_DP0 pid=363121) .b8 117
(EngineCore_DP0 pid=363121) .b8 49
(EngineCore_DP0 pid=363121) .b8 50
(EngineCore_DP0 pid=363121) .b8 57
(EngineCore_DP0 pid=363121) .b8 95
(EngineCore_DP0 pid=363121) .b8 97
(EngineCore_DP0 pid=363121) .b8 97
(EngineCore_DP0 pid=363121) .b8 114
(EngineCore_DP0 pid=363121) .b8 99
(EngineCore_DP0 pid=363121) .b8 104
(EngineCore_DP0 pid=363121) .b8 54
(EngineCore_DP0 pid=363121) .b8 52
(EngineCore_DP0 pid=363121) .b8 0
(EngineCore_DP0 pid=363121) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=363121) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=363121) .b8 113
(EngineCore_DP0 pid=363121) .b8 117
(EngineCore_DP0 pid=363121) .b8 97
(EngineCore_DP0 pid=363121) .b8 110
(EngineCore_DP0 pid=363121) .b8 116
(EngineCore_DP0 pid=363121) .b8 95
(EngineCore_DP0 pid=363121) .b8 115
(EngineCore_DP0 pid=363121) .b8 108
(EngineCore_DP0 pid=363121) .b8 105
(EngineCore_DP0 pid=363121) .b8 100
(EngineCore_DP0 pid=363121) .b8 101
(EngineCore_DP0 pid=363121) .b8 95
(EngineCore_DP0 pid=363121) .b8 105
(EngineCore_DP0 pid=363121) .b8 110
(EngineCore_DP0 pid=363121) .b8 116
(EngineCore_DP0 pid=363121) .b8 56
(EngineCore_DP0 pid=363121) .b8 95
(EngineCore_DP0 pid=363121) .b8 107
(EngineCore_DP0 pid=363121) .b8 101
(EngineCore_DP0 pid=363121) .b8 114
(EngineCore_DP0 pid=363121) .b8 110
(EngineCore_DP0 pid=363121) .b8 101
(EngineCore_DP0 pid=363121) .b8 108
(EngineCore_DP0 pid=363121) .b8 0
(EngineCore_DP0 pid=363121) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=363121) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=363121) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=363121) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=363121) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=363121) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=363121) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=363121) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=363121) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=363121) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=363121) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=363121) .b8 1
(EngineCore_DP0 pid=363121) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=363121) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=363121) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=363121) 	}
(EngineCore_DP0 pid=363121) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=363121) 
(EngineCore_DP0 pid=363121) ================================================================
(EngineCore_DP0 pid=363121) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=363121) 
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmptiiwszag.ptx', '-o', '/tmp/tmptiiwszag.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866] 
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866] 
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866] 
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmptiiwszag.ptx -o /tmp/tmptiiwszag.ptx.o
(EngineCore_DP0 pid=363121) ERROR 01-25 19:38:37 [core.py:866] 

STDERR:
[2026-01-25 19:38:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:38:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:38:05] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:38:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:38:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:38:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:38:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:38:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:38:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:38:08] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:38:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:38:08] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:38:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:38:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:38:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:38:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:38:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:38:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=363121) [2026-01-25 19:38:09] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=363121) [2026-01-25 19:38:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=363121) [2026-01-25 19:38:09] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=363121) [2026-01-25 19:38:09] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=363121) [2026-01-25 19:38:09] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=363121) [2026-01-25 19:38:09] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=363121) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=363121) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.06s/it]
(EngineCore_DP0 pid=363121) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.06s/it]
(EngineCore_DP0 pid=363121) 
(EngineCore_DP0 pid=363121) [2026-01-25 19:38:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=363121) [2026-01-25 19:38:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=363121) [2026-01-25 19:38:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=363121) [2026-01-25 19:38:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9437184 bytes
(EngineCore_DP0 pid=363121) [2026-01-25 19:38:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=363121) [2026-01-25 19:38:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50331648 bytes
(EngineCore_DP0 pid=363121) [2026-01-25 19:38:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=363121) [2026-01-25 19:38:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25264128 bytes
(EngineCore_DP0 pid=363121) Process EngineCore_DP0:
(EngineCore_DP0 pid=363121) Traceback (most recent call last):
(EngineCore_DP0 pid=363121)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=363121)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=363121)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=363121)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=363121) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmptiiwszag.ptx', '-o', '/tmp/tmptiiwszag.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=363121) 
(EngineCore_DP0 pid=363121) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=363121) 
(EngineCore_DP0 pid=363121) Traceback (most recent call last):
(EngineCore_DP0 pid=363121)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=363121)     self.run()
(EngineCore_DP0 pid=363121)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=363121)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=363121)     raise e
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=363121)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=363121)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=363121)     super().__init__(
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=363121)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=363121)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=363121)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=363121)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=363121)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=363121)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=363121)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=363121)     return func(*args, **kwargs)
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=363121)     return func(*args, **kwargs)
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=363121)     self.model_runner.profile_run()
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=363121)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=363121)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=363121)     return func(*args, **kwargs)
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=363121)     outputs = self.model(
(EngineCore_DP0 pid=363121)               ^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=363121)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=363121)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=363121)     model_output = self.model(
(EngineCore_DP0 pid=363121)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=363121)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=363121)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=363121)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=363121)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=363121)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=363121)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=363121)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=363121)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=363121)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=363121)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=363121)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=363121)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=363121)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=363121)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=363121)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=363121)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=363121)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=363121)     return self._linear_fn(
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=363121)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=363121)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=363121)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=363121)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=363121)     return fn(input, L)
(EngineCore_DP0 pid=363121)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=363121)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=363121)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=363121)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=363121)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=363121)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=363121)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=363121)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=363121)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=363121)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=363121)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=363121)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=363121)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363121)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=363121)     raise PTXASError(error)
(EngineCore_DP0 pid=363121) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=363121) `ptxas` stderr:
(EngineCore_DP0 pid=363121) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=363121) 
(EngineCore_DP0 pid=363121) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmptiiwszag.ptx -o /tmp/tmptiiwszag.ptx.o
(EngineCore_DP0 pid=363121) 
[rank0]:[W125 19:38:37.634507876 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 19:38:39
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:38:43 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:38:43 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=363844) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=363844) 
(EngineCore_DP0 pid=363844) 
(EngineCore_DP0 pid=363844) ================================================================
(EngineCore_DP0 pid=363844) Internal Triton PTX codegen error
(EngineCore_DP0 pid=363844) `ptxas` stderr:
(EngineCore_DP0 pid=363844) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=363844) 
(EngineCore_DP0 pid=363844) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp6_3fnws8.ptx -o /tmp/tmp6_3fnws8.ptx.o
(EngineCore_DP0 pid=363844) 
(EngineCore_DP0 pid=363844) 
(EngineCore_DP0 pid=363844) //
(EngineCore_DP0 pid=363844) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=363844) //
(EngineCore_DP0 pid=363844) 
(EngineCore_DP0 pid=363844) .version 8.7
(EngineCore_DP0 pid=363844) .target sm_121a
(EngineCore_DP0 pid=363844) .address_size 64
(EngineCore_DP0 pid=363844) 
(EngineCore_DP0 pid=363844) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=363844) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=363844)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=363844) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=363844) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=363844) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=363844) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=363844) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=363844) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=363844) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=363844) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=363844) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=363844) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=363844) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=363844) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=363844) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=363844) )
(EngineCore_DP0 pid=363844) .reqntid 512
(EngineCore_DP0 pid=363844) {
(EngineCore_DP0 pid=363844) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=363844) 	.reg .b16 	%rs<32>;
(EngineCore_DP0 pid=363844) 	.reg .b32 	%r<122>;
(EngineCore_DP0 pid=363844) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=363844) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=363844) $L__func_begin0:
(EngineCore_DP0 pid=363844) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=363844) 
(EngineCore_DP0 pid=363844) // %bb.0:
(EngineCore_DP0 pid=363844) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=363844) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=363844) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=363844) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=363844) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=363844) $L__tmp0:
(EngineCore_DP0 pid=363844) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=363844) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=363844) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=363844) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=363844) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=363844) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=363844) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=363844) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=363844) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=363844) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=363844) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=363844) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=363844) 	mov.b32 	%r120, 0f2B8CBCCC;
(EngineCore_DP0 pid=363844) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=363844) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=363844) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=363844) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=363844) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=363844) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=363844) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=363844) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=363844) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=363844) 	add.s32 	%r44, %r34, %r33;
(EngineCore_DP0 pid=363844) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=363844) 	add.s32 	%r47, %r34, %r35;
(EngineCore_DP0 pid=363844) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=363844) 	mov.b32 	%r118, 0f00000000;
(EngineCore_DP0 pid=363844) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=363844) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=363844) 	mov.b32 	%r119, %r40;
(EngineCore_DP0 pid=363844) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=363844) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=363844) 	add.s32 	%r50, %r4, %r119;
(EngineCore_DP0 pid=363844) 	setp.lt.s32 	%p2, %r50, %r18;
(EngineCore_DP0 pid=363844) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=363844) 	mad.wide.s32 	%rd6, %r50, 2, %rd1;
(EngineCore_DP0 pid=363844) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=363844) 	// begin inline asm
(EngineCore_DP0 pid=363844) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=363844) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=363844) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=363844) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=363844) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=363844) 	// end inline asm
(EngineCore_DP0 pid=363844) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=363844) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=363844) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=363844) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=363844) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=363844) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=363844) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=363844) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=363844) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=363844) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=363844) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=363844) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=363844) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=363844) $L__tmp1:
(EngineCore_DP0 pid=363844) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	bar.sync 	0;
(EngineCore_DP0 pid=363844) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=363844) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=363844) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=363844) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=363844) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=363844) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=363844) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=363844) 	cvt.f32.bf16 	%r51, %rs23;
(EngineCore_DP0 pid=363844) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	shfl.sync.bfly.b32 	%r52, %r51, 16, 31, -1;
(EngineCore_DP0 pid=363844) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=363844) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	shfl.sync.bfly.b32 	%r54, %r53, 8, 31, -1;
(EngineCore_DP0 pid=363844) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=363844) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	shfl.sync.bfly.b32 	%r56, %r55, 4, 31, -1;
(EngineCore_DP0 pid=363844) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=363844) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	shfl.sync.bfly.b32 	%r58, %r57, 2, 31, -1;
(EngineCore_DP0 pid=363844) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=363844) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	shfl.sync.bfly.b32 	%r60, %r59, 1, 31, -1;
(EngineCore_DP0 pid=363844) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	max.f32 	%r45, %r59, %r60;
(EngineCore_DP0 pid=363844) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	// begin inline asm
(EngineCore_DP0 pid=363844) 	@%p3 st.shared.b32 [ %r44 + 0 ], %r45;
(EngineCore_DP0 pid=363844) 	// end inline asm
(EngineCore_DP0 pid=363844) 	bar.sync 	0;
(EngineCore_DP0 pid=363844) 	// begin inline asm
(EngineCore_DP0 pid=363844) 	@%p4 ld.shared.b32 %r46, [ %r47 + 0 ];
(EngineCore_DP0 pid=363844) 	// end inline asm
(EngineCore_DP0 pid=363844) 	shfl.sync.bfly.b32 	%r61, %r46, 8, 31, -1;
(EngineCore_DP0 pid=363844) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	max.f32 	%r62, %r46, %r61;
(EngineCore_DP0 pid=363844) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	shfl.sync.bfly.b32 	%r63, %r62, 4, 31, -1;
(EngineCore_DP0 pid=363844) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=363844) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	shfl.sync.bfly.b32 	%r65, %r64, 2, 31, -1;
(EngineCore_DP0 pid=363844) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=363844) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	shfl.sync.bfly.b32 	%r67, %r66, 1, 31, -1;
(EngineCore_DP0 pid=363844) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	max.f32 	%r49, %r66, %r67;
(EngineCore_DP0 pid=363844) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=363844) 	// begin inline asm
(EngineCore_DP0 pid=363844) 	@%p19 st.shared.b32 [ %r47 + 0 ], %r49;
(EngineCore_DP0 pid=363844) 	// end inline asm
(EngineCore_DP0 pid=363844) 	bar.sync 	0;
(EngineCore_DP0 pid=363844) 	ld.shared.b32 	%r68, [global_smem];
(EngineCore_DP0 pid=363844) $L__tmp2:
(EngineCore_DP0 pid=363844) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=363844) 	max.f32 	%r118, %r118, %r68;
(EngineCore_DP0 pid=363844) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=363844) 	add.s32 	%r119, %r119, 4096;
(EngineCore_DP0 pid=363844) 	setp.lt.s32 	%p6, %r119, %r19;
(EngineCore_DP0 pid=363844) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=363844) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=363844) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=363844) 	max.f32 	%r120, %r118, 0f2B8CBCCC;
(EngineCore_DP0 pid=363844) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=363844) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=363844) 	mov.b32 	%r70, 0f42FE0000;
(EngineCore_DP0 pid=363844) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=363844) 	div.full.f32 	%r71, %r120, %r70;
(EngineCore_DP0 pid=363844) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=363844) 	max.f32 	%r69, %r71, 0f37810204;
(EngineCore_DP0 pid=363844) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=363844) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=363844) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=363844) 	// begin inline asm
(EngineCore_DP0 pid=363844) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r69 };
(EngineCore_DP0 pid=363844) 	// end inline asm
(EngineCore_DP0 pid=363844) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=363844) 	shl.b32 	%r15, %r20, 1;
(EngineCore_DP0 pid=363844) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=363844) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=363844) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=363844) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=363844) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=363844) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=363844) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=363844) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=363844) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=363844) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=363844) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=363844) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=363844) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=363844) 	div.full.f32 	%r14, %r70, %r120;
(EngineCore_DP0 pid=363844) 	mov.b32 	%r121, 0;
(EngineCore_DP0 pid=363844) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=363844)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=363844) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=363844) 	add.s32 	%r75, %r3, %r121;
(EngineCore_DP0 pid=363844) 	setp.lt.s32 	%p13, %r75, %r15;
(EngineCore_DP0 pid=363844) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=363844) 	shr.u32 	%r76, %r75, 31;
(EngineCore_DP0 pid=363844) 	add.s32 	%r77, %r75, %r76;
(EngineCore_DP0 pid=363844) 	shr.u32 	%r78, %r77, 1;
(EngineCore_DP0 pid=363844) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=363844) 	and.b32 	%r79, %r77, 2147483646;
(EngineCore_DP0 pid=363844) 	sub.s32 	%r80, %r75, %r79;
(EngineCore_DP0 pid=363844) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=363844) 	shl.b32 	%r81, %r80, 1;
(EngineCore_DP0 pid=363844) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=363844) 	mad.lo.s32 	%r82, %r78, 6, %r81;
(EngineCore_DP0 pid=363844) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=363844) 	setp.lt.s32 	%p14, %r82, %r18;
(EngineCore_DP0 pid=363844) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=363844) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=363844) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=363844) 	mad.wide.s32 	%rd8, %r82, 2, %rd1;
(EngineCore_DP0 pid=363844) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=363844) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=363844) 	// begin inline asm
(EngineCore_DP0 pid=363844) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=363844) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=363844) 	// end inline asm
(EngineCore_DP0 pid=363844) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=363844) 	cvt.f32.bf16 	%r83, %rs24;
(EngineCore_DP0 pid=363844) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=363844) 	or.b32 	%r84, %r82, 1;
(EngineCore_DP0 pid=363844) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=363844) 	setp.lt.s32 	%p15, %r84, %r18;
(EngineCore_DP0 pid=363844) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=363844) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=363844) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=363844) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=363844) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=363844) 	// begin inline asm
(EngineCore_DP0 pid=363844) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=363844) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=363844) 	// end inline asm
(EngineCore_DP0 pid=363844) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=363844) 	cvt.f32.bf16 	%r85, %rs26;
(EngineCore_DP0 pid=363844) 	.loc	1 340 48                        // quant_slide_tuned_Llama3.2-3B.py:340:48
(EngineCore_DP0 pid=363844) 	add.s32 	%r86, %r82, 2;
(EngineCore_DP0 pid=363844) 	.loc	1 340 53                        // quant_slide_tuned_Llama3.2-3B.py:340:53
(EngineCore_DP0 pid=363844) 	setp.lt.s32 	%p16, %r86, %r18;
(EngineCore_DP0 pid=363844) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=363844) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=363844) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=363844) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=363844) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=363844) 	// begin inline asm
(EngineCore_DP0 pid=363844) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=363844) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=363844) 	// end inline asm
(EngineCore_DP0 pid=363844) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=363844) 	cvt.f32.bf16 	%r87, %rs28;
(EngineCore_DP0 pid=363844) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=363844) 	add.s32 	%r88, %r82, 3;
(EngineCore_DP0 pid=363844) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=363844) 	setp.lt.s32 	%p17, %r88, %r18;
(EngineCore_DP0 pid=363844) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=363844) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=363844) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=363844) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=363844) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=363844) 	// begin inline asm
(EngineCore_DP0 pid=363844) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=363844) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=363844) 	// end inline asm
(EngineCore_DP0 pid=363844) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=363844) 	cvt.f32.bf16 	%r89, %rs30;
(EngineCore_DP0 pid=363844) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=363844) 	mul.f32 	%r90, %r14, %r83;
(EngineCore_DP0 pid=363844) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=363844) 	cvt.rni.f32.f32 	%r91, %r90;
(EngineCore_DP0 pid=363844) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=363844) 	max.f32 	%r92, %r91, 0fC3000000;
(EngineCore_DP0 pid=363844) 	min.f32 	%r93, %r92, 0f42FE0000;
(EngineCore_DP0 pid=363844) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=363844) 	cvt.rzi.s32.f32 	%r94, %r93;
(EngineCore_DP0 pid=363844) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=363844) 	and.b32 	%r95, %r94, 255;
(EngineCore_DP0 pid=363844) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=363844) 	mul.f32 	%r96, %r14, %r85;
(EngineCore_DP0 pid=363844) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=363844) 	cvt.rni.f32.f32 	%r97, %r96;
(EngineCore_DP0 pid=363844) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=363844) 	mul.f32 	%r98, %r14, %r87;
(EngineCore_DP0 pid=363844) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=363844) 	cvt.rni.f32.f32 	%r99, %r98;
(EngineCore_DP0 pid=363844) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=363844) 	mul.f32 	%r100, %r14, %r89;
(EngineCore_DP0 pid=363844) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=363844) 	cvt.rni.f32.f32 	%r101, %r100;
(EngineCore_DP0 pid=363844) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=363844) 	max.f32 	%r102, %r101, 0fC3000000;
(EngineCore_DP0 pid=363844) 	min.f32 	%r103, %r102, 0f42FE0000;
(EngineCore_DP0 pid=363844) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=363844) 	cvt.rzi.s32.f32 	%r104, %r103;
(EngineCore_DP0 pid=363844) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=363844) 	max.f32 	%r105, %r99, 0fC3000000;
(EngineCore_DP0 pid=363844) 	max.f32 	%r106, %r97, 0fC3000000;
(EngineCore_DP0 pid=363844) 	min.f32 	%r107, %r106, 0f42FE0000;
(EngineCore_DP0 pid=363844) 	min.f32 	%r108, %r105, 0f42FE0000;
(EngineCore_DP0 pid=363844) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=363844) 	cvt.rzi.s32.f32 	%r109, %r108;
(EngineCore_DP0 pid=363844) 	cvt.rzi.s32.f32 	%r110, %r107;
(EngineCore_DP0 pid=363844) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=363844) 	shl.b32 	%r111, %r110, 8;
(EngineCore_DP0 pid=363844) 	shl.b32 	%r112, %r109, 16;
(EngineCore_DP0 pid=363844) 	and.b32 	%r113, %r112, 16711680;
(EngineCore_DP0 pid=363844) 	and.b32 	%r114, %r111, 65280;
(EngineCore_DP0 pid=363844) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=363844) 	or.b32 	%r115, %r114, %r95;
(EngineCore_DP0 pid=363844) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=363844) 	or.b32 	%r116, %r115, %r113;
(EngineCore_DP0 pid=363844) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=363844) 	shl.b32 	%r117, %r104, 24;
(EngineCore_DP0 pid=363844) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=363844) 	or.b32 	%r73, %r116, %r117;
(EngineCore_DP0 pid=363844) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=363844) 	mad.wide.s32 	%rd12, %r75, 4, %rd2;
(EngineCore_DP0 pid=363844) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=363844) 	// begin inline asm
(EngineCore_DP0 pid=363844) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r73 };
(EngineCore_DP0 pid=363844) 	// end inline asm
(EngineCore_DP0 pid=363844) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=363844) 	add.s32 	%r121, %r121, 512;
(EngineCore_DP0 pid=363844) 	setp.lt.s32 	%p18, %r121, %r15;
(EngineCore_DP0 pid=363844) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=363844) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=363844) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=363844) 	ret;
(EngineCore_DP0 pid=363844) $L__tmp3:
(EngineCore_DP0 pid=363844) $L__func_end0:
(EngineCore_DP0 pid=363844)                                         // -- End function
(EngineCore_DP0 pid=363844) }
(EngineCore_DP0 pid=363844) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=363844) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=363844) 	.section	.debug_abbrev
(EngineCore_DP0 pid=363844) 	{
(EngineCore_DP0 pid=363844) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=363844) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=363844) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=363844) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=363844) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=363844) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=363844) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=363844) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=363844) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=363844) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=363844) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=363844) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=363844) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=363844) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=363844) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=363844) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=363844) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=363844) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=363844) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=363844) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=363844) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=363844) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=363844) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=363844) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=363844) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=363844) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=363844) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=363844) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=363844) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=363844) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=363844) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=363844) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=363844) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=363844) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=363844) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=363844) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=363844) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=363844) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=363844) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=363844) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=363844) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=363844) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=363844) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=363844) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=363844) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=363844) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=363844) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=363844) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=363844) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=363844) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=363844) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=363844) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=363844) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=363844) 	}
(EngineCore_DP0 pid=363844) 	.section	.debug_info
(EngineCore_DP0 pid=363844) 	{
(EngineCore_DP0 pid=363844) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=363844) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=363844) .b8 0
(EngineCore_DP0 pid=363844) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=363844) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=363844) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=363844) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=363844) .b8 114
(EngineCore_DP0 pid=363844) .b8 105
(EngineCore_DP0 pid=363844) .b8 116
(EngineCore_DP0 pid=363844) .b8 111
(EngineCore_DP0 pid=363844) .b8 110
(EngineCore_DP0 pid=363844) .b8 0
(EngineCore_DP0 pid=363844) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=363844) .b8 0
(EngineCore_DP0 pid=363844) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=363844) .b8 117
(EngineCore_DP0 pid=363844) .b8 97
(EngineCore_DP0 pid=363844) .b8 110
(EngineCore_DP0 pid=363844) .b8 116
(EngineCore_DP0 pid=363844) .b8 95
(EngineCore_DP0 pid=363844) .b8 115
(EngineCore_DP0 pid=363844) .b8 108
(EngineCore_DP0 pid=363844) .b8 105
(EngineCore_DP0 pid=363844) .b8 100
(EngineCore_DP0 pid=363844) .b8 101
(EngineCore_DP0 pid=363844) .b8 95
(EngineCore_DP0 pid=363844) .b8 116
(EngineCore_DP0 pid=363844) .b8 117
(EngineCore_DP0 pid=363844) .b8 110
(EngineCore_DP0 pid=363844) .b8 101
(EngineCore_DP0 pid=363844) .b8 100
(EngineCore_DP0 pid=363844) .b8 95
(EngineCore_DP0 pid=363844) .b8 76
(EngineCore_DP0 pid=363844) .b8 108
(EngineCore_DP0 pid=363844) .b8 97
(EngineCore_DP0 pid=363844) .b8 109
(EngineCore_DP0 pid=363844) .b8 97
(EngineCore_DP0 pid=363844) .b8 51
(EngineCore_DP0 pid=363844) .b8 46
(EngineCore_DP0 pid=363844) .b8 50
(EngineCore_DP0 pid=363844) .b8 45
(EngineCore_DP0 pid=363844) .b8 51
(EngineCore_DP0 pid=363844) .b8 66
(EngineCore_DP0 pid=363844) .b8 46
(EngineCore_DP0 pid=363844) .b8 112
(EngineCore_DP0 pid=363844) .b8 121
(EngineCore_DP0 pid=363844) .b8 0
(EngineCore_DP0 pid=363844) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=363844) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=363844) .b8 114
(EngineCore_DP0 pid=363844) .b8 111
(EngineCore_DP0 pid=363844) .b8 111
(EngineCore_DP0 pid=363844) .b8 116
(EngineCore_DP0 pid=363844) .b8 47
(EngineCore_DP0 pid=363844) .b8 118
(EngineCore_DP0 pid=363844) .b8 108
(EngineCore_DP0 pid=363844) .b8 108
(EngineCore_DP0 pid=363844) .b8 109
(EngineCore_DP0 pid=363844) .b8 98
(EngineCore_DP0 pid=363844) .b8 101
(EngineCore_DP0 pid=363844) .b8 110
(EngineCore_DP0 pid=363844) .b8 99
(EngineCore_DP0 pid=363844) .b8 104
(EngineCore_DP0 pid=363844) .b8 47
(EngineCore_DP0 pid=363844) .b8 115
(EngineCore_DP0 pid=363844) .b8 108
(EngineCore_DP0 pid=363844) .b8 105
(EngineCore_DP0 pid=363844) .b8 100
(EngineCore_DP0 pid=363844) .b8 101
(EngineCore_DP0 pid=363844) .b8 115
(EngineCore_DP0 pid=363844) .b8 112
(EngineCore_DP0 pid=363844) .b8 97
(EngineCore_DP0 pid=363844) .b8 114
(EngineCore_DP0 pid=363844) .b8 115
(EngineCore_DP0 pid=363844) .b8 101
(EngineCore_DP0 pid=363844) .b8 47
(EngineCore_DP0 pid=363844) .b8 99
(EngineCore_DP0 pid=363844) .b8 115
(EngineCore_DP0 pid=363844) .b8 114
(EngineCore_DP0 pid=363844) .b8 99
(EngineCore_DP0 pid=363844) .b8 47
(EngineCore_DP0 pid=363844) .b8 102
(EngineCore_DP0 pid=363844) .b8 117
(EngineCore_DP0 pid=363844) .b8 115
(EngineCore_DP0 pid=363844) .b8 101
(EngineCore_DP0 pid=363844) .b8 100
(EngineCore_DP0 pid=363844) .b8 95
(EngineCore_DP0 pid=363844) .b8 113
(EngineCore_DP0 pid=363844) .b8 117
(EngineCore_DP0 pid=363844) .b8 97
(EngineCore_DP0 pid=363844) .b8 110
(EngineCore_DP0 pid=363844) .b8 116
(EngineCore_DP0 pid=363844) .b8 95
(EngineCore_DP0 pid=363844) .b8 115
(EngineCore_DP0 pid=363844) .b8 108
(EngineCore_DP0 pid=363844) .b8 105
(EngineCore_DP0 pid=363844) .b8 100
(EngineCore_DP0 pid=363844) .b8 101
(EngineCore_DP0 pid=363844) .b8 95
(EngineCore_DP0 pid=363844) .b8 116
(EngineCore_DP0 pid=363844) .b8 114
(EngineCore_DP0 pid=363844) .b8 105
(EngineCore_DP0 pid=363844) .b8 116
(EngineCore_DP0 pid=363844) .b8 111
(EngineCore_DP0 pid=363844) .b8 110
(EngineCore_DP0 pid=363844) .b8 47
(EngineCore_DP0 pid=363844) .b8 98
(EngineCore_DP0 pid=363844) .b8 117
(EngineCore_DP0 pid=363844) .b8 105
(EngineCore_DP0 pid=363844) .b8 108
(EngineCore_DP0 pid=363844) .b8 100
(EngineCore_DP0 pid=363844) .b8 47
(EngineCore_DP0 pid=363844) .b8 71
(EngineCore_DP0 pid=363844) .b8 66
(EngineCore_DP0 pid=363844) .b8 49
(EngineCore_DP0 pid=363844) .b8 48
(EngineCore_DP0 pid=363844) .b8 95
(EngineCore_DP0 pid=363844) .b8 99
(EngineCore_DP0 pid=363844) .b8 99
(EngineCore_DP0 pid=363844) .b8 49
(EngineCore_DP0 pid=363844) .b8 50
(EngineCore_DP0 pid=363844) .b8 49
(EngineCore_DP0 pid=363844) .b8 95
(EngineCore_DP0 pid=363844) .b8 112
(EngineCore_DP0 pid=363844) .b8 121
(EngineCore_DP0 pid=363844) .b8 51
(EngineCore_DP0 pid=363844) .b8 49
(EngineCore_DP0 pid=363844) .b8 50
(EngineCore_DP0 pid=363844) .b8 95
(EngineCore_DP0 pid=363844) .b8 99
(EngineCore_DP0 pid=363844) .b8 117
(EngineCore_DP0 pid=363844) .b8 49
(EngineCore_DP0 pid=363844) .b8 50
(EngineCore_DP0 pid=363844) .b8 57
(EngineCore_DP0 pid=363844) .b8 95
(EngineCore_DP0 pid=363844) .b8 97
(EngineCore_DP0 pid=363844) .b8 97
(EngineCore_DP0 pid=363844) .b8 114
(EngineCore_DP0 pid=363844) .b8 99
(EngineCore_DP0 pid=363844) .b8 104
(EngineCore_DP0 pid=363844) .b8 54
(EngineCore_DP0 pid=363844) .b8 52
(EngineCore_DP0 pid=363844) .b8 0
(EngineCore_DP0 pid=363844) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=363844) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=363844) .b8 113
(EngineCore_DP0 pid=363844) .b8 117
(EngineCore_DP0 pid=363844) .b8 97
(EngineCore_DP0 pid=363844) .b8 110
(EngineCore_DP0 pid=363844) .b8 116
(EngineCore_DP0 pid=363844) .b8 95
(EngineCore_DP0 pid=363844) .b8 115
(EngineCore_DP0 pid=363844) .b8 108
(EngineCore_DP0 pid=363844) .b8 105
(EngineCore_DP0 pid=363844) .b8 100
(EngineCore_DP0 pid=363844) .b8 101
(EngineCore_DP0 pid=363844) .b8 95
(EngineCore_DP0 pid=363844) .b8 105
(EngineCore_DP0 pid=363844) .b8 110
(EngineCore_DP0 pid=363844) .b8 116
(EngineCore_DP0 pid=363844) .b8 56
(EngineCore_DP0 pid=363844) .b8 95
(EngineCore_DP0 pid=363844) .b8 107
(EngineCore_DP0 pid=363844) .b8 101
(EngineCore_DP0 pid=363844) .b8 114
(EngineCore_DP0 pid=363844) .b8 110
(EngineCore_DP0 pid=363844) .b8 101
(EngineCore_DP0 pid=363844) .b8 108
(EngineCore_DP0 pid=363844) .b8 0
(EngineCore_DP0 pid=363844) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=363844) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=363844) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=363844) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=363844) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=363844) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=363844) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=363844) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=363844) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=363844) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=363844) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=363844) .b8 1
(EngineCore_DP0 pid=363844) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=363844) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=363844) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=363844) 	}
(EngineCore_DP0 pid=363844) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=363844) 
(EngineCore_DP0 pid=363844) ================================================================
(EngineCore_DP0 pid=363844) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=363844) 
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp6_3fnws8.ptx', '-o', '/tmp/tmp6_3fnws8.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866] 
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866] 
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866] 
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp6_3fnws8.ptx -o /tmp/tmp6_3fnws8.ptx.o
(EngineCore_DP0 pid=363844) ERROR 01-25 19:39:14 [core.py:866] 

STDERR:
[2026-01-25 19:38:43] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:38:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:38:43] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:38:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:38:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:38:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:38:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:38:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:38:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:38:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:38:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:38:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:38:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:38:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:38:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:38:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:38:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:38:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:38:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=363844) [2026-01-25 19:38:47] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=363844) [2026-01-25 19:38:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=363844) [2026-01-25 19:38:47] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=363844) [2026-01-25 19:38:47] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=363844) [2026-01-25 19:38:47] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=363844) [2026-01-25 19:38:47] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=363844) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=363844) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.00s/it]
(EngineCore_DP0 pid=363844) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.00s/it]
(EngineCore_DP0 pid=363844) 
(EngineCore_DP0 pid=363844) [2026-01-25 19:39:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=363844) [2026-01-25 19:39:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=363844) [2026-01-25 19:39:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=363844) [2026-01-25 19:39:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9437184 bytes
(EngineCore_DP0 pid=363844) [2026-01-25 19:39:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=363844) [2026-01-25 19:39:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50331648 bytes
(EngineCore_DP0 pid=363844) [2026-01-25 19:39:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=363844) [2026-01-25 19:39:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25264128 bytes
(EngineCore_DP0 pid=363844) Process EngineCore_DP0:
(EngineCore_DP0 pid=363844) Traceback (most recent call last):
(EngineCore_DP0 pid=363844)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=363844)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=363844)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=363844)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=363844) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp6_3fnws8.ptx', '-o', '/tmp/tmp6_3fnws8.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=363844) 
(EngineCore_DP0 pid=363844) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=363844) 
(EngineCore_DP0 pid=363844) Traceback (most recent call last):
(EngineCore_DP0 pid=363844)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=363844)     self.run()
(EngineCore_DP0 pid=363844)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=363844)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=363844)     raise e
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=363844)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=363844)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=363844)     super().__init__(
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=363844)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=363844)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=363844)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=363844)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=363844)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=363844)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=363844)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=363844)     return func(*args, **kwargs)
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=363844)     return func(*args, **kwargs)
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=363844)     self.model_runner.profile_run()
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=363844)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=363844)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=363844)     return func(*args, **kwargs)
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=363844)     outputs = self.model(
(EngineCore_DP0 pid=363844)               ^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=363844)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=363844)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=363844)     model_output = self.model(
(EngineCore_DP0 pid=363844)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=363844)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=363844)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=363844)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=363844)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=363844)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=363844)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=363844)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=363844)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=363844)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=363844)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=363844)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=363844)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=363844)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=363844)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=363844)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=363844)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=363844)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=363844)     return self._linear_fn(
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=363844)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=363844)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=363844)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=363844)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=363844)     return fn(input, L)
(EngineCore_DP0 pid=363844)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=363844)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=363844)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=363844)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=363844)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=363844)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=363844)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=363844)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=363844)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=363844)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=363844)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=363844)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=363844)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=363844)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=363844)     raise PTXASError(error)
(EngineCore_DP0 pid=363844) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=363844) `ptxas` stderr:
(EngineCore_DP0 pid=363844) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=363844) 
(EngineCore_DP0 pid=363844) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp6_3fnws8.ptx -o /tmp/tmp6_3fnws8.ptx.o
(EngineCore_DP0 pid=363844) 
[rank0]:[W125 19:39:15.329983242 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 19:39:16
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:39:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:39:21 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=364570) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=364570) 
(EngineCore_DP0 pid=364570) 
(EngineCore_DP0 pid=364570) ================================================================
(EngineCore_DP0 pid=364570) Internal Triton PTX codegen error
(EngineCore_DP0 pid=364570) `ptxas` stderr:
(EngineCore_DP0 pid=364570) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=364570) 
(EngineCore_DP0 pid=364570) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp5idyhbiy.ptx -o /tmp/tmp5idyhbiy.ptx.o
(EngineCore_DP0 pid=364570) 
(EngineCore_DP0 pid=364570) 
(EngineCore_DP0 pid=364570) //
(EngineCore_DP0 pid=364570) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=364570) //
(EngineCore_DP0 pid=364570) 
(EngineCore_DP0 pid=364570) .version 8.7
(EngineCore_DP0 pid=364570) .target sm_121a
(EngineCore_DP0 pid=364570) .address_size 64
(EngineCore_DP0 pid=364570) 
(EngineCore_DP0 pid=364570) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=364570) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=364570)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=364570) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=364570) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=364570) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=364570) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=364570) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=364570) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=364570) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=364570) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=364570) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=364570) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=364570) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=364570) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=364570) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=364570) )
(EngineCore_DP0 pid=364570) .reqntid 512
(EngineCore_DP0 pid=364570) {
(EngineCore_DP0 pid=364570) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=364570) 	.reg .b16 	%rs<40>;
(EngineCore_DP0 pid=364570) 	.reg .b32 	%r<160>;
(EngineCore_DP0 pid=364570) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=364570) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=364570) $L__func_begin0:
(EngineCore_DP0 pid=364570) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=364570) 
(EngineCore_DP0 pid=364570) // %bb.0:
(EngineCore_DP0 pid=364570) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=364570) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=364570) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=364570) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=364570) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=364570) $L__tmp0:
(EngineCore_DP0 pid=364570) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=364570) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=364570) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=364570) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=364570) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=364570) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=364570) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=364570) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=364570) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=364570) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=364570) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=364570) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=364570) 	mov.b32 	%r158, 0f2B8CBCCC;
(EngineCore_DP0 pid=364570) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=364570) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=364570) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=364570) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=364570) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=364570) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=364570) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=364570) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=364570) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=364570) 	add.s32 	%r45, %r35, %r34;
(EngineCore_DP0 pid=364570) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=364570) 	add.s32 	%r48, %r35, %r36;
(EngineCore_DP0 pid=364570) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=364570) 	mov.b32 	%r156, 0f00000000;
(EngineCore_DP0 pid=364570) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=364570) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=364570) 	mov.b32 	%r157, %r41;
(EngineCore_DP0 pid=364570) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=364570) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=364570) 	add.s32 	%r51, %r4, %r157;
(EngineCore_DP0 pid=364570) 	setp.lt.s32 	%p2, %r51, %r19;
(EngineCore_DP0 pid=364570) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=364570) 	mad.wide.s32 	%rd6, %r51, 2, %rd1;
(EngineCore_DP0 pid=364570) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=364570) 	// begin inline asm
(EngineCore_DP0 pid=364570) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=364570) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=364570) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=364570) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=364570) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=364570) 	// end inline asm
(EngineCore_DP0 pid=364570) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=364570) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=364570) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=364570) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=364570) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=364570) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=364570) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=364570) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=364570) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=364570) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=364570) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=364570) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=364570) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=364570) $L__tmp1:
(EngineCore_DP0 pid=364570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	bar.sync 	0;
(EngineCore_DP0 pid=364570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=364570) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=364570) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=364570) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=364570) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=364570) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=364570) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=364570) 	cvt.f32.bf16 	%r52, %rs23;
(EngineCore_DP0 pid=364570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	shfl.sync.bfly.b32 	%r53, %r52, 16, 31, -1;
(EngineCore_DP0 pid=364570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=364570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	shfl.sync.bfly.b32 	%r55, %r54, 8, 31, -1;
(EngineCore_DP0 pid=364570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=364570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	shfl.sync.bfly.b32 	%r57, %r56, 4, 31, -1;
(EngineCore_DP0 pid=364570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=364570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	shfl.sync.bfly.b32 	%r59, %r58, 2, 31, -1;
(EngineCore_DP0 pid=364570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=364570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	shfl.sync.bfly.b32 	%r61, %r60, 1, 31, -1;
(EngineCore_DP0 pid=364570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	max.f32 	%r46, %r60, %r61;
(EngineCore_DP0 pid=364570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	// begin inline asm
(EngineCore_DP0 pid=364570) 	@%p3 st.shared.b32 [ %r45 + 0 ], %r46;
(EngineCore_DP0 pid=364570) 	// end inline asm
(EngineCore_DP0 pid=364570) 	bar.sync 	0;
(EngineCore_DP0 pid=364570) 	// begin inline asm
(EngineCore_DP0 pid=364570) 	@%p4 ld.shared.b32 %r47, [ %r48 + 0 ];
(EngineCore_DP0 pid=364570) 	// end inline asm
(EngineCore_DP0 pid=364570) 	shfl.sync.bfly.b32 	%r62, %r47, 8, 31, -1;
(EngineCore_DP0 pid=364570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	max.f32 	%r63, %r47, %r62;
(EngineCore_DP0 pid=364570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	shfl.sync.bfly.b32 	%r64, %r63, 4, 31, -1;
(EngineCore_DP0 pid=364570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=364570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	shfl.sync.bfly.b32 	%r66, %r65, 2, 31, -1;
(EngineCore_DP0 pid=364570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=364570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	shfl.sync.bfly.b32 	%r68, %r67, 1, 31, -1;
(EngineCore_DP0 pid=364570) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	max.f32 	%r50, %r67, %r68;
(EngineCore_DP0 pid=364570) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=364570) 	// begin inline asm
(EngineCore_DP0 pid=364570) 	@%p27 st.shared.b32 [ %r48 + 0 ], %r50;
(EngineCore_DP0 pid=364570) 	// end inline asm
(EngineCore_DP0 pid=364570) 	bar.sync 	0;
(EngineCore_DP0 pid=364570) 	ld.shared.b32 	%r69, [global_smem];
(EngineCore_DP0 pid=364570) $L__tmp2:
(EngineCore_DP0 pid=364570) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=364570) 	max.f32 	%r156, %r156, %r69;
(EngineCore_DP0 pid=364570) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=364570) 	add.s32 	%r157, %r157, 4096;
(EngineCore_DP0 pid=364570) 	setp.lt.s32 	%p6, %r157, %r20;
(EngineCore_DP0 pid=364570) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=364570) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=364570) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=364570) 	max.f32 	%r158, %r156, 0f2B8CBCCC;
(EngineCore_DP0 pid=364570) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=364570) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=364570) 	mov.b32 	%r71, 0f42FE0000;
(EngineCore_DP0 pid=364570) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=364570) 	div.full.f32 	%r72, %r158, %r71;
(EngineCore_DP0 pid=364570) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=364570) 	max.f32 	%r70, %r72, 0f37810204;
(EngineCore_DP0 pid=364570) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=364570) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=364570) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=364570) 	// begin inline asm
(EngineCore_DP0 pid=364570) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r70 };
(EngineCore_DP0 pid=364570) 	// end inline asm
(EngineCore_DP0 pid=364570) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=364570) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=364570) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=364570) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=364570) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=364570) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=364570) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=364570) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=364570) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=364570) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=364570) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=364570) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=364570) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=364570) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=364570) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=364570) 	div.full.f32 	%r14, %r71, %r158;
(EngineCore_DP0 pid=364570) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=364570) 	mov.b32 	%r159, 0;
(EngineCore_DP0 pid=364570) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=364570)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=364570) 	.loc	1 327 31                        // quant_slide_tuned_Llama3.2-3B.py:327:31
(EngineCore_DP0 pid=364570) 	add.s32 	%r76, %r16, %r159;
(EngineCore_DP0 pid=364570) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=364570) 	add.s32 	%r77, %r159, 1;
(EngineCore_DP0 pid=364570) 	setp.lt.s32 	%p17, %r76, %r15;
(EngineCore_DP0 pid=364570) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=364570) 	shr.u32 	%r78, %r76, 1;
(EngineCore_DP0 pid=364570) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=364570) 	shr.u32 	%r79, %r77, 31;
(EngineCore_DP0 pid=364570) 	add.s32 	%r80, %r77, %r79;
(EngineCore_DP0 pid=364570) 	and.b32 	%r81, %r80, 2147483646;
(EngineCore_DP0 pid=364570) 	sub.s32 	%r82, %r77, %r81;
(EngineCore_DP0 pid=364570) 	.loc	1 333 22                        // quant_slide_tuned_Llama3.2-3B.py:333:22
(EngineCore_DP0 pid=364570) 	mul.lo.s32 	%r83, %r78, 6;
(EngineCore_DP0 pid=364570) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=364570) 	shl.b32 	%r84, %r82, 1;
(EngineCore_DP0 pid=364570) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=364570) 	add.s32 	%r85, %r83, %r84;
(EngineCore_DP0 pid=364570) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=364570) 	setp.lt.s32 	%p18, %r83, %r19;
(EngineCore_DP0 pid=364570) 	setp.lt.s32 	%p19, %r85, %r19;
(EngineCore_DP0 pid=364570) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=364570) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=364570) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=364570) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=364570) 	mad.wide.s32 	%rd8, %r83, 2, %rd1;
(EngineCore_DP0 pid=364570) 	mad.wide.s32 	%rd9, %r85, 2, %rd1;
(EngineCore_DP0 pid=364570) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=364570) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=364570) 	// begin inline asm
(EngineCore_DP0 pid=364570) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=364570) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=364570) 	// end inline asm
(EngineCore_DP0 pid=364570) 	// begin inline asm
(EngineCore_DP0 pid=364570) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=364570) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=364570) 	// end inline asm
(EngineCore_DP0 pid=364570) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=364570) 	cvt.f32.bf16 	%r86, %rs24;
(EngineCore_DP0 pid=364570) 	cvt.f32.bf16 	%r87, %rs26;
(EngineCore_DP0 pid=364570) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=364570) 	or.b32 	%r88, %r83, 1;
(EngineCore_DP0 pid=364570) 	or.b32 	%r89, %r85, 1;
(EngineCore_DP0 pid=364570) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=364570) 	setp.lt.s32 	%p20, %r88, %r19;
(EngineCore_DP0 pid=364570) 	setp.lt.s32 	%p21, %r89, %r19;
(EngineCore_DP0 pid=364570) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=364570) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=364570) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=364570) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=364570) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=364570) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=364570) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=364570) 	// begin inline asm
(EngineCore_DP0 pid=364570) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=364570) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=364570) 	// end inline asm
(EngineCore_DP0 pid=364570) 	// begin inline asm
(EngineCore_DP0 pid=364570) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=364570) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=364570) 	// end inline asm
(EngineCore_DP0 pid=364570) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=364570) 	cvt.f32.bf16 	%r90, %rs28;
(EngineCore_DP0 pid=364570) 	cvt.f32.bf16 	%r91, %rs30;
(EngineCore_DP0 pid=364570) 	.loc	1 340 48                        // quant_slide_tuned_Llama3.2-3B.py:340:48
(EngineCore_DP0 pid=364570) 	add.s32 	%r92, %r83, 2;
(EngineCore_DP0 pid=364570) 	add.s32 	%r93, %r85, 2;
(EngineCore_DP0 pid=364570) 	.loc	1 340 53                        // quant_slide_tuned_Llama3.2-3B.py:340:53
(EngineCore_DP0 pid=364570) 	setp.lt.s32 	%p22, %r92, %r19;
(EngineCore_DP0 pid=364570) 	setp.lt.s32 	%p23, %r93, %r19;
(EngineCore_DP0 pid=364570) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=364570) 	and.pred 	%p13, %p17, %p22;
(EngineCore_DP0 pid=364570) 	and.pred 	%p14, %p17, %p23;
(EngineCore_DP0 pid=364570) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=364570) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=364570) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=364570) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=364570) 	// begin inline asm
(EngineCore_DP0 pid=364570) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=364570) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=364570) 	// end inline asm
(EngineCore_DP0 pid=364570) 	// begin inline asm
(EngineCore_DP0 pid=364570) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=364570) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=364570) 	// end inline asm
(EngineCore_DP0 pid=364570) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=364570) 	cvt.f32.bf16 	%r94, %rs32;
(EngineCore_DP0 pid=364570) 	cvt.f32.bf16 	%r95, %rs34;
(EngineCore_DP0 pid=364570) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=364570) 	add.s32 	%r96, %r83, 3;
(EngineCore_DP0 pid=364570) 	add.s32 	%r97, %r85, 3;
(EngineCore_DP0 pid=364570) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=364570) 	setp.lt.s32 	%p24, %r96, %r19;
(EngineCore_DP0 pid=364570) 	setp.lt.s32 	%p25, %r97, %r19;
(EngineCore_DP0 pid=364570) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=364570) 	and.pred 	%p15, %p17, %p24;
(EngineCore_DP0 pid=364570) 	and.pred 	%p16, %p17, %p25;
(EngineCore_DP0 pid=364570) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=364570) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=364570) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=364570) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=364570) 	// begin inline asm
(EngineCore_DP0 pid=364570) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=364570) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=364570) 	// end inline asm
(EngineCore_DP0 pid=364570) 	// begin inline asm
(EngineCore_DP0 pid=364570) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=364570) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=364570) 	// end inline asm
(EngineCore_DP0 pid=364570) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=364570) 	cvt.f32.bf16 	%r98, %rs36;
(EngineCore_DP0 pid=364570) 	cvt.f32.bf16 	%r99, %rs38;
(EngineCore_DP0 pid=364570) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=364570) 	mul.f32 	%r100, %r14, %r86;
(EngineCore_DP0 pid=364570) 	mul.f32 	%r101, %r14, %r87;
(EngineCore_DP0 pid=364570) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=364570) 	cvt.rni.f32.f32 	%r102, %r100;
(EngineCore_DP0 pid=364570) 	cvt.rni.f32.f32 	%r103, %r101;
(EngineCore_DP0 pid=364570) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=364570) 	max.f32 	%r104, %r102, 0fC3000000;
(EngineCore_DP0 pid=364570) 	min.f32 	%r105, %r104, 0f42FE0000;
(EngineCore_DP0 pid=364570) 	max.f32 	%r106, %r103, 0fC3000000;
(EngineCore_DP0 pid=364570) 	min.f32 	%r107, %r106, 0f42FE0000;
(EngineCore_DP0 pid=364570) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=364570) 	cvt.rzi.s32.f32 	%r108, %r105;
(EngineCore_DP0 pid=364570) 	cvt.rzi.s32.f32 	%r109, %r107;
(EngineCore_DP0 pid=364570) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=364570) 	and.b32 	%r110, %r108, 255;
(EngineCore_DP0 pid=364570) 	and.b32 	%r111, %r109, 255;
(EngineCore_DP0 pid=364570) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=364570) 	mul.f32 	%r112, %r14, %r90;
(EngineCore_DP0 pid=364570) 	mul.f32 	%r113, %r14, %r91;
(EngineCore_DP0 pid=364570) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=364570) 	cvt.rni.f32.f32 	%r114, %r112;
(EngineCore_DP0 pid=364570) 	cvt.rni.f32.f32 	%r115, %r113;
(EngineCore_DP0 pid=364570) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=364570) 	mul.f32 	%r116, %r14, %r94;
(EngineCore_DP0 pid=364570) 	mul.f32 	%r117, %r14, %r95;
(EngineCore_DP0 pid=364570) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=364570) 	cvt.rni.f32.f32 	%r118, %r116;
(EngineCore_DP0 pid=364570) 	cvt.rni.f32.f32 	%r119, %r117;
(EngineCore_DP0 pid=364570) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=364570) 	mul.f32 	%r120, %r14, %r98;
(EngineCore_DP0 pid=364570) 	mul.f32 	%r121, %r14, %r99;
(EngineCore_DP0 pid=364570) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=364570) 	cvt.rni.f32.f32 	%r122, %r120;
(EngineCore_DP0 pid=364570) 	cvt.rni.f32.f32 	%r123, %r121;
(EngineCore_DP0 pid=364570) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=364570) 	max.f32 	%r124, %r122, 0fC3000000;
(EngineCore_DP0 pid=364570) 	min.f32 	%r125, %r124, 0f42FE0000;
(EngineCore_DP0 pid=364570) 	max.f32 	%r126, %r123, 0fC3000000;
(EngineCore_DP0 pid=364570) 	min.f32 	%r127, %r126, 0f42FE0000;
(EngineCore_DP0 pid=364570) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=364570) 	cvt.rzi.s32.f32 	%r128, %r125;
(EngineCore_DP0 pid=364570) 	cvt.rzi.s32.f32 	%r129, %r127;
(EngineCore_DP0 pid=364570) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=364570) 	max.f32 	%r130, %r118, 0fC3000000;
(EngineCore_DP0 pid=364570) 	max.f32 	%r131, %r114, 0fC3000000;
(EngineCore_DP0 pid=364570) 	min.f32 	%r132, %r131, 0f42FE0000;
(EngineCore_DP0 pid=364570) 	min.f32 	%r133, %r130, 0f42FE0000;
(EngineCore_DP0 pid=364570) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=364570) 	cvt.rzi.s32.f32 	%r134, %r133;
(EngineCore_DP0 pid=364570) 	cvt.rzi.s32.f32 	%r135, %r132;
(EngineCore_DP0 pid=364570) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=364570) 	shl.b32 	%r136, %r135, 8;
(EngineCore_DP0 pid=364570) 	shl.b32 	%r137, %r134, 16;
(EngineCore_DP0 pid=364570) 	and.b32 	%r138, %r137, 16711680;
(EngineCore_DP0 pid=364570) 	and.b32 	%r139, %r136, 65280;
(EngineCore_DP0 pid=364570) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=364570) 	or.b32 	%r140, %r139, %r110;
(EngineCore_DP0 pid=364570) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=364570) 	max.f32 	%r141, %r119, 0fC3000000;
(EngineCore_DP0 pid=364570) 	max.f32 	%r142, %r115, 0fC3000000;
(EngineCore_DP0 pid=364570) 	min.f32 	%r143, %r142, 0f42FE0000;
(EngineCore_DP0 pid=364570) 	min.f32 	%r144, %r141, 0f42FE0000;
(EngineCore_DP0 pid=364570) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=364570) 	cvt.rzi.s32.f32 	%r145, %r144;
(EngineCore_DP0 pid=364570) 	cvt.rzi.s32.f32 	%r146, %r143;
(EngineCore_DP0 pid=364570) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=364570) 	shl.b32 	%r147, %r146, 8;
(EngineCore_DP0 pid=364570) 	shl.b32 	%r148, %r145, 16;
(EngineCore_DP0 pid=364570) 	and.b32 	%r149, %r148, 16711680;
(EngineCore_DP0 pid=364570) 	and.b32 	%r150, %r147, 65280;
(EngineCore_DP0 pid=364570) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=364570) 	or.b32 	%r151, %r150, %r111;
(EngineCore_DP0 pid=364570) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=364570) 	or.b32 	%r152, %r140, %r138;
(EngineCore_DP0 pid=364570) 	or.b32 	%r153, %r151, %r149;
(EngineCore_DP0 pid=364570) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=364570) 	shl.b32 	%r154, %r128, 24;
(EngineCore_DP0 pid=364570) 	shl.b32 	%r155, %r129, 24;
(EngineCore_DP0 pid=364570) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=364570) 	or.b32 	%r74, %r152, %r154;
(EngineCore_DP0 pid=364570) 	or.b32 	%r75, %r153, %r155;
(EngineCore_DP0 pid=364570) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=364570) 	mad.wide.s32 	%rd16, %r76, 4, %rd2;
(EngineCore_DP0 pid=364570) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=364570) 	// begin inline asm
(EngineCore_DP0 pid=364570) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r74, %r75 };
(EngineCore_DP0 pid=364570) 	// end inline asm
(EngineCore_DP0 pid=364570) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=364570) 	add.s32 	%r159, %r159, 1024;
(EngineCore_DP0 pid=364570) 	setp.lt.s32 	%p26, %r159, %r15;
(EngineCore_DP0 pid=364570) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=364570) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=364570) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=364570) 	ret;
(EngineCore_DP0 pid=364570) $L__tmp3:
(EngineCore_DP0 pid=364570) $L__func_end0:
(EngineCore_DP0 pid=364570)                                         // -- End function
(EngineCore_DP0 pid=364570) }
(EngineCore_DP0 pid=364570) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=364570) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=364570) 	.section	.debug_abbrev
(EngineCore_DP0 pid=364570) 	{
(EngineCore_DP0 pid=364570) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=364570) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=364570) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=364570) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=364570) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=364570) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=364570) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=364570) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=364570) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=364570) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=364570) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=364570) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=364570) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=364570) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=364570) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=364570) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=364570) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=364570) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=364570) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=364570) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=364570) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=364570) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=364570) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=364570) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=364570) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=364570) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=364570) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=364570) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=364570) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=364570) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=364570) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=364570) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=364570) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=364570) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=364570) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=364570) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=364570) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=364570) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=364570) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=364570) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=364570) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=364570) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=364570) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=364570) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=364570) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=364570) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=364570) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=364570) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=364570) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=364570) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=364570) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=364570) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=364570) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=364570) 	}
(EngineCore_DP0 pid=364570) 	.section	.debug_info
(EngineCore_DP0 pid=364570) 	{
(EngineCore_DP0 pid=364570) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=364570) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=364570) .b8 0
(EngineCore_DP0 pid=364570) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=364570) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=364570) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=364570) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=364570) .b8 114
(EngineCore_DP0 pid=364570) .b8 105
(EngineCore_DP0 pid=364570) .b8 116
(EngineCore_DP0 pid=364570) .b8 111
(EngineCore_DP0 pid=364570) .b8 110
(EngineCore_DP0 pid=364570) .b8 0
(EngineCore_DP0 pid=364570) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=364570) .b8 0
(EngineCore_DP0 pid=364570) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=364570) .b8 117
(EngineCore_DP0 pid=364570) .b8 97
(EngineCore_DP0 pid=364570) .b8 110
(EngineCore_DP0 pid=364570) .b8 116
(EngineCore_DP0 pid=364570) .b8 95
(EngineCore_DP0 pid=364570) .b8 115
(EngineCore_DP0 pid=364570) .b8 108
(EngineCore_DP0 pid=364570) .b8 105
(EngineCore_DP0 pid=364570) .b8 100
(EngineCore_DP0 pid=364570) .b8 101
(EngineCore_DP0 pid=364570) .b8 95
(EngineCore_DP0 pid=364570) .b8 116
(EngineCore_DP0 pid=364570) .b8 117
(EngineCore_DP0 pid=364570) .b8 110
(EngineCore_DP0 pid=364570) .b8 101
(EngineCore_DP0 pid=364570) .b8 100
(EngineCore_DP0 pid=364570) .b8 95
(EngineCore_DP0 pid=364570) .b8 76
(EngineCore_DP0 pid=364570) .b8 108
(EngineCore_DP0 pid=364570) .b8 97
(EngineCore_DP0 pid=364570) .b8 109
(EngineCore_DP0 pid=364570) .b8 97
(EngineCore_DP0 pid=364570) .b8 51
(EngineCore_DP0 pid=364570) .b8 46
(EngineCore_DP0 pid=364570) .b8 50
(EngineCore_DP0 pid=364570) .b8 45
(EngineCore_DP0 pid=364570) .b8 51
(EngineCore_DP0 pid=364570) .b8 66
(EngineCore_DP0 pid=364570) .b8 46
(EngineCore_DP0 pid=364570) .b8 112
(EngineCore_DP0 pid=364570) .b8 121
(EngineCore_DP0 pid=364570) .b8 0
(EngineCore_DP0 pid=364570) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=364570) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=364570) .b8 114
(EngineCore_DP0 pid=364570) .b8 111
(EngineCore_DP0 pid=364570) .b8 111
(EngineCore_DP0 pid=364570) .b8 116
(EngineCore_DP0 pid=364570) .b8 47
(EngineCore_DP0 pid=364570) .b8 118
(EngineCore_DP0 pid=364570) .b8 108
(EngineCore_DP0 pid=364570) .b8 108
(EngineCore_DP0 pid=364570) .b8 109
(EngineCore_DP0 pid=364570) .b8 98
(EngineCore_DP0 pid=364570) .b8 101
(EngineCore_DP0 pid=364570) .b8 110
(EngineCore_DP0 pid=364570) .b8 99
(EngineCore_DP0 pid=364570) .b8 104
(EngineCore_DP0 pid=364570) .b8 47
(EngineCore_DP0 pid=364570) .b8 115
(EngineCore_DP0 pid=364570) .b8 108
(EngineCore_DP0 pid=364570) .b8 105
(EngineCore_DP0 pid=364570) .b8 100
(EngineCore_DP0 pid=364570) .b8 101
(EngineCore_DP0 pid=364570) .b8 115
(EngineCore_DP0 pid=364570) .b8 112
(EngineCore_DP0 pid=364570) .b8 97
(EngineCore_DP0 pid=364570) .b8 114
(EngineCore_DP0 pid=364570) .b8 115
(EngineCore_DP0 pid=364570) .b8 101
(EngineCore_DP0 pid=364570) .b8 47
(EngineCore_DP0 pid=364570) .b8 99
(EngineCore_DP0 pid=364570) .b8 115
(EngineCore_DP0 pid=364570) .b8 114
(EngineCore_DP0 pid=364570) .b8 99
(EngineCore_DP0 pid=364570) .b8 47
(EngineCore_DP0 pid=364570) .b8 102
(EngineCore_DP0 pid=364570) .b8 117
(EngineCore_DP0 pid=364570) .b8 115
(EngineCore_DP0 pid=364570) .b8 101
(EngineCore_DP0 pid=364570) .b8 100
(EngineCore_DP0 pid=364570) .b8 95
(EngineCore_DP0 pid=364570) .b8 113
(EngineCore_DP0 pid=364570) .b8 117
(EngineCore_DP0 pid=364570) .b8 97
(EngineCore_DP0 pid=364570) .b8 110
(EngineCore_DP0 pid=364570) .b8 116
(EngineCore_DP0 pid=364570) .b8 95
(EngineCore_DP0 pid=364570) .b8 115
(EngineCore_DP0 pid=364570) .b8 108
(EngineCore_DP0 pid=364570) .b8 105
(EngineCore_DP0 pid=364570) .b8 100
(EngineCore_DP0 pid=364570) .b8 101
(EngineCore_DP0 pid=364570) .b8 95
(EngineCore_DP0 pid=364570) .b8 116
(EngineCore_DP0 pid=364570) .b8 114
(EngineCore_DP0 pid=364570) .b8 105
(EngineCore_DP0 pid=364570) .b8 116
(EngineCore_DP0 pid=364570) .b8 111
(EngineCore_DP0 pid=364570) .b8 110
(EngineCore_DP0 pid=364570) .b8 47
(EngineCore_DP0 pid=364570) .b8 98
(EngineCore_DP0 pid=364570) .b8 117
(EngineCore_DP0 pid=364570) .b8 105
(EngineCore_DP0 pid=364570) .b8 108
(EngineCore_DP0 pid=364570) .b8 100
(EngineCore_DP0 pid=364570) .b8 47
(EngineCore_DP0 pid=364570) .b8 71
(EngineCore_DP0 pid=364570) .b8 66
(EngineCore_DP0 pid=364570) .b8 49
(EngineCore_DP0 pid=364570) .b8 48
(EngineCore_DP0 pid=364570) .b8 95
(EngineCore_DP0 pid=364570) .b8 99
(EngineCore_DP0 pid=364570) .b8 99
(EngineCore_DP0 pid=364570) .b8 49
(EngineCore_DP0 pid=364570) .b8 50
(EngineCore_DP0 pid=364570) .b8 49
(EngineCore_DP0 pid=364570) .b8 95
(EngineCore_DP0 pid=364570) .b8 112
(EngineCore_DP0 pid=364570) .b8 121
(EngineCore_DP0 pid=364570) .b8 51
(EngineCore_DP0 pid=364570) .b8 49
(EngineCore_DP0 pid=364570) .b8 50
(EngineCore_DP0 pid=364570) .b8 95
(EngineCore_DP0 pid=364570) .b8 99
(EngineCore_DP0 pid=364570) .b8 117
(EngineCore_DP0 pid=364570) .b8 49
(EngineCore_DP0 pid=364570) .b8 50
(EngineCore_DP0 pid=364570) .b8 57
(EngineCore_DP0 pid=364570) .b8 95
(EngineCore_DP0 pid=364570) .b8 97
(EngineCore_DP0 pid=364570) .b8 97
(EngineCore_DP0 pid=364570) .b8 114
(EngineCore_DP0 pid=364570) .b8 99
(EngineCore_DP0 pid=364570) .b8 104
(EngineCore_DP0 pid=364570) .b8 54
(EngineCore_DP0 pid=364570) .b8 52
(EngineCore_DP0 pid=364570) .b8 0
(EngineCore_DP0 pid=364570) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=364570) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=364570) .b8 113
(EngineCore_DP0 pid=364570) .b8 117
(EngineCore_DP0 pid=364570) .b8 97
(EngineCore_DP0 pid=364570) .b8 110
(EngineCore_DP0 pid=364570) .b8 116
(EngineCore_DP0 pid=364570) .b8 95
(EngineCore_DP0 pid=364570) .b8 115
(EngineCore_DP0 pid=364570) .b8 108
(EngineCore_DP0 pid=364570) .b8 105
(EngineCore_DP0 pid=364570) .b8 100
(EngineCore_DP0 pid=364570) .b8 101
(EngineCore_DP0 pid=364570) .b8 95
(EngineCore_DP0 pid=364570) .b8 105
(EngineCore_DP0 pid=364570) .b8 110
(EngineCore_DP0 pid=364570) .b8 116
(EngineCore_DP0 pid=364570) .b8 56
(EngineCore_DP0 pid=364570) .b8 95
(EngineCore_DP0 pid=364570) .b8 107
(EngineCore_DP0 pid=364570) .b8 101
(EngineCore_DP0 pid=364570) .b8 114
(EngineCore_DP0 pid=364570) .b8 110
(EngineCore_DP0 pid=364570) .b8 101
(EngineCore_DP0 pid=364570) .b8 108
(EngineCore_DP0 pid=364570) .b8 0
(EngineCore_DP0 pid=364570) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=364570) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=364570) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=364570) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=364570) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=364570) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=364570) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=364570) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=364570) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=364570) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=364570) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=364570) .b8 1
(EngineCore_DP0 pid=364570) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=364570) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=364570) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=364570) 	}
(EngineCore_DP0 pid=364570) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=364570) 
(EngineCore_DP0 pid=364570) ================================================================
(EngineCore_DP0 pid=364570) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=364570) 
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp5idyhbiy.ptx', '-o', '/tmp/tmp5idyhbiy.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866] 
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866] 
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866] 
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp5idyhbiy.ptx -o /tmp/tmp5idyhbiy.ptx.o
(EngineCore_DP0 pid=364570) ERROR 01-25 19:39:52 [core.py:866] 

STDERR:
[2026-01-25 19:39:21] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:39:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:39:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:39:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:39:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:39:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:39:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:39:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:39:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:39:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:39:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:39:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:39:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:39:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:39:24] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:39:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:39:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:39:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:39:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:39:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:39:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:39:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:39:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:39:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:39:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:39:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:39:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:39:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=364570) [2026-01-25 19:39:25] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=364570) [2026-01-25 19:39:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=364570) [2026-01-25 19:39:25] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=364570) [2026-01-25 19:39:25] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=364570) [2026-01-25 19:39:25] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=364570) [2026-01-25 19:39:25] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=364570) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=364570) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.75s/it]
(EngineCore_DP0 pid=364570) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.75s/it]
(EngineCore_DP0 pid=364570) 
(EngineCore_DP0 pid=364570) [2026-01-25 19:39:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=364570) [2026-01-25 19:39:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=364570) [2026-01-25 19:39:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=364570) [2026-01-25 19:39:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9437184 bytes
(EngineCore_DP0 pid=364570) [2026-01-25 19:39:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=364570) [2026-01-25 19:39:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50331648 bytes
(EngineCore_DP0 pid=364570) [2026-01-25 19:39:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=364570) [2026-01-25 19:39:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25264128 bytes
(EngineCore_DP0 pid=364570) Process EngineCore_DP0:
(EngineCore_DP0 pid=364570) Traceback (most recent call last):
(EngineCore_DP0 pid=364570)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=364570)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=364570)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=364570)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=364570) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp5idyhbiy.ptx', '-o', '/tmp/tmp5idyhbiy.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=364570) 
(EngineCore_DP0 pid=364570) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=364570) 
(EngineCore_DP0 pid=364570) Traceback (most recent call last):
(EngineCore_DP0 pid=364570)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=364570)     self.run()
(EngineCore_DP0 pid=364570)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=364570)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=364570)     raise e
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=364570)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=364570)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=364570)     super().__init__(
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=364570)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=364570)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=364570)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=364570)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=364570)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=364570)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=364570)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=364570)     return func(*args, **kwargs)
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=364570)     return func(*args, **kwargs)
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=364570)     self.model_runner.profile_run()
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=364570)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=364570)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=364570)     return func(*args, **kwargs)
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=364570)     outputs = self.model(
(EngineCore_DP0 pid=364570)               ^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=364570)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=364570)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=364570)     model_output = self.model(
(EngineCore_DP0 pid=364570)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=364570)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=364570)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=364570)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=364570)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=364570)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=364570)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=364570)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=364570)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=364570)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=364570)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=364570)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=364570)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=364570)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=364570)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=364570)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=364570)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=364570)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=364570)     return self._linear_fn(
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=364570)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=364570)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=364570)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=364570)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=364570)     return fn(input, L)
(EngineCore_DP0 pid=364570)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=364570)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=364570)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=364570)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=364570)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=364570)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=364570)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=364570)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=364570)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=364570)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=364570)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=364570)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=364570)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=364570)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=364570)     raise PTXASError(error)
(EngineCore_DP0 pid=364570) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=364570) `ptxas` stderr:
(EngineCore_DP0 pid=364570) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=364570) 
(EngineCore_DP0 pid=364570) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp5idyhbiy.ptx -o /tmp/tmp5idyhbiy.ptx.o
(EngineCore_DP0 pid=364570) 
[rank0]:[W125 19:39:53.399461991 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 19:39:54
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:40:01 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:40:01 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=365309) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=365309) 
(EngineCore_DP0 pid=365309) 
(EngineCore_DP0 pid=365309) ================================================================
(EngineCore_DP0 pid=365309) Internal Triton PTX codegen error
(EngineCore_DP0 pid=365309) `ptxas` stderr:
(EngineCore_DP0 pid=365309) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=365309) 
(EngineCore_DP0 pid=365309) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpix5r9ndz.ptx -o /tmp/tmpix5r9ndz.ptx.o
(EngineCore_DP0 pid=365309) 
(EngineCore_DP0 pid=365309) 
(EngineCore_DP0 pid=365309) //
(EngineCore_DP0 pid=365309) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=365309) //
(EngineCore_DP0 pid=365309) 
(EngineCore_DP0 pid=365309) .version 8.7
(EngineCore_DP0 pid=365309) .target sm_121a
(EngineCore_DP0 pid=365309) .address_size 64
(EngineCore_DP0 pid=365309) 
(EngineCore_DP0 pid=365309) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=365309) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=365309)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=365309) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=365309) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=365309) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=365309) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=365309) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=365309) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=365309) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=365309) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=365309) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=365309) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=365309) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=365309) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=365309) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=365309) )
(EngineCore_DP0 pid=365309) .reqntid 512
(EngineCore_DP0 pid=365309) {
(EngineCore_DP0 pid=365309) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=365309) 	.reg .b16 	%rs<64>;
(EngineCore_DP0 pid=365309) 	.reg .b32 	%r<169>;
(EngineCore_DP0 pid=365309) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=365309) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=365309) $L__func_begin0:
(EngineCore_DP0 pid=365309) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=365309) 
(EngineCore_DP0 pid=365309) // %bb.0:
(EngineCore_DP0 pid=365309) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=365309) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=365309) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=365309) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=365309) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=365309) $L__tmp0:
(EngineCore_DP0 pid=365309) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=365309) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=365309) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=365309) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=365309) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=365309) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=365309) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=365309) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=365309) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=365309) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=365309) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=365309) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=365309) 	mov.b32 	%r167, 0f2B8CBCCC;
(EngineCore_DP0 pid=365309) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=365309) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=365309) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=365309) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=365309) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=365309) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=365309) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=365309) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=365309) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=365309) 	add.s32 	%r53, %r35, %r34;
(EngineCore_DP0 pid=365309) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=365309) 	add.s32 	%r56, %r35, %r36;
(EngineCore_DP0 pid=365309) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=365309) 	mov.b32 	%r165, 0f00000000;
(EngineCore_DP0 pid=365309) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=365309) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=365309) 	mov.b32 	%r166, %r41;
(EngineCore_DP0 pid=365309) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=365309) 	.loc	1 313 19                        // quant_slide_tuned_Llama3.2-3B.py:313:19
(EngineCore_DP0 pid=365309) 	add.s32 	%r59, %r4, %r166;
(EngineCore_DP0 pid=365309) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=365309) 	add.s32 	%r60, %r59, 4096;
(EngineCore_DP0 pid=365309) 	setp.lt.s32 	%p2, %r59, %r19;
(EngineCore_DP0 pid=365309) 	setp.lt.s32 	%p3, %r60, %r19;
(EngineCore_DP0 pid=365309) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=365309) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=365309) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=365309) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=365309) 	// begin inline asm
(EngineCore_DP0 pid=365309) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=365309) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=365309) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=365309) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=365309) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=365309) 	// end inline asm
(EngineCore_DP0 pid=365309) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=365309) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=365309) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=365309) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=365309) 	// begin inline asm
(EngineCore_DP0 pid=365309) 	mov.u32 %r45, %r41;
(EngineCore_DP0 pid=365309) 	mov.u32 %r46, %r41;
(EngineCore_DP0 pid=365309) 	mov.u32 %r47, %r41;
(EngineCore_DP0 pid=365309) 	mov.u32 %r48, %r41;
(EngineCore_DP0 pid=365309) 	@%p3 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=365309) 	// end inline asm
(EngineCore_DP0 pid=365309) 	mov.b32 	{%rs9, %rs10}, %r45;
(EngineCore_DP0 pid=365309) 	mov.b32 	{%rs11, %rs12}, %r46;
(EngineCore_DP0 pid=365309) 	mov.b32 	{%rs13, %rs14}, %r47;
(EngineCore_DP0 pid=365309) 	mov.b32 	{%rs15, %rs16}, %r48;
(EngineCore_DP0 pid=365309) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=365309) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=365309) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=365309) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=365309) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=365309) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=365309) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=365309) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=365309) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=365309) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=365309) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=365309) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=365309) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=365309) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=365309) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=365309) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=365309) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=365309) $L__tmp1:
(EngineCore_DP0 pid=365309) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	bar.sync 	0;
(EngineCore_DP0 pid=365309) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=365309) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=365309) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=365309) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=365309) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=365309) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=365309) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=365309) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=365309) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=365309) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=365309) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=365309) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=365309) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=365309) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=365309) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=365309) 	cvt.f32.bf16 	%r61, %rs47;
(EngineCore_DP0 pid=365309) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	shfl.sync.bfly.b32 	%r62, %r61, 16, 31, -1;
(EngineCore_DP0 pid=365309) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=365309) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	shfl.sync.bfly.b32 	%r64, %r63, 8, 31, -1;
(EngineCore_DP0 pid=365309) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=365309) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=365309) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=365309) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=365309) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=365309) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=365309) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	max.f32 	%r54, %r69, %r70;
(EngineCore_DP0 pid=365309) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	// begin inline asm
(EngineCore_DP0 pid=365309) 	@%p4 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=365309) 	// end inline asm
(EngineCore_DP0 pid=365309) 	bar.sync 	0;
(EngineCore_DP0 pid=365309) 	// begin inline asm
(EngineCore_DP0 pid=365309) 	@%p5 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=365309) 	// end inline asm
(EngineCore_DP0 pid=365309) 	shfl.sync.bfly.b32 	%r71, %r55, 8, 31, -1;
(EngineCore_DP0 pid=365309) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	max.f32 	%r72, %r55, %r71;
(EngineCore_DP0 pid=365309) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	shfl.sync.bfly.b32 	%r73, %r72, 4, 31, -1;
(EngineCore_DP0 pid=365309) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	max.f32 	%r74, %r72, %r73;
(EngineCore_DP0 pid=365309) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	shfl.sync.bfly.b32 	%r75, %r74, 2, 31, -1;
(EngineCore_DP0 pid=365309) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	max.f32 	%r76, %r74, %r75;
(EngineCore_DP0 pid=365309) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	shfl.sync.bfly.b32 	%r77, %r76, 1, 31, -1;
(EngineCore_DP0 pid=365309) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	max.f32 	%r58, %r76, %r77;
(EngineCore_DP0 pid=365309) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=365309) 	// begin inline asm
(EngineCore_DP0 pid=365309) 	@%p28 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=365309) 	// end inline asm
(EngineCore_DP0 pid=365309) 	bar.sync 	0;
(EngineCore_DP0 pid=365309) 	ld.shared.b32 	%r78, [global_smem];
(EngineCore_DP0 pid=365309) $L__tmp2:
(EngineCore_DP0 pid=365309) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=365309) 	max.f32 	%r165, %r165, %r78;
(EngineCore_DP0 pid=365309) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=365309) 	add.s32 	%r166, %r166, 8192;
(EngineCore_DP0 pid=365309) 	setp.lt.s32 	%p7, %r166, %r20;
(EngineCore_DP0 pid=365309) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=365309) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=365309) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=365309) 	max.f32 	%r167, %r165, 0f2B8CBCCC;
(EngineCore_DP0 pid=365309) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=365309) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=365309) 	mov.b32 	%r80, 0f42FE0000;
(EngineCore_DP0 pid=365309) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=365309) 	div.full.f32 	%r81, %r167, %r80;
(EngineCore_DP0 pid=365309) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=365309) 	max.f32 	%r79, %r81, 0f37810204;
(EngineCore_DP0 pid=365309) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=365309) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=365309) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=365309) 	// begin inline asm
(EngineCore_DP0 pid=365309) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r79 };
(EngineCore_DP0 pid=365309) 	// end inline asm
(EngineCore_DP0 pid=365309) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=365309) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=365309) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=365309) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=365309) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=365309) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=365309) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=365309) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=365309) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=365309) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=365309) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=365309) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=365309) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=365309) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=365309) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=365309) 	div.full.f32 	%r14, %r80, %r167;
(EngineCore_DP0 pid=365309) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=365309) 	mov.b32 	%r168, 0;
(EngineCore_DP0 pid=365309) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=365309)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=365309) 	.loc	1 327 31                        // quant_slide_tuned_Llama3.2-3B.py:327:31
(EngineCore_DP0 pid=365309) 	add.s32 	%r85, %r16, %r168;
(EngineCore_DP0 pid=365309) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=365309) 	add.s32 	%r86, %r168, 1;
(EngineCore_DP0 pid=365309) 	setp.lt.s32 	%p18, %r85, %r15;
(EngineCore_DP0 pid=365309) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=365309) 	shr.u32 	%r87, %r85, 1;
(EngineCore_DP0 pid=365309) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=365309) 	shr.u32 	%r88, %r86, 31;
(EngineCore_DP0 pid=365309) 	add.s32 	%r89, %r86, %r88;
(EngineCore_DP0 pid=365309) 	and.b32 	%r90, %r89, 2147483646;
(EngineCore_DP0 pid=365309) 	sub.s32 	%r91, %r86, %r90;
(EngineCore_DP0 pid=365309) 	.loc	1 333 22                        // quant_slide_tuned_Llama3.2-3B.py:333:22
(EngineCore_DP0 pid=365309) 	mul.lo.s32 	%r92, %r87, 6;
(EngineCore_DP0 pid=365309) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=365309) 	shl.b32 	%r93, %r91, 1;
(EngineCore_DP0 pid=365309) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=365309) 	add.s32 	%r94, %r92, %r93;
(EngineCore_DP0 pid=365309) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=365309) 	setp.lt.s32 	%p19, %r92, %r19;
(EngineCore_DP0 pid=365309) 	setp.lt.s32 	%p20, %r94, %r19;
(EngineCore_DP0 pid=365309) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=365309) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=365309) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=365309) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=365309) 	mad.wide.s32 	%rd9, %r92, 2, %rd1;
(EngineCore_DP0 pid=365309) 	mad.wide.s32 	%rd10, %r94, 2, %rd1;
(EngineCore_DP0 pid=365309) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=365309) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=365309) 	// begin inline asm
(EngineCore_DP0 pid=365309) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=365309) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=365309) 	// end inline asm
(EngineCore_DP0 pid=365309) 	// begin inline asm
(EngineCore_DP0 pid=365309) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=365309) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=365309) 	// end inline asm
(EngineCore_DP0 pid=365309) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=365309) 	cvt.f32.bf16 	%r95, %rs48;
(EngineCore_DP0 pid=365309) 	cvt.f32.bf16 	%r96, %rs50;
(EngineCore_DP0 pid=365309) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=365309) 	or.b32 	%r97, %r92, 1;
(EngineCore_DP0 pid=365309) 	or.b32 	%r98, %r94, 1;
(EngineCore_DP0 pid=365309) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=365309) 	setp.lt.s32 	%p21, %r97, %r19;
(EngineCore_DP0 pid=365309) 	setp.lt.s32 	%p22, %r98, %r19;
(EngineCore_DP0 pid=365309) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=365309) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=365309) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=365309) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=365309) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=365309) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=365309) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=365309) 	// begin inline asm
(EngineCore_DP0 pid=365309) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=365309) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=365309) 	// end inline asm
(EngineCore_DP0 pid=365309) 	// begin inline asm
(EngineCore_DP0 pid=365309) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=365309) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=365309) 	// end inline asm
(EngineCore_DP0 pid=365309) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=365309) 	cvt.f32.bf16 	%r99, %rs52;
(EngineCore_DP0 pid=365309) 	cvt.f32.bf16 	%r100, %rs54;
(EngineCore_DP0 pid=365309) 	.loc	1 340 48                        // quant_slide_tuned_Llama3.2-3B.py:340:48
(EngineCore_DP0 pid=365309) 	add.s32 	%r101, %r92, 2;
(EngineCore_DP0 pid=365309) 	add.s32 	%r102, %r94, 2;
(EngineCore_DP0 pid=365309) 	.loc	1 340 53                        // quant_slide_tuned_Llama3.2-3B.py:340:53
(EngineCore_DP0 pid=365309) 	setp.lt.s32 	%p23, %r101, %r19;
(EngineCore_DP0 pid=365309) 	setp.lt.s32 	%p24, %r102, %r19;
(EngineCore_DP0 pid=365309) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=365309) 	and.pred 	%p14, %p18, %p23;
(EngineCore_DP0 pid=365309) 	and.pred 	%p15, %p18, %p24;
(EngineCore_DP0 pid=365309) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=365309) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=365309) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=365309) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=365309) 	// begin inline asm
(EngineCore_DP0 pid=365309) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=365309) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=365309) 	// end inline asm
(EngineCore_DP0 pid=365309) 	// begin inline asm
(EngineCore_DP0 pid=365309) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=365309) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=365309) 	// end inline asm
(EngineCore_DP0 pid=365309) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=365309) 	cvt.f32.bf16 	%r103, %rs56;
(EngineCore_DP0 pid=365309) 	cvt.f32.bf16 	%r104, %rs58;
(EngineCore_DP0 pid=365309) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=365309) 	add.s32 	%r105, %r92, 3;
(EngineCore_DP0 pid=365309) 	add.s32 	%r106, %r94, 3;
(EngineCore_DP0 pid=365309) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=365309) 	setp.lt.s32 	%p25, %r105, %r19;
(EngineCore_DP0 pid=365309) 	setp.lt.s32 	%p26, %r106, %r19;
(EngineCore_DP0 pid=365309) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=365309) 	and.pred 	%p16, %p18, %p25;
(EngineCore_DP0 pid=365309) 	and.pred 	%p17, %p18, %p26;
(EngineCore_DP0 pid=365309) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=365309) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=365309) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=365309) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=365309) 	// begin inline asm
(EngineCore_DP0 pid=365309) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=365309) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=365309) 	// end inline asm
(EngineCore_DP0 pid=365309) 	// begin inline asm
(EngineCore_DP0 pid=365309) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=365309) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=365309) 	// end inline asm
(EngineCore_DP0 pid=365309) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=365309) 	cvt.f32.bf16 	%r107, %rs60;
(EngineCore_DP0 pid=365309) 	cvt.f32.bf16 	%r108, %rs62;
(EngineCore_DP0 pid=365309) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=365309) 	mul.f32 	%r109, %r14, %r95;
(EngineCore_DP0 pid=365309) 	mul.f32 	%r110, %r14, %r96;
(EngineCore_DP0 pid=365309) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=365309) 	cvt.rni.f32.f32 	%r111, %r109;
(EngineCore_DP0 pid=365309) 	cvt.rni.f32.f32 	%r112, %r110;
(EngineCore_DP0 pid=365309) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=365309) 	max.f32 	%r113, %r111, 0fC3000000;
(EngineCore_DP0 pid=365309) 	min.f32 	%r114, %r113, 0f42FE0000;
(EngineCore_DP0 pid=365309) 	max.f32 	%r115, %r112, 0fC3000000;
(EngineCore_DP0 pid=365309) 	min.f32 	%r116, %r115, 0f42FE0000;
(EngineCore_DP0 pid=365309) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=365309) 	cvt.rzi.s32.f32 	%r117, %r114;
(EngineCore_DP0 pid=365309) 	cvt.rzi.s32.f32 	%r118, %r116;
(EngineCore_DP0 pid=365309) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=365309) 	and.b32 	%r119, %r117, 255;
(EngineCore_DP0 pid=365309) 	and.b32 	%r120, %r118, 255;
(EngineCore_DP0 pid=365309) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=365309) 	mul.f32 	%r121, %r14, %r99;
(EngineCore_DP0 pid=365309) 	mul.f32 	%r122, %r14, %r100;
(EngineCore_DP0 pid=365309) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=365309) 	cvt.rni.f32.f32 	%r123, %r121;
(EngineCore_DP0 pid=365309) 	cvt.rni.f32.f32 	%r124, %r122;
(EngineCore_DP0 pid=365309) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=365309) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=365309) 	mul.f32 	%r126, %r14, %r104;
(EngineCore_DP0 pid=365309) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=365309) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=365309) 	cvt.rni.f32.f32 	%r128, %r126;
(EngineCore_DP0 pid=365309) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=365309) 	mul.f32 	%r129, %r14, %r107;
(EngineCore_DP0 pid=365309) 	mul.f32 	%r130, %r14, %r108;
(EngineCore_DP0 pid=365309) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=365309) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=365309) 	cvt.rni.f32.f32 	%r132, %r130;
(EngineCore_DP0 pid=365309) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=365309) 	max.f32 	%r133, %r131, 0fC3000000;
(EngineCore_DP0 pid=365309) 	min.f32 	%r134, %r133, 0f42FE0000;
(EngineCore_DP0 pid=365309) 	max.f32 	%r135, %r132, 0fC3000000;
(EngineCore_DP0 pid=365309) 	min.f32 	%r136, %r135, 0f42FE0000;
(EngineCore_DP0 pid=365309) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=365309) 	cvt.rzi.s32.f32 	%r137, %r134;
(EngineCore_DP0 pid=365309) 	cvt.rzi.s32.f32 	%r138, %r136;
(EngineCore_DP0 pid=365309) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=365309) 	max.f32 	%r139, %r127, 0fC3000000;
(EngineCore_DP0 pid=365309) 	max.f32 	%r140, %r123, 0fC3000000;
(EngineCore_DP0 pid=365309) 	min.f32 	%r141, %r140, 0f42FE0000;
(EngineCore_DP0 pid=365309) 	min.f32 	%r142, %r139, 0f42FE0000;
(EngineCore_DP0 pid=365309) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=365309) 	cvt.rzi.s32.f32 	%r143, %r142;
(EngineCore_DP0 pid=365309) 	cvt.rzi.s32.f32 	%r144, %r141;
(EngineCore_DP0 pid=365309) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=365309) 	shl.b32 	%r145, %r144, 8;
(EngineCore_DP0 pid=365309) 	shl.b32 	%r146, %r143, 16;
(EngineCore_DP0 pid=365309) 	and.b32 	%r147, %r146, 16711680;
(EngineCore_DP0 pid=365309) 	and.b32 	%r148, %r145, 65280;
(EngineCore_DP0 pid=365309) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=365309) 	or.b32 	%r149, %r148, %r119;
(EngineCore_DP0 pid=365309) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=365309) 	max.f32 	%r150, %r128, 0fC3000000;
(EngineCore_DP0 pid=365309) 	max.f32 	%r151, %r124, 0fC3000000;
(EngineCore_DP0 pid=365309) 	min.f32 	%r152, %r151, 0f42FE0000;
(EngineCore_DP0 pid=365309) 	min.f32 	%r153, %r150, 0f42FE0000;
(EngineCore_DP0 pid=365309) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=365309) 	cvt.rzi.s32.f32 	%r154, %r153;
(EngineCore_DP0 pid=365309) 	cvt.rzi.s32.f32 	%r155, %r152;
(EngineCore_DP0 pid=365309) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=365309) 	shl.b32 	%r156, %r155, 8;
(EngineCore_DP0 pid=365309) 	shl.b32 	%r157, %r154, 16;
(EngineCore_DP0 pid=365309) 	and.b32 	%r158, %r157, 16711680;
(EngineCore_DP0 pid=365309) 	and.b32 	%r159, %r156, 65280;
(EngineCore_DP0 pid=365309) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=365309) 	or.b32 	%r160, %r159, %r120;
(EngineCore_DP0 pid=365309) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=365309) 	or.b32 	%r161, %r149, %r147;
(EngineCore_DP0 pid=365309) 	or.b32 	%r162, %r160, %r158;
(EngineCore_DP0 pid=365309) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=365309) 	shl.b32 	%r163, %r137, 24;
(EngineCore_DP0 pid=365309) 	shl.b32 	%r164, %r138, 24;
(EngineCore_DP0 pid=365309) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=365309) 	or.b32 	%r83, %r161, %r163;
(EngineCore_DP0 pid=365309) 	or.b32 	%r84, %r162, %r164;
(EngineCore_DP0 pid=365309) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=365309) 	mad.wide.s32 	%rd17, %r85, 4, %rd2;
(EngineCore_DP0 pid=365309) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=365309) 	// begin inline asm
(EngineCore_DP0 pid=365309) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r83, %r84 };
(EngineCore_DP0 pid=365309) 	// end inline asm
(EngineCore_DP0 pid=365309) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=365309) 	add.s32 	%r168, %r168, 1024;
(EngineCore_DP0 pid=365309) 	setp.lt.s32 	%p27, %r168, %r15;
(EngineCore_DP0 pid=365309) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=365309) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=365309) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=365309) 	ret;
(EngineCore_DP0 pid=365309) $L__tmp3:
(EngineCore_DP0 pid=365309) $L__func_end0:
(EngineCore_DP0 pid=365309)                                         // -- End function
(EngineCore_DP0 pid=365309) }
(EngineCore_DP0 pid=365309) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=365309) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=365309) 	.section	.debug_abbrev
(EngineCore_DP0 pid=365309) 	{
(EngineCore_DP0 pid=365309) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=365309) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=365309) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=365309) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=365309) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=365309) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=365309) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=365309) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=365309) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=365309) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=365309) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=365309) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=365309) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=365309) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=365309) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=365309) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=365309) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=365309) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=365309) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=365309) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=365309) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=365309) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=365309) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=365309) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=365309) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=365309) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=365309) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=365309) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=365309) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=365309) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=365309) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=365309) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=365309) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=365309) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=365309) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=365309) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=365309) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=365309) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=365309) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=365309) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=365309) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=365309) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=365309) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=365309) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=365309) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=365309) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=365309) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=365309) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=365309) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=365309) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=365309) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=365309) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=365309) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=365309) 	}
(EngineCore_DP0 pid=365309) 	.section	.debug_info
(EngineCore_DP0 pid=365309) 	{
(EngineCore_DP0 pid=365309) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=365309) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=365309) .b8 0
(EngineCore_DP0 pid=365309) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=365309) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=365309) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=365309) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=365309) .b8 114
(EngineCore_DP0 pid=365309) .b8 105
(EngineCore_DP0 pid=365309) .b8 116
(EngineCore_DP0 pid=365309) .b8 111
(EngineCore_DP0 pid=365309) .b8 110
(EngineCore_DP0 pid=365309) .b8 0
(EngineCore_DP0 pid=365309) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=365309) .b8 0
(EngineCore_DP0 pid=365309) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=365309) .b8 117
(EngineCore_DP0 pid=365309) .b8 97
(EngineCore_DP0 pid=365309) .b8 110
(EngineCore_DP0 pid=365309) .b8 116
(EngineCore_DP0 pid=365309) .b8 95
(EngineCore_DP0 pid=365309) .b8 115
(EngineCore_DP0 pid=365309) .b8 108
(EngineCore_DP0 pid=365309) .b8 105
(EngineCore_DP0 pid=365309) .b8 100
(EngineCore_DP0 pid=365309) .b8 101
(EngineCore_DP0 pid=365309) .b8 95
(EngineCore_DP0 pid=365309) .b8 116
(EngineCore_DP0 pid=365309) .b8 117
(EngineCore_DP0 pid=365309) .b8 110
(EngineCore_DP0 pid=365309) .b8 101
(EngineCore_DP0 pid=365309) .b8 100
(EngineCore_DP0 pid=365309) .b8 95
(EngineCore_DP0 pid=365309) .b8 76
(EngineCore_DP0 pid=365309) .b8 108
(EngineCore_DP0 pid=365309) .b8 97
(EngineCore_DP0 pid=365309) .b8 109
(EngineCore_DP0 pid=365309) .b8 97
(EngineCore_DP0 pid=365309) .b8 51
(EngineCore_DP0 pid=365309) .b8 46
(EngineCore_DP0 pid=365309) .b8 50
(EngineCore_DP0 pid=365309) .b8 45
(EngineCore_DP0 pid=365309) .b8 51
(EngineCore_DP0 pid=365309) .b8 66
(EngineCore_DP0 pid=365309) .b8 46
(EngineCore_DP0 pid=365309) .b8 112
(EngineCore_DP0 pid=365309) .b8 121
(EngineCore_DP0 pid=365309) .b8 0
(EngineCore_DP0 pid=365309) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=365309) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=365309) .b8 114
(EngineCore_DP0 pid=365309) .b8 111
(EngineCore_DP0 pid=365309) .b8 111
(EngineCore_DP0 pid=365309) .b8 116
(EngineCore_DP0 pid=365309) .b8 47
(EngineCore_DP0 pid=365309) .b8 118
(EngineCore_DP0 pid=365309) .b8 108
(EngineCore_DP0 pid=365309) .b8 108
(EngineCore_DP0 pid=365309) .b8 109
(EngineCore_DP0 pid=365309) .b8 98
(EngineCore_DP0 pid=365309) .b8 101
(EngineCore_DP0 pid=365309) .b8 110
(EngineCore_DP0 pid=365309) .b8 99
(EngineCore_DP0 pid=365309) .b8 104
(EngineCore_DP0 pid=365309) .b8 47
(EngineCore_DP0 pid=365309) .b8 115
(EngineCore_DP0 pid=365309) .b8 108
(EngineCore_DP0 pid=365309) .b8 105
(EngineCore_DP0 pid=365309) .b8 100
(EngineCore_DP0 pid=365309) .b8 101
(EngineCore_DP0 pid=365309) .b8 115
(EngineCore_DP0 pid=365309) .b8 112
(EngineCore_DP0 pid=365309) .b8 97
(EngineCore_DP0 pid=365309) .b8 114
(EngineCore_DP0 pid=365309) .b8 115
(EngineCore_DP0 pid=365309) .b8 101
(EngineCore_DP0 pid=365309) .b8 47
(EngineCore_DP0 pid=365309) .b8 99
(EngineCore_DP0 pid=365309) .b8 115
(EngineCore_DP0 pid=365309) .b8 114
(EngineCore_DP0 pid=365309) .b8 99
(EngineCore_DP0 pid=365309) .b8 47
(EngineCore_DP0 pid=365309) .b8 102
(EngineCore_DP0 pid=365309) .b8 117
(EngineCore_DP0 pid=365309) .b8 115
(EngineCore_DP0 pid=365309) .b8 101
(EngineCore_DP0 pid=365309) .b8 100
(EngineCore_DP0 pid=365309) .b8 95
(EngineCore_DP0 pid=365309) .b8 113
(EngineCore_DP0 pid=365309) .b8 117
(EngineCore_DP0 pid=365309) .b8 97
(EngineCore_DP0 pid=365309) .b8 110
(EngineCore_DP0 pid=365309) .b8 116
(EngineCore_DP0 pid=365309) .b8 95
(EngineCore_DP0 pid=365309) .b8 115
(EngineCore_DP0 pid=365309) .b8 108
(EngineCore_DP0 pid=365309) .b8 105
(EngineCore_DP0 pid=365309) .b8 100
(EngineCore_DP0 pid=365309) .b8 101
(EngineCore_DP0 pid=365309) .b8 95
(EngineCore_DP0 pid=365309) .b8 116
(EngineCore_DP0 pid=365309) .b8 114
(EngineCore_DP0 pid=365309) .b8 105
(EngineCore_DP0 pid=365309) .b8 116
(EngineCore_DP0 pid=365309) .b8 111
(EngineCore_DP0 pid=365309) .b8 110
(EngineCore_DP0 pid=365309) .b8 47
(EngineCore_DP0 pid=365309) .b8 98
(EngineCore_DP0 pid=365309) .b8 117
(EngineCore_DP0 pid=365309) .b8 105
(EngineCore_DP0 pid=365309) .b8 108
(EngineCore_DP0 pid=365309) .b8 100
(EngineCore_DP0 pid=365309) .b8 47
(EngineCore_DP0 pid=365309) .b8 71
(EngineCore_DP0 pid=365309) .b8 66
(EngineCore_DP0 pid=365309) .b8 49
(EngineCore_DP0 pid=365309) .b8 48
(EngineCore_DP0 pid=365309) .b8 95
(EngineCore_DP0 pid=365309) .b8 99
(EngineCore_DP0 pid=365309) .b8 99
(EngineCore_DP0 pid=365309) .b8 49
(EngineCore_DP0 pid=365309) .b8 50
(EngineCore_DP0 pid=365309) .b8 49
(EngineCore_DP0 pid=365309) .b8 95
(EngineCore_DP0 pid=365309) .b8 112
(EngineCore_DP0 pid=365309) .b8 121
(EngineCore_DP0 pid=365309) .b8 51
(EngineCore_DP0 pid=365309) .b8 49
(EngineCore_DP0 pid=365309) .b8 50
(EngineCore_DP0 pid=365309) .b8 95
(EngineCore_DP0 pid=365309) .b8 99
(EngineCore_DP0 pid=365309) .b8 117
(EngineCore_DP0 pid=365309) .b8 49
(EngineCore_DP0 pid=365309) .b8 50
(EngineCore_DP0 pid=365309) .b8 57
(EngineCore_DP0 pid=365309) .b8 95
(EngineCore_DP0 pid=365309) .b8 97
(EngineCore_DP0 pid=365309) .b8 97
(EngineCore_DP0 pid=365309) .b8 114
(EngineCore_DP0 pid=365309) .b8 99
(EngineCore_DP0 pid=365309) .b8 104
(EngineCore_DP0 pid=365309) .b8 54
(EngineCore_DP0 pid=365309) .b8 52
(EngineCore_DP0 pid=365309) .b8 0
(EngineCore_DP0 pid=365309) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=365309) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=365309) .b8 113
(EngineCore_DP0 pid=365309) .b8 117
(EngineCore_DP0 pid=365309) .b8 97
(EngineCore_DP0 pid=365309) .b8 110
(EngineCore_DP0 pid=365309) .b8 116
(EngineCore_DP0 pid=365309) .b8 95
(EngineCore_DP0 pid=365309) .b8 115
(EngineCore_DP0 pid=365309) .b8 108
(EngineCore_DP0 pid=365309) .b8 105
(EngineCore_DP0 pid=365309) .b8 100
(EngineCore_DP0 pid=365309) .b8 101
(EngineCore_DP0 pid=365309) .b8 95
(EngineCore_DP0 pid=365309) .b8 105
(EngineCore_DP0 pid=365309) .b8 110
(EngineCore_DP0 pid=365309) .b8 116
(EngineCore_DP0 pid=365309) .b8 56
(EngineCore_DP0 pid=365309) .b8 95
(EngineCore_DP0 pid=365309) .b8 107
(EngineCore_DP0 pid=365309) .b8 101
(EngineCore_DP0 pid=365309) .b8 114
(EngineCore_DP0 pid=365309) .b8 110
(EngineCore_DP0 pid=365309) .b8 101
(EngineCore_DP0 pid=365309) .b8 108
(EngineCore_DP0 pid=365309) .b8 0
(EngineCore_DP0 pid=365309) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=365309) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=365309) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=365309) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=365309) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=365309) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=365309) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=365309) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=365309) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=365309) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=365309) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=365309) .b8 1
(EngineCore_DP0 pid=365309) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=365309) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=365309) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=365309) 	}
(EngineCore_DP0 pid=365309) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=365309) 
(EngineCore_DP0 pid=365309) ================================================================
(EngineCore_DP0 pid=365309) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=365309) 
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpix5r9ndz.ptx', '-o', '/tmp/tmpix5r9ndz.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866] 
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866] 
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866] 
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpix5r9ndz.ptx -o /tmp/tmpix5r9ndz.ptx.o
(EngineCore_DP0 pid=365309) ERROR 01-25 19:40:32 [core.py:866] 

STDERR:
[2026-01-25 19:40:01] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:40:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:40:01] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:40:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:40:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:40:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:40:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:40:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:40:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:40:04] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:40:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:40:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:40:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:40:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:40:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:40:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:40:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:40:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=365309) [2026-01-25 19:40:05] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=365309) [2026-01-25 19:40:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=365309) [2026-01-25 19:40:05] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=365309) [2026-01-25 19:40:05] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=365309) [2026-01-25 19:40:05] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=365309) [2026-01-25 19:40:05] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=365309) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=365309) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.59s/it]
(EngineCore_DP0 pid=365309) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.59s/it]
(EngineCore_DP0 pid=365309) 
(EngineCore_DP0 pid=365309) [2026-01-25 19:40:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=365309) [2026-01-25 19:40:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=365309) [2026-01-25 19:40:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=365309) [2026-01-25 19:40:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9437184 bytes
(EngineCore_DP0 pid=365309) [2026-01-25 19:40:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=365309) [2026-01-25 19:40:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50331648 bytes
(EngineCore_DP0 pid=365309) [2026-01-25 19:40:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=365309) [2026-01-25 19:40:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25264128 bytes
(EngineCore_DP0 pid=365309) Process EngineCore_DP0:
(EngineCore_DP0 pid=365309) Traceback (most recent call last):
(EngineCore_DP0 pid=365309)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=365309)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=365309)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=365309)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=365309) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpix5r9ndz.ptx', '-o', '/tmp/tmpix5r9ndz.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=365309) 
(EngineCore_DP0 pid=365309) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=365309) 
(EngineCore_DP0 pid=365309) Traceback (most recent call last):
(EngineCore_DP0 pid=365309)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=365309)     self.run()
(EngineCore_DP0 pid=365309)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=365309)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=365309)     raise e
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=365309)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=365309)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=365309)     super().__init__(
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=365309)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=365309)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=365309)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=365309)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=365309)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=365309)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=365309)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=365309)     return func(*args, **kwargs)
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=365309)     return func(*args, **kwargs)
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=365309)     self.model_runner.profile_run()
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=365309)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=365309)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=365309)     return func(*args, **kwargs)
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=365309)     outputs = self.model(
(EngineCore_DP0 pid=365309)               ^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=365309)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=365309)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=365309)     model_output = self.model(
(EngineCore_DP0 pid=365309)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=365309)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=365309)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=365309)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=365309)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=365309)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=365309)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=365309)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=365309)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=365309)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=365309)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=365309)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=365309)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=365309)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=365309)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=365309)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=365309)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=365309)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=365309)     return self._linear_fn(
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=365309)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=365309)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=365309)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=365309)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=365309)     return fn(input, L)
(EngineCore_DP0 pid=365309)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=365309)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=365309)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=365309)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=365309)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=365309)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=365309)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=365309)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=365309)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=365309)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=365309)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=365309)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=365309)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=365309)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=365309)     raise PTXASError(error)
(EngineCore_DP0 pid=365309) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=365309) `ptxas` stderr:
(EngineCore_DP0 pid=365309) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=365309) 
(EngineCore_DP0 pid=365309) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpix5r9ndz.ptx -o /tmp/tmpix5r9ndz.ptx.o
(EngineCore_DP0 pid=365309) 
[rank0]:[W125 19:40:32.919454260 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 19:40:34
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:40:43 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:40:43 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=366078) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=366078) 
(EngineCore_DP0 pid=366078) 
(EngineCore_DP0 pid=366078) ================================================================
(EngineCore_DP0 pid=366078) Internal Triton PTX codegen error
(EngineCore_DP0 pid=366078) `ptxas` stderr:
(EngineCore_DP0 pid=366078) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=366078) 
(EngineCore_DP0 pid=366078) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpjm6jf_fl.ptx -o /tmp/tmpjm6jf_fl.ptx.o
(EngineCore_DP0 pid=366078) 
(EngineCore_DP0 pid=366078) 
(EngineCore_DP0 pid=366078) //
(EngineCore_DP0 pid=366078) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=366078) //
(EngineCore_DP0 pid=366078) 
(EngineCore_DP0 pid=366078) .version 8.7
(EngineCore_DP0 pid=366078) .target sm_121a
(EngineCore_DP0 pid=366078) .address_size 64
(EngineCore_DP0 pid=366078) 
(EngineCore_DP0 pid=366078) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=366078) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=366078)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=366078) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=366078) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=366078) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=366078) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=366078) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=366078) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=366078) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=366078) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=366078) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=366078) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=366078) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=366078) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=366078) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=366078) )
(EngineCore_DP0 pid=366078) .reqntid 512
(EngineCore_DP0 pid=366078) {
(EngineCore_DP0 pid=366078) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=366078) 	.reg .b16 	%rs<64>;
(EngineCore_DP0 pid=366078) 	.reg .b32 	%r<169>;
(EngineCore_DP0 pid=366078) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=366078) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=366078) $L__func_begin0:
(EngineCore_DP0 pid=366078) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=366078) 
(EngineCore_DP0 pid=366078) // %bb.0:
(EngineCore_DP0 pid=366078) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=366078) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=366078) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=366078) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=366078) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=366078) $L__tmp0:
(EngineCore_DP0 pid=366078) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=366078) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=366078) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=366078) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=366078) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=366078) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=366078) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=366078) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=366078) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=366078) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=366078) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=366078) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=366078) 	mov.b32 	%r167, 0f2B8CBCCC;
(EngineCore_DP0 pid=366078) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=366078) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=366078) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=366078) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=366078) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=366078) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=366078) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=366078) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=366078) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=366078) 	add.s32 	%r53, %r35, %r34;
(EngineCore_DP0 pid=366078) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=366078) 	add.s32 	%r56, %r35, %r36;
(EngineCore_DP0 pid=366078) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=366078) 	mov.b32 	%r165, 0f00000000;
(EngineCore_DP0 pid=366078) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=366078) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=366078) 	mov.b32 	%r166, %r41;
(EngineCore_DP0 pid=366078) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=366078) 	.loc	1 313 19                        // quant_slide_tuned_Llama3.2-3B.py:313:19
(EngineCore_DP0 pid=366078) 	add.s32 	%r59, %r4, %r166;
(EngineCore_DP0 pid=366078) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=366078) 	add.s32 	%r60, %r59, 4096;
(EngineCore_DP0 pid=366078) 	setp.lt.s32 	%p2, %r59, %r19;
(EngineCore_DP0 pid=366078) 	setp.lt.s32 	%p3, %r60, %r19;
(EngineCore_DP0 pid=366078) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=366078) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=366078) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=366078) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=366078) 	// begin inline asm
(EngineCore_DP0 pid=366078) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=366078) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=366078) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=366078) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=366078) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=366078) 	// end inline asm
(EngineCore_DP0 pid=366078) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=366078) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=366078) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=366078) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=366078) 	// begin inline asm
(EngineCore_DP0 pid=366078) 	mov.u32 %r45, %r41;
(EngineCore_DP0 pid=366078) 	mov.u32 %r46, %r41;
(EngineCore_DP0 pid=366078) 	mov.u32 %r47, %r41;
(EngineCore_DP0 pid=366078) 	mov.u32 %r48, %r41;
(EngineCore_DP0 pid=366078) 	@%p3 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=366078) 	// end inline asm
(EngineCore_DP0 pid=366078) 	mov.b32 	{%rs9, %rs10}, %r45;
(EngineCore_DP0 pid=366078) 	mov.b32 	{%rs11, %rs12}, %r46;
(EngineCore_DP0 pid=366078) 	mov.b32 	{%rs13, %rs14}, %r47;
(EngineCore_DP0 pid=366078) 	mov.b32 	{%rs15, %rs16}, %r48;
(EngineCore_DP0 pid=366078) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=366078) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=366078) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=366078) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=366078) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=366078) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=366078) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=366078) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=366078) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=366078) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=366078) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=366078) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=366078) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=366078) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=366078) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=366078) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=366078) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=366078) $L__tmp1:
(EngineCore_DP0 pid=366078) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	bar.sync 	0;
(EngineCore_DP0 pid=366078) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=366078) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=366078) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=366078) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=366078) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=366078) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=366078) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=366078) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=366078) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=366078) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=366078) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=366078) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=366078) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=366078) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=366078) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=366078) 	cvt.f32.bf16 	%r61, %rs47;
(EngineCore_DP0 pid=366078) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	shfl.sync.bfly.b32 	%r62, %r61, 16, 31, -1;
(EngineCore_DP0 pid=366078) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=366078) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	shfl.sync.bfly.b32 	%r64, %r63, 8, 31, -1;
(EngineCore_DP0 pid=366078) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=366078) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=366078) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=366078) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=366078) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=366078) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=366078) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	max.f32 	%r54, %r69, %r70;
(EngineCore_DP0 pid=366078) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	// begin inline asm
(EngineCore_DP0 pid=366078) 	@%p4 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=366078) 	// end inline asm
(EngineCore_DP0 pid=366078) 	bar.sync 	0;
(EngineCore_DP0 pid=366078) 	// begin inline asm
(EngineCore_DP0 pid=366078) 	@%p5 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=366078) 	// end inline asm
(EngineCore_DP0 pid=366078) 	shfl.sync.bfly.b32 	%r71, %r55, 8, 31, -1;
(EngineCore_DP0 pid=366078) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	max.f32 	%r72, %r55, %r71;
(EngineCore_DP0 pid=366078) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	shfl.sync.bfly.b32 	%r73, %r72, 4, 31, -1;
(EngineCore_DP0 pid=366078) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	max.f32 	%r74, %r72, %r73;
(EngineCore_DP0 pid=366078) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	shfl.sync.bfly.b32 	%r75, %r74, 2, 31, -1;
(EngineCore_DP0 pid=366078) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	max.f32 	%r76, %r74, %r75;
(EngineCore_DP0 pid=366078) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	shfl.sync.bfly.b32 	%r77, %r76, 1, 31, -1;
(EngineCore_DP0 pid=366078) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	max.f32 	%r58, %r76, %r77;
(EngineCore_DP0 pid=366078) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366078) 	// begin inline asm
(EngineCore_DP0 pid=366078) 	@%p28 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=366078) 	// end inline asm
(EngineCore_DP0 pid=366078) 	bar.sync 	0;
(EngineCore_DP0 pid=366078) 	ld.shared.b32 	%r78, [global_smem];
(EngineCore_DP0 pid=366078) $L__tmp2:
(EngineCore_DP0 pid=366078) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=366078) 	max.f32 	%r165, %r165, %r78;
(EngineCore_DP0 pid=366078) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=366078) 	add.s32 	%r166, %r166, 8192;
(EngineCore_DP0 pid=366078) 	setp.lt.s32 	%p7, %r166, %r20;
(EngineCore_DP0 pid=366078) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=366078) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=366078) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=366078) 	max.f32 	%r167, %r165, 0f2B8CBCCC;
(EngineCore_DP0 pid=366078) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=366078) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=366078) 	mov.b32 	%r80, 0f42FE0000;
(EngineCore_DP0 pid=366078) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=366078) 	div.full.f32 	%r81, %r167, %r80;
(EngineCore_DP0 pid=366078) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=366078) 	max.f32 	%r79, %r81, 0f37810204;
(EngineCore_DP0 pid=366078) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=366078) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=366078) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=366078) 	// begin inline asm
(EngineCore_DP0 pid=366078) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r79 };
(EngineCore_DP0 pid=366078) 	// end inline asm
(EngineCore_DP0 pid=366078) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=366078) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=366078) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=366078) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=366078) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=366078) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=366078) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=366078) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=366078) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=366078) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=366078) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=366078) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=366078) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=366078) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=366078) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=366078) 	div.full.f32 	%r14, %r80, %r167;
(EngineCore_DP0 pid=366078) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=366078) 	mov.b32 	%r168, 0;
(EngineCore_DP0 pid=366078) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=366078)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=366078) 	.loc	1 327 31                        // quant_slide_tuned_Llama3.2-3B.py:327:31
(EngineCore_DP0 pid=366078) 	add.s32 	%r85, %r16, %r168;
(EngineCore_DP0 pid=366078) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=366078) 	add.s32 	%r86, %r168, 1;
(EngineCore_DP0 pid=366078) 	setp.lt.s32 	%p18, %r85, %r15;
(EngineCore_DP0 pid=366078) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=366078) 	shr.u32 	%r87, %r85, 1;
(EngineCore_DP0 pid=366078) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=366078) 	shr.u32 	%r88, %r86, 31;
(EngineCore_DP0 pid=366078) 	add.s32 	%r89, %r86, %r88;
(EngineCore_DP0 pid=366078) 	and.b32 	%r90, %r89, 2147483646;
(EngineCore_DP0 pid=366078) 	sub.s32 	%r91, %r86, %r90;
(EngineCore_DP0 pid=366078) 	.loc	1 333 22                        // quant_slide_tuned_Llama3.2-3B.py:333:22
(EngineCore_DP0 pid=366078) 	mul.lo.s32 	%r92, %r87, 6;
(EngineCore_DP0 pid=366078) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=366078) 	shl.b32 	%r93, %r91, 1;
(EngineCore_DP0 pid=366078) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=366078) 	add.s32 	%r94, %r92, %r93;
(EngineCore_DP0 pid=366078) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=366078) 	setp.lt.s32 	%p19, %r92, %r19;
(EngineCore_DP0 pid=366078) 	setp.lt.s32 	%p20, %r94, %r19;
(EngineCore_DP0 pid=366078) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=366078) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=366078) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=366078) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=366078) 	mad.wide.s32 	%rd9, %r92, 2, %rd1;
(EngineCore_DP0 pid=366078) 	mad.wide.s32 	%rd10, %r94, 2, %rd1;
(EngineCore_DP0 pid=366078) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=366078) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=366078) 	// begin inline asm
(EngineCore_DP0 pid=366078) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=366078) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=366078) 	// end inline asm
(EngineCore_DP0 pid=366078) 	// begin inline asm
(EngineCore_DP0 pid=366078) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=366078) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=366078) 	// end inline asm
(EngineCore_DP0 pid=366078) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=366078) 	cvt.f32.bf16 	%r95, %rs48;
(EngineCore_DP0 pid=366078) 	cvt.f32.bf16 	%r96, %rs50;
(EngineCore_DP0 pid=366078) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=366078) 	or.b32 	%r97, %r92, 1;
(EngineCore_DP0 pid=366078) 	or.b32 	%r98, %r94, 1;
(EngineCore_DP0 pid=366078) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=366078) 	setp.lt.s32 	%p21, %r97, %r19;
(EngineCore_DP0 pid=366078) 	setp.lt.s32 	%p22, %r98, %r19;
(EngineCore_DP0 pid=366078) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=366078) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=366078) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=366078) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=366078) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=366078) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=366078) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=366078) 	// begin inline asm
(EngineCore_DP0 pid=366078) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=366078) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=366078) 	// end inline asm
(EngineCore_DP0 pid=366078) 	// begin inline asm
(EngineCore_DP0 pid=366078) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=366078) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=366078) 	// end inline asm
(EngineCore_DP0 pid=366078) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=366078) 	cvt.f32.bf16 	%r99, %rs52;
(EngineCore_DP0 pid=366078) 	cvt.f32.bf16 	%r100, %rs54;
(EngineCore_DP0 pid=366078) 	.loc	1 340 48                        // quant_slide_tuned_Llama3.2-3B.py:340:48
(EngineCore_DP0 pid=366078) 	add.s32 	%r101, %r92, 2;
(EngineCore_DP0 pid=366078) 	add.s32 	%r102, %r94, 2;
(EngineCore_DP0 pid=366078) 	.loc	1 340 53                        // quant_slide_tuned_Llama3.2-3B.py:340:53
(EngineCore_DP0 pid=366078) 	setp.lt.s32 	%p23, %r101, %r19;
(EngineCore_DP0 pid=366078) 	setp.lt.s32 	%p24, %r102, %r19;
(EngineCore_DP0 pid=366078) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=366078) 	and.pred 	%p14, %p18, %p23;
(EngineCore_DP0 pid=366078) 	and.pred 	%p15, %p18, %p24;
(EngineCore_DP0 pid=366078) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=366078) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=366078) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=366078) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=366078) 	// begin inline asm
(EngineCore_DP0 pid=366078) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=366078) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=366078) 	// end inline asm
(EngineCore_DP0 pid=366078) 	// begin inline asm
(EngineCore_DP0 pid=366078) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=366078) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=366078) 	// end inline asm
(EngineCore_DP0 pid=366078) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=366078) 	cvt.f32.bf16 	%r103, %rs56;
(EngineCore_DP0 pid=366078) 	cvt.f32.bf16 	%r104, %rs58;
(EngineCore_DP0 pid=366078) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=366078) 	add.s32 	%r105, %r92, 3;
(EngineCore_DP0 pid=366078) 	add.s32 	%r106, %r94, 3;
(EngineCore_DP0 pid=366078) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=366078) 	setp.lt.s32 	%p25, %r105, %r19;
(EngineCore_DP0 pid=366078) 	setp.lt.s32 	%p26, %r106, %r19;
(EngineCore_DP0 pid=366078) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=366078) 	and.pred 	%p16, %p18, %p25;
(EngineCore_DP0 pid=366078) 	and.pred 	%p17, %p18, %p26;
(EngineCore_DP0 pid=366078) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=366078) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=366078) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=366078) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=366078) 	// begin inline asm
(EngineCore_DP0 pid=366078) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=366078) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=366078) 	// end inline asm
(EngineCore_DP0 pid=366078) 	// begin inline asm
(EngineCore_DP0 pid=366078) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=366078) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=366078) 	// end inline asm
(EngineCore_DP0 pid=366078) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=366078) 	cvt.f32.bf16 	%r107, %rs60;
(EngineCore_DP0 pid=366078) 	cvt.f32.bf16 	%r108, %rs62;
(EngineCore_DP0 pid=366078) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=366078) 	mul.f32 	%r109, %r14, %r95;
(EngineCore_DP0 pid=366078) 	mul.f32 	%r110, %r14, %r96;
(EngineCore_DP0 pid=366078) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=366078) 	cvt.rni.f32.f32 	%r111, %r109;
(EngineCore_DP0 pid=366078) 	cvt.rni.f32.f32 	%r112, %r110;
(EngineCore_DP0 pid=366078) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=366078) 	max.f32 	%r113, %r111, 0fC3000000;
(EngineCore_DP0 pid=366078) 	min.f32 	%r114, %r113, 0f42FE0000;
(EngineCore_DP0 pid=366078) 	max.f32 	%r115, %r112, 0fC3000000;
(EngineCore_DP0 pid=366078) 	min.f32 	%r116, %r115, 0f42FE0000;
(EngineCore_DP0 pid=366078) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=366078) 	cvt.rzi.s32.f32 	%r117, %r114;
(EngineCore_DP0 pid=366078) 	cvt.rzi.s32.f32 	%r118, %r116;
(EngineCore_DP0 pid=366078) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=366078) 	and.b32 	%r119, %r117, 255;
(EngineCore_DP0 pid=366078) 	and.b32 	%r120, %r118, 255;
(EngineCore_DP0 pid=366078) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=366078) 	mul.f32 	%r121, %r14, %r99;
(EngineCore_DP0 pid=366078) 	mul.f32 	%r122, %r14, %r100;
(EngineCore_DP0 pid=366078) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=366078) 	cvt.rni.f32.f32 	%r123, %r121;
(EngineCore_DP0 pid=366078) 	cvt.rni.f32.f32 	%r124, %r122;
(EngineCore_DP0 pid=366078) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=366078) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=366078) 	mul.f32 	%r126, %r14, %r104;
(EngineCore_DP0 pid=366078) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=366078) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=366078) 	cvt.rni.f32.f32 	%r128, %r126;
(EngineCore_DP0 pid=366078) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=366078) 	mul.f32 	%r129, %r14, %r107;
(EngineCore_DP0 pid=366078) 	mul.f32 	%r130, %r14, %r108;
(EngineCore_DP0 pid=366078) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=366078) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=366078) 	cvt.rni.f32.f32 	%r132, %r130;
(EngineCore_DP0 pid=366078) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=366078) 	max.f32 	%r133, %r131, 0fC3000000;
(EngineCore_DP0 pid=366078) 	min.f32 	%r134, %r133, 0f42FE0000;
(EngineCore_DP0 pid=366078) 	max.f32 	%r135, %r132, 0fC3000000;
(EngineCore_DP0 pid=366078) 	min.f32 	%r136, %r135, 0f42FE0000;
(EngineCore_DP0 pid=366078) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=366078) 	cvt.rzi.s32.f32 	%r137, %r134;
(EngineCore_DP0 pid=366078) 	cvt.rzi.s32.f32 	%r138, %r136;
(EngineCore_DP0 pid=366078) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=366078) 	max.f32 	%r139, %r127, 0fC3000000;
(EngineCore_DP0 pid=366078) 	max.f32 	%r140, %r123, 0fC3000000;
(EngineCore_DP0 pid=366078) 	min.f32 	%r141, %r140, 0f42FE0000;
(EngineCore_DP0 pid=366078) 	min.f32 	%r142, %r139, 0f42FE0000;
(EngineCore_DP0 pid=366078) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=366078) 	cvt.rzi.s32.f32 	%r143, %r142;
(EngineCore_DP0 pid=366078) 	cvt.rzi.s32.f32 	%r144, %r141;
(EngineCore_DP0 pid=366078) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=366078) 	shl.b32 	%r145, %r144, 8;
(EngineCore_DP0 pid=366078) 	shl.b32 	%r146, %r143, 16;
(EngineCore_DP0 pid=366078) 	and.b32 	%r147, %r146, 16711680;
(EngineCore_DP0 pid=366078) 	and.b32 	%r148, %r145, 65280;
(EngineCore_DP0 pid=366078) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=366078) 	or.b32 	%r149, %r148, %r119;
(EngineCore_DP0 pid=366078) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=366078) 	max.f32 	%r150, %r128, 0fC3000000;
(EngineCore_DP0 pid=366078) 	max.f32 	%r151, %r124, 0fC3000000;
(EngineCore_DP0 pid=366078) 	min.f32 	%r152, %r151, 0f42FE0000;
(EngineCore_DP0 pid=366078) 	min.f32 	%r153, %r150, 0f42FE0000;
(EngineCore_DP0 pid=366078) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=366078) 	cvt.rzi.s32.f32 	%r154, %r153;
(EngineCore_DP0 pid=366078) 	cvt.rzi.s32.f32 	%r155, %r152;
(EngineCore_DP0 pid=366078) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=366078) 	shl.b32 	%r156, %r155, 8;
(EngineCore_DP0 pid=366078) 	shl.b32 	%r157, %r154, 16;
(EngineCore_DP0 pid=366078) 	and.b32 	%r158, %r157, 16711680;
(EngineCore_DP0 pid=366078) 	and.b32 	%r159, %r156, 65280;
(EngineCore_DP0 pid=366078) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=366078) 	or.b32 	%r160, %r159, %r120;
(EngineCore_DP0 pid=366078) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=366078) 	or.b32 	%r161, %r149, %r147;
(EngineCore_DP0 pid=366078) 	or.b32 	%r162, %r160, %r158;
(EngineCore_DP0 pid=366078) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=366078) 	shl.b32 	%r163, %r137, 24;
(EngineCore_DP0 pid=366078) 	shl.b32 	%r164, %r138, 24;
(EngineCore_DP0 pid=366078) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=366078) 	or.b32 	%r83, %r161, %r163;
(EngineCore_DP0 pid=366078) 	or.b32 	%r84, %r162, %r164;
(EngineCore_DP0 pid=366078) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=366078) 	mad.wide.s32 	%rd17, %r85, 4, %rd2;
(EngineCore_DP0 pid=366078) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=366078) 	// begin inline asm
(EngineCore_DP0 pid=366078) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r83, %r84 };
(EngineCore_DP0 pid=366078) 	// end inline asm
(EngineCore_DP0 pid=366078) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=366078) 	add.s32 	%r168, %r168, 1024;
(EngineCore_DP0 pid=366078) 	setp.lt.s32 	%p27, %r168, %r15;
(EngineCore_DP0 pid=366078) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=366078) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=366078) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=366078) 	ret;
(EngineCore_DP0 pid=366078) $L__tmp3:
(EngineCore_DP0 pid=366078) $L__func_end0:
(EngineCore_DP0 pid=366078)                                         // -- End function
(EngineCore_DP0 pid=366078) }
(EngineCore_DP0 pid=366078) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=366078) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=366078) 	.section	.debug_abbrev
(EngineCore_DP0 pid=366078) 	{
(EngineCore_DP0 pid=366078) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=366078) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=366078) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=366078) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=366078) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=366078) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=366078) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=366078) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=366078) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=366078) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=366078) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=366078) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=366078) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=366078) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=366078) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=366078) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=366078) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=366078) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=366078) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=366078) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=366078) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=366078) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=366078) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=366078) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=366078) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=366078) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=366078) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=366078) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=366078) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=366078) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=366078) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=366078) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=366078) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=366078) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=366078) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=366078) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=366078) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=366078) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=366078) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=366078) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=366078) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=366078) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=366078) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=366078) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=366078) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=366078) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=366078) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=366078) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=366078) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=366078) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=366078) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=366078) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=366078) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=366078) 	}
(EngineCore_DP0 pid=366078) 	.section	.debug_info
(EngineCore_DP0 pid=366078) 	{
(EngineCore_DP0 pid=366078) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=366078) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=366078) .b8 0
(EngineCore_DP0 pid=366078) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=366078) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=366078) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=366078) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=366078) .b8 114
(EngineCore_DP0 pid=366078) .b8 105
(EngineCore_DP0 pid=366078) .b8 116
(EngineCore_DP0 pid=366078) .b8 111
(EngineCore_DP0 pid=366078) .b8 110
(EngineCore_DP0 pid=366078) .b8 0
(EngineCore_DP0 pid=366078) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=366078) .b8 0
(EngineCore_DP0 pid=366078) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=366078) .b8 117
(EngineCore_DP0 pid=366078) .b8 97
(EngineCore_DP0 pid=366078) .b8 110
(EngineCore_DP0 pid=366078) .b8 116
(EngineCore_DP0 pid=366078) .b8 95
(EngineCore_DP0 pid=366078) .b8 115
(EngineCore_DP0 pid=366078) .b8 108
(EngineCore_DP0 pid=366078) .b8 105
(EngineCore_DP0 pid=366078) .b8 100
(EngineCore_DP0 pid=366078) .b8 101
(EngineCore_DP0 pid=366078) .b8 95
(EngineCore_DP0 pid=366078) .b8 116
(EngineCore_DP0 pid=366078) .b8 117
(EngineCore_DP0 pid=366078) .b8 110
(EngineCore_DP0 pid=366078) .b8 101
(EngineCore_DP0 pid=366078) .b8 100
(EngineCore_DP0 pid=366078) .b8 95
(EngineCore_DP0 pid=366078) .b8 76
(EngineCore_DP0 pid=366078) .b8 108
(EngineCore_DP0 pid=366078) .b8 97
(EngineCore_DP0 pid=366078) .b8 109
(EngineCore_DP0 pid=366078) .b8 97
(EngineCore_DP0 pid=366078) .b8 51
(EngineCore_DP0 pid=366078) .b8 46
(EngineCore_DP0 pid=366078) .b8 50
(EngineCore_DP0 pid=366078) .b8 45
(EngineCore_DP0 pid=366078) .b8 51
(EngineCore_DP0 pid=366078) .b8 66
(EngineCore_DP0 pid=366078) .b8 46
(EngineCore_DP0 pid=366078) .b8 112
(EngineCore_DP0 pid=366078) .b8 121
(EngineCore_DP0 pid=366078) .b8 0
(EngineCore_DP0 pid=366078) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=366078) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=366078) .b8 114
(EngineCore_DP0 pid=366078) .b8 111
(EngineCore_DP0 pid=366078) .b8 111
(EngineCore_DP0 pid=366078) .b8 116
(EngineCore_DP0 pid=366078) .b8 47
(EngineCore_DP0 pid=366078) .b8 118
(EngineCore_DP0 pid=366078) .b8 108
(EngineCore_DP0 pid=366078) .b8 108
(EngineCore_DP0 pid=366078) .b8 109
(EngineCore_DP0 pid=366078) .b8 98
(EngineCore_DP0 pid=366078) .b8 101
(EngineCore_DP0 pid=366078) .b8 110
(EngineCore_DP0 pid=366078) .b8 99
(EngineCore_DP0 pid=366078) .b8 104
(EngineCore_DP0 pid=366078) .b8 47
(EngineCore_DP0 pid=366078) .b8 115
(EngineCore_DP0 pid=366078) .b8 108
(EngineCore_DP0 pid=366078) .b8 105
(EngineCore_DP0 pid=366078) .b8 100
(EngineCore_DP0 pid=366078) .b8 101
(EngineCore_DP0 pid=366078) .b8 115
(EngineCore_DP0 pid=366078) .b8 112
(EngineCore_DP0 pid=366078) .b8 97
(EngineCore_DP0 pid=366078) .b8 114
(EngineCore_DP0 pid=366078) .b8 115
(EngineCore_DP0 pid=366078) .b8 101
(EngineCore_DP0 pid=366078) .b8 47
(EngineCore_DP0 pid=366078) .b8 99
(EngineCore_DP0 pid=366078) .b8 115
(EngineCore_DP0 pid=366078) .b8 114
(EngineCore_DP0 pid=366078) .b8 99
(EngineCore_DP0 pid=366078) .b8 47
(EngineCore_DP0 pid=366078) .b8 102
(EngineCore_DP0 pid=366078) .b8 117
(EngineCore_DP0 pid=366078) .b8 115
(EngineCore_DP0 pid=366078) .b8 101
(EngineCore_DP0 pid=366078) .b8 100
(EngineCore_DP0 pid=366078) .b8 95
(EngineCore_DP0 pid=366078) .b8 113
(EngineCore_DP0 pid=366078) .b8 117
(EngineCore_DP0 pid=366078) .b8 97
(EngineCore_DP0 pid=366078) .b8 110
(EngineCore_DP0 pid=366078) .b8 116
(EngineCore_DP0 pid=366078) .b8 95
(EngineCore_DP0 pid=366078) .b8 115
(EngineCore_DP0 pid=366078) .b8 108
(EngineCore_DP0 pid=366078) .b8 105
(EngineCore_DP0 pid=366078) .b8 100
(EngineCore_DP0 pid=366078) .b8 101
(EngineCore_DP0 pid=366078) .b8 95
(EngineCore_DP0 pid=366078) .b8 116
(EngineCore_DP0 pid=366078) .b8 114
(EngineCore_DP0 pid=366078) .b8 105
(EngineCore_DP0 pid=366078) .b8 116
(EngineCore_DP0 pid=366078) .b8 111
(EngineCore_DP0 pid=366078) .b8 110
(EngineCore_DP0 pid=366078) .b8 47
(EngineCore_DP0 pid=366078) .b8 98
(EngineCore_DP0 pid=366078) .b8 117
(EngineCore_DP0 pid=366078) .b8 105
(EngineCore_DP0 pid=366078) .b8 108
(EngineCore_DP0 pid=366078) .b8 100
(EngineCore_DP0 pid=366078) .b8 47
(EngineCore_DP0 pid=366078) .b8 71
(EngineCore_DP0 pid=366078) .b8 66
(EngineCore_DP0 pid=366078) .b8 49
(EngineCore_DP0 pid=366078) .b8 48
(EngineCore_DP0 pid=366078) .b8 95
(EngineCore_DP0 pid=366078) .b8 99
(EngineCore_DP0 pid=366078) .b8 99
(EngineCore_DP0 pid=366078) .b8 49
(EngineCore_DP0 pid=366078) .b8 50
(EngineCore_DP0 pid=366078) .b8 49
(EngineCore_DP0 pid=366078) .b8 95
(EngineCore_DP0 pid=366078) .b8 112
(EngineCore_DP0 pid=366078) .b8 121
(EngineCore_DP0 pid=366078) .b8 51
(EngineCore_DP0 pid=366078) .b8 49
(EngineCore_DP0 pid=366078) .b8 50
(EngineCore_DP0 pid=366078) .b8 95
(EngineCore_DP0 pid=366078) .b8 99
(EngineCore_DP0 pid=366078) .b8 117
(EngineCore_DP0 pid=366078) .b8 49
(EngineCore_DP0 pid=366078) .b8 50
(EngineCore_DP0 pid=366078) .b8 57
(EngineCore_DP0 pid=366078) .b8 95
(EngineCore_DP0 pid=366078) .b8 97
(EngineCore_DP0 pid=366078) .b8 97
(EngineCore_DP0 pid=366078) .b8 114
(EngineCore_DP0 pid=366078) .b8 99
(EngineCore_DP0 pid=366078) .b8 104
(EngineCore_DP0 pid=366078) .b8 54
(EngineCore_DP0 pid=366078) .b8 52
(EngineCore_DP0 pid=366078) .b8 0
(EngineCore_DP0 pid=366078) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=366078) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=366078) .b8 113
(EngineCore_DP0 pid=366078) .b8 117
(EngineCore_DP0 pid=366078) .b8 97
(EngineCore_DP0 pid=366078) .b8 110
(EngineCore_DP0 pid=366078) .b8 116
(EngineCore_DP0 pid=366078) .b8 95
(EngineCore_DP0 pid=366078) .b8 115
(EngineCore_DP0 pid=366078) .b8 108
(EngineCore_DP0 pid=366078) .b8 105
(EngineCore_DP0 pid=366078) .b8 100
(EngineCore_DP0 pid=366078) .b8 101
(EngineCore_DP0 pid=366078) .b8 95
(EngineCore_DP0 pid=366078) .b8 105
(EngineCore_DP0 pid=366078) .b8 110
(EngineCore_DP0 pid=366078) .b8 116
(EngineCore_DP0 pid=366078) .b8 56
(EngineCore_DP0 pid=366078) .b8 95
(EngineCore_DP0 pid=366078) .b8 107
(EngineCore_DP0 pid=366078) .b8 101
(EngineCore_DP0 pid=366078) .b8 114
(EngineCore_DP0 pid=366078) .b8 110
(EngineCore_DP0 pid=366078) .b8 101
(EngineCore_DP0 pid=366078) .b8 108
(EngineCore_DP0 pid=366078) .b8 0
(EngineCore_DP0 pid=366078) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=366078) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=366078) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=366078) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=366078) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=366078) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=366078) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=366078) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=366078) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=366078) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=366078) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=366078) .b8 1
(EngineCore_DP0 pid=366078) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=366078) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=366078) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=366078) 	}
(EngineCore_DP0 pid=366078) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=366078) 
(EngineCore_DP0 pid=366078) ================================================================
(EngineCore_DP0 pid=366078) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=366078) 
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpjm6jf_fl.ptx', '-o', '/tmp/tmpjm6jf_fl.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866] 
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866] 
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866] 
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpjm6jf_fl.ptx -o /tmp/tmpjm6jf_fl.ptx.o
(EngineCore_DP0 pid=366078) ERROR 01-25 19:41:14 [core.py:866] 

STDERR:
[2026-01-25 19:40:43] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:40:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:40:43] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:40:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:40:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:40:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:40:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:40:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:40:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:40:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:40:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:40:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:40:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:40:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:40:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:40:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:40:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:40:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:40:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=366078) [2026-01-25 19:40:47] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=366078) [2026-01-25 19:40:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=366078) [2026-01-25 19:40:47] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=366078) [2026-01-25 19:40:47] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=366078) [2026-01-25 19:40:47] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=366078) [2026-01-25 19:40:47] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=366078) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=366078) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.57s/it]
(EngineCore_DP0 pid=366078) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.57s/it]
(EngineCore_DP0 pid=366078) 
(EngineCore_DP0 pid=366078) [2026-01-25 19:41:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=366078) [2026-01-25 19:41:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=366078) [2026-01-25 19:41:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=366078) [2026-01-25 19:41:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9437184 bytes
(EngineCore_DP0 pid=366078) [2026-01-25 19:41:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=366078) [2026-01-25 19:41:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50331648 bytes
(EngineCore_DP0 pid=366078) [2026-01-25 19:41:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=366078) [2026-01-25 19:41:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25264128 bytes
(EngineCore_DP0 pid=366078) Process EngineCore_DP0:
(EngineCore_DP0 pid=366078) Traceback (most recent call last):
(EngineCore_DP0 pid=366078)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=366078)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=366078)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=366078)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=366078) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpjm6jf_fl.ptx', '-o', '/tmp/tmpjm6jf_fl.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=366078) 
(EngineCore_DP0 pid=366078) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=366078) 
(EngineCore_DP0 pid=366078) Traceback (most recent call last):
(EngineCore_DP0 pid=366078)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=366078)     self.run()
(EngineCore_DP0 pid=366078)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=366078)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=366078)     raise e
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=366078)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=366078)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=366078)     super().__init__(
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=366078)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=366078)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=366078)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=366078)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=366078)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=366078)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=366078)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=366078)     return func(*args, **kwargs)
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=366078)     return func(*args, **kwargs)
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=366078)     self.model_runner.profile_run()
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=366078)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=366078)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=366078)     return func(*args, **kwargs)
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=366078)     outputs = self.model(
(EngineCore_DP0 pid=366078)               ^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=366078)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=366078)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=366078)     model_output = self.model(
(EngineCore_DP0 pid=366078)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=366078)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=366078)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=366078)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=366078)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=366078)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=366078)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=366078)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=366078)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=366078)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=366078)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=366078)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=366078)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=366078)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=366078)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=366078)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=366078)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=366078)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=366078)     return self._linear_fn(
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=366078)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=366078)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=366078)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=366078)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=366078)     return fn(input, L)
(EngineCore_DP0 pid=366078)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=366078)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=366078)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=366078)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=366078)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=366078)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=366078)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=366078)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=366078)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=366078)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=366078)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=366078)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=366078)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366078)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=366078)     raise PTXASError(error)
(EngineCore_DP0 pid=366078) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=366078) `ptxas` stderr:
(EngineCore_DP0 pid=366078) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=366078) 
(EngineCore_DP0 pid=366078) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpjm6jf_fl.ptx -o /tmp/tmpjm6jf_fl.ptx.o
(EngineCore_DP0 pid=366078) 
[rank0]:[W125 19:41:14.980401699 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 19:41:16
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:41:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:41:31 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=366931) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=366931) 
(EngineCore_DP0 pid=366931) 
(EngineCore_DP0 pid=366931) ================================================================
(EngineCore_DP0 pid=366931) Internal Triton PTX codegen error
(EngineCore_DP0 pid=366931) `ptxas` stderr:
(EngineCore_DP0 pid=366931) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=366931) 
(EngineCore_DP0 pid=366931) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpo8x0u9hc.ptx -o /tmp/tmpo8x0u9hc.ptx.o
(EngineCore_DP0 pid=366931) 
(EngineCore_DP0 pid=366931) 
(EngineCore_DP0 pid=366931) //
(EngineCore_DP0 pid=366931) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=366931) //
(EngineCore_DP0 pid=366931) 
(EngineCore_DP0 pid=366931) .version 8.7
(EngineCore_DP0 pid=366931) .target sm_121a
(EngineCore_DP0 pid=366931) .address_size 64
(EngineCore_DP0 pid=366931) 
(EngineCore_DP0 pid=366931) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=366931) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=366931)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=366931) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=366931) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=366931) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=366931) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=366931) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=366931) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=366931) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=366931) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=366931) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=366931) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=366931) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=366931) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=366931) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=366931) )
(EngineCore_DP0 pid=366931) .reqntid 512
(EngineCore_DP0 pid=366931) {
(EngineCore_DP0 pid=366931) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=366931) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=366931) 	.reg .b32 	%r<242>;
(EngineCore_DP0 pid=366931) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=366931) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=366931) $L__func_begin0:
(EngineCore_DP0 pid=366931) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=366931) 
(EngineCore_DP0 pid=366931) // %bb.0:
(EngineCore_DP0 pid=366931) 	ld.param.b32 	%r29, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=366931) 	ld.param.b32 	%r28, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=366931) 	ld.param.b32 	%r27, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=366931) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=366931) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=366931) $L__tmp0:
(EngineCore_DP0 pid=366931) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=366931) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=366931) 	ld.param.b32 	%r31, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=366931) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=366931) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=366931) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=366931) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=366931) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=366931) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=366931) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=366931) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=366931) 	mov.b32 	%r240, 0f2B8CBCCC;
(EngineCore_DP0 pid=366931) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=366931) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=366931) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=366931) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=366931) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=366931) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=366931) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=366931) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=366931) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=366931) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=366931) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=366931) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=366931) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=366931) 	mov.b32 	%r238, 0f00000000;
(EngineCore_DP0 pid=366931) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=366931) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=366931) 	mov.b32 	%r239, %r49;
(EngineCore_DP0 pid=366931) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=366931) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=366931) 	add.s32 	%r59, %r4, %r239;
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=366931) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=366931) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=366931) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=366931) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=366931) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=366931) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=366931) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=366931) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=366931) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=366931) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=366931) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=366931) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=366931) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=366931) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=366931) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=366931) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=366931) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=366931) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=366931) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=366931) $L__tmp1:
(EngineCore_DP0 pid=366931) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	bar.sync 	0;
(EngineCore_DP0 pid=366931) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=366931) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=366931) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=366931) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=366931) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=366931) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=366931) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=366931) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=366931) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=366931) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=366931) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=366931) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=366931) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=366931) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=366931) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=366931) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=366931) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=366931) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=366931) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	bar.sync 	0;
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=366931) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=366931) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=366931) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=366931) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=366931) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=366931) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=366931) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=366931) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	bar.sync 	0;
(EngineCore_DP0 pid=366931) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=366931) $L__tmp2:
(EngineCore_DP0 pid=366931) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=366931) 	max.f32 	%r238, %r238, %r77;
(EngineCore_DP0 pid=366931) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=366931) 	add.s32 	%r239, %r239, 4096;
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p6, %r239, %r28;
(EngineCore_DP0 pid=366931) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=366931) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=366931) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=366931) 	max.f32 	%r240, %r238, 0f2B8CBCCC;
(EngineCore_DP0 pid=366931) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=366931) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=366931) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=366931) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=366931) 	div.full.f32 	%r80, %r240, %r79;
(EngineCore_DP0 pid=366931) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=366931) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=366931) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=366931) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=366931) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=366931) 	shl.b32 	%r15, %r29, 1;
(EngineCore_DP0 pid=366931) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=366931) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=366931) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=366931) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=366931) 	ld.param.b32 	%r33, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=366931) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=366931) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=366931) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=366931) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=366931) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=366931) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=366931) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=366931) 	div.full.f32 	%r14, %r79, %r240;
(EngineCore_DP0 pid=366931) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=366931) 	mov.b32 	%r241, 0;
(EngineCore_DP0 pid=366931) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=366931)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=366931) 	.loc	1 327 31                        // quant_slide_tuned_Llama3.2-3B.py:327:31
(EngineCore_DP0 pid=366931) 	add.s32 	%r86, %r16, %r241;
(EngineCore_DP0 pid=366931) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=366931) 	add.s32 	%r87, %r241, 1;
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p25, %r86, %r15;
(EngineCore_DP0 pid=366931) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=366931) 	shr.u32 	%r88, %r86, 1;
(EngineCore_DP0 pid=366931) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=366931) 	shr.u32 	%r89, %r87, 31;
(EngineCore_DP0 pid=366931) 	add.s32 	%r90, %r87, %r89;
(EngineCore_DP0 pid=366931) 	and.b32 	%r91, %r90, 2147483646;
(EngineCore_DP0 pid=366931) 	sub.s32 	%r92, %r87, %r91;
(EngineCore_DP0 pid=366931) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=366931) 	shl.b32 	%r93, %r92, 1;
(EngineCore_DP0 pid=366931) 	.loc	1 333 22                        // quant_slide_tuned_Llama3.2-3B.py:333:22
(EngineCore_DP0 pid=366931) 	mul.lo.s32 	%r94, %r88, 6;
(EngineCore_DP0 pid=366931) 	add.s32 	%r95, %r94, 6;
(EngineCore_DP0 pid=366931) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=366931) 	add.s32 	%r96, %r94, %r93;
(EngineCore_DP0 pid=366931) 	add.s32 	%r97, %r95, %r93;
(EngineCore_DP0 pid=366931) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p26, %r94, %r27;
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p27, %r96, %r27;
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p28, %r95, %r27;
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p29, %r97, %r27;
(EngineCore_DP0 pid=366931) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=366931) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=366931) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=366931) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=366931) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=366931) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=366931) 	mad.wide.s32 	%rd8, %r94, 2, %rd1;
(EngineCore_DP0 pid=366931) 	mad.wide.s32 	%rd9, %r96, 2, %rd1;
(EngineCore_DP0 pid=366931) 	mad.wide.s32 	%rd10, %r95, 2, %rd1;
(EngineCore_DP0 pid=366931) 	mad.wide.s32 	%rd11, %r97, 2, %rd1;
(EngineCore_DP0 pid=366931) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=366931) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=366931) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=366931) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=366931) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=366931) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=366931) 	cvt.f32.bf16 	%r98, %rs24;
(EngineCore_DP0 pid=366931) 	cvt.f32.bf16 	%r99, %rs26;
(EngineCore_DP0 pid=366931) 	cvt.f32.bf16 	%r100, %rs28;
(EngineCore_DP0 pid=366931) 	cvt.f32.bf16 	%r101, %rs30;
(EngineCore_DP0 pid=366931) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=366931) 	or.b32 	%r102, %r96, 1;
(EngineCore_DP0 pid=366931) 	or.b32 	%r103, %r97, 1;
(EngineCore_DP0 pid=366931) 	or.b32 	%r104, %r97, 2;
(EngineCore_DP0 pid=366931) 	or.b32 	%r105, %r97, 3;
(EngineCore_DP0 pid=366931) 	or.b32 	%r106, %r94, 1;
(EngineCore_DP0 pid=366931) 	add.s32 	%r107, %r94, 7;
(EngineCore_DP0 pid=366931) 	or.b32 	%r108, %r94, 2;
(EngineCore_DP0 pid=366931) 	or.b32 	%r109, %r94, 3;
(EngineCore_DP0 pid=366931) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p30, %r105, %r27;
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p31, %r104, %r27;
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p32, %r103, %r27;
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p33, %r102, %r27;
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p34, %r109, %r27;
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p35, %r108, %r27;
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p36, %r107, %r27;
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p37, %r106, %r27;
(EngineCore_DP0 pid=366931) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=366931) 	and.pred 	%p13, %p25, %p37;
(EngineCore_DP0 pid=366931) 	and.pred 	%p14, %p25, %p33;
(EngineCore_DP0 pid=366931) 	and.pred 	%p15, %p25, %p36;
(EngineCore_DP0 pid=366931) 	and.pred 	%p16, %p25, %p32;
(EngineCore_DP0 pid=366931) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=366931) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=366931) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=366931) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=366931) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=366931) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=366931) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=366931) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=366931) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=366931) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=366931) 	cvt.f32.bf16 	%r110, %rs32;
(EngineCore_DP0 pid=366931) 	cvt.f32.bf16 	%r111, %rs34;
(EngineCore_DP0 pid=366931) 	cvt.f32.bf16 	%r112, %rs36;
(EngineCore_DP0 pid=366931) 	cvt.f32.bf16 	%r113, %rs38;
(EngineCore_DP0 pid=366931) 	.loc	1 340 48                        // quant_slide_tuned_Llama3.2-3B.py:340:48
(EngineCore_DP0 pid=366931) 	add.s32 	%r114, %r96, 2;
(EngineCore_DP0 pid=366931) 	add.s32 	%r115, %r94, 8;
(EngineCore_DP0 pid=366931) 	.loc	1 340 53                        // quant_slide_tuned_Llama3.2-3B.py:340:53
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p38, %r114, %r27;
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p39, %r115, %r27;
(EngineCore_DP0 pid=366931) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=366931) 	and.pred 	%p17, %p25, %p35;
(EngineCore_DP0 pid=366931) 	and.pred 	%p18, %p25, %p38;
(EngineCore_DP0 pid=366931) 	and.pred 	%p19, %p25, %p39;
(EngineCore_DP0 pid=366931) 	and.pred 	%p20, %p25, %p31;
(EngineCore_DP0 pid=366931) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=366931) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=366931) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=366931) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=366931) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=366931) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=366931) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=366931) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=366931) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=366931) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=366931) 	cvt.f32.bf16 	%r116, %rs40;
(EngineCore_DP0 pid=366931) 	cvt.f32.bf16 	%r117, %rs42;
(EngineCore_DP0 pid=366931) 	cvt.f32.bf16 	%r118, %rs44;
(EngineCore_DP0 pid=366931) 	cvt.f32.bf16 	%r119, %rs46;
(EngineCore_DP0 pid=366931) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=366931) 	add.s32 	%r120, %r96, 3;
(EngineCore_DP0 pid=366931) 	add.s32 	%r121, %r94, 9;
(EngineCore_DP0 pid=366931) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p40, %r120, %r27;
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p41, %r121, %r27;
(EngineCore_DP0 pid=366931) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=366931) 	and.pred 	%p21, %p25, %p34;
(EngineCore_DP0 pid=366931) 	and.pred 	%p22, %p25, %p40;
(EngineCore_DP0 pid=366931) 	and.pred 	%p23, %p25, %p41;
(EngineCore_DP0 pid=366931) 	and.pred 	%p24, %p25, %p30;
(EngineCore_DP0 pid=366931) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=366931) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=366931) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=366931) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=366931) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=366931) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=366931) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=366931) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=366931) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=366931) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=366931) 	cvt.f32.bf16 	%r122, %rs48;
(EngineCore_DP0 pid=366931) 	cvt.f32.bf16 	%r123, %rs50;
(EngineCore_DP0 pid=366931) 	cvt.f32.bf16 	%r124, %rs52;
(EngineCore_DP0 pid=366931) 	cvt.f32.bf16 	%r125, %rs54;
(EngineCore_DP0 pid=366931) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=366931) 	mul.f32 	%r126, %r14, %r98;
(EngineCore_DP0 pid=366931) 	mul.f32 	%r127, %r14, %r99;
(EngineCore_DP0 pid=366931) 	mul.f32 	%r128, %r14, %r100;
(EngineCore_DP0 pid=366931) 	mul.f32 	%r129, %r14, %r101;
(EngineCore_DP0 pid=366931) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=366931) 	cvt.rni.f32.f32 	%r130, %r126;
(EngineCore_DP0 pid=366931) 	cvt.rni.f32.f32 	%r131, %r127;
(EngineCore_DP0 pid=366931) 	cvt.rni.f32.f32 	%r132, %r128;
(EngineCore_DP0 pid=366931) 	cvt.rni.f32.f32 	%r133, %r129;
(EngineCore_DP0 pid=366931) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=366931) 	max.f32 	%r134, %r130, 0fC3000000;
(EngineCore_DP0 pid=366931) 	min.f32 	%r135, %r134, 0f42FE0000;
(EngineCore_DP0 pid=366931) 	max.f32 	%r136, %r131, 0fC3000000;
(EngineCore_DP0 pid=366931) 	min.f32 	%r137, %r136, 0f42FE0000;
(EngineCore_DP0 pid=366931) 	max.f32 	%r138, %r132, 0fC3000000;
(EngineCore_DP0 pid=366931) 	min.f32 	%r139, %r138, 0f42FE0000;
(EngineCore_DP0 pid=366931) 	max.f32 	%r140, %r133, 0fC3000000;
(EngineCore_DP0 pid=366931) 	min.f32 	%r141, %r140, 0f42FE0000;
(EngineCore_DP0 pid=366931) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=366931) 	cvt.rzi.s32.f32 	%r142, %r135;
(EngineCore_DP0 pid=366931) 	cvt.rzi.s32.f32 	%r143, %r137;
(EngineCore_DP0 pid=366931) 	cvt.rzi.s32.f32 	%r144, %r139;
(EngineCore_DP0 pid=366931) 	cvt.rzi.s32.f32 	%r145, %r141;
(EngineCore_DP0 pid=366931) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=366931) 	and.b32 	%r146, %r142, 255;
(EngineCore_DP0 pid=366931) 	and.b32 	%r147, %r143, 255;
(EngineCore_DP0 pid=366931) 	and.b32 	%r148, %r144, 255;
(EngineCore_DP0 pid=366931) 	and.b32 	%r149, %r145, 255;
(EngineCore_DP0 pid=366931) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=366931) 	mul.f32 	%r150, %r14, %r110;
(EngineCore_DP0 pid=366931) 	mul.f32 	%r151, %r14, %r111;
(EngineCore_DP0 pid=366931) 	mul.f32 	%r152, %r14, %r112;
(EngineCore_DP0 pid=366931) 	mul.f32 	%r153, %r14, %r113;
(EngineCore_DP0 pid=366931) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=366931) 	cvt.rni.f32.f32 	%r154, %r150;
(EngineCore_DP0 pid=366931) 	cvt.rni.f32.f32 	%r155, %r151;
(EngineCore_DP0 pid=366931) 	cvt.rni.f32.f32 	%r156, %r152;
(EngineCore_DP0 pid=366931) 	cvt.rni.f32.f32 	%r157, %r153;
(EngineCore_DP0 pid=366931) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=366931) 	mul.f32 	%r158, %r14, %r116;
(EngineCore_DP0 pid=366931) 	mul.f32 	%r159, %r14, %r117;
(EngineCore_DP0 pid=366931) 	mul.f32 	%r160, %r14, %r118;
(EngineCore_DP0 pid=366931) 	mul.f32 	%r161, %r14, %r119;
(EngineCore_DP0 pid=366931) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=366931) 	cvt.rni.f32.f32 	%r162, %r158;
(EngineCore_DP0 pid=366931) 	cvt.rni.f32.f32 	%r163, %r159;
(EngineCore_DP0 pid=366931) 	cvt.rni.f32.f32 	%r164, %r160;
(EngineCore_DP0 pid=366931) 	cvt.rni.f32.f32 	%r165, %r161;
(EngineCore_DP0 pid=366931) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=366931) 	mul.f32 	%r166, %r14, %r122;
(EngineCore_DP0 pid=366931) 	mul.f32 	%r167, %r14, %r123;
(EngineCore_DP0 pid=366931) 	mul.f32 	%r168, %r14, %r124;
(EngineCore_DP0 pid=366931) 	mul.f32 	%r169, %r14, %r125;
(EngineCore_DP0 pid=366931) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=366931) 	cvt.rni.f32.f32 	%r170, %r166;
(EngineCore_DP0 pid=366931) 	cvt.rni.f32.f32 	%r171, %r167;
(EngineCore_DP0 pid=366931) 	cvt.rni.f32.f32 	%r172, %r168;
(EngineCore_DP0 pid=366931) 	cvt.rni.f32.f32 	%r173, %r169;
(EngineCore_DP0 pid=366931) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=366931) 	max.f32 	%r174, %r170, 0fC3000000;
(EngineCore_DP0 pid=366931) 	min.f32 	%r175, %r174, 0f42FE0000;
(EngineCore_DP0 pid=366931) 	max.f32 	%r176, %r171, 0fC3000000;
(EngineCore_DP0 pid=366931) 	min.f32 	%r177, %r176, 0f42FE0000;
(EngineCore_DP0 pid=366931) 	max.f32 	%r178, %r172, 0fC3000000;
(EngineCore_DP0 pid=366931) 	min.f32 	%r179, %r178, 0f42FE0000;
(EngineCore_DP0 pid=366931) 	max.f32 	%r180, %r173, 0fC3000000;
(EngineCore_DP0 pid=366931) 	min.f32 	%r181, %r180, 0f42FE0000;
(EngineCore_DP0 pid=366931) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=366931) 	cvt.rzi.s32.f32 	%r182, %r175;
(EngineCore_DP0 pid=366931) 	cvt.rzi.s32.f32 	%r183, %r177;
(EngineCore_DP0 pid=366931) 	cvt.rzi.s32.f32 	%r184, %r179;
(EngineCore_DP0 pid=366931) 	cvt.rzi.s32.f32 	%r185, %r181;
(EngineCore_DP0 pid=366931) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=366931) 	max.f32 	%r186, %r162, 0fC3000000;
(EngineCore_DP0 pid=366931) 	max.f32 	%r187, %r154, 0fC3000000;
(EngineCore_DP0 pid=366931) 	min.f32 	%r188, %r187, 0f42FE0000;
(EngineCore_DP0 pid=366931) 	min.f32 	%r189, %r186, 0f42FE0000;
(EngineCore_DP0 pid=366931) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=366931) 	cvt.rzi.s32.f32 	%r190, %r189;
(EngineCore_DP0 pid=366931) 	cvt.rzi.s32.f32 	%r191, %r188;
(EngineCore_DP0 pid=366931) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=366931) 	shl.b32 	%r192, %r191, 8;
(EngineCore_DP0 pid=366931) 	shl.b32 	%r193, %r190, 16;
(EngineCore_DP0 pid=366931) 	and.b32 	%r194, %r193, 16711680;
(EngineCore_DP0 pid=366931) 	and.b32 	%r195, %r192, 65280;
(EngineCore_DP0 pid=366931) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=366931) 	or.b32 	%r196, %r195, %r146;
(EngineCore_DP0 pid=366931) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=366931) 	max.f32 	%r197, %r163, 0fC3000000;
(EngineCore_DP0 pid=366931) 	max.f32 	%r198, %r155, 0fC3000000;
(EngineCore_DP0 pid=366931) 	min.f32 	%r199, %r198, 0f42FE0000;
(EngineCore_DP0 pid=366931) 	min.f32 	%r200, %r197, 0f42FE0000;
(EngineCore_DP0 pid=366931) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=366931) 	cvt.rzi.s32.f32 	%r201, %r200;
(EngineCore_DP0 pid=366931) 	cvt.rzi.s32.f32 	%r202, %r199;
(EngineCore_DP0 pid=366931) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=366931) 	shl.b32 	%r203, %r202, 8;
(EngineCore_DP0 pid=366931) 	shl.b32 	%r204, %r201, 16;
(EngineCore_DP0 pid=366931) 	and.b32 	%r205, %r204, 16711680;
(EngineCore_DP0 pid=366931) 	and.b32 	%r206, %r203, 65280;
(EngineCore_DP0 pid=366931) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=366931) 	or.b32 	%r207, %r206, %r147;
(EngineCore_DP0 pid=366931) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=366931) 	max.f32 	%r208, %r164, 0fC3000000;
(EngineCore_DP0 pid=366931) 	max.f32 	%r209, %r156, 0fC3000000;
(EngineCore_DP0 pid=366931) 	min.f32 	%r210, %r209, 0f42FE0000;
(EngineCore_DP0 pid=366931) 	min.f32 	%r211, %r208, 0f42FE0000;
(EngineCore_DP0 pid=366931) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=366931) 	cvt.rzi.s32.f32 	%r212, %r211;
(EngineCore_DP0 pid=366931) 	cvt.rzi.s32.f32 	%r213, %r210;
(EngineCore_DP0 pid=366931) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=366931) 	shl.b32 	%r214, %r213, 8;
(EngineCore_DP0 pid=366931) 	shl.b32 	%r215, %r212, 16;
(EngineCore_DP0 pid=366931) 	and.b32 	%r216, %r215, 16711680;
(EngineCore_DP0 pid=366931) 	and.b32 	%r217, %r214, 65280;
(EngineCore_DP0 pid=366931) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=366931) 	or.b32 	%r218, %r217, %r148;
(EngineCore_DP0 pid=366931) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=366931) 	max.f32 	%r219, %r165, 0fC3000000;
(EngineCore_DP0 pid=366931) 	max.f32 	%r220, %r157, 0fC3000000;
(EngineCore_DP0 pid=366931) 	min.f32 	%r221, %r220, 0f42FE0000;
(EngineCore_DP0 pid=366931) 	min.f32 	%r222, %r219, 0f42FE0000;
(EngineCore_DP0 pid=366931) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=366931) 	cvt.rzi.s32.f32 	%r223, %r222;
(EngineCore_DP0 pid=366931) 	cvt.rzi.s32.f32 	%r224, %r221;
(EngineCore_DP0 pid=366931) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=366931) 	shl.b32 	%r225, %r224, 8;
(EngineCore_DP0 pid=366931) 	shl.b32 	%r226, %r223, 16;
(EngineCore_DP0 pid=366931) 	and.b32 	%r227, %r226, 16711680;
(EngineCore_DP0 pid=366931) 	and.b32 	%r228, %r225, 65280;
(EngineCore_DP0 pid=366931) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=366931) 	or.b32 	%r229, %r228, %r149;
(EngineCore_DP0 pid=366931) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=366931) 	or.b32 	%r230, %r196, %r194;
(EngineCore_DP0 pid=366931) 	or.b32 	%r231, %r207, %r205;
(EngineCore_DP0 pid=366931) 	or.b32 	%r232, %r218, %r216;
(EngineCore_DP0 pid=366931) 	or.b32 	%r233, %r229, %r227;
(EngineCore_DP0 pid=366931) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=366931) 	shl.b32 	%r234, %r182, 24;
(EngineCore_DP0 pid=366931) 	shl.b32 	%r235, %r183, 24;
(EngineCore_DP0 pid=366931) 	shl.b32 	%r236, %r184, 24;
(EngineCore_DP0 pid=366931) 	shl.b32 	%r237, %r185, 24;
(EngineCore_DP0 pid=366931) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=366931) 	or.b32 	%r82, %r230, %r234;
(EngineCore_DP0 pid=366931) 	or.b32 	%r83, %r231, %r235;
(EngineCore_DP0 pid=366931) 	or.b32 	%r84, %r232, %r236;
(EngineCore_DP0 pid=366931) 	or.b32 	%r85, %r233, %r237;
(EngineCore_DP0 pid=366931) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=366931) 	mad.wide.s32 	%rd24, %r86, 4, %rd2;
(EngineCore_DP0 pid=366931) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=366931) 	// begin inline asm
(EngineCore_DP0 pid=366931) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r82, %r83, %r84, %r85 };
(EngineCore_DP0 pid=366931) 	// end inline asm
(EngineCore_DP0 pid=366931) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=366931) 	add.s32 	%r241, %r241, 2048;
(EngineCore_DP0 pid=366931) 	setp.lt.s32 	%p42, %r241, %r15;
(EngineCore_DP0 pid=366931) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=366931) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=366931) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=366931) 	ret;
(EngineCore_DP0 pid=366931) $L__tmp3:
(EngineCore_DP0 pid=366931) $L__func_end0:
(EngineCore_DP0 pid=366931)                                         // -- End function
(EngineCore_DP0 pid=366931) }
(EngineCore_DP0 pid=366931) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=366931) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=366931) 	.section	.debug_abbrev
(EngineCore_DP0 pid=366931) 	{
(EngineCore_DP0 pid=366931) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=366931) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=366931) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=366931) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=366931) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=366931) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=366931) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=366931) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=366931) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=366931) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=366931) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=366931) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=366931) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=366931) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=366931) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=366931) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=366931) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=366931) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=366931) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=366931) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=366931) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=366931) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=366931) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=366931) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=366931) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=366931) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=366931) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=366931) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=366931) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=366931) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=366931) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=366931) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=366931) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=366931) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=366931) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=366931) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=366931) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=366931) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=366931) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=366931) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=366931) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=366931) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=366931) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=366931) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=366931) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=366931) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=366931) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=366931) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=366931) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=366931) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=366931) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=366931) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=366931) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=366931) 	}
(EngineCore_DP0 pid=366931) 	.section	.debug_info
(EngineCore_DP0 pid=366931) 	{
(EngineCore_DP0 pid=366931) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=366931) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=366931) .b8 0
(EngineCore_DP0 pid=366931) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=366931) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=366931) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=366931) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=366931) .b8 114
(EngineCore_DP0 pid=366931) .b8 105
(EngineCore_DP0 pid=366931) .b8 116
(EngineCore_DP0 pid=366931) .b8 111
(EngineCore_DP0 pid=366931) .b8 110
(EngineCore_DP0 pid=366931) .b8 0
(EngineCore_DP0 pid=366931) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=366931) .b8 0
(EngineCore_DP0 pid=366931) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=366931) .b8 117
(EngineCore_DP0 pid=366931) .b8 97
(EngineCore_DP0 pid=366931) .b8 110
(EngineCore_DP0 pid=366931) .b8 116
(EngineCore_DP0 pid=366931) .b8 95
(EngineCore_DP0 pid=366931) .b8 115
(EngineCore_DP0 pid=366931) .b8 108
(EngineCore_DP0 pid=366931) .b8 105
(EngineCore_DP0 pid=366931) .b8 100
(EngineCore_DP0 pid=366931) .b8 101
(EngineCore_DP0 pid=366931) .b8 95
(EngineCore_DP0 pid=366931) .b8 116
(EngineCore_DP0 pid=366931) .b8 117
(EngineCore_DP0 pid=366931) .b8 110
(EngineCore_DP0 pid=366931) .b8 101
(EngineCore_DP0 pid=366931) .b8 100
(EngineCore_DP0 pid=366931) .b8 95
(EngineCore_DP0 pid=366931) .b8 76
(EngineCore_DP0 pid=366931) .b8 108
(EngineCore_DP0 pid=366931) .b8 97
(EngineCore_DP0 pid=366931) .b8 109
(EngineCore_DP0 pid=366931) .b8 97
(EngineCore_DP0 pid=366931) .b8 51
(EngineCore_DP0 pid=366931) .b8 46
(EngineCore_DP0 pid=366931) .b8 50
(EngineCore_DP0 pid=366931) .b8 45
(EngineCore_DP0 pid=366931) .b8 51
(EngineCore_DP0 pid=366931) .b8 66
(EngineCore_DP0 pid=366931) .b8 46
(EngineCore_DP0 pid=366931) .b8 112
(EngineCore_DP0 pid=366931) .b8 121
(EngineCore_DP0 pid=366931) .b8 0
(EngineCore_DP0 pid=366931) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=366931) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=366931) .b8 114
(EngineCore_DP0 pid=366931) .b8 111
(EngineCore_DP0 pid=366931) .b8 111
(EngineCore_DP0 pid=366931) .b8 116
(EngineCore_DP0 pid=366931) .b8 47
(EngineCore_DP0 pid=366931) .b8 118
(EngineCore_DP0 pid=366931) .b8 108
(EngineCore_DP0 pid=366931) .b8 108
(EngineCore_DP0 pid=366931) .b8 109
(EngineCore_DP0 pid=366931) .b8 98
(EngineCore_DP0 pid=366931) .b8 101
(EngineCore_DP0 pid=366931) .b8 110
(EngineCore_DP0 pid=366931) .b8 99
(EngineCore_DP0 pid=366931) .b8 104
(EngineCore_DP0 pid=366931) .b8 47
(EngineCore_DP0 pid=366931) .b8 115
(EngineCore_DP0 pid=366931) .b8 108
(EngineCore_DP0 pid=366931) .b8 105
(EngineCore_DP0 pid=366931) .b8 100
(EngineCore_DP0 pid=366931) .b8 101
(EngineCore_DP0 pid=366931) .b8 115
(EngineCore_DP0 pid=366931) .b8 112
(EngineCore_DP0 pid=366931) .b8 97
(EngineCore_DP0 pid=366931) .b8 114
(EngineCore_DP0 pid=366931) .b8 115
(EngineCore_DP0 pid=366931) .b8 101
(EngineCore_DP0 pid=366931) .b8 47
(EngineCore_DP0 pid=366931) .b8 99
(EngineCore_DP0 pid=366931) .b8 115
(EngineCore_DP0 pid=366931) .b8 114
(EngineCore_DP0 pid=366931) .b8 99
(EngineCore_DP0 pid=366931) .b8 47
(EngineCore_DP0 pid=366931) .b8 102
(EngineCore_DP0 pid=366931) .b8 117
(EngineCore_DP0 pid=366931) .b8 115
(EngineCore_DP0 pid=366931) .b8 101
(EngineCore_DP0 pid=366931) .b8 100
(EngineCore_DP0 pid=366931) .b8 95
(EngineCore_DP0 pid=366931) .b8 113
(EngineCore_DP0 pid=366931) .b8 117
(EngineCore_DP0 pid=366931) .b8 97
(EngineCore_DP0 pid=366931) .b8 110
(EngineCore_DP0 pid=366931) .b8 116
(EngineCore_DP0 pid=366931) .b8 95
(EngineCore_DP0 pid=366931) .b8 115
(EngineCore_DP0 pid=366931) .b8 108
(EngineCore_DP0 pid=366931) .b8 105
(EngineCore_DP0 pid=366931) .b8 100
(EngineCore_DP0 pid=366931) .b8 101
(EngineCore_DP0 pid=366931) .b8 95
(EngineCore_DP0 pid=366931) .b8 116
(EngineCore_DP0 pid=366931) .b8 114
(EngineCore_DP0 pid=366931) .b8 105
(EngineCore_DP0 pid=366931) .b8 116
(EngineCore_DP0 pid=366931) .b8 111
(EngineCore_DP0 pid=366931) .b8 110
(EngineCore_DP0 pid=366931) .b8 47
(EngineCore_DP0 pid=366931) .b8 98
(EngineCore_DP0 pid=366931) .b8 117
(EngineCore_DP0 pid=366931) .b8 105
(EngineCore_DP0 pid=366931) .b8 108
(EngineCore_DP0 pid=366931) .b8 100
(EngineCore_DP0 pid=366931) .b8 47
(EngineCore_DP0 pid=366931) .b8 71
(EngineCore_DP0 pid=366931) .b8 66
(EngineCore_DP0 pid=366931) .b8 49
(EngineCore_DP0 pid=366931) .b8 48
(EngineCore_DP0 pid=366931) .b8 95
(EngineCore_DP0 pid=366931) .b8 99
(EngineCore_DP0 pid=366931) .b8 99
(EngineCore_DP0 pid=366931) .b8 49
(EngineCore_DP0 pid=366931) .b8 50
(EngineCore_DP0 pid=366931) .b8 49
(EngineCore_DP0 pid=366931) .b8 95
(EngineCore_DP0 pid=366931) .b8 112
(EngineCore_DP0 pid=366931) .b8 121
(EngineCore_DP0 pid=366931) .b8 51
(EngineCore_DP0 pid=366931) .b8 49
(EngineCore_DP0 pid=366931) .b8 50
(EngineCore_DP0 pid=366931) .b8 95
(EngineCore_DP0 pid=366931) .b8 99
(EngineCore_DP0 pid=366931) .b8 117
(EngineCore_DP0 pid=366931) .b8 49
(EngineCore_DP0 pid=366931) .b8 50
(EngineCore_DP0 pid=366931) .b8 57
(EngineCore_DP0 pid=366931) .b8 95
(EngineCore_DP0 pid=366931) .b8 97
(EngineCore_DP0 pid=366931) .b8 97
(EngineCore_DP0 pid=366931) .b8 114
(EngineCore_DP0 pid=366931) .b8 99
(EngineCore_DP0 pid=366931) .b8 104
(EngineCore_DP0 pid=366931) .b8 54
(EngineCore_DP0 pid=366931) .b8 52
(EngineCore_DP0 pid=366931) .b8 0
(EngineCore_DP0 pid=366931) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=366931) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=366931) .b8 113
(EngineCore_DP0 pid=366931) .b8 117
(EngineCore_DP0 pid=366931) .b8 97
(EngineCore_DP0 pid=366931) .b8 110
(EngineCore_DP0 pid=366931) .b8 116
(EngineCore_DP0 pid=366931) .b8 95
(EngineCore_DP0 pid=366931) .b8 115
(EngineCore_DP0 pid=366931) .b8 108
(EngineCore_DP0 pid=366931) .b8 105
(EngineCore_DP0 pid=366931) .b8 100
(EngineCore_DP0 pid=366931) .b8 101
(EngineCore_DP0 pid=366931) .b8 95
(EngineCore_DP0 pid=366931) .b8 105
(EngineCore_DP0 pid=366931) .b8 110
(EngineCore_DP0 pid=366931) .b8 116
(EngineCore_DP0 pid=366931) .b8 56
(EngineCore_DP0 pid=366931) .b8 95
(EngineCore_DP0 pid=366931) .b8 107
(EngineCore_DP0 pid=366931) .b8 101
(EngineCore_DP0 pid=366931) .b8 114
(EngineCore_DP0 pid=366931) .b8 110
(EngineCore_DP0 pid=366931) .b8 101
(EngineCore_DP0 pid=366931) .b8 108
(EngineCore_DP0 pid=366931) .b8 0
(EngineCore_DP0 pid=366931) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=366931) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=366931) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=366931) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=366931) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=366931) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=366931) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=366931) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=366931) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=366931) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=366931) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=366931) .b8 1
(EngineCore_DP0 pid=366931) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=366931) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=366931) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=366931) 	}
(EngineCore_DP0 pid=366931) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=366931) 
(EngineCore_DP0 pid=366931) ================================================================
(EngineCore_DP0 pid=366931) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=366931) 
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpo8x0u9hc.ptx', '-o', '/tmp/tmpo8x0u9hc.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866] 
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866] 
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866] 
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpo8x0u9hc.ptx -o /tmp/tmpo8x0u9hc.ptx.o
(EngineCore_DP0 pid=366931) ERROR 01-25 19:42:02 [core.py:866] 

STDERR:
[2026-01-25 19:41:31] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:41:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:41:31] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:41:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:41:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:41:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:41:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:41:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:41:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:41:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:41:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:41:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:41:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:41:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:41:34] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:41:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:41:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:41:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:41:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:41:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:41:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:41:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:41:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:41:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:41:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:41:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:41:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:41:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=366931) [2026-01-25 19:41:35] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=366931) [2026-01-25 19:41:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=366931) [2026-01-25 19:41:35] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=366931) [2026-01-25 19:41:35] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=366931) [2026-01-25 19:41:35] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=366931) [2026-01-25 19:41:35] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=366931) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=366931) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.02s/it]
(EngineCore_DP0 pid=366931) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.02s/it]
(EngineCore_DP0 pid=366931) 
(EngineCore_DP0 pid=366931) [2026-01-25 19:42:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=366931) [2026-01-25 19:42:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=366931) [2026-01-25 19:42:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=366931) [2026-01-25 19:42:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9437184 bytes
(EngineCore_DP0 pid=366931) [2026-01-25 19:42:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=366931) [2026-01-25 19:42:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50331648 bytes
(EngineCore_DP0 pid=366931) [2026-01-25 19:42:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=366931) [2026-01-25 19:42:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25264128 bytes
(EngineCore_DP0 pid=366931) Process EngineCore_DP0:
(EngineCore_DP0 pid=366931) Traceback (most recent call last):
(EngineCore_DP0 pid=366931)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=366931)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=366931)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=366931)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=366931) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpo8x0u9hc.ptx', '-o', '/tmp/tmpo8x0u9hc.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=366931) 
(EngineCore_DP0 pid=366931) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=366931) 
(EngineCore_DP0 pid=366931) Traceback (most recent call last):
(EngineCore_DP0 pid=366931)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=366931)     self.run()
(EngineCore_DP0 pid=366931)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=366931)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=366931)     raise e
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=366931)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=366931)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=366931)     super().__init__(
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=366931)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=366931)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=366931)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=366931)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=366931)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=366931)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=366931)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=366931)     return func(*args, **kwargs)
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=366931)     return func(*args, **kwargs)
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=366931)     self.model_runner.profile_run()
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=366931)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=366931)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=366931)     return func(*args, **kwargs)
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=366931)     outputs = self.model(
(EngineCore_DP0 pid=366931)               ^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=366931)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=366931)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=366931)     model_output = self.model(
(EngineCore_DP0 pid=366931)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=366931)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=366931)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=366931)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=366931)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=366931)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=366931)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=366931)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=366931)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=366931)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=366931)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=366931)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=366931)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=366931)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=366931)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=366931)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=366931)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=366931)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=366931)     return self._linear_fn(
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=366931)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=366931)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=366931)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=366931)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=366931)     return fn(input, L)
(EngineCore_DP0 pid=366931)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=366931)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=366931)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=366931)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=366931)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=366931)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=366931)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=366931)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=366931)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=366931)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=366931)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=366931)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=366931)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=366931)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=366931)     raise PTXASError(error)
(EngineCore_DP0 pid=366931) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=366931) `ptxas` stderr:
(EngineCore_DP0 pid=366931) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=366931) 
(EngineCore_DP0 pid=366931) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpo8x0u9hc.ptx -o /tmp/tmpo8x0u9hc.ptx.o
(EngineCore_DP0 pid=366931) 
[rank0]:[W125 19:42:03.343021918 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 19:42:04
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:42:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:42:30 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=367925) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=367925) 
(EngineCore_DP0 pid=367925) 
(EngineCore_DP0 pid=367925) ================================================================
(EngineCore_DP0 pid=367925) Internal Triton PTX codegen error
(EngineCore_DP0 pid=367925) `ptxas` stderr:
(EngineCore_DP0 pid=367925) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=367925) 
(EngineCore_DP0 pid=367925) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp8c3a1q9f.ptx -o /tmp/tmp8c3a1q9f.ptx.o
(EngineCore_DP0 pid=367925) 
(EngineCore_DP0 pid=367925) 
(EngineCore_DP0 pid=367925) //
(EngineCore_DP0 pid=367925) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=367925) //
(EngineCore_DP0 pid=367925) 
(EngineCore_DP0 pid=367925) .version 8.7
(EngineCore_DP0 pid=367925) .target sm_121a
(EngineCore_DP0 pid=367925) .address_size 64
(EngineCore_DP0 pid=367925) 
(EngineCore_DP0 pid=367925) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=367925) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=367925)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=367925) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=367925) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=367925) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=367925) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=367925) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=367925) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=367925) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=367925) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=367925) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=367925) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=367925) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=367925) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=367925) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=367925) )
(EngineCore_DP0 pid=367925) .reqntid 512
(EngineCore_DP0 pid=367925) {
(EngineCore_DP0 pid=367925) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=367925) 	.reg .b16 	%rs<40>;
(EngineCore_DP0 pid=367925) 	.reg .b32 	%r<160>;
(EngineCore_DP0 pid=367925) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=367925) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=367925) $L__func_begin0:
(EngineCore_DP0 pid=367925) 	.loc	1 292 0                         // quant_slide_tuned_Llama3.2-3B.py:292:0
(EngineCore_DP0 pid=367925) 
(EngineCore_DP0 pid=367925) // %bb.0:
(EngineCore_DP0 pid=367925) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=367925) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=367925) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=367925) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=367925) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=367925) $L__tmp0:
(EngineCore_DP0 pid=367925) 	.loc	1 302 24                        // quant_slide_tuned_Llama3.2-3B.py:302:24
(EngineCore_DP0 pid=367925) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=367925) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=367925) 	.loc	1 307 26                        // quant_slide_tuned_Llama3.2-3B.py:307:26
(EngineCore_DP0 pid=367925) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=367925) 	.loc	1 307 20                        // quant_slide_tuned_Llama3.2-3B.py:307:20
(EngineCore_DP0 pid=367925) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=367925) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=367925) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=367925) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=367925) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=367925) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=367925) 	mov.b32 	%r158, 0f2B8CBCCC;
(EngineCore_DP0 pid=367925) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=367925) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=367925) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=367925) 	.loc	1 313 32                        // quant_slide_tuned_Llama3.2-3B.py:313:32
(EngineCore_DP0 pid=367925) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=367925) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=367925) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=367925) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=367925) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=367925) 	add.s32 	%r45, %r35, %r34;
(EngineCore_DP0 pid=367925) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=367925) 	add.s32 	%r48, %r35, %r36;
(EngineCore_DP0 pid=367925) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=367925) 	mov.b32 	%r156, 0f00000000;
(EngineCore_DP0 pid=367925) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=367925) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=367925) 	mov.b32 	%r157, %r41;
(EngineCore_DP0 pid=367925) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=367925) 	.loc	1 314 22                        // quant_slide_tuned_Llama3.2-3B.py:314:22
(EngineCore_DP0 pid=367925) 	add.s32 	%r51, %r4, %r157;
(EngineCore_DP0 pid=367925) 	setp.lt.s32 	%p2, %r51, %r19;
(EngineCore_DP0 pid=367925) 	.loc	1 315 29                        // quant_slide_tuned_Llama3.2-3B.py:315:29
(EngineCore_DP0 pid=367925) 	mad.wide.s32 	%rd6, %r51, 2, %rd1;
(EngineCore_DP0 pid=367925) 	.loc	1 315 21                        // quant_slide_tuned_Llama3.2-3B.py:315:21
(EngineCore_DP0 pid=367925) 	// begin inline asm
(EngineCore_DP0 pid=367925) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=367925) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=367925) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=367925) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=367925) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=367925) 	// end inline asm
(EngineCore_DP0 pid=367925) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=367925) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=367925) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=367925) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=367925) 	.loc	1 316 50                        // quant_slide_tuned_Llama3.2-3B.py:316:50
(EngineCore_DP0 pid=367925) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=367925) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=367925) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=367925) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=367925) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=367925) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=367925) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=367925) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=367925) $L__tmp1:
(EngineCore_DP0 pid=367925) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	bar.sync 	0;
(EngineCore_DP0 pid=367925) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=367925) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=367925) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=367925) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=367925) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=367925) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=367925) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=367925) 	cvt.f32.bf16 	%r52, %rs23;
(EngineCore_DP0 pid=367925) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	shfl.sync.bfly.b32 	%r53, %r52, 16, 31, -1;
(EngineCore_DP0 pid=367925) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=367925) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	shfl.sync.bfly.b32 	%r55, %r54, 8, 31, -1;
(EngineCore_DP0 pid=367925) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=367925) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	shfl.sync.bfly.b32 	%r57, %r56, 4, 31, -1;
(EngineCore_DP0 pid=367925) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=367925) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	shfl.sync.bfly.b32 	%r59, %r58, 2, 31, -1;
(EngineCore_DP0 pid=367925) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=367925) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	shfl.sync.bfly.b32 	%r61, %r60, 1, 31, -1;
(EngineCore_DP0 pid=367925) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	max.f32 	%r46, %r60, %r61;
(EngineCore_DP0 pid=367925) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	// begin inline asm
(EngineCore_DP0 pid=367925) 	@%p3 st.shared.b32 [ %r45 + 0 ], %r46;
(EngineCore_DP0 pid=367925) 	// end inline asm
(EngineCore_DP0 pid=367925) 	bar.sync 	0;
(EngineCore_DP0 pid=367925) 	// begin inline asm
(EngineCore_DP0 pid=367925) 	@%p4 ld.shared.b32 %r47, [ %r48 + 0 ];
(EngineCore_DP0 pid=367925) 	// end inline asm
(EngineCore_DP0 pid=367925) 	shfl.sync.bfly.b32 	%r62, %r47, 8, 31, -1;
(EngineCore_DP0 pid=367925) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	max.f32 	%r63, %r47, %r62;
(EngineCore_DP0 pid=367925) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	shfl.sync.bfly.b32 	%r64, %r63, 4, 31, -1;
(EngineCore_DP0 pid=367925) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=367925) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	shfl.sync.bfly.b32 	%r66, %r65, 2, 31, -1;
(EngineCore_DP0 pid=367925) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=367925) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	shfl.sync.bfly.b32 	%r68, %r67, 1, 31, -1;
(EngineCore_DP0 pid=367925) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	max.f32 	%r50, %r67, %r68;
(EngineCore_DP0 pid=367925) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:316:43 ]
(EngineCore_DP0 pid=367925) 	// begin inline asm
(EngineCore_DP0 pid=367925) 	@%p27 st.shared.b32 [ %r48 + 0 ], %r50;
(EngineCore_DP0 pid=367925) 	// end inline asm
(EngineCore_DP0 pid=367925) 	bar.sync 	0;
(EngineCore_DP0 pid=367925) 	ld.shared.b32 	%r69, [global_smem];
(EngineCore_DP0 pid=367925) $L__tmp2:
(EngineCore_DP0 pid=367925) 	.loc	1 316 36                        // quant_slide_tuned_Llama3.2-3B.py:316:36
(EngineCore_DP0 pid=367925) 	max.f32 	%r156, %r156, %r69;
(EngineCore_DP0 pid=367925) 	.loc	1 312 35                        // quant_slide_tuned_Llama3.2-3B.py:312:35
(EngineCore_DP0 pid=367925) 	add.s32 	%r157, %r157, 4096;
(EngineCore_DP0 pid=367925) 	setp.lt.s32 	%p6, %r157, %r20;
(EngineCore_DP0 pid=367925) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=367925) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=367925) 	.loc	1 318 32                        // quant_slide_tuned_Llama3.2-3B.py:318:32
(EngineCore_DP0 pid=367925) 	max.f32 	%r158, %r156, 0f2B8CBCCC;
(EngineCore_DP0 pid=367925) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=367925) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=367925) 	mov.b32 	%r71, 0f42FE0000;
(EngineCore_DP0 pid=367925) 	.loc	1 319 32                        // quant_slide_tuned_Llama3.2-3B.py:319:32
(EngineCore_DP0 pid=367925) 	div.full.f32 	%r72, %r158, %r71;
(EngineCore_DP0 pid=367925) 	.loc	1 319 42                        // quant_slide_tuned_Llama3.2-3B.py:319:42
(EngineCore_DP0 pid=367925) 	max.f32 	%r70, %r72, 0f37810204;
(EngineCore_DP0 pid=367925) 	.loc	1 321 25                        // quant_slide_tuned_Llama3.2-3B.py:321:25
(EngineCore_DP0 pid=367925) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=367925) 	.loc	1 321 30                        // quant_slide_tuned_Llama3.2-3B.py:321:30
(EngineCore_DP0 pid=367925) 	// begin inline asm
(EngineCore_DP0 pid=367925) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r70 };
(EngineCore_DP0 pid=367925) 	// end inline asm
(EngineCore_DP0 pid=367925) 	.loc	1 324 29                        // quant_slide_tuned_Llama3.2-3B.py:324:29
(EngineCore_DP0 pid=367925) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=367925) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=367925) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=367925) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=367925) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=367925) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=367925) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=367925) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=367925) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=367925) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=367925) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=367925) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=367925) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=367925) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=367925) 	div.full.f32 	%r14, %r71, %r158;
(EngineCore_DP0 pid=367925) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=367925) 	mov.b32 	%r159, 0;
(EngineCore_DP0 pid=367925) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=367925)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=367925) 	.loc	1 327 31                        // quant_slide_tuned_Llama3.2-3B.py:327:31
(EngineCore_DP0 pid=367925) 	add.s32 	%r76, %r16, %r159;
(EngineCore_DP0 pid=367925) 	.loc	1 328 30                        // quant_slide_tuned_Llama3.2-3B.py:328:30
(EngineCore_DP0 pid=367925) 	add.s32 	%r77, %r159, 1;
(EngineCore_DP0 pid=367925) 	setp.lt.s32 	%p17, %r76, %r15;
(EngineCore_DP0 pid=367925) 	.loc	1 331 24                        // quant_slide_tuned_Llama3.2-3B.py:331:24
(EngineCore_DP0 pid=367925) 	shr.u32 	%r78, %r76, 1;
(EngineCore_DP0 pid=367925) 	.loc	1 332 23                        // quant_slide_tuned_Llama3.2-3B.py:332:23
(EngineCore_DP0 pid=367925) 	shr.u32 	%r79, %r77, 31;
(EngineCore_DP0 pid=367925) 	add.s32 	%r80, %r77, %r79;
(EngineCore_DP0 pid=367925) 	and.b32 	%r81, %r80, 2147483646;
(EngineCore_DP0 pid=367925) 	sub.s32 	%r82, %r77, %r81;
(EngineCore_DP0 pid=367925) 	.loc	1 333 22                        // quant_slide_tuned_Llama3.2-3B.py:333:22
(EngineCore_DP0 pid=367925) 	mul.lo.s32 	%r83, %r78, 6;
(EngineCore_DP0 pid=367925) 	.loc	1 333 30                        // quant_slide_tuned_Llama3.2-3B.py:333:30
(EngineCore_DP0 pid=367925) 	shl.b32 	%r84, %r82, 1;
(EngineCore_DP0 pid=367925) 	.loc	1 333 26                        // quant_slide_tuned_Llama3.2-3B.py:333:26
(EngineCore_DP0 pid=367925) 	add.s32 	%r85, %r83, %r84;
(EngineCore_DP0 pid=367925) 	.loc	1 336 53                        // quant_slide_tuned_Llama3.2-3B.py:336:53
(EngineCore_DP0 pid=367925) 	setp.lt.s32 	%p18, %r83, %r19;
(EngineCore_DP0 pid=367925) 	setp.lt.s32 	%p19, %r85, %r19;
(EngineCore_DP0 pid=367925) 	.loc	1 336 37                        // quant_slide_tuned_Llama3.2-3B.py:336:37
(EngineCore_DP0 pid=367925) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=367925) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=367925) 	.loc	1 335 29                        // quant_slide_tuned_Llama3.2-3B.py:335:29
(EngineCore_DP0 pid=367925) 	mad.wide.s32 	%rd8, %r83, 2, %rd1;
(EngineCore_DP0 pid=367925) 	mad.wide.s32 	%rd9, %r85, 2, %rd1;
(EngineCore_DP0 pid=367925) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=367925) 	.loc	1 335 21                        // quant_slide_tuned_Llama3.2-3B.py:335:21
(EngineCore_DP0 pid=367925) 	// begin inline asm
(EngineCore_DP0 pid=367925) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=367925) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=367925) 	// end inline asm
(EngineCore_DP0 pid=367925) 	// begin inline asm
(EngineCore_DP0 pid=367925) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=367925) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=367925) 	// end inline asm
(EngineCore_DP0 pid=367925) 	.loc	1 336 79                        // quant_slide_tuned_Llama3.2-3B.py:336:79
(EngineCore_DP0 pid=367925) 	cvt.f32.bf16 	%r86, %rs24;
(EngineCore_DP0 pid=367925) 	cvt.f32.bf16 	%r87, %rs26;
(EngineCore_DP0 pid=367925) 	.loc	1 338 48                        // quant_slide_tuned_Llama3.2-3B.py:338:48
(EngineCore_DP0 pid=367925) 	or.b32 	%r88, %r83, 1;
(EngineCore_DP0 pid=367925) 	or.b32 	%r89, %r85, 1;
(EngineCore_DP0 pid=367925) 	.loc	1 338 53                        // quant_slide_tuned_Llama3.2-3B.py:338:53
(EngineCore_DP0 pid=367925) 	setp.lt.s32 	%p20, %r88, %r19;
(EngineCore_DP0 pid=367925) 	setp.lt.s32 	%p21, %r89, %r19;
(EngineCore_DP0 pid=367925) 	.loc	1 338 37                        // quant_slide_tuned_Llama3.2-3B.py:338:37
(EngineCore_DP0 pid=367925) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=367925) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=367925) 	.loc	1 337 39                        // quant_slide_tuned_Llama3.2-3B.py:337:39
(EngineCore_DP0 pid=367925) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=367925) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=367925) 	.loc	1 337 21                        // quant_slide_tuned_Llama3.2-3B.py:337:21
(EngineCore_DP0 pid=367925) 	// begin inline asm
(EngineCore_DP0 pid=367925) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=367925) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=367925) 	// end inline asm
(EngineCore_DP0 pid=367925) 	// begin inline asm
(EngineCore_DP0 pid=367925) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=367925) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=367925) 	// end inline asm
(EngineCore_DP0 pid=367925) 	.loc	1 338 79                        // quant_slide_tuned_Llama3.2-3B.py:338:79
(EngineCore_DP0 pid=367925) 	cvt.f32.bf16 	%r90, %rs28;
(EngineCore_DP0 pid=367925) 	cvt.f32.bf16 	%r91, %rs30;
(EngineCore_DP0 pid=367925) 	.loc	1 340 48                        // quant_slide_tuned_Llama3.2-3B.py:340:48
(EngineCore_DP0 pid=367925) 	add.s32 	%r92, %r83, 2;
(EngineCore_DP0 pid=367925) 	add.s32 	%r93, %r85, 2;
(EngineCore_DP0 pid=367925) 	.loc	1 340 53                        // quant_slide_tuned_Llama3.2-3B.py:340:53
(EngineCore_DP0 pid=367925) 	setp.lt.s32 	%p22, %r92, %r19;
(EngineCore_DP0 pid=367925) 	setp.lt.s32 	%p23, %r93, %r19;
(EngineCore_DP0 pid=367925) 	.loc	1 340 37                        // quant_slide_tuned_Llama3.2-3B.py:340:37
(EngineCore_DP0 pid=367925) 	and.pred 	%p13, %p17, %p22;
(EngineCore_DP0 pid=367925) 	and.pred 	%p14, %p17, %p23;
(EngineCore_DP0 pid=367925) 	.loc	1 339 39                        // quant_slide_tuned_Llama3.2-3B.py:339:39
(EngineCore_DP0 pid=367925) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=367925) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=367925) 	.loc	1 339 21                        // quant_slide_tuned_Llama3.2-3B.py:339:21
(EngineCore_DP0 pid=367925) 	// begin inline asm
(EngineCore_DP0 pid=367925) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=367925) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=367925) 	// end inline asm
(EngineCore_DP0 pid=367925) 	// begin inline asm
(EngineCore_DP0 pid=367925) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=367925) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=367925) 	// end inline asm
(EngineCore_DP0 pid=367925) 	.loc	1 340 79                        // quant_slide_tuned_Llama3.2-3B.py:340:79
(EngineCore_DP0 pid=367925) 	cvt.f32.bf16 	%r94, %rs32;
(EngineCore_DP0 pid=367925) 	cvt.f32.bf16 	%r95, %rs34;
(EngineCore_DP0 pid=367925) 	.loc	1 342 48                        // quant_slide_tuned_Llama3.2-3B.py:342:48
(EngineCore_DP0 pid=367925) 	add.s32 	%r96, %r83, 3;
(EngineCore_DP0 pid=367925) 	add.s32 	%r97, %r85, 3;
(EngineCore_DP0 pid=367925) 	.loc	1 342 53                        // quant_slide_tuned_Llama3.2-3B.py:342:53
(EngineCore_DP0 pid=367925) 	setp.lt.s32 	%p24, %r96, %r19;
(EngineCore_DP0 pid=367925) 	setp.lt.s32 	%p25, %r97, %r19;
(EngineCore_DP0 pid=367925) 	.loc	1 342 37                        // quant_slide_tuned_Llama3.2-3B.py:342:37
(EngineCore_DP0 pid=367925) 	and.pred 	%p15, %p17, %p24;
(EngineCore_DP0 pid=367925) 	and.pred 	%p16, %p17, %p25;
(EngineCore_DP0 pid=367925) 	.loc	1 341 39                        // quant_slide_tuned_Llama3.2-3B.py:341:39
(EngineCore_DP0 pid=367925) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=367925) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=367925) 	.loc	1 341 21                        // quant_slide_tuned_Llama3.2-3B.py:341:21
(EngineCore_DP0 pid=367925) 	// begin inline asm
(EngineCore_DP0 pid=367925) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=367925) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=367925) 	// end inline asm
(EngineCore_DP0 pid=367925) 	// begin inline asm
(EngineCore_DP0 pid=367925) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=367925) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=367925) 	// end inline asm
(EngineCore_DP0 pid=367925) 	.loc	1 342 79                        // quant_slide_tuned_Llama3.2-3B.py:342:79
(EngineCore_DP0 pid=367925) 	cvt.f32.bf16 	%r98, %rs36;
(EngineCore_DP0 pid=367925) 	cvt.f32.bf16 	%r99, %rs38;
(EngineCore_DP0 pid=367925) 	.loc	1 344 56                        // quant_slide_tuned_Llama3.2-3B.py:344:56
(EngineCore_DP0 pid=367925) 	mul.f32 	%r100, %r14, %r86;
(EngineCore_DP0 pid=367925) 	mul.f32 	%r101, %r14, %r87;
(EngineCore_DP0 pid=367925) 	.loc	1 344 51                        // quant_slide_tuned_Llama3.2-3B.py:344:51
(EngineCore_DP0 pid=367925) 	cvt.rni.f32.f32 	%r102, %r100;
(EngineCore_DP0 pid=367925) 	cvt.rni.f32.f32 	%r103, %r101;
(EngineCore_DP0 pid=367925) 	.loc	1 344 76                        // quant_slide_tuned_Llama3.2-3B.py:344:76
(EngineCore_DP0 pid=367925) 	max.f32 	%r104, %r102, 0fC3000000;
(EngineCore_DP0 pid=367925) 	min.f32 	%r105, %r104, 0f42FE0000;
(EngineCore_DP0 pid=367925) 	max.f32 	%r106, %r103, 0fC3000000;
(EngineCore_DP0 pid=367925) 	min.f32 	%r107, %r106, 0f42FE0000;
(EngineCore_DP0 pid=367925) 	.loc	1 344 86                        // quant_slide_tuned_Llama3.2-3B.py:344:86
(EngineCore_DP0 pid=367925) 	cvt.rzi.s32.f32 	%r108, %r105;
(EngineCore_DP0 pid=367925) 	cvt.rzi.s32.f32 	%r109, %r107;
(EngineCore_DP0 pid=367925) 	.loc	1 344 98                        // quant_slide_tuned_Llama3.2-3B.py:344:98
(EngineCore_DP0 pid=367925) 	and.b32 	%r110, %r108, 255;
(EngineCore_DP0 pid=367925) 	and.b32 	%r111, %r109, 255;
(EngineCore_DP0 pid=367925) 	.loc	1 345 56                        // quant_slide_tuned_Llama3.2-3B.py:345:56
(EngineCore_DP0 pid=367925) 	mul.f32 	%r112, %r14, %r90;
(EngineCore_DP0 pid=367925) 	mul.f32 	%r113, %r14, %r91;
(EngineCore_DP0 pid=367925) 	.loc	1 345 51                        // quant_slide_tuned_Llama3.2-3B.py:345:51
(EngineCore_DP0 pid=367925) 	cvt.rni.f32.f32 	%r114, %r112;
(EngineCore_DP0 pid=367925) 	cvt.rni.f32.f32 	%r115, %r113;
(EngineCore_DP0 pid=367925) 	.loc	1 346 56                        // quant_slide_tuned_Llama3.2-3B.py:346:56
(EngineCore_DP0 pid=367925) 	mul.f32 	%r116, %r14, %r94;
(EngineCore_DP0 pid=367925) 	mul.f32 	%r117, %r14, %r95;
(EngineCore_DP0 pid=367925) 	.loc	1 346 51                        // quant_slide_tuned_Llama3.2-3B.py:346:51
(EngineCore_DP0 pid=367925) 	cvt.rni.f32.f32 	%r118, %r116;
(EngineCore_DP0 pid=367925) 	cvt.rni.f32.f32 	%r119, %r117;
(EngineCore_DP0 pid=367925) 	.loc	1 347 56                        // quant_slide_tuned_Llama3.2-3B.py:347:56
(EngineCore_DP0 pid=367925) 	mul.f32 	%r120, %r14, %r98;
(EngineCore_DP0 pid=367925) 	mul.f32 	%r121, %r14, %r99;
(EngineCore_DP0 pid=367925) 	.loc	1 347 51                        // quant_slide_tuned_Llama3.2-3B.py:347:51
(EngineCore_DP0 pid=367925) 	cvt.rni.f32.f32 	%r122, %r120;
(EngineCore_DP0 pid=367925) 	cvt.rni.f32.f32 	%r123, %r121;
(EngineCore_DP0 pid=367925) 	.loc	1 347 76                        // quant_slide_tuned_Llama3.2-3B.py:347:76
(EngineCore_DP0 pid=367925) 	max.f32 	%r124, %r122, 0fC3000000;
(EngineCore_DP0 pid=367925) 	min.f32 	%r125, %r124, 0f42FE0000;
(EngineCore_DP0 pid=367925) 	max.f32 	%r126, %r123, 0fC3000000;
(EngineCore_DP0 pid=367925) 	min.f32 	%r127, %r126, 0f42FE0000;
(EngineCore_DP0 pid=367925) 	.loc	1 347 86                        // quant_slide_tuned_Llama3.2-3B.py:347:86
(EngineCore_DP0 pid=367925) 	cvt.rzi.s32.f32 	%r128, %r125;
(EngineCore_DP0 pid=367925) 	cvt.rzi.s32.f32 	%r129, %r127;
(EngineCore_DP0 pid=367925) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=367925) 	max.f32 	%r130, %r118, 0fC3000000;
(EngineCore_DP0 pid=367925) 	max.f32 	%r131, %r114, 0fC3000000;
(EngineCore_DP0 pid=367925) 	min.f32 	%r132, %r131, 0f42FE0000;
(EngineCore_DP0 pid=367925) 	min.f32 	%r133, %r130, 0f42FE0000;
(EngineCore_DP0 pid=367925) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=367925) 	cvt.rzi.s32.f32 	%r134, %r133;
(EngineCore_DP0 pid=367925) 	cvt.rzi.s32.f32 	%r135, %r132;
(EngineCore_DP0 pid=367925) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=367925) 	shl.b32 	%r136, %r135, 8;
(EngineCore_DP0 pid=367925) 	shl.b32 	%r137, %r134, 16;
(EngineCore_DP0 pid=367925) 	and.b32 	%r138, %r137, 16711680;
(EngineCore_DP0 pid=367925) 	and.b32 	%r139, %r136, 65280;
(EngineCore_DP0 pid=367925) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=367925) 	or.b32 	%r140, %r139, %r110;
(EngineCore_DP0 pid=367925) 	.loc	1 345 76                        // quant_slide_tuned_Llama3.2-3B.py:345:76
(EngineCore_DP0 pid=367925) 	max.f32 	%r141, %r119, 0fC3000000;
(EngineCore_DP0 pid=367925) 	max.f32 	%r142, %r115, 0fC3000000;
(EngineCore_DP0 pid=367925) 	min.f32 	%r143, %r142, 0f42FE0000;
(EngineCore_DP0 pid=367925) 	min.f32 	%r144, %r141, 0f42FE0000;
(EngineCore_DP0 pid=367925) 	.loc	1 345 86                        // quant_slide_tuned_Llama3.2-3B.py:345:86
(EngineCore_DP0 pid=367925) 	cvt.rzi.s32.f32 	%r145, %r144;
(EngineCore_DP0 pid=367925) 	cvt.rzi.s32.f32 	%r146, %r143;
(EngineCore_DP0 pid=367925) 	.loc	1 349 30                        // quant_slide_tuned_Llama3.2-3B.py:349:30
(EngineCore_DP0 pid=367925) 	shl.b32 	%r147, %r146, 8;
(EngineCore_DP0 pid=367925) 	shl.b32 	%r148, %r145, 16;
(EngineCore_DP0 pid=367925) 	and.b32 	%r149, %r148, 16711680;
(EngineCore_DP0 pid=367925) 	and.b32 	%r150, %r147, 65280;
(EngineCore_DP0 pid=367925) 	.loc	1 349 24                        // quant_slide_tuned_Llama3.2-3B.py:349:24
(EngineCore_DP0 pid=367925) 	or.b32 	%r151, %r150, %r111;
(EngineCore_DP0 pid=367925) 	.loc	1 349 36                        // quant_slide_tuned_Llama3.2-3B.py:349:36
(EngineCore_DP0 pid=367925) 	or.b32 	%r152, %r140, %r138;
(EngineCore_DP0 pid=367925) 	or.b32 	%r153, %r151, %r149;
(EngineCore_DP0 pid=367925) 	.loc	1 349 55                        // quant_slide_tuned_Llama3.2-3B.py:349:55
(EngineCore_DP0 pid=367925) 	shl.b32 	%r154, %r128, 24;
(EngineCore_DP0 pid=367925) 	shl.b32 	%r155, %r129, 24;
(EngineCore_DP0 pid=367925) 	.loc	1 349 49                        // quant_slide_tuned_Llama3.2-3B.py:349:49
(EngineCore_DP0 pid=367925) 	or.b32 	%r74, %r152, %r154;
(EngineCore_DP0 pid=367925) 	or.b32 	%r75, %r153, %r155;
(EngineCore_DP0 pid=367925) 	.loc	1 350 29                        // quant_slide_tuned_Llama3.2-3B.py:350:29
(EngineCore_DP0 pid=367925) 	mad.wide.s32 	%rd16, %r76, 4, %rd2;
(EngineCore_DP0 pid=367925) 	.loc	1 350 39                        // quant_slide_tuned_Llama3.2-3B.py:350:39
(EngineCore_DP0 pid=367925) 	// begin inline asm
(EngineCore_DP0 pid=367925) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r74, %r75 };
(EngineCore_DP0 pid=367925) 	// end inline asm
(EngineCore_DP0 pid=367925) 	.loc	1 326 41                        // quant_slide_tuned_Llama3.2-3B.py:326:41
(EngineCore_DP0 pid=367925) 	add.s32 	%r159, %r159, 1024;
(EngineCore_DP0 pid=367925) 	setp.lt.s32 	%p26, %r159, %r15;
(EngineCore_DP0 pid=367925) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=367925) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=367925) 	.loc	1 326 4                         // quant_slide_tuned_Llama3.2-3B.py:326:4
(EngineCore_DP0 pid=367925) 	ret;
(EngineCore_DP0 pid=367925) $L__tmp3:
(EngineCore_DP0 pid=367925) $L__func_end0:
(EngineCore_DP0 pid=367925)                                         // -- End function
(EngineCore_DP0 pid=367925) }
(EngineCore_DP0 pid=367925) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=367925) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=367925) 	.section	.debug_abbrev
(EngineCore_DP0 pid=367925) 	{
(EngineCore_DP0 pid=367925) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=367925) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=367925) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=367925) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=367925) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=367925) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=367925) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=367925) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=367925) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=367925) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=367925) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=367925) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=367925) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=367925) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=367925) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=367925) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=367925) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=367925) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=367925) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=367925) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=367925) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=367925) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=367925) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=367925) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=367925) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=367925) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=367925) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=367925) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=367925) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=367925) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=367925) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=367925) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=367925) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=367925) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=367925) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=367925) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=367925) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=367925) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=367925) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=367925) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=367925) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=367925) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=367925) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=367925) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=367925) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=367925) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=367925) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=367925) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=367925) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=367925) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=367925) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=367925) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=367925) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=367925) 	}
(EngineCore_DP0 pid=367925) 	.section	.debug_info
(EngineCore_DP0 pid=367925) 	{
(EngineCore_DP0 pid=367925) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=367925) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=367925) .b8 0
(EngineCore_DP0 pid=367925) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=367925) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=367925) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=367925) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=367925) .b8 114
(EngineCore_DP0 pid=367925) .b8 105
(EngineCore_DP0 pid=367925) .b8 116
(EngineCore_DP0 pid=367925) .b8 111
(EngineCore_DP0 pid=367925) .b8 110
(EngineCore_DP0 pid=367925) .b8 0
(EngineCore_DP0 pid=367925) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=367925) .b8 0
(EngineCore_DP0 pid=367925) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=367925) .b8 117
(EngineCore_DP0 pid=367925) .b8 97
(EngineCore_DP0 pid=367925) .b8 110
(EngineCore_DP0 pid=367925) .b8 116
(EngineCore_DP0 pid=367925) .b8 95
(EngineCore_DP0 pid=367925) .b8 115
(EngineCore_DP0 pid=367925) .b8 108
(EngineCore_DP0 pid=367925) .b8 105
(EngineCore_DP0 pid=367925) .b8 100
(EngineCore_DP0 pid=367925) .b8 101
(EngineCore_DP0 pid=367925) .b8 95
(EngineCore_DP0 pid=367925) .b8 116
(EngineCore_DP0 pid=367925) .b8 117
(EngineCore_DP0 pid=367925) .b8 110
(EngineCore_DP0 pid=367925) .b8 101
(EngineCore_DP0 pid=367925) .b8 100
(EngineCore_DP0 pid=367925) .b8 95
(EngineCore_DP0 pid=367925) .b8 76
(EngineCore_DP0 pid=367925) .b8 108
(EngineCore_DP0 pid=367925) .b8 97
(EngineCore_DP0 pid=367925) .b8 109
(EngineCore_DP0 pid=367925) .b8 97
(EngineCore_DP0 pid=367925) .b8 51
(EngineCore_DP0 pid=367925) .b8 46
(EngineCore_DP0 pid=367925) .b8 50
(EngineCore_DP0 pid=367925) .b8 45
(EngineCore_DP0 pid=367925) .b8 51
(EngineCore_DP0 pid=367925) .b8 66
(EngineCore_DP0 pid=367925) .b8 46
(EngineCore_DP0 pid=367925) .b8 112
(EngineCore_DP0 pid=367925) .b8 121
(EngineCore_DP0 pid=367925) .b8 0
(EngineCore_DP0 pid=367925) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=367925) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=367925) .b8 114
(EngineCore_DP0 pid=367925) .b8 111
(EngineCore_DP0 pid=367925) .b8 111
(EngineCore_DP0 pid=367925) .b8 116
(EngineCore_DP0 pid=367925) .b8 47
(EngineCore_DP0 pid=367925) .b8 118
(EngineCore_DP0 pid=367925) .b8 108
(EngineCore_DP0 pid=367925) .b8 108
(EngineCore_DP0 pid=367925) .b8 109
(EngineCore_DP0 pid=367925) .b8 98
(EngineCore_DP0 pid=367925) .b8 101
(EngineCore_DP0 pid=367925) .b8 110
(EngineCore_DP0 pid=367925) .b8 99
(EngineCore_DP0 pid=367925) .b8 104
(EngineCore_DP0 pid=367925) .b8 47
(EngineCore_DP0 pid=367925) .b8 115
(EngineCore_DP0 pid=367925) .b8 108
(EngineCore_DP0 pid=367925) .b8 105
(EngineCore_DP0 pid=367925) .b8 100
(EngineCore_DP0 pid=367925) .b8 101
(EngineCore_DP0 pid=367925) .b8 115
(EngineCore_DP0 pid=367925) .b8 112
(EngineCore_DP0 pid=367925) .b8 97
(EngineCore_DP0 pid=367925) .b8 114
(EngineCore_DP0 pid=367925) .b8 115
(EngineCore_DP0 pid=367925) .b8 101
(EngineCore_DP0 pid=367925) .b8 47
(EngineCore_DP0 pid=367925) .b8 99
(EngineCore_DP0 pid=367925) .b8 115
(EngineCore_DP0 pid=367925) .b8 114
(EngineCore_DP0 pid=367925) .b8 99
(EngineCore_DP0 pid=367925) .b8 47
(EngineCore_DP0 pid=367925) .b8 102
(EngineCore_DP0 pid=367925) .b8 117
(EngineCore_DP0 pid=367925) .b8 115
(EngineCore_DP0 pid=367925) .b8 101
(EngineCore_DP0 pid=367925) .b8 100
(EngineCore_DP0 pid=367925) .b8 95
(EngineCore_DP0 pid=367925) .b8 113
(EngineCore_DP0 pid=367925) .b8 117
(EngineCore_DP0 pid=367925) .b8 97
(EngineCore_DP0 pid=367925) .b8 110
(EngineCore_DP0 pid=367925) .b8 116
(EngineCore_DP0 pid=367925) .b8 95
(EngineCore_DP0 pid=367925) .b8 115
(EngineCore_DP0 pid=367925) .b8 108
(EngineCore_DP0 pid=367925) .b8 105
(EngineCore_DP0 pid=367925) .b8 100
(EngineCore_DP0 pid=367925) .b8 101
(EngineCore_DP0 pid=367925) .b8 95
(EngineCore_DP0 pid=367925) .b8 116
(EngineCore_DP0 pid=367925) .b8 114
(EngineCore_DP0 pid=367925) .b8 105
(EngineCore_DP0 pid=367925) .b8 116
(EngineCore_DP0 pid=367925) .b8 111
(EngineCore_DP0 pid=367925) .b8 110
(EngineCore_DP0 pid=367925) .b8 47
(EngineCore_DP0 pid=367925) .b8 98
(EngineCore_DP0 pid=367925) .b8 117
(EngineCore_DP0 pid=367925) .b8 105
(EngineCore_DP0 pid=367925) .b8 108
(EngineCore_DP0 pid=367925) .b8 100
(EngineCore_DP0 pid=367925) .b8 47
(EngineCore_DP0 pid=367925) .b8 71
(EngineCore_DP0 pid=367925) .b8 66
(EngineCore_DP0 pid=367925) .b8 49
(EngineCore_DP0 pid=367925) .b8 48
(EngineCore_DP0 pid=367925) .b8 95
(EngineCore_DP0 pid=367925) .b8 99
(EngineCore_DP0 pid=367925) .b8 99
(EngineCore_DP0 pid=367925) .b8 49
(EngineCore_DP0 pid=367925) .b8 50
(EngineCore_DP0 pid=367925) .b8 49
(EngineCore_DP0 pid=367925) .b8 95
(EngineCore_DP0 pid=367925) .b8 112
(EngineCore_DP0 pid=367925) .b8 121
(EngineCore_DP0 pid=367925) .b8 51
(EngineCore_DP0 pid=367925) .b8 49
(EngineCore_DP0 pid=367925) .b8 50
(EngineCore_DP0 pid=367925) .b8 95
(EngineCore_DP0 pid=367925) .b8 99
(EngineCore_DP0 pid=367925) .b8 117
(EngineCore_DP0 pid=367925) .b8 49
(EngineCore_DP0 pid=367925) .b8 50
(EngineCore_DP0 pid=367925) .b8 57
(EngineCore_DP0 pid=367925) .b8 95
(EngineCore_DP0 pid=367925) .b8 97
(EngineCore_DP0 pid=367925) .b8 97
(EngineCore_DP0 pid=367925) .b8 114
(EngineCore_DP0 pid=367925) .b8 99
(EngineCore_DP0 pid=367925) .b8 104
(EngineCore_DP0 pid=367925) .b8 54
(EngineCore_DP0 pid=367925) .b8 52
(EngineCore_DP0 pid=367925) .b8 0
(EngineCore_DP0 pid=367925) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=367925) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=367925) .b8 113
(EngineCore_DP0 pid=367925) .b8 117
(EngineCore_DP0 pid=367925) .b8 97
(EngineCore_DP0 pid=367925) .b8 110
(EngineCore_DP0 pid=367925) .b8 116
(EngineCore_DP0 pid=367925) .b8 95
(EngineCore_DP0 pid=367925) .b8 115
(EngineCore_DP0 pid=367925) .b8 108
(EngineCore_DP0 pid=367925) .b8 105
(EngineCore_DP0 pid=367925) .b8 100
(EngineCore_DP0 pid=367925) .b8 101
(EngineCore_DP0 pid=367925) .b8 95
(EngineCore_DP0 pid=367925) .b8 105
(EngineCore_DP0 pid=367925) .b8 110
(EngineCore_DP0 pid=367925) .b8 116
(EngineCore_DP0 pid=367925) .b8 56
(EngineCore_DP0 pid=367925) .b8 95
(EngineCore_DP0 pid=367925) .b8 107
(EngineCore_DP0 pid=367925) .b8 101
(EngineCore_DP0 pid=367925) .b8 114
(EngineCore_DP0 pid=367925) .b8 110
(EngineCore_DP0 pid=367925) .b8 101
(EngineCore_DP0 pid=367925) .b8 108
(EngineCore_DP0 pid=367925) .b8 0
(EngineCore_DP0 pid=367925) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=367925) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=367925) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=367925) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=367925) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=367925) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=367925) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=367925) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=367925) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=367925) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=367925) .b8 60                                  // DW_AT_call_line
(EngineCore_DP0 pid=367925) .b8 1
(EngineCore_DP0 pid=367925) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=367925) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=367925) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=367925) 	}
(EngineCore_DP0 pid=367925) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=367925) 
(EngineCore_DP0 pid=367925) ================================================================
(EngineCore_DP0 pid=367925) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=367925) 
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp8c3a1q9f.ptx', '-o', '/tmp/tmp8c3a1q9f.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866] 
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866] 
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866] 
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp8c3a1q9f.ptx -o /tmp/tmp8c3a1q9f.ptx.o
(EngineCore_DP0 pid=367925) ERROR 01-25 19:43:02 [core.py:866] 

STDERR:
[2026-01-25 19:42:30] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:42:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:42:30] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:42:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:42:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:42:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:42:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:42:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:42:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:42:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:42:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:42:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:42:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:42:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:42:34] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:42:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 19:42:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 19:42:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:42:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:42:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:42:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:42:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 19:42:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 19:42:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:42:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:42:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:42:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:42:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=367925) [2026-01-25 19:42:35] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=367925) [2026-01-25 19:42:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=367925) [2026-01-25 19:42:35] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=367925) [2026-01-25 19:42:35] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=367925) [2026-01-25 19:42:35] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=367925) [2026-01-25 19:42:35] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=367925) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=367925) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.85s/it]
(EngineCore_DP0 pid=367925) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.85s/it]
(EngineCore_DP0 pid=367925) 
(EngineCore_DP0 pid=367925) [2026-01-25 19:43:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=367925) [2026-01-25 19:43:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=367925) [2026-01-25 19:43:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=367925) [2026-01-25 19:43:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9437184 bytes
(EngineCore_DP0 pid=367925) [2026-01-25 19:43:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=367925) [2026-01-25 19:43:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50331648 bytes
(EngineCore_DP0 pid=367925) [2026-01-25 19:43:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=367925) [2026-01-25 19:43:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25264128 bytes
(EngineCore_DP0 pid=367925) Process EngineCore_DP0:
(EngineCore_DP0 pid=367925) Traceback (most recent call last):
(EngineCore_DP0 pid=367925)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=367925)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=367925)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=367925)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=367925) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp8c3a1q9f.ptx', '-o', '/tmp/tmp8c3a1q9f.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=367925) 
(EngineCore_DP0 pid=367925) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=367925) 
(EngineCore_DP0 pid=367925) Traceback (most recent call last):
(EngineCore_DP0 pid=367925)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=367925)     self.run()
(EngineCore_DP0 pid=367925)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=367925)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=367925)     raise e
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=367925)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=367925)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=367925)     super().__init__(
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=367925)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=367925)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=367925)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=367925)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=367925)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=367925)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=367925)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=367925)     return func(*args, **kwargs)
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=367925)     return func(*args, **kwargs)
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=367925)     self.model_runner.profile_run()
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=367925)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=367925)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=367925)     return func(*args, **kwargs)
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=367925)     outputs = self.model(
(EngineCore_DP0 pid=367925)               ^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=367925)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=367925)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=367925)     model_output = self.model(
(EngineCore_DP0 pid=367925)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=367925)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=367925)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=367925)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=367925)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=367925)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=367925)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=367925)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=367925)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=367925)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=367925)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=367925)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=367925)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=367925)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=367925)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=367925)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=367925)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=367925)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=367925)     return self._linear_fn(
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=367925)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=367925)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=367925)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=367925)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=367925)     return fn(input, L)
(EngineCore_DP0 pid=367925)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 379, in quant_slide_int8_triton
(EngineCore_DP0 pid=367925)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=367925)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=367925)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=367925)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=367925)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=367925)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=367925)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=367925)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=367925)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=367925)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=367925)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=367925)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=367925)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=367925)     raise PTXASError(error)
(EngineCore_DP0 pid=367925) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=367925) `ptxas` stderr:
(EngineCore_DP0 pid=367925) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=367925) 
(EngineCore_DP0 pid=367925) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp8c3a1q9f.ptx -o /tmp/tmp8c3a1q9f.ptx.o
(EngineCore_DP0 pid=367925) 
[rank0]:[W125 19:43:02.800652486 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-25 20:36:38
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:36:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:36:42 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=426947) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=426947) 
(EngineCore_DP0 pid=426947) 
(EngineCore_DP0 pid=426947) ================================================================
(EngineCore_DP0 pid=426947) Internal Triton PTX codegen error
(EngineCore_DP0 pid=426947) `ptxas` stderr:
(EngineCore_DP0 pid=426947) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=426947) 
(EngineCore_DP0 pid=426947) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpf5bz96ti.ptx -o /tmp/tmpf5bz96ti.ptx.o
(EngineCore_DP0 pid=426947) 
(EngineCore_DP0 pid=426947) 
(EngineCore_DP0 pid=426947) //
(EngineCore_DP0 pid=426947) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=426947) //
(EngineCore_DP0 pid=426947) 
(EngineCore_DP0 pid=426947) .version 8.7
(EngineCore_DP0 pid=426947) .target sm_121a
(EngineCore_DP0 pid=426947) .address_size 64
(EngineCore_DP0 pid=426947) 
(EngineCore_DP0 pid=426947) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=426947) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=426947)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=426947) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=426947) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=426947) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=426947) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=426947) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=426947) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=426947) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=426947) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=426947) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=426947) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=426947) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=426947) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=426947) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=426947) )
(EngineCore_DP0 pid=426947) .reqntid 1024
(EngineCore_DP0 pid=426947) {
(EngineCore_DP0 pid=426947) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=426947) 	.reg .b16 	%rs<20>;
(EngineCore_DP0 pid=426947) 	.reg .b32 	%r<119>;
(EngineCore_DP0 pid=426947) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=426947) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=426947) $L__func_begin0:
(EngineCore_DP0 pid=426947) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=426947) 
(EngineCore_DP0 pid=426947) // %bb.0:
(EngineCore_DP0 pid=426947) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=426947) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=426947) 	ld.param.b32 	%r17, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=426947) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=426947) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=426947) $L__tmp0:
(EngineCore_DP0 pid=426947) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=426947) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=426947) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=426947) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=426947) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=426947) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=426947) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=426947) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=426947) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=426947) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=426947) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=426947) 	mov.b32 	%r117, 0f2B8CBCCC;
(EngineCore_DP0 pid=426947) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=426947) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=426947) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=426947) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=426947) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=426947) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=426947) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=426947) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=426947) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=426947) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=426947) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=426947) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=426947) 	mov.b32 	%r115, 0f00000000;
(EngineCore_DP0 pid=426947) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=426947) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=426947) 	mov.b32 	%r116, %r37;
(EngineCore_DP0 pid=426947) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=426947) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=426947) 	add.s32 	%r45, %r3, %r116;
(EngineCore_DP0 pid=426947) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=426947) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=426947) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=426947) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=426947) 	// begin inline asm
(EngineCore_DP0 pid=426947) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=426947) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=426947) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=426947) 	// end inline asm
(EngineCore_DP0 pid=426947) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=426947) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=426947) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=426947) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=426947) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=426947) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=426947) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=426947) $L__tmp1:
(EngineCore_DP0 pid=426947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	bar.sync 	0;
(EngineCore_DP0 pid=426947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=426947) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=426947) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=426947) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=426947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=426947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=426947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=426947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=426947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=426947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=426947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=426947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=426947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=426947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=426947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	// begin inline asm
(EngineCore_DP0 pid=426947) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=426947) 	// end inline asm
(EngineCore_DP0 pid=426947) 	bar.sync 	0;
(EngineCore_DP0 pid=426947) 	// begin inline asm
(EngineCore_DP0 pid=426947) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=426947) 	// end inline asm
(EngineCore_DP0 pid=426947) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=426947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=426947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=426947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=426947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=426947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=426947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=426947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=426947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=426947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=426947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=426947) 	// begin inline asm
(EngineCore_DP0 pid=426947) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=426947) 	// end inline asm
(EngineCore_DP0 pid=426947) 	bar.sync 	0;
(EngineCore_DP0 pid=426947) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=426947) $L__tmp2:
(EngineCore_DP0 pid=426947) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=426947) 	max.f32 	%r115, %r115, %r65;
(EngineCore_DP0 pid=426947) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=426947) 	add.s32 	%r116, %r116, 4096;
(EngineCore_DP0 pid=426947) 	setp.lt.s32 	%p6, %r116, %r18;
(EngineCore_DP0 pid=426947) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=426947) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=426947) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=426947) 	max.f32 	%r117, %r115, 0f2B8CBCCC;
(EngineCore_DP0 pid=426947) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=426947) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=426947) 	mov.b32 	%r67, 0f42FE0000;
(EngineCore_DP0 pid=426947) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=426947) 	div.full.f32 	%r68, %r117, %r67;
(EngineCore_DP0 pid=426947) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=426947) 	max.f32 	%r66, %r68, 0f37810204;
(EngineCore_DP0 pid=426947) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=426947) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=426947) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=426947) 	// begin inline asm
(EngineCore_DP0 pid=426947) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=426947) 	// end inline asm
(EngineCore_DP0 pid=426947) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=426947) 	shl.b32 	%r14, %r19, 1;
(EngineCore_DP0 pid=426947) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=426947) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=426947) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=426947) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=426947) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=426947) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=426947) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=426947) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=426947) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=426947) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=426947) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=426947) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=426947) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=426947) 	div.full.f32 	%r13, %r67, %r117;
(EngineCore_DP0 pid=426947) 	mov.b32 	%r118, 0;
(EngineCore_DP0 pid=426947) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=426947)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=426947) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=426947) 	add.s32 	%r72, %r2, %r118;
(EngineCore_DP0 pid=426947) 	setp.lt.s32 	%p13, %r72, %r14;
(EngineCore_DP0 pid=426947) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=426947) 	shr.u32 	%r73, %r72, 31;
(EngineCore_DP0 pid=426947) 	add.s32 	%r74, %r72, %r73;
(EngineCore_DP0 pid=426947) 	shr.u32 	%r75, %r74, 1;
(EngineCore_DP0 pid=426947) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=426947) 	and.b32 	%r76, %r74, 2147483646;
(EngineCore_DP0 pid=426947) 	sub.s32 	%r77, %r72, %r76;
(EngineCore_DP0 pid=426947) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=426947) 	shl.b32 	%r78, %r77, 1;
(EngineCore_DP0 pid=426947) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=426947) 	mad.lo.s32 	%r79, %r75, 6, %r78;
(EngineCore_DP0 pid=426947) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=426947) 	setp.lt.s32 	%p14, %r79, %r17;
(EngineCore_DP0 pid=426947) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=426947) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=426947) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=426947) 	mad.wide.s32 	%rd8, %r79, 2, %rd1;
(EngineCore_DP0 pid=426947) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=426947) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=426947) 	// begin inline asm
(EngineCore_DP0 pid=426947) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=426947) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=426947) 	// end inline asm
(EngineCore_DP0 pid=426947) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=426947) 	cvt.f32.bf16 	%r80, %rs12;
(EngineCore_DP0 pid=426947) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=426947) 	or.b32 	%r81, %r79, 1;
(EngineCore_DP0 pid=426947) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=426947) 	setp.lt.s32 	%p15, %r81, %r17;
(EngineCore_DP0 pid=426947) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=426947) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=426947) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=426947) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=426947) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=426947) 	// begin inline asm
(EngineCore_DP0 pid=426947) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=426947) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=426947) 	// end inline asm
(EngineCore_DP0 pid=426947) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=426947) 	cvt.f32.bf16 	%r82, %rs14;
(EngineCore_DP0 pid=426947) 	.loc	1 292 48                        // quant_slide_tuned_Qwen2.5-7B.py:292:48
(EngineCore_DP0 pid=426947) 	add.s32 	%r83, %r79, 2;
(EngineCore_DP0 pid=426947) 	.loc	1 292 53                        // quant_slide_tuned_Qwen2.5-7B.py:292:53
(EngineCore_DP0 pid=426947) 	setp.lt.s32 	%p16, %r83, %r17;
(EngineCore_DP0 pid=426947) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=426947) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=426947) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=426947) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=426947) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=426947) 	// begin inline asm
(EngineCore_DP0 pid=426947) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=426947) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=426947) 	// end inline asm
(EngineCore_DP0 pid=426947) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=426947) 	cvt.f32.bf16 	%r84, %rs16;
(EngineCore_DP0 pid=426947) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=426947) 	add.s32 	%r85, %r79, 3;
(EngineCore_DP0 pid=426947) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=426947) 	setp.lt.s32 	%p17, %r85, %r17;
(EngineCore_DP0 pid=426947) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=426947) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=426947) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=426947) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=426947) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=426947) 	// begin inline asm
(EngineCore_DP0 pid=426947) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=426947) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=426947) 	// end inline asm
(EngineCore_DP0 pid=426947) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=426947) 	cvt.f32.bf16 	%r86, %rs18;
(EngineCore_DP0 pid=426947) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=426947) 	mul.f32 	%r87, %r13, %r80;
(EngineCore_DP0 pid=426947) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=426947) 	cvt.rni.f32.f32 	%r88, %r87;
(EngineCore_DP0 pid=426947) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=426947) 	max.f32 	%r89, %r88, 0fC3000000;
(EngineCore_DP0 pid=426947) 	min.f32 	%r90, %r89, 0f42FE0000;
(EngineCore_DP0 pid=426947) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=426947) 	cvt.rzi.s32.f32 	%r91, %r90;
(EngineCore_DP0 pid=426947) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=426947) 	and.b32 	%r92, %r91, 255;
(EngineCore_DP0 pid=426947) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=426947) 	mul.f32 	%r93, %r13, %r82;
(EngineCore_DP0 pid=426947) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=426947) 	cvt.rni.f32.f32 	%r94, %r93;
(EngineCore_DP0 pid=426947) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=426947) 	mul.f32 	%r95, %r13, %r84;
(EngineCore_DP0 pid=426947) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=426947) 	cvt.rni.f32.f32 	%r96, %r95;
(EngineCore_DP0 pid=426947) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=426947) 	mul.f32 	%r97, %r13, %r86;
(EngineCore_DP0 pid=426947) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=426947) 	cvt.rni.f32.f32 	%r98, %r97;
(EngineCore_DP0 pid=426947) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=426947) 	max.f32 	%r99, %r98, 0fC3000000;
(EngineCore_DP0 pid=426947) 	min.f32 	%r100, %r99, 0f42FE0000;
(EngineCore_DP0 pid=426947) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=426947) 	cvt.rzi.s32.f32 	%r101, %r100;
(EngineCore_DP0 pid=426947) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=426947) 	max.f32 	%r102, %r96, 0fC3000000;
(EngineCore_DP0 pid=426947) 	max.f32 	%r103, %r94, 0fC3000000;
(EngineCore_DP0 pid=426947) 	min.f32 	%r104, %r103, 0f42FE0000;
(EngineCore_DP0 pid=426947) 	min.f32 	%r105, %r102, 0f42FE0000;
(EngineCore_DP0 pid=426947) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=426947) 	cvt.rzi.s32.f32 	%r106, %r105;
(EngineCore_DP0 pid=426947) 	cvt.rzi.s32.f32 	%r107, %r104;
(EngineCore_DP0 pid=426947) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=426947) 	shl.b32 	%r108, %r107, 8;
(EngineCore_DP0 pid=426947) 	shl.b32 	%r109, %r106, 16;
(EngineCore_DP0 pid=426947) 	and.b32 	%r110, %r109, 16711680;
(EngineCore_DP0 pid=426947) 	and.b32 	%r111, %r108, 65280;
(EngineCore_DP0 pid=426947) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=426947) 	or.b32 	%r112, %r111, %r92;
(EngineCore_DP0 pid=426947) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=426947) 	or.b32 	%r113, %r112, %r110;
(EngineCore_DP0 pid=426947) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=426947) 	shl.b32 	%r114, %r101, 24;
(EngineCore_DP0 pid=426947) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=426947) 	or.b32 	%r70, %r113, %r114;
(EngineCore_DP0 pid=426947) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=426947) 	mad.wide.s32 	%rd12, %r72, 4, %rd2;
(EngineCore_DP0 pid=426947) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=426947) 	// begin inline asm
(EngineCore_DP0 pid=426947) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r70 };
(EngineCore_DP0 pid=426947) 	// end inline asm
(EngineCore_DP0 pid=426947) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=426947) 	add.s32 	%r118, %r118, 1024;
(EngineCore_DP0 pid=426947) 	setp.lt.s32 	%p18, %r118, %r14;
(EngineCore_DP0 pid=426947) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=426947) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=426947) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=426947) 	ret;
(EngineCore_DP0 pid=426947) $L__tmp3:
(EngineCore_DP0 pid=426947) $L__func_end0:
(EngineCore_DP0 pid=426947)                                         // -- End function
(EngineCore_DP0 pid=426947) }
(EngineCore_DP0 pid=426947) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=426947) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=426947) 	.section	.debug_abbrev
(EngineCore_DP0 pid=426947) 	{
(EngineCore_DP0 pid=426947) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=426947) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=426947) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=426947) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=426947) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=426947) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=426947) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=426947) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=426947) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=426947) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=426947) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=426947) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=426947) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=426947) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=426947) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=426947) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=426947) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=426947) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=426947) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=426947) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=426947) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=426947) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=426947) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=426947) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=426947) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=426947) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=426947) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=426947) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=426947) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=426947) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=426947) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=426947) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=426947) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=426947) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=426947) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=426947) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=426947) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=426947) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=426947) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=426947) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=426947) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=426947) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=426947) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=426947) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=426947) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=426947) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=426947) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=426947) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=426947) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=426947) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=426947) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=426947) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=426947) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=426947) 	}
(EngineCore_DP0 pid=426947) 	.section	.debug_info
(EngineCore_DP0 pid=426947) 	{
(EngineCore_DP0 pid=426947) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=426947) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=426947) .b8 0
(EngineCore_DP0 pid=426947) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=426947) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=426947) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=426947) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=426947) .b8 114
(EngineCore_DP0 pid=426947) .b8 105
(EngineCore_DP0 pid=426947) .b8 116
(EngineCore_DP0 pid=426947) .b8 111
(EngineCore_DP0 pid=426947) .b8 110
(EngineCore_DP0 pid=426947) .b8 0
(EngineCore_DP0 pid=426947) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=426947) .b8 0
(EngineCore_DP0 pid=426947) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=426947) .b8 117
(EngineCore_DP0 pid=426947) .b8 97
(EngineCore_DP0 pid=426947) .b8 110
(EngineCore_DP0 pid=426947) .b8 116
(EngineCore_DP0 pid=426947) .b8 95
(EngineCore_DP0 pid=426947) .b8 115
(EngineCore_DP0 pid=426947) .b8 108
(EngineCore_DP0 pid=426947) .b8 105
(EngineCore_DP0 pid=426947) .b8 100
(EngineCore_DP0 pid=426947) .b8 101
(EngineCore_DP0 pid=426947) .b8 95
(EngineCore_DP0 pid=426947) .b8 116
(EngineCore_DP0 pid=426947) .b8 117
(EngineCore_DP0 pid=426947) .b8 110
(EngineCore_DP0 pid=426947) .b8 101
(EngineCore_DP0 pid=426947) .b8 100
(EngineCore_DP0 pid=426947) .b8 95
(EngineCore_DP0 pid=426947) .b8 81
(EngineCore_DP0 pid=426947) .b8 119
(EngineCore_DP0 pid=426947) .b8 101
(EngineCore_DP0 pid=426947) .b8 110
(EngineCore_DP0 pid=426947) .b8 50
(EngineCore_DP0 pid=426947) .b8 46
(EngineCore_DP0 pid=426947) .b8 53
(EngineCore_DP0 pid=426947) .b8 45
(EngineCore_DP0 pid=426947) .b8 55
(EngineCore_DP0 pid=426947) .b8 66
(EngineCore_DP0 pid=426947) .b8 46
(EngineCore_DP0 pid=426947) .b8 112
(EngineCore_DP0 pid=426947) .b8 121
(EngineCore_DP0 pid=426947) .b8 0
(EngineCore_DP0 pid=426947) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=426947) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=426947) .b8 114
(EngineCore_DP0 pid=426947) .b8 111
(EngineCore_DP0 pid=426947) .b8 111
(EngineCore_DP0 pid=426947) .b8 116
(EngineCore_DP0 pid=426947) .b8 47
(EngineCore_DP0 pid=426947) .b8 118
(EngineCore_DP0 pid=426947) .b8 108
(EngineCore_DP0 pid=426947) .b8 108
(EngineCore_DP0 pid=426947) .b8 109
(EngineCore_DP0 pid=426947) .b8 98
(EngineCore_DP0 pid=426947) .b8 101
(EngineCore_DP0 pid=426947) .b8 110
(EngineCore_DP0 pid=426947) .b8 99
(EngineCore_DP0 pid=426947) .b8 104
(EngineCore_DP0 pid=426947) .b8 47
(EngineCore_DP0 pid=426947) .b8 115
(EngineCore_DP0 pid=426947) .b8 108
(EngineCore_DP0 pid=426947) .b8 105
(EngineCore_DP0 pid=426947) .b8 100
(EngineCore_DP0 pid=426947) .b8 101
(EngineCore_DP0 pid=426947) .b8 115
(EngineCore_DP0 pid=426947) .b8 112
(EngineCore_DP0 pid=426947) .b8 97
(EngineCore_DP0 pid=426947) .b8 114
(EngineCore_DP0 pid=426947) .b8 115
(EngineCore_DP0 pid=426947) .b8 101
(EngineCore_DP0 pid=426947) .b8 47
(EngineCore_DP0 pid=426947) .b8 99
(EngineCore_DP0 pid=426947) .b8 115
(EngineCore_DP0 pid=426947) .b8 114
(EngineCore_DP0 pid=426947) .b8 99
(EngineCore_DP0 pid=426947) .b8 47
(EngineCore_DP0 pid=426947) .b8 102
(EngineCore_DP0 pid=426947) .b8 117
(EngineCore_DP0 pid=426947) .b8 115
(EngineCore_DP0 pid=426947) .b8 101
(EngineCore_DP0 pid=426947) .b8 100
(EngineCore_DP0 pid=426947) .b8 95
(EngineCore_DP0 pid=426947) .b8 113
(EngineCore_DP0 pid=426947) .b8 117
(EngineCore_DP0 pid=426947) .b8 97
(EngineCore_DP0 pid=426947) .b8 110
(EngineCore_DP0 pid=426947) .b8 116
(EngineCore_DP0 pid=426947) .b8 95
(EngineCore_DP0 pid=426947) .b8 115
(EngineCore_DP0 pid=426947) .b8 108
(EngineCore_DP0 pid=426947) .b8 105
(EngineCore_DP0 pid=426947) .b8 100
(EngineCore_DP0 pid=426947) .b8 101
(EngineCore_DP0 pid=426947) .b8 95
(EngineCore_DP0 pid=426947) .b8 116
(EngineCore_DP0 pid=426947) .b8 114
(EngineCore_DP0 pid=426947) .b8 105
(EngineCore_DP0 pid=426947) .b8 116
(EngineCore_DP0 pid=426947) .b8 111
(EngineCore_DP0 pid=426947) .b8 110
(EngineCore_DP0 pid=426947) .b8 47
(EngineCore_DP0 pid=426947) .b8 98
(EngineCore_DP0 pid=426947) .b8 117
(EngineCore_DP0 pid=426947) .b8 105
(EngineCore_DP0 pid=426947) .b8 108
(EngineCore_DP0 pid=426947) .b8 100
(EngineCore_DP0 pid=426947) .b8 47
(EngineCore_DP0 pid=426947) .b8 71
(EngineCore_DP0 pid=426947) .b8 66
(EngineCore_DP0 pid=426947) .b8 49
(EngineCore_DP0 pid=426947) .b8 48
(EngineCore_DP0 pid=426947) .b8 95
(EngineCore_DP0 pid=426947) .b8 99
(EngineCore_DP0 pid=426947) .b8 99
(EngineCore_DP0 pid=426947) .b8 49
(EngineCore_DP0 pid=426947) .b8 50
(EngineCore_DP0 pid=426947) .b8 49
(EngineCore_DP0 pid=426947) .b8 95
(EngineCore_DP0 pid=426947) .b8 112
(EngineCore_DP0 pid=426947) .b8 121
(EngineCore_DP0 pid=426947) .b8 51
(EngineCore_DP0 pid=426947) .b8 49
(EngineCore_DP0 pid=426947) .b8 50
(EngineCore_DP0 pid=426947) .b8 95
(EngineCore_DP0 pid=426947) .b8 99
(EngineCore_DP0 pid=426947) .b8 117
(EngineCore_DP0 pid=426947) .b8 49
(EngineCore_DP0 pid=426947) .b8 50
(EngineCore_DP0 pid=426947) .b8 57
(EngineCore_DP0 pid=426947) .b8 95
(EngineCore_DP0 pid=426947) .b8 97
(EngineCore_DP0 pid=426947) .b8 97
(EngineCore_DP0 pid=426947) .b8 114
(EngineCore_DP0 pid=426947) .b8 99
(EngineCore_DP0 pid=426947) .b8 104
(EngineCore_DP0 pid=426947) .b8 54
(EngineCore_DP0 pid=426947) .b8 52
(EngineCore_DP0 pid=426947) .b8 0
(EngineCore_DP0 pid=426947) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=426947) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=426947) .b8 113
(EngineCore_DP0 pid=426947) .b8 117
(EngineCore_DP0 pid=426947) .b8 97
(EngineCore_DP0 pid=426947) .b8 110
(EngineCore_DP0 pid=426947) .b8 116
(EngineCore_DP0 pid=426947) .b8 95
(EngineCore_DP0 pid=426947) .b8 115
(EngineCore_DP0 pid=426947) .b8 108
(EngineCore_DP0 pid=426947) .b8 105
(EngineCore_DP0 pid=426947) .b8 100
(EngineCore_DP0 pid=426947) .b8 101
(EngineCore_DP0 pid=426947) .b8 95
(EngineCore_DP0 pid=426947) .b8 105
(EngineCore_DP0 pid=426947) .b8 110
(EngineCore_DP0 pid=426947) .b8 116
(EngineCore_DP0 pid=426947) .b8 56
(EngineCore_DP0 pid=426947) .b8 95
(EngineCore_DP0 pid=426947) .b8 107
(EngineCore_DP0 pid=426947) .b8 101
(EngineCore_DP0 pid=426947) .b8 114
(EngineCore_DP0 pid=426947) .b8 110
(EngineCore_DP0 pid=426947) .b8 101
(EngineCore_DP0 pid=426947) .b8 108
(EngineCore_DP0 pid=426947) .b8 0
(EngineCore_DP0 pid=426947) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=426947) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=426947) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=426947) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=426947) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=426947) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=426947) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=426947) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=426947) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=426947) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=426947) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=426947) .b8 1
(EngineCore_DP0 pid=426947) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=426947) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=426947) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=426947) 	}
(EngineCore_DP0 pid=426947) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=426947) 
(EngineCore_DP0 pid=426947) ================================================================
(EngineCore_DP0 pid=426947) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=426947) 
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpf5bz96ti.ptx', '-o', '/tmp/tmpf5bz96ti.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866] 
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866] 
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866] 
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpf5bz96ti.ptx -o /tmp/tmpf5bz96ti.ptx.o
(EngineCore_DP0 pid=426947) ERROR 01-25 20:37:48 [core.py:866] 

STDERR:
[2026-01-25 20:36:42] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:36:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:36:42] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:36:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:36:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:36:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:36:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:36:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:36:45] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:36:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:36:45] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:36:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:36:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:36:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:36:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:36:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=426947) [2026-01-25 20:36:46] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=426947) [2026-01-25 20:36:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=426947) [2026-01-25 20:36:46] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=426947) [2026-01-25 20:36:46] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=426947) [2026-01-25 20:36:46] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=426947) [2026-01-25 20:36:46] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=426947) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=426947) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:24<00:24, 24.64s/it]
(EngineCore_DP0 pid=426947) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:58<00:00, 30.12s/it]
(EngineCore_DP0 pid=426947) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:58<00:00, 29.30s/it]
(EngineCore_DP0 pid=426947) 
(EngineCore_DP0 pid=426947) [2026-01-25 20:37:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=426947) [2026-01-25 20:37:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=426947) [2026-01-25 20:37:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=426947) [2026-01-25 20:37:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=426947) [2026-01-25 20:37:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=426947) [2026-01-25 20:37:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=426947) [2026-01-25 20:37:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=426947) [2026-01-25 20:37:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=426947) Process EngineCore_DP0:
(EngineCore_DP0 pid=426947) Traceback (most recent call last):
(EngineCore_DP0 pid=426947)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=426947)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=426947)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=426947)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=426947) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpf5bz96ti.ptx', '-o', '/tmp/tmpf5bz96ti.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=426947) 
(EngineCore_DP0 pid=426947) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=426947) 
(EngineCore_DP0 pid=426947) Traceback (most recent call last):
(EngineCore_DP0 pid=426947)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=426947)     self.run()
(EngineCore_DP0 pid=426947)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=426947)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=426947)     raise e
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=426947)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=426947)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=426947)     super().__init__(
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=426947)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=426947)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=426947)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=426947)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=426947)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=426947)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=426947)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=426947)     return func(*args, **kwargs)
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=426947)     return func(*args, **kwargs)
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=426947)     self.model_runner.profile_run()
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=426947)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=426947)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=426947)     return func(*args, **kwargs)
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=426947)     outputs = self.model(
(EngineCore_DP0 pid=426947)               ^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=426947)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=426947)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=426947)     hidden_states = self.model(
(EngineCore_DP0 pid=426947)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=426947)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=426947)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=426947)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=426947)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=426947)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=426947)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=426947)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=426947)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=426947)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=426947)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=426947)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=426947)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=426947)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=426947)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=426947)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=426947)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=426947)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=426947)     return self._linear_fn(
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=426947)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=426947)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=426947)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=426947)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=426947)     return fn(input, L)
(EngineCore_DP0 pid=426947)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=426947)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=426947)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=426947)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=426947)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=426947)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=426947)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=426947)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=426947)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=426947)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=426947)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=426947)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=426947)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=426947)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=426947)     raise PTXASError(error)
(EngineCore_DP0 pid=426947) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=426947) `ptxas` stderr:
(EngineCore_DP0 pid=426947) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=426947) 
(EngineCore_DP0 pid=426947) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpf5bz96ti.ptx -o /tmp/tmpf5bz96ti.ptx.o
(EngineCore_DP0 pid=426947) 
[rank0]:[W125 20:37:48.780022594 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 20:37:50
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:37:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:37:54 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=428122) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=428122) 
(EngineCore_DP0 pid=428122) 
(EngineCore_DP0 pid=428122) ================================================================
(EngineCore_DP0 pid=428122) Internal Triton PTX codegen error
(EngineCore_DP0 pid=428122) `ptxas` stderr:
(EngineCore_DP0 pid=428122) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=428122) 
(EngineCore_DP0 pid=428122) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpvg9o87_z.ptx -o /tmp/tmpvg9o87_z.ptx.o
(EngineCore_DP0 pid=428122) 
(EngineCore_DP0 pid=428122) 
(EngineCore_DP0 pid=428122) //
(EngineCore_DP0 pid=428122) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=428122) //
(EngineCore_DP0 pid=428122) 
(EngineCore_DP0 pid=428122) .version 8.7
(EngineCore_DP0 pid=428122) .target sm_121a
(EngineCore_DP0 pid=428122) .address_size 64
(EngineCore_DP0 pid=428122) 
(EngineCore_DP0 pid=428122) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=428122) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=428122)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=428122) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=428122) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=428122) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=428122) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=428122) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=428122) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=428122) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=428122) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=428122) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=428122) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=428122) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=428122) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=428122) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=428122) )
(EngineCore_DP0 pid=428122) .reqntid 512
(EngineCore_DP0 pid=428122) {
(EngineCore_DP0 pid=428122) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=428122) 	.reg .b16 	%rs<40>;
(EngineCore_DP0 pid=428122) 	.reg .b32 	%r<160>;
(EngineCore_DP0 pid=428122) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=428122) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=428122) $L__func_begin0:
(EngineCore_DP0 pid=428122) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=428122) 
(EngineCore_DP0 pid=428122) // %bb.0:
(EngineCore_DP0 pid=428122) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=428122) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=428122) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=428122) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=428122) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=428122) $L__tmp0:
(EngineCore_DP0 pid=428122) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=428122) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=428122) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=428122) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=428122) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=428122) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=428122) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=428122) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=428122) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=428122) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=428122) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=428122) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=428122) 	mov.b32 	%r158, 0f2B8CBCCC;
(EngineCore_DP0 pid=428122) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=428122) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=428122) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=428122) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=428122) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=428122) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=428122) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=428122) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=428122) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=428122) 	add.s32 	%r45, %r35, %r34;
(EngineCore_DP0 pid=428122) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=428122) 	add.s32 	%r48, %r35, %r36;
(EngineCore_DP0 pid=428122) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=428122) 	mov.b32 	%r156, 0f00000000;
(EngineCore_DP0 pid=428122) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=428122) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=428122) 	mov.b32 	%r157, %r41;
(EngineCore_DP0 pid=428122) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=428122) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=428122) 	add.s32 	%r51, %r4, %r157;
(EngineCore_DP0 pid=428122) 	setp.lt.s32 	%p2, %r51, %r19;
(EngineCore_DP0 pid=428122) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=428122) 	mad.wide.s32 	%rd6, %r51, 2, %rd1;
(EngineCore_DP0 pid=428122) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=428122) 	// begin inline asm
(EngineCore_DP0 pid=428122) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=428122) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=428122) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=428122) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=428122) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=428122) 	// end inline asm
(EngineCore_DP0 pid=428122) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=428122) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=428122) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=428122) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=428122) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=428122) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=428122) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=428122) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=428122) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=428122) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=428122) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=428122) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=428122) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=428122) $L__tmp1:
(EngineCore_DP0 pid=428122) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	bar.sync 	0;
(EngineCore_DP0 pid=428122) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=428122) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=428122) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=428122) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=428122) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=428122) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=428122) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=428122) 	cvt.f32.bf16 	%r52, %rs23;
(EngineCore_DP0 pid=428122) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	shfl.sync.bfly.b32 	%r53, %r52, 16, 31, -1;
(EngineCore_DP0 pid=428122) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=428122) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	shfl.sync.bfly.b32 	%r55, %r54, 8, 31, -1;
(EngineCore_DP0 pid=428122) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=428122) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	shfl.sync.bfly.b32 	%r57, %r56, 4, 31, -1;
(EngineCore_DP0 pid=428122) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=428122) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	shfl.sync.bfly.b32 	%r59, %r58, 2, 31, -1;
(EngineCore_DP0 pid=428122) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=428122) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	shfl.sync.bfly.b32 	%r61, %r60, 1, 31, -1;
(EngineCore_DP0 pid=428122) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	max.f32 	%r46, %r60, %r61;
(EngineCore_DP0 pid=428122) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	// begin inline asm
(EngineCore_DP0 pid=428122) 	@%p3 st.shared.b32 [ %r45 + 0 ], %r46;
(EngineCore_DP0 pid=428122) 	// end inline asm
(EngineCore_DP0 pid=428122) 	bar.sync 	0;
(EngineCore_DP0 pid=428122) 	// begin inline asm
(EngineCore_DP0 pid=428122) 	@%p4 ld.shared.b32 %r47, [ %r48 + 0 ];
(EngineCore_DP0 pid=428122) 	// end inline asm
(EngineCore_DP0 pid=428122) 	shfl.sync.bfly.b32 	%r62, %r47, 8, 31, -1;
(EngineCore_DP0 pid=428122) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	max.f32 	%r63, %r47, %r62;
(EngineCore_DP0 pid=428122) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	shfl.sync.bfly.b32 	%r64, %r63, 4, 31, -1;
(EngineCore_DP0 pid=428122) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=428122) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	shfl.sync.bfly.b32 	%r66, %r65, 2, 31, -1;
(EngineCore_DP0 pid=428122) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=428122) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	shfl.sync.bfly.b32 	%r68, %r67, 1, 31, -1;
(EngineCore_DP0 pid=428122) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	max.f32 	%r50, %r67, %r68;
(EngineCore_DP0 pid=428122) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=428122) 	// begin inline asm
(EngineCore_DP0 pid=428122) 	@%p27 st.shared.b32 [ %r48 + 0 ], %r50;
(EngineCore_DP0 pid=428122) 	// end inline asm
(EngineCore_DP0 pid=428122) 	bar.sync 	0;
(EngineCore_DP0 pid=428122) 	ld.shared.b32 	%r69, [global_smem];
(EngineCore_DP0 pid=428122) $L__tmp2:
(EngineCore_DP0 pid=428122) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=428122) 	max.f32 	%r156, %r156, %r69;
(EngineCore_DP0 pid=428122) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=428122) 	add.s32 	%r157, %r157, 4096;
(EngineCore_DP0 pid=428122) 	setp.lt.s32 	%p6, %r157, %r20;
(EngineCore_DP0 pid=428122) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=428122) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=428122) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=428122) 	max.f32 	%r158, %r156, 0f2B8CBCCC;
(EngineCore_DP0 pid=428122) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=428122) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=428122) 	mov.b32 	%r71, 0f42FE0000;
(EngineCore_DP0 pid=428122) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=428122) 	div.full.f32 	%r72, %r158, %r71;
(EngineCore_DP0 pid=428122) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=428122) 	max.f32 	%r70, %r72, 0f37810204;
(EngineCore_DP0 pid=428122) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=428122) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=428122) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=428122) 	// begin inline asm
(EngineCore_DP0 pid=428122) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r70 };
(EngineCore_DP0 pid=428122) 	// end inline asm
(EngineCore_DP0 pid=428122) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=428122) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=428122) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=428122) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=428122) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=428122) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=428122) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=428122) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=428122) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=428122) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=428122) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=428122) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=428122) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=428122) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=428122) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=428122) 	div.full.f32 	%r14, %r71, %r158;
(EngineCore_DP0 pid=428122) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=428122) 	mov.b32 	%r159, 0;
(EngineCore_DP0 pid=428122) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=428122)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=428122) 	.loc	1 279 31                        // quant_slide_tuned_Qwen2.5-7B.py:279:31
(EngineCore_DP0 pid=428122) 	add.s32 	%r76, %r16, %r159;
(EngineCore_DP0 pid=428122) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=428122) 	add.s32 	%r77, %r159, 1;
(EngineCore_DP0 pid=428122) 	setp.lt.s32 	%p17, %r76, %r15;
(EngineCore_DP0 pid=428122) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=428122) 	shr.u32 	%r78, %r76, 1;
(EngineCore_DP0 pid=428122) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=428122) 	shr.u32 	%r79, %r77, 31;
(EngineCore_DP0 pid=428122) 	add.s32 	%r80, %r77, %r79;
(EngineCore_DP0 pid=428122) 	and.b32 	%r81, %r80, 2147483646;
(EngineCore_DP0 pid=428122) 	sub.s32 	%r82, %r77, %r81;
(EngineCore_DP0 pid=428122) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=428122) 	mul.lo.s32 	%r83, %r78, 6;
(EngineCore_DP0 pid=428122) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=428122) 	shl.b32 	%r84, %r82, 1;
(EngineCore_DP0 pid=428122) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=428122) 	add.s32 	%r85, %r83, %r84;
(EngineCore_DP0 pid=428122) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=428122) 	setp.lt.s32 	%p18, %r83, %r19;
(EngineCore_DP0 pid=428122) 	setp.lt.s32 	%p19, %r85, %r19;
(EngineCore_DP0 pid=428122) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=428122) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=428122) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=428122) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=428122) 	mad.wide.s32 	%rd8, %r83, 2, %rd1;
(EngineCore_DP0 pid=428122) 	mad.wide.s32 	%rd9, %r85, 2, %rd1;
(EngineCore_DP0 pid=428122) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=428122) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=428122) 	// begin inline asm
(EngineCore_DP0 pid=428122) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=428122) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=428122) 	// end inline asm
(EngineCore_DP0 pid=428122) 	// begin inline asm
(EngineCore_DP0 pid=428122) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=428122) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=428122) 	// end inline asm
(EngineCore_DP0 pid=428122) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=428122) 	cvt.f32.bf16 	%r86, %rs24;
(EngineCore_DP0 pid=428122) 	cvt.f32.bf16 	%r87, %rs26;
(EngineCore_DP0 pid=428122) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=428122) 	or.b32 	%r88, %r83, 1;
(EngineCore_DP0 pid=428122) 	or.b32 	%r89, %r85, 1;
(EngineCore_DP0 pid=428122) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=428122) 	setp.lt.s32 	%p20, %r88, %r19;
(EngineCore_DP0 pid=428122) 	setp.lt.s32 	%p21, %r89, %r19;
(EngineCore_DP0 pid=428122) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=428122) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=428122) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=428122) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=428122) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=428122) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=428122) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=428122) 	// begin inline asm
(EngineCore_DP0 pid=428122) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=428122) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=428122) 	// end inline asm
(EngineCore_DP0 pid=428122) 	// begin inline asm
(EngineCore_DP0 pid=428122) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=428122) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=428122) 	// end inline asm
(EngineCore_DP0 pid=428122) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=428122) 	cvt.f32.bf16 	%r90, %rs28;
(EngineCore_DP0 pid=428122) 	cvt.f32.bf16 	%r91, %rs30;
(EngineCore_DP0 pid=428122) 	.loc	1 292 48                        // quant_slide_tuned_Qwen2.5-7B.py:292:48
(EngineCore_DP0 pid=428122) 	add.s32 	%r92, %r83, 2;
(EngineCore_DP0 pid=428122) 	add.s32 	%r93, %r85, 2;
(EngineCore_DP0 pid=428122) 	.loc	1 292 53                        // quant_slide_tuned_Qwen2.5-7B.py:292:53
(EngineCore_DP0 pid=428122) 	setp.lt.s32 	%p22, %r92, %r19;
(EngineCore_DP0 pid=428122) 	setp.lt.s32 	%p23, %r93, %r19;
(EngineCore_DP0 pid=428122) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=428122) 	and.pred 	%p13, %p17, %p22;
(EngineCore_DP0 pid=428122) 	and.pred 	%p14, %p17, %p23;
(EngineCore_DP0 pid=428122) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=428122) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=428122) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=428122) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=428122) 	// begin inline asm
(EngineCore_DP0 pid=428122) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=428122) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=428122) 	// end inline asm
(EngineCore_DP0 pid=428122) 	// begin inline asm
(EngineCore_DP0 pid=428122) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=428122) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=428122) 	// end inline asm
(EngineCore_DP0 pid=428122) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=428122) 	cvt.f32.bf16 	%r94, %rs32;
(EngineCore_DP0 pid=428122) 	cvt.f32.bf16 	%r95, %rs34;
(EngineCore_DP0 pid=428122) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=428122) 	add.s32 	%r96, %r83, 3;
(EngineCore_DP0 pid=428122) 	add.s32 	%r97, %r85, 3;
(EngineCore_DP0 pid=428122) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=428122) 	setp.lt.s32 	%p24, %r96, %r19;
(EngineCore_DP0 pid=428122) 	setp.lt.s32 	%p25, %r97, %r19;
(EngineCore_DP0 pid=428122) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=428122) 	and.pred 	%p15, %p17, %p24;
(EngineCore_DP0 pid=428122) 	and.pred 	%p16, %p17, %p25;
(EngineCore_DP0 pid=428122) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=428122) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=428122) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=428122) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=428122) 	// begin inline asm
(EngineCore_DP0 pid=428122) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=428122) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=428122) 	// end inline asm
(EngineCore_DP0 pid=428122) 	// begin inline asm
(EngineCore_DP0 pid=428122) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=428122) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=428122) 	// end inline asm
(EngineCore_DP0 pid=428122) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=428122) 	cvt.f32.bf16 	%r98, %rs36;
(EngineCore_DP0 pid=428122) 	cvt.f32.bf16 	%r99, %rs38;
(EngineCore_DP0 pid=428122) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=428122) 	mul.f32 	%r100, %r14, %r86;
(EngineCore_DP0 pid=428122) 	mul.f32 	%r101, %r14, %r87;
(EngineCore_DP0 pid=428122) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=428122) 	cvt.rni.f32.f32 	%r102, %r100;
(EngineCore_DP0 pid=428122) 	cvt.rni.f32.f32 	%r103, %r101;
(EngineCore_DP0 pid=428122) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=428122) 	max.f32 	%r104, %r102, 0fC3000000;
(EngineCore_DP0 pid=428122) 	min.f32 	%r105, %r104, 0f42FE0000;
(EngineCore_DP0 pid=428122) 	max.f32 	%r106, %r103, 0fC3000000;
(EngineCore_DP0 pid=428122) 	min.f32 	%r107, %r106, 0f42FE0000;
(EngineCore_DP0 pid=428122) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=428122) 	cvt.rzi.s32.f32 	%r108, %r105;
(EngineCore_DP0 pid=428122) 	cvt.rzi.s32.f32 	%r109, %r107;
(EngineCore_DP0 pid=428122) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=428122) 	and.b32 	%r110, %r108, 255;
(EngineCore_DP0 pid=428122) 	and.b32 	%r111, %r109, 255;
(EngineCore_DP0 pid=428122) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=428122) 	mul.f32 	%r112, %r14, %r90;
(EngineCore_DP0 pid=428122) 	mul.f32 	%r113, %r14, %r91;
(EngineCore_DP0 pid=428122) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=428122) 	cvt.rni.f32.f32 	%r114, %r112;
(EngineCore_DP0 pid=428122) 	cvt.rni.f32.f32 	%r115, %r113;
(EngineCore_DP0 pid=428122) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=428122) 	mul.f32 	%r116, %r14, %r94;
(EngineCore_DP0 pid=428122) 	mul.f32 	%r117, %r14, %r95;
(EngineCore_DP0 pid=428122) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=428122) 	cvt.rni.f32.f32 	%r118, %r116;
(EngineCore_DP0 pid=428122) 	cvt.rni.f32.f32 	%r119, %r117;
(EngineCore_DP0 pid=428122) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=428122) 	mul.f32 	%r120, %r14, %r98;
(EngineCore_DP0 pid=428122) 	mul.f32 	%r121, %r14, %r99;
(EngineCore_DP0 pid=428122) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=428122) 	cvt.rni.f32.f32 	%r122, %r120;
(EngineCore_DP0 pid=428122) 	cvt.rni.f32.f32 	%r123, %r121;
(EngineCore_DP0 pid=428122) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=428122) 	max.f32 	%r124, %r122, 0fC3000000;
(EngineCore_DP0 pid=428122) 	min.f32 	%r125, %r124, 0f42FE0000;
(EngineCore_DP0 pid=428122) 	max.f32 	%r126, %r123, 0fC3000000;
(EngineCore_DP0 pid=428122) 	min.f32 	%r127, %r126, 0f42FE0000;
(EngineCore_DP0 pid=428122) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=428122) 	cvt.rzi.s32.f32 	%r128, %r125;
(EngineCore_DP0 pid=428122) 	cvt.rzi.s32.f32 	%r129, %r127;
(EngineCore_DP0 pid=428122) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=428122) 	max.f32 	%r130, %r118, 0fC3000000;
(EngineCore_DP0 pid=428122) 	max.f32 	%r131, %r114, 0fC3000000;
(EngineCore_DP0 pid=428122) 	min.f32 	%r132, %r131, 0f42FE0000;
(EngineCore_DP0 pid=428122) 	min.f32 	%r133, %r130, 0f42FE0000;
(EngineCore_DP0 pid=428122) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=428122) 	cvt.rzi.s32.f32 	%r134, %r133;
(EngineCore_DP0 pid=428122) 	cvt.rzi.s32.f32 	%r135, %r132;
(EngineCore_DP0 pid=428122) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=428122) 	shl.b32 	%r136, %r135, 8;
(EngineCore_DP0 pid=428122) 	shl.b32 	%r137, %r134, 16;
(EngineCore_DP0 pid=428122) 	and.b32 	%r138, %r137, 16711680;
(EngineCore_DP0 pid=428122) 	and.b32 	%r139, %r136, 65280;
(EngineCore_DP0 pid=428122) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=428122) 	or.b32 	%r140, %r139, %r110;
(EngineCore_DP0 pid=428122) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=428122) 	max.f32 	%r141, %r119, 0fC3000000;
(EngineCore_DP0 pid=428122) 	max.f32 	%r142, %r115, 0fC3000000;
(EngineCore_DP0 pid=428122) 	min.f32 	%r143, %r142, 0f42FE0000;
(EngineCore_DP0 pid=428122) 	min.f32 	%r144, %r141, 0f42FE0000;
(EngineCore_DP0 pid=428122) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=428122) 	cvt.rzi.s32.f32 	%r145, %r144;
(EngineCore_DP0 pid=428122) 	cvt.rzi.s32.f32 	%r146, %r143;
(EngineCore_DP0 pid=428122) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=428122) 	shl.b32 	%r147, %r146, 8;
(EngineCore_DP0 pid=428122) 	shl.b32 	%r148, %r145, 16;
(EngineCore_DP0 pid=428122) 	and.b32 	%r149, %r148, 16711680;
(EngineCore_DP0 pid=428122) 	and.b32 	%r150, %r147, 65280;
(EngineCore_DP0 pid=428122) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=428122) 	or.b32 	%r151, %r150, %r111;
(EngineCore_DP0 pid=428122) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=428122) 	or.b32 	%r152, %r140, %r138;
(EngineCore_DP0 pid=428122) 	or.b32 	%r153, %r151, %r149;
(EngineCore_DP0 pid=428122) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=428122) 	shl.b32 	%r154, %r128, 24;
(EngineCore_DP0 pid=428122) 	shl.b32 	%r155, %r129, 24;
(EngineCore_DP0 pid=428122) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=428122) 	or.b32 	%r74, %r152, %r154;
(EngineCore_DP0 pid=428122) 	or.b32 	%r75, %r153, %r155;
(EngineCore_DP0 pid=428122) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=428122) 	mad.wide.s32 	%rd16, %r76, 4, %rd2;
(EngineCore_DP0 pid=428122) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=428122) 	// begin inline asm
(EngineCore_DP0 pid=428122) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r74, %r75 };
(EngineCore_DP0 pid=428122) 	// end inline asm
(EngineCore_DP0 pid=428122) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=428122) 	add.s32 	%r159, %r159, 1024;
(EngineCore_DP0 pid=428122) 	setp.lt.s32 	%p26, %r159, %r15;
(EngineCore_DP0 pid=428122) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=428122) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=428122) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=428122) 	ret;
(EngineCore_DP0 pid=428122) $L__tmp3:
(EngineCore_DP0 pid=428122) $L__func_end0:
(EngineCore_DP0 pid=428122)                                         // -- End function
(EngineCore_DP0 pid=428122) }
(EngineCore_DP0 pid=428122) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=428122) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=428122) 	.section	.debug_abbrev
(EngineCore_DP0 pid=428122) 	{
(EngineCore_DP0 pid=428122) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=428122) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=428122) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=428122) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=428122) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=428122) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=428122) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=428122) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=428122) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=428122) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=428122) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=428122) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=428122) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=428122) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=428122) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=428122) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=428122) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=428122) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=428122) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=428122) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=428122) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=428122) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=428122) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=428122) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=428122) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=428122) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=428122) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=428122) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=428122) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=428122) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=428122) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=428122) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=428122) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=428122) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=428122) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=428122) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=428122) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=428122) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=428122) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=428122) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=428122) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=428122) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=428122) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=428122) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=428122) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=428122) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=428122) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=428122) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=428122) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=428122) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=428122) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=428122) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=428122) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=428122) 	}
(EngineCore_DP0 pid=428122) 	.section	.debug_info
(EngineCore_DP0 pid=428122) 	{
(EngineCore_DP0 pid=428122) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=428122) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=428122) .b8 0
(EngineCore_DP0 pid=428122) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=428122) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=428122) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=428122) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=428122) .b8 114
(EngineCore_DP0 pid=428122) .b8 105
(EngineCore_DP0 pid=428122) .b8 116
(EngineCore_DP0 pid=428122) .b8 111
(EngineCore_DP0 pid=428122) .b8 110
(EngineCore_DP0 pid=428122) .b8 0
(EngineCore_DP0 pid=428122) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=428122) .b8 0
(EngineCore_DP0 pid=428122) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=428122) .b8 117
(EngineCore_DP0 pid=428122) .b8 97
(EngineCore_DP0 pid=428122) .b8 110
(EngineCore_DP0 pid=428122) .b8 116
(EngineCore_DP0 pid=428122) .b8 95
(EngineCore_DP0 pid=428122) .b8 115
(EngineCore_DP0 pid=428122) .b8 108
(EngineCore_DP0 pid=428122) .b8 105
(EngineCore_DP0 pid=428122) .b8 100
(EngineCore_DP0 pid=428122) .b8 101
(EngineCore_DP0 pid=428122) .b8 95
(EngineCore_DP0 pid=428122) .b8 116
(EngineCore_DP0 pid=428122) .b8 117
(EngineCore_DP0 pid=428122) .b8 110
(EngineCore_DP0 pid=428122) .b8 101
(EngineCore_DP0 pid=428122) .b8 100
(EngineCore_DP0 pid=428122) .b8 95
(EngineCore_DP0 pid=428122) .b8 81
(EngineCore_DP0 pid=428122) .b8 119
(EngineCore_DP0 pid=428122) .b8 101
(EngineCore_DP0 pid=428122) .b8 110
(EngineCore_DP0 pid=428122) .b8 50
(EngineCore_DP0 pid=428122) .b8 46
(EngineCore_DP0 pid=428122) .b8 53
(EngineCore_DP0 pid=428122) .b8 45
(EngineCore_DP0 pid=428122) .b8 55
(EngineCore_DP0 pid=428122) .b8 66
(EngineCore_DP0 pid=428122) .b8 46
(EngineCore_DP0 pid=428122) .b8 112
(EngineCore_DP0 pid=428122) .b8 121
(EngineCore_DP0 pid=428122) .b8 0
(EngineCore_DP0 pid=428122) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=428122) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=428122) .b8 114
(EngineCore_DP0 pid=428122) .b8 111
(EngineCore_DP0 pid=428122) .b8 111
(EngineCore_DP0 pid=428122) .b8 116
(EngineCore_DP0 pid=428122) .b8 47
(EngineCore_DP0 pid=428122) .b8 118
(EngineCore_DP0 pid=428122) .b8 108
(EngineCore_DP0 pid=428122) .b8 108
(EngineCore_DP0 pid=428122) .b8 109
(EngineCore_DP0 pid=428122) .b8 98
(EngineCore_DP0 pid=428122) .b8 101
(EngineCore_DP0 pid=428122) .b8 110
(EngineCore_DP0 pid=428122) .b8 99
(EngineCore_DP0 pid=428122) .b8 104
(EngineCore_DP0 pid=428122) .b8 47
(EngineCore_DP0 pid=428122) .b8 115
(EngineCore_DP0 pid=428122) .b8 108
(EngineCore_DP0 pid=428122) .b8 105
(EngineCore_DP0 pid=428122) .b8 100
(EngineCore_DP0 pid=428122) .b8 101
(EngineCore_DP0 pid=428122) .b8 115
(EngineCore_DP0 pid=428122) .b8 112
(EngineCore_DP0 pid=428122) .b8 97
(EngineCore_DP0 pid=428122) .b8 114
(EngineCore_DP0 pid=428122) .b8 115
(EngineCore_DP0 pid=428122) .b8 101
(EngineCore_DP0 pid=428122) .b8 47
(EngineCore_DP0 pid=428122) .b8 99
(EngineCore_DP0 pid=428122) .b8 115
(EngineCore_DP0 pid=428122) .b8 114
(EngineCore_DP0 pid=428122) .b8 99
(EngineCore_DP0 pid=428122) .b8 47
(EngineCore_DP0 pid=428122) .b8 102
(EngineCore_DP0 pid=428122) .b8 117
(EngineCore_DP0 pid=428122) .b8 115
(EngineCore_DP0 pid=428122) .b8 101
(EngineCore_DP0 pid=428122) .b8 100
(EngineCore_DP0 pid=428122) .b8 95
(EngineCore_DP0 pid=428122) .b8 113
(EngineCore_DP0 pid=428122) .b8 117
(EngineCore_DP0 pid=428122) .b8 97
(EngineCore_DP0 pid=428122) .b8 110
(EngineCore_DP0 pid=428122) .b8 116
(EngineCore_DP0 pid=428122) .b8 95
(EngineCore_DP0 pid=428122) .b8 115
(EngineCore_DP0 pid=428122) .b8 108
(EngineCore_DP0 pid=428122) .b8 105
(EngineCore_DP0 pid=428122) .b8 100
(EngineCore_DP0 pid=428122) .b8 101
(EngineCore_DP0 pid=428122) .b8 95
(EngineCore_DP0 pid=428122) .b8 116
(EngineCore_DP0 pid=428122) .b8 114
(EngineCore_DP0 pid=428122) .b8 105
(EngineCore_DP0 pid=428122) .b8 116
(EngineCore_DP0 pid=428122) .b8 111
(EngineCore_DP0 pid=428122) .b8 110
(EngineCore_DP0 pid=428122) .b8 47
(EngineCore_DP0 pid=428122) .b8 98
(EngineCore_DP0 pid=428122) .b8 117
(EngineCore_DP0 pid=428122) .b8 105
(EngineCore_DP0 pid=428122) .b8 108
(EngineCore_DP0 pid=428122) .b8 100
(EngineCore_DP0 pid=428122) .b8 47
(EngineCore_DP0 pid=428122) .b8 71
(EngineCore_DP0 pid=428122) .b8 66
(EngineCore_DP0 pid=428122) .b8 49
(EngineCore_DP0 pid=428122) .b8 48
(EngineCore_DP0 pid=428122) .b8 95
(EngineCore_DP0 pid=428122) .b8 99
(EngineCore_DP0 pid=428122) .b8 99
(EngineCore_DP0 pid=428122) .b8 49
(EngineCore_DP0 pid=428122) .b8 50
(EngineCore_DP0 pid=428122) .b8 49
(EngineCore_DP0 pid=428122) .b8 95
(EngineCore_DP0 pid=428122) .b8 112
(EngineCore_DP0 pid=428122) .b8 121
(EngineCore_DP0 pid=428122) .b8 51
(EngineCore_DP0 pid=428122) .b8 49
(EngineCore_DP0 pid=428122) .b8 50
(EngineCore_DP0 pid=428122) .b8 95
(EngineCore_DP0 pid=428122) .b8 99
(EngineCore_DP0 pid=428122) .b8 117
(EngineCore_DP0 pid=428122) .b8 49
(EngineCore_DP0 pid=428122) .b8 50
(EngineCore_DP0 pid=428122) .b8 57
(EngineCore_DP0 pid=428122) .b8 95
(EngineCore_DP0 pid=428122) .b8 97
(EngineCore_DP0 pid=428122) .b8 97
(EngineCore_DP0 pid=428122) .b8 114
(EngineCore_DP0 pid=428122) .b8 99
(EngineCore_DP0 pid=428122) .b8 104
(EngineCore_DP0 pid=428122) .b8 54
(EngineCore_DP0 pid=428122) .b8 52
(EngineCore_DP0 pid=428122) .b8 0
(EngineCore_DP0 pid=428122) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=428122) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=428122) .b8 113
(EngineCore_DP0 pid=428122) .b8 117
(EngineCore_DP0 pid=428122) .b8 97
(EngineCore_DP0 pid=428122) .b8 110
(EngineCore_DP0 pid=428122) .b8 116
(EngineCore_DP0 pid=428122) .b8 95
(EngineCore_DP0 pid=428122) .b8 115
(EngineCore_DP0 pid=428122) .b8 108
(EngineCore_DP0 pid=428122) .b8 105
(EngineCore_DP0 pid=428122) .b8 100
(EngineCore_DP0 pid=428122) .b8 101
(EngineCore_DP0 pid=428122) .b8 95
(EngineCore_DP0 pid=428122) .b8 105
(EngineCore_DP0 pid=428122) .b8 110
(EngineCore_DP0 pid=428122) .b8 116
(EngineCore_DP0 pid=428122) .b8 56
(EngineCore_DP0 pid=428122) .b8 95
(EngineCore_DP0 pid=428122) .b8 107
(EngineCore_DP0 pid=428122) .b8 101
(EngineCore_DP0 pid=428122) .b8 114
(EngineCore_DP0 pid=428122) .b8 110
(EngineCore_DP0 pid=428122) .b8 101
(EngineCore_DP0 pid=428122) .b8 108
(EngineCore_DP0 pid=428122) .b8 0
(EngineCore_DP0 pid=428122) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=428122) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=428122) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=428122) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=428122) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=428122) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=428122) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=428122) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=428122) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=428122) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=428122) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=428122) .b8 1
(EngineCore_DP0 pid=428122) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=428122) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=428122) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=428122) 	}
(EngineCore_DP0 pid=428122) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=428122) 
(EngineCore_DP0 pid=428122) ================================================================
(EngineCore_DP0 pid=428122) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=428122) 
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpvg9o87_z.ptx', '-o', '/tmp/tmpvg9o87_z.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866] 
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866] 
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866] 
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpvg9o87_z.ptx -o /tmp/tmpvg9o87_z.ptx.o
(EngineCore_DP0 pid=428122) ERROR 01-25 20:38:58 [core.py:866] 

STDERR:
[2026-01-25 20:37:54] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:37:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:37:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:37:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:37:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:37:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:37:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:37:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:37:57] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:37:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:37:57] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:37:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:37:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:37:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:37:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:37:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=428122) [2026-01-25 20:37:58] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=428122) [2026-01-25 20:37:58] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=428122) [2026-01-25 20:37:58] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=428122) [2026-01-25 20:37:58] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=428122) [2026-01-25 20:37:58] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=428122) [2026-01-25 20:37:58] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=428122) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=428122) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:23<00:23, 23.71s/it]
(EngineCore_DP0 pid=428122) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:56<00:00, 29.04s/it]
(EngineCore_DP0 pid=428122) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:56<00:00, 28.24s/it]
(EngineCore_DP0 pid=428122) 
(EngineCore_DP0 pid=428122) [2026-01-25 20:38:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=428122) [2026-01-25 20:38:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=428122) [2026-01-25 20:38:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=428122) [2026-01-25 20:38:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=428122) [2026-01-25 20:38:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=428122) [2026-01-25 20:38:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=428122) [2026-01-25 20:38:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=428122) [2026-01-25 20:38:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=428122) Process EngineCore_DP0:
(EngineCore_DP0 pid=428122) Traceback (most recent call last):
(EngineCore_DP0 pid=428122)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=428122)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=428122)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=428122)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=428122) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpvg9o87_z.ptx', '-o', '/tmp/tmpvg9o87_z.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=428122) 
(EngineCore_DP0 pid=428122) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=428122) 
(EngineCore_DP0 pid=428122) Traceback (most recent call last):
(EngineCore_DP0 pid=428122)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=428122)     self.run()
(EngineCore_DP0 pid=428122)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=428122)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=428122)     raise e
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=428122)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=428122)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=428122)     super().__init__(
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=428122)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=428122)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=428122)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=428122)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=428122)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=428122)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=428122)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=428122)     return func(*args, **kwargs)
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=428122)     return func(*args, **kwargs)
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=428122)     self.model_runner.profile_run()
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=428122)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=428122)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=428122)     return func(*args, **kwargs)
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=428122)     outputs = self.model(
(EngineCore_DP0 pid=428122)               ^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=428122)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=428122)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=428122)     hidden_states = self.model(
(EngineCore_DP0 pid=428122)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=428122)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=428122)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=428122)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=428122)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=428122)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=428122)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=428122)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=428122)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=428122)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=428122)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=428122)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=428122)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=428122)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=428122)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=428122)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=428122)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=428122)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=428122)     return self._linear_fn(
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=428122)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=428122)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=428122)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=428122)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=428122)     return fn(input, L)
(EngineCore_DP0 pid=428122)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=428122)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=428122)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=428122)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=428122)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=428122)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=428122)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=428122)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=428122)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=428122)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=428122)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=428122)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=428122)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=428122)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=428122)     raise PTXASError(error)
(EngineCore_DP0 pid=428122) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=428122) `ptxas` stderr:
(EngineCore_DP0 pid=428122) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=428122) 
(EngineCore_DP0 pid=428122) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpvg9o87_z.ptx -o /tmp/tmpvg9o87_z.ptx.o
(EngineCore_DP0 pid=428122) 
[rank0]:[W125 20:38:58.663300731 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 20:39:00
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:39:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:39:04 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=429287) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=429287) 
(EngineCore_DP0 pid=429287) 
(EngineCore_DP0 pid=429287) ================================================================
(EngineCore_DP0 pid=429287) Internal Triton PTX codegen error
(EngineCore_DP0 pid=429287) `ptxas` stderr:
(EngineCore_DP0 pid=429287) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=429287) 
(EngineCore_DP0 pid=429287) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpytnmya80.ptx -o /tmp/tmpytnmya80.ptx.o
(EngineCore_DP0 pid=429287) 
(EngineCore_DP0 pid=429287) 
(EngineCore_DP0 pid=429287) //
(EngineCore_DP0 pid=429287) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=429287) //
(EngineCore_DP0 pid=429287) 
(EngineCore_DP0 pid=429287) .version 8.7
(EngineCore_DP0 pid=429287) .target sm_121a
(EngineCore_DP0 pid=429287) .address_size 64
(EngineCore_DP0 pid=429287) 
(EngineCore_DP0 pid=429287) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=429287) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=429287)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=429287) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=429287) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=429287) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=429287) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=429287) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=429287) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=429287) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=429287) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=429287) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=429287) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=429287) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=429287) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=429287) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=429287) )
(EngineCore_DP0 pid=429287) .reqntid 512
(EngineCore_DP0 pid=429287) {
(EngineCore_DP0 pid=429287) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=429287) 	.reg .b16 	%rs<40>;
(EngineCore_DP0 pid=429287) 	.reg .b32 	%r<160>;
(EngineCore_DP0 pid=429287) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=429287) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=429287) $L__func_begin0:
(EngineCore_DP0 pid=429287) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=429287) 
(EngineCore_DP0 pid=429287) // %bb.0:
(EngineCore_DP0 pid=429287) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=429287) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=429287) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=429287) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=429287) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=429287) $L__tmp0:
(EngineCore_DP0 pid=429287) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=429287) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=429287) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=429287) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=429287) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=429287) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=429287) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=429287) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=429287) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=429287) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=429287) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=429287) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=429287) 	mov.b32 	%r158, 0f2B8CBCCC;
(EngineCore_DP0 pid=429287) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=429287) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=429287) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=429287) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=429287) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=429287) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=429287) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=429287) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=429287) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=429287) 	add.s32 	%r45, %r35, %r34;
(EngineCore_DP0 pid=429287) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=429287) 	add.s32 	%r48, %r35, %r36;
(EngineCore_DP0 pid=429287) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=429287) 	mov.b32 	%r156, 0f00000000;
(EngineCore_DP0 pid=429287) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=429287) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=429287) 	mov.b32 	%r157, %r41;
(EngineCore_DP0 pid=429287) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=429287) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=429287) 	add.s32 	%r51, %r4, %r157;
(EngineCore_DP0 pid=429287) 	setp.lt.s32 	%p2, %r51, %r19;
(EngineCore_DP0 pid=429287) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=429287) 	mad.wide.s32 	%rd6, %r51, 2, %rd1;
(EngineCore_DP0 pid=429287) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=429287) 	// begin inline asm
(EngineCore_DP0 pid=429287) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=429287) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=429287) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=429287) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=429287) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=429287) 	// end inline asm
(EngineCore_DP0 pid=429287) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=429287) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=429287) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=429287) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=429287) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=429287) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=429287) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=429287) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=429287) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=429287) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=429287) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=429287) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=429287) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=429287) $L__tmp1:
(EngineCore_DP0 pid=429287) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	bar.sync 	0;
(EngineCore_DP0 pid=429287) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=429287) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=429287) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=429287) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=429287) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=429287) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=429287) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=429287) 	cvt.f32.bf16 	%r52, %rs23;
(EngineCore_DP0 pid=429287) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	shfl.sync.bfly.b32 	%r53, %r52, 16, 31, -1;
(EngineCore_DP0 pid=429287) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=429287) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	shfl.sync.bfly.b32 	%r55, %r54, 8, 31, -1;
(EngineCore_DP0 pid=429287) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=429287) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	shfl.sync.bfly.b32 	%r57, %r56, 4, 31, -1;
(EngineCore_DP0 pid=429287) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=429287) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	shfl.sync.bfly.b32 	%r59, %r58, 2, 31, -1;
(EngineCore_DP0 pid=429287) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=429287) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	shfl.sync.bfly.b32 	%r61, %r60, 1, 31, -1;
(EngineCore_DP0 pid=429287) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	max.f32 	%r46, %r60, %r61;
(EngineCore_DP0 pid=429287) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	// begin inline asm
(EngineCore_DP0 pid=429287) 	@%p3 st.shared.b32 [ %r45 + 0 ], %r46;
(EngineCore_DP0 pid=429287) 	// end inline asm
(EngineCore_DP0 pid=429287) 	bar.sync 	0;
(EngineCore_DP0 pid=429287) 	// begin inline asm
(EngineCore_DP0 pid=429287) 	@%p4 ld.shared.b32 %r47, [ %r48 + 0 ];
(EngineCore_DP0 pid=429287) 	// end inline asm
(EngineCore_DP0 pid=429287) 	shfl.sync.bfly.b32 	%r62, %r47, 8, 31, -1;
(EngineCore_DP0 pid=429287) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	max.f32 	%r63, %r47, %r62;
(EngineCore_DP0 pid=429287) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	shfl.sync.bfly.b32 	%r64, %r63, 4, 31, -1;
(EngineCore_DP0 pid=429287) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=429287) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	shfl.sync.bfly.b32 	%r66, %r65, 2, 31, -1;
(EngineCore_DP0 pid=429287) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=429287) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	shfl.sync.bfly.b32 	%r68, %r67, 1, 31, -1;
(EngineCore_DP0 pid=429287) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	max.f32 	%r50, %r67, %r68;
(EngineCore_DP0 pid=429287) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=429287) 	// begin inline asm
(EngineCore_DP0 pid=429287) 	@%p27 st.shared.b32 [ %r48 + 0 ], %r50;
(EngineCore_DP0 pid=429287) 	// end inline asm
(EngineCore_DP0 pid=429287) 	bar.sync 	0;
(EngineCore_DP0 pid=429287) 	ld.shared.b32 	%r69, [global_smem];
(EngineCore_DP0 pid=429287) $L__tmp2:
(EngineCore_DP0 pid=429287) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=429287) 	max.f32 	%r156, %r156, %r69;
(EngineCore_DP0 pid=429287) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=429287) 	add.s32 	%r157, %r157, 4096;
(EngineCore_DP0 pid=429287) 	setp.lt.s32 	%p6, %r157, %r20;
(EngineCore_DP0 pid=429287) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=429287) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=429287) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=429287) 	max.f32 	%r158, %r156, 0f2B8CBCCC;
(EngineCore_DP0 pid=429287) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=429287) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=429287) 	mov.b32 	%r71, 0f42FE0000;
(EngineCore_DP0 pid=429287) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=429287) 	div.full.f32 	%r72, %r158, %r71;
(EngineCore_DP0 pid=429287) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=429287) 	max.f32 	%r70, %r72, 0f37810204;
(EngineCore_DP0 pid=429287) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=429287) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=429287) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=429287) 	// begin inline asm
(EngineCore_DP0 pid=429287) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r70 };
(EngineCore_DP0 pid=429287) 	// end inline asm
(EngineCore_DP0 pid=429287) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=429287) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=429287) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=429287) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=429287) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=429287) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=429287) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=429287) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=429287) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=429287) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=429287) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=429287) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=429287) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=429287) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=429287) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=429287) 	div.full.f32 	%r14, %r71, %r158;
(EngineCore_DP0 pid=429287) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=429287) 	mov.b32 	%r159, 0;
(EngineCore_DP0 pid=429287) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=429287)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=429287) 	.loc	1 279 31                        // quant_slide_tuned_Qwen2.5-7B.py:279:31
(EngineCore_DP0 pid=429287) 	add.s32 	%r76, %r16, %r159;
(EngineCore_DP0 pid=429287) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=429287) 	add.s32 	%r77, %r159, 1;
(EngineCore_DP0 pid=429287) 	setp.lt.s32 	%p17, %r76, %r15;
(EngineCore_DP0 pid=429287) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=429287) 	shr.u32 	%r78, %r76, 1;
(EngineCore_DP0 pid=429287) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=429287) 	shr.u32 	%r79, %r77, 31;
(EngineCore_DP0 pid=429287) 	add.s32 	%r80, %r77, %r79;
(EngineCore_DP0 pid=429287) 	and.b32 	%r81, %r80, 2147483646;
(EngineCore_DP0 pid=429287) 	sub.s32 	%r82, %r77, %r81;
(EngineCore_DP0 pid=429287) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=429287) 	mul.lo.s32 	%r83, %r78, 6;
(EngineCore_DP0 pid=429287) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=429287) 	shl.b32 	%r84, %r82, 1;
(EngineCore_DP0 pid=429287) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=429287) 	add.s32 	%r85, %r83, %r84;
(EngineCore_DP0 pid=429287) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=429287) 	setp.lt.s32 	%p18, %r83, %r19;
(EngineCore_DP0 pid=429287) 	setp.lt.s32 	%p19, %r85, %r19;
(EngineCore_DP0 pid=429287) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=429287) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=429287) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=429287) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=429287) 	mad.wide.s32 	%rd8, %r83, 2, %rd1;
(EngineCore_DP0 pid=429287) 	mad.wide.s32 	%rd9, %r85, 2, %rd1;
(EngineCore_DP0 pid=429287) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=429287) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=429287) 	// begin inline asm
(EngineCore_DP0 pid=429287) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=429287) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=429287) 	// end inline asm
(EngineCore_DP0 pid=429287) 	// begin inline asm
(EngineCore_DP0 pid=429287) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=429287) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=429287) 	// end inline asm
(EngineCore_DP0 pid=429287) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=429287) 	cvt.f32.bf16 	%r86, %rs24;
(EngineCore_DP0 pid=429287) 	cvt.f32.bf16 	%r87, %rs26;
(EngineCore_DP0 pid=429287) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=429287) 	or.b32 	%r88, %r83, 1;
(EngineCore_DP0 pid=429287) 	or.b32 	%r89, %r85, 1;
(EngineCore_DP0 pid=429287) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=429287) 	setp.lt.s32 	%p20, %r88, %r19;
(EngineCore_DP0 pid=429287) 	setp.lt.s32 	%p21, %r89, %r19;
(EngineCore_DP0 pid=429287) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=429287) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=429287) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=429287) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=429287) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=429287) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=429287) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=429287) 	// begin inline asm
(EngineCore_DP0 pid=429287) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=429287) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=429287) 	// end inline asm
(EngineCore_DP0 pid=429287) 	// begin inline asm
(EngineCore_DP0 pid=429287) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=429287) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=429287) 	// end inline asm
(EngineCore_DP0 pid=429287) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=429287) 	cvt.f32.bf16 	%r90, %rs28;
(EngineCore_DP0 pid=429287) 	cvt.f32.bf16 	%r91, %rs30;
(EngineCore_DP0 pid=429287) 	.loc	1 292 48                        // quant_slide_tuned_Qwen2.5-7B.py:292:48
(EngineCore_DP0 pid=429287) 	add.s32 	%r92, %r83, 2;
(EngineCore_DP0 pid=429287) 	add.s32 	%r93, %r85, 2;
(EngineCore_DP0 pid=429287) 	.loc	1 292 53                        // quant_slide_tuned_Qwen2.5-7B.py:292:53
(EngineCore_DP0 pid=429287) 	setp.lt.s32 	%p22, %r92, %r19;
(EngineCore_DP0 pid=429287) 	setp.lt.s32 	%p23, %r93, %r19;
(EngineCore_DP0 pid=429287) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=429287) 	and.pred 	%p13, %p17, %p22;
(EngineCore_DP0 pid=429287) 	and.pred 	%p14, %p17, %p23;
(EngineCore_DP0 pid=429287) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=429287) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=429287) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=429287) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=429287) 	// begin inline asm
(EngineCore_DP0 pid=429287) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=429287) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=429287) 	// end inline asm
(EngineCore_DP0 pid=429287) 	// begin inline asm
(EngineCore_DP0 pid=429287) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=429287) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=429287) 	// end inline asm
(EngineCore_DP0 pid=429287) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=429287) 	cvt.f32.bf16 	%r94, %rs32;
(EngineCore_DP0 pid=429287) 	cvt.f32.bf16 	%r95, %rs34;
(EngineCore_DP0 pid=429287) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=429287) 	add.s32 	%r96, %r83, 3;
(EngineCore_DP0 pid=429287) 	add.s32 	%r97, %r85, 3;
(EngineCore_DP0 pid=429287) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=429287) 	setp.lt.s32 	%p24, %r96, %r19;
(EngineCore_DP0 pid=429287) 	setp.lt.s32 	%p25, %r97, %r19;
(EngineCore_DP0 pid=429287) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=429287) 	and.pred 	%p15, %p17, %p24;
(EngineCore_DP0 pid=429287) 	and.pred 	%p16, %p17, %p25;
(EngineCore_DP0 pid=429287) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=429287) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=429287) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=429287) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=429287) 	// begin inline asm
(EngineCore_DP0 pid=429287) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=429287) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=429287) 	// end inline asm
(EngineCore_DP0 pid=429287) 	// begin inline asm
(EngineCore_DP0 pid=429287) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=429287) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=429287) 	// end inline asm
(EngineCore_DP0 pid=429287) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=429287) 	cvt.f32.bf16 	%r98, %rs36;
(EngineCore_DP0 pid=429287) 	cvt.f32.bf16 	%r99, %rs38;
(EngineCore_DP0 pid=429287) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=429287) 	mul.f32 	%r100, %r14, %r86;
(EngineCore_DP0 pid=429287) 	mul.f32 	%r101, %r14, %r87;
(EngineCore_DP0 pid=429287) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=429287) 	cvt.rni.f32.f32 	%r102, %r100;
(EngineCore_DP0 pid=429287) 	cvt.rni.f32.f32 	%r103, %r101;
(EngineCore_DP0 pid=429287) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=429287) 	max.f32 	%r104, %r102, 0fC3000000;
(EngineCore_DP0 pid=429287) 	min.f32 	%r105, %r104, 0f42FE0000;
(EngineCore_DP0 pid=429287) 	max.f32 	%r106, %r103, 0fC3000000;
(EngineCore_DP0 pid=429287) 	min.f32 	%r107, %r106, 0f42FE0000;
(EngineCore_DP0 pid=429287) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=429287) 	cvt.rzi.s32.f32 	%r108, %r105;
(EngineCore_DP0 pid=429287) 	cvt.rzi.s32.f32 	%r109, %r107;
(EngineCore_DP0 pid=429287) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=429287) 	and.b32 	%r110, %r108, 255;
(EngineCore_DP0 pid=429287) 	and.b32 	%r111, %r109, 255;
(EngineCore_DP0 pid=429287) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=429287) 	mul.f32 	%r112, %r14, %r90;
(EngineCore_DP0 pid=429287) 	mul.f32 	%r113, %r14, %r91;
(EngineCore_DP0 pid=429287) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=429287) 	cvt.rni.f32.f32 	%r114, %r112;
(EngineCore_DP0 pid=429287) 	cvt.rni.f32.f32 	%r115, %r113;
(EngineCore_DP0 pid=429287) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=429287) 	mul.f32 	%r116, %r14, %r94;
(EngineCore_DP0 pid=429287) 	mul.f32 	%r117, %r14, %r95;
(EngineCore_DP0 pid=429287) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=429287) 	cvt.rni.f32.f32 	%r118, %r116;
(EngineCore_DP0 pid=429287) 	cvt.rni.f32.f32 	%r119, %r117;
(EngineCore_DP0 pid=429287) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=429287) 	mul.f32 	%r120, %r14, %r98;
(EngineCore_DP0 pid=429287) 	mul.f32 	%r121, %r14, %r99;
(EngineCore_DP0 pid=429287) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=429287) 	cvt.rni.f32.f32 	%r122, %r120;
(EngineCore_DP0 pid=429287) 	cvt.rni.f32.f32 	%r123, %r121;
(EngineCore_DP0 pid=429287) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=429287) 	max.f32 	%r124, %r122, 0fC3000000;
(EngineCore_DP0 pid=429287) 	min.f32 	%r125, %r124, 0f42FE0000;
(EngineCore_DP0 pid=429287) 	max.f32 	%r126, %r123, 0fC3000000;
(EngineCore_DP0 pid=429287) 	min.f32 	%r127, %r126, 0f42FE0000;
(EngineCore_DP0 pid=429287) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=429287) 	cvt.rzi.s32.f32 	%r128, %r125;
(EngineCore_DP0 pid=429287) 	cvt.rzi.s32.f32 	%r129, %r127;
(EngineCore_DP0 pid=429287) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=429287) 	max.f32 	%r130, %r118, 0fC3000000;
(EngineCore_DP0 pid=429287) 	max.f32 	%r131, %r114, 0fC3000000;
(EngineCore_DP0 pid=429287) 	min.f32 	%r132, %r131, 0f42FE0000;
(EngineCore_DP0 pid=429287) 	min.f32 	%r133, %r130, 0f42FE0000;
(EngineCore_DP0 pid=429287) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=429287) 	cvt.rzi.s32.f32 	%r134, %r133;
(EngineCore_DP0 pid=429287) 	cvt.rzi.s32.f32 	%r135, %r132;
(EngineCore_DP0 pid=429287) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=429287) 	shl.b32 	%r136, %r135, 8;
(EngineCore_DP0 pid=429287) 	shl.b32 	%r137, %r134, 16;
(EngineCore_DP0 pid=429287) 	and.b32 	%r138, %r137, 16711680;
(EngineCore_DP0 pid=429287) 	and.b32 	%r139, %r136, 65280;
(EngineCore_DP0 pid=429287) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=429287) 	or.b32 	%r140, %r139, %r110;
(EngineCore_DP0 pid=429287) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=429287) 	max.f32 	%r141, %r119, 0fC3000000;
(EngineCore_DP0 pid=429287) 	max.f32 	%r142, %r115, 0fC3000000;
(EngineCore_DP0 pid=429287) 	min.f32 	%r143, %r142, 0f42FE0000;
(EngineCore_DP0 pid=429287) 	min.f32 	%r144, %r141, 0f42FE0000;
(EngineCore_DP0 pid=429287) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=429287) 	cvt.rzi.s32.f32 	%r145, %r144;
(EngineCore_DP0 pid=429287) 	cvt.rzi.s32.f32 	%r146, %r143;
(EngineCore_DP0 pid=429287) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=429287) 	shl.b32 	%r147, %r146, 8;
(EngineCore_DP0 pid=429287) 	shl.b32 	%r148, %r145, 16;
(EngineCore_DP0 pid=429287) 	and.b32 	%r149, %r148, 16711680;
(EngineCore_DP0 pid=429287) 	and.b32 	%r150, %r147, 65280;
(EngineCore_DP0 pid=429287) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=429287) 	or.b32 	%r151, %r150, %r111;
(EngineCore_DP0 pid=429287) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=429287) 	or.b32 	%r152, %r140, %r138;
(EngineCore_DP0 pid=429287) 	or.b32 	%r153, %r151, %r149;
(EngineCore_DP0 pid=429287) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=429287) 	shl.b32 	%r154, %r128, 24;
(EngineCore_DP0 pid=429287) 	shl.b32 	%r155, %r129, 24;
(EngineCore_DP0 pid=429287) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=429287) 	or.b32 	%r74, %r152, %r154;
(EngineCore_DP0 pid=429287) 	or.b32 	%r75, %r153, %r155;
(EngineCore_DP0 pid=429287) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=429287) 	mad.wide.s32 	%rd16, %r76, 4, %rd2;
(EngineCore_DP0 pid=429287) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=429287) 	// begin inline asm
(EngineCore_DP0 pid=429287) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r74, %r75 };
(EngineCore_DP0 pid=429287) 	// end inline asm
(EngineCore_DP0 pid=429287) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=429287) 	add.s32 	%r159, %r159, 1024;
(EngineCore_DP0 pid=429287) 	setp.lt.s32 	%p26, %r159, %r15;
(EngineCore_DP0 pid=429287) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=429287) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=429287) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=429287) 	ret;
(EngineCore_DP0 pid=429287) $L__tmp3:
(EngineCore_DP0 pid=429287) $L__func_end0:
(EngineCore_DP0 pid=429287)                                         // -- End function
(EngineCore_DP0 pid=429287) }
(EngineCore_DP0 pid=429287) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=429287) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=429287) 	.section	.debug_abbrev
(EngineCore_DP0 pid=429287) 	{
(EngineCore_DP0 pid=429287) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=429287) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=429287) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=429287) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=429287) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=429287) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=429287) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=429287) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=429287) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=429287) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=429287) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=429287) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=429287) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=429287) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=429287) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=429287) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=429287) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=429287) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=429287) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=429287) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=429287) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=429287) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=429287) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=429287) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=429287) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=429287) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=429287) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=429287) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=429287) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=429287) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=429287) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=429287) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=429287) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=429287) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=429287) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=429287) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=429287) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=429287) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=429287) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=429287) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=429287) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=429287) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=429287) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=429287) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=429287) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=429287) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=429287) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=429287) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=429287) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=429287) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=429287) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=429287) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=429287) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=429287) 	}
(EngineCore_DP0 pid=429287) 	.section	.debug_info
(EngineCore_DP0 pid=429287) 	{
(EngineCore_DP0 pid=429287) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=429287) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=429287) .b8 0
(EngineCore_DP0 pid=429287) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=429287) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=429287) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=429287) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=429287) .b8 114
(EngineCore_DP0 pid=429287) .b8 105
(EngineCore_DP0 pid=429287) .b8 116
(EngineCore_DP0 pid=429287) .b8 111
(EngineCore_DP0 pid=429287) .b8 110
(EngineCore_DP0 pid=429287) .b8 0
(EngineCore_DP0 pid=429287) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=429287) .b8 0
(EngineCore_DP0 pid=429287) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=429287) .b8 117
(EngineCore_DP0 pid=429287) .b8 97
(EngineCore_DP0 pid=429287) .b8 110
(EngineCore_DP0 pid=429287) .b8 116
(EngineCore_DP0 pid=429287) .b8 95
(EngineCore_DP0 pid=429287) .b8 115
(EngineCore_DP0 pid=429287) .b8 108
(EngineCore_DP0 pid=429287) .b8 105
(EngineCore_DP0 pid=429287) .b8 100
(EngineCore_DP0 pid=429287) .b8 101
(EngineCore_DP0 pid=429287) .b8 95
(EngineCore_DP0 pid=429287) .b8 116
(EngineCore_DP0 pid=429287) .b8 117
(EngineCore_DP0 pid=429287) .b8 110
(EngineCore_DP0 pid=429287) .b8 101
(EngineCore_DP0 pid=429287) .b8 100
(EngineCore_DP0 pid=429287) .b8 95
(EngineCore_DP0 pid=429287) .b8 81
(EngineCore_DP0 pid=429287) .b8 119
(EngineCore_DP0 pid=429287) .b8 101
(EngineCore_DP0 pid=429287) .b8 110
(EngineCore_DP0 pid=429287) .b8 50
(EngineCore_DP0 pid=429287) .b8 46
(EngineCore_DP0 pid=429287) .b8 53
(EngineCore_DP0 pid=429287) .b8 45
(EngineCore_DP0 pid=429287) .b8 55
(EngineCore_DP0 pid=429287) .b8 66
(EngineCore_DP0 pid=429287) .b8 46
(EngineCore_DP0 pid=429287) .b8 112
(EngineCore_DP0 pid=429287) .b8 121
(EngineCore_DP0 pid=429287) .b8 0
(EngineCore_DP0 pid=429287) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=429287) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=429287) .b8 114
(EngineCore_DP0 pid=429287) .b8 111
(EngineCore_DP0 pid=429287) .b8 111
(EngineCore_DP0 pid=429287) .b8 116
(EngineCore_DP0 pid=429287) .b8 47
(EngineCore_DP0 pid=429287) .b8 118
(EngineCore_DP0 pid=429287) .b8 108
(EngineCore_DP0 pid=429287) .b8 108
(EngineCore_DP0 pid=429287) .b8 109
(EngineCore_DP0 pid=429287) .b8 98
(EngineCore_DP0 pid=429287) .b8 101
(EngineCore_DP0 pid=429287) .b8 110
(EngineCore_DP0 pid=429287) .b8 99
(EngineCore_DP0 pid=429287) .b8 104
(EngineCore_DP0 pid=429287) .b8 47
(EngineCore_DP0 pid=429287) .b8 115
(EngineCore_DP0 pid=429287) .b8 108
(EngineCore_DP0 pid=429287) .b8 105
(EngineCore_DP0 pid=429287) .b8 100
(EngineCore_DP0 pid=429287) .b8 101
(EngineCore_DP0 pid=429287) .b8 115
(EngineCore_DP0 pid=429287) .b8 112
(EngineCore_DP0 pid=429287) .b8 97
(EngineCore_DP0 pid=429287) .b8 114
(EngineCore_DP0 pid=429287) .b8 115
(EngineCore_DP0 pid=429287) .b8 101
(EngineCore_DP0 pid=429287) .b8 47
(EngineCore_DP0 pid=429287) .b8 99
(EngineCore_DP0 pid=429287) .b8 115
(EngineCore_DP0 pid=429287) .b8 114
(EngineCore_DP0 pid=429287) .b8 99
(EngineCore_DP0 pid=429287) .b8 47
(EngineCore_DP0 pid=429287) .b8 102
(EngineCore_DP0 pid=429287) .b8 117
(EngineCore_DP0 pid=429287) .b8 115
(EngineCore_DP0 pid=429287) .b8 101
(EngineCore_DP0 pid=429287) .b8 100
(EngineCore_DP0 pid=429287) .b8 95
(EngineCore_DP0 pid=429287) .b8 113
(EngineCore_DP0 pid=429287) .b8 117
(EngineCore_DP0 pid=429287) .b8 97
(EngineCore_DP0 pid=429287) .b8 110
(EngineCore_DP0 pid=429287) .b8 116
(EngineCore_DP0 pid=429287) .b8 95
(EngineCore_DP0 pid=429287) .b8 115
(EngineCore_DP0 pid=429287) .b8 108
(EngineCore_DP0 pid=429287) .b8 105
(EngineCore_DP0 pid=429287) .b8 100
(EngineCore_DP0 pid=429287) .b8 101
(EngineCore_DP0 pid=429287) .b8 95
(EngineCore_DP0 pid=429287) .b8 116
(EngineCore_DP0 pid=429287) .b8 114
(EngineCore_DP0 pid=429287) .b8 105
(EngineCore_DP0 pid=429287) .b8 116
(EngineCore_DP0 pid=429287) .b8 111
(EngineCore_DP0 pid=429287) .b8 110
(EngineCore_DP0 pid=429287) .b8 47
(EngineCore_DP0 pid=429287) .b8 98
(EngineCore_DP0 pid=429287) .b8 117
(EngineCore_DP0 pid=429287) .b8 105
(EngineCore_DP0 pid=429287) .b8 108
(EngineCore_DP0 pid=429287) .b8 100
(EngineCore_DP0 pid=429287) .b8 47
(EngineCore_DP0 pid=429287) .b8 71
(EngineCore_DP0 pid=429287) .b8 66
(EngineCore_DP0 pid=429287) .b8 49
(EngineCore_DP0 pid=429287) .b8 48
(EngineCore_DP0 pid=429287) .b8 95
(EngineCore_DP0 pid=429287) .b8 99
(EngineCore_DP0 pid=429287) .b8 99
(EngineCore_DP0 pid=429287) .b8 49
(EngineCore_DP0 pid=429287) .b8 50
(EngineCore_DP0 pid=429287) .b8 49
(EngineCore_DP0 pid=429287) .b8 95
(EngineCore_DP0 pid=429287) .b8 112
(EngineCore_DP0 pid=429287) .b8 121
(EngineCore_DP0 pid=429287) .b8 51
(EngineCore_DP0 pid=429287) .b8 49
(EngineCore_DP0 pid=429287) .b8 50
(EngineCore_DP0 pid=429287) .b8 95
(EngineCore_DP0 pid=429287) .b8 99
(EngineCore_DP0 pid=429287) .b8 117
(EngineCore_DP0 pid=429287) .b8 49
(EngineCore_DP0 pid=429287) .b8 50
(EngineCore_DP0 pid=429287) .b8 57
(EngineCore_DP0 pid=429287) .b8 95
(EngineCore_DP0 pid=429287) .b8 97
(EngineCore_DP0 pid=429287) .b8 97
(EngineCore_DP0 pid=429287) .b8 114
(EngineCore_DP0 pid=429287) .b8 99
(EngineCore_DP0 pid=429287) .b8 104
(EngineCore_DP0 pid=429287) .b8 54
(EngineCore_DP0 pid=429287) .b8 52
(EngineCore_DP0 pid=429287) .b8 0
(EngineCore_DP0 pid=429287) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=429287) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=429287) .b8 113
(EngineCore_DP0 pid=429287) .b8 117
(EngineCore_DP0 pid=429287) .b8 97
(EngineCore_DP0 pid=429287) .b8 110
(EngineCore_DP0 pid=429287) .b8 116
(EngineCore_DP0 pid=429287) .b8 95
(EngineCore_DP0 pid=429287) .b8 115
(EngineCore_DP0 pid=429287) .b8 108
(EngineCore_DP0 pid=429287) .b8 105
(EngineCore_DP0 pid=429287) .b8 100
(EngineCore_DP0 pid=429287) .b8 101
(EngineCore_DP0 pid=429287) .b8 95
(EngineCore_DP0 pid=429287) .b8 105
(EngineCore_DP0 pid=429287) .b8 110
(EngineCore_DP0 pid=429287) .b8 116
(EngineCore_DP0 pid=429287) .b8 56
(EngineCore_DP0 pid=429287) .b8 95
(EngineCore_DP0 pid=429287) .b8 107
(EngineCore_DP0 pid=429287) .b8 101
(EngineCore_DP0 pid=429287) .b8 114
(EngineCore_DP0 pid=429287) .b8 110
(EngineCore_DP0 pid=429287) .b8 101
(EngineCore_DP0 pid=429287) .b8 108
(EngineCore_DP0 pid=429287) .b8 0
(EngineCore_DP0 pid=429287) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=429287) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=429287) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=429287) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=429287) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=429287) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=429287) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=429287) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=429287) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=429287) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=429287) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=429287) .b8 1
(EngineCore_DP0 pid=429287) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=429287) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=429287) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=429287) 	}
(EngineCore_DP0 pid=429287) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=429287) 
(EngineCore_DP0 pid=429287) ================================================================
(EngineCore_DP0 pid=429287) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=429287) 
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpytnmya80.ptx', '-o', '/tmp/tmpytnmya80.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866] 
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866] 
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866] 
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpytnmya80.ptx -o /tmp/tmpytnmya80.ptx.o
(EngineCore_DP0 pid=429287) ERROR 01-25 20:40:09 [core.py:866] 

STDERR:
[2026-01-25 20:39:04] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:39:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:39:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:39:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:39:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:39:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:39:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:39:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:39:07] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:39:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:39:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:39:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:39:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:39:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:39:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:39:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=429287) [2026-01-25 20:39:08] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=429287) [2026-01-25 20:39:08] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=429287) [2026-01-25 20:39:08] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=429287) [2026-01-25 20:39:08] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=429287) [2026-01-25 20:39:08] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=429287) [2026-01-25 20:39:08] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=429287) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=429287) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:23<00:23, 23.84s/it]
(EngineCore_DP0 pid=429287) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:57<00:00, 29.53s/it]
(EngineCore_DP0 pid=429287) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:57<00:00, 28.68s/it]
(EngineCore_DP0 pid=429287) 
(EngineCore_DP0 pid=429287) [2026-01-25 20:40:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=429287) [2026-01-25 20:40:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=429287) [2026-01-25 20:40:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=429287) [2026-01-25 20:40:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=429287) [2026-01-25 20:40:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=429287) [2026-01-25 20:40:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=429287) [2026-01-25 20:40:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=429287) [2026-01-25 20:40:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=429287) Process EngineCore_DP0:
(EngineCore_DP0 pid=429287) Traceback (most recent call last):
(EngineCore_DP0 pid=429287)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=429287)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=429287)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=429287)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=429287) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpytnmya80.ptx', '-o', '/tmp/tmpytnmya80.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=429287) 
(EngineCore_DP0 pid=429287) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=429287) 
(EngineCore_DP0 pid=429287) Traceback (most recent call last):
(EngineCore_DP0 pid=429287)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=429287)     self.run()
(EngineCore_DP0 pid=429287)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=429287)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=429287)     raise e
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=429287)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=429287)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=429287)     super().__init__(
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=429287)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=429287)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=429287)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=429287)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=429287)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=429287)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=429287)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=429287)     return func(*args, **kwargs)
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=429287)     return func(*args, **kwargs)
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=429287)     self.model_runner.profile_run()
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=429287)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=429287)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=429287)     return func(*args, **kwargs)
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=429287)     outputs = self.model(
(EngineCore_DP0 pid=429287)               ^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=429287)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=429287)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=429287)     hidden_states = self.model(
(EngineCore_DP0 pid=429287)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=429287)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=429287)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=429287)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=429287)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=429287)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=429287)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=429287)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=429287)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=429287)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=429287)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=429287)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=429287)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=429287)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=429287)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=429287)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=429287)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=429287)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=429287)     return self._linear_fn(
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=429287)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=429287)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=429287)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=429287)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=429287)     return fn(input, L)
(EngineCore_DP0 pid=429287)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=429287)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=429287)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=429287)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=429287)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=429287)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=429287)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=429287)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=429287)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=429287)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=429287)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=429287)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=429287)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=429287)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=429287)     raise PTXASError(error)
(EngineCore_DP0 pid=429287) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=429287) `ptxas` stderr:
(EngineCore_DP0 pid=429287) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=429287) 
(EngineCore_DP0 pid=429287) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpytnmya80.ptx -o /tmp/tmpytnmya80.ptx.o
(EngineCore_DP0 pid=429287) 
[rank0]:[W125 20:40:09.814078342 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 20:40:11
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:40:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:40:16 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=430478) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=430478) 
(EngineCore_DP0 pid=430478) 
(EngineCore_DP0 pid=430478) ================================================================
(EngineCore_DP0 pid=430478) Internal Triton PTX codegen error
(EngineCore_DP0 pid=430478) `ptxas` stderr:
(EngineCore_DP0 pid=430478) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=430478) 
(EngineCore_DP0 pid=430478) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpou3l2qp4.ptx -o /tmp/tmpou3l2qp4.ptx.o
(EngineCore_DP0 pid=430478) 
(EngineCore_DP0 pid=430478) 
(EngineCore_DP0 pid=430478) //
(EngineCore_DP0 pid=430478) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=430478) //
(EngineCore_DP0 pid=430478) 
(EngineCore_DP0 pid=430478) .version 8.7
(EngineCore_DP0 pid=430478) .target sm_121a
(EngineCore_DP0 pid=430478) .address_size 64
(EngineCore_DP0 pid=430478) 
(EngineCore_DP0 pid=430478) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=430478) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=430478)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=430478) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=430478) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=430478) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=430478) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=430478) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=430478) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=430478) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=430478) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=430478) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=430478) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=430478) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=430478) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=430478) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=430478) )
(EngineCore_DP0 pid=430478) .reqntid 512
(EngineCore_DP0 pid=430478) {
(EngineCore_DP0 pid=430478) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=430478) 	.reg .b16 	%rs<40>;
(EngineCore_DP0 pid=430478) 	.reg .b32 	%r<160>;
(EngineCore_DP0 pid=430478) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=430478) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=430478) $L__func_begin0:
(EngineCore_DP0 pid=430478) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=430478) 
(EngineCore_DP0 pid=430478) // %bb.0:
(EngineCore_DP0 pid=430478) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=430478) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=430478) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=430478) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=430478) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=430478) $L__tmp0:
(EngineCore_DP0 pid=430478) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=430478) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=430478) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=430478) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=430478) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=430478) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=430478) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=430478) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=430478) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=430478) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=430478) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=430478) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=430478) 	mov.b32 	%r158, 0f2B8CBCCC;
(EngineCore_DP0 pid=430478) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=430478) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=430478) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=430478) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=430478) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=430478) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=430478) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=430478) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=430478) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=430478) 	add.s32 	%r45, %r35, %r34;
(EngineCore_DP0 pid=430478) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=430478) 	add.s32 	%r48, %r35, %r36;
(EngineCore_DP0 pid=430478) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=430478) 	mov.b32 	%r156, 0f00000000;
(EngineCore_DP0 pid=430478) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=430478) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=430478) 	mov.b32 	%r157, %r41;
(EngineCore_DP0 pid=430478) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=430478) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=430478) 	add.s32 	%r51, %r4, %r157;
(EngineCore_DP0 pid=430478) 	setp.lt.s32 	%p2, %r51, %r19;
(EngineCore_DP0 pid=430478) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=430478) 	mad.wide.s32 	%rd6, %r51, 2, %rd1;
(EngineCore_DP0 pid=430478) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=430478) 	// begin inline asm
(EngineCore_DP0 pid=430478) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=430478) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=430478) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=430478) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=430478) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=430478) 	// end inline asm
(EngineCore_DP0 pid=430478) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=430478) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=430478) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=430478) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=430478) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=430478) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=430478) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=430478) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=430478) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=430478) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=430478) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=430478) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=430478) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=430478) $L__tmp1:
(EngineCore_DP0 pid=430478) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	bar.sync 	0;
(EngineCore_DP0 pid=430478) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=430478) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=430478) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=430478) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=430478) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=430478) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=430478) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=430478) 	cvt.f32.bf16 	%r52, %rs23;
(EngineCore_DP0 pid=430478) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	shfl.sync.bfly.b32 	%r53, %r52, 16, 31, -1;
(EngineCore_DP0 pid=430478) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=430478) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	shfl.sync.bfly.b32 	%r55, %r54, 8, 31, -1;
(EngineCore_DP0 pid=430478) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=430478) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	shfl.sync.bfly.b32 	%r57, %r56, 4, 31, -1;
(EngineCore_DP0 pid=430478) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=430478) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	shfl.sync.bfly.b32 	%r59, %r58, 2, 31, -1;
(EngineCore_DP0 pid=430478) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=430478) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	shfl.sync.bfly.b32 	%r61, %r60, 1, 31, -1;
(EngineCore_DP0 pid=430478) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	max.f32 	%r46, %r60, %r61;
(EngineCore_DP0 pid=430478) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	// begin inline asm
(EngineCore_DP0 pid=430478) 	@%p3 st.shared.b32 [ %r45 + 0 ], %r46;
(EngineCore_DP0 pid=430478) 	// end inline asm
(EngineCore_DP0 pid=430478) 	bar.sync 	0;
(EngineCore_DP0 pid=430478) 	// begin inline asm
(EngineCore_DP0 pid=430478) 	@%p4 ld.shared.b32 %r47, [ %r48 + 0 ];
(EngineCore_DP0 pid=430478) 	// end inline asm
(EngineCore_DP0 pid=430478) 	shfl.sync.bfly.b32 	%r62, %r47, 8, 31, -1;
(EngineCore_DP0 pid=430478) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	max.f32 	%r63, %r47, %r62;
(EngineCore_DP0 pid=430478) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	shfl.sync.bfly.b32 	%r64, %r63, 4, 31, -1;
(EngineCore_DP0 pid=430478) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=430478) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	shfl.sync.bfly.b32 	%r66, %r65, 2, 31, -1;
(EngineCore_DP0 pid=430478) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=430478) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	shfl.sync.bfly.b32 	%r68, %r67, 1, 31, -1;
(EngineCore_DP0 pid=430478) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	max.f32 	%r50, %r67, %r68;
(EngineCore_DP0 pid=430478) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=430478) 	// begin inline asm
(EngineCore_DP0 pid=430478) 	@%p27 st.shared.b32 [ %r48 + 0 ], %r50;
(EngineCore_DP0 pid=430478) 	// end inline asm
(EngineCore_DP0 pid=430478) 	bar.sync 	0;
(EngineCore_DP0 pid=430478) 	ld.shared.b32 	%r69, [global_smem];
(EngineCore_DP0 pid=430478) $L__tmp2:
(EngineCore_DP0 pid=430478) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=430478) 	max.f32 	%r156, %r156, %r69;
(EngineCore_DP0 pid=430478) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=430478) 	add.s32 	%r157, %r157, 4096;
(EngineCore_DP0 pid=430478) 	setp.lt.s32 	%p6, %r157, %r20;
(EngineCore_DP0 pid=430478) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=430478) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=430478) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=430478) 	max.f32 	%r158, %r156, 0f2B8CBCCC;
(EngineCore_DP0 pid=430478) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=430478) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=430478) 	mov.b32 	%r71, 0f42FE0000;
(EngineCore_DP0 pid=430478) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=430478) 	div.full.f32 	%r72, %r158, %r71;
(EngineCore_DP0 pid=430478) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=430478) 	max.f32 	%r70, %r72, 0f37810204;
(EngineCore_DP0 pid=430478) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=430478) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=430478) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=430478) 	// begin inline asm
(EngineCore_DP0 pid=430478) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r70 };
(EngineCore_DP0 pid=430478) 	// end inline asm
(EngineCore_DP0 pid=430478) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=430478) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=430478) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=430478) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=430478) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=430478) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=430478) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=430478) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=430478) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=430478) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=430478) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=430478) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=430478) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=430478) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=430478) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=430478) 	div.full.f32 	%r14, %r71, %r158;
(EngineCore_DP0 pid=430478) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=430478) 	mov.b32 	%r159, 0;
(EngineCore_DP0 pid=430478) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=430478)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=430478) 	.loc	1 279 31                        // quant_slide_tuned_Qwen2.5-7B.py:279:31
(EngineCore_DP0 pid=430478) 	add.s32 	%r76, %r16, %r159;
(EngineCore_DP0 pid=430478) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=430478) 	add.s32 	%r77, %r159, 1;
(EngineCore_DP0 pid=430478) 	setp.lt.s32 	%p17, %r76, %r15;
(EngineCore_DP0 pid=430478) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=430478) 	shr.u32 	%r78, %r76, 1;
(EngineCore_DP0 pid=430478) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=430478) 	shr.u32 	%r79, %r77, 31;
(EngineCore_DP0 pid=430478) 	add.s32 	%r80, %r77, %r79;
(EngineCore_DP0 pid=430478) 	and.b32 	%r81, %r80, 2147483646;
(EngineCore_DP0 pid=430478) 	sub.s32 	%r82, %r77, %r81;
(EngineCore_DP0 pid=430478) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=430478) 	mul.lo.s32 	%r83, %r78, 6;
(EngineCore_DP0 pid=430478) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=430478) 	shl.b32 	%r84, %r82, 1;
(EngineCore_DP0 pid=430478) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=430478) 	add.s32 	%r85, %r83, %r84;
(EngineCore_DP0 pid=430478) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=430478) 	setp.lt.s32 	%p18, %r83, %r19;
(EngineCore_DP0 pid=430478) 	setp.lt.s32 	%p19, %r85, %r19;
(EngineCore_DP0 pid=430478) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=430478) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=430478) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=430478) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=430478) 	mad.wide.s32 	%rd8, %r83, 2, %rd1;
(EngineCore_DP0 pid=430478) 	mad.wide.s32 	%rd9, %r85, 2, %rd1;
(EngineCore_DP0 pid=430478) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=430478) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=430478) 	// begin inline asm
(EngineCore_DP0 pid=430478) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=430478) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=430478) 	// end inline asm
(EngineCore_DP0 pid=430478) 	// begin inline asm
(EngineCore_DP0 pid=430478) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=430478) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=430478) 	// end inline asm
(EngineCore_DP0 pid=430478) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=430478) 	cvt.f32.bf16 	%r86, %rs24;
(EngineCore_DP0 pid=430478) 	cvt.f32.bf16 	%r87, %rs26;
(EngineCore_DP0 pid=430478) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=430478) 	or.b32 	%r88, %r83, 1;
(EngineCore_DP0 pid=430478) 	or.b32 	%r89, %r85, 1;
(EngineCore_DP0 pid=430478) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=430478) 	setp.lt.s32 	%p20, %r88, %r19;
(EngineCore_DP0 pid=430478) 	setp.lt.s32 	%p21, %r89, %r19;
(EngineCore_DP0 pid=430478) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=430478) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=430478) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=430478) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=430478) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=430478) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=430478) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=430478) 	// begin inline asm
(EngineCore_DP0 pid=430478) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=430478) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=430478) 	// end inline asm
(EngineCore_DP0 pid=430478) 	// begin inline asm
(EngineCore_DP0 pid=430478) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=430478) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=430478) 	// end inline asm
(EngineCore_DP0 pid=430478) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=430478) 	cvt.f32.bf16 	%r90, %rs28;
(EngineCore_DP0 pid=430478) 	cvt.f32.bf16 	%r91, %rs30;
(EngineCore_DP0 pid=430478) 	.loc	1 292 48                        // quant_slide_tuned_Qwen2.5-7B.py:292:48
(EngineCore_DP0 pid=430478) 	add.s32 	%r92, %r83, 2;
(EngineCore_DP0 pid=430478) 	add.s32 	%r93, %r85, 2;
(EngineCore_DP0 pid=430478) 	.loc	1 292 53                        // quant_slide_tuned_Qwen2.5-7B.py:292:53
(EngineCore_DP0 pid=430478) 	setp.lt.s32 	%p22, %r92, %r19;
(EngineCore_DP0 pid=430478) 	setp.lt.s32 	%p23, %r93, %r19;
(EngineCore_DP0 pid=430478) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=430478) 	and.pred 	%p13, %p17, %p22;
(EngineCore_DP0 pid=430478) 	and.pred 	%p14, %p17, %p23;
(EngineCore_DP0 pid=430478) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=430478) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=430478) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=430478) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=430478) 	// begin inline asm
(EngineCore_DP0 pid=430478) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=430478) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=430478) 	// end inline asm
(EngineCore_DP0 pid=430478) 	// begin inline asm
(EngineCore_DP0 pid=430478) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=430478) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=430478) 	// end inline asm
(EngineCore_DP0 pid=430478) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=430478) 	cvt.f32.bf16 	%r94, %rs32;
(EngineCore_DP0 pid=430478) 	cvt.f32.bf16 	%r95, %rs34;
(EngineCore_DP0 pid=430478) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=430478) 	add.s32 	%r96, %r83, 3;
(EngineCore_DP0 pid=430478) 	add.s32 	%r97, %r85, 3;
(EngineCore_DP0 pid=430478) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=430478) 	setp.lt.s32 	%p24, %r96, %r19;
(EngineCore_DP0 pid=430478) 	setp.lt.s32 	%p25, %r97, %r19;
(EngineCore_DP0 pid=430478) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=430478) 	and.pred 	%p15, %p17, %p24;
(EngineCore_DP0 pid=430478) 	and.pred 	%p16, %p17, %p25;
(EngineCore_DP0 pid=430478) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=430478) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=430478) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=430478) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=430478) 	// begin inline asm
(EngineCore_DP0 pid=430478) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=430478) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=430478) 	// end inline asm
(EngineCore_DP0 pid=430478) 	// begin inline asm
(EngineCore_DP0 pid=430478) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=430478) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=430478) 	// end inline asm
(EngineCore_DP0 pid=430478) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=430478) 	cvt.f32.bf16 	%r98, %rs36;
(EngineCore_DP0 pid=430478) 	cvt.f32.bf16 	%r99, %rs38;
(EngineCore_DP0 pid=430478) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=430478) 	mul.f32 	%r100, %r14, %r86;
(EngineCore_DP0 pid=430478) 	mul.f32 	%r101, %r14, %r87;
(EngineCore_DP0 pid=430478) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=430478) 	cvt.rni.f32.f32 	%r102, %r100;
(EngineCore_DP0 pid=430478) 	cvt.rni.f32.f32 	%r103, %r101;
(EngineCore_DP0 pid=430478) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=430478) 	max.f32 	%r104, %r102, 0fC3000000;
(EngineCore_DP0 pid=430478) 	min.f32 	%r105, %r104, 0f42FE0000;
(EngineCore_DP0 pid=430478) 	max.f32 	%r106, %r103, 0fC3000000;
(EngineCore_DP0 pid=430478) 	min.f32 	%r107, %r106, 0f42FE0000;
(EngineCore_DP0 pid=430478) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=430478) 	cvt.rzi.s32.f32 	%r108, %r105;
(EngineCore_DP0 pid=430478) 	cvt.rzi.s32.f32 	%r109, %r107;
(EngineCore_DP0 pid=430478) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=430478) 	and.b32 	%r110, %r108, 255;
(EngineCore_DP0 pid=430478) 	and.b32 	%r111, %r109, 255;
(EngineCore_DP0 pid=430478) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=430478) 	mul.f32 	%r112, %r14, %r90;
(EngineCore_DP0 pid=430478) 	mul.f32 	%r113, %r14, %r91;
(EngineCore_DP0 pid=430478) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=430478) 	cvt.rni.f32.f32 	%r114, %r112;
(EngineCore_DP0 pid=430478) 	cvt.rni.f32.f32 	%r115, %r113;
(EngineCore_DP0 pid=430478) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=430478) 	mul.f32 	%r116, %r14, %r94;
(EngineCore_DP0 pid=430478) 	mul.f32 	%r117, %r14, %r95;
(EngineCore_DP0 pid=430478) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=430478) 	cvt.rni.f32.f32 	%r118, %r116;
(EngineCore_DP0 pid=430478) 	cvt.rni.f32.f32 	%r119, %r117;
(EngineCore_DP0 pid=430478) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=430478) 	mul.f32 	%r120, %r14, %r98;
(EngineCore_DP0 pid=430478) 	mul.f32 	%r121, %r14, %r99;
(EngineCore_DP0 pid=430478) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=430478) 	cvt.rni.f32.f32 	%r122, %r120;
(EngineCore_DP0 pid=430478) 	cvt.rni.f32.f32 	%r123, %r121;
(EngineCore_DP0 pid=430478) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=430478) 	max.f32 	%r124, %r122, 0fC3000000;
(EngineCore_DP0 pid=430478) 	min.f32 	%r125, %r124, 0f42FE0000;
(EngineCore_DP0 pid=430478) 	max.f32 	%r126, %r123, 0fC3000000;
(EngineCore_DP0 pid=430478) 	min.f32 	%r127, %r126, 0f42FE0000;
(EngineCore_DP0 pid=430478) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=430478) 	cvt.rzi.s32.f32 	%r128, %r125;
(EngineCore_DP0 pid=430478) 	cvt.rzi.s32.f32 	%r129, %r127;
(EngineCore_DP0 pid=430478) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=430478) 	max.f32 	%r130, %r118, 0fC3000000;
(EngineCore_DP0 pid=430478) 	max.f32 	%r131, %r114, 0fC3000000;
(EngineCore_DP0 pid=430478) 	min.f32 	%r132, %r131, 0f42FE0000;
(EngineCore_DP0 pid=430478) 	min.f32 	%r133, %r130, 0f42FE0000;
(EngineCore_DP0 pid=430478) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=430478) 	cvt.rzi.s32.f32 	%r134, %r133;
(EngineCore_DP0 pid=430478) 	cvt.rzi.s32.f32 	%r135, %r132;
(EngineCore_DP0 pid=430478) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=430478) 	shl.b32 	%r136, %r135, 8;
(EngineCore_DP0 pid=430478) 	shl.b32 	%r137, %r134, 16;
(EngineCore_DP0 pid=430478) 	and.b32 	%r138, %r137, 16711680;
(EngineCore_DP0 pid=430478) 	and.b32 	%r139, %r136, 65280;
(EngineCore_DP0 pid=430478) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=430478) 	or.b32 	%r140, %r139, %r110;
(EngineCore_DP0 pid=430478) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=430478) 	max.f32 	%r141, %r119, 0fC3000000;
(EngineCore_DP0 pid=430478) 	max.f32 	%r142, %r115, 0fC3000000;
(EngineCore_DP0 pid=430478) 	min.f32 	%r143, %r142, 0f42FE0000;
(EngineCore_DP0 pid=430478) 	min.f32 	%r144, %r141, 0f42FE0000;
(EngineCore_DP0 pid=430478) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=430478) 	cvt.rzi.s32.f32 	%r145, %r144;
(EngineCore_DP0 pid=430478) 	cvt.rzi.s32.f32 	%r146, %r143;
(EngineCore_DP0 pid=430478) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=430478) 	shl.b32 	%r147, %r146, 8;
(EngineCore_DP0 pid=430478) 	shl.b32 	%r148, %r145, 16;
(EngineCore_DP0 pid=430478) 	and.b32 	%r149, %r148, 16711680;
(EngineCore_DP0 pid=430478) 	and.b32 	%r150, %r147, 65280;
(EngineCore_DP0 pid=430478) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=430478) 	or.b32 	%r151, %r150, %r111;
(EngineCore_DP0 pid=430478) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=430478) 	or.b32 	%r152, %r140, %r138;
(EngineCore_DP0 pid=430478) 	or.b32 	%r153, %r151, %r149;
(EngineCore_DP0 pid=430478) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=430478) 	shl.b32 	%r154, %r128, 24;
(EngineCore_DP0 pid=430478) 	shl.b32 	%r155, %r129, 24;
(EngineCore_DP0 pid=430478) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=430478) 	or.b32 	%r74, %r152, %r154;
(EngineCore_DP0 pid=430478) 	or.b32 	%r75, %r153, %r155;
(EngineCore_DP0 pid=430478) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=430478) 	mad.wide.s32 	%rd16, %r76, 4, %rd2;
(EngineCore_DP0 pid=430478) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=430478) 	// begin inline asm
(EngineCore_DP0 pid=430478) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r74, %r75 };
(EngineCore_DP0 pid=430478) 	// end inline asm
(EngineCore_DP0 pid=430478) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=430478) 	add.s32 	%r159, %r159, 1024;
(EngineCore_DP0 pid=430478) 	setp.lt.s32 	%p26, %r159, %r15;
(EngineCore_DP0 pid=430478) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=430478) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=430478) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=430478) 	ret;
(EngineCore_DP0 pid=430478) $L__tmp3:
(EngineCore_DP0 pid=430478) $L__func_end0:
(EngineCore_DP0 pid=430478)                                         // -- End function
(EngineCore_DP0 pid=430478) }
(EngineCore_DP0 pid=430478) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=430478) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=430478) 	.section	.debug_abbrev
(EngineCore_DP0 pid=430478) 	{
(EngineCore_DP0 pid=430478) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=430478) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=430478) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=430478) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=430478) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=430478) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=430478) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=430478) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=430478) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=430478) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=430478) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=430478) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=430478) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=430478) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=430478) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=430478) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=430478) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=430478) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=430478) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=430478) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=430478) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=430478) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=430478) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=430478) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=430478) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=430478) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=430478) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=430478) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=430478) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=430478) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=430478) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=430478) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=430478) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=430478) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=430478) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=430478) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=430478) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=430478) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=430478) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=430478) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=430478) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=430478) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=430478) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=430478) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=430478) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=430478) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=430478) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=430478) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=430478) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=430478) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=430478) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=430478) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=430478) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=430478) 	}
(EngineCore_DP0 pid=430478) 	.section	.debug_info
(EngineCore_DP0 pid=430478) 	{
(EngineCore_DP0 pid=430478) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=430478) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=430478) .b8 0
(EngineCore_DP0 pid=430478) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=430478) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=430478) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=430478) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=430478) .b8 114
(EngineCore_DP0 pid=430478) .b8 105
(EngineCore_DP0 pid=430478) .b8 116
(EngineCore_DP0 pid=430478) .b8 111
(EngineCore_DP0 pid=430478) .b8 110
(EngineCore_DP0 pid=430478) .b8 0
(EngineCore_DP0 pid=430478) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=430478) .b8 0
(EngineCore_DP0 pid=430478) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=430478) .b8 117
(EngineCore_DP0 pid=430478) .b8 97
(EngineCore_DP0 pid=430478) .b8 110
(EngineCore_DP0 pid=430478) .b8 116
(EngineCore_DP0 pid=430478) .b8 95
(EngineCore_DP0 pid=430478) .b8 115
(EngineCore_DP0 pid=430478) .b8 108
(EngineCore_DP0 pid=430478) .b8 105
(EngineCore_DP0 pid=430478) .b8 100
(EngineCore_DP0 pid=430478) .b8 101
(EngineCore_DP0 pid=430478) .b8 95
(EngineCore_DP0 pid=430478) .b8 116
(EngineCore_DP0 pid=430478) .b8 117
(EngineCore_DP0 pid=430478) .b8 110
(EngineCore_DP0 pid=430478) .b8 101
(EngineCore_DP0 pid=430478) .b8 100
(EngineCore_DP0 pid=430478) .b8 95
(EngineCore_DP0 pid=430478) .b8 81
(EngineCore_DP0 pid=430478) .b8 119
(EngineCore_DP0 pid=430478) .b8 101
(EngineCore_DP0 pid=430478) .b8 110
(EngineCore_DP0 pid=430478) .b8 50
(EngineCore_DP0 pid=430478) .b8 46
(EngineCore_DP0 pid=430478) .b8 53
(EngineCore_DP0 pid=430478) .b8 45
(EngineCore_DP0 pid=430478) .b8 55
(EngineCore_DP0 pid=430478) .b8 66
(EngineCore_DP0 pid=430478) .b8 46
(EngineCore_DP0 pid=430478) .b8 112
(EngineCore_DP0 pid=430478) .b8 121
(EngineCore_DP0 pid=430478) .b8 0
(EngineCore_DP0 pid=430478) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=430478) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=430478) .b8 114
(EngineCore_DP0 pid=430478) .b8 111
(EngineCore_DP0 pid=430478) .b8 111
(EngineCore_DP0 pid=430478) .b8 116
(EngineCore_DP0 pid=430478) .b8 47
(EngineCore_DP0 pid=430478) .b8 118
(EngineCore_DP0 pid=430478) .b8 108
(EngineCore_DP0 pid=430478) .b8 108
(EngineCore_DP0 pid=430478) .b8 109
(EngineCore_DP0 pid=430478) .b8 98
(EngineCore_DP0 pid=430478) .b8 101
(EngineCore_DP0 pid=430478) .b8 110
(EngineCore_DP0 pid=430478) .b8 99
(EngineCore_DP0 pid=430478) .b8 104
(EngineCore_DP0 pid=430478) .b8 47
(EngineCore_DP0 pid=430478) .b8 115
(EngineCore_DP0 pid=430478) .b8 108
(EngineCore_DP0 pid=430478) .b8 105
(EngineCore_DP0 pid=430478) .b8 100
(EngineCore_DP0 pid=430478) .b8 101
(EngineCore_DP0 pid=430478) .b8 115
(EngineCore_DP0 pid=430478) .b8 112
(EngineCore_DP0 pid=430478) .b8 97
(EngineCore_DP0 pid=430478) .b8 114
(EngineCore_DP0 pid=430478) .b8 115
(EngineCore_DP0 pid=430478) .b8 101
(EngineCore_DP0 pid=430478) .b8 47
(EngineCore_DP0 pid=430478) .b8 99
(EngineCore_DP0 pid=430478) .b8 115
(EngineCore_DP0 pid=430478) .b8 114
(EngineCore_DP0 pid=430478) .b8 99
(EngineCore_DP0 pid=430478) .b8 47
(EngineCore_DP0 pid=430478) .b8 102
(EngineCore_DP0 pid=430478) .b8 117
(EngineCore_DP0 pid=430478) .b8 115
(EngineCore_DP0 pid=430478) .b8 101
(EngineCore_DP0 pid=430478) .b8 100
(EngineCore_DP0 pid=430478) .b8 95
(EngineCore_DP0 pid=430478) .b8 113
(EngineCore_DP0 pid=430478) .b8 117
(EngineCore_DP0 pid=430478) .b8 97
(EngineCore_DP0 pid=430478) .b8 110
(EngineCore_DP0 pid=430478) .b8 116
(EngineCore_DP0 pid=430478) .b8 95
(EngineCore_DP0 pid=430478) .b8 115
(EngineCore_DP0 pid=430478) .b8 108
(EngineCore_DP0 pid=430478) .b8 105
(EngineCore_DP0 pid=430478) .b8 100
(EngineCore_DP0 pid=430478) .b8 101
(EngineCore_DP0 pid=430478) .b8 95
(EngineCore_DP0 pid=430478) .b8 116
(EngineCore_DP0 pid=430478) .b8 114
(EngineCore_DP0 pid=430478) .b8 105
(EngineCore_DP0 pid=430478) .b8 116
(EngineCore_DP0 pid=430478) .b8 111
(EngineCore_DP0 pid=430478) .b8 110
(EngineCore_DP0 pid=430478) .b8 47
(EngineCore_DP0 pid=430478) .b8 98
(EngineCore_DP0 pid=430478) .b8 117
(EngineCore_DP0 pid=430478) .b8 105
(EngineCore_DP0 pid=430478) .b8 108
(EngineCore_DP0 pid=430478) .b8 100
(EngineCore_DP0 pid=430478) .b8 47
(EngineCore_DP0 pid=430478) .b8 71
(EngineCore_DP0 pid=430478) .b8 66
(EngineCore_DP0 pid=430478) .b8 49
(EngineCore_DP0 pid=430478) .b8 48
(EngineCore_DP0 pid=430478) .b8 95
(EngineCore_DP0 pid=430478) .b8 99
(EngineCore_DP0 pid=430478) .b8 99
(EngineCore_DP0 pid=430478) .b8 49
(EngineCore_DP0 pid=430478) .b8 50
(EngineCore_DP0 pid=430478) .b8 49
(EngineCore_DP0 pid=430478) .b8 95
(EngineCore_DP0 pid=430478) .b8 112
(EngineCore_DP0 pid=430478) .b8 121
(EngineCore_DP0 pid=430478) .b8 51
(EngineCore_DP0 pid=430478) .b8 49
(EngineCore_DP0 pid=430478) .b8 50
(EngineCore_DP0 pid=430478) .b8 95
(EngineCore_DP0 pid=430478) .b8 99
(EngineCore_DP0 pid=430478) .b8 117
(EngineCore_DP0 pid=430478) .b8 49
(EngineCore_DP0 pid=430478) .b8 50
(EngineCore_DP0 pid=430478) .b8 57
(EngineCore_DP0 pid=430478) .b8 95
(EngineCore_DP0 pid=430478) .b8 97
(EngineCore_DP0 pid=430478) .b8 97
(EngineCore_DP0 pid=430478) .b8 114
(EngineCore_DP0 pid=430478) .b8 99
(EngineCore_DP0 pid=430478) .b8 104
(EngineCore_DP0 pid=430478) .b8 54
(EngineCore_DP0 pid=430478) .b8 52
(EngineCore_DP0 pid=430478) .b8 0
(EngineCore_DP0 pid=430478) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=430478) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=430478) .b8 113
(EngineCore_DP0 pid=430478) .b8 117
(EngineCore_DP0 pid=430478) .b8 97
(EngineCore_DP0 pid=430478) .b8 110
(EngineCore_DP0 pid=430478) .b8 116
(EngineCore_DP0 pid=430478) .b8 95
(EngineCore_DP0 pid=430478) .b8 115
(EngineCore_DP0 pid=430478) .b8 108
(EngineCore_DP0 pid=430478) .b8 105
(EngineCore_DP0 pid=430478) .b8 100
(EngineCore_DP0 pid=430478) .b8 101
(EngineCore_DP0 pid=430478) .b8 95
(EngineCore_DP0 pid=430478) .b8 105
(EngineCore_DP0 pid=430478) .b8 110
(EngineCore_DP0 pid=430478) .b8 116
(EngineCore_DP0 pid=430478) .b8 56
(EngineCore_DP0 pid=430478) .b8 95
(EngineCore_DP0 pid=430478) .b8 107
(EngineCore_DP0 pid=430478) .b8 101
(EngineCore_DP0 pid=430478) .b8 114
(EngineCore_DP0 pid=430478) .b8 110
(EngineCore_DP0 pid=430478) .b8 101
(EngineCore_DP0 pid=430478) .b8 108
(EngineCore_DP0 pid=430478) .b8 0
(EngineCore_DP0 pid=430478) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=430478) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=430478) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=430478) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=430478) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=430478) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=430478) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=430478) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=430478) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=430478) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=430478) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=430478) .b8 1
(EngineCore_DP0 pid=430478) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=430478) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=430478) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=430478) 	}
(EngineCore_DP0 pid=430478) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=430478) 
(EngineCore_DP0 pid=430478) ================================================================
(EngineCore_DP0 pid=430478) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=430478) 
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpou3l2qp4.ptx', '-o', '/tmp/tmpou3l2qp4.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866] 
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866] 
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866] 
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpou3l2qp4.ptx -o /tmp/tmpou3l2qp4.ptx.o
(EngineCore_DP0 pid=430478) ERROR 01-25 20:41:20 [core.py:866] 

STDERR:
[2026-01-25 20:40:16] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:40:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:40:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:40:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:40:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:40:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:40:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:40:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:40:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:40:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:40:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:40:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:40:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:40:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:40:19] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:40:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:40:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:40:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:40:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:40:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:40:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:40:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:40:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:40:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:40:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:40:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:40:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:40:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=430478) [2026-01-25 20:40:20] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=430478) [2026-01-25 20:40:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=430478) [2026-01-25 20:40:20] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=430478) [2026-01-25 20:40:20] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=430478) [2026-01-25 20:40:20] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=430478) [2026-01-25 20:40:20] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=430478) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=430478) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:23<00:23, 23.52s/it]
(EngineCore_DP0 pid=430478) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:56<00:00, 29.20s/it]
(EngineCore_DP0 pid=430478) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:56<00:00, 28.35s/it]
(EngineCore_DP0 pid=430478) 
(EngineCore_DP0 pid=430478) [2026-01-25 20:41:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=430478) [2026-01-25 20:41:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=430478) [2026-01-25 20:41:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=430478) [2026-01-25 20:41:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=430478) [2026-01-25 20:41:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=430478) [2026-01-25 20:41:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=430478) [2026-01-25 20:41:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=430478) [2026-01-25 20:41:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=430478) Process EngineCore_DP0:
(EngineCore_DP0 pid=430478) Traceback (most recent call last):
(EngineCore_DP0 pid=430478)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=430478)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=430478)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=430478)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=430478) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpou3l2qp4.ptx', '-o', '/tmp/tmpou3l2qp4.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=430478) 
(EngineCore_DP0 pid=430478) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=430478) 
(EngineCore_DP0 pid=430478) Traceback (most recent call last):
(EngineCore_DP0 pid=430478)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=430478)     self.run()
(EngineCore_DP0 pid=430478)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=430478)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=430478)     raise e
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=430478)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=430478)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=430478)     super().__init__(
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=430478)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=430478)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=430478)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=430478)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=430478)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=430478)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=430478)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=430478)     return func(*args, **kwargs)
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=430478)     return func(*args, **kwargs)
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=430478)     self.model_runner.profile_run()
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=430478)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=430478)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=430478)     return func(*args, **kwargs)
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=430478)     outputs = self.model(
(EngineCore_DP0 pid=430478)               ^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=430478)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=430478)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=430478)     hidden_states = self.model(
(EngineCore_DP0 pid=430478)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=430478)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=430478)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=430478)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=430478)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=430478)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=430478)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=430478)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=430478)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=430478)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=430478)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=430478)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=430478)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=430478)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=430478)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=430478)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=430478)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=430478)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=430478)     return self._linear_fn(
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=430478)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=430478)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=430478)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=430478)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=430478)     return fn(input, L)
(EngineCore_DP0 pid=430478)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=430478)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=430478)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=430478)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=430478)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=430478)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=430478)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=430478)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=430478)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=430478)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=430478)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=430478)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=430478)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=430478)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=430478)     raise PTXASError(error)
(EngineCore_DP0 pid=430478) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=430478) `ptxas` stderr:
(EngineCore_DP0 pid=430478) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=430478) 
(EngineCore_DP0 pid=430478) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpou3l2qp4.ptx -o /tmp/tmpou3l2qp4.ptx.o
(EngineCore_DP0 pid=430478) 
[rank0]:[W125 20:41:21.469957517 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 20:41:23
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:41:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:41:30 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=431674) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=431674) 
(EngineCore_DP0 pid=431674) 
(EngineCore_DP0 pid=431674) ================================================================
(EngineCore_DP0 pid=431674) Internal Triton PTX codegen error
(EngineCore_DP0 pid=431674) `ptxas` stderr:
(EngineCore_DP0 pid=431674) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=431674) 
(EngineCore_DP0 pid=431674) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp0rel5c8i.ptx -o /tmp/tmp0rel5c8i.ptx.o
(EngineCore_DP0 pid=431674) 
(EngineCore_DP0 pid=431674) 
(EngineCore_DP0 pid=431674) //
(EngineCore_DP0 pid=431674) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=431674) //
(EngineCore_DP0 pid=431674) 
(EngineCore_DP0 pid=431674) .version 8.7
(EngineCore_DP0 pid=431674) .target sm_121a
(EngineCore_DP0 pid=431674) .address_size 64
(EngineCore_DP0 pid=431674) 
(EngineCore_DP0 pid=431674) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=431674) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=431674)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=431674) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=431674) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=431674) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=431674) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=431674) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=431674) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=431674) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=431674) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=431674) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=431674) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=431674) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=431674) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=431674) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=431674) )
(EngineCore_DP0 pid=431674) .reqntid 512
(EngineCore_DP0 pid=431674) {
(EngineCore_DP0 pid=431674) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=431674) 	.reg .b16 	%rs<64>;
(EngineCore_DP0 pid=431674) 	.reg .b32 	%r<169>;
(EngineCore_DP0 pid=431674) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=431674) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=431674) $L__func_begin0:
(EngineCore_DP0 pid=431674) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=431674) 
(EngineCore_DP0 pid=431674) // %bb.0:
(EngineCore_DP0 pid=431674) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=431674) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=431674) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=431674) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=431674) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=431674) $L__tmp0:
(EngineCore_DP0 pid=431674) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=431674) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=431674) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=431674) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=431674) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=431674) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=431674) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=431674) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=431674) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=431674) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=431674) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=431674) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=431674) 	mov.b32 	%r167, 0f2B8CBCCC;
(EngineCore_DP0 pid=431674) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=431674) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=431674) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=431674) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=431674) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=431674) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=431674) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=431674) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=431674) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=431674) 	add.s32 	%r53, %r35, %r34;
(EngineCore_DP0 pid=431674) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=431674) 	add.s32 	%r56, %r35, %r36;
(EngineCore_DP0 pid=431674) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=431674) 	mov.b32 	%r165, 0f00000000;
(EngineCore_DP0 pid=431674) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=431674) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=431674) 	mov.b32 	%r166, %r41;
(EngineCore_DP0 pid=431674) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=431674) 	.loc	1 265 19                        // quant_slide_tuned_Qwen2.5-7B.py:265:19
(EngineCore_DP0 pid=431674) 	add.s32 	%r59, %r4, %r166;
(EngineCore_DP0 pid=431674) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=431674) 	add.s32 	%r60, %r59, 4096;
(EngineCore_DP0 pid=431674) 	setp.lt.s32 	%p2, %r59, %r19;
(EngineCore_DP0 pid=431674) 	setp.lt.s32 	%p3, %r60, %r19;
(EngineCore_DP0 pid=431674) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=431674) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=431674) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=431674) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=431674) 	// begin inline asm
(EngineCore_DP0 pid=431674) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=431674) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=431674) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=431674) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=431674) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=431674) 	// end inline asm
(EngineCore_DP0 pid=431674) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=431674) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=431674) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=431674) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=431674) 	// begin inline asm
(EngineCore_DP0 pid=431674) 	mov.u32 %r45, %r41;
(EngineCore_DP0 pid=431674) 	mov.u32 %r46, %r41;
(EngineCore_DP0 pid=431674) 	mov.u32 %r47, %r41;
(EngineCore_DP0 pid=431674) 	mov.u32 %r48, %r41;
(EngineCore_DP0 pid=431674) 	@%p3 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=431674) 	// end inline asm
(EngineCore_DP0 pid=431674) 	mov.b32 	{%rs9, %rs10}, %r45;
(EngineCore_DP0 pid=431674) 	mov.b32 	{%rs11, %rs12}, %r46;
(EngineCore_DP0 pid=431674) 	mov.b32 	{%rs13, %rs14}, %r47;
(EngineCore_DP0 pid=431674) 	mov.b32 	{%rs15, %rs16}, %r48;
(EngineCore_DP0 pid=431674) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=431674) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=431674) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=431674) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=431674) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=431674) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=431674) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=431674) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=431674) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=431674) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=431674) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=431674) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=431674) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=431674) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=431674) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=431674) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=431674) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=431674) $L__tmp1:
(EngineCore_DP0 pid=431674) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	bar.sync 	0;
(EngineCore_DP0 pid=431674) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=431674) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=431674) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=431674) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=431674) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=431674) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=431674) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=431674) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=431674) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=431674) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=431674) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=431674) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=431674) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=431674) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=431674) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=431674) 	cvt.f32.bf16 	%r61, %rs47;
(EngineCore_DP0 pid=431674) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	shfl.sync.bfly.b32 	%r62, %r61, 16, 31, -1;
(EngineCore_DP0 pid=431674) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=431674) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	shfl.sync.bfly.b32 	%r64, %r63, 8, 31, -1;
(EngineCore_DP0 pid=431674) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=431674) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=431674) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=431674) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=431674) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=431674) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=431674) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	max.f32 	%r54, %r69, %r70;
(EngineCore_DP0 pid=431674) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	// begin inline asm
(EngineCore_DP0 pid=431674) 	@%p4 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=431674) 	// end inline asm
(EngineCore_DP0 pid=431674) 	bar.sync 	0;
(EngineCore_DP0 pid=431674) 	// begin inline asm
(EngineCore_DP0 pid=431674) 	@%p5 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=431674) 	// end inline asm
(EngineCore_DP0 pid=431674) 	shfl.sync.bfly.b32 	%r71, %r55, 8, 31, -1;
(EngineCore_DP0 pid=431674) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	max.f32 	%r72, %r55, %r71;
(EngineCore_DP0 pid=431674) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	shfl.sync.bfly.b32 	%r73, %r72, 4, 31, -1;
(EngineCore_DP0 pid=431674) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	max.f32 	%r74, %r72, %r73;
(EngineCore_DP0 pid=431674) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	shfl.sync.bfly.b32 	%r75, %r74, 2, 31, -1;
(EngineCore_DP0 pid=431674) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	max.f32 	%r76, %r74, %r75;
(EngineCore_DP0 pid=431674) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	shfl.sync.bfly.b32 	%r77, %r76, 1, 31, -1;
(EngineCore_DP0 pid=431674) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	max.f32 	%r58, %r76, %r77;
(EngineCore_DP0 pid=431674) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=431674) 	// begin inline asm
(EngineCore_DP0 pid=431674) 	@%p28 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=431674) 	// end inline asm
(EngineCore_DP0 pid=431674) 	bar.sync 	0;
(EngineCore_DP0 pid=431674) 	ld.shared.b32 	%r78, [global_smem];
(EngineCore_DP0 pid=431674) $L__tmp2:
(EngineCore_DP0 pid=431674) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=431674) 	max.f32 	%r165, %r165, %r78;
(EngineCore_DP0 pid=431674) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=431674) 	add.s32 	%r166, %r166, 8192;
(EngineCore_DP0 pid=431674) 	setp.lt.s32 	%p7, %r166, %r20;
(EngineCore_DP0 pid=431674) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=431674) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=431674) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=431674) 	max.f32 	%r167, %r165, 0f2B8CBCCC;
(EngineCore_DP0 pid=431674) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=431674) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=431674) 	mov.b32 	%r80, 0f42FE0000;
(EngineCore_DP0 pid=431674) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=431674) 	div.full.f32 	%r81, %r167, %r80;
(EngineCore_DP0 pid=431674) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=431674) 	max.f32 	%r79, %r81, 0f37810204;
(EngineCore_DP0 pid=431674) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=431674) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=431674) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=431674) 	// begin inline asm
(EngineCore_DP0 pid=431674) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r79 };
(EngineCore_DP0 pid=431674) 	// end inline asm
(EngineCore_DP0 pid=431674) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=431674) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=431674) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=431674) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=431674) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=431674) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=431674) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=431674) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=431674) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=431674) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=431674) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=431674) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=431674) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=431674) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=431674) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=431674) 	div.full.f32 	%r14, %r80, %r167;
(EngineCore_DP0 pid=431674) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=431674) 	mov.b32 	%r168, 0;
(EngineCore_DP0 pid=431674) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=431674)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=431674) 	.loc	1 279 31                        // quant_slide_tuned_Qwen2.5-7B.py:279:31
(EngineCore_DP0 pid=431674) 	add.s32 	%r85, %r16, %r168;
(EngineCore_DP0 pid=431674) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=431674) 	add.s32 	%r86, %r168, 1;
(EngineCore_DP0 pid=431674) 	setp.lt.s32 	%p18, %r85, %r15;
(EngineCore_DP0 pid=431674) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=431674) 	shr.u32 	%r87, %r85, 1;
(EngineCore_DP0 pid=431674) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=431674) 	shr.u32 	%r88, %r86, 31;
(EngineCore_DP0 pid=431674) 	add.s32 	%r89, %r86, %r88;
(EngineCore_DP0 pid=431674) 	and.b32 	%r90, %r89, 2147483646;
(EngineCore_DP0 pid=431674) 	sub.s32 	%r91, %r86, %r90;
(EngineCore_DP0 pid=431674) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=431674) 	mul.lo.s32 	%r92, %r87, 6;
(EngineCore_DP0 pid=431674) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=431674) 	shl.b32 	%r93, %r91, 1;
(EngineCore_DP0 pid=431674) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=431674) 	add.s32 	%r94, %r92, %r93;
(EngineCore_DP0 pid=431674) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=431674) 	setp.lt.s32 	%p19, %r92, %r19;
(EngineCore_DP0 pid=431674) 	setp.lt.s32 	%p20, %r94, %r19;
(EngineCore_DP0 pid=431674) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=431674) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=431674) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=431674) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=431674) 	mad.wide.s32 	%rd9, %r92, 2, %rd1;
(EngineCore_DP0 pid=431674) 	mad.wide.s32 	%rd10, %r94, 2, %rd1;
(EngineCore_DP0 pid=431674) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=431674) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=431674) 	// begin inline asm
(EngineCore_DP0 pid=431674) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=431674) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=431674) 	// end inline asm
(EngineCore_DP0 pid=431674) 	// begin inline asm
(EngineCore_DP0 pid=431674) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=431674) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=431674) 	// end inline asm
(EngineCore_DP0 pid=431674) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=431674) 	cvt.f32.bf16 	%r95, %rs48;
(EngineCore_DP0 pid=431674) 	cvt.f32.bf16 	%r96, %rs50;
(EngineCore_DP0 pid=431674) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=431674) 	or.b32 	%r97, %r92, 1;
(EngineCore_DP0 pid=431674) 	or.b32 	%r98, %r94, 1;
(EngineCore_DP0 pid=431674) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=431674) 	setp.lt.s32 	%p21, %r97, %r19;
(EngineCore_DP0 pid=431674) 	setp.lt.s32 	%p22, %r98, %r19;
(EngineCore_DP0 pid=431674) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=431674) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=431674) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=431674) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=431674) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=431674) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=431674) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=431674) 	// begin inline asm
(EngineCore_DP0 pid=431674) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=431674) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=431674) 	// end inline asm
(EngineCore_DP0 pid=431674) 	// begin inline asm
(EngineCore_DP0 pid=431674) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=431674) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=431674) 	// end inline asm
(EngineCore_DP0 pid=431674) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=431674) 	cvt.f32.bf16 	%r99, %rs52;
(EngineCore_DP0 pid=431674) 	cvt.f32.bf16 	%r100, %rs54;
(EngineCore_DP0 pid=431674) 	.loc	1 292 48                        // quant_slide_tuned_Qwen2.5-7B.py:292:48
(EngineCore_DP0 pid=431674) 	add.s32 	%r101, %r92, 2;
(EngineCore_DP0 pid=431674) 	add.s32 	%r102, %r94, 2;
(EngineCore_DP0 pid=431674) 	.loc	1 292 53                        // quant_slide_tuned_Qwen2.5-7B.py:292:53
(EngineCore_DP0 pid=431674) 	setp.lt.s32 	%p23, %r101, %r19;
(EngineCore_DP0 pid=431674) 	setp.lt.s32 	%p24, %r102, %r19;
(EngineCore_DP0 pid=431674) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=431674) 	and.pred 	%p14, %p18, %p23;
(EngineCore_DP0 pid=431674) 	and.pred 	%p15, %p18, %p24;
(EngineCore_DP0 pid=431674) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=431674) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=431674) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=431674) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=431674) 	// begin inline asm
(EngineCore_DP0 pid=431674) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=431674) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=431674) 	// end inline asm
(EngineCore_DP0 pid=431674) 	// begin inline asm
(EngineCore_DP0 pid=431674) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=431674) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=431674) 	// end inline asm
(EngineCore_DP0 pid=431674) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=431674) 	cvt.f32.bf16 	%r103, %rs56;
(EngineCore_DP0 pid=431674) 	cvt.f32.bf16 	%r104, %rs58;
(EngineCore_DP0 pid=431674) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=431674) 	add.s32 	%r105, %r92, 3;
(EngineCore_DP0 pid=431674) 	add.s32 	%r106, %r94, 3;
(EngineCore_DP0 pid=431674) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=431674) 	setp.lt.s32 	%p25, %r105, %r19;
(EngineCore_DP0 pid=431674) 	setp.lt.s32 	%p26, %r106, %r19;
(EngineCore_DP0 pid=431674) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=431674) 	and.pred 	%p16, %p18, %p25;
(EngineCore_DP0 pid=431674) 	and.pred 	%p17, %p18, %p26;
(EngineCore_DP0 pid=431674) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=431674) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=431674) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=431674) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=431674) 	// begin inline asm
(EngineCore_DP0 pid=431674) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=431674) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=431674) 	// end inline asm
(EngineCore_DP0 pid=431674) 	// begin inline asm
(EngineCore_DP0 pid=431674) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=431674) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=431674) 	// end inline asm
(EngineCore_DP0 pid=431674) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=431674) 	cvt.f32.bf16 	%r107, %rs60;
(EngineCore_DP0 pid=431674) 	cvt.f32.bf16 	%r108, %rs62;
(EngineCore_DP0 pid=431674) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=431674) 	mul.f32 	%r109, %r14, %r95;
(EngineCore_DP0 pid=431674) 	mul.f32 	%r110, %r14, %r96;
(EngineCore_DP0 pid=431674) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=431674) 	cvt.rni.f32.f32 	%r111, %r109;
(EngineCore_DP0 pid=431674) 	cvt.rni.f32.f32 	%r112, %r110;
(EngineCore_DP0 pid=431674) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=431674) 	max.f32 	%r113, %r111, 0fC3000000;
(EngineCore_DP0 pid=431674) 	min.f32 	%r114, %r113, 0f42FE0000;
(EngineCore_DP0 pid=431674) 	max.f32 	%r115, %r112, 0fC3000000;
(EngineCore_DP0 pid=431674) 	min.f32 	%r116, %r115, 0f42FE0000;
(EngineCore_DP0 pid=431674) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=431674) 	cvt.rzi.s32.f32 	%r117, %r114;
(EngineCore_DP0 pid=431674) 	cvt.rzi.s32.f32 	%r118, %r116;
(EngineCore_DP0 pid=431674) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=431674) 	and.b32 	%r119, %r117, 255;
(EngineCore_DP0 pid=431674) 	and.b32 	%r120, %r118, 255;
(EngineCore_DP0 pid=431674) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=431674) 	mul.f32 	%r121, %r14, %r99;
(EngineCore_DP0 pid=431674) 	mul.f32 	%r122, %r14, %r100;
(EngineCore_DP0 pid=431674) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=431674) 	cvt.rni.f32.f32 	%r123, %r121;
(EngineCore_DP0 pid=431674) 	cvt.rni.f32.f32 	%r124, %r122;
(EngineCore_DP0 pid=431674) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=431674) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=431674) 	mul.f32 	%r126, %r14, %r104;
(EngineCore_DP0 pid=431674) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=431674) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=431674) 	cvt.rni.f32.f32 	%r128, %r126;
(EngineCore_DP0 pid=431674) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=431674) 	mul.f32 	%r129, %r14, %r107;
(EngineCore_DP0 pid=431674) 	mul.f32 	%r130, %r14, %r108;
(EngineCore_DP0 pid=431674) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=431674) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=431674) 	cvt.rni.f32.f32 	%r132, %r130;
(EngineCore_DP0 pid=431674) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=431674) 	max.f32 	%r133, %r131, 0fC3000000;
(EngineCore_DP0 pid=431674) 	min.f32 	%r134, %r133, 0f42FE0000;
(EngineCore_DP0 pid=431674) 	max.f32 	%r135, %r132, 0fC3000000;
(EngineCore_DP0 pid=431674) 	min.f32 	%r136, %r135, 0f42FE0000;
(EngineCore_DP0 pid=431674) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=431674) 	cvt.rzi.s32.f32 	%r137, %r134;
(EngineCore_DP0 pid=431674) 	cvt.rzi.s32.f32 	%r138, %r136;
(EngineCore_DP0 pid=431674) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=431674) 	max.f32 	%r139, %r127, 0fC3000000;
(EngineCore_DP0 pid=431674) 	max.f32 	%r140, %r123, 0fC3000000;
(EngineCore_DP0 pid=431674) 	min.f32 	%r141, %r140, 0f42FE0000;
(EngineCore_DP0 pid=431674) 	min.f32 	%r142, %r139, 0f42FE0000;
(EngineCore_DP0 pid=431674) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=431674) 	cvt.rzi.s32.f32 	%r143, %r142;
(EngineCore_DP0 pid=431674) 	cvt.rzi.s32.f32 	%r144, %r141;
(EngineCore_DP0 pid=431674) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=431674) 	shl.b32 	%r145, %r144, 8;
(EngineCore_DP0 pid=431674) 	shl.b32 	%r146, %r143, 16;
(EngineCore_DP0 pid=431674) 	and.b32 	%r147, %r146, 16711680;
(EngineCore_DP0 pid=431674) 	and.b32 	%r148, %r145, 65280;
(EngineCore_DP0 pid=431674) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=431674) 	or.b32 	%r149, %r148, %r119;
(EngineCore_DP0 pid=431674) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=431674) 	max.f32 	%r150, %r128, 0fC3000000;
(EngineCore_DP0 pid=431674) 	max.f32 	%r151, %r124, 0fC3000000;
(EngineCore_DP0 pid=431674) 	min.f32 	%r152, %r151, 0f42FE0000;
(EngineCore_DP0 pid=431674) 	min.f32 	%r153, %r150, 0f42FE0000;
(EngineCore_DP0 pid=431674) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=431674) 	cvt.rzi.s32.f32 	%r154, %r153;
(EngineCore_DP0 pid=431674) 	cvt.rzi.s32.f32 	%r155, %r152;
(EngineCore_DP0 pid=431674) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=431674) 	shl.b32 	%r156, %r155, 8;
(EngineCore_DP0 pid=431674) 	shl.b32 	%r157, %r154, 16;
(EngineCore_DP0 pid=431674) 	and.b32 	%r158, %r157, 16711680;
(EngineCore_DP0 pid=431674) 	and.b32 	%r159, %r156, 65280;
(EngineCore_DP0 pid=431674) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=431674) 	or.b32 	%r160, %r159, %r120;
(EngineCore_DP0 pid=431674) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=431674) 	or.b32 	%r161, %r149, %r147;
(EngineCore_DP0 pid=431674) 	or.b32 	%r162, %r160, %r158;
(EngineCore_DP0 pid=431674) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=431674) 	shl.b32 	%r163, %r137, 24;
(EngineCore_DP0 pid=431674) 	shl.b32 	%r164, %r138, 24;
(EngineCore_DP0 pid=431674) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=431674) 	or.b32 	%r83, %r161, %r163;
(EngineCore_DP0 pid=431674) 	or.b32 	%r84, %r162, %r164;
(EngineCore_DP0 pid=431674) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=431674) 	mad.wide.s32 	%rd17, %r85, 4, %rd2;
(EngineCore_DP0 pid=431674) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=431674) 	// begin inline asm
(EngineCore_DP0 pid=431674) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r83, %r84 };
(EngineCore_DP0 pid=431674) 	// end inline asm
(EngineCore_DP0 pid=431674) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=431674) 	add.s32 	%r168, %r168, 1024;
(EngineCore_DP0 pid=431674) 	setp.lt.s32 	%p27, %r168, %r15;
(EngineCore_DP0 pid=431674) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=431674) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=431674) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=431674) 	ret;
(EngineCore_DP0 pid=431674) $L__tmp3:
(EngineCore_DP0 pid=431674) $L__func_end0:
(EngineCore_DP0 pid=431674)                                         // -- End function
(EngineCore_DP0 pid=431674) }
(EngineCore_DP0 pid=431674) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=431674) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=431674) 	.section	.debug_abbrev
(EngineCore_DP0 pid=431674) 	{
(EngineCore_DP0 pid=431674) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=431674) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=431674) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=431674) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=431674) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=431674) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=431674) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=431674) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=431674) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=431674) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=431674) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=431674) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=431674) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=431674) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=431674) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=431674) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=431674) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=431674) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=431674) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=431674) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=431674) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=431674) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=431674) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=431674) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=431674) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=431674) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=431674) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=431674) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=431674) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=431674) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=431674) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=431674) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=431674) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=431674) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=431674) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=431674) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=431674) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=431674) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=431674) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=431674) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=431674) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=431674) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=431674) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=431674) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=431674) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=431674) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=431674) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=431674) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=431674) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=431674) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=431674) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=431674) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=431674) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=431674) 	}
(EngineCore_DP0 pid=431674) 	.section	.debug_info
(EngineCore_DP0 pid=431674) 	{
(EngineCore_DP0 pid=431674) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=431674) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=431674) .b8 0
(EngineCore_DP0 pid=431674) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=431674) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=431674) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=431674) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=431674) .b8 114
(EngineCore_DP0 pid=431674) .b8 105
(EngineCore_DP0 pid=431674) .b8 116
(EngineCore_DP0 pid=431674) .b8 111
(EngineCore_DP0 pid=431674) .b8 110
(EngineCore_DP0 pid=431674) .b8 0
(EngineCore_DP0 pid=431674) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=431674) .b8 0
(EngineCore_DP0 pid=431674) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=431674) .b8 117
(EngineCore_DP0 pid=431674) .b8 97
(EngineCore_DP0 pid=431674) .b8 110
(EngineCore_DP0 pid=431674) .b8 116
(EngineCore_DP0 pid=431674) .b8 95
(EngineCore_DP0 pid=431674) .b8 115
(EngineCore_DP0 pid=431674) .b8 108
(EngineCore_DP0 pid=431674) .b8 105
(EngineCore_DP0 pid=431674) .b8 100
(EngineCore_DP0 pid=431674) .b8 101
(EngineCore_DP0 pid=431674) .b8 95
(EngineCore_DP0 pid=431674) .b8 116
(EngineCore_DP0 pid=431674) .b8 117
(EngineCore_DP0 pid=431674) .b8 110
(EngineCore_DP0 pid=431674) .b8 101
(EngineCore_DP0 pid=431674) .b8 100
(EngineCore_DP0 pid=431674) .b8 95
(EngineCore_DP0 pid=431674) .b8 81
(EngineCore_DP0 pid=431674) .b8 119
(EngineCore_DP0 pid=431674) .b8 101
(EngineCore_DP0 pid=431674) .b8 110
(EngineCore_DP0 pid=431674) .b8 50
(EngineCore_DP0 pid=431674) .b8 46
(EngineCore_DP0 pid=431674) .b8 53
(EngineCore_DP0 pid=431674) .b8 45
(EngineCore_DP0 pid=431674) .b8 55
(EngineCore_DP0 pid=431674) .b8 66
(EngineCore_DP0 pid=431674) .b8 46
(EngineCore_DP0 pid=431674) .b8 112
(EngineCore_DP0 pid=431674) .b8 121
(EngineCore_DP0 pid=431674) .b8 0
(EngineCore_DP0 pid=431674) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=431674) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=431674) .b8 114
(EngineCore_DP0 pid=431674) .b8 111
(EngineCore_DP0 pid=431674) .b8 111
(EngineCore_DP0 pid=431674) .b8 116
(EngineCore_DP0 pid=431674) .b8 47
(EngineCore_DP0 pid=431674) .b8 118
(EngineCore_DP0 pid=431674) .b8 108
(EngineCore_DP0 pid=431674) .b8 108
(EngineCore_DP0 pid=431674) .b8 109
(EngineCore_DP0 pid=431674) .b8 98
(EngineCore_DP0 pid=431674) .b8 101
(EngineCore_DP0 pid=431674) .b8 110
(EngineCore_DP0 pid=431674) .b8 99
(EngineCore_DP0 pid=431674) .b8 104
(EngineCore_DP0 pid=431674) .b8 47
(EngineCore_DP0 pid=431674) .b8 115
(EngineCore_DP0 pid=431674) .b8 108
(EngineCore_DP0 pid=431674) .b8 105
(EngineCore_DP0 pid=431674) .b8 100
(EngineCore_DP0 pid=431674) .b8 101
(EngineCore_DP0 pid=431674) .b8 115
(EngineCore_DP0 pid=431674) .b8 112
(EngineCore_DP0 pid=431674) .b8 97
(EngineCore_DP0 pid=431674) .b8 114
(EngineCore_DP0 pid=431674) .b8 115
(EngineCore_DP0 pid=431674) .b8 101
(EngineCore_DP0 pid=431674) .b8 47
(EngineCore_DP0 pid=431674) .b8 99
(EngineCore_DP0 pid=431674) .b8 115
(EngineCore_DP0 pid=431674) .b8 114
(EngineCore_DP0 pid=431674) .b8 99
(EngineCore_DP0 pid=431674) .b8 47
(EngineCore_DP0 pid=431674) .b8 102
(EngineCore_DP0 pid=431674) .b8 117
(EngineCore_DP0 pid=431674) .b8 115
(EngineCore_DP0 pid=431674) .b8 101
(EngineCore_DP0 pid=431674) .b8 100
(EngineCore_DP0 pid=431674) .b8 95
(EngineCore_DP0 pid=431674) .b8 113
(EngineCore_DP0 pid=431674) .b8 117
(EngineCore_DP0 pid=431674) .b8 97
(EngineCore_DP0 pid=431674) .b8 110
(EngineCore_DP0 pid=431674) .b8 116
(EngineCore_DP0 pid=431674) .b8 95
(EngineCore_DP0 pid=431674) .b8 115
(EngineCore_DP0 pid=431674) .b8 108
(EngineCore_DP0 pid=431674) .b8 105
(EngineCore_DP0 pid=431674) .b8 100
(EngineCore_DP0 pid=431674) .b8 101
(EngineCore_DP0 pid=431674) .b8 95
(EngineCore_DP0 pid=431674) .b8 116
(EngineCore_DP0 pid=431674) .b8 114
(EngineCore_DP0 pid=431674) .b8 105
(EngineCore_DP0 pid=431674) .b8 116
(EngineCore_DP0 pid=431674) .b8 111
(EngineCore_DP0 pid=431674) .b8 110
(EngineCore_DP0 pid=431674) .b8 47
(EngineCore_DP0 pid=431674) .b8 98
(EngineCore_DP0 pid=431674) .b8 117
(EngineCore_DP0 pid=431674) .b8 105
(EngineCore_DP0 pid=431674) .b8 108
(EngineCore_DP0 pid=431674) .b8 100
(EngineCore_DP0 pid=431674) .b8 47
(EngineCore_DP0 pid=431674) .b8 71
(EngineCore_DP0 pid=431674) .b8 66
(EngineCore_DP0 pid=431674) .b8 49
(EngineCore_DP0 pid=431674) .b8 48
(EngineCore_DP0 pid=431674) .b8 95
(EngineCore_DP0 pid=431674) .b8 99
(EngineCore_DP0 pid=431674) .b8 99
(EngineCore_DP0 pid=431674) .b8 49
(EngineCore_DP0 pid=431674) .b8 50
(EngineCore_DP0 pid=431674) .b8 49
(EngineCore_DP0 pid=431674) .b8 95
(EngineCore_DP0 pid=431674) .b8 112
(EngineCore_DP0 pid=431674) .b8 121
(EngineCore_DP0 pid=431674) .b8 51
(EngineCore_DP0 pid=431674) .b8 49
(EngineCore_DP0 pid=431674) .b8 50
(EngineCore_DP0 pid=431674) .b8 95
(EngineCore_DP0 pid=431674) .b8 99
(EngineCore_DP0 pid=431674) .b8 117
(EngineCore_DP0 pid=431674) .b8 49
(EngineCore_DP0 pid=431674) .b8 50
(EngineCore_DP0 pid=431674) .b8 57
(EngineCore_DP0 pid=431674) .b8 95
(EngineCore_DP0 pid=431674) .b8 97
(EngineCore_DP0 pid=431674) .b8 97
(EngineCore_DP0 pid=431674) .b8 114
(EngineCore_DP0 pid=431674) .b8 99
(EngineCore_DP0 pid=431674) .b8 104
(EngineCore_DP0 pid=431674) .b8 54
(EngineCore_DP0 pid=431674) .b8 52
(EngineCore_DP0 pid=431674) .b8 0
(EngineCore_DP0 pid=431674) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=431674) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=431674) .b8 113
(EngineCore_DP0 pid=431674) .b8 117
(EngineCore_DP0 pid=431674) .b8 97
(EngineCore_DP0 pid=431674) .b8 110
(EngineCore_DP0 pid=431674) .b8 116
(EngineCore_DP0 pid=431674) .b8 95
(EngineCore_DP0 pid=431674) .b8 115
(EngineCore_DP0 pid=431674) .b8 108
(EngineCore_DP0 pid=431674) .b8 105
(EngineCore_DP0 pid=431674) .b8 100
(EngineCore_DP0 pid=431674) .b8 101
(EngineCore_DP0 pid=431674) .b8 95
(EngineCore_DP0 pid=431674) .b8 105
(EngineCore_DP0 pid=431674) .b8 110
(EngineCore_DP0 pid=431674) .b8 116
(EngineCore_DP0 pid=431674) .b8 56
(EngineCore_DP0 pid=431674) .b8 95
(EngineCore_DP0 pid=431674) .b8 107
(EngineCore_DP0 pid=431674) .b8 101
(EngineCore_DP0 pid=431674) .b8 114
(EngineCore_DP0 pid=431674) .b8 110
(EngineCore_DP0 pid=431674) .b8 101
(EngineCore_DP0 pid=431674) .b8 108
(EngineCore_DP0 pid=431674) .b8 0
(EngineCore_DP0 pid=431674) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=431674) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=431674) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=431674) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=431674) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=431674) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=431674) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=431674) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=431674) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=431674) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=431674) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=431674) .b8 1
(EngineCore_DP0 pid=431674) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=431674) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=431674) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=431674) 	}
(EngineCore_DP0 pid=431674) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=431674) 
(EngineCore_DP0 pid=431674) ================================================================
(EngineCore_DP0 pid=431674) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=431674) 
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp0rel5c8i.ptx', '-o', '/tmp/tmp0rel5c8i.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866] 
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866] 
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866] 
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp0rel5c8i.ptx -o /tmp/tmp0rel5c8i.ptx.o
(EngineCore_DP0 pid=431674) ERROR 01-25 20:42:34 [core.py:866] 

STDERR:
[2026-01-25 20:41:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:41:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:41:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:41:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:41:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:41:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:41:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:41:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:41:33] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:41:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:41:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:41:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:41:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:41:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:41:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:41:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=431674) [2026-01-25 20:41:34] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=431674) [2026-01-25 20:41:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=431674) [2026-01-25 20:41:34] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=431674) [2026-01-25 20:41:34] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=431674) [2026-01-25 20:41:34] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=431674) [2026-01-25 20:41:34] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=431674) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=431674) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:23<00:23, 23.46s/it]
(EngineCore_DP0 pid=431674) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:56<00:00, 29.21s/it]
(EngineCore_DP0 pid=431674) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:56<00:00, 28.35s/it]
(EngineCore_DP0 pid=431674) 
(EngineCore_DP0 pid=431674) [2026-01-25 20:42:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=431674) [2026-01-25 20:42:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=431674) [2026-01-25 20:42:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=431674) [2026-01-25 20:42:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=431674) [2026-01-25 20:42:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=431674) [2026-01-25 20:42:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=431674) [2026-01-25 20:42:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=431674) [2026-01-25 20:42:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=431674) Process EngineCore_DP0:
(EngineCore_DP0 pid=431674) Traceback (most recent call last):
(EngineCore_DP0 pid=431674)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=431674)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=431674)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=431674)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=431674) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp0rel5c8i.ptx', '-o', '/tmp/tmp0rel5c8i.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=431674) 
(EngineCore_DP0 pid=431674) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=431674) 
(EngineCore_DP0 pid=431674) Traceback (most recent call last):
(EngineCore_DP0 pid=431674)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=431674)     self.run()
(EngineCore_DP0 pid=431674)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=431674)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=431674)     raise e
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=431674)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=431674)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=431674)     super().__init__(
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=431674)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=431674)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=431674)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=431674)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=431674)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=431674)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=431674)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=431674)     return func(*args, **kwargs)
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=431674)     return func(*args, **kwargs)
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=431674)     self.model_runner.profile_run()
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=431674)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=431674)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=431674)     return func(*args, **kwargs)
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=431674)     outputs = self.model(
(EngineCore_DP0 pid=431674)               ^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=431674)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=431674)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=431674)     hidden_states = self.model(
(EngineCore_DP0 pid=431674)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=431674)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=431674)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=431674)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=431674)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=431674)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=431674)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=431674)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=431674)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=431674)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=431674)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=431674)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=431674)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=431674)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=431674)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=431674)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=431674)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=431674)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=431674)     return self._linear_fn(
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=431674)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=431674)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=431674)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=431674)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=431674)     return fn(input, L)
(EngineCore_DP0 pid=431674)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=431674)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=431674)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=431674)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=431674)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=431674)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=431674)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=431674)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=431674)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=431674)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=431674)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=431674)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=431674)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=431674)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=431674)     raise PTXASError(error)
(EngineCore_DP0 pid=431674) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=431674) `ptxas` stderr:
(EngineCore_DP0 pid=431674) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=431674) 
(EngineCore_DP0 pid=431674) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp0rel5c8i.ptx -o /tmp/tmp0rel5c8i.ptx.o
(EngineCore_DP0 pid=431674) 
[rank0]:[W125 20:42:34.849394219 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 20:42:36
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:42:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:42:47 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=432948) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=432948) 
(EngineCore_DP0 pid=432948) 
(EngineCore_DP0 pid=432948) ================================================================
(EngineCore_DP0 pid=432948) Internal Triton PTX codegen error
(EngineCore_DP0 pid=432948) `ptxas` stderr:
(EngineCore_DP0 pid=432948) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=432948) 
(EngineCore_DP0 pid=432948) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpumzvsy_y.ptx -o /tmp/tmpumzvsy_y.ptx.o
(EngineCore_DP0 pid=432948) 
(EngineCore_DP0 pid=432948) 
(EngineCore_DP0 pid=432948) //
(EngineCore_DP0 pid=432948) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=432948) //
(EngineCore_DP0 pid=432948) 
(EngineCore_DP0 pid=432948) .version 8.7
(EngineCore_DP0 pid=432948) .target sm_121a
(EngineCore_DP0 pid=432948) .address_size 64
(EngineCore_DP0 pid=432948) 
(EngineCore_DP0 pid=432948) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=432948) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=432948)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=432948) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=432948) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=432948) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=432948) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=432948) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=432948) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=432948) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=432948) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=432948) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=432948) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=432948) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=432948) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=432948) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=432948) )
(EngineCore_DP0 pid=432948) .reqntid 512
(EngineCore_DP0 pid=432948) {
(EngineCore_DP0 pid=432948) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=432948) 	.reg .b16 	%rs<64>;
(EngineCore_DP0 pid=432948) 	.reg .b32 	%r<169>;
(EngineCore_DP0 pid=432948) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=432948) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=432948) $L__func_begin0:
(EngineCore_DP0 pid=432948) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=432948) 
(EngineCore_DP0 pid=432948) // %bb.0:
(EngineCore_DP0 pid=432948) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=432948) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=432948) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=432948) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=432948) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=432948) $L__tmp0:
(EngineCore_DP0 pid=432948) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=432948) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=432948) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=432948) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=432948) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=432948) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=432948) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=432948) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=432948) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=432948) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=432948) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=432948) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=432948) 	mov.b32 	%r167, 0f2B8CBCCC;
(EngineCore_DP0 pid=432948) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=432948) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=432948) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=432948) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=432948) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=432948) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=432948) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=432948) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=432948) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=432948) 	add.s32 	%r53, %r35, %r34;
(EngineCore_DP0 pid=432948) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=432948) 	add.s32 	%r56, %r35, %r36;
(EngineCore_DP0 pid=432948) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=432948) 	mov.b32 	%r165, 0f00000000;
(EngineCore_DP0 pid=432948) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=432948) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=432948) 	mov.b32 	%r166, %r41;
(EngineCore_DP0 pid=432948) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=432948) 	.loc	1 265 19                        // quant_slide_tuned_Qwen2.5-7B.py:265:19
(EngineCore_DP0 pid=432948) 	add.s32 	%r59, %r4, %r166;
(EngineCore_DP0 pid=432948) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=432948) 	add.s32 	%r60, %r59, 4096;
(EngineCore_DP0 pid=432948) 	setp.lt.s32 	%p2, %r59, %r19;
(EngineCore_DP0 pid=432948) 	setp.lt.s32 	%p3, %r60, %r19;
(EngineCore_DP0 pid=432948) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=432948) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=432948) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=432948) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=432948) 	// begin inline asm
(EngineCore_DP0 pid=432948) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=432948) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=432948) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=432948) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=432948) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=432948) 	// end inline asm
(EngineCore_DP0 pid=432948) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=432948) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=432948) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=432948) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=432948) 	// begin inline asm
(EngineCore_DP0 pid=432948) 	mov.u32 %r45, %r41;
(EngineCore_DP0 pid=432948) 	mov.u32 %r46, %r41;
(EngineCore_DP0 pid=432948) 	mov.u32 %r47, %r41;
(EngineCore_DP0 pid=432948) 	mov.u32 %r48, %r41;
(EngineCore_DP0 pid=432948) 	@%p3 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=432948) 	// end inline asm
(EngineCore_DP0 pid=432948) 	mov.b32 	{%rs9, %rs10}, %r45;
(EngineCore_DP0 pid=432948) 	mov.b32 	{%rs11, %rs12}, %r46;
(EngineCore_DP0 pid=432948) 	mov.b32 	{%rs13, %rs14}, %r47;
(EngineCore_DP0 pid=432948) 	mov.b32 	{%rs15, %rs16}, %r48;
(EngineCore_DP0 pid=432948) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=432948) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=432948) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=432948) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=432948) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=432948) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=432948) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=432948) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=432948) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=432948) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=432948) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=432948) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=432948) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=432948) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=432948) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=432948) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=432948) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=432948) $L__tmp1:
(EngineCore_DP0 pid=432948) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	bar.sync 	0;
(EngineCore_DP0 pid=432948) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=432948) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=432948) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=432948) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=432948) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=432948) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=432948) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=432948) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=432948) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=432948) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=432948) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=432948) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=432948) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=432948) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=432948) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=432948) 	cvt.f32.bf16 	%r61, %rs47;
(EngineCore_DP0 pid=432948) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	shfl.sync.bfly.b32 	%r62, %r61, 16, 31, -1;
(EngineCore_DP0 pid=432948) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=432948) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	shfl.sync.bfly.b32 	%r64, %r63, 8, 31, -1;
(EngineCore_DP0 pid=432948) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=432948) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=432948) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=432948) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=432948) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=432948) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=432948) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	max.f32 	%r54, %r69, %r70;
(EngineCore_DP0 pid=432948) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	// begin inline asm
(EngineCore_DP0 pid=432948) 	@%p4 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=432948) 	// end inline asm
(EngineCore_DP0 pid=432948) 	bar.sync 	0;
(EngineCore_DP0 pid=432948) 	// begin inline asm
(EngineCore_DP0 pid=432948) 	@%p5 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=432948) 	// end inline asm
(EngineCore_DP0 pid=432948) 	shfl.sync.bfly.b32 	%r71, %r55, 8, 31, -1;
(EngineCore_DP0 pid=432948) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	max.f32 	%r72, %r55, %r71;
(EngineCore_DP0 pid=432948) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	shfl.sync.bfly.b32 	%r73, %r72, 4, 31, -1;
(EngineCore_DP0 pid=432948) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	max.f32 	%r74, %r72, %r73;
(EngineCore_DP0 pid=432948) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	shfl.sync.bfly.b32 	%r75, %r74, 2, 31, -1;
(EngineCore_DP0 pid=432948) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	max.f32 	%r76, %r74, %r75;
(EngineCore_DP0 pid=432948) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	shfl.sync.bfly.b32 	%r77, %r76, 1, 31, -1;
(EngineCore_DP0 pid=432948) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	max.f32 	%r58, %r76, %r77;
(EngineCore_DP0 pid=432948) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=432948) 	// begin inline asm
(EngineCore_DP0 pid=432948) 	@%p28 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=432948) 	// end inline asm
(EngineCore_DP0 pid=432948) 	bar.sync 	0;
(EngineCore_DP0 pid=432948) 	ld.shared.b32 	%r78, [global_smem];
(EngineCore_DP0 pid=432948) $L__tmp2:
(EngineCore_DP0 pid=432948) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=432948) 	max.f32 	%r165, %r165, %r78;
(EngineCore_DP0 pid=432948) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=432948) 	add.s32 	%r166, %r166, 8192;
(EngineCore_DP0 pid=432948) 	setp.lt.s32 	%p7, %r166, %r20;
(EngineCore_DP0 pid=432948) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=432948) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=432948) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=432948) 	max.f32 	%r167, %r165, 0f2B8CBCCC;
(EngineCore_DP0 pid=432948) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=432948) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=432948) 	mov.b32 	%r80, 0f42FE0000;
(EngineCore_DP0 pid=432948) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=432948) 	div.full.f32 	%r81, %r167, %r80;
(EngineCore_DP0 pid=432948) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=432948) 	max.f32 	%r79, %r81, 0f37810204;
(EngineCore_DP0 pid=432948) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=432948) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=432948) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=432948) 	// begin inline asm
(EngineCore_DP0 pid=432948) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r79 };
(EngineCore_DP0 pid=432948) 	// end inline asm
(EngineCore_DP0 pid=432948) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=432948) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=432948) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=432948) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=432948) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=432948) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=432948) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=432948) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=432948) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=432948) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=432948) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=432948) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=432948) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=432948) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=432948) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=432948) 	div.full.f32 	%r14, %r80, %r167;
(EngineCore_DP0 pid=432948) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=432948) 	mov.b32 	%r168, 0;
(EngineCore_DP0 pid=432948) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=432948)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=432948) 	.loc	1 279 31                        // quant_slide_tuned_Qwen2.5-7B.py:279:31
(EngineCore_DP0 pid=432948) 	add.s32 	%r85, %r16, %r168;
(EngineCore_DP0 pid=432948) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=432948) 	add.s32 	%r86, %r168, 1;
(EngineCore_DP0 pid=432948) 	setp.lt.s32 	%p18, %r85, %r15;
(EngineCore_DP0 pid=432948) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=432948) 	shr.u32 	%r87, %r85, 1;
(EngineCore_DP0 pid=432948) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=432948) 	shr.u32 	%r88, %r86, 31;
(EngineCore_DP0 pid=432948) 	add.s32 	%r89, %r86, %r88;
(EngineCore_DP0 pid=432948) 	and.b32 	%r90, %r89, 2147483646;
(EngineCore_DP0 pid=432948) 	sub.s32 	%r91, %r86, %r90;
(EngineCore_DP0 pid=432948) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=432948) 	mul.lo.s32 	%r92, %r87, 6;
(EngineCore_DP0 pid=432948) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=432948) 	shl.b32 	%r93, %r91, 1;
(EngineCore_DP0 pid=432948) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=432948) 	add.s32 	%r94, %r92, %r93;
(EngineCore_DP0 pid=432948) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=432948) 	setp.lt.s32 	%p19, %r92, %r19;
(EngineCore_DP0 pid=432948) 	setp.lt.s32 	%p20, %r94, %r19;
(EngineCore_DP0 pid=432948) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=432948) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=432948) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=432948) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=432948) 	mad.wide.s32 	%rd9, %r92, 2, %rd1;
(EngineCore_DP0 pid=432948) 	mad.wide.s32 	%rd10, %r94, 2, %rd1;
(EngineCore_DP0 pid=432948) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=432948) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=432948) 	// begin inline asm
(EngineCore_DP0 pid=432948) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=432948) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=432948) 	// end inline asm
(EngineCore_DP0 pid=432948) 	// begin inline asm
(EngineCore_DP0 pid=432948) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=432948) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=432948) 	// end inline asm
(EngineCore_DP0 pid=432948) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=432948) 	cvt.f32.bf16 	%r95, %rs48;
(EngineCore_DP0 pid=432948) 	cvt.f32.bf16 	%r96, %rs50;
(EngineCore_DP0 pid=432948) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=432948) 	or.b32 	%r97, %r92, 1;
(EngineCore_DP0 pid=432948) 	or.b32 	%r98, %r94, 1;
(EngineCore_DP0 pid=432948) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=432948) 	setp.lt.s32 	%p21, %r97, %r19;
(EngineCore_DP0 pid=432948) 	setp.lt.s32 	%p22, %r98, %r19;
(EngineCore_DP0 pid=432948) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=432948) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=432948) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=432948) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=432948) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=432948) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=432948) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=432948) 	// begin inline asm
(EngineCore_DP0 pid=432948) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=432948) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=432948) 	// end inline asm
(EngineCore_DP0 pid=432948) 	// begin inline asm
(EngineCore_DP0 pid=432948) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=432948) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=432948) 	// end inline asm
(EngineCore_DP0 pid=432948) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=432948) 	cvt.f32.bf16 	%r99, %rs52;
(EngineCore_DP0 pid=432948) 	cvt.f32.bf16 	%r100, %rs54;
(EngineCore_DP0 pid=432948) 	.loc	1 292 48                        // quant_slide_tuned_Qwen2.5-7B.py:292:48
(EngineCore_DP0 pid=432948) 	add.s32 	%r101, %r92, 2;
(EngineCore_DP0 pid=432948) 	add.s32 	%r102, %r94, 2;
(EngineCore_DP0 pid=432948) 	.loc	1 292 53                        // quant_slide_tuned_Qwen2.5-7B.py:292:53
(EngineCore_DP0 pid=432948) 	setp.lt.s32 	%p23, %r101, %r19;
(EngineCore_DP0 pid=432948) 	setp.lt.s32 	%p24, %r102, %r19;
(EngineCore_DP0 pid=432948) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=432948) 	and.pred 	%p14, %p18, %p23;
(EngineCore_DP0 pid=432948) 	and.pred 	%p15, %p18, %p24;
(EngineCore_DP0 pid=432948) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=432948) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=432948) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=432948) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=432948) 	// begin inline asm
(EngineCore_DP0 pid=432948) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=432948) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=432948) 	// end inline asm
(EngineCore_DP0 pid=432948) 	// begin inline asm
(EngineCore_DP0 pid=432948) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=432948) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=432948) 	// end inline asm
(EngineCore_DP0 pid=432948) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=432948) 	cvt.f32.bf16 	%r103, %rs56;
(EngineCore_DP0 pid=432948) 	cvt.f32.bf16 	%r104, %rs58;
(EngineCore_DP0 pid=432948) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=432948) 	add.s32 	%r105, %r92, 3;
(EngineCore_DP0 pid=432948) 	add.s32 	%r106, %r94, 3;
(EngineCore_DP0 pid=432948) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=432948) 	setp.lt.s32 	%p25, %r105, %r19;
(EngineCore_DP0 pid=432948) 	setp.lt.s32 	%p26, %r106, %r19;
(EngineCore_DP0 pid=432948) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=432948) 	and.pred 	%p16, %p18, %p25;
(EngineCore_DP0 pid=432948) 	and.pred 	%p17, %p18, %p26;
(EngineCore_DP0 pid=432948) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=432948) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=432948) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=432948) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=432948) 	// begin inline asm
(EngineCore_DP0 pid=432948) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=432948) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=432948) 	// end inline asm
(EngineCore_DP0 pid=432948) 	// begin inline asm
(EngineCore_DP0 pid=432948) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=432948) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=432948) 	// end inline asm
(EngineCore_DP0 pid=432948) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=432948) 	cvt.f32.bf16 	%r107, %rs60;
(EngineCore_DP0 pid=432948) 	cvt.f32.bf16 	%r108, %rs62;
(EngineCore_DP0 pid=432948) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=432948) 	mul.f32 	%r109, %r14, %r95;
(EngineCore_DP0 pid=432948) 	mul.f32 	%r110, %r14, %r96;
(EngineCore_DP0 pid=432948) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=432948) 	cvt.rni.f32.f32 	%r111, %r109;
(EngineCore_DP0 pid=432948) 	cvt.rni.f32.f32 	%r112, %r110;
(EngineCore_DP0 pid=432948) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=432948) 	max.f32 	%r113, %r111, 0fC3000000;
(EngineCore_DP0 pid=432948) 	min.f32 	%r114, %r113, 0f42FE0000;
(EngineCore_DP0 pid=432948) 	max.f32 	%r115, %r112, 0fC3000000;
(EngineCore_DP0 pid=432948) 	min.f32 	%r116, %r115, 0f42FE0000;
(EngineCore_DP0 pid=432948) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=432948) 	cvt.rzi.s32.f32 	%r117, %r114;
(EngineCore_DP0 pid=432948) 	cvt.rzi.s32.f32 	%r118, %r116;
(EngineCore_DP0 pid=432948) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=432948) 	and.b32 	%r119, %r117, 255;
(EngineCore_DP0 pid=432948) 	and.b32 	%r120, %r118, 255;
(EngineCore_DP0 pid=432948) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=432948) 	mul.f32 	%r121, %r14, %r99;
(EngineCore_DP0 pid=432948) 	mul.f32 	%r122, %r14, %r100;
(EngineCore_DP0 pid=432948) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=432948) 	cvt.rni.f32.f32 	%r123, %r121;
(EngineCore_DP0 pid=432948) 	cvt.rni.f32.f32 	%r124, %r122;
(EngineCore_DP0 pid=432948) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=432948) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=432948) 	mul.f32 	%r126, %r14, %r104;
(EngineCore_DP0 pid=432948) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=432948) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=432948) 	cvt.rni.f32.f32 	%r128, %r126;
(EngineCore_DP0 pid=432948) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=432948) 	mul.f32 	%r129, %r14, %r107;
(EngineCore_DP0 pid=432948) 	mul.f32 	%r130, %r14, %r108;
(EngineCore_DP0 pid=432948) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=432948) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=432948) 	cvt.rni.f32.f32 	%r132, %r130;
(EngineCore_DP0 pid=432948) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=432948) 	max.f32 	%r133, %r131, 0fC3000000;
(EngineCore_DP0 pid=432948) 	min.f32 	%r134, %r133, 0f42FE0000;
(EngineCore_DP0 pid=432948) 	max.f32 	%r135, %r132, 0fC3000000;
(EngineCore_DP0 pid=432948) 	min.f32 	%r136, %r135, 0f42FE0000;
(EngineCore_DP0 pid=432948) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=432948) 	cvt.rzi.s32.f32 	%r137, %r134;
(EngineCore_DP0 pid=432948) 	cvt.rzi.s32.f32 	%r138, %r136;
(EngineCore_DP0 pid=432948) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=432948) 	max.f32 	%r139, %r127, 0fC3000000;
(EngineCore_DP0 pid=432948) 	max.f32 	%r140, %r123, 0fC3000000;
(EngineCore_DP0 pid=432948) 	min.f32 	%r141, %r140, 0f42FE0000;
(EngineCore_DP0 pid=432948) 	min.f32 	%r142, %r139, 0f42FE0000;
(EngineCore_DP0 pid=432948) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=432948) 	cvt.rzi.s32.f32 	%r143, %r142;
(EngineCore_DP0 pid=432948) 	cvt.rzi.s32.f32 	%r144, %r141;
(EngineCore_DP0 pid=432948) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=432948) 	shl.b32 	%r145, %r144, 8;
(EngineCore_DP0 pid=432948) 	shl.b32 	%r146, %r143, 16;
(EngineCore_DP0 pid=432948) 	and.b32 	%r147, %r146, 16711680;
(EngineCore_DP0 pid=432948) 	and.b32 	%r148, %r145, 65280;
(EngineCore_DP0 pid=432948) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=432948) 	or.b32 	%r149, %r148, %r119;
(EngineCore_DP0 pid=432948) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=432948) 	max.f32 	%r150, %r128, 0fC3000000;
(EngineCore_DP0 pid=432948) 	max.f32 	%r151, %r124, 0fC3000000;
(EngineCore_DP0 pid=432948) 	min.f32 	%r152, %r151, 0f42FE0000;
(EngineCore_DP0 pid=432948) 	min.f32 	%r153, %r150, 0f42FE0000;
(EngineCore_DP0 pid=432948) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=432948) 	cvt.rzi.s32.f32 	%r154, %r153;
(EngineCore_DP0 pid=432948) 	cvt.rzi.s32.f32 	%r155, %r152;
(EngineCore_DP0 pid=432948) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=432948) 	shl.b32 	%r156, %r155, 8;
(EngineCore_DP0 pid=432948) 	shl.b32 	%r157, %r154, 16;
(EngineCore_DP0 pid=432948) 	and.b32 	%r158, %r157, 16711680;
(EngineCore_DP0 pid=432948) 	and.b32 	%r159, %r156, 65280;
(EngineCore_DP0 pid=432948) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=432948) 	or.b32 	%r160, %r159, %r120;
(EngineCore_DP0 pid=432948) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=432948) 	or.b32 	%r161, %r149, %r147;
(EngineCore_DP0 pid=432948) 	or.b32 	%r162, %r160, %r158;
(EngineCore_DP0 pid=432948) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=432948) 	shl.b32 	%r163, %r137, 24;
(EngineCore_DP0 pid=432948) 	shl.b32 	%r164, %r138, 24;
(EngineCore_DP0 pid=432948) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=432948) 	or.b32 	%r83, %r161, %r163;
(EngineCore_DP0 pid=432948) 	or.b32 	%r84, %r162, %r164;
(EngineCore_DP0 pid=432948) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=432948) 	mad.wide.s32 	%rd17, %r85, 4, %rd2;
(EngineCore_DP0 pid=432948) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=432948) 	// begin inline asm
(EngineCore_DP0 pid=432948) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r83, %r84 };
(EngineCore_DP0 pid=432948) 	// end inline asm
(EngineCore_DP0 pid=432948) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=432948) 	add.s32 	%r168, %r168, 1024;
(EngineCore_DP0 pid=432948) 	setp.lt.s32 	%p27, %r168, %r15;
(EngineCore_DP0 pid=432948) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=432948) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=432948) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=432948) 	ret;
(EngineCore_DP0 pid=432948) $L__tmp3:
(EngineCore_DP0 pid=432948) $L__func_end0:
(EngineCore_DP0 pid=432948)                                         // -- End function
(EngineCore_DP0 pid=432948) }
(EngineCore_DP0 pid=432948) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=432948) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=432948) 	.section	.debug_abbrev
(EngineCore_DP0 pid=432948) 	{
(EngineCore_DP0 pid=432948) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=432948) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=432948) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=432948) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=432948) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=432948) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=432948) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=432948) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=432948) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=432948) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=432948) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=432948) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=432948) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=432948) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=432948) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=432948) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=432948) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=432948) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=432948) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=432948) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=432948) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=432948) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=432948) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=432948) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=432948) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=432948) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=432948) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=432948) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=432948) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=432948) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=432948) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=432948) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=432948) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=432948) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=432948) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=432948) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=432948) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=432948) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=432948) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=432948) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=432948) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=432948) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=432948) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=432948) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=432948) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=432948) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=432948) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=432948) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=432948) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=432948) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=432948) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=432948) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=432948) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=432948) 	}
(EngineCore_DP0 pid=432948) 	.section	.debug_info
(EngineCore_DP0 pid=432948) 	{
(EngineCore_DP0 pid=432948) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=432948) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=432948) .b8 0
(EngineCore_DP0 pid=432948) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=432948) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=432948) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=432948) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=432948) .b8 114
(EngineCore_DP0 pid=432948) .b8 105
(EngineCore_DP0 pid=432948) .b8 116
(EngineCore_DP0 pid=432948) .b8 111
(EngineCore_DP0 pid=432948) .b8 110
(EngineCore_DP0 pid=432948) .b8 0
(EngineCore_DP0 pid=432948) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=432948) .b8 0
(EngineCore_DP0 pid=432948) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=432948) .b8 117
(EngineCore_DP0 pid=432948) .b8 97
(EngineCore_DP0 pid=432948) .b8 110
(EngineCore_DP0 pid=432948) .b8 116
(EngineCore_DP0 pid=432948) .b8 95
(EngineCore_DP0 pid=432948) .b8 115
(EngineCore_DP0 pid=432948) .b8 108
(EngineCore_DP0 pid=432948) .b8 105
(EngineCore_DP0 pid=432948) .b8 100
(EngineCore_DP0 pid=432948) .b8 101
(EngineCore_DP0 pid=432948) .b8 95
(EngineCore_DP0 pid=432948) .b8 116
(EngineCore_DP0 pid=432948) .b8 117
(EngineCore_DP0 pid=432948) .b8 110
(EngineCore_DP0 pid=432948) .b8 101
(EngineCore_DP0 pid=432948) .b8 100
(EngineCore_DP0 pid=432948) .b8 95
(EngineCore_DP0 pid=432948) .b8 81
(EngineCore_DP0 pid=432948) .b8 119
(EngineCore_DP0 pid=432948) .b8 101
(EngineCore_DP0 pid=432948) .b8 110
(EngineCore_DP0 pid=432948) .b8 50
(EngineCore_DP0 pid=432948) .b8 46
(EngineCore_DP0 pid=432948) .b8 53
(EngineCore_DP0 pid=432948) .b8 45
(EngineCore_DP0 pid=432948) .b8 55
(EngineCore_DP0 pid=432948) .b8 66
(EngineCore_DP0 pid=432948) .b8 46
(EngineCore_DP0 pid=432948) .b8 112
(EngineCore_DP0 pid=432948) .b8 121
(EngineCore_DP0 pid=432948) .b8 0
(EngineCore_DP0 pid=432948) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=432948) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=432948) .b8 114
(EngineCore_DP0 pid=432948) .b8 111
(EngineCore_DP0 pid=432948) .b8 111
(EngineCore_DP0 pid=432948) .b8 116
(EngineCore_DP0 pid=432948) .b8 47
(EngineCore_DP0 pid=432948) .b8 118
(EngineCore_DP0 pid=432948) .b8 108
(EngineCore_DP0 pid=432948) .b8 108
(EngineCore_DP0 pid=432948) .b8 109
(EngineCore_DP0 pid=432948) .b8 98
(EngineCore_DP0 pid=432948) .b8 101
(EngineCore_DP0 pid=432948) .b8 110
(EngineCore_DP0 pid=432948) .b8 99
(EngineCore_DP0 pid=432948) .b8 104
(EngineCore_DP0 pid=432948) .b8 47
(EngineCore_DP0 pid=432948) .b8 115
(EngineCore_DP0 pid=432948) .b8 108
(EngineCore_DP0 pid=432948) .b8 105
(EngineCore_DP0 pid=432948) .b8 100
(EngineCore_DP0 pid=432948) .b8 101
(EngineCore_DP0 pid=432948) .b8 115
(EngineCore_DP0 pid=432948) .b8 112
(EngineCore_DP0 pid=432948) .b8 97
(EngineCore_DP0 pid=432948) .b8 114
(EngineCore_DP0 pid=432948) .b8 115
(EngineCore_DP0 pid=432948) .b8 101
(EngineCore_DP0 pid=432948) .b8 47
(EngineCore_DP0 pid=432948) .b8 99
(EngineCore_DP0 pid=432948) .b8 115
(EngineCore_DP0 pid=432948) .b8 114
(EngineCore_DP0 pid=432948) .b8 99
(EngineCore_DP0 pid=432948) .b8 47
(EngineCore_DP0 pid=432948) .b8 102
(EngineCore_DP0 pid=432948) .b8 117
(EngineCore_DP0 pid=432948) .b8 115
(EngineCore_DP0 pid=432948) .b8 101
(EngineCore_DP0 pid=432948) .b8 100
(EngineCore_DP0 pid=432948) .b8 95
(EngineCore_DP0 pid=432948) .b8 113
(EngineCore_DP0 pid=432948) .b8 117
(EngineCore_DP0 pid=432948) .b8 97
(EngineCore_DP0 pid=432948) .b8 110
(EngineCore_DP0 pid=432948) .b8 116
(EngineCore_DP0 pid=432948) .b8 95
(EngineCore_DP0 pid=432948) .b8 115
(EngineCore_DP0 pid=432948) .b8 108
(EngineCore_DP0 pid=432948) .b8 105
(EngineCore_DP0 pid=432948) .b8 100
(EngineCore_DP0 pid=432948) .b8 101
(EngineCore_DP0 pid=432948) .b8 95
(EngineCore_DP0 pid=432948) .b8 116
(EngineCore_DP0 pid=432948) .b8 114
(EngineCore_DP0 pid=432948) .b8 105
(EngineCore_DP0 pid=432948) .b8 116
(EngineCore_DP0 pid=432948) .b8 111
(EngineCore_DP0 pid=432948) .b8 110
(EngineCore_DP0 pid=432948) .b8 47
(EngineCore_DP0 pid=432948) .b8 98
(EngineCore_DP0 pid=432948) .b8 117
(EngineCore_DP0 pid=432948) .b8 105
(EngineCore_DP0 pid=432948) .b8 108
(EngineCore_DP0 pid=432948) .b8 100
(EngineCore_DP0 pid=432948) .b8 47
(EngineCore_DP0 pid=432948) .b8 71
(EngineCore_DP0 pid=432948) .b8 66
(EngineCore_DP0 pid=432948) .b8 49
(EngineCore_DP0 pid=432948) .b8 48
(EngineCore_DP0 pid=432948) .b8 95
(EngineCore_DP0 pid=432948) .b8 99
(EngineCore_DP0 pid=432948) .b8 99
(EngineCore_DP0 pid=432948) .b8 49
(EngineCore_DP0 pid=432948) .b8 50
(EngineCore_DP0 pid=432948) .b8 49
(EngineCore_DP0 pid=432948) .b8 95
(EngineCore_DP0 pid=432948) .b8 112
(EngineCore_DP0 pid=432948) .b8 121
(EngineCore_DP0 pid=432948) .b8 51
(EngineCore_DP0 pid=432948) .b8 49
(EngineCore_DP0 pid=432948) .b8 50
(EngineCore_DP0 pid=432948) .b8 95
(EngineCore_DP0 pid=432948) .b8 99
(EngineCore_DP0 pid=432948) .b8 117
(EngineCore_DP0 pid=432948) .b8 49
(EngineCore_DP0 pid=432948) .b8 50
(EngineCore_DP0 pid=432948) .b8 57
(EngineCore_DP0 pid=432948) .b8 95
(EngineCore_DP0 pid=432948) .b8 97
(EngineCore_DP0 pid=432948) .b8 97
(EngineCore_DP0 pid=432948) .b8 114
(EngineCore_DP0 pid=432948) .b8 99
(EngineCore_DP0 pid=432948) .b8 104
(EngineCore_DP0 pid=432948) .b8 54
(EngineCore_DP0 pid=432948) .b8 52
(EngineCore_DP0 pid=432948) .b8 0
(EngineCore_DP0 pid=432948) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=432948) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=432948) .b8 113
(EngineCore_DP0 pid=432948) .b8 117
(EngineCore_DP0 pid=432948) .b8 97
(EngineCore_DP0 pid=432948) .b8 110
(EngineCore_DP0 pid=432948) .b8 116
(EngineCore_DP0 pid=432948) .b8 95
(EngineCore_DP0 pid=432948) .b8 115
(EngineCore_DP0 pid=432948) .b8 108
(EngineCore_DP0 pid=432948) .b8 105
(EngineCore_DP0 pid=432948) .b8 100
(EngineCore_DP0 pid=432948) .b8 101
(EngineCore_DP0 pid=432948) .b8 95
(EngineCore_DP0 pid=432948) .b8 105
(EngineCore_DP0 pid=432948) .b8 110
(EngineCore_DP0 pid=432948) .b8 116
(EngineCore_DP0 pid=432948) .b8 56
(EngineCore_DP0 pid=432948) .b8 95
(EngineCore_DP0 pid=432948) .b8 107
(EngineCore_DP0 pid=432948) .b8 101
(EngineCore_DP0 pid=432948) .b8 114
(EngineCore_DP0 pid=432948) .b8 110
(EngineCore_DP0 pid=432948) .b8 101
(EngineCore_DP0 pid=432948) .b8 108
(EngineCore_DP0 pid=432948) .b8 0
(EngineCore_DP0 pid=432948) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=432948) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=432948) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=432948) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=432948) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=432948) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=432948) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=432948) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=432948) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=432948) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=432948) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=432948) .b8 1
(EngineCore_DP0 pid=432948) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=432948) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=432948) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=432948) 	}
(EngineCore_DP0 pid=432948) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=432948) 
(EngineCore_DP0 pid=432948) ================================================================
(EngineCore_DP0 pid=432948) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=432948) 
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpumzvsy_y.ptx', '-o', '/tmp/tmpumzvsy_y.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866] 
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866] 
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866] 
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpumzvsy_y.ptx -o /tmp/tmpumzvsy_y.ptx.o
(EngineCore_DP0 pid=432948) ERROR 01-25 20:43:51 [core.py:866] 

STDERR:
[2026-01-25 20:42:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:42:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:42:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:42:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:42:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:42:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:42:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:42:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:42:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:42:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:42:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:42:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:42:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:42:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:42:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:42:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:42:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:42:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:42:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:42:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:42:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:42:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:42:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:42:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:42:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:42:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:42:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:42:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=432948) [2026-01-25 20:42:51] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=432948) [2026-01-25 20:42:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=432948) [2026-01-25 20:42:51] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=432948) [2026-01-25 20:42:51] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=432948) [2026-01-25 20:42:51] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=432948) [2026-01-25 20:42:51] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=432948) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=432948) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:23<00:23, 23.82s/it]
(EngineCore_DP0 pid=432948) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:57<00:00, 29.37s/it]
(EngineCore_DP0 pid=432948) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:57<00:00, 28.53s/it]
(EngineCore_DP0 pid=432948) 
(EngineCore_DP0 pid=432948) [2026-01-25 20:43:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=432948) [2026-01-25 20:43:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=432948) [2026-01-25 20:43:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=432948) [2026-01-25 20:43:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=432948) [2026-01-25 20:43:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=432948) [2026-01-25 20:43:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=432948) [2026-01-25 20:43:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=432948) [2026-01-25 20:43:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=432948) Process EngineCore_DP0:
(EngineCore_DP0 pid=432948) Traceback (most recent call last):
(EngineCore_DP0 pid=432948)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=432948)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=432948)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=432948)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=432948) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpumzvsy_y.ptx', '-o', '/tmp/tmpumzvsy_y.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=432948) 
(EngineCore_DP0 pid=432948) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=432948) 
(EngineCore_DP0 pid=432948) Traceback (most recent call last):
(EngineCore_DP0 pid=432948)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=432948)     self.run()
(EngineCore_DP0 pid=432948)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=432948)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=432948)     raise e
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=432948)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=432948)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=432948)     super().__init__(
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=432948)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=432948)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=432948)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=432948)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=432948)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=432948)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=432948)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=432948)     return func(*args, **kwargs)
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=432948)     return func(*args, **kwargs)
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=432948)     self.model_runner.profile_run()
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=432948)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=432948)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=432948)     return func(*args, **kwargs)
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=432948)     outputs = self.model(
(EngineCore_DP0 pid=432948)               ^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=432948)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=432948)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=432948)     hidden_states = self.model(
(EngineCore_DP0 pid=432948)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=432948)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=432948)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=432948)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=432948)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=432948)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=432948)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=432948)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=432948)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=432948)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=432948)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=432948)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=432948)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=432948)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=432948)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=432948)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=432948)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=432948)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=432948)     return self._linear_fn(
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=432948)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=432948)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=432948)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=432948)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=432948)     return fn(input, L)
(EngineCore_DP0 pid=432948)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=432948)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=432948)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=432948)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=432948)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=432948)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=432948)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=432948)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=432948)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=432948)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=432948)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=432948)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=432948)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=432948)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=432948)     raise PTXASError(error)
(EngineCore_DP0 pid=432948) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=432948) `ptxas` stderr:
(EngineCore_DP0 pid=432948) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=432948) 
(EngineCore_DP0 pid=432948) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpumzvsy_y.ptx -o /tmp/tmpumzvsy_y.ptx.o
(EngineCore_DP0 pid=432948) 
[rank0]:[W125 20:43:52.331232218 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 20:43:53
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:44:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:44:11 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=434300) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=434300) 
(EngineCore_DP0 pid=434300) 
(EngineCore_DP0 pid=434300) ================================================================
(EngineCore_DP0 pid=434300) Internal Triton PTX codegen error
(EngineCore_DP0 pid=434300) `ptxas` stderr:
(EngineCore_DP0 pid=434300) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=434300) 
(EngineCore_DP0 pid=434300) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmptvsx1pac.ptx -o /tmp/tmptvsx1pac.ptx.o
(EngineCore_DP0 pid=434300) 
(EngineCore_DP0 pid=434300) 
(EngineCore_DP0 pid=434300) //
(EngineCore_DP0 pid=434300) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=434300) //
(EngineCore_DP0 pid=434300) 
(EngineCore_DP0 pid=434300) .version 8.7
(EngineCore_DP0 pid=434300) .target sm_121a
(EngineCore_DP0 pid=434300) .address_size 64
(EngineCore_DP0 pid=434300) 
(EngineCore_DP0 pid=434300) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=434300) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=434300)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=434300) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=434300) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=434300) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=434300) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=434300) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=434300) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=434300) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=434300) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=434300) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=434300) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=434300) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=434300) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=434300) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=434300) )
(EngineCore_DP0 pid=434300) .reqntid 512
(EngineCore_DP0 pid=434300) {
(EngineCore_DP0 pid=434300) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=434300) 	.reg .b16 	%rs<40>;
(EngineCore_DP0 pid=434300) 	.reg .b32 	%r<160>;
(EngineCore_DP0 pid=434300) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=434300) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=434300) $L__func_begin0:
(EngineCore_DP0 pid=434300) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=434300) 
(EngineCore_DP0 pid=434300) // %bb.0:
(EngineCore_DP0 pid=434300) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=434300) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=434300) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=434300) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=434300) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=434300) $L__tmp0:
(EngineCore_DP0 pid=434300) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=434300) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=434300) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=434300) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=434300) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=434300) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=434300) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=434300) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=434300) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=434300) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=434300) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=434300) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=434300) 	mov.b32 	%r158, 0f2B8CBCCC;
(EngineCore_DP0 pid=434300) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=434300) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=434300) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=434300) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=434300) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=434300) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=434300) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=434300) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=434300) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=434300) 	add.s32 	%r45, %r35, %r34;
(EngineCore_DP0 pid=434300) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=434300) 	add.s32 	%r48, %r35, %r36;
(EngineCore_DP0 pid=434300) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=434300) 	mov.b32 	%r156, 0f00000000;
(EngineCore_DP0 pid=434300) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=434300) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=434300) 	mov.b32 	%r157, %r41;
(EngineCore_DP0 pid=434300) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=434300) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=434300) 	add.s32 	%r51, %r4, %r157;
(EngineCore_DP0 pid=434300) 	setp.lt.s32 	%p2, %r51, %r19;
(EngineCore_DP0 pid=434300) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=434300) 	mad.wide.s32 	%rd6, %r51, 2, %rd1;
(EngineCore_DP0 pid=434300) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=434300) 	// begin inline asm
(EngineCore_DP0 pid=434300) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=434300) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=434300) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=434300) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=434300) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=434300) 	// end inline asm
(EngineCore_DP0 pid=434300) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=434300) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=434300) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=434300) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=434300) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=434300) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=434300) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=434300) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=434300) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=434300) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=434300) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=434300) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=434300) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=434300) $L__tmp1:
(EngineCore_DP0 pid=434300) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	bar.sync 	0;
(EngineCore_DP0 pid=434300) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=434300) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=434300) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=434300) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=434300) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=434300) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=434300) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=434300) 	cvt.f32.bf16 	%r52, %rs23;
(EngineCore_DP0 pid=434300) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	shfl.sync.bfly.b32 	%r53, %r52, 16, 31, -1;
(EngineCore_DP0 pid=434300) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=434300) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	shfl.sync.bfly.b32 	%r55, %r54, 8, 31, -1;
(EngineCore_DP0 pid=434300) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=434300) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	shfl.sync.bfly.b32 	%r57, %r56, 4, 31, -1;
(EngineCore_DP0 pid=434300) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=434300) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	shfl.sync.bfly.b32 	%r59, %r58, 2, 31, -1;
(EngineCore_DP0 pid=434300) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=434300) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	shfl.sync.bfly.b32 	%r61, %r60, 1, 31, -1;
(EngineCore_DP0 pid=434300) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	max.f32 	%r46, %r60, %r61;
(EngineCore_DP0 pid=434300) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	// begin inline asm
(EngineCore_DP0 pid=434300) 	@%p3 st.shared.b32 [ %r45 + 0 ], %r46;
(EngineCore_DP0 pid=434300) 	// end inline asm
(EngineCore_DP0 pid=434300) 	bar.sync 	0;
(EngineCore_DP0 pid=434300) 	// begin inline asm
(EngineCore_DP0 pid=434300) 	@%p4 ld.shared.b32 %r47, [ %r48 + 0 ];
(EngineCore_DP0 pid=434300) 	// end inline asm
(EngineCore_DP0 pid=434300) 	shfl.sync.bfly.b32 	%r62, %r47, 8, 31, -1;
(EngineCore_DP0 pid=434300) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	max.f32 	%r63, %r47, %r62;
(EngineCore_DP0 pid=434300) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	shfl.sync.bfly.b32 	%r64, %r63, 4, 31, -1;
(EngineCore_DP0 pid=434300) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=434300) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	shfl.sync.bfly.b32 	%r66, %r65, 2, 31, -1;
(EngineCore_DP0 pid=434300) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=434300) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	shfl.sync.bfly.b32 	%r68, %r67, 1, 31, -1;
(EngineCore_DP0 pid=434300) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	max.f32 	%r50, %r67, %r68;
(EngineCore_DP0 pid=434300) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=434300) 	// begin inline asm
(EngineCore_DP0 pid=434300) 	@%p27 st.shared.b32 [ %r48 + 0 ], %r50;
(EngineCore_DP0 pid=434300) 	// end inline asm
(EngineCore_DP0 pid=434300) 	bar.sync 	0;
(EngineCore_DP0 pid=434300) 	ld.shared.b32 	%r69, [global_smem];
(EngineCore_DP0 pid=434300) $L__tmp2:
(EngineCore_DP0 pid=434300) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=434300) 	max.f32 	%r156, %r156, %r69;
(EngineCore_DP0 pid=434300) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=434300) 	add.s32 	%r157, %r157, 4096;
(EngineCore_DP0 pid=434300) 	setp.lt.s32 	%p6, %r157, %r20;
(EngineCore_DP0 pid=434300) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=434300) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=434300) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=434300) 	max.f32 	%r158, %r156, 0f2B8CBCCC;
(EngineCore_DP0 pid=434300) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=434300) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=434300) 	mov.b32 	%r71, 0f42FE0000;
(EngineCore_DP0 pid=434300) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=434300) 	div.full.f32 	%r72, %r158, %r71;
(EngineCore_DP0 pid=434300) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=434300) 	max.f32 	%r70, %r72, 0f37810204;
(EngineCore_DP0 pid=434300) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=434300) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=434300) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=434300) 	// begin inline asm
(EngineCore_DP0 pid=434300) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r70 };
(EngineCore_DP0 pid=434300) 	// end inline asm
(EngineCore_DP0 pid=434300) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=434300) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=434300) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=434300) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=434300) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=434300) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=434300) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=434300) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=434300) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=434300) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=434300) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=434300) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=434300) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=434300) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=434300) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=434300) 	div.full.f32 	%r14, %r71, %r158;
(EngineCore_DP0 pid=434300) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=434300) 	mov.b32 	%r159, 0;
(EngineCore_DP0 pid=434300) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=434300)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=434300) 	.loc	1 279 31                        // quant_slide_tuned_Qwen2.5-7B.py:279:31
(EngineCore_DP0 pid=434300) 	add.s32 	%r76, %r16, %r159;
(EngineCore_DP0 pid=434300) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=434300) 	add.s32 	%r77, %r159, 1;
(EngineCore_DP0 pid=434300) 	setp.lt.s32 	%p17, %r76, %r15;
(EngineCore_DP0 pid=434300) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=434300) 	shr.u32 	%r78, %r76, 1;
(EngineCore_DP0 pid=434300) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=434300) 	shr.u32 	%r79, %r77, 31;
(EngineCore_DP0 pid=434300) 	add.s32 	%r80, %r77, %r79;
(EngineCore_DP0 pid=434300) 	and.b32 	%r81, %r80, 2147483646;
(EngineCore_DP0 pid=434300) 	sub.s32 	%r82, %r77, %r81;
(EngineCore_DP0 pid=434300) 	.loc	1 285 22                        // quant_slide_tuned_Qwen2.5-7B.py:285:22
(EngineCore_DP0 pid=434300) 	mul.lo.s32 	%r83, %r78, 6;
(EngineCore_DP0 pid=434300) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=434300) 	shl.b32 	%r84, %r82, 1;
(EngineCore_DP0 pid=434300) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=434300) 	add.s32 	%r85, %r83, %r84;
(EngineCore_DP0 pid=434300) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=434300) 	setp.lt.s32 	%p18, %r83, %r19;
(EngineCore_DP0 pid=434300) 	setp.lt.s32 	%p19, %r85, %r19;
(EngineCore_DP0 pid=434300) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=434300) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=434300) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=434300) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=434300) 	mad.wide.s32 	%rd8, %r83, 2, %rd1;
(EngineCore_DP0 pid=434300) 	mad.wide.s32 	%rd9, %r85, 2, %rd1;
(EngineCore_DP0 pid=434300) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=434300) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=434300) 	// begin inline asm
(EngineCore_DP0 pid=434300) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=434300) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=434300) 	// end inline asm
(EngineCore_DP0 pid=434300) 	// begin inline asm
(EngineCore_DP0 pid=434300) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=434300) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=434300) 	// end inline asm
(EngineCore_DP0 pid=434300) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=434300) 	cvt.f32.bf16 	%r86, %rs24;
(EngineCore_DP0 pid=434300) 	cvt.f32.bf16 	%r87, %rs26;
(EngineCore_DP0 pid=434300) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=434300) 	or.b32 	%r88, %r83, 1;
(EngineCore_DP0 pid=434300) 	or.b32 	%r89, %r85, 1;
(EngineCore_DP0 pid=434300) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=434300) 	setp.lt.s32 	%p20, %r88, %r19;
(EngineCore_DP0 pid=434300) 	setp.lt.s32 	%p21, %r89, %r19;
(EngineCore_DP0 pid=434300) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=434300) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=434300) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=434300) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=434300) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=434300) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=434300) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=434300) 	// begin inline asm
(EngineCore_DP0 pid=434300) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=434300) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=434300) 	// end inline asm
(EngineCore_DP0 pid=434300) 	// begin inline asm
(EngineCore_DP0 pid=434300) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=434300) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=434300) 	// end inline asm
(EngineCore_DP0 pid=434300) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=434300) 	cvt.f32.bf16 	%r90, %rs28;
(EngineCore_DP0 pid=434300) 	cvt.f32.bf16 	%r91, %rs30;
(EngineCore_DP0 pid=434300) 	.loc	1 292 48                        // quant_slide_tuned_Qwen2.5-7B.py:292:48
(EngineCore_DP0 pid=434300) 	add.s32 	%r92, %r83, 2;
(EngineCore_DP0 pid=434300) 	add.s32 	%r93, %r85, 2;
(EngineCore_DP0 pid=434300) 	.loc	1 292 53                        // quant_slide_tuned_Qwen2.5-7B.py:292:53
(EngineCore_DP0 pid=434300) 	setp.lt.s32 	%p22, %r92, %r19;
(EngineCore_DP0 pid=434300) 	setp.lt.s32 	%p23, %r93, %r19;
(EngineCore_DP0 pid=434300) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=434300) 	and.pred 	%p13, %p17, %p22;
(EngineCore_DP0 pid=434300) 	and.pred 	%p14, %p17, %p23;
(EngineCore_DP0 pid=434300) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=434300) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=434300) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=434300) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=434300) 	// begin inline asm
(EngineCore_DP0 pid=434300) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=434300) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=434300) 	// end inline asm
(EngineCore_DP0 pid=434300) 	// begin inline asm
(EngineCore_DP0 pid=434300) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=434300) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=434300) 	// end inline asm
(EngineCore_DP0 pid=434300) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=434300) 	cvt.f32.bf16 	%r94, %rs32;
(EngineCore_DP0 pid=434300) 	cvt.f32.bf16 	%r95, %rs34;
(EngineCore_DP0 pid=434300) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=434300) 	add.s32 	%r96, %r83, 3;
(EngineCore_DP0 pid=434300) 	add.s32 	%r97, %r85, 3;
(EngineCore_DP0 pid=434300) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=434300) 	setp.lt.s32 	%p24, %r96, %r19;
(EngineCore_DP0 pid=434300) 	setp.lt.s32 	%p25, %r97, %r19;
(EngineCore_DP0 pid=434300) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=434300) 	and.pred 	%p15, %p17, %p24;
(EngineCore_DP0 pid=434300) 	and.pred 	%p16, %p17, %p25;
(EngineCore_DP0 pid=434300) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=434300) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=434300) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=434300) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=434300) 	// begin inline asm
(EngineCore_DP0 pid=434300) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=434300) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=434300) 	// end inline asm
(EngineCore_DP0 pid=434300) 	// begin inline asm
(EngineCore_DP0 pid=434300) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=434300) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=434300) 	// end inline asm
(EngineCore_DP0 pid=434300) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=434300) 	cvt.f32.bf16 	%r98, %rs36;
(EngineCore_DP0 pid=434300) 	cvt.f32.bf16 	%r99, %rs38;
(EngineCore_DP0 pid=434300) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=434300) 	mul.f32 	%r100, %r14, %r86;
(EngineCore_DP0 pid=434300) 	mul.f32 	%r101, %r14, %r87;
(EngineCore_DP0 pid=434300) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=434300) 	cvt.rni.f32.f32 	%r102, %r100;
(EngineCore_DP0 pid=434300) 	cvt.rni.f32.f32 	%r103, %r101;
(EngineCore_DP0 pid=434300) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=434300) 	max.f32 	%r104, %r102, 0fC3000000;
(EngineCore_DP0 pid=434300) 	min.f32 	%r105, %r104, 0f42FE0000;
(EngineCore_DP0 pid=434300) 	max.f32 	%r106, %r103, 0fC3000000;
(EngineCore_DP0 pid=434300) 	min.f32 	%r107, %r106, 0f42FE0000;
(EngineCore_DP0 pid=434300) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=434300) 	cvt.rzi.s32.f32 	%r108, %r105;
(EngineCore_DP0 pid=434300) 	cvt.rzi.s32.f32 	%r109, %r107;
(EngineCore_DP0 pid=434300) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=434300) 	and.b32 	%r110, %r108, 255;
(EngineCore_DP0 pid=434300) 	and.b32 	%r111, %r109, 255;
(EngineCore_DP0 pid=434300) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=434300) 	mul.f32 	%r112, %r14, %r90;
(EngineCore_DP0 pid=434300) 	mul.f32 	%r113, %r14, %r91;
(EngineCore_DP0 pid=434300) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=434300) 	cvt.rni.f32.f32 	%r114, %r112;
(EngineCore_DP0 pid=434300) 	cvt.rni.f32.f32 	%r115, %r113;
(EngineCore_DP0 pid=434300) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=434300) 	mul.f32 	%r116, %r14, %r94;
(EngineCore_DP0 pid=434300) 	mul.f32 	%r117, %r14, %r95;
(EngineCore_DP0 pid=434300) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=434300) 	cvt.rni.f32.f32 	%r118, %r116;
(EngineCore_DP0 pid=434300) 	cvt.rni.f32.f32 	%r119, %r117;
(EngineCore_DP0 pid=434300) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=434300) 	mul.f32 	%r120, %r14, %r98;
(EngineCore_DP0 pid=434300) 	mul.f32 	%r121, %r14, %r99;
(EngineCore_DP0 pid=434300) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=434300) 	cvt.rni.f32.f32 	%r122, %r120;
(EngineCore_DP0 pid=434300) 	cvt.rni.f32.f32 	%r123, %r121;
(EngineCore_DP0 pid=434300) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=434300) 	max.f32 	%r124, %r122, 0fC3000000;
(EngineCore_DP0 pid=434300) 	min.f32 	%r125, %r124, 0f42FE0000;
(EngineCore_DP0 pid=434300) 	max.f32 	%r126, %r123, 0fC3000000;
(EngineCore_DP0 pid=434300) 	min.f32 	%r127, %r126, 0f42FE0000;
(EngineCore_DP0 pid=434300) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=434300) 	cvt.rzi.s32.f32 	%r128, %r125;
(EngineCore_DP0 pid=434300) 	cvt.rzi.s32.f32 	%r129, %r127;
(EngineCore_DP0 pid=434300) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=434300) 	max.f32 	%r130, %r118, 0fC3000000;
(EngineCore_DP0 pid=434300) 	max.f32 	%r131, %r114, 0fC3000000;
(EngineCore_DP0 pid=434300) 	min.f32 	%r132, %r131, 0f42FE0000;
(EngineCore_DP0 pid=434300) 	min.f32 	%r133, %r130, 0f42FE0000;
(EngineCore_DP0 pid=434300) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=434300) 	cvt.rzi.s32.f32 	%r134, %r133;
(EngineCore_DP0 pid=434300) 	cvt.rzi.s32.f32 	%r135, %r132;
(EngineCore_DP0 pid=434300) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=434300) 	shl.b32 	%r136, %r135, 8;
(EngineCore_DP0 pid=434300) 	shl.b32 	%r137, %r134, 16;
(EngineCore_DP0 pid=434300) 	and.b32 	%r138, %r137, 16711680;
(EngineCore_DP0 pid=434300) 	and.b32 	%r139, %r136, 65280;
(EngineCore_DP0 pid=434300) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=434300) 	or.b32 	%r140, %r139, %r110;
(EngineCore_DP0 pid=434300) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=434300) 	max.f32 	%r141, %r119, 0fC3000000;
(EngineCore_DP0 pid=434300) 	max.f32 	%r142, %r115, 0fC3000000;
(EngineCore_DP0 pid=434300) 	min.f32 	%r143, %r142, 0f42FE0000;
(EngineCore_DP0 pid=434300) 	min.f32 	%r144, %r141, 0f42FE0000;
(EngineCore_DP0 pid=434300) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=434300) 	cvt.rzi.s32.f32 	%r145, %r144;
(EngineCore_DP0 pid=434300) 	cvt.rzi.s32.f32 	%r146, %r143;
(EngineCore_DP0 pid=434300) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=434300) 	shl.b32 	%r147, %r146, 8;
(EngineCore_DP0 pid=434300) 	shl.b32 	%r148, %r145, 16;
(EngineCore_DP0 pid=434300) 	and.b32 	%r149, %r148, 16711680;
(EngineCore_DP0 pid=434300) 	and.b32 	%r150, %r147, 65280;
(EngineCore_DP0 pid=434300) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=434300) 	or.b32 	%r151, %r150, %r111;
(EngineCore_DP0 pid=434300) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=434300) 	or.b32 	%r152, %r140, %r138;
(EngineCore_DP0 pid=434300) 	or.b32 	%r153, %r151, %r149;
(EngineCore_DP0 pid=434300) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=434300) 	shl.b32 	%r154, %r128, 24;
(EngineCore_DP0 pid=434300) 	shl.b32 	%r155, %r129, 24;
(EngineCore_DP0 pid=434300) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=434300) 	or.b32 	%r74, %r152, %r154;
(EngineCore_DP0 pid=434300) 	or.b32 	%r75, %r153, %r155;
(EngineCore_DP0 pid=434300) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=434300) 	mad.wide.s32 	%rd16, %r76, 4, %rd2;
(EngineCore_DP0 pid=434300) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=434300) 	// begin inline asm
(EngineCore_DP0 pid=434300) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r74, %r75 };
(EngineCore_DP0 pid=434300) 	// end inline asm
(EngineCore_DP0 pid=434300) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=434300) 	add.s32 	%r159, %r159, 1024;
(EngineCore_DP0 pid=434300) 	setp.lt.s32 	%p26, %r159, %r15;
(EngineCore_DP0 pid=434300) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=434300) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=434300) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=434300) 	ret;
(EngineCore_DP0 pid=434300) $L__tmp3:
(EngineCore_DP0 pid=434300) $L__func_end0:
(EngineCore_DP0 pid=434300)                                         // -- End function
(EngineCore_DP0 pid=434300) }
(EngineCore_DP0 pid=434300) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=434300) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=434300) 	.section	.debug_abbrev
(EngineCore_DP0 pid=434300) 	{
(EngineCore_DP0 pid=434300) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=434300) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=434300) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=434300) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=434300) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=434300) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=434300) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=434300) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=434300) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=434300) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=434300) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=434300) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=434300) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=434300) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=434300) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=434300) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=434300) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=434300) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=434300) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=434300) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=434300) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=434300) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=434300) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=434300) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=434300) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=434300) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=434300) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=434300) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=434300) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=434300) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=434300) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=434300) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=434300) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=434300) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=434300) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=434300) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=434300) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=434300) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=434300) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=434300) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=434300) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=434300) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=434300) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=434300) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=434300) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=434300) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=434300) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=434300) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=434300) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=434300) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=434300) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=434300) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=434300) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=434300) 	}
(EngineCore_DP0 pid=434300) 	.section	.debug_info
(EngineCore_DP0 pid=434300) 	{
(EngineCore_DP0 pid=434300) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=434300) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=434300) .b8 0
(EngineCore_DP0 pid=434300) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=434300) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=434300) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=434300) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=434300) .b8 114
(EngineCore_DP0 pid=434300) .b8 105
(EngineCore_DP0 pid=434300) .b8 116
(EngineCore_DP0 pid=434300) .b8 111
(EngineCore_DP0 pid=434300) .b8 110
(EngineCore_DP0 pid=434300) .b8 0
(EngineCore_DP0 pid=434300) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=434300) .b8 0
(EngineCore_DP0 pid=434300) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=434300) .b8 117
(EngineCore_DP0 pid=434300) .b8 97
(EngineCore_DP0 pid=434300) .b8 110
(EngineCore_DP0 pid=434300) .b8 116
(EngineCore_DP0 pid=434300) .b8 95
(EngineCore_DP0 pid=434300) .b8 115
(EngineCore_DP0 pid=434300) .b8 108
(EngineCore_DP0 pid=434300) .b8 105
(EngineCore_DP0 pid=434300) .b8 100
(EngineCore_DP0 pid=434300) .b8 101
(EngineCore_DP0 pid=434300) .b8 95
(EngineCore_DP0 pid=434300) .b8 116
(EngineCore_DP0 pid=434300) .b8 117
(EngineCore_DP0 pid=434300) .b8 110
(EngineCore_DP0 pid=434300) .b8 101
(EngineCore_DP0 pid=434300) .b8 100
(EngineCore_DP0 pid=434300) .b8 95
(EngineCore_DP0 pid=434300) .b8 81
(EngineCore_DP0 pid=434300) .b8 119
(EngineCore_DP0 pid=434300) .b8 101
(EngineCore_DP0 pid=434300) .b8 110
(EngineCore_DP0 pid=434300) .b8 50
(EngineCore_DP0 pid=434300) .b8 46
(EngineCore_DP0 pid=434300) .b8 53
(EngineCore_DP0 pid=434300) .b8 45
(EngineCore_DP0 pid=434300) .b8 55
(EngineCore_DP0 pid=434300) .b8 66
(EngineCore_DP0 pid=434300) .b8 46
(EngineCore_DP0 pid=434300) .b8 112
(EngineCore_DP0 pid=434300) .b8 121
(EngineCore_DP0 pid=434300) .b8 0
(EngineCore_DP0 pid=434300) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=434300) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=434300) .b8 114
(EngineCore_DP0 pid=434300) .b8 111
(EngineCore_DP0 pid=434300) .b8 111
(EngineCore_DP0 pid=434300) .b8 116
(EngineCore_DP0 pid=434300) .b8 47
(EngineCore_DP0 pid=434300) .b8 118
(EngineCore_DP0 pid=434300) .b8 108
(EngineCore_DP0 pid=434300) .b8 108
(EngineCore_DP0 pid=434300) .b8 109
(EngineCore_DP0 pid=434300) .b8 98
(EngineCore_DP0 pid=434300) .b8 101
(EngineCore_DP0 pid=434300) .b8 110
(EngineCore_DP0 pid=434300) .b8 99
(EngineCore_DP0 pid=434300) .b8 104
(EngineCore_DP0 pid=434300) .b8 47
(EngineCore_DP0 pid=434300) .b8 115
(EngineCore_DP0 pid=434300) .b8 108
(EngineCore_DP0 pid=434300) .b8 105
(EngineCore_DP0 pid=434300) .b8 100
(EngineCore_DP0 pid=434300) .b8 101
(EngineCore_DP0 pid=434300) .b8 115
(EngineCore_DP0 pid=434300) .b8 112
(EngineCore_DP0 pid=434300) .b8 97
(EngineCore_DP0 pid=434300) .b8 114
(EngineCore_DP0 pid=434300) .b8 115
(EngineCore_DP0 pid=434300) .b8 101
(EngineCore_DP0 pid=434300) .b8 47
(EngineCore_DP0 pid=434300) .b8 99
(EngineCore_DP0 pid=434300) .b8 115
(EngineCore_DP0 pid=434300) .b8 114
(EngineCore_DP0 pid=434300) .b8 99
(EngineCore_DP0 pid=434300) .b8 47
(EngineCore_DP0 pid=434300) .b8 102
(EngineCore_DP0 pid=434300) .b8 117
(EngineCore_DP0 pid=434300) .b8 115
(EngineCore_DP0 pid=434300) .b8 101
(EngineCore_DP0 pid=434300) .b8 100
(EngineCore_DP0 pid=434300) .b8 95
(EngineCore_DP0 pid=434300) .b8 113
(EngineCore_DP0 pid=434300) .b8 117
(EngineCore_DP0 pid=434300) .b8 97
(EngineCore_DP0 pid=434300) .b8 110
(EngineCore_DP0 pid=434300) .b8 116
(EngineCore_DP0 pid=434300) .b8 95
(EngineCore_DP0 pid=434300) .b8 115
(EngineCore_DP0 pid=434300) .b8 108
(EngineCore_DP0 pid=434300) .b8 105
(EngineCore_DP0 pid=434300) .b8 100
(EngineCore_DP0 pid=434300) .b8 101
(EngineCore_DP0 pid=434300) .b8 95
(EngineCore_DP0 pid=434300) .b8 116
(EngineCore_DP0 pid=434300) .b8 114
(EngineCore_DP0 pid=434300) .b8 105
(EngineCore_DP0 pid=434300) .b8 116
(EngineCore_DP0 pid=434300) .b8 111
(EngineCore_DP0 pid=434300) .b8 110
(EngineCore_DP0 pid=434300) .b8 47
(EngineCore_DP0 pid=434300) .b8 98
(EngineCore_DP0 pid=434300) .b8 117
(EngineCore_DP0 pid=434300) .b8 105
(EngineCore_DP0 pid=434300) .b8 108
(EngineCore_DP0 pid=434300) .b8 100
(EngineCore_DP0 pid=434300) .b8 47
(EngineCore_DP0 pid=434300) .b8 71
(EngineCore_DP0 pid=434300) .b8 66
(EngineCore_DP0 pid=434300) .b8 49
(EngineCore_DP0 pid=434300) .b8 48
(EngineCore_DP0 pid=434300) .b8 95
(EngineCore_DP0 pid=434300) .b8 99
(EngineCore_DP0 pid=434300) .b8 99
(EngineCore_DP0 pid=434300) .b8 49
(EngineCore_DP0 pid=434300) .b8 50
(EngineCore_DP0 pid=434300) .b8 49
(EngineCore_DP0 pid=434300) .b8 95
(EngineCore_DP0 pid=434300) .b8 112
(EngineCore_DP0 pid=434300) .b8 121
(EngineCore_DP0 pid=434300) .b8 51
(EngineCore_DP0 pid=434300) .b8 49
(EngineCore_DP0 pid=434300) .b8 50
(EngineCore_DP0 pid=434300) .b8 95
(EngineCore_DP0 pid=434300) .b8 99
(EngineCore_DP0 pid=434300) .b8 117
(EngineCore_DP0 pid=434300) .b8 49
(EngineCore_DP0 pid=434300) .b8 50
(EngineCore_DP0 pid=434300) .b8 57
(EngineCore_DP0 pid=434300) .b8 95
(EngineCore_DP0 pid=434300) .b8 97
(EngineCore_DP0 pid=434300) .b8 97
(EngineCore_DP0 pid=434300) .b8 114
(EngineCore_DP0 pid=434300) .b8 99
(EngineCore_DP0 pid=434300) .b8 104
(EngineCore_DP0 pid=434300) .b8 54
(EngineCore_DP0 pid=434300) .b8 52
(EngineCore_DP0 pid=434300) .b8 0
(EngineCore_DP0 pid=434300) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=434300) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=434300) .b8 113
(EngineCore_DP0 pid=434300) .b8 117
(EngineCore_DP0 pid=434300) .b8 97
(EngineCore_DP0 pid=434300) .b8 110
(EngineCore_DP0 pid=434300) .b8 116
(EngineCore_DP0 pid=434300) .b8 95
(EngineCore_DP0 pid=434300) .b8 115
(EngineCore_DP0 pid=434300) .b8 108
(EngineCore_DP0 pid=434300) .b8 105
(EngineCore_DP0 pid=434300) .b8 100
(EngineCore_DP0 pid=434300) .b8 101
(EngineCore_DP0 pid=434300) .b8 95
(EngineCore_DP0 pid=434300) .b8 105
(EngineCore_DP0 pid=434300) .b8 110
(EngineCore_DP0 pid=434300) .b8 116
(EngineCore_DP0 pid=434300) .b8 56
(EngineCore_DP0 pid=434300) .b8 95
(EngineCore_DP0 pid=434300) .b8 107
(EngineCore_DP0 pid=434300) .b8 101
(EngineCore_DP0 pid=434300) .b8 114
(EngineCore_DP0 pid=434300) .b8 110
(EngineCore_DP0 pid=434300) .b8 101
(EngineCore_DP0 pid=434300) .b8 108
(EngineCore_DP0 pid=434300) .b8 0
(EngineCore_DP0 pid=434300) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=434300) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=434300) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=434300) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=434300) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=434300) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=434300) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=434300) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=434300) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=434300) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=434300) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=434300) .b8 1
(EngineCore_DP0 pid=434300) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=434300) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=434300) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=434300) 	}
(EngineCore_DP0 pid=434300) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=434300) 
(EngineCore_DP0 pid=434300) ================================================================
(EngineCore_DP0 pid=434300) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=434300) 
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmptvsx1pac.ptx', '-o', '/tmp/tmptvsx1pac.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866] 
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866] 
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866] 
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmptvsx1pac.ptx -o /tmp/tmptvsx1pac.ptx.o
(EngineCore_DP0 pid=434300) ERROR 01-25 20:45:15 [core.py:866] 

STDERR:
[2026-01-25 20:44:11] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:44:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:44:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:44:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:44:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:44:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:44:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:44:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:44:14] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:44:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:44:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:44:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:44:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:44:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:44:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:44:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:44:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=434300) [2026-01-25 20:44:15] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=434300) [2026-01-25 20:44:16] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=434300) [2026-01-25 20:44:16] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=434300) [2026-01-25 20:44:16] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=434300) [2026-01-25 20:44:16] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=434300) [2026-01-25 20:44:16] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=434300) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=434300) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:23<00:23, 23.73s/it]
(EngineCore_DP0 pid=434300) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:56<00:00, 29.11s/it]
(EngineCore_DP0 pid=434300) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:56<00:00, 28.30s/it]
(EngineCore_DP0 pid=434300) 
(EngineCore_DP0 pid=434300) [2026-01-25 20:45:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=434300) [2026-01-25 20:45:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=434300) [2026-01-25 20:45:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=434300) [2026-01-25 20:45:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=434300) [2026-01-25 20:45:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=434300) [2026-01-25 20:45:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=434300) [2026-01-25 20:45:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=434300) [2026-01-25 20:45:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=434300) Process EngineCore_DP0:
(EngineCore_DP0 pid=434300) Traceback (most recent call last):
(EngineCore_DP0 pid=434300)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=434300)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=434300)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=434300)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=434300) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmptvsx1pac.ptx', '-o', '/tmp/tmptvsx1pac.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=434300) 
(EngineCore_DP0 pid=434300) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=434300) 
(EngineCore_DP0 pid=434300) Traceback (most recent call last):
(EngineCore_DP0 pid=434300)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=434300)     self.run()
(EngineCore_DP0 pid=434300)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=434300)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=434300)     raise e
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=434300)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=434300)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=434300)     super().__init__(
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=434300)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=434300)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=434300)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=434300)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=434300)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=434300)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=434300)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=434300)     return func(*args, **kwargs)
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=434300)     return func(*args, **kwargs)
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=434300)     self.model_runner.profile_run()
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=434300)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=434300)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=434300)     return func(*args, **kwargs)
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=434300)     outputs = self.model(
(EngineCore_DP0 pid=434300)               ^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=434300)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=434300)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=434300)     hidden_states = self.model(
(EngineCore_DP0 pid=434300)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=434300)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=434300)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=434300)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=434300)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=434300)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=434300)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=434300)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=434300)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=434300)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=434300)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=434300)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=434300)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=434300)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=434300)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=434300)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=434300)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=434300)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=434300)     return self._linear_fn(
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=434300)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=434300)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=434300)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=434300)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=434300)     return fn(input, L)
(EngineCore_DP0 pid=434300)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=434300)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=434300)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=434300)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=434300)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=434300)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=434300)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=434300)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=434300)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=434300)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=434300)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=434300)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=434300)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=434300)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=434300)     raise PTXASError(error)
(EngineCore_DP0 pid=434300) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=434300) `ptxas` stderr:
(EngineCore_DP0 pid=434300) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=434300) 
(EngineCore_DP0 pid=434300) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmptvsx1pac.ptx -o /tmp/tmptvsx1pac.ptx.o
(EngineCore_DP0 pid=434300) 
[rank0]:[W125 20:45:16.389927180 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 20:45:18
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:45:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:45:50 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=435839) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=435839) 
(EngineCore_DP0 pid=435839) 
(EngineCore_DP0 pid=435839) ================================================================
(EngineCore_DP0 pid=435839) Internal Triton PTX codegen error
(EngineCore_DP0 pid=435839) `ptxas` stderr:
(EngineCore_DP0 pid=435839) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=435839) 
(EngineCore_DP0 pid=435839) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpqheo6xfv.ptx -o /tmp/tmpqheo6xfv.ptx.o
(EngineCore_DP0 pid=435839) 
(EngineCore_DP0 pid=435839) 
(EngineCore_DP0 pid=435839) //
(EngineCore_DP0 pid=435839) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=435839) //
(EngineCore_DP0 pid=435839) 
(EngineCore_DP0 pid=435839) .version 8.7
(EngineCore_DP0 pid=435839) .target sm_121a
(EngineCore_DP0 pid=435839) .address_size 64
(EngineCore_DP0 pid=435839) 
(EngineCore_DP0 pid=435839) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=435839) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=435839)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=435839) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=435839) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=435839) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=435839) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=435839) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=435839) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=435839) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=435839) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=435839) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=435839) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=435839) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=435839) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=435839) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=435839) )
(EngineCore_DP0 pid=435839) .reqntid 512
(EngineCore_DP0 pid=435839) {
(EngineCore_DP0 pid=435839) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=435839) 	.reg .b16 	%rs<56>;
(EngineCore_DP0 pid=435839) 	.reg .b32 	%r<131>;
(EngineCore_DP0 pid=435839) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=435839) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=435839) $L__func_begin0:
(EngineCore_DP0 pid=435839) 	.loc	1 244 0                         // quant_slide_tuned_Qwen2.5-7B.py:244:0
(EngineCore_DP0 pid=435839) 
(EngineCore_DP0 pid=435839) // %bb.0:
(EngineCore_DP0 pid=435839) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=435839) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=435839) 	ld.param.b32 	%r18, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=435839) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=435839) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=435839) $L__tmp0:
(EngineCore_DP0 pid=435839) 	.loc	1 254 24                        // quant_slide_tuned_Qwen2.5-7B.py:254:24
(EngineCore_DP0 pid=435839) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=435839) 	ld.param.b32 	%r22, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=435839) 	.loc	1 259 26                        // quant_slide_tuned_Qwen2.5-7B.py:259:26
(EngineCore_DP0 pid=435839) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=435839) 	.loc	1 259 20                        // quant_slide_tuned_Qwen2.5-7B.py:259:20
(EngineCore_DP0 pid=435839) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=435839) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=435839) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=435839) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=435839) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=435839) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=435839) 	mov.b32 	%r129, 0f2B8CBCCC;
(EngineCore_DP0 pid=435839) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=435839) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=435839) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=435839) 	.loc	1 265 32                        // quant_slide_tuned_Qwen2.5-7B.py:265:32
(EngineCore_DP0 pid=435839) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=435839) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=435839) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=435839) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=435839) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=435839) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=435839) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=435839) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=435839) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=435839) 	mov.b32 	%r127, 0f00000000;
(EngineCore_DP0 pid=435839) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=435839) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=435839) 	mov.b32 	%r128, %r40;
(EngineCore_DP0 pid=435839) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=435839) 	.loc	1 265 19                        // quant_slide_tuned_Qwen2.5-7B.py:265:19
(EngineCore_DP0 pid=435839) 	add.s32 	%r58, %r4, %r128;
(EngineCore_DP0 pid=435839) 	.loc	1 266 22                        // quant_slide_tuned_Qwen2.5-7B.py:266:22
(EngineCore_DP0 pid=435839) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=435839) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=435839) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=435839) 	.loc	1 267 29                        // quant_slide_tuned_Qwen2.5-7B.py:267:29
(EngineCore_DP0 pid=435839) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=435839) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=435839) 	.loc	1 267 21                        // quant_slide_tuned_Qwen2.5-7B.py:267:21
(EngineCore_DP0 pid=435839) 	// begin inline asm
(EngineCore_DP0 pid=435839) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=435839) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=435839) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=435839) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=435839) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=435839) 	// end inline asm
(EngineCore_DP0 pid=435839) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=435839) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=435839) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=435839) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=435839) 	// begin inline asm
(EngineCore_DP0 pid=435839) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=435839) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=435839) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=435839) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=435839) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=435839) 	// end inline asm
(EngineCore_DP0 pid=435839) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=435839) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=435839) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=435839) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=435839) 	.loc	1 268 50                        // quant_slide_tuned_Qwen2.5-7B.py:268:50
(EngineCore_DP0 pid=435839) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=435839) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=435839) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=435839) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=435839) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=435839) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=435839) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=435839) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=435839) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=435839) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=435839) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=435839) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=435839) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=435839) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=435839) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=435839) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=435839) $L__tmp1:
(EngineCore_DP0 pid=435839) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	bar.sync 	0;
(EngineCore_DP0 pid=435839) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=435839) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=435839) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=435839) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=435839) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=435839) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=435839) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=435839) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=435839) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=435839) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=435839) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=435839) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=435839) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=435839) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=435839) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=435839) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=435839) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=435839) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=435839) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=435839) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=435839) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=435839) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=435839) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=435839) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=435839) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=435839) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=435839) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	// begin inline asm
(EngineCore_DP0 pid=435839) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=435839) 	// end inline asm
(EngineCore_DP0 pid=435839) 	bar.sync 	0;
(EngineCore_DP0 pid=435839) 	// begin inline asm
(EngineCore_DP0 pid=435839) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=435839) 	// end inline asm
(EngineCore_DP0 pid=435839) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=435839) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=435839) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=435839) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=435839) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=435839) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=435839) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=435839) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=435839) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:268:43 ]
(EngineCore_DP0 pid=435839) 	// begin inline asm
(EngineCore_DP0 pid=435839) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=435839) 	// end inline asm
(EngineCore_DP0 pid=435839) 	bar.sync 	0;
(EngineCore_DP0 pid=435839) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=435839) $L__tmp2:
(EngineCore_DP0 pid=435839) 	.loc	1 268 36                        // quant_slide_tuned_Qwen2.5-7B.py:268:36
(EngineCore_DP0 pid=435839) 	max.f32 	%r127, %r127, %r77;
(EngineCore_DP0 pid=435839) 	.loc	1 264 35                        // quant_slide_tuned_Qwen2.5-7B.py:264:35
(EngineCore_DP0 pid=435839) 	add.s32 	%r128, %r128, 8192;
(EngineCore_DP0 pid=435839) 	setp.lt.s32 	%p7, %r128, %r19;
(EngineCore_DP0 pid=435839) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=435839) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=435839) 	.loc	1 270 32                        // quant_slide_tuned_Qwen2.5-7B.py:270:32
(EngineCore_DP0 pid=435839) 	max.f32 	%r129, %r127, 0f2B8CBCCC;
(EngineCore_DP0 pid=435839) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=435839) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=435839) 	mov.b32 	%r79, 0f42FE0000;
(EngineCore_DP0 pid=435839) 	.loc	1 271 32                        // quant_slide_tuned_Qwen2.5-7B.py:271:32
(EngineCore_DP0 pid=435839) 	div.full.f32 	%r80, %r129, %r79;
(EngineCore_DP0 pid=435839) 	.loc	1 271 42                        // quant_slide_tuned_Qwen2.5-7B.py:271:42
(EngineCore_DP0 pid=435839) 	max.f32 	%r78, %r80, 0f37810204;
(EngineCore_DP0 pid=435839) 	.loc	1 273 25                        // quant_slide_tuned_Qwen2.5-7B.py:273:25
(EngineCore_DP0 pid=435839) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=435839) 	.loc	1 273 30                        // quant_slide_tuned_Qwen2.5-7B.py:273:30
(EngineCore_DP0 pid=435839) 	// begin inline asm
(EngineCore_DP0 pid=435839) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=435839) 	// end inline asm
(EngineCore_DP0 pid=435839) 	.loc	1 276 29                        // quant_slide_tuned_Qwen2.5-7B.py:276:29
(EngineCore_DP0 pid=435839) 	shl.b32 	%r15, %r20, 1;
(EngineCore_DP0 pid=435839) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=435839) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=435839) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=435839) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=435839) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=435839) 	ld.param.b32 	%r24, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=435839) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=435839) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=435839) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=435839) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=435839) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=435839) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=435839) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=435839) 	div.full.f32 	%r14, %r79, %r129;
(EngineCore_DP0 pid=435839) 	mov.b32 	%r130, 0;
(EngineCore_DP0 pid=435839) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=435839)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=435839) 	.loc	1 280 30                        // quant_slide_tuned_Qwen2.5-7B.py:280:30
(EngineCore_DP0 pid=435839) 	add.s32 	%r84, %r3, %r130;
(EngineCore_DP0 pid=435839) 	setp.lt.s32 	%p14, %r84, %r15;
(EngineCore_DP0 pid=435839) 	.loc	1 283 24                        // quant_slide_tuned_Qwen2.5-7B.py:283:24
(EngineCore_DP0 pid=435839) 	shr.u32 	%r85, %r84, 31;
(EngineCore_DP0 pid=435839) 	add.s32 	%r86, %r84, %r85;
(EngineCore_DP0 pid=435839) 	shr.u32 	%r87, %r86, 1;
(EngineCore_DP0 pid=435839) 	.loc	1 284 23                        // quant_slide_tuned_Qwen2.5-7B.py:284:23
(EngineCore_DP0 pid=435839) 	and.b32 	%r88, %r86, 2147483646;
(EngineCore_DP0 pid=435839) 	sub.s32 	%r89, %r84, %r88;
(EngineCore_DP0 pid=435839) 	.loc	1 285 30                        // quant_slide_tuned_Qwen2.5-7B.py:285:30
(EngineCore_DP0 pid=435839) 	shl.b32 	%r90, %r89, 1;
(EngineCore_DP0 pid=435839) 	.loc	1 285 26                        // quant_slide_tuned_Qwen2.5-7B.py:285:26
(EngineCore_DP0 pid=435839) 	mad.lo.s32 	%r91, %r87, 6, %r90;
(EngineCore_DP0 pid=435839) 	.loc	1 288 53                        // quant_slide_tuned_Qwen2.5-7B.py:288:53
(EngineCore_DP0 pid=435839) 	setp.lt.s32 	%p15, %r91, %r18;
(EngineCore_DP0 pid=435839) 	.loc	1 288 37                        // quant_slide_tuned_Qwen2.5-7B.py:288:37
(EngineCore_DP0 pid=435839) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=435839) 	.loc	1 287 29                        // quant_slide_tuned_Qwen2.5-7B.py:287:29
(EngineCore_DP0 pid=435839) 	mad.wide.s32 	%rd9, %r91, 2, %rd1;
(EngineCore_DP0 pid=435839) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=435839) 	.loc	1 287 21                        // quant_slide_tuned_Qwen2.5-7B.py:287:21
(EngineCore_DP0 pid=435839) 	// begin inline asm
(EngineCore_DP0 pid=435839) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=435839) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=435839) 	// end inline asm
(EngineCore_DP0 pid=435839) 	.loc	1 288 79                        // quant_slide_tuned_Qwen2.5-7B.py:288:79
(EngineCore_DP0 pid=435839) 	cvt.f32.bf16 	%r92, %rs48;
(EngineCore_DP0 pid=435839) 	.loc	1 290 48                        // quant_slide_tuned_Qwen2.5-7B.py:290:48
(EngineCore_DP0 pid=435839) 	or.b32 	%r93, %r91, 1;
(EngineCore_DP0 pid=435839) 	.loc	1 290 53                        // quant_slide_tuned_Qwen2.5-7B.py:290:53
(EngineCore_DP0 pid=435839) 	setp.lt.s32 	%p16, %r93, %r18;
(EngineCore_DP0 pid=435839) 	.loc	1 290 37                        // quant_slide_tuned_Qwen2.5-7B.py:290:37
(EngineCore_DP0 pid=435839) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=435839) 	.loc	1 289 39                        // quant_slide_tuned_Qwen2.5-7B.py:289:39
(EngineCore_DP0 pid=435839) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=435839) 	.loc	1 289 21                        // quant_slide_tuned_Qwen2.5-7B.py:289:21
(EngineCore_DP0 pid=435839) 	// begin inline asm
(EngineCore_DP0 pid=435839) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=435839) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=435839) 	// end inline asm
(EngineCore_DP0 pid=435839) 	.loc	1 290 79                        // quant_slide_tuned_Qwen2.5-7B.py:290:79
(EngineCore_DP0 pid=435839) 	cvt.f32.bf16 	%r94, %rs50;
(EngineCore_DP0 pid=435839) 	.loc	1 292 48                        // quant_slide_tuned_Qwen2.5-7B.py:292:48
(EngineCore_DP0 pid=435839) 	add.s32 	%r95, %r91, 2;
(EngineCore_DP0 pid=435839) 	.loc	1 292 53                        // quant_slide_tuned_Qwen2.5-7B.py:292:53
(EngineCore_DP0 pid=435839) 	setp.lt.s32 	%p17, %r95, %r18;
(EngineCore_DP0 pid=435839) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-7B.py:292:37
(EngineCore_DP0 pid=435839) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=435839) 	.loc	1 291 39                        // quant_slide_tuned_Qwen2.5-7B.py:291:39
(EngineCore_DP0 pid=435839) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=435839) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-7B.py:291:21
(EngineCore_DP0 pid=435839) 	// begin inline asm
(EngineCore_DP0 pid=435839) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=435839) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=435839) 	// end inline asm
(EngineCore_DP0 pid=435839) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-7B.py:292:79
(EngineCore_DP0 pid=435839) 	cvt.f32.bf16 	%r96, %rs52;
(EngineCore_DP0 pid=435839) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-7B.py:294:48
(EngineCore_DP0 pid=435839) 	add.s32 	%r97, %r91, 3;
(EngineCore_DP0 pid=435839) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-7B.py:294:53
(EngineCore_DP0 pid=435839) 	setp.lt.s32 	%p18, %r97, %r18;
(EngineCore_DP0 pid=435839) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-7B.py:294:37
(EngineCore_DP0 pid=435839) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=435839) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-7B.py:293:39
(EngineCore_DP0 pid=435839) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=435839) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-7B.py:293:21
(EngineCore_DP0 pid=435839) 	// begin inline asm
(EngineCore_DP0 pid=435839) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=435839) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=435839) 	// end inline asm
(EngineCore_DP0 pid=435839) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-7B.py:294:79
(EngineCore_DP0 pid=435839) 	cvt.f32.bf16 	%r98, %rs54;
(EngineCore_DP0 pid=435839) 	.loc	1 296 56                        // quant_slide_tuned_Qwen2.5-7B.py:296:56
(EngineCore_DP0 pid=435839) 	mul.f32 	%r99, %r14, %r92;
(EngineCore_DP0 pid=435839) 	.loc	1 296 51                        // quant_slide_tuned_Qwen2.5-7B.py:296:51
(EngineCore_DP0 pid=435839) 	cvt.rni.f32.f32 	%r100, %r99;
(EngineCore_DP0 pid=435839) 	.loc	1 296 76                        // quant_slide_tuned_Qwen2.5-7B.py:296:76
(EngineCore_DP0 pid=435839) 	max.f32 	%r101, %r100, 0fC3000000;
(EngineCore_DP0 pid=435839) 	min.f32 	%r102, %r101, 0f42FE0000;
(EngineCore_DP0 pid=435839) 	.loc	1 296 86                        // quant_slide_tuned_Qwen2.5-7B.py:296:86
(EngineCore_DP0 pid=435839) 	cvt.rzi.s32.f32 	%r103, %r102;
(EngineCore_DP0 pid=435839) 	.loc	1 296 98                        // quant_slide_tuned_Qwen2.5-7B.py:296:98
(EngineCore_DP0 pid=435839) 	and.b32 	%r104, %r103, 255;
(EngineCore_DP0 pid=435839) 	.loc	1 297 56                        // quant_slide_tuned_Qwen2.5-7B.py:297:56
(EngineCore_DP0 pid=435839) 	mul.f32 	%r105, %r14, %r94;
(EngineCore_DP0 pid=435839) 	.loc	1 297 51                        // quant_slide_tuned_Qwen2.5-7B.py:297:51
(EngineCore_DP0 pid=435839) 	cvt.rni.f32.f32 	%r106, %r105;
(EngineCore_DP0 pid=435839) 	.loc	1 298 56                        // quant_slide_tuned_Qwen2.5-7B.py:298:56
(EngineCore_DP0 pid=435839) 	mul.f32 	%r107, %r14, %r96;
(EngineCore_DP0 pid=435839) 	.loc	1 298 51                        // quant_slide_tuned_Qwen2.5-7B.py:298:51
(EngineCore_DP0 pid=435839) 	cvt.rni.f32.f32 	%r108, %r107;
(EngineCore_DP0 pid=435839) 	.loc	1 299 56                        // quant_slide_tuned_Qwen2.5-7B.py:299:56
(EngineCore_DP0 pid=435839) 	mul.f32 	%r109, %r14, %r98;
(EngineCore_DP0 pid=435839) 	.loc	1 299 51                        // quant_slide_tuned_Qwen2.5-7B.py:299:51
(EngineCore_DP0 pid=435839) 	cvt.rni.f32.f32 	%r110, %r109;
(EngineCore_DP0 pid=435839) 	.loc	1 299 76                        // quant_slide_tuned_Qwen2.5-7B.py:299:76
(EngineCore_DP0 pid=435839) 	max.f32 	%r111, %r110, 0fC3000000;
(EngineCore_DP0 pid=435839) 	min.f32 	%r112, %r111, 0f42FE0000;
(EngineCore_DP0 pid=435839) 	.loc	1 299 86                        // quant_slide_tuned_Qwen2.5-7B.py:299:86
(EngineCore_DP0 pid=435839) 	cvt.rzi.s32.f32 	%r113, %r112;
(EngineCore_DP0 pid=435839) 	.loc	1 297 76                        // quant_slide_tuned_Qwen2.5-7B.py:297:76
(EngineCore_DP0 pid=435839) 	max.f32 	%r114, %r108, 0fC3000000;
(EngineCore_DP0 pid=435839) 	max.f32 	%r115, %r106, 0fC3000000;
(EngineCore_DP0 pid=435839) 	min.f32 	%r116, %r115, 0f42FE0000;
(EngineCore_DP0 pid=435839) 	min.f32 	%r117, %r114, 0f42FE0000;
(EngineCore_DP0 pid=435839) 	.loc	1 297 86                        // quant_slide_tuned_Qwen2.5-7B.py:297:86
(EngineCore_DP0 pid=435839) 	cvt.rzi.s32.f32 	%r118, %r117;
(EngineCore_DP0 pid=435839) 	cvt.rzi.s32.f32 	%r119, %r116;
(EngineCore_DP0 pid=435839) 	.loc	1 301 30                        // quant_slide_tuned_Qwen2.5-7B.py:301:30
(EngineCore_DP0 pid=435839) 	shl.b32 	%r120, %r119, 8;
(EngineCore_DP0 pid=435839) 	shl.b32 	%r121, %r118, 16;
(EngineCore_DP0 pid=435839) 	and.b32 	%r122, %r121, 16711680;
(EngineCore_DP0 pid=435839) 	and.b32 	%r123, %r120, 65280;
(EngineCore_DP0 pid=435839) 	.loc	1 301 24                        // quant_slide_tuned_Qwen2.5-7B.py:301:24
(EngineCore_DP0 pid=435839) 	or.b32 	%r124, %r123, %r104;
(EngineCore_DP0 pid=435839) 	.loc	1 301 36                        // quant_slide_tuned_Qwen2.5-7B.py:301:36
(EngineCore_DP0 pid=435839) 	or.b32 	%r125, %r124, %r122;
(EngineCore_DP0 pid=435839) 	.loc	1 301 55                        // quant_slide_tuned_Qwen2.5-7B.py:301:55
(EngineCore_DP0 pid=435839) 	shl.b32 	%r126, %r113, 24;
(EngineCore_DP0 pid=435839) 	.loc	1 301 49                        // quant_slide_tuned_Qwen2.5-7B.py:301:49
(EngineCore_DP0 pid=435839) 	or.b32 	%r82, %r125, %r126;
(EngineCore_DP0 pid=435839) 	.loc	1 302 29                        // quant_slide_tuned_Qwen2.5-7B.py:302:29
(EngineCore_DP0 pid=435839) 	mad.wide.s32 	%rd13, %r84, 4, %rd2;
(EngineCore_DP0 pid=435839) 	.loc	1 302 39                        // quant_slide_tuned_Qwen2.5-7B.py:302:39
(EngineCore_DP0 pid=435839) 	// begin inline asm
(EngineCore_DP0 pid=435839) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r82 };
(EngineCore_DP0 pid=435839) 	// end inline asm
(EngineCore_DP0 pid=435839) 	.loc	1 278 41                        // quant_slide_tuned_Qwen2.5-7B.py:278:41
(EngineCore_DP0 pid=435839) 	add.s32 	%r130, %r130, 512;
(EngineCore_DP0 pid=435839) 	setp.lt.s32 	%p19, %r130, %r15;
(EngineCore_DP0 pid=435839) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=435839) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=435839) 	.loc	1 278 4                         // quant_slide_tuned_Qwen2.5-7B.py:278:4
(EngineCore_DP0 pid=435839) 	ret;
(EngineCore_DP0 pid=435839) $L__tmp3:
(EngineCore_DP0 pid=435839) $L__func_end0:
(EngineCore_DP0 pid=435839)                                         // -- End function
(EngineCore_DP0 pid=435839) }
(EngineCore_DP0 pid=435839) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=435839) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=435839) 	.section	.debug_abbrev
(EngineCore_DP0 pid=435839) 	{
(EngineCore_DP0 pid=435839) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=435839) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=435839) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=435839) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=435839) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=435839) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=435839) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=435839) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=435839) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=435839) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=435839) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=435839) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=435839) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=435839) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=435839) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=435839) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=435839) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=435839) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=435839) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=435839) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=435839) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=435839) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=435839) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=435839) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=435839) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=435839) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=435839) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=435839) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=435839) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=435839) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=435839) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=435839) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=435839) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=435839) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=435839) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=435839) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=435839) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=435839) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=435839) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=435839) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=435839) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=435839) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=435839) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=435839) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=435839) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=435839) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=435839) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=435839) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=435839) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=435839) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=435839) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=435839) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=435839) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=435839) 	}
(EngineCore_DP0 pid=435839) 	.section	.debug_info
(EngineCore_DP0 pid=435839) 	{
(EngineCore_DP0 pid=435839) .b32 223                                // Length of Unit
(EngineCore_DP0 pid=435839) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=435839) .b8 0
(EngineCore_DP0 pid=435839) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=435839) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=435839) .b8 1                                   // Abbrev [1] 0xb:0xd8 DW_TAG_compile_unit
(EngineCore_DP0 pid=435839) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=435839) .b8 114
(EngineCore_DP0 pid=435839) .b8 105
(EngineCore_DP0 pid=435839) .b8 116
(EngineCore_DP0 pid=435839) .b8 111
(EngineCore_DP0 pid=435839) .b8 110
(EngineCore_DP0 pid=435839) .b8 0
(EngineCore_DP0 pid=435839) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=435839) .b8 0
(EngineCore_DP0 pid=435839) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=435839) .b8 117
(EngineCore_DP0 pid=435839) .b8 97
(EngineCore_DP0 pid=435839) .b8 110
(EngineCore_DP0 pid=435839) .b8 116
(EngineCore_DP0 pid=435839) .b8 95
(EngineCore_DP0 pid=435839) .b8 115
(EngineCore_DP0 pid=435839) .b8 108
(EngineCore_DP0 pid=435839) .b8 105
(EngineCore_DP0 pid=435839) .b8 100
(EngineCore_DP0 pid=435839) .b8 101
(EngineCore_DP0 pid=435839) .b8 95
(EngineCore_DP0 pid=435839) .b8 116
(EngineCore_DP0 pid=435839) .b8 117
(EngineCore_DP0 pid=435839) .b8 110
(EngineCore_DP0 pid=435839) .b8 101
(EngineCore_DP0 pid=435839) .b8 100
(EngineCore_DP0 pid=435839) .b8 95
(EngineCore_DP0 pid=435839) .b8 81
(EngineCore_DP0 pid=435839) .b8 119
(EngineCore_DP0 pid=435839) .b8 101
(EngineCore_DP0 pid=435839) .b8 110
(EngineCore_DP0 pid=435839) .b8 50
(EngineCore_DP0 pid=435839) .b8 46
(EngineCore_DP0 pid=435839) .b8 53
(EngineCore_DP0 pid=435839) .b8 45
(EngineCore_DP0 pid=435839) .b8 55
(EngineCore_DP0 pid=435839) .b8 66
(EngineCore_DP0 pid=435839) .b8 46
(EngineCore_DP0 pid=435839) .b8 112
(EngineCore_DP0 pid=435839) .b8 121
(EngineCore_DP0 pid=435839) .b8 0
(EngineCore_DP0 pid=435839) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=435839) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=435839) .b8 114
(EngineCore_DP0 pid=435839) .b8 111
(EngineCore_DP0 pid=435839) .b8 111
(EngineCore_DP0 pid=435839) .b8 116
(EngineCore_DP0 pid=435839) .b8 47
(EngineCore_DP0 pid=435839) .b8 118
(EngineCore_DP0 pid=435839) .b8 108
(EngineCore_DP0 pid=435839) .b8 108
(EngineCore_DP0 pid=435839) .b8 109
(EngineCore_DP0 pid=435839) .b8 98
(EngineCore_DP0 pid=435839) .b8 101
(EngineCore_DP0 pid=435839) .b8 110
(EngineCore_DP0 pid=435839) .b8 99
(EngineCore_DP0 pid=435839) .b8 104
(EngineCore_DP0 pid=435839) .b8 47
(EngineCore_DP0 pid=435839) .b8 115
(EngineCore_DP0 pid=435839) .b8 108
(EngineCore_DP0 pid=435839) .b8 105
(EngineCore_DP0 pid=435839) .b8 100
(EngineCore_DP0 pid=435839) .b8 101
(EngineCore_DP0 pid=435839) .b8 115
(EngineCore_DP0 pid=435839) .b8 112
(EngineCore_DP0 pid=435839) .b8 97
(EngineCore_DP0 pid=435839) .b8 114
(EngineCore_DP0 pid=435839) .b8 115
(EngineCore_DP0 pid=435839) .b8 101
(EngineCore_DP0 pid=435839) .b8 47
(EngineCore_DP0 pid=435839) .b8 99
(EngineCore_DP0 pid=435839) .b8 115
(EngineCore_DP0 pid=435839) .b8 114
(EngineCore_DP0 pid=435839) .b8 99
(EngineCore_DP0 pid=435839) .b8 47
(EngineCore_DP0 pid=435839) .b8 102
(EngineCore_DP0 pid=435839) .b8 117
(EngineCore_DP0 pid=435839) .b8 115
(EngineCore_DP0 pid=435839) .b8 101
(EngineCore_DP0 pid=435839) .b8 100
(EngineCore_DP0 pid=435839) .b8 95
(EngineCore_DP0 pid=435839) .b8 113
(EngineCore_DP0 pid=435839) .b8 117
(EngineCore_DP0 pid=435839) .b8 97
(EngineCore_DP0 pid=435839) .b8 110
(EngineCore_DP0 pid=435839) .b8 116
(EngineCore_DP0 pid=435839) .b8 95
(EngineCore_DP0 pid=435839) .b8 115
(EngineCore_DP0 pid=435839) .b8 108
(EngineCore_DP0 pid=435839) .b8 105
(EngineCore_DP0 pid=435839) .b8 100
(EngineCore_DP0 pid=435839) .b8 101
(EngineCore_DP0 pid=435839) .b8 95
(EngineCore_DP0 pid=435839) .b8 116
(EngineCore_DP0 pid=435839) .b8 114
(EngineCore_DP0 pid=435839) .b8 105
(EngineCore_DP0 pid=435839) .b8 116
(EngineCore_DP0 pid=435839) .b8 111
(EngineCore_DP0 pid=435839) .b8 110
(EngineCore_DP0 pid=435839) .b8 47
(EngineCore_DP0 pid=435839) .b8 98
(EngineCore_DP0 pid=435839) .b8 117
(EngineCore_DP0 pid=435839) .b8 105
(EngineCore_DP0 pid=435839) .b8 108
(EngineCore_DP0 pid=435839) .b8 100
(EngineCore_DP0 pid=435839) .b8 47
(EngineCore_DP0 pid=435839) .b8 71
(EngineCore_DP0 pid=435839) .b8 66
(EngineCore_DP0 pid=435839) .b8 49
(EngineCore_DP0 pid=435839) .b8 48
(EngineCore_DP0 pid=435839) .b8 95
(EngineCore_DP0 pid=435839) .b8 99
(EngineCore_DP0 pid=435839) .b8 99
(EngineCore_DP0 pid=435839) .b8 49
(EngineCore_DP0 pid=435839) .b8 50
(EngineCore_DP0 pid=435839) .b8 49
(EngineCore_DP0 pid=435839) .b8 95
(EngineCore_DP0 pid=435839) .b8 112
(EngineCore_DP0 pid=435839) .b8 121
(EngineCore_DP0 pid=435839) .b8 51
(EngineCore_DP0 pid=435839) .b8 49
(EngineCore_DP0 pid=435839) .b8 50
(EngineCore_DP0 pid=435839) .b8 95
(EngineCore_DP0 pid=435839) .b8 99
(EngineCore_DP0 pid=435839) .b8 117
(EngineCore_DP0 pid=435839) .b8 49
(EngineCore_DP0 pid=435839) .b8 50
(EngineCore_DP0 pid=435839) .b8 57
(EngineCore_DP0 pid=435839) .b8 95
(EngineCore_DP0 pid=435839) .b8 97
(EngineCore_DP0 pid=435839) .b8 97
(EngineCore_DP0 pid=435839) .b8 114
(EngineCore_DP0 pid=435839) .b8 99
(EngineCore_DP0 pid=435839) .b8 104
(EngineCore_DP0 pid=435839) .b8 54
(EngineCore_DP0 pid=435839) .b8 52
(EngineCore_DP0 pid=435839) .b8 0
(EngineCore_DP0 pid=435839) .b8 2                                   // Abbrev [2] 0x98:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=435839) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=435839) .b8 113
(EngineCore_DP0 pid=435839) .b8 117
(EngineCore_DP0 pid=435839) .b8 97
(EngineCore_DP0 pid=435839) .b8 110
(EngineCore_DP0 pid=435839) .b8 116
(EngineCore_DP0 pid=435839) .b8 95
(EngineCore_DP0 pid=435839) .b8 115
(EngineCore_DP0 pid=435839) .b8 108
(EngineCore_DP0 pid=435839) .b8 105
(EngineCore_DP0 pid=435839) .b8 100
(EngineCore_DP0 pid=435839) .b8 101
(EngineCore_DP0 pid=435839) .b8 95
(EngineCore_DP0 pid=435839) .b8 105
(EngineCore_DP0 pid=435839) .b8 110
(EngineCore_DP0 pid=435839) .b8 116
(EngineCore_DP0 pid=435839) .b8 56
(EngineCore_DP0 pid=435839) .b8 95
(EngineCore_DP0 pid=435839) .b8 107
(EngineCore_DP0 pid=435839) .b8 101
(EngineCore_DP0 pid=435839) .b8 114
(EngineCore_DP0 pid=435839) .b8 110
(EngineCore_DP0 pid=435839) .b8 101
(EngineCore_DP0 pid=435839) .b8 108
(EngineCore_DP0 pid=435839) .b8 0
(EngineCore_DP0 pid=435839) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=435839) .b8 3                                   // Abbrev [3] 0xb3:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=435839) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=435839) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=435839) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=435839) .b8 4                                   // Abbrev [4] 0xc8:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=435839) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=435839) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=435839) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=435839) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=435839) .b8 12                                  // DW_AT_call_line
(EngineCore_DP0 pid=435839) .b8 1
(EngineCore_DP0 pid=435839) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=435839) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=435839) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=435839) 	}
(EngineCore_DP0 pid=435839) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=435839) 
(EngineCore_DP0 pid=435839) ================================================================
(EngineCore_DP0 pid=435839) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=435839) 
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpqheo6xfv.ptx', '-o', '/tmp/tmpqheo6xfv.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866] 
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866] 
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866] 
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpqheo6xfv.ptx -o /tmp/tmpqheo6xfv.ptx.o
(EngineCore_DP0 pid=435839) ERROR 01-25 20:46:55 [core.py:866] 

STDERR:
[2026-01-25 20:45:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:45:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:45:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:45:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:45:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:45:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:45:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:45:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:45:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:45:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:45:53] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:45:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:45:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:45:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:45:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:45:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:45:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=435839) [2026-01-25 20:45:54] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=435839) [2026-01-25 20:45:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=435839) [2026-01-25 20:45:54] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=435839) [2026-01-25 20:45:54] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=435839) [2026-01-25 20:45:54] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=435839) [2026-01-25 20:45:54] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=435839) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=435839) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:23<00:23, 23.68s/it]
(EngineCore_DP0 pid=435839) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:56<00:00, 29.33s/it]
(EngineCore_DP0 pid=435839) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:56<00:00, 28.48s/it]
(EngineCore_DP0 pid=435839) 
(EngineCore_DP0 pid=435839) [2026-01-25 20:46:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=435839) [2026-01-25 20:46:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=435839) [2026-01-25 20:46:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=435839) [2026-01-25 20:46:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=435839) [2026-01-25 20:46:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=435839) [2026-01-25 20:46:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=435839) [2026-01-25 20:46:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=435839) [2026-01-25 20:46:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=435839) Process EngineCore_DP0:
(EngineCore_DP0 pid=435839) Traceback (most recent call last):
(EngineCore_DP0 pid=435839)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=435839)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=435839)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=435839)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=435839) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpqheo6xfv.ptx', '-o', '/tmp/tmpqheo6xfv.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=435839) 
(EngineCore_DP0 pid=435839) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=435839) 
(EngineCore_DP0 pid=435839) Traceback (most recent call last):
(EngineCore_DP0 pid=435839)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=435839)     self.run()
(EngineCore_DP0 pid=435839)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=435839)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=435839)     raise e
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=435839)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=435839)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=435839)     super().__init__(
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=435839)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=435839)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=435839)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=435839)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=435839)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=435839)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=435839)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=435839)     return func(*args, **kwargs)
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=435839)     return func(*args, **kwargs)
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=435839)     self.model_runner.profile_run()
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=435839)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=435839)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=435839)     return func(*args, **kwargs)
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=435839)     outputs = self.model(
(EngineCore_DP0 pid=435839)               ^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=435839)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=435839)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=435839)     hidden_states = self.model(
(EngineCore_DP0 pid=435839)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=435839)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=435839)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=435839)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=435839)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=435839)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=435839)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=435839)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=435839)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=435839)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=435839)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=435839)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=435839)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=435839)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=435839)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=435839)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=435839)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=435839)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=435839)     return self._linear_fn(
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=435839)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=435839)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=435839)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=435839)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=435839)     return fn(input, L)
(EngineCore_DP0 pid=435839)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 331, in quant_slide_int8_triton
(EngineCore_DP0 pid=435839)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=435839)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=435839)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=435839)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=435839)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=435839)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=435839)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=435839)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=435839)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=435839)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=435839)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=435839)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435839)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=435839)     raise PTXASError(error)
(EngineCore_DP0 pid=435839) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=435839) `ptxas` stderr:
(EngineCore_DP0 pid=435839) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=435839) 
(EngineCore_DP0 pid=435839) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpqheo6xfv.ptx -o /tmp/tmpqheo6xfv.ptx.o
(EngineCore_DP0 pid=435839) 
[rank0]:[W125 20:46:55.608435319 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-25 22:24:50
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:24:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 22:24:54 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=532421) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=532421) 
(EngineCore_DP0 pid=532421) 
(EngineCore_DP0 pid=532421) ================================================================
(EngineCore_DP0 pid=532421) Internal Triton PTX codegen error
(EngineCore_DP0 pid=532421) `ptxas` stderr:
(EngineCore_DP0 pid=532421) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=532421) 
(EngineCore_DP0 pid=532421) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp2m3w691g.ptx -o /tmp/tmp2m3w691g.ptx.o
(EngineCore_DP0 pid=532421) 
(EngineCore_DP0 pid=532421) 
(EngineCore_DP0 pid=532421) //
(EngineCore_DP0 pid=532421) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=532421) //
(EngineCore_DP0 pid=532421) 
(EngineCore_DP0 pid=532421) .version 8.7
(EngineCore_DP0 pid=532421) .target sm_121a
(EngineCore_DP0 pid=532421) .address_size 64
(EngineCore_DP0 pid=532421) 
(EngineCore_DP0 pid=532421) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=532421) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=532421)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=532421) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=532421) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=532421) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=532421) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=532421) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=532421) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=532421) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=532421) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=532421) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=532421) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=532421) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=532421) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=532421) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=532421) )
(EngineCore_DP0 pid=532421) .reqntid 512
(EngineCore_DP0 pid=532421) {
(EngineCore_DP0 pid=532421) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=532421) 	.reg .b16 	%rs<64>;
(EngineCore_DP0 pid=532421) 	.reg .b32 	%r<169>;
(EngineCore_DP0 pid=532421) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=532421) 	.loc	1 248 0                         // quant_slide_tuned_Qwen2.5-14B.py:248:0
(EngineCore_DP0 pid=532421) $L__func_begin0:
(EngineCore_DP0 pid=532421) 	.loc	1 248 0                         // quant_slide_tuned_Qwen2.5-14B.py:248:0
(EngineCore_DP0 pid=532421) 
(EngineCore_DP0 pid=532421) // %bb.0:
(EngineCore_DP0 pid=532421) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=532421) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=532421) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=532421) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=532421) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=532421) $L__tmp0:
(EngineCore_DP0 pid=532421) 	.loc	1 258 24                        // quant_slide_tuned_Qwen2.5-14B.py:258:24
(EngineCore_DP0 pid=532421) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=532421) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=532421) 	.loc	1 263 26                        // quant_slide_tuned_Qwen2.5-14B.py:263:26
(EngineCore_DP0 pid=532421) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=532421) 	.loc	1 263 20                        // quant_slide_tuned_Qwen2.5-14B.py:263:20
(EngineCore_DP0 pid=532421) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=532421) 	.loc	1 269 32                        // quant_slide_tuned_Qwen2.5-14B.py:269:32
(EngineCore_DP0 pid=532421) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=532421) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=532421) 	.loc	1 268 35                        // quant_slide_tuned_Qwen2.5-14B.py:268:35
(EngineCore_DP0 pid=532421) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=532421) 	mov.b32 	%r167, 0f2B8CBCCC;
(EngineCore_DP0 pid=532421) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=532421) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=532421) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=532421) 	.loc	1 269 32                        // quant_slide_tuned_Qwen2.5-14B.py:269:32
(EngineCore_DP0 pid=532421) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=532421) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=532421) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=532421) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=532421) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=532421) 	add.s32 	%r53, %r35, %r34;
(EngineCore_DP0 pid=532421) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=532421) 	add.s32 	%r56, %r35, %r36;
(EngineCore_DP0 pid=532421) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=532421) 	mov.b32 	%r165, 0f00000000;
(EngineCore_DP0 pid=532421) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=532421) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=532421) 	mov.b32 	%r166, %r41;
(EngineCore_DP0 pid=532421) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=532421) 	.loc	1 269 19                        // quant_slide_tuned_Qwen2.5-14B.py:269:19
(EngineCore_DP0 pid=532421) 	add.s32 	%r59, %r4, %r166;
(EngineCore_DP0 pid=532421) 	.loc	1 270 22                        // quant_slide_tuned_Qwen2.5-14B.py:270:22
(EngineCore_DP0 pid=532421) 	add.s32 	%r60, %r59, 4096;
(EngineCore_DP0 pid=532421) 	setp.lt.s32 	%p2, %r59, %r19;
(EngineCore_DP0 pid=532421) 	setp.lt.s32 	%p3, %r60, %r19;
(EngineCore_DP0 pid=532421) 	.loc	1 271 29                        // quant_slide_tuned_Qwen2.5-14B.py:271:29
(EngineCore_DP0 pid=532421) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=532421) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=532421) 	.loc	1 271 21                        // quant_slide_tuned_Qwen2.5-14B.py:271:21
(EngineCore_DP0 pid=532421) 	// begin inline asm
(EngineCore_DP0 pid=532421) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=532421) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=532421) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=532421) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=532421) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=532421) 	// end inline asm
(EngineCore_DP0 pid=532421) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=532421) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=532421) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=532421) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=532421) 	// begin inline asm
(EngineCore_DP0 pid=532421) 	mov.u32 %r45, %r41;
(EngineCore_DP0 pid=532421) 	mov.u32 %r46, %r41;
(EngineCore_DP0 pid=532421) 	mov.u32 %r47, %r41;
(EngineCore_DP0 pid=532421) 	mov.u32 %r48, %r41;
(EngineCore_DP0 pid=532421) 	@%p3 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=532421) 	// end inline asm
(EngineCore_DP0 pid=532421) 	mov.b32 	{%rs9, %rs10}, %r45;
(EngineCore_DP0 pid=532421) 	mov.b32 	{%rs11, %rs12}, %r46;
(EngineCore_DP0 pid=532421) 	mov.b32 	{%rs13, %rs14}, %r47;
(EngineCore_DP0 pid=532421) 	mov.b32 	{%rs15, %rs16}, %r48;
(EngineCore_DP0 pid=532421) 	.loc	1 272 50                        // quant_slide_tuned_Qwen2.5-14B.py:272:50
(EngineCore_DP0 pid=532421) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=532421) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=532421) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=532421) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=532421) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=532421) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=532421) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=532421) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=532421) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=532421) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=532421) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=532421) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=532421) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=532421) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=532421) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=532421) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=532421) $L__tmp1:
(EngineCore_DP0 pid=532421) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	bar.sync 	0;
(EngineCore_DP0 pid=532421) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=532421) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=532421) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=532421) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=532421) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=532421) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=532421) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=532421) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=532421) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=532421) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=532421) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=532421) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=532421) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=532421) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=532421) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=532421) 	cvt.f32.bf16 	%r61, %rs47;
(EngineCore_DP0 pid=532421) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	shfl.sync.bfly.b32 	%r62, %r61, 16, 31, -1;
(EngineCore_DP0 pid=532421) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=532421) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	shfl.sync.bfly.b32 	%r64, %r63, 8, 31, -1;
(EngineCore_DP0 pid=532421) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=532421) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=532421) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=532421) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=532421) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=532421) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=532421) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	max.f32 	%r54, %r69, %r70;
(EngineCore_DP0 pid=532421) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	// begin inline asm
(EngineCore_DP0 pid=532421) 	@%p4 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=532421) 	// end inline asm
(EngineCore_DP0 pid=532421) 	bar.sync 	0;
(EngineCore_DP0 pid=532421) 	// begin inline asm
(EngineCore_DP0 pid=532421) 	@%p5 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=532421) 	// end inline asm
(EngineCore_DP0 pid=532421) 	shfl.sync.bfly.b32 	%r71, %r55, 8, 31, -1;
(EngineCore_DP0 pid=532421) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	max.f32 	%r72, %r55, %r71;
(EngineCore_DP0 pid=532421) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	shfl.sync.bfly.b32 	%r73, %r72, 4, 31, -1;
(EngineCore_DP0 pid=532421) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	max.f32 	%r74, %r72, %r73;
(EngineCore_DP0 pid=532421) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	shfl.sync.bfly.b32 	%r75, %r74, 2, 31, -1;
(EngineCore_DP0 pid=532421) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	max.f32 	%r76, %r74, %r75;
(EngineCore_DP0 pid=532421) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	shfl.sync.bfly.b32 	%r77, %r76, 1, 31, -1;
(EngineCore_DP0 pid=532421) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	max.f32 	%r58, %r76, %r77;
(EngineCore_DP0 pid=532421) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=532421) 	// begin inline asm
(EngineCore_DP0 pid=532421) 	@%p28 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=532421) 	// end inline asm
(EngineCore_DP0 pid=532421) 	bar.sync 	0;
(EngineCore_DP0 pid=532421) 	ld.shared.b32 	%r78, [global_smem];
(EngineCore_DP0 pid=532421) $L__tmp2:
(EngineCore_DP0 pid=532421) 	.loc	1 272 36                        // quant_slide_tuned_Qwen2.5-14B.py:272:36
(EngineCore_DP0 pid=532421) 	max.f32 	%r165, %r165, %r78;
(EngineCore_DP0 pid=532421) 	.loc	1 268 35                        // quant_slide_tuned_Qwen2.5-14B.py:268:35
(EngineCore_DP0 pid=532421) 	add.s32 	%r166, %r166, 8192;
(EngineCore_DP0 pid=532421) 	setp.lt.s32 	%p7, %r166, %r20;
(EngineCore_DP0 pid=532421) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=532421) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=532421) 	.loc	1 274 32                        // quant_slide_tuned_Qwen2.5-14B.py:274:32
(EngineCore_DP0 pid=532421) 	max.f32 	%r167, %r165, 0f2B8CBCCC;
(EngineCore_DP0 pid=532421) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=532421) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-14B.py:0:32
(EngineCore_DP0 pid=532421) 	mov.b32 	%r80, 0f42FE0000;
(EngineCore_DP0 pid=532421) 	.loc	1 275 32                        // quant_slide_tuned_Qwen2.5-14B.py:275:32
(EngineCore_DP0 pid=532421) 	div.full.f32 	%r81, %r167, %r80;
(EngineCore_DP0 pid=532421) 	.loc	1 275 42                        // quant_slide_tuned_Qwen2.5-14B.py:275:42
(EngineCore_DP0 pid=532421) 	max.f32 	%r79, %r81, 0f37810204;
(EngineCore_DP0 pid=532421) 	.loc	1 277 25                        // quant_slide_tuned_Qwen2.5-14B.py:277:25
(EngineCore_DP0 pid=532421) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=532421) 	.loc	1 277 30                        // quant_slide_tuned_Qwen2.5-14B.py:277:30
(EngineCore_DP0 pid=532421) 	// begin inline asm
(EngineCore_DP0 pid=532421) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r79 };
(EngineCore_DP0 pid=532421) 	// end inline asm
(EngineCore_DP0 pid=532421) 	.loc	1 280 29                        // quant_slide_tuned_Qwen2.5-14B.py:280:29
(EngineCore_DP0 pid=532421) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=532421) 	.loc	1 282 41                        // quant_slide_tuned_Qwen2.5-14B.py:282:41
(EngineCore_DP0 pid=532421) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=532421) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=532421) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=532421) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-14B.py:0:41
(EngineCore_DP0 pid=532421) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=532421) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=532421) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=532421) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=532421) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=532421) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=532421) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=532421) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=532421) 	div.full.f32 	%r14, %r80, %r167;
(EngineCore_DP0 pid=532421) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=532421) 	mov.b32 	%r168, 0;
(EngineCore_DP0 pid=532421) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=532421)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=532421) 	.loc	1 283 31                        // quant_slide_tuned_Qwen2.5-14B.py:283:31
(EngineCore_DP0 pid=532421) 	add.s32 	%r85, %r16, %r168;
(EngineCore_DP0 pid=532421) 	.loc	1 284 30                        // quant_slide_tuned_Qwen2.5-14B.py:284:30
(EngineCore_DP0 pid=532421) 	add.s32 	%r86, %r168, 1;
(EngineCore_DP0 pid=532421) 	setp.lt.s32 	%p18, %r85, %r15;
(EngineCore_DP0 pid=532421) 	.loc	1 287 24                        // quant_slide_tuned_Qwen2.5-14B.py:287:24
(EngineCore_DP0 pid=532421) 	shr.u32 	%r87, %r85, 1;
(EngineCore_DP0 pid=532421) 	.loc	1 288 23                        // quant_slide_tuned_Qwen2.5-14B.py:288:23
(EngineCore_DP0 pid=532421) 	shr.u32 	%r88, %r86, 31;
(EngineCore_DP0 pid=532421) 	add.s32 	%r89, %r86, %r88;
(EngineCore_DP0 pid=532421) 	and.b32 	%r90, %r89, 2147483646;
(EngineCore_DP0 pid=532421) 	sub.s32 	%r91, %r86, %r90;
(EngineCore_DP0 pid=532421) 	.loc	1 289 22                        // quant_slide_tuned_Qwen2.5-14B.py:289:22
(EngineCore_DP0 pid=532421) 	mul.lo.s32 	%r92, %r87, 6;
(EngineCore_DP0 pid=532421) 	.loc	1 289 30                        // quant_slide_tuned_Qwen2.5-14B.py:289:30
(EngineCore_DP0 pid=532421) 	shl.b32 	%r93, %r91, 1;
(EngineCore_DP0 pid=532421) 	.loc	1 289 26                        // quant_slide_tuned_Qwen2.5-14B.py:289:26
(EngineCore_DP0 pid=532421) 	add.s32 	%r94, %r92, %r93;
(EngineCore_DP0 pid=532421) 	.loc	1 292 53                        // quant_slide_tuned_Qwen2.5-14B.py:292:53
(EngineCore_DP0 pid=532421) 	setp.lt.s32 	%p19, %r92, %r19;
(EngineCore_DP0 pid=532421) 	setp.lt.s32 	%p20, %r94, %r19;
(EngineCore_DP0 pid=532421) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-14B.py:292:37
(EngineCore_DP0 pid=532421) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=532421) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=532421) 	.loc	1 291 29                        // quant_slide_tuned_Qwen2.5-14B.py:291:29
(EngineCore_DP0 pid=532421) 	mad.wide.s32 	%rd9, %r92, 2, %rd1;
(EngineCore_DP0 pid=532421) 	mad.wide.s32 	%rd10, %r94, 2, %rd1;
(EngineCore_DP0 pid=532421) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=532421) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-14B.py:291:21
(EngineCore_DP0 pid=532421) 	// begin inline asm
(EngineCore_DP0 pid=532421) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=532421) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=532421) 	// end inline asm
(EngineCore_DP0 pid=532421) 	// begin inline asm
(EngineCore_DP0 pid=532421) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=532421) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=532421) 	// end inline asm
(EngineCore_DP0 pid=532421) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-14B.py:292:79
(EngineCore_DP0 pid=532421) 	cvt.f32.bf16 	%r95, %rs48;
(EngineCore_DP0 pid=532421) 	cvt.f32.bf16 	%r96, %rs50;
(EngineCore_DP0 pid=532421) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-14B.py:294:48
(EngineCore_DP0 pid=532421) 	or.b32 	%r97, %r92, 1;
(EngineCore_DP0 pid=532421) 	or.b32 	%r98, %r94, 1;
(EngineCore_DP0 pid=532421) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-14B.py:294:53
(EngineCore_DP0 pid=532421) 	setp.lt.s32 	%p21, %r97, %r19;
(EngineCore_DP0 pid=532421) 	setp.lt.s32 	%p22, %r98, %r19;
(EngineCore_DP0 pid=532421) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-14B.py:294:37
(EngineCore_DP0 pid=532421) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=532421) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=532421) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-14B.py:293:39
(EngineCore_DP0 pid=532421) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=532421) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=532421) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-14B.py:293:21
(EngineCore_DP0 pid=532421) 	// begin inline asm
(EngineCore_DP0 pid=532421) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=532421) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=532421) 	// end inline asm
(EngineCore_DP0 pid=532421) 	// begin inline asm
(EngineCore_DP0 pid=532421) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=532421) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=532421) 	// end inline asm
(EngineCore_DP0 pid=532421) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-14B.py:294:79
(EngineCore_DP0 pid=532421) 	cvt.f32.bf16 	%r99, %rs52;
(EngineCore_DP0 pid=532421) 	cvt.f32.bf16 	%r100, %rs54;
(EngineCore_DP0 pid=532421) 	.loc	1 296 48                        // quant_slide_tuned_Qwen2.5-14B.py:296:48
(EngineCore_DP0 pid=532421) 	add.s32 	%r101, %r92, 2;
(EngineCore_DP0 pid=532421) 	add.s32 	%r102, %r94, 2;
(EngineCore_DP0 pid=532421) 	.loc	1 296 53                        // quant_slide_tuned_Qwen2.5-14B.py:296:53
(EngineCore_DP0 pid=532421) 	setp.lt.s32 	%p23, %r101, %r19;
(EngineCore_DP0 pid=532421) 	setp.lt.s32 	%p24, %r102, %r19;
(EngineCore_DP0 pid=532421) 	.loc	1 296 37                        // quant_slide_tuned_Qwen2.5-14B.py:296:37
(EngineCore_DP0 pid=532421) 	and.pred 	%p14, %p18, %p23;
(EngineCore_DP0 pid=532421) 	and.pred 	%p15, %p18, %p24;
(EngineCore_DP0 pid=532421) 	.loc	1 295 39                        // quant_slide_tuned_Qwen2.5-14B.py:295:39
(EngineCore_DP0 pid=532421) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=532421) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=532421) 	.loc	1 295 21                        // quant_slide_tuned_Qwen2.5-14B.py:295:21
(EngineCore_DP0 pid=532421) 	// begin inline asm
(EngineCore_DP0 pid=532421) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=532421) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=532421) 	// end inline asm
(EngineCore_DP0 pid=532421) 	// begin inline asm
(EngineCore_DP0 pid=532421) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=532421) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=532421) 	// end inline asm
(EngineCore_DP0 pid=532421) 	.loc	1 296 79                        // quant_slide_tuned_Qwen2.5-14B.py:296:79
(EngineCore_DP0 pid=532421) 	cvt.f32.bf16 	%r103, %rs56;
(EngineCore_DP0 pid=532421) 	cvt.f32.bf16 	%r104, %rs58;
(EngineCore_DP0 pid=532421) 	.loc	1 298 48                        // quant_slide_tuned_Qwen2.5-14B.py:298:48
(EngineCore_DP0 pid=532421) 	add.s32 	%r105, %r92, 3;
(EngineCore_DP0 pid=532421) 	add.s32 	%r106, %r94, 3;
(EngineCore_DP0 pid=532421) 	.loc	1 298 53                        // quant_slide_tuned_Qwen2.5-14B.py:298:53
(EngineCore_DP0 pid=532421) 	setp.lt.s32 	%p25, %r105, %r19;
(EngineCore_DP0 pid=532421) 	setp.lt.s32 	%p26, %r106, %r19;
(EngineCore_DP0 pid=532421) 	.loc	1 298 37                        // quant_slide_tuned_Qwen2.5-14B.py:298:37
(EngineCore_DP0 pid=532421) 	and.pred 	%p16, %p18, %p25;
(EngineCore_DP0 pid=532421) 	and.pred 	%p17, %p18, %p26;
(EngineCore_DP0 pid=532421) 	.loc	1 297 39                        // quant_slide_tuned_Qwen2.5-14B.py:297:39
(EngineCore_DP0 pid=532421) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=532421) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=532421) 	.loc	1 297 21                        // quant_slide_tuned_Qwen2.5-14B.py:297:21
(EngineCore_DP0 pid=532421) 	// begin inline asm
(EngineCore_DP0 pid=532421) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=532421) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=532421) 	// end inline asm
(EngineCore_DP0 pid=532421) 	// begin inline asm
(EngineCore_DP0 pid=532421) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=532421) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=532421) 	// end inline asm
(EngineCore_DP0 pid=532421) 	.loc	1 298 79                        // quant_slide_tuned_Qwen2.5-14B.py:298:79
(EngineCore_DP0 pid=532421) 	cvt.f32.bf16 	%r107, %rs60;
(EngineCore_DP0 pid=532421) 	cvt.f32.bf16 	%r108, %rs62;
(EngineCore_DP0 pid=532421) 	.loc	1 300 56                        // quant_slide_tuned_Qwen2.5-14B.py:300:56
(EngineCore_DP0 pid=532421) 	mul.f32 	%r109, %r14, %r95;
(EngineCore_DP0 pid=532421) 	mul.f32 	%r110, %r14, %r96;
(EngineCore_DP0 pid=532421) 	.loc	1 300 51                        // quant_slide_tuned_Qwen2.5-14B.py:300:51
(EngineCore_DP0 pid=532421) 	cvt.rni.f32.f32 	%r111, %r109;
(EngineCore_DP0 pid=532421) 	cvt.rni.f32.f32 	%r112, %r110;
(EngineCore_DP0 pid=532421) 	.loc	1 300 76                        // quant_slide_tuned_Qwen2.5-14B.py:300:76
(EngineCore_DP0 pid=532421) 	max.f32 	%r113, %r111, 0fC3000000;
(EngineCore_DP0 pid=532421) 	min.f32 	%r114, %r113, 0f42FE0000;
(EngineCore_DP0 pid=532421) 	max.f32 	%r115, %r112, 0fC3000000;
(EngineCore_DP0 pid=532421) 	min.f32 	%r116, %r115, 0f42FE0000;
(EngineCore_DP0 pid=532421) 	.loc	1 300 86                        // quant_slide_tuned_Qwen2.5-14B.py:300:86
(EngineCore_DP0 pid=532421) 	cvt.rzi.s32.f32 	%r117, %r114;
(EngineCore_DP0 pid=532421) 	cvt.rzi.s32.f32 	%r118, %r116;
(EngineCore_DP0 pid=532421) 	.loc	1 300 98                        // quant_slide_tuned_Qwen2.5-14B.py:300:98
(EngineCore_DP0 pid=532421) 	and.b32 	%r119, %r117, 255;
(EngineCore_DP0 pid=532421) 	and.b32 	%r120, %r118, 255;
(EngineCore_DP0 pid=532421) 	.loc	1 301 56                        // quant_slide_tuned_Qwen2.5-14B.py:301:56
(EngineCore_DP0 pid=532421) 	mul.f32 	%r121, %r14, %r99;
(EngineCore_DP0 pid=532421) 	mul.f32 	%r122, %r14, %r100;
(EngineCore_DP0 pid=532421) 	.loc	1 301 51                        // quant_slide_tuned_Qwen2.5-14B.py:301:51
(EngineCore_DP0 pid=532421) 	cvt.rni.f32.f32 	%r123, %r121;
(EngineCore_DP0 pid=532421) 	cvt.rni.f32.f32 	%r124, %r122;
(EngineCore_DP0 pid=532421) 	.loc	1 302 56                        // quant_slide_tuned_Qwen2.5-14B.py:302:56
(EngineCore_DP0 pid=532421) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=532421) 	mul.f32 	%r126, %r14, %r104;
(EngineCore_DP0 pid=532421) 	.loc	1 302 51                        // quant_slide_tuned_Qwen2.5-14B.py:302:51
(EngineCore_DP0 pid=532421) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=532421) 	cvt.rni.f32.f32 	%r128, %r126;
(EngineCore_DP0 pid=532421) 	.loc	1 303 56                        // quant_slide_tuned_Qwen2.5-14B.py:303:56
(EngineCore_DP0 pid=532421) 	mul.f32 	%r129, %r14, %r107;
(EngineCore_DP0 pid=532421) 	mul.f32 	%r130, %r14, %r108;
(EngineCore_DP0 pid=532421) 	.loc	1 303 51                        // quant_slide_tuned_Qwen2.5-14B.py:303:51
(EngineCore_DP0 pid=532421) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=532421) 	cvt.rni.f32.f32 	%r132, %r130;
(EngineCore_DP0 pid=532421) 	.loc	1 303 76                        // quant_slide_tuned_Qwen2.5-14B.py:303:76
(EngineCore_DP0 pid=532421) 	max.f32 	%r133, %r131, 0fC3000000;
(EngineCore_DP0 pid=532421) 	min.f32 	%r134, %r133, 0f42FE0000;
(EngineCore_DP0 pid=532421) 	max.f32 	%r135, %r132, 0fC3000000;
(EngineCore_DP0 pid=532421) 	min.f32 	%r136, %r135, 0f42FE0000;
(EngineCore_DP0 pid=532421) 	.loc	1 303 86                        // quant_slide_tuned_Qwen2.5-14B.py:303:86
(EngineCore_DP0 pid=532421) 	cvt.rzi.s32.f32 	%r137, %r134;
(EngineCore_DP0 pid=532421) 	cvt.rzi.s32.f32 	%r138, %r136;
(EngineCore_DP0 pid=532421) 	.loc	1 301 76                        // quant_slide_tuned_Qwen2.5-14B.py:301:76
(EngineCore_DP0 pid=532421) 	max.f32 	%r139, %r127, 0fC3000000;
(EngineCore_DP0 pid=532421) 	max.f32 	%r140, %r123, 0fC3000000;
(EngineCore_DP0 pid=532421) 	min.f32 	%r141, %r140, 0f42FE0000;
(EngineCore_DP0 pid=532421) 	min.f32 	%r142, %r139, 0f42FE0000;
(EngineCore_DP0 pid=532421) 	.loc	1 301 86                        // quant_slide_tuned_Qwen2.5-14B.py:301:86
(EngineCore_DP0 pid=532421) 	cvt.rzi.s32.f32 	%r143, %r142;
(EngineCore_DP0 pid=532421) 	cvt.rzi.s32.f32 	%r144, %r141;
(EngineCore_DP0 pid=532421) 	.loc	1 305 30                        // quant_slide_tuned_Qwen2.5-14B.py:305:30
(EngineCore_DP0 pid=532421) 	shl.b32 	%r145, %r144, 8;
(EngineCore_DP0 pid=532421) 	shl.b32 	%r146, %r143, 16;
(EngineCore_DP0 pid=532421) 	and.b32 	%r147, %r146, 16711680;
(EngineCore_DP0 pid=532421) 	and.b32 	%r148, %r145, 65280;
(EngineCore_DP0 pid=532421) 	.loc	1 305 24                        // quant_slide_tuned_Qwen2.5-14B.py:305:24
(EngineCore_DP0 pid=532421) 	or.b32 	%r149, %r148, %r119;
(EngineCore_DP0 pid=532421) 	.loc	1 301 76                        // quant_slide_tuned_Qwen2.5-14B.py:301:76
(EngineCore_DP0 pid=532421) 	max.f32 	%r150, %r128, 0fC3000000;
(EngineCore_DP0 pid=532421) 	max.f32 	%r151, %r124, 0fC3000000;
(EngineCore_DP0 pid=532421) 	min.f32 	%r152, %r151, 0f42FE0000;
(EngineCore_DP0 pid=532421) 	min.f32 	%r153, %r150, 0f42FE0000;
(EngineCore_DP0 pid=532421) 	.loc	1 301 86                        // quant_slide_tuned_Qwen2.5-14B.py:301:86
(EngineCore_DP0 pid=532421) 	cvt.rzi.s32.f32 	%r154, %r153;
(EngineCore_DP0 pid=532421) 	cvt.rzi.s32.f32 	%r155, %r152;
(EngineCore_DP0 pid=532421) 	.loc	1 305 30                        // quant_slide_tuned_Qwen2.5-14B.py:305:30
(EngineCore_DP0 pid=532421) 	shl.b32 	%r156, %r155, 8;
(EngineCore_DP0 pid=532421) 	shl.b32 	%r157, %r154, 16;
(EngineCore_DP0 pid=532421) 	and.b32 	%r158, %r157, 16711680;
(EngineCore_DP0 pid=532421) 	and.b32 	%r159, %r156, 65280;
(EngineCore_DP0 pid=532421) 	.loc	1 305 24                        // quant_slide_tuned_Qwen2.5-14B.py:305:24
(EngineCore_DP0 pid=532421) 	or.b32 	%r160, %r159, %r120;
(EngineCore_DP0 pid=532421) 	.loc	1 305 36                        // quant_slide_tuned_Qwen2.5-14B.py:305:36
(EngineCore_DP0 pid=532421) 	or.b32 	%r161, %r149, %r147;
(EngineCore_DP0 pid=532421) 	or.b32 	%r162, %r160, %r158;
(EngineCore_DP0 pid=532421) 	.loc	1 305 55                        // quant_slide_tuned_Qwen2.5-14B.py:305:55
(EngineCore_DP0 pid=532421) 	shl.b32 	%r163, %r137, 24;
(EngineCore_DP0 pid=532421) 	shl.b32 	%r164, %r138, 24;
(EngineCore_DP0 pid=532421) 	.loc	1 305 49                        // quant_slide_tuned_Qwen2.5-14B.py:305:49
(EngineCore_DP0 pid=532421) 	or.b32 	%r83, %r161, %r163;
(EngineCore_DP0 pid=532421) 	or.b32 	%r84, %r162, %r164;
(EngineCore_DP0 pid=532421) 	.loc	1 306 29                        // quant_slide_tuned_Qwen2.5-14B.py:306:29
(EngineCore_DP0 pid=532421) 	mad.wide.s32 	%rd17, %r85, 4, %rd2;
(EngineCore_DP0 pid=532421) 	.loc	1 306 39                        // quant_slide_tuned_Qwen2.5-14B.py:306:39
(EngineCore_DP0 pid=532421) 	// begin inline asm
(EngineCore_DP0 pid=532421) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r83, %r84 };
(EngineCore_DP0 pid=532421) 	// end inline asm
(EngineCore_DP0 pid=532421) 	.loc	1 282 41                        // quant_slide_tuned_Qwen2.5-14B.py:282:41
(EngineCore_DP0 pid=532421) 	add.s32 	%r168, %r168, 1024;
(EngineCore_DP0 pid=532421) 	setp.lt.s32 	%p27, %r168, %r15;
(EngineCore_DP0 pid=532421) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=532421) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=532421) 	.loc	1 282 4                         // quant_slide_tuned_Qwen2.5-14B.py:282:4
(EngineCore_DP0 pid=532421) 	ret;
(EngineCore_DP0 pid=532421) $L__tmp3:
(EngineCore_DP0 pid=532421) $L__func_end0:
(EngineCore_DP0 pid=532421)                                         // -- End function
(EngineCore_DP0 pid=532421) }
(EngineCore_DP0 pid=532421) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-14B.py"
(EngineCore_DP0 pid=532421) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=532421) 	.section	.debug_abbrev
(EngineCore_DP0 pid=532421) 	{
(EngineCore_DP0 pid=532421) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=532421) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=532421) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=532421) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=532421) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=532421) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=532421) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=532421) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=532421) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=532421) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=532421) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=532421) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=532421) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=532421) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=532421) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=532421) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=532421) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=532421) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=532421) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=532421) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=532421) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=532421) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=532421) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=532421) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=532421) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=532421) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=532421) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=532421) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=532421) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=532421) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=532421) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=532421) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=532421) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=532421) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=532421) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=532421) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=532421) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=532421) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=532421) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=532421) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=532421) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=532421) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=532421) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=532421) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=532421) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=532421) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=532421) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=532421) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=532421) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=532421) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=532421) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=532421) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=532421) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=532421) 	}
(EngineCore_DP0 pid=532421) 	.section	.debug_info
(EngineCore_DP0 pid=532421) 	{
(EngineCore_DP0 pid=532421) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=532421) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=532421) .b8 0
(EngineCore_DP0 pid=532421) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=532421) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=532421) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=532421) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=532421) .b8 114
(EngineCore_DP0 pid=532421) .b8 105
(EngineCore_DP0 pid=532421) .b8 116
(EngineCore_DP0 pid=532421) .b8 111
(EngineCore_DP0 pid=532421) .b8 110
(EngineCore_DP0 pid=532421) .b8 0
(EngineCore_DP0 pid=532421) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=532421) .b8 0
(EngineCore_DP0 pid=532421) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=532421) .b8 117
(EngineCore_DP0 pid=532421) .b8 97
(EngineCore_DP0 pid=532421) .b8 110
(EngineCore_DP0 pid=532421) .b8 116
(EngineCore_DP0 pid=532421) .b8 95
(EngineCore_DP0 pid=532421) .b8 115
(EngineCore_DP0 pid=532421) .b8 108
(EngineCore_DP0 pid=532421) .b8 105
(EngineCore_DP0 pid=532421) .b8 100
(EngineCore_DP0 pid=532421) .b8 101
(EngineCore_DP0 pid=532421) .b8 95
(EngineCore_DP0 pid=532421) .b8 116
(EngineCore_DP0 pid=532421) .b8 117
(EngineCore_DP0 pid=532421) .b8 110
(EngineCore_DP0 pid=532421) .b8 101
(EngineCore_DP0 pid=532421) .b8 100
(EngineCore_DP0 pid=532421) .b8 95
(EngineCore_DP0 pid=532421) .b8 81
(EngineCore_DP0 pid=532421) .b8 119
(EngineCore_DP0 pid=532421) .b8 101
(EngineCore_DP0 pid=532421) .b8 110
(EngineCore_DP0 pid=532421) .b8 50
(EngineCore_DP0 pid=532421) .b8 46
(EngineCore_DP0 pid=532421) .b8 53
(EngineCore_DP0 pid=532421) .b8 45
(EngineCore_DP0 pid=532421) .b8 49
(EngineCore_DP0 pid=532421) .b8 52
(EngineCore_DP0 pid=532421) .b8 66
(EngineCore_DP0 pid=532421) .b8 46
(EngineCore_DP0 pid=532421) .b8 112
(EngineCore_DP0 pid=532421) .b8 121
(EngineCore_DP0 pid=532421) .b8 0
(EngineCore_DP0 pid=532421) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=532421) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=532421) .b8 114
(EngineCore_DP0 pid=532421) .b8 111
(EngineCore_DP0 pid=532421) .b8 111
(EngineCore_DP0 pid=532421) .b8 116
(EngineCore_DP0 pid=532421) .b8 47
(EngineCore_DP0 pid=532421) .b8 118
(EngineCore_DP0 pid=532421) .b8 108
(EngineCore_DP0 pid=532421) .b8 108
(EngineCore_DP0 pid=532421) .b8 109
(EngineCore_DP0 pid=532421) .b8 98
(EngineCore_DP0 pid=532421) .b8 101
(EngineCore_DP0 pid=532421) .b8 110
(EngineCore_DP0 pid=532421) .b8 99
(EngineCore_DP0 pid=532421) .b8 104
(EngineCore_DP0 pid=532421) .b8 47
(EngineCore_DP0 pid=532421) .b8 115
(EngineCore_DP0 pid=532421) .b8 108
(EngineCore_DP0 pid=532421) .b8 105
(EngineCore_DP0 pid=532421) .b8 100
(EngineCore_DP0 pid=532421) .b8 101
(EngineCore_DP0 pid=532421) .b8 115
(EngineCore_DP0 pid=532421) .b8 112
(EngineCore_DP0 pid=532421) .b8 97
(EngineCore_DP0 pid=532421) .b8 114
(EngineCore_DP0 pid=532421) .b8 115
(EngineCore_DP0 pid=532421) .b8 101
(EngineCore_DP0 pid=532421) .b8 47
(EngineCore_DP0 pid=532421) .b8 99
(EngineCore_DP0 pid=532421) .b8 115
(EngineCore_DP0 pid=532421) .b8 114
(EngineCore_DP0 pid=532421) .b8 99
(EngineCore_DP0 pid=532421) .b8 47
(EngineCore_DP0 pid=532421) .b8 102
(EngineCore_DP0 pid=532421) .b8 117
(EngineCore_DP0 pid=532421) .b8 115
(EngineCore_DP0 pid=532421) .b8 101
(EngineCore_DP0 pid=532421) .b8 100
(EngineCore_DP0 pid=532421) .b8 95
(EngineCore_DP0 pid=532421) .b8 113
(EngineCore_DP0 pid=532421) .b8 117
(EngineCore_DP0 pid=532421) .b8 97
(EngineCore_DP0 pid=532421) .b8 110
(EngineCore_DP0 pid=532421) .b8 116
(EngineCore_DP0 pid=532421) .b8 95
(EngineCore_DP0 pid=532421) .b8 115
(EngineCore_DP0 pid=532421) .b8 108
(EngineCore_DP0 pid=532421) .b8 105
(EngineCore_DP0 pid=532421) .b8 100
(EngineCore_DP0 pid=532421) .b8 101
(EngineCore_DP0 pid=532421) .b8 95
(EngineCore_DP0 pid=532421) .b8 116
(EngineCore_DP0 pid=532421) .b8 114
(EngineCore_DP0 pid=532421) .b8 105
(EngineCore_DP0 pid=532421) .b8 116
(EngineCore_DP0 pid=532421) .b8 111
(EngineCore_DP0 pid=532421) .b8 110
(EngineCore_DP0 pid=532421) .b8 47
(EngineCore_DP0 pid=532421) .b8 98
(EngineCore_DP0 pid=532421) .b8 117
(EngineCore_DP0 pid=532421) .b8 105
(EngineCore_DP0 pid=532421) .b8 108
(EngineCore_DP0 pid=532421) .b8 100
(EngineCore_DP0 pid=532421) .b8 47
(EngineCore_DP0 pid=532421) .b8 71
(EngineCore_DP0 pid=532421) .b8 66
(EngineCore_DP0 pid=532421) .b8 49
(EngineCore_DP0 pid=532421) .b8 48
(EngineCore_DP0 pid=532421) .b8 95
(EngineCore_DP0 pid=532421) .b8 99
(EngineCore_DP0 pid=532421) .b8 99
(EngineCore_DP0 pid=532421) .b8 49
(EngineCore_DP0 pid=532421) .b8 50
(EngineCore_DP0 pid=532421) .b8 49
(EngineCore_DP0 pid=532421) .b8 95
(EngineCore_DP0 pid=532421) .b8 112
(EngineCore_DP0 pid=532421) .b8 121
(EngineCore_DP0 pid=532421) .b8 51
(EngineCore_DP0 pid=532421) .b8 49
(EngineCore_DP0 pid=532421) .b8 50
(EngineCore_DP0 pid=532421) .b8 95
(EngineCore_DP0 pid=532421) .b8 99
(EngineCore_DP0 pid=532421) .b8 117
(EngineCore_DP0 pid=532421) .b8 49
(EngineCore_DP0 pid=532421) .b8 50
(EngineCore_DP0 pid=532421) .b8 57
(EngineCore_DP0 pid=532421) .b8 95
(EngineCore_DP0 pid=532421) .b8 97
(EngineCore_DP0 pid=532421) .b8 97
(EngineCore_DP0 pid=532421) .b8 114
(EngineCore_DP0 pid=532421) .b8 99
(EngineCore_DP0 pid=532421) .b8 104
(EngineCore_DP0 pid=532421) .b8 54
(EngineCore_DP0 pid=532421) .b8 52
(EngineCore_DP0 pid=532421) .b8 0
(EngineCore_DP0 pid=532421) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=532421) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=532421) .b8 113
(EngineCore_DP0 pid=532421) .b8 117
(EngineCore_DP0 pid=532421) .b8 97
(EngineCore_DP0 pid=532421) .b8 110
(EngineCore_DP0 pid=532421) .b8 116
(EngineCore_DP0 pid=532421) .b8 95
(EngineCore_DP0 pid=532421) .b8 115
(EngineCore_DP0 pid=532421) .b8 108
(EngineCore_DP0 pid=532421) .b8 105
(EngineCore_DP0 pid=532421) .b8 100
(EngineCore_DP0 pid=532421) .b8 101
(EngineCore_DP0 pid=532421) .b8 95
(EngineCore_DP0 pid=532421) .b8 105
(EngineCore_DP0 pid=532421) .b8 110
(EngineCore_DP0 pid=532421) .b8 116
(EngineCore_DP0 pid=532421) .b8 56
(EngineCore_DP0 pid=532421) .b8 95
(EngineCore_DP0 pid=532421) .b8 107
(EngineCore_DP0 pid=532421) .b8 101
(EngineCore_DP0 pid=532421) .b8 114
(EngineCore_DP0 pid=532421) .b8 110
(EngineCore_DP0 pid=532421) .b8 101
(EngineCore_DP0 pid=532421) .b8 108
(EngineCore_DP0 pid=532421) .b8 0
(EngineCore_DP0 pid=532421) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=532421) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=532421) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=532421) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=532421) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=532421) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=532421) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=532421) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=532421) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=532421) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=532421) .b8 16                                  // DW_AT_call_line
(EngineCore_DP0 pid=532421) .b8 1
(EngineCore_DP0 pid=532421) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=532421) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=532421) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=532421) 	}
(EngineCore_DP0 pid=532421) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=532421) 
(EngineCore_DP0 pid=532421) ================================================================
(EngineCore_DP0 pid=532421) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=532421) 
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp2m3w691g.ptx', '-o', '/tmp/tmp2m3w691g.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866] 
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866] 
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-14B.py", line 335, in quant_slide_int8_triton
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866] 
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp2m3w691g.ptx -o /tmp/tmp2m3w691g.ptx.o
(EngineCore_DP0 pid=532421) ERROR 01-25 22:26:52 [core.py:866] 

STDERR:
[2026-01-25 22:24:54] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 22:24:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-25 22:24:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-25 22:24:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:24:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:24:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:24:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:24:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:24:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-25 22:24:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:24:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:24:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:24:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:24:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:24:57] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 22:24:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-25 22:24:57] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-25 22:24:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:24:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:24:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:24:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:24:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:24:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-25 22:24:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:24:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:24:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:24:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:24:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=532421) [2026-01-25 22:24:58] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=532421) [2026-01-25 22:24:58] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=532421) [2026-01-25 22:24:58] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=532421) [2026-01-25 22:24:58] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=532421) [2026-01-25 22:24:58] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=532421) [2026-01-25 22:24:58] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=532421) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=532421) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.55s/it]
(EngineCore_DP0 pid=532421) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:42<00:47, 23.68s/it]
(EngineCore_DP0 pid=532421) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:14<00:27, 27.55s/it]
(EngineCore_DP0 pid=532421) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:47<00:00, 29.63s/it]
(EngineCore_DP0 pid=532421) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:47<00:00, 26.95s/it]
(EngineCore_DP0 pid=532421) 
(EngineCore_DP0 pid=532421) [2026-01-25 22:26:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=532421) [2026-01-25 22:26:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36929536 bytes
(EngineCore_DP0 pid=532421) [2026-01-25 22:26:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=532421) [2026-01-25 22:26:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26378240 bytes
(EngineCore_DP0 pid=532421) [2026-01-25 22:26:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=532421) [2026-01-25 22:26:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 142442496 bytes
(EngineCore_DP0 pid=532421) [2026-01-25 22:26:48] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=532421) [2026-01-25 22:26:48] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70778880 bytes
(EngineCore_DP0 pid=532421) Process EngineCore_DP0:
(EngineCore_DP0 pid=532421) Traceback (most recent call last):
(EngineCore_DP0 pid=532421)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=532421)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=532421)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=532421)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=532421) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp2m3w691g.ptx', '-o', '/tmp/tmp2m3w691g.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=532421) 
(EngineCore_DP0 pid=532421) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=532421) 
(EngineCore_DP0 pid=532421) Traceback (most recent call last):
(EngineCore_DP0 pid=532421)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=532421)     self.run()
(EngineCore_DP0 pid=532421)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=532421)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=532421)     raise e
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=532421)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=532421)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=532421)     super().__init__(
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=532421)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=532421)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=532421)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=532421)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=532421)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=532421)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=532421)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=532421)     return func(*args, **kwargs)
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=532421)     return func(*args, **kwargs)
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=532421)     self.model_runner.profile_run()
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=532421)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=532421)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=532421)     return func(*args, **kwargs)
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=532421)     outputs = self.model(
(EngineCore_DP0 pid=532421)               ^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=532421)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=532421)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=532421)     hidden_states = self.model(
(EngineCore_DP0 pid=532421)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=532421)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=532421)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=532421)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=532421)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=532421)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=532421)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=532421)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=532421)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=532421)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=532421)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=532421)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=532421)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=532421)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=532421)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=532421)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=532421)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=532421)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=532421)     return self._linear_fn(
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=532421)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=532421)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=532421)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=532421)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=532421)     return fn(input, L)
(EngineCore_DP0 pid=532421)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-14B.py", line 335, in quant_slide_int8_triton
(EngineCore_DP0 pid=532421)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=532421)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=532421)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=532421)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=532421)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=532421)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=532421)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=532421)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=532421)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=532421)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=532421)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=532421)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=532421)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=532421)     raise PTXASError(error)
(EngineCore_DP0 pid=532421) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=532421) `ptxas` stderr:
(EngineCore_DP0 pid=532421) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=532421) 
(EngineCore_DP0 pid=532421) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp2m3w691g.ptx -o /tmp/tmp2m3w691g.ptx.o
(EngineCore_DP0 pid=532421) 
[rank0]:[W125 22:26:52.666160099 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 22:26:54
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:26:58 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 22:26:59 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=534278) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=534278) 
(EngineCore_DP0 pid=534278) 
(EngineCore_DP0 pid=534278) ================================================================
(EngineCore_DP0 pid=534278) Internal Triton PTX codegen error
(EngineCore_DP0 pid=534278) `ptxas` stderr:
(EngineCore_DP0 pid=534278) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=534278) 
(EngineCore_DP0 pid=534278) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmppbwt7a4_.ptx -o /tmp/tmppbwt7a4_.ptx.o
(EngineCore_DP0 pid=534278) 
(EngineCore_DP0 pid=534278) 
(EngineCore_DP0 pid=534278) //
(EngineCore_DP0 pid=534278) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=534278) //
(EngineCore_DP0 pid=534278) 
(EngineCore_DP0 pid=534278) .version 8.7
(EngineCore_DP0 pid=534278) .target sm_121a
(EngineCore_DP0 pid=534278) .address_size 64
(EngineCore_DP0 pid=534278) 
(EngineCore_DP0 pid=534278) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=534278) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=534278)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=534278) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=534278) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=534278) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=534278) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=534278) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=534278) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=534278) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=534278) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=534278) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=534278) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=534278) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=534278) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=534278) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=534278) )
(EngineCore_DP0 pid=534278) .reqntid 512
(EngineCore_DP0 pid=534278) {
(EngineCore_DP0 pid=534278) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=534278) 	.reg .b16 	%rs<64>;
(EngineCore_DP0 pid=534278) 	.reg .b32 	%r<169>;
(EngineCore_DP0 pid=534278) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=534278) 	.loc	1 248 0                         // quant_slide_tuned_Qwen2.5-14B.py:248:0
(EngineCore_DP0 pid=534278) $L__func_begin0:
(EngineCore_DP0 pid=534278) 	.loc	1 248 0                         // quant_slide_tuned_Qwen2.5-14B.py:248:0
(EngineCore_DP0 pid=534278) 
(EngineCore_DP0 pid=534278) // %bb.0:
(EngineCore_DP0 pid=534278) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=534278) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=534278) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=534278) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=534278) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=534278) $L__tmp0:
(EngineCore_DP0 pid=534278) 	.loc	1 258 24                        // quant_slide_tuned_Qwen2.5-14B.py:258:24
(EngineCore_DP0 pid=534278) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=534278) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=534278) 	.loc	1 263 26                        // quant_slide_tuned_Qwen2.5-14B.py:263:26
(EngineCore_DP0 pid=534278) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=534278) 	.loc	1 263 20                        // quant_slide_tuned_Qwen2.5-14B.py:263:20
(EngineCore_DP0 pid=534278) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=534278) 	.loc	1 269 32                        // quant_slide_tuned_Qwen2.5-14B.py:269:32
(EngineCore_DP0 pid=534278) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=534278) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=534278) 	.loc	1 268 35                        // quant_slide_tuned_Qwen2.5-14B.py:268:35
(EngineCore_DP0 pid=534278) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=534278) 	mov.b32 	%r167, 0f2B8CBCCC;
(EngineCore_DP0 pid=534278) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=534278) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=534278) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=534278) 	.loc	1 269 32                        // quant_slide_tuned_Qwen2.5-14B.py:269:32
(EngineCore_DP0 pid=534278) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=534278) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=534278) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=534278) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=534278) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=534278) 	add.s32 	%r53, %r35, %r34;
(EngineCore_DP0 pid=534278) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=534278) 	add.s32 	%r56, %r35, %r36;
(EngineCore_DP0 pid=534278) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=534278) 	mov.b32 	%r165, 0f00000000;
(EngineCore_DP0 pid=534278) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=534278) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=534278) 	mov.b32 	%r166, %r41;
(EngineCore_DP0 pid=534278) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=534278) 	.loc	1 269 19                        // quant_slide_tuned_Qwen2.5-14B.py:269:19
(EngineCore_DP0 pid=534278) 	add.s32 	%r59, %r4, %r166;
(EngineCore_DP0 pid=534278) 	.loc	1 270 22                        // quant_slide_tuned_Qwen2.5-14B.py:270:22
(EngineCore_DP0 pid=534278) 	add.s32 	%r60, %r59, 4096;
(EngineCore_DP0 pid=534278) 	setp.lt.s32 	%p2, %r59, %r19;
(EngineCore_DP0 pid=534278) 	setp.lt.s32 	%p3, %r60, %r19;
(EngineCore_DP0 pid=534278) 	.loc	1 271 29                        // quant_slide_tuned_Qwen2.5-14B.py:271:29
(EngineCore_DP0 pid=534278) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=534278) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=534278) 	.loc	1 271 21                        // quant_slide_tuned_Qwen2.5-14B.py:271:21
(EngineCore_DP0 pid=534278) 	// begin inline asm
(EngineCore_DP0 pid=534278) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=534278) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=534278) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=534278) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=534278) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=534278) 	// end inline asm
(EngineCore_DP0 pid=534278) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=534278) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=534278) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=534278) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=534278) 	// begin inline asm
(EngineCore_DP0 pid=534278) 	mov.u32 %r45, %r41;
(EngineCore_DP0 pid=534278) 	mov.u32 %r46, %r41;
(EngineCore_DP0 pid=534278) 	mov.u32 %r47, %r41;
(EngineCore_DP0 pid=534278) 	mov.u32 %r48, %r41;
(EngineCore_DP0 pid=534278) 	@%p3 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=534278) 	// end inline asm
(EngineCore_DP0 pid=534278) 	mov.b32 	{%rs9, %rs10}, %r45;
(EngineCore_DP0 pid=534278) 	mov.b32 	{%rs11, %rs12}, %r46;
(EngineCore_DP0 pid=534278) 	mov.b32 	{%rs13, %rs14}, %r47;
(EngineCore_DP0 pid=534278) 	mov.b32 	{%rs15, %rs16}, %r48;
(EngineCore_DP0 pid=534278) 	.loc	1 272 50                        // quant_slide_tuned_Qwen2.5-14B.py:272:50
(EngineCore_DP0 pid=534278) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=534278) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=534278) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=534278) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=534278) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=534278) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=534278) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=534278) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=534278) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=534278) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=534278) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=534278) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=534278) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=534278) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=534278) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=534278) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=534278) $L__tmp1:
(EngineCore_DP0 pid=534278) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	bar.sync 	0;
(EngineCore_DP0 pid=534278) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=534278) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=534278) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=534278) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=534278) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=534278) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=534278) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=534278) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=534278) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=534278) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=534278) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=534278) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=534278) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=534278) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=534278) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=534278) 	cvt.f32.bf16 	%r61, %rs47;
(EngineCore_DP0 pid=534278) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	shfl.sync.bfly.b32 	%r62, %r61, 16, 31, -1;
(EngineCore_DP0 pid=534278) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=534278) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	shfl.sync.bfly.b32 	%r64, %r63, 8, 31, -1;
(EngineCore_DP0 pid=534278) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=534278) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=534278) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=534278) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=534278) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=534278) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=534278) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	max.f32 	%r54, %r69, %r70;
(EngineCore_DP0 pid=534278) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	// begin inline asm
(EngineCore_DP0 pid=534278) 	@%p4 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=534278) 	// end inline asm
(EngineCore_DP0 pid=534278) 	bar.sync 	0;
(EngineCore_DP0 pid=534278) 	// begin inline asm
(EngineCore_DP0 pid=534278) 	@%p5 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=534278) 	// end inline asm
(EngineCore_DP0 pid=534278) 	shfl.sync.bfly.b32 	%r71, %r55, 8, 31, -1;
(EngineCore_DP0 pid=534278) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	max.f32 	%r72, %r55, %r71;
(EngineCore_DP0 pid=534278) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	shfl.sync.bfly.b32 	%r73, %r72, 4, 31, -1;
(EngineCore_DP0 pid=534278) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	max.f32 	%r74, %r72, %r73;
(EngineCore_DP0 pid=534278) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	shfl.sync.bfly.b32 	%r75, %r74, 2, 31, -1;
(EngineCore_DP0 pid=534278) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	max.f32 	%r76, %r74, %r75;
(EngineCore_DP0 pid=534278) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	shfl.sync.bfly.b32 	%r77, %r76, 1, 31, -1;
(EngineCore_DP0 pid=534278) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	max.f32 	%r58, %r76, %r77;
(EngineCore_DP0 pid=534278) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=534278) 	// begin inline asm
(EngineCore_DP0 pid=534278) 	@%p28 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=534278) 	// end inline asm
(EngineCore_DP0 pid=534278) 	bar.sync 	0;
(EngineCore_DP0 pid=534278) 	ld.shared.b32 	%r78, [global_smem];
(EngineCore_DP0 pid=534278) $L__tmp2:
(EngineCore_DP0 pid=534278) 	.loc	1 272 36                        // quant_slide_tuned_Qwen2.5-14B.py:272:36
(EngineCore_DP0 pid=534278) 	max.f32 	%r165, %r165, %r78;
(EngineCore_DP0 pid=534278) 	.loc	1 268 35                        // quant_slide_tuned_Qwen2.5-14B.py:268:35
(EngineCore_DP0 pid=534278) 	add.s32 	%r166, %r166, 8192;
(EngineCore_DP0 pid=534278) 	setp.lt.s32 	%p7, %r166, %r20;
(EngineCore_DP0 pid=534278) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=534278) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=534278) 	.loc	1 274 32                        // quant_slide_tuned_Qwen2.5-14B.py:274:32
(EngineCore_DP0 pid=534278) 	max.f32 	%r167, %r165, 0f2B8CBCCC;
(EngineCore_DP0 pid=534278) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=534278) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-14B.py:0:32
(EngineCore_DP0 pid=534278) 	mov.b32 	%r80, 0f42FE0000;
(EngineCore_DP0 pid=534278) 	.loc	1 275 32                        // quant_slide_tuned_Qwen2.5-14B.py:275:32
(EngineCore_DP0 pid=534278) 	div.full.f32 	%r81, %r167, %r80;
(EngineCore_DP0 pid=534278) 	.loc	1 275 42                        // quant_slide_tuned_Qwen2.5-14B.py:275:42
(EngineCore_DP0 pid=534278) 	max.f32 	%r79, %r81, 0f37810204;
(EngineCore_DP0 pid=534278) 	.loc	1 277 25                        // quant_slide_tuned_Qwen2.5-14B.py:277:25
(EngineCore_DP0 pid=534278) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=534278) 	.loc	1 277 30                        // quant_slide_tuned_Qwen2.5-14B.py:277:30
(EngineCore_DP0 pid=534278) 	// begin inline asm
(EngineCore_DP0 pid=534278) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r79 };
(EngineCore_DP0 pid=534278) 	// end inline asm
(EngineCore_DP0 pid=534278) 	.loc	1 280 29                        // quant_slide_tuned_Qwen2.5-14B.py:280:29
(EngineCore_DP0 pid=534278) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=534278) 	.loc	1 282 41                        // quant_slide_tuned_Qwen2.5-14B.py:282:41
(EngineCore_DP0 pid=534278) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=534278) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=534278) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=534278) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-14B.py:0:41
(EngineCore_DP0 pid=534278) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=534278) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=534278) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=534278) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=534278) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=534278) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=534278) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=534278) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=534278) 	div.full.f32 	%r14, %r80, %r167;
(EngineCore_DP0 pid=534278) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=534278) 	mov.b32 	%r168, 0;
(EngineCore_DP0 pid=534278) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=534278)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=534278) 	.loc	1 283 31                        // quant_slide_tuned_Qwen2.5-14B.py:283:31
(EngineCore_DP0 pid=534278) 	add.s32 	%r85, %r16, %r168;
(EngineCore_DP0 pid=534278) 	.loc	1 284 30                        // quant_slide_tuned_Qwen2.5-14B.py:284:30
(EngineCore_DP0 pid=534278) 	add.s32 	%r86, %r168, 1;
(EngineCore_DP0 pid=534278) 	setp.lt.s32 	%p18, %r85, %r15;
(EngineCore_DP0 pid=534278) 	.loc	1 287 24                        // quant_slide_tuned_Qwen2.5-14B.py:287:24
(EngineCore_DP0 pid=534278) 	shr.u32 	%r87, %r85, 1;
(EngineCore_DP0 pid=534278) 	.loc	1 288 23                        // quant_slide_tuned_Qwen2.5-14B.py:288:23
(EngineCore_DP0 pid=534278) 	shr.u32 	%r88, %r86, 31;
(EngineCore_DP0 pid=534278) 	add.s32 	%r89, %r86, %r88;
(EngineCore_DP0 pid=534278) 	and.b32 	%r90, %r89, 2147483646;
(EngineCore_DP0 pid=534278) 	sub.s32 	%r91, %r86, %r90;
(EngineCore_DP0 pid=534278) 	.loc	1 289 22                        // quant_slide_tuned_Qwen2.5-14B.py:289:22
(EngineCore_DP0 pid=534278) 	mul.lo.s32 	%r92, %r87, 6;
(EngineCore_DP0 pid=534278) 	.loc	1 289 30                        // quant_slide_tuned_Qwen2.5-14B.py:289:30
(EngineCore_DP0 pid=534278) 	shl.b32 	%r93, %r91, 1;
(EngineCore_DP0 pid=534278) 	.loc	1 289 26                        // quant_slide_tuned_Qwen2.5-14B.py:289:26
(EngineCore_DP0 pid=534278) 	add.s32 	%r94, %r92, %r93;
(EngineCore_DP0 pid=534278) 	.loc	1 292 53                        // quant_slide_tuned_Qwen2.5-14B.py:292:53
(EngineCore_DP0 pid=534278) 	setp.lt.s32 	%p19, %r92, %r19;
(EngineCore_DP0 pid=534278) 	setp.lt.s32 	%p20, %r94, %r19;
(EngineCore_DP0 pid=534278) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-14B.py:292:37
(EngineCore_DP0 pid=534278) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=534278) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=534278) 	.loc	1 291 29                        // quant_slide_tuned_Qwen2.5-14B.py:291:29
(EngineCore_DP0 pid=534278) 	mad.wide.s32 	%rd9, %r92, 2, %rd1;
(EngineCore_DP0 pid=534278) 	mad.wide.s32 	%rd10, %r94, 2, %rd1;
(EngineCore_DP0 pid=534278) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=534278) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-14B.py:291:21
(EngineCore_DP0 pid=534278) 	// begin inline asm
(EngineCore_DP0 pid=534278) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=534278) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=534278) 	// end inline asm
(EngineCore_DP0 pid=534278) 	// begin inline asm
(EngineCore_DP0 pid=534278) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=534278) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=534278) 	// end inline asm
(EngineCore_DP0 pid=534278) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-14B.py:292:79
(EngineCore_DP0 pid=534278) 	cvt.f32.bf16 	%r95, %rs48;
(EngineCore_DP0 pid=534278) 	cvt.f32.bf16 	%r96, %rs50;
(EngineCore_DP0 pid=534278) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-14B.py:294:48
(EngineCore_DP0 pid=534278) 	or.b32 	%r97, %r92, 1;
(EngineCore_DP0 pid=534278) 	or.b32 	%r98, %r94, 1;
(EngineCore_DP0 pid=534278) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-14B.py:294:53
(EngineCore_DP0 pid=534278) 	setp.lt.s32 	%p21, %r97, %r19;
(EngineCore_DP0 pid=534278) 	setp.lt.s32 	%p22, %r98, %r19;
(EngineCore_DP0 pid=534278) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-14B.py:294:37
(EngineCore_DP0 pid=534278) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=534278) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=534278) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-14B.py:293:39
(EngineCore_DP0 pid=534278) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=534278) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=534278) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-14B.py:293:21
(EngineCore_DP0 pid=534278) 	// begin inline asm
(EngineCore_DP0 pid=534278) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=534278) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=534278) 	// end inline asm
(EngineCore_DP0 pid=534278) 	// begin inline asm
(EngineCore_DP0 pid=534278) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=534278) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=534278) 	// end inline asm
(EngineCore_DP0 pid=534278) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-14B.py:294:79
(EngineCore_DP0 pid=534278) 	cvt.f32.bf16 	%r99, %rs52;
(EngineCore_DP0 pid=534278) 	cvt.f32.bf16 	%r100, %rs54;
(EngineCore_DP0 pid=534278) 	.loc	1 296 48                        // quant_slide_tuned_Qwen2.5-14B.py:296:48
(EngineCore_DP0 pid=534278) 	add.s32 	%r101, %r92, 2;
(EngineCore_DP0 pid=534278) 	add.s32 	%r102, %r94, 2;
(EngineCore_DP0 pid=534278) 	.loc	1 296 53                        // quant_slide_tuned_Qwen2.5-14B.py:296:53
(EngineCore_DP0 pid=534278) 	setp.lt.s32 	%p23, %r101, %r19;
(EngineCore_DP0 pid=534278) 	setp.lt.s32 	%p24, %r102, %r19;
(EngineCore_DP0 pid=534278) 	.loc	1 296 37                        // quant_slide_tuned_Qwen2.5-14B.py:296:37
(EngineCore_DP0 pid=534278) 	and.pred 	%p14, %p18, %p23;
(EngineCore_DP0 pid=534278) 	and.pred 	%p15, %p18, %p24;
(EngineCore_DP0 pid=534278) 	.loc	1 295 39                        // quant_slide_tuned_Qwen2.5-14B.py:295:39
(EngineCore_DP0 pid=534278) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=534278) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=534278) 	.loc	1 295 21                        // quant_slide_tuned_Qwen2.5-14B.py:295:21
(EngineCore_DP0 pid=534278) 	// begin inline asm
(EngineCore_DP0 pid=534278) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=534278) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=534278) 	// end inline asm
(EngineCore_DP0 pid=534278) 	// begin inline asm
(EngineCore_DP0 pid=534278) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=534278) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=534278) 	// end inline asm
(EngineCore_DP0 pid=534278) 	.loc	1 296 79                        // quant_slide_tuned_Qwen2.5-14B.py:296:79
(EngineCore_DP0 pid=534278) 	cvt.f32.bf16 	%r103, %rs56;
(EngineCore_DP0 pid=534278) 	cvt.f32.bf16 	%r104, %rs58;
(EngineCore_DP0 pid=534278) 	.loc	1 298 48                        // quant_slide_tuned_Qwen2.5-14B.py:298:48
(EngineCore_DP0 pid=534278) 	add.s32 	%r105, %r92, 3;
(EngineCore_DP0 pid=534278) 	add.s32 	%r106, %r94, 3;
(EngineCore_DP0 pid=534278) 	.loc	1 298 53                        // quant_slide_tuned_Qwen2.5-14B.py:298:53
(EngineCore_DP0 pid=534278) 	setp.lt.s32 	%p25, %r105, %r19;
(EngineCore_DP0 pid=534278) 	setp.lt.s32 	%p26, %r106, %r19;
(EngineCore_DP0 pid=534278) 	.loc	1 298 37                        // quant_slide_tuned_Qwen2.5-14B.py:298:37
(EngineCore_DP0 pid=534278) 	and.pred 	%p16, %p18, %p25;
(EngineCore_DP0 pid=534278) 	and.pred 	%p17, %p18, %p26;
(EngineCore_DP0 pid=534278) 	.loc	1 297 39                        // quant_slide_tuned_Qwen2.5-14B.py:297:39
(EngineCore_DP0 pid=534278) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=534278) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=534278) 	.loc	1 297 21                        // quant_slide_tuned_Qwen2.5-14B.py:297:21
(EngineCore_DP0 pid=534278) 	// begin inline asm
(EngineCore_DP0 pid=534278) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=534278) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=534278) 	// end inline asm
(EngineCore_DP0 pid=534278) 	// begin inline asm
(EngineCore_DP0 pid=534278) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=534278) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=534278) 	// end inline asm
(EngineCore_DP0 pid=534278) 	.loc	1 298 79                        // quant_slide_tuned_Qwen2.5-14B.py:298:79
(EngineCore_DP0 pid=534278) 	cvt.f32.bf16 	%r107, %rs60;
(EngineCore_DP0 pid=534278) 	cvt.f32.bf16 	%r108, %rs62;
(EngineCore_DP0 pid=534278) 	.loc	1 300 56                        // quant_slide_tuned_Qwen2.5-14B.py:300:56
(EngineCore_DP0 pid=534278) 	mul.f32 	%r109, %r14, %r95;
(EngineCore_DP0 pid=534278) 	mul.f32 	%r110, %r14, %r96;
(EngineCore_DP0 pid=534278) 	.loc	1 300 51                        // quant_slide_tuned_Qwen2.5-14B.py:300:51
(EngineCore_DP0 pid=534278) 	cvt.rni.f32.f32 	%r111, %r109;
(EngineCore_DP0 pid=534278) 	cvt.rni.f32.f32 	%r112, %r110;
(EngineCore_DP0 pid=534278) 	.loc	1 300 76                        // quant_slide_tuned_Qwen2.5-14B.py:300:76
(EngineCore_DP0 pid=534278) 	max.f32 	%r113, %r111, 0fC3000000;
(EngineCore_DP0 pid=534278) 	min.f32 	%r114, %r113, 0f42FE0000;
(EngineCore_DP0 pid=534278) 	max.f32 	%r115, %r112, 0fC3000000;
(EngineCore_DP0 pid=534278) 	min.f32 	%r116, %r115, 0f42FE0000;
(EngineCore_DP0 pid=534278) 	.loc	1 300 86                        // quant_slide_tuned_Qwen2.5-14B.py:300:86
(EngineCore_DP0 pid=534278) 	cvt.rzi.s32.f32 	%r117, %r114;
(EngineCore_DP0 pid=534278) 	cvt.rzi.s32.f32 	%r118, %r116;
(EngineCore_DP0 pid=534278) 	.loc	1 300 98                        // quant_slide_tuned_Qwen2.5-14B.py:300:98
(EngineCore_DP0 pid=534278) 	and.b32 	%r119, %r117, 255;
(EngineCore_DP0 pid=534278) 	and.b32 	%r120, %r118, 255;
(EngineCore_DP0 pid=534278) 	.loc	1 301 56                        // quant_slide_tuned_Qwen2.5-14B.py:301:56
(EngineCore_DP0 pid=534278) 	mul.f32 	%r121, %r14, %r99;
(EngineCore_DP0 pid=534278) 	mul.f32 	%r122, %r14, %r100;
(EngineCore_DP0 pid=534278) 	.loc	1 301 51                        // quant_slide_tuned_Qwen2.5-14B.py:301:51
(EngineCore_DP0 pid=534278) 	cvt.rni.f32.f32 	%r123, %r121;
(EngineCore_DP0 pid=534278) 	cvt.rni.f32.f32 	%r124, %r122;
(EngineCore_DP0 pid=534278) 	.loc	1 302 56                        // quant_slide_tuned_Qwen2.5-14B.py:302:56
(EngineCore_DP0 pid=534278) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=534278) 	mul.f32 	%r126, %r14, %r104;
(EngineCore_DP0 pid=534278) 	.loc	1 302 51                        // quant_slide_tuned_Qwen2.5-14B.py:302:51
(EngineCore_DP0 pid=534278) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=534278) 	cvt.rni.f32.f32 	%r128, %r126;
(EngineCore_DP0 pid=534278) 	.loc	1 303 56                        // quant_slide_tuned_Qwen2.5-14B.py:303:56
(EngineCore_DP0 pid=534278) 	mul.f32 	%r129, %r14, %r107;
(EngineCore_DP0 pid=534278) 	mul.f32 	%r130, %r14, %r108;
(EngineCore_DP0 pid=534278) 	.loc	1 303 51                        // quant_slide_tuned_Qwen2.5-14B.py:303:51
(EngineCore_DP0 pid=534278) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=534278) 	cvt.rni.f32.f32 	%r132, %r130;
(EngineCore_DP0 pid=534278) 	.loc	1 303 76                        // quant_slide_tuned_Qwen2.5-14B.py:303:76
(EngineCore_DP0 pid=534278) 	max.f32 	%r133, %r131, 0fC3000000;
(EngineCore_DP0 pid=534278) 	min.f32 	%r134, %r133, 0f42FE0000;
(EngineCore_DP0 pid=534278) 	max.f32 	%r135, %r132, 0fC3000000;
(EngineCore_DP0 pid=534278) 	min.f32 	%r136, %r135, 0f42FE0000;
(EngineCore_DP0 pid=534278) 	.loc	1 303 86                        // quant_slide_tuned_Qwen2.5-14B.py:303:86
(EngineCore_DP0 pid=534278) 	cvt.rzi.s32.f32 	%r137, %r134;
(EngineCore_DP0 pid=534278) 	cvt.rzi.s32.f32 	%r138, %r136;
(EngineCore_DP0 pid=534278) 	.loc	1 301 76                        // quant_slide_tuned_Qwen2.5-14B.py:301:76
(EngineCore_DP0 pid=534278) 	max.f32 	%r139, %r127, 0fC3000000;
(EngineCore_DP0 pid=534278) 	max.f32 	%r140, %r123, 0fC3000000;
(EngineCore_DP0 pid=534278) 	min.f32 	%r141, %r140, 0f42FE0000;
(EngineCore_DP0 pid=534278) 	min.f32 	%r142, %r139, 0f42FE0000;
(EngineCore_DP0 pid=534278) 	.loc	1 301 86                        // quant_slide_tuned_Qwen2.5-14B.py:301:86
(EngineCore_DP0 pid=534278) 	cvt.rzi.s32.f32 	%r143, %r142;
(EngineCore_DP0 pid=534278) 	cvt.rzi.s32.f32 	%r144, %r141;
(EngineCore_DP0 pid=534278) 	.loc	1 305 30                        // quant_slide_tuned_Qwen2.5-14B.py:305:30
(EngineCore_DP0 pid=534278) 	shl.b32 	%r145, %r144, 8;
(EngineCore_DP0 pid=534278) 	shl.b32 	%r146, %r143, 16;
(EngineCore_DP0 pid=534278) 	and.b32 	%r147, %r146, 16711680;
(EngineCore_DP0 pid=534278) 	and.b32 	%r148, %r145, 65280;
(EngineCore_DP0 pid=534278) 	.loc	1 305 24                        // quant_slide_tuned_Qwen2.5-14B.py:305:24
(EngineCore_DP0 pid=534278) 	or.b32 	%r149, %r148, %r119;
(EngineCore_DP0 pid=534278) 	.loc	1 301 76                        // quant_slide_tuned_Qwen2.5-14B.py:301:76
(EngineCore_DP0 pid=534278) 	max.f32 	%r150, %r128, 0fC3000000;
(EngineCore_DP0 pid=534278) 	max.f32 	%r151, %r124, 0fC3000000;
(EngineCore_DP0 pid=534278) 	min.f32 	%r152, %r151, 0f42FE0000;
(EngineCore_DP0 pid=534278) 	min.f32 	%r153, %r150, 0f42FE0000;
(EngineCore_DP0 pid=534278) 	.loc	1 301 86                        // quant_slide_tuned_Qwen2.5-14B.py:301:86
(EngineCore_DP0 pid=534278) 	cvt.rzi.s32.f32 	%r154, %r153;
(EngineCore_DP0 pid=534278) 	cvt.rzi.s32.f32 	%r155, %r152;
(EngineCore_DP0 pid=534278) 	.loc	1 305 30                        // quant_slide_tuned_Qwen2.5-14B.py:305:30
(EngineCore_DP0 pid=534278) 	shl.b32 	%r156, %r155, 8;
(EngineCore_DP0 pid=534278) 	shl.b32 	%r157, %r154, 16;
(EngineCore_DP0 pid=534278) 	and.b32 	%r158, %r157, 16711680;
(EngineCore_DP0 pid=534278) 	and.b32 	%r159, %r156, 65280;
(EngineCore_DP0 pid=534278) 	.loc	1 305 24                        // quant_slide_tuned_Qwen2.5-14B.py:305:24
(EngineCore_DP0 pid=534278) 	or.b32 	%r160, %r159, %r120;
(EngineCore_DP0 pid=534278) 	.loc	1 305 36                        // quant_slide_tuned_Qwen2.5-14B.py:305:36
(EngineCore_DP0 pid=534278) 	or.b32 	%r161, %r149, %r147;
(EngineCore_DP0 pid=534278) 	or.b32 	%r162, %r160, %r158;
(EngineCore_DP0 pid=534278) 	.loc	1 305 55                        // quant_slide_tuned_Qwen2.5-14B.py:305:55
(EngineCore_DP0 pid=534278) 	shl.b32 	%r163, %r137, 24;
(EngineCore_DP0 pid=534278) 	shl.b32 	%r164, %r138, 24;
(EngineCore_DP0 pid=534278) 	.loc	1 305 49                        // quant_slide_tuned_Qwen2.5-14B.py:305:49
(EngineCore_DP0 pid=534278) 	or.b32 	%r83, %r161, %r163;
(EngineCore_DP0 pid=534278) 	or.b32 	%r84, %r162, %r164;
(EngineCore_DP0 pid=534278) 	.loc	1 306 29                        // quant_slide_tuned_Qwen2.5-14B.py:306:29
(EngineCore_DP0 pid=534278) 	mad.wide.s32 	%rd17, %r85, 4, %rd2;
(EngineCore_DP0 pid=534278) 	.loc	1 306 39                        // quant_slide_tuned_Qwen2.5-14B.py:306:39
(EngineCore_DP0 pid=534278) 	// begin inline asm
(EngineCore_DP0 pid=534278) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r83, %r84 };
(EngineCore_DP0 pid=534278) 	// end inline asm
(EngineCore_DP0 pid=534278) 	.loc	1 282 41                        // quant_slide_tuned_Qwen2.5-14B.py:282:41
(EngineCore_DP0 pid=534278) 	add.s32 	%r168, %r168, 1024;
(EngineCore_DP0 pid=534278) 	setp.lt.s32 	%p27, %r168, %r15;
(EngineCore_DP0 pid=534278) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=534278) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=534278) 	.loc	1 282 4                         // quant_slide_tuned_Qwen2.5-14B.py:282:4
(EngineCore_DP0 pid=534278) 	ret;
(EngineCore_DP0 pid=534278) $L__tmp3:
(EngineCore_DP0 pid=534278) $L__func_end0:
(EngineCore_DP0 pid=534278)                                         // -- End function
(EngineCore_DP0 pid=534278) }
(EngineCore_DP0 pid=534278) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-14B.py"
(EngineCore_DP0 pid=534278) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=534278) 	.section	.debug_abbrev
(EngineCore_DP0 pid=534278) 	{
(EngineCore_DP0 pid=534278) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=534278) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=534278) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=534278) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=534278) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=534278) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=534278) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=534278) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=534278) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=534278) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=534278) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=534278) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=534278) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=534278) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=534278) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=534278) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=534278) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=534278) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=534278) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=534278) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=534278) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=534278) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=534278) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=534278) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=534278) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=534278) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=534278) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=534278) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=534278) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=534278) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=534278) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=534278) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=534278) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=534278) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=534278) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=534278) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=534278) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=534278) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=534278) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=534278) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=534278) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=534278) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=534278) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=534278) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=534278) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=534278) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=534278) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=534278) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=534278) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=534278) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=534278) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=534278) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=534278) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=534278) 	}
(EngineCore_DP0 pid=534278) 	.section	.debug_info
(EngineCore_DP0 pid=534278) 	{
(EngineCore_DP0 pid=534278) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=534278) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=534278) .b8 0
(EngineCore_DP0 pid=534278) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=534278) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=534278) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=534278) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=534278) .b8 114
(EngineCore_DP0 pid=534278) .b8 105
(EngineCore_DP0 pid=534278) .b8 116
(EngineCore_DP0 pid=534278) .b8 111
(EngineCore_DP0 pid=534278) .b8 110
(EngineCore_DP0 pid=534278) .b8 0
(EngineCore_DP0 pid=534278) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=534278) .b8 0
(EngineCore_DP0 pid=534278) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=534278) .b8 117
(EngineCore_DP0 pid=534278) .b8 97
(EngineCore_DP0 pid=534278) .b8 110
(EngineCore_DP0 pid=534278) .b8 116
(EngineCore_DP0 pid=534278) .b8 95
(EngineCore_DP0 pid=534278) .b8 115
(EngineCore_DP0 pid=534278) .b8 108
(EngineCore_DP0 pid=534278) .b8 105
(EngineCore_DP0 pid=534278) .b8 100
(EngineCore_DP0 pid=534278) .b8 101
(EngineCore_DP0 pid=534278) .b8 95
(EngineCore_DP0 pid=534278) .b8 116
(EngineCore_DP0 pid=534278) .b8 117
(EngineCore_DP0 pid=534278) .b8 110
(EngineCore_DP0 pid=534278) .b8 101
(EngineCore_DP0 pid=534278) .b8 100
(EngineCore_DP0 pid=534278) .b8 95
(EngineCore_DP0 pid=534278) .b8 81
(EngineCore_DP0 pid=534278) .b8 119
(EngineCore_DP0 pid=534278) .b8 101
(EngineCore_DP0 pid=534278) .b8 110
(EngineCore_DP0 pid=534278) .b8 50
(EngineCore_DP0 pid=534278) .b8 46
(EngineCore_DP0 pid=534278) .b8 53
(EngineCore_DP0 pid=534278) .b8 45
(EngineCore_DP0 pid=534278) .b8 49
(EngineCore_DP0 pid=534278) .b8 52
(EngineCore_DP0 pid=534278) .b8 66
(EngineCore_DP0 pid=534278) .b8 46
(EngineCore_DP0 pid=534278) .b8 112
(EngineCore_DP0 pid=534278) .b8 121
(EngineCore_DP0 pid=534278) .b8 0
(EngineCore_DP0 pid=534278) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=534278) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=534278) .b8 114
(EngineCore_DP0 pid=534278) .b8 111
(EngineCore_DP0 pid=534278) .b8 111
(EngineCore_DP0 pid=534278) .b8 116
(EngineCore_DP0 pid=534278) .b8 47
(EngineCore_DP0 pid=534278) .b8 118
(EngineCore_DP0 pid=534278) .b8 108
(EngineCore_DP0 pid=534278) .b8 108
(EngineCore_DP0 pid=534278) .b8 109
(EngineCore_DP0 pid=534278) .b8 98
(EngineCore_DP0 pid=534278) .b8 101
(EngineCore_DP0 pid=534278) .b8 110
(EngineCore_DP0 pid=534278) .b8 99
(EngineCore_DP0 pid=534278) .b8 104
(EngineCore_DP0 pid=534278) .b8 47
(EngineCore_DP0 pid=534278) .b8 115
(EngineCore_DP0 pid=534278) .b8 108
(EngineCore_DP0 pid=534278) .b8 105
(EngineCore_DP0 pid=534278) .b8 100
(EngineCore_DP0 pid=534278) .b8 101
(EngineCore_DP0 pid=534278) .b8 115
(EngineCore_DP0 pid=534278) .b8 112
(EngineCore_DP0 pid=534278) .b8 97
(EngineCore_DP0 pid=534278) .b8 114
(EngineCore_DP0 pid=534278) .b8 115
(EngineCore_DP0 pid=534278) .b8 101
(EngineCore_DP0 pid=534278) .b8 47
(EngineCore_DP0 pid=534278) .b8 99
(EngineCore_DP0 pid=534278) .b8 115
(EngineCore_DP0 pid=534278) .b8 114
(EngineCore_DP0 pid=534278) .b8 99
(EngineCore_DP0 pid=534278) .b8 47
(EngineCore_DP0 pid=534278) .b8 102
(EngineCore_DP0 pid=534278) .b8 117
(EngineCore_DP0 pid=534278) .b8 115
(EngineCore_DP0 pid=534278) .b8 101
(EngineCore_DP0 pid=534278) .b8 100
(EngineCore_DP0 pid=534278) .b8 95
(EngineCore_DP0 pid=534278) .b8 113
(EngineCore_DP0 pid=534278) .b8 117
(EngineCore_DP0 pid=534278) .b8 97
(EngineCore_DP0 pid=534278) .b8 110
(EngineCore_DP0 pid=534278) .b8 116
(EngineCore_DP0 pid=534278) .b8 95
(EngineCore_DP0 pid=534278) .b8 115
(EngineCore_DP0 pid=534278) .b8 108
(EngineCore_DP0 pid=534278) .b8 105
(EngineCore_DP0 pid=534278) .b8 100
(EngineCore_DP0 pid=534278) .b8 101
(EngineCore_DP0 pid=534278) .b8 95
(EngineCore_DP0 pid=534278) .b8 116
(EngineCore_DP0 pid=534278) .b8 114
(EngineCore_DP0 pid=534278) .b8 105
(EngineCore_DP0 pid=534278) .b8 116
(EngineCore_DP0 pid=534278) .b8 111
(EngineCore_DP0 pid=534278) .b8 110
(EngineCore_DP0 pid=534278) .b8 47
(EngineCore_DP0 pid=534278) .b8 98
(EngineCore_DP0 pid=534278) .b8 117
(EngineCore_DP0 pid=534278) .b8 105
(EngineCore_DP0 pid=534278) .b8 108
(EngineCore_DP0 pid=534278) .b8 100
(EngineCore_DP0 pid=534278) .b8 47
(EngineCore_DP0 pid=534278) .b8 71
(EngineCore_DP0 pid=534278) .b8 66
(EngineCore_DP0 pid=534278) .b8 49
(EngineCore_DP0 pid=534278) .b8 48
(EngineCore_DP0 pid=534278) .b8 95
(EngineCore_DP0 pid=534278) .b8 99
(EngineCore_DP0 pid=534278) .b8 99
(EngineCore_DP0 pid=534278) .b8 49
(EngineCore_DP0 pid=534278) .b8 50
(EngineCore_DP0 pid=534278) .b8 49
(EngineCore_DP0 pid=534278) .b8 95
(EngineCore_DP0 pid=534278) .b8 112
(EngineCore_DP0 pid=534278) .b8 121
(EngineCore_DP0 pid=534278) .b8 51
(EngineCore_DP0 pid=534278) .b8 49
(EngineCore_DP0 pid=534278) .b8 50
(EngineCore_DP0 pid=534278) .b8 95
(EngineCore_DP0 pid=534278) .b8 99
(EngineCore_DP0 pid=534278) .b8 117
(EngineCore_DP0 pid=534278) .b8 49
(EngineCore_DP0 pid=534278) .b8 50
(EngineCore_DP0 pid=534278) .b8 57
(EngineCore_DP0 pid=534278) .b8 95
(EngineCore_DP0 pid=534278) .b8 97
(EngineCore_DP0 pid=534278) .b8 97
(EngineCore_DP0 pid=534278) .b8 114
(EngineCore_DP0 pid=534278) .b8 99
(EngineCore_DP0 pid=534278) .b8 104
(EngineCore_DP0 pid=534278) .b8 54
(EngineCore_DP0 pid=534278) .b8 52
(EngineCore_DP0 pid=534278) .b8 0
(EngineCore_DP0 pid=534278) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=534278) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=534278) .b8 113
(EngineCore_DP0 pid=534278) .b8 117
(EngineCore_DP0 pid=534278) .b8 97
(EngineCore_DP0 pid=534278) .b8 110
(EngineCore_DP0 pid=534278) .b8 116
(EngineCore_DP0 pid=534278) .b8 95
(EngineCore_DP0 pid=534278) .b8 115
(EngineCore_DP0 pid=534278) .b8 108
(EngineCore_DP0 pid=534278) .b8 105
(EngineCore_DP0 pid=534278) .b8 100
(EngineCore_DP0 pid=534278) .b8 101
(EngineCore_DP0 pid=534278) .b8 95
(EngineCore_DP0 pid=534278) .b8 105
(EngineCore_DP0 pid=534278) .b8 110
(EngineCore_DP0 pid=534278) .b8 116
(EngineCore_DP0 pid=534278) .b8 56
(EngineCore_DP0 pid=534278) .b8 95
(EngineCore_DP0 pid=534278) .b8 107
(EngineCore_DP0 pid=534278) .b8 101
(EngineCore_DP0 pid=534278) .b8 114
(EngineCore_DP0 pid=534278) .b8 110
(EngineCore_DP0 pid=534278) .b8 101
(EngineCore_DP0 pid=534278) .b8 108
(EngineCore_DP0 pid=534278) .b8 0
(EngineCore_DP0 pid=534278) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=534278) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=534278) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=534278) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=534278) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=534278) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=534278) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=534278) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=534278) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=534278) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=534278) .b8 16                                  // DW_AT_call_line
(EngineCore_DP0 pid=534278) .b8 1
(EngineCore_DP0 pid=534278) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=534278) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=534278) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=534278) 	}
(EngineCore_DP0 pid=534278) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=534278) 
(EngineCore_DP0 pid=534278) ================================================================
(EngineCore_DP0 pid=534278) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=534278) 
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmppbwt7a4_.ptx', '-o', '/tmp/tmppbwt7a4_.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866] 
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866] 
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-14B.py", line 335, in quant_slide_int8_triton
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866] 
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmppbwt7a4_.ptx -o /tmp/tmppbwt7a4_.ptx.o
(EngineCore_DP0 pid=534278) ERROR 01-25 22:28:55 [core.py:866] 

STDERR:
[2026-01-25 22:26:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 22:26:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-25 22:26:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-25 22:26:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:26:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:26:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:26:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:26:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:26:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-25 22:26:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:26:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:26:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:26:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:26:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:27:02] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 22:27:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-25 22:27:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-25 22:27:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:27:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:27:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:27:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:27:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:27:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-25 22:27:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:27:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:27:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:27:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:27:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=534278) [2026-01-25 22:27:03] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=534278) [2026-01-25 22:27:03] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=534278) [2026-01-25 22:27:03] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=534278) [2026-01-25 22:27:03] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=534278) [2026-01-25 22:27:03] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=534278) [2026-01-25 22:27:03] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=534278) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=534278) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:24,  8.03s/it]
(EngineCore_DP0 pid=534278) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:41<00:46, 23.26s/it]
(EngineCore_DP0 pid=534278) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:13<00:26, 26.87s/it]
(EngineCore_DP0 pid=534278) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:46<00:00, 29.40s/it]
(EngineCore_DP0 pid=534278) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:46<00:00, 26.60s/it]
(EngineCore_DP0 pid=534278) 
(EngineCore_DP0 pid=534278) [2026-01-25 22:28:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=534278) [2026-01-25 22:28:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36929536 bytes
(EngineCore_DP0 pid=534278) [2026-01-25 22:28:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=534278) [2026-01-25 22:28:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26378240 bytes
(EngineCore_DP0 pid=534278) [2026-01-25 22:28:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=534278) [2026-01-25 22:28:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 142442496 bytes
(EngineCore_DP0 pid=534278) [2026-01-25 22:28:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=534278) [2026-01-25 22:28:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70778880 bytes
(EngineCore_DP0 pid=534278) Process EngineCore_DP0:
(EngineCore_DP0 pid=534278) Traceback (most recent call last):
(EngineCore_DP0 pid=534278)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=534278)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=534278)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=534278)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=534278) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmppbwt7a4_.ptx', '-o', '/tmp/tmppbwt7a4_.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=534278) 
(EngineCore_DP0 pid=534278) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=534278) 
(EngineCore_DP0 pid=534278) Traceback (most recent call last):
(EngineCore_DP0 pid=534278)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=534278)     self.run()
(EngineCore_DP0 pid=534278)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=534278)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=534278)     raise e
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=534278)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=534278)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=534278)     super().__init__(
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=534278)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=534278)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=534278)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=534278)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=534278)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=534278)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=534278)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=534278)     return func(*args, **kwargs)
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=534278)     return func(*args, **kwargs)
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=534278)     self.model_runner.profile_run()
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=534278)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=534278)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=534278)     return func(*args, **kwargs)
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=534278)     outputs = self.model(
(EngineCore_DP0 pid=534278)               ^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=534278)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=534278)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=534278)     hidden_states = self.model(
(EngineCore_DP0 pid=534278)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=534278)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=534278)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=534278)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=534278)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=534278)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=534278)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=534278)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=534278)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=534278)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=534278)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=534278)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=534278)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=534278)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=534278)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=534278)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=534278)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=534278)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=534278)     return self._linear_fn(
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=534278)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=534278)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=534278)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=534278)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=534278)     return fn(input, L)
(EngineCore_DP0 pid=534278)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-14B.py", line 335, in quant_slide_int8_triton
(EngineCore_DP0 pid=534278)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=534278)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=534278)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=534278)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=534278)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=534278)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=534278)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=534278)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=534278)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=534278)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=534278)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=534278)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=534278)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=534278)     raise PTXASError(error)
(EngineCore_DP0 pid=534278) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=534278) `ptxas` stderr:
(EngineCore_DP0 pid=534278) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=534278) 
(EngineCore_DP0 pid=534278) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmppbwt7a4_.ptx -o /tmp/tmppbwt7a4_.ptx.o
(EngineCore_DP0 pid=534278) 
[rank0]:[W125 22:28:55.829958642 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 22:28:57
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:29:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 22:29:02 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=536393) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=536393) 
(EngineCore_DP0 pid=536393) 
(EngineCore_DP0 pid=536393) ================================================================
(EngineCore_DP0 pid=536393) Internal Triton PTX codegen error
(EngineCore_DP0 pid=536393) `ptxas` stderr:
(EngineCore_DP0 pid=536393) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=536393) 
(EngineCore_DP0 pid=536393) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmplsmeo3__.ptx -o /tmp/tmplsmeo3__.ptx.o
(EngineCore_DP0 pid=536393) 
(EngineCore_DP0 pid=536393) 
(EngineCore_DP0 pid=536393) //
(EngineCore_DP0 pid=536393) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=536393) //
(EngineCore_DP0 pid=536393) 
(EngineCore_DP0 pid=536393) .version 8.7
(EngineCore_DP0 pid=536393) .target sm_121a
(EngineCore_DP0 pid=536393) .address_size 64
(EngineCore_DP0 pid=536393) 
(EngineCore_DP0 pid=536393) 	// .globl	_quant_slide_int8_kernel // -- Begin function _quant_slide_int8_kernel
(EngineCore_DP0 pid=536393) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=536393)                                         // @_quant_slide_int8_kernel
(EngineCore_DP0 pid=536393) .visible .entry _quant_slide_int8_kernel(
(EngineCore_DP0 pid=536393) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_0,
(EngineCore_DP0 pid=536393) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_1,
(EngineCore_DP0 pid=536393) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_2,
(EngineCore_DP0 pid=536393) 	.param .u32 _quant_slide_int8_kernel_param_3,
(EngineCore_DP0 pid=536393) 	.param .u32 _quant_slide_int8_kernel_param_4,
(EngineCore_DP0 pid=536393) 	.param .u32 _quant_slide_int8_kernel_param_5,
(EngineCore_DP0 pid=536393) 	.param .u32 _quant_slide_int8_kernel_param_6,
(EngineCore_DP0 pid=536393) 	.param .u32 _quant_slide_int8_kernel_param_7,
(EngineCore_DP0 pid=536393) 	.param .u32 _quant_slide_int8_kernel_param_8,
(EngineCore_DP0 pid=536393) 	.param .u32 _quant_slide_int8_kernel_param_9,
(EngineCore_DP0 pid=536393) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_10,
(EngineCore_DP0 pid=536393) 	.param .u64 .ptr .global .align 1 _quant_slide_int8_kernel_param_11
(EngineCore_DP0 pid=536393) )
(EngineCore_DP0 pid=536393) .reqntid 512
(EngineCore_DP0 pid=536393) {
(EngineCore_DP0 pid=536393) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=536393) 	.reg .b16 	%rs<64>;
(EngineCore_DP0 pid=536393) 	.reg .b32 	%r<169>;
(EngineCore_DP0 pid=536393) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=536393) 	.loc	1 248 0                         // quant_slide_tuned_Qwen2.5-14B.py:248:0
(EngineCore_DP0 pid=536393) $L__func_begin0:
(EngineCore_DP0 pid=536393) 	.loc	1 248 0                         // quant_slide_tuned_Qwen2.5-14B.py:248:0
(EngineCore_DP0 pid=536393) 
(EngineCore_DP0 pid=536393) // %bb.0:
(EngineCore_DP0 pid=536393) 	ld.param.b32 	%r21, [_quant_slide_int8_kernel_param_7];
(EngineCore_DP0 pid=536393) 	ld.param.b32 	%r20, [_quant_slide_int8_kernel_param_5];
(EngineCore_DP0 pid=536393) 	ld.param.b32 	%r19, [_quant_slide_int8_kernel_param_4];
(EngineCore_DP0 pid=536393) 	ld.param.b64 	%rd3, [_quant_slide_int8_kernel_param_2];
(EngineCore_DP0 pid=536393) 	ld.param.b64 	%rd4, [_quant_slide_int8_kernel_param_0];
(EngineCore_DP0 pid=536393) $L__tmp0:
(EngineCore_DP0 pid=536393) 	.loc	1 258 24                        // quant_slide_tuned_Qwen2.5-14B.py:258:24
(EngineCore_DP0 pid=536393) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=536393) 	ld.param.b32 	%r23, [_quant_slide_int8_kernel_param_8];
(EngineCore_DP0 pid=536393) 	.loc	1 263 26                        // quant_slide_tuned_Qwen2.5-14B.py:263:26
(EngineCore_DP0 pid=536393) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=536393) 	.loc	1 263 20                        // quant_slide_tuned_Qwen2.5-14B.py:263:20
(EngineCore_DP0 pid=536393) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=536393) 	.loc	1 269 32                        // quant_slide_tuned_Qwen2.5-14B.py:269:32
(EngineCore_DP0 pid=536393) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=536393) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=536393) 	.loc	1 268 35                        // quant_slide_tuned_Qwen2.5-14B.py:268:35
(EngineCore_DP0 pid=536393) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=536393) 	mov.b32 	%r167, 0f2B8CBCCC;
(EngineCore_DP0 pid=536393) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=536393) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=536393) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=536393) 	.loc	1 269 32                        // quant_slide_tuned_Qwen2.5-14B.py:269:32
(EngineCore_DP0 pid=536393) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=536393) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=536393) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=536393) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=536393) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=536393) 	add.s32 	%r53, %r35, %r34;
(EngineCore_DP0 pid=536393) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=536393) 	add.s32 	%r56, %r35, %r36;
(EngineCore_DP0 pid=536393) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=536393) 	mov.b32 	%r165, 0f00000000;
(EngineCore_DP0 pid=536393) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=536393) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=536393) 	mov.b32 	%r166, %r41;
(EngineCore_DP0 pid=536393) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=536393) 	.loc	1 269 19                        // quant_slide_tuned_Qwen2.5-14B.py:269:19
(EngineCore_DP0 pid=536393) 	add.s32 	%r59, %r4, %r166;
(EngineCore_DP0 pid=536393) 	.loc	1 270 22                        // quant_slide_tuned_Qwen2.5-14B.py:270:22
(EngineCore_DP0 pid=536393) 	add.s32 	%r60, %r59, 4096;
(EngineCore_DP0 pid=536393) 	setp.lt.s32 	%p2, %r59, %r19;
(EngineCore_DP0 pid=536393) 	setp.lt.s32 	%p3, %r60, %r19;
(EngineCore_DP0 pid=536393) 	.loc	1 271 29                        // quant_slide_tuned_Qwen2.5-14B.py:271:29
(EngineCore_DP0 pid=536393) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=536393) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=536393) 	.loc	1 271 21                        // quant_slide_tuned_Qwen2.5-14B.py:271:21
(EngineCore_DP0 pid=536393) 	// begin inline asm
(EngineCore_DP0 pid=536393) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=536393) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=536393) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=536393) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=536393) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=536393) 	// end inline asm
(EngineCore_DP0 pid=536393) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=536393) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=536393) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=536393) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=536393) 	// begin inline asm
(EngineCore_DP0 pid=536393) 	mov.u32 %r45, %r41;
(EngineCore_DP0 pid=536393) 	mov.u32 %r46, %r41;
(EngineCore_DP0 pid=536393) 	mov.u32 %r47, %r41;
(EngineCore_DP0 pid=536393) 	mov.u32 %r48, %r41;
(EngineCore_DP0 pid=536393) 	@%p3 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=536393) 	// end inline asm
(EngineCore_DP0 pid=536393) 	mov.b32 	{%rs9, %rs10}, %r45;
(EngineCore_DP0 pid=536393) 	mov.b32 	{%rs11, %rs12}, %r46;
(EngineCore_DP0 pid=536393) 	mov.b32 	{%rs13, %rs14}, %r47;
(EngineCore_DP0 pid=536393) 	mov.b32 	{%rs15, %rs16}, %r48;
(EngineCore_DP0 pid=536393) 	.loc	1 272 50                        // quant_slide_tuned_Qwen2.5-14B.py:272:50
(EngineCore_DP0 pid=536393) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=536393) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=536393) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=536393) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=536393) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=536393) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=536393) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=536393) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=536393) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=536393) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=536393) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=536393) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=536393) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=536393) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=536393) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=536393) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=536393) $L__tmp1:
(EngineCore_DP0 pid=536393) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	bar.sync 	0;
(EngineCore_DP0 pid=536393) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=536393) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=536393) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=536393) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=536393) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=536393) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=536393) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=536393) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=536393) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=536393) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=536393) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=536393) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=536393) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=536393) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=536393) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=536393) 	cvt.f32.bf16 	%r61, %rs47;
(EngineCore_DP0 pid=536393) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	shfl.sync.bfly.b32 	%r62, %r61, 16, 31, -1;
(EngineCore_DP0 pid=536393) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=536393) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	shfl.sync.bfly.b32 	%r64, %r63, 8, 31, -1;
(EngineCore_DP0 pid=536393) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=536393) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=536393) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=536393) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=536393) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=536393) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=536393) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	max.f32 	%r54, %r69, %r70;
(EngineCore_DP0 pid=536393) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	// begin inline asm
(EngineCore_DP0 pid=536393) 	@%p4 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=536393) 	// end inline asm
(EngineCore_DP0 pid=536393) 	bar.sync 	0;
(EngineCore_DP0 pid=536393) 	// begin inline asm
(EngineCore_DP0 pid=536393) 	@%p5 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=536393) 	// end inline asm
(EngineCore_DP0 pid=536393) 	shfl.sync.bfly.b32 	%r71, %r55, 8, 31, -1;
(EngineCore_DP0 pid=536393) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	max.f32 	%r72, %r55, %r71;
(EngineCore_DP0 pid=536393) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	shfl.sync.bfly.b32 	%r73, %r72, 4, 31, -1;
(EngineCore_DP0 pid=536393) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	max.f32 	%r74, %r72, %r73;
(EngineCore_DP0 pid=536393) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	shfl.sync.bfly.b32 	%r75, %r74, 2, 31, -1;
(EngineCore_DP0 pid=536393) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	max.f32 	%r76, %r74, %r75;
(EngineCore_DP0 pid=536393) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	shfl.sync.bfly.b32 	%r77, %r76, 1, 31, -1;
(EngineCore_DP0 pid=536393) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	max.f32 	%r58, %r76, %r77;
(EngineCore_DP0 pid=536393) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-14B.py:272:43 ]
(EngineCore_DP0 pid=536393) 	// begin inline asm
(EngineCore_DP0 pid=536393) 	@%p28 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=536393) 	// end inline asm
(EngineCore_DP0 pid=536393) 	bar.sync 	0;
(EngineCore_DP0 pid=536393) 	ld.shared.b32 	%r78, [global_smem];
(EngineCore_DP0 pid=536393) $L__tmp2:
(EngineCore_DP0 pid=536393) 	.loc	1 272 36                        // quant_slide_tuned_Qwen2.5-14B.py:272:36
(EngineCore_DP0 pid=536393) 	max.f32 	%r165, %r165, %r78;
(EngineCore_DP0 pid=536393) 	.loc	1 268 35                        // quant_slide_tuned_Qwen2.5-14B.py:268:35
(EngineCore_DP0 pid=536393) 	add.s32 	%r166, %r166, 8192;
(EngineCore_DP0 pid=536393) 	setp.lt.s32 	%p7, %r166, %r20;
(EngineCore_DP0 pid=536393) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=536393) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=536393) 	.loc	1 274 32                        // quant_slide_tuned_Qwen2.5-14B.py:274:32
(EngineCore_DP0 pid=536393) 	max.f32 	%r167, %r165, 0f2B8CBCCC;
(EngineCore_DP0 pid=536393) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=536393) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-14B.py:0:32
(EngineCore_DP0 pid=536393) 	mov.b32 	%r80, 0f42FE0000;
(EngineCore_DP0 pid=536393) 	.loc	1 275 32                        // quant_slide_tuned_Qwen2.5-14B.py:275:32
(EngineCore_DP0 pid=536393) 	div.full.f32 	%r81, %r167, %r80;
(EngineCore_DP0 pid=536393) 	.loc	1 275 42                        // quant_slide_tuned_Qwen2.5-14B.py:275:42
(EngineCore_DP0 pid=536393) 	max.f32 	%r79, %r81, 0f37810204;
(EngineCore_DP0 pid=536393) 	.loc	1 277 25                        // quant_slide_tuned_Qwen2.5-14B.py:277:25
(EngineCore_DP0 pid=536393) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=536393) 	.loc	1 277 30                        // quant_slide_tuned_Qwen2.5-14B.py:277:30
(EngineCore_DP0 pid=536393) 	// begin inline asm
(EngineCore_DP0 pid=536393) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r79 };
(EngineCore_DP0 pid=536393) 	// end inline asm
(EngineCore_DP0 pid=536393) 	.loc	1 280 29                        // quant_slide_tuned_Qwen2.5-14B.py:280:29
(EngineCore_DP0 pid=536393) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=536393) 	.loc	1 282 41                        // quant_slide_tuned_Qwen2.5-14B.py:282:41
(EngineCore_DP0 pid=536393) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=536393) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=536393) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=536393) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-14B.py:0:41
(EngineCore_DP0 pid=536393) 	ld.param.b32 	%r25, [_quant_slide_int8_kernel_param_9];
(EngineCore_DP0 pid=536393) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=536393) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=536393) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=536393) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=536393) 	ld.param.b64 	%rd5, [_quant_slide_int8_kernel_param_1];
(EngineCore_DP0 pid=536393) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=536393) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=536393) 	div.full.f32 	%r14, %r80, %r167;
(EngineCore_DP0 pid=536393) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=536393) 	mov.b32 	%r168, 0;
(EngineCore_DP0 pid=536393) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=536393)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=536393) 	.loc	1 283 31                        // quant_slide_tuned_Qwen2.5-14B.py:283:31
(EngineCore_DP0 pid=536393) 	add.s32 	%r85, %r16, %r168;
(EngineCore_DP0 pid=536393) 	.loc	1 284 30                        // quant_slide_tuned_Qwen2.5-14B.py:284:30
(EngineCore_DP0 pid=536393) 	add.s32 	%r86, %r168, 1;
(EngineCore_DP0 pid=536393) 	setp.lt.s32 	%p18, %r85, %r15;
(EngineCore_DP0 pid=536393) 	.loc	1 287 24                        // quant_slide_tuned_Qwen2.5-14B.py:287:24
(EngineCore_DP0 pid=536393) 	shr.u32 	%r87, %r85, 1;
(EngineCore_DP0 pid=536393) 	.loc	1 288 23                        // quant_slide_tuned_Qwen2.5-14B.py:288:23
(EngineCore_DP0 pid=536393) 	shr.u32 	%r88, %r86, 31;
(EngineCore_DP0 pid=536393) 	add.s32 	%r89, %r86, %r88;
(EngineCore_DP0 pid=536393) 	and.b32 	%r90, %r89, 2147483646;
(EngineCore_DP0 pid=536393) 	sub.s32 	%r91, %r86, %r90;
(EngineCore_DP0 pid=536393) 	.loc	1 289 22                        // quant_slide_tuned_Qwen2.5-14B.py:289:22
(EngineCore_DP0 pid=536393) 	mul.lo.s32 	%r92, %r87, 6;
(EngineCore_DP0 pid=536393) 	.loc	1 289 30                        // quant_slide_tuned_Qwen2.5-14B.py:289:30
(EngineCore_DP0 pid=536393) 	shl.b32 	%r93, %r91, 1;
(EngineCore_DP0 pid=536393) 	.loc	1 289 26                        // quant_slide_tuned_Qwen2.5-14B.py:289:26
(EngineCore_DP0 pid=536393) 	add.s32 	%r94, %r92, %r93;
(EngineCore_DP0 pid=536393) 	.loc	1 292 53                        // quant_slide_tuned_Qwen2.5-14B.py:292:53
(EngineCore_DP0 pid=536393) 	setp.lt.s32 	%p19, %r92, %r19;
(EngineCore_DP0 pid=536393) 	setp.lt.s32 	%p20, %r94, %r19;
(EngineCore_DP0 pid=536393) 	.loc	1 292 37                        // quant_slide_tuned_Qwen2.5-14B.py:292:37
(EngineCore_DP0 pid=536393) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=536393) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=536393) 	.loc	1 291 29                        // quant_slide_tuned_Qwen2.5-14B.py:291:29
(EngineCore_DP0 pid=536393) 	mad.wide.s32 	%rd9, %r92, 2, %rd1;
(EngineCore_DP0 pid=536393) 	mad.wide.s32 	%rd10, %r94, 2, %rd1;
(EngineCore_DP0 pid=536393) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=536393) 	.loc	1 291 21                        // quant_slide_tuned_Qwen2.5-14B.py:291:21
(EngineCore_DP0 pid=536393) 	// begin inline asm
(EngineCore_DP0 pid=536393) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=536393) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=536393) 	// end inline asm
(EngineCore_DP0 pid=536393) 	// begin inline asm
(EngineCore_DP0 pid=536393) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=536393) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=536393) 	// end inline asm
(EngineCore_DP0 pid=536393) 	.loc	1 292 79                        // quant_slide_tuned_Qwen2.5-14B.py:292:79
(EngineCore_DP0 pid=536393) 	cvt.f32.bf16 	%r95, %rs48;
(EngineCore_DP0 pid=536393) 	cvt.f32.bf16 	%r96, %rs50;
(EngineCore_DP0 pid=536393) 	.loc	1 294 48                        // quant_slide_tuned_Qwen2.5-14B.py:294:48
(EngineCore_DP0 pid=536393) 	or.b32 	%r97, %r92, 1;
(EngineCore_DP0 pid=536393) 	or.b32 	%r98, %r94, 1;
(EngineCore_DP0 pid=536393) 	.loc	1 294 53                        // quant_slide_tuned_Qwen2.5-14B.py:294:53
(EngineCore_DP0 pid=536393) 	setp.lt.s32 	%p21, %r97, %r19;
(EngineCore_DP0 pid=536393) 	setp.lt.s32 	%p22, %r98, %r19;
(EngineCore_DP0 pid=536393) 	.loc	1 294 37                        // quant_slide_tuned_Qwen2.5-14B.py:294:37
(EngineCore_DP0 pid=536393) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=536393) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=536393) 	.loc	1 293 39                        // quant_slide_tuned_Qwen2.5-14B.py:293:39
(EngineCore_DP0 pid=536393) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=536393) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=536393) 	.loc	1 293 21                        // quant_slide_tuned_Qwen2.5-14B.py:293:21
(EngineCore_DP0 pid=536393) 	// begin inline asm
(EngineCore_DP0 pid=536393) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=536393) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=536393) 	// end inline asm
(EngineCore_DP0 pid=536393) 	// begin inline asm
(EngineCore_DP0 pid=536393) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=536393) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=536393) 	// end inline asm
(EngineCore_DP0 pid=536393) 	.loc	1 294 79                        // quant_slide_tuned_Qwen2.5-14B.py:294:79
(EngineCore_DP0 pid=536393) 	cvt.f32.bf16 	%r99, %rs52;
(EngineCore_DP0 pid=536393) 	cvt.f32.bf16 	%r100, %rs54;
(EngineCore_DP0 pid=536393) 	.loc	1 296 48                        // quant_slide_tuned_Qwen2.5-14B.py:296:48
(EngineCore_DP0 pid=536393) 	add.s32 	%r101, %r92, 2;
(EngineCore_DP0 pid=536393) 	add.s32 	%r102, %r94, 2;
(EngineCore_DP0 pid=536393) 	.loc	1 296 53                        // quant_slide_tuned_Qwen2.5-14B.py:296:53
(EngineCore_DP0 pid=536393) 	setp.lt.s32 	%p23, %r101, %r19;
(EngineCore_DP0 pid=536393) 	setp.lt.s32 	%p24, %r102, %r19;
(EngineCore_DP0 pid=536393) 	.loc	1 296 37                        // quant_slide_tuned_Qwen2.5-14B.py:296:37
(EngineCore_DP0 pid=536393) 	and.pred 	%p14, %p18, %p23;
(EngineCore_DP0 pid=536393) 	and.pred 	%p15, %p18, %p24;
(EngineCore_DP0 pid=536393) 	.loc	1 295 39                        // quant_slide_tuned_Qwen2.5-14B.py:295:39
(EngineCore_DP0 pid=536393) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=536393) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=536393) 	.loc	1 295 21                        // quant_slide_tuned_Qwen2.5-14B.py:295:21
(EngineCore_DP0 pid=536393) 	// begin inline asm
(EngineCore_DP0 pid=536393) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=536393) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=536393) 	// end inline asm
(EngineCore_DP0 pid=536393) 	// begin inline asm
(EngineCore_DP0 pid=536393) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=536393) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=536393) 	// end inline asm
(EngineCore_DP0 pid=536393) 	.loc	1 296 79                        // quant_slide_tuned_Qwen2.5-14B.py:296:79
(EngineCore_DP0 pid=536393) 	cvt.f32.bf16 	%r103, %rs56;
(EngineCore_DP0 pid=536393) 	cvt.f32.bf16 	%r104, %rs58;
(EngineCore_DP0 pid=536393) 	.loc	1 298 48                        // quant_slide_tuned_Qwen2.5-14B.py:298:48
(EngineCore_DP0 pid=536393) 	add.s32 	%r105, %r92, 3;
(EngineCore_DP0 pid=536393) 	add.s32 	%r106, %r94, 3;
(EngineCore_DP0 pid=536393) 	.loc	1 298 53                        // quant_slide_tuned_Qwen2.5-14B.py:298:53
(EngineCore_DP0 pid=536393) 	setp.lt.s32 	%p25, %r105, %r19;
(EngineCore_DP0 pid=536393) 	setp.lt.s32 	%p26, %r106, %r19;
(EngineCore_DP0 pid=536393) 	.loc	1 298 37                        // quant_slide_tuned_Qwen2.5-14B.py:298:37
(EngineCore_DP0 pid=536393) 	and.pred 	%p16, %p18, %p25;
(EngineCore_DP0 pid=536393) 	and.pred 	%p17, %p18, %p26;
(EngineCore_DP0 pid=536393) 	.loc	1 297 39                        // quant_slide_tuned_Qwen2.5-14B.py:297:39
(EngineCore_DP0 pid=536393) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=536393) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=536393) 	.loc	1 297 21                        // quant_slide_tuned_Qwen2.5-14B.py:297:21
(EngineCore_DP0 pid=536393) 	// begin inline asm
(EngineCore_DP0 pid=536393) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=536393) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=536393) 	// end inline asm
(EngineCore_DP0 pid=536393) 	// begin inline asm
(EngineCore_DP0 pid=536393) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=536393) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=536393) 	// end inline asm
(EngineCore_DP0 pid=536393) 	.loc	1 298 79                        // quant_slide_tuned_Qwen2.5-14B.py:298:79
(EngineCore_DP0 pid=536393) 	cvt.f32.bf16 	%r107, %rs60;
(EngineCore_DP0 pid=536393) 	cvt.f32.bf16 	%r108, %rs62;
(EngineCore_DP0 pid=536393) 	.loc	1 300 56                        // quant_slide_tuned_Qwen2.5-14B.py:300:56
(EngineCore_DP0 pid=536393) 	mul.f32 	%r109, %r14, %r95;
(EngineCore_DP0 pid=536393) 	mul.f32 	%r110, %r14, %r96;
(EngineCore_DP0 pid=536393) 	.loc	1 300 51                        // quant_slide_tuned_Qwen2.5-14B.py:300:51
(EngineCore_DP0 pid=536393) 	cvt.rni.f32.f32 	%r111, %r109;
(EngineCore_DP0 pid=536393) 	cvt.rni.f32.f32 	%r112, %r110;
(EngineCore_DP0 pid=536393) 	.loc	1 300 76                        // quant_slide_tuned_Qwen2.5-14B.py:300:76
(EngineCore_DP0 pid=536393) 	max.f32 	%r113, %r111, 0fC3000000;
(EngineCore_DP0 pid=536393) 	min.f32 	%r114, %r113, 0f42FE0000;
(EngineCore_DP0 pid=536393) 	max.f32 	%r115, %r112, 0fC3000000;
(EngineCore_DP0 pid=536393) 	min.f32 	%r116, %r115, 0f42FE0000;
(EngineCore_DP0 pid=536393) 	.loc	1 300 86                        // quant_slide_tuned_Qwen2.5-14B.py:300:86
(EngineCore_DP0 pid=536393) 	cvt.rzi.s32.f32 	%r117, %r114;
(EngineCore_DP0 pid=536393) 	cvt.rzi.s32.f32 	%r118, %r116;
(EngineCore_DP0 pid=536393) 	.loc	1 300 98                        // quant_slide_tuned_Qwen2.5-14B.py:300:98
(EngineCore_DP0 pid=536393) 	and.b32 	%r119, %r117, 255;
(EngineCore_DP0 pid=536393) 	and.b32 	%r120, %r118, 255;
(EngineCore_DP0 pid=536393) 	.loc	1 301 56                        // quant_slide_tuned_Qwen2.5-14B.py:301:56
(EngineCore_DP0 pid=536393) 	mul.f32 	%r121, %r14, %r99;
(EngineCore_DP0 pid=536393) 	mul.f32 	%r122, %r14, %r100;
(EngineCore_DP0 pid=536393) 	.loc	1 301 51                        // quant_slide_tuned_Qwen2.5-14B.py:301:51
(EngineCore_DP0 pid=536393) 	cvt.rni.f32.f32 	%r123, %r121;
(EngineCore_DP0 pid=536393) 	cvt.rni.f32.f32 	%r124, %r122;
(EngineCore_DP0 pid=536393) 	.loc	1 302 56                        // quant_slide_tuned_Qwen2.5-14B.py:302:56
(EngineCore_DP0 pid=536393) 	mul.f32 	%r125, %r14, %r103;
(EngineCore_DP0 pid=536393) 	mul.f32 	%r126, %r14, %r104;
(EngineCore_DP0 pid=536393) 	.loc	1 302 51                        // quant_slide_tuned_Qwen2.5-14B.py:302:51
(EngineCore_DP0 pid=536393) 	cvt.rni.f32.f32 	%r127, %r125;
(EngineCore_DP0 pid=536393) 	cvt.rni.f32.f32 	%r128, %r126;
(EngineCore_DP0 pid=536393) 	.loc	1 303 56                        // quant_slide_tuned_Qwen2.5-14B.py:303:56
(EngineCore_DP0 pid=536393) 	mul.f32 	%r129, %r14, %r107;
(EngineCore_DP0 pid=536393) 	mul.f32 	%r130, %r14, %r108;
(EngineCore_DP0 pid=536393) 	.loc	1 303 51                        // quant_slide_tuned_Qwen2.5-14B.py:303:51
(EngineCore_DP0 pid=536393) 	cvt.rni.f32.f32 	%r131, %r129;
(EngineCore_DP0 pid=536393) 	cvt.rni.f32.f32 	%r132, %r130;
(EngineCore_DP0 pid=536393) 	.loc	1 303 76                        // quant_slide_tuned_Qwen2.5-14B.py:303:76
(EngineCore_DP0 pid=536393) 	max.f32 	%r133, %r131, 0fC3000000;
(EngineCore_DP0 pid=536393) 	min.f32 	%r134, %r133, 0f42FE0000;
(EngineCore_DP0 pid=536393) 	max.f32 	%r135, %r132, 0fC3000000;
(EngineCore_DP0 pid=536393) 	min.f32 	%r136, %r135, 0f42FE0000;
(EngineCore_DP0 pid=536393) 	.loc	1 303 86                        // quant_slide_tuned_Qwen2.5-14B.py:303:86
(EngineCore_DP0 pid=536393) 	cvt.rzi.s32.f32 	%r137, %r134;
(EngineCore_DP0 pid=536393) 	cvt.rzi.s32.f32 	%r138, %r136;
(EngineCore_DP0 pid=536393) 	.loc	1 301 76                        // quant_slide_tuned_Qwen2.5-14B.py:301:76
(EngineCore_DP0 pid=536393) 	max.f32 	%r139, %r127, 0fC3000000;
(EngineCore_DP0 pid=536393) 	max.f32 	%r140, %r123, 0fC3000000;
(EngineCore_DP0 pid=536393) 	min.f32 	%r141, %r140, 0f42FE0000;
(EngineCore_DP0 pid=536393) 	min.f32 	%r142, %r139, 0f42FE0000;
(EngineCore_DP0 pid=536393) 	.loc	1 301 86                        // quant_slide_tuned_Qwen2.5-14B.py:301:86
(EngineCore_DP0 pid=536393) 	cvt.rzi.s32.f32 	%r143, %r142;
(EngineCore_DP0 pid=536393) 	cvt.rzi.s32.f32 	%r144, %r141;
(EngineCore_DP0 pid=536393) 	.loc	1 305 30                        // quant_slide_tuned_Qwen2.5-14B.py:305:30
(EngineCore_DP0 pid=536393) 	shl.b32 	%r145, %r144, 8;
(EngineCore_DP0 pid=536393) 	shl.b32 	%r146, %r143, 16;
(EngineCore_DP0 pid=536393) 	and.b32 	%r147, %r146, 16711680;
(EngineCore_DP0 pid=536393) 	and.b32 	%r148, %r145, 65280;
(EngineCore_DP0 pid=536393) 	.loc	1 305 24                        // quant_slide_tuned_Qwen2.5-14B.py:305:24
(EngineCore_DP0 pid=536393) 	or.b32 	%r149, %r148, %r119;
(EngineCore_DP0 pid=536393) 	.loc	1 301 76                        // quant_slide_tuned_Qwen2.5-14B.py:301:76
(EngineCore_DP0 pid=536393) 	max.f32 	%r150, %r128, 0fC3000000;
(EngineCore_DP0 pid=536393) 	max.f32 	%r151, %r124, 0fC3000000;
(EngineCore_DP0 pid=536393) 	min.f32 	%r152, %r151, 0f42FE0000;
(EngineCore_DP0 pid=536393) 	min.f32 	%r153, %r150, 0f42FE0000;
(EngineCore_DP0 pid=536393) 	.loc	1 301 86                        // quant_slide_tuned_Qwen2.5-14B.py:301:86
(EngineCore_DP0 pid=536393) 	cvt.rzi.s32.f32 	%r154, %r153;
(EngineCore_DP0 pid=536393) 	cvt.rzi.s32.f32 	%r155, %r152;
(EngineCore_DP0 pid=536393) 	.loc	1 305 30                        // quant_slide_tuned_Qwen2.5-14B.py:305:30
(EngineCore_DP0 pid=536393) 	shl.b32 	%r156, %r155, 8;
(EngineCore_DP0 pid=536393) 	shl.b32 	%r157, %r154, 16;
(EngineCore_DP0 pid=536393) 	and.b32 	%r158, %r157, 16711680;
(EngineCore_DP0 pid=536393) 	and.b32 	%r159, %r156, 65280;
(EngineCore_DP0 pid=536393) 	.loc	1 305 24                        // quant_slide_tuned_Qwen2.5-14B.py:305:24
(EngineCore_DP0 pid=536393) 	or.b32 	%r160, %r159, %r120;
(EngineCore_DP0 pid=536393) 	.loc	1 305 36                        // quant_slide_tuned_Qwen2.5-14B.py:305:36
(EngineCore_DP0 pid=536393) 	or.b32 	%r161, %r149, %r147;
(EngineCore_DP0 pid=536393) 	or.b32 	%r162, %r160, %r158;
(EngineCore_DP0 pid=536393) 	.loc	1 305 55                        // quant_slide_tuned_Qwen2.5-14B.py:305:55
(EngineCore_DP0 pid=536393) 	shl.b32 	%r163, %r137, 24;
(EngineCore_DP0 pid=536393) 	shl.b32 	%r164, %r138, 24;
(EngineCore_DP0 pid=536393) 	.loc	1 305 49                        // quant_slide_tuned_Qwen2.5-14B.py:305:49
(EngineCore_DP0 pid=536393) 	or.b32 	%r83, %r161, %r163;
(EngineCore_DP0 pid=536393) 	or.b32 	%r84, %r162, %r164;
(EngineCore_DP0 pid=536393) 	.loc	1 306 29                        // quant_slide_tuned_Qwen2.5-14B.py:306:29
(EngineCore_DP0 pid=536393) 	mad.wide.s32 	%rd17, %r85, 4, %rd2;
(EngineCore_DP0 pid=536393) 	.loc	1 306 39                        // quant_slide_tuned_Qwen2.5-14B.py:306:39
(EngineCore_DP0 pid=536393) 	// begin inline asm
(EngineCore_DP0 pid=536393) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r83, %r84 };
(EngineCore_DP0 pid=536393) 	// end inline asm
(EngineCore_DP0 pid=536393) 	.loc	1 282 41                        // quant_slide_tuned_Qwen2.5-14B.py:282:41
(EngineCore_DP0 pid=536393) 	add.s32 	%r168, %r168, 1024;
(EngineCore_DP0 pid=536393) 	setp.lt.s32 	%p27, %r168, %r15;
(EngineCore_DP0 pid=536393) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=536393) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=536393) 	.loc	1 282 4                         // quant_slide_tuned_Qwen2.5-14B.py:282:4
(EngineCore_DP0 pid=536393) 	ret;
(EngineCore_DP0 pid=536393) $L__tmp3:
(EngineCore_DP0 pid=536393) $L__func_end0:
(EngineCore_DP0 pid=536393)                                         // -- End function
(EngineCore_DP0 pid=536393) }
(EngineCore_DP0 pid=536393) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-14B.py"
(EngineCore_DP0 pid=536393) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=536393) 	.section	.debug_abbrev
(EngineCore_DP0 pid=536393) 	{
(EngineCore_DP0 pid=536393) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=536393) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=536393) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=536393) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=536393) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=536393) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=536393) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=536393) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=536393) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=536393) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=536393) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=536393) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=536393) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=536393) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=536393) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=536393) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=536393) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=536393) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=536393) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=536393) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=536393) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=536393) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=536393) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=536393) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=536393) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=536393) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=536393) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=536393) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=536393) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=536393) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=536393) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=536393) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=536393) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=536393) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=536393) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=536393) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=536393) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=536393) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=536393) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=536393) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=536393) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=536393) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=536393) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=536393) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=536393) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=536393) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=536393) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=536393) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=536393) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=536393) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=536393) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=536393) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=536393) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=536393) 	}
(EngineCore_DP0 pid=536393) 	.section	.debug_info
(EngineCore_DP0 pid=536393) 	{
(EngineCore_DP0 pid=536393) .b32 224                                // Length of Unit
(EngineCore_DP0 pid=536393) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=536393) .b8 0
(EngineCore_DP0 pid=536393) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=536393) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=536393) .b8 1                                   // Abbrev [1] 0xb:0xd9 DW_TAG_compile_unit
(EngineCore_DP0 pid=536393) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=536393) .b8 114
(EngineCore_DP0 pid=536393) .b8 105
(EngineCore_DP0 pid=536393) .b8 116
(EngineCore_DP0 pid=536393) .b8 111
(EngineCore_DP0 pid=536393) .b8 110
(EngineCore_DP0 pid=536393) .b8 0
(EngineCore_DP0 pid=536393) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=536393) .b8 0
(EngineCore_DP0 pid=536393) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=536393) .b8 117
(EngineCore_DP0 pid=536393) .b8 97
(EngineCore_DP0 pid=536393) .b8 110
(EngineCore_DP0 pid=536393) .b8 116
(EngineCore_DP0 pid=536393) .b8 95
(EngineCore_DP0 pid=536393) .b8 115
(EngineCore_DP0 pid=536393) .b8 108
(EngineCore_DP0 pid=536393) .b8 105
(EngineCore_DP0 pid=536393) .b8 100
(EngineCore_DP0 pid=536393) .b8 101
(EngineCore_DP0 pid=536393) .b8 95
(EngineCore_DP0 pid=536393) .b8 116
(EngineCore_DP0 pid=536393) .b8 117
(EngineCore_DP0 pid=536393) .b8 110
(EngineCore_DP0 pid=536393) .b8 101
(EngineCore_DP0 pid=536393) .b8 100
(EngineCore_DP0 pid=536393) .b8 95
(EngineCore_DP0 pid=536393) .b8 81
(EngineCore_DP0 pid=536393) .b8 119
(EngineCore_DP0 pid=536393) .b8 101
(EngineCore_DP0 pid=536393) .b8 110
(EngineCore_DP0 pid=536393) .b8 50
(EngineCore_DP0 pid=536393) .b8 46
(EngineCore_DP0 pid=536393) .b8 53
(EngineCore_DP0 pid=536393) .b8 45
(EngineCore_DP0 pid=536393) .b8 49
(EngineCore_DP0 pid=536393) .b8 52
(EngineCore_DP0 pid=536393) .b8 66
(EngineCore_DP0 pid=536393) .b8 46
(EngineCore_DP0 pid=536393) .b8 112
(EngineCore_DP0 pid=536393) .b8 121
(EngineCore_DP0 pid=536393) .b8 0
(EngineCore_DP0 pid=536393) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=536393) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=536393) .b8 114
(EngineCore_DP0 pid=536393) .b8 111
(EngineCore_DP0 pid=536393) .b8 111
(EngineCore_DP0 pid=536393) .b8 116
(EngineCore_DP0 pid=536393) .b8 47
(EngineCore_DP0 pid=536393) .b8 118
(EngineCore_DP0 pid=536393) .b8 108
(EngineCore_DP0 pid=536393) .b8 108
(EngineCore_DP0 pid=536393) .b8 109
(EngineCore_DP0 pid=536393) .b8 98
(EngineCore_DP0 pid=536393) .b8 101
(EngineCore_DP0 pid=536393) .b8 110
(EngineCore_DP0 pid=536393) .b8 99
(EngineCore_DP0 pid=536393) .b8 104
(EngineCore_DP0 pid=536393) .b8 47
(EngineCore_DP0 pid=536393) .b8 115
(EngineCore_DP0 pid=536393) .b8 108
(EngineCore_DP0 pid=536393) .b8 105
(EngineCore_DP0 pid=536393) .b8 100
(EngineCore_DP0 pid=536393) .b8 101
(EngineCore_DP0 pid=536393) .b8 115
(EngineCore_DP0 pid=536393) .b8 112
(EngineCore_DP0 pid=536393) .b8 97
(EngineCore_DP0 pid=536393) .b8 114
(EngineCore_DP0 pid=536393) .b8 115
(EngineCore_DP0 pid=536393) .b8 101
(EngineCore_DP0 pid=536393) .b8 47
(EngineCore_DP0 pid=536393) .b8 99
(EngineCore_DP0 pid=536393) .b8 115
(EngineCore_DP0 pid=536393) .b8 114
(EngineCore_DP0 pid=536393) .b8 99
(EngineCore_DP0 pid=536393) .b8 47
(EngineCore_DP0 pid=536393) .b8 102
(EngineCore_DP0 pid=536393) .b8 117
(EngineCore_DP0 pid=536393) .b8 115
(EngineCore_DP0 pid=536393) .b8 101
(EngineCore_DP0 pid=536393) .b8 100
(EngineCore_DP0 pid=536393) .b8 95
(EngineCore_DP0 pid=536393) .b8 113
(EngineCore_DP0 pid=536393) .b8 117
(EngineCore_DP0 pid=536393) .b8 97
(EngineCore_DP0 pid=536393) .b8 110
(EngineCore_DP0 pid=536393) .b8 116
(EngineCore_DP0 pid=536393) .b8 95
(EngineCore_DP0 pid=536393) .b8 115
(EngineCore_DP0 pid=536393) .b8 108
(EngineCore_DP0 pid=536393) .b8 105
(EngineCore_DP0 pid=536393) .b8 100
(EngineCore_DP0 pid=536393) .b8 101
(EngineCore_DP0 pid=536393) .b8 95
(EngineCore_DP0 pid=536393) .b8 116
(EngineCore_DP0 pid=536393) .b8 114
(EngineCore_DP0 pid=536393) .b8 105
(EngineCore_DP0 pid=536393) .b8 116
(EngineCore_DP0 pid=536393) .b8 111
(EngineCore_DP0 pid=536393) .b8 110
(EngineCore_DP0 pid=536393) .b8 47
(EngineCore_DP0 pid=536393) .b8 98
(EngineCore_DP0 pid=536393) .b8 117
(EngineCore_DP0 pid=536393) .b8 105
(EngineCore_DP0 pid=536393) .b8 108
(EngineCore_DP0 pid=536393) .b8 100
(EngineCore_DP0 pid=536393) .b8 47
(EngineCore_DP0 pid=536393) .b8 71
(EngineCore_DP0 pid=536393) .b8 66
(EngineCore_DP0 pid=536393) .b8 49
(EngineCore_DP0 pid=536393) .b8 48
(EngineCore_DP0 pid=536393) .b8 95
(EngineCore_DP0 pid=536393) .b8 99
(EngineCore_DP0 pid=536393) .b8 99
(EngineCore_DP0 pid=536393) .b8 49
(EngineCore_DP0 pid=536393) .b8 50
(EngineCore_DP0 pid=536393) .b8 49
(EngineCore_DP0 pid=536393) .b8 95
(EngineCore_DP0 pid=536393) .b8 112
(EngineCore_DP0 pid=536393) .b8 121
(EngineCore_DP0 pid=536393) .b8 51
(EngineCore_DP0 pid=536393) .b8 49
(EngineCore_DP0 pid=536393) .b8 50
(EngineCore_DP0 pid=536393) .b8 95
(EngineCore_DP0 pid=536393) .b8 99
(EngineCore_DP0 pid=536393) .b8 117
(EngineCore_DP0 pid=536393) .b8 49
(EngineCore_DP0 pid=536393) .b8 50
(EngineCore_DP0 pid=536393) .b8 57
(EngineCore_DP0 pid=536393) .b8 95
(EngineCore_DP0 pid=536393) .b8 97
(EngineCore_DP0 pid=536393) .b8 97
(EngineCore_DP0 pid=536393) .b8 114
(EngineCore_DP0 pid=536393) .b8 99
(EngineCore_DP0 pid=536393) .b8 104
(EngineCore_DP0 pid=536393) .b8 54
(EngineCore_DP0 pid=536393) .b8 52
(EngineCore_DP0 pid=536393) .b8 0
(EngineCore_DP0 pid=536393) .b8 2                                   // Abbrev [2] 0x99:0x1b DW_TAG_subprogram
(EngineCore_DP0 pid=536393) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=536393) .b8 113
(EngineCore_DP0 pid=536393) .b8 117
(EngineCore_DP0 pid=536393) .b8 97
(EngineCore_DP0 pid=536393) .b8 110
(EngineCore_DP0 pid=536393) .b8 116
(EngineCore_DP0 pid=536393) .b8 95
(EngineCore_DP0 pid=536393) .b8 115
(EngineCore_DP0 pid=536393) .b8 108
(EngineCore_DP0 pid=536393) .b8 105
(EngineCore_DP0 pid=536393) .b8 100
(EngineCore_DP0 pid=536393) .b8 101
(EngineCore_DP0 pid=536393) .b8 95
(EngineCore_DP0 pid=536393) .b8 105
(EngineCore_DP0 pid=536393) .b8 110
(EngineCore_DP0 pid=536393) .b8 116
(EngineCore_DP0 pid=536393) .b8 56
(EngineCore_DP0 pid=536393) .b8 95
(EngineCore_DP0 pid=536393) .b8 107
(EngineCore_DP0 pid=536393) .b8 101
(EngineCore_DP0 pid=536393) .b8 114
(EngineCore_DP0 pid=536393) .b8 110
(EngineCore_DP0 pid=536393) .b8 101
(EngineCore_DP0 pid=536393) .b8 108
(EngineCore_DP0 pid=536393) .b8 0
(EngineCore_DP0 pid=536393) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=536393) .b8 3                                   // Abbrev [3] 0xb4:0x2f DW_TAG_subprogram
(EngineCore_DP0 pid=536393) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=536393) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=536393) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=536393) .b8 4                                   // Abbrev [4] 0xc9:0x19 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=536393) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=536393) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=536393) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=536393) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=536393) .b8 16                                  // DW_AT_call_line
(EngineCore_DP0 pid=536393) .b8 1
(EngineCore_DP0 pid=536393) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=536393) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=536393) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=536393) 	}
(EngineCore_DP0 pid=536393) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=536393) 
(EngineCore_DP0 pid=536393) ================================================================
(EngineCore_DP0 pid=536393) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=536393) 
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmplsmeo3__.ptx', '-o', '/tmp/tmplsmeo3__.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866] 
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866] 
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-14B.py", line 335, in quant_slide_int8_triton
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866] 
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmplsmeo3__.ptx -o /tmp/tmplsmeo3__.ptx.o
(EngineCore_DP0 pid=536393) ERROR 01-25 22:30:57 [core.py:866] 

STDERR:
[2026-01-25 22:29:01] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 22:29:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-25 22:29:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-25 22:29:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:29:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:29:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:29:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:29:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:29:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-25 22:29:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:29:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:29:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:29:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:29:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:29:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 22:29:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-25 22:29:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-25 22:29:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:29:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:29:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:29:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:29:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 22:29:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-25 22:29:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:29:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:29:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:29:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:29:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=536393) [2026-01-25 22:29:06] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=536393) [2026-01-25 22:29:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=536393) [2026-01-25 22:29:06] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=536393) [2026-01-25 22:29:06] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=536393) [2026-01-25 22:29:06] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=536393) [2026-01-25 22:29:06] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=536393) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=536393) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:24,  8.23s/it]
(EngineCore_DP0 pid=536393) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:42<00:46, 23.47s/it]
(EngineCore_DP0 pid=536393) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:13<00:26, 26.92s/it]
(EngineCore_DP0 pid=536393) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:46<00:00, 29.17s/it]
(EngineCore_DP0 pid=536393) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:46<00:00, 26.50s/it]
(EngineCore_DP0 pid=536393) 
(EngineCore_DP0 pid=536393) [2026-01-25 22:30:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=536393) [2026-01-25 22:30:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36929536 bytes
(EngineCore_DP0 pid=536393) [2026-01-25 22:30:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=536393) [2026-01-25 22:30:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26378240 bytes
(EngineCore_DP0 pid=536393) [2026-01-25 22:30:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=536393) [2026-01-25 22:30:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 142442496 bytes
(EngineCore_DP0 pid=536393) [2026-01-25 22:30:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=536393) [2026-01-25 22:30:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70778880 bytes
(EngineCore_DP0 pid=536393) Process EngineCore_DP0:
(EngineCore_DP0 pid=536393) Traceback (most recent call last):
(EngineCore_DP0 pid=536393)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=536393)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=536393)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=536393)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=536393) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmplsmeo3__.ptx', '-o', '/tmp/tmplsmeo3__.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=536393) 
(EngineCore_DP0 pid=536393) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=536393) 
(EngineCore_DP0 pid=536393) Traceback (most recent call last):
(EngineCore_DP0 pid=536393)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=536393)     self.run()
(EngineCore_DP0 pid=536393)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=536393)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=536393)     raise e
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=536393)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=536393)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=536393)     super().__init__(
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=536393)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=536393)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=536393)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=536393)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=536393)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=536393)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=536393)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=536393)     return func(*args, **kwargs)
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=536393)     return func(*args, **kwargs)
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=536393)     self.model_runner.profile_run()
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=536393)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=536393)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=536393)     return func(*args, **kwargs)
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=536393)     outputs = self.model(
(EngineCore_DP0 pid=536393)               ^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=536393)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=536393)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=536393)     hidden_states = self.model(
(EngineCore_DP0 pid=536393)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=536393)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=536393)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=536393)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=536393)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=536393)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=536393)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=536393)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=536393)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=536393)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=536393)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=536393)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=536393)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=536393)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=536393)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=536393)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=536393)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=536393)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=536393)     return self._linear_fn(
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=536393)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=536393)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=536393)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=536393)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=536393)     return fn(input, L)
(EngineCore_DP0 pid=536393)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-14B.py", line 335, in quant_slide_int8_triton
(EngineCore_DP0 pid=536393)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=536393)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=536393)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=536393)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=536393)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=536393)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=536393)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=536393)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=536393)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=536393)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=536393)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=536393)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=536393)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=536393)     raise PTXASError(error)
(EngineCore_DP0 pid=536393) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=536393) `ptxas` stderr:
(EngineCore_DP0 pid=536393) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=536393) 
(EngineCore_DP0 pid=536393) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmplsmeo3__.ptx -o /tmp/tmplsmeo3__.ptx.o
(EngineCore_DP0 pid=536393) 
[rank0]:[W125 22:30:57.814057180 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 22:30:59
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M4096.json --enforce-eager


========== M=16 ==========
Time: 2026-01-26 02:26:50
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M16.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:26:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:26:53 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=741039) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=741039) WARNING 01-26 02:27:14 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 81.04 requests/s, 1377.72 total tokens/s, 81.04 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  128

STDERR:
[2026-01-26 02:26:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:26:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 02:26:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 02:26:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:26:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:26:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:26:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:26:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:26:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 02:26:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:26:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:26:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:26:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:26:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:26:57] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:26:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 02:26:57] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 02:26:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:26:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:26:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:26:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:26:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:26:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 02:26:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:26:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:26:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:26:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:26:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=741039) [2026-01-26 02:26:58] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=741039) [2026-01-26 02:26:58] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=741039) [2026-01-26 02:26:58] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=741039) [2026-01-26 02:26:58] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=741039) [2026-01-26 02:26:58] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=741039) [2026-01-26 02:26:58] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=741039) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=741039) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.30s/it]
(EngineCore_DP0 pid=741039) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.30s/it]
(EngineCore_DP0 pid=741039) 
(EngineCore_DP0 pid=741039) [2026-01-26 02:27:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=741039) [2026-01-26 02:27:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=741039) [2026-01-26 02:27:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=741039) [2026-01-26 02:27:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=741039) [2026-01-26 02:27:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=741039) [2026-01-26 02:27:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=741039) [2026-01-26 02:27:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=741039) [2026-01-26 02:27:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=741039) 2026-01-26 02:27:14,158 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=741039) 2026-01-26 02:27:14,167 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 13262.95it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:30,  4.15it/s, est. speed input: 66.35 toks/s, output: 4.15 toks/s]
Processed prompts:   9%|         | 11/128 [00:00<00:03, 38.86it/s, est. speed input: 506.25 toks/s, output: 31.64 toks/s]
Processed prompts:  16%|        | 21/128 [00:00<00:01, 58.68it/s, est. speed input: 741.79 toks/s, output: 46.36 toks/s]
Processed prompts:  24%|       | 31/128 [00:00<00:01, 71.29it/s, est. speed input: 891.53 toks/s, output: 55.72 toks/s]
Processed prompts:  32%|      | 41/128 [00:00<00:01, 79.31it/s, est. speed input: 993.43 toks/s, output: 62.09 toks/s]
Processed prompts:  40%|      | 51/128 [00:00<00:00, 84.57it/s, est. speed input: 1067.27 toks/s, output: 66.70 toks/s]
Processed prompts:  48%|     | 61/128 [00:00<00:00, 88.26it/s, est. speed input: 1124.16 toks/s, output: 70.26 toks/s]
Processed prompts:  55%|    | 71/128 [00:00<00:00, 90.84it/s, est. speed input: 1169.20 toks/s, output: 73.07 toks/s]
Processed prompts:  63%|   | 81/128 [00:01<00:00, 92.45it/s, est. speed input: 1204.80 toks/s, output: 75.30 toks/s]
Processed prompts:  71%|   | 91/128 [00:01<00:00, 93.80it/s, est. speed input: 1235.10 toks/s, output: 77.19 toks/s]
Processed prompts:  79%|  | 101/128 [00:01<00:00, 93.47it/s, est. speed input: 1255.92 toks/s, output: 78.49 toks/s]
Processed prompts:  87%| | 111/128 [00:01<00:00, 93.85it/s, est. speed input: 1275.63 toks/s, output: 79.73 toks/s]
Processed prompts:  95%|| 121/128 [00:01<00:00, 94.90it/s, est. speed input: 1295.05 toks/s, output: 80.94 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 94.90it/s, est. speed input: 1305.91 toks/s, output: 81.62 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 81.61it/s, est. speed input: 1305.91 toks/s, output: 81.62 toks/s]
[rank0]:[W126 02:27:16.844544931 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 02:27:18
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M128.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:27:22 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:27:22 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=741630) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=741630) WARNING 01-26 02:27:42 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 71.99 requests/s, 9286.85 total tokens/s, 71.99 output tokens/s
Total num prompt tokens:  16384
Total num output tokens:  128

STDERR:
[2026-01-26 02:27:22] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:27:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 02:27:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 02:27:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 02:27:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:27:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:27:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:27:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:27:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:27:25] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:27:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 02:27:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 02:27:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 02:27:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:27:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:27:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:27:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:27:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=741630) [2026-01-26 02:27:26] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=741630) [2026-01-26 02:27:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=741630) [2026-01-26 02:27:26] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=741630) [2026-01-26 02:27:26] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=741630) [2026-01-26 02:27:26] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=741630) [2026-01-26 02:27:26] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=741630) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=741630) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.16s/it]
(EngineCore_DP0 pid=741630) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.16s/it]
(EngineCore_DP0 pid=741630) 
(EngineCore_DP0 pid=741630) [2026-01-26 02:27:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=741630) [2026-01-26 02:27:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=741630) [2026-01-26 02:27:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=741630) [2026-01-26 02:27:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=741630) [2026-01-26 02:27:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=741630) [2026-01-26 02:27:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=741630) [2026-01-26 02:27:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=741630) [2026-01-26 02:27:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=741630) 2026-01-26 02:27:42,125 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=741630) 2026-01-26 02:27:42,133 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 3985.44it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:28,  4.40it/s, est. speed input: 563.52 toks/s, output: 4.40 toks/s]
Processed prompts:   8%|         | 10/128 [00:00<00:03, 36.33it/s, est. speed input: 3820.06 toks/s, output: 29.84 toks/s]
Processed prompts:  15%|        | 19/128 [00:00<00:02, 53.45it/s, est. speed input: 5481.73 toks/s, output: 42.82 toks/s]
Processed prompts:  22%|       | 28/128 [00:00<00:01, 64.00it/s, est. speed input: 6514.08 toks/s, output: 50.89 toks/s]
Processed prompts:  29%|       | 37/128 [00:00<00:01, 69.63it/s, est. speed input: 7157.36 toks/s, output: 55.92 toks/s]
Processed prompts:  36%|      | 46/128 [00:00<00:01, 74.22it/s, est. speed input: 7660.22 toks/s, output: 59.84 toks/s]
Processed prompts:  43%|     | 55/128 [00:00<00:00, 77.53it/s, est. speed input: 8049.22 toks/s, output: 62.88 toks/s]
Processed prompts:  50%|     | 64/128 [00:00<00:00, 79.53it/s, est. speed input: 8344.37 toks/s, output: 65.19 toks/s]
Processed prompts:  57%|    | 73/128 [00:01<00:00, 80.96it/s, est. speed input: 8583.46 toks/s, output: 67.06 toks/s]
Processed prompts:  64%|   | 82/128 [00:01<00:00, 82.04it/s, est. speed input: 8782.68 toks/s, output: 68.61 toks/s]
Processed prompts:  71%|   | 91/128 [00:01<00:00, 82.96it/s, est. speed input: 8954.21 toks/s, output: 69.95 toks/s]
Processed prompts:  78%|  | 100/128 [00:01<00:00, 83.59it/s, est. speed input: 9099.49 toks/s, output: 71.09 toks/s]
Processed prompts:  85%| | 109/128 [00:01<00:00, 83.78it/s, est. speed input: 9218.13 toks/s, output: 72.02 toks/s]
Processed prompts:  92%|| 118/128 [00:01<00:00, 83.33it/s, est. speed input: 9307.07 toks/s, output: 72.71 toks/s]
Processed prompts:  99%|| 127/128 [00:01<00:00, 82.80it/s, est. speed input: 9379.39 toks/s, output: 73.28 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 82.80it/s, est. speed input: 9389.02 toks/s, output: 73.35 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 73.34it/s, est. speed input: 9389.02 toks/s, output: 73.35 toks/s]
[rank0]:[W126 02:27:44.833565807 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 02:27:46
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M256.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:27:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:27:50 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=742211) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=742211) WARNING 01-26 02:28:10 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 62.65 requests/s, 16101.86 total tokens/s, 62.65 output tokens/s
Total num prompt tokens:  32768
Total num output tokens:  128

STDERR:
[2026-01-26 02:27:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:27:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 02:27:50] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 02:27:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 02:27:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:27:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:27:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:27:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:27:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:27:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:27:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 02:27:54] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 02:27:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 02:27:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 02:27:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:27:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:27:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:27:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:27:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=742211) [2026-01-26 02:27:54] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=742211) [2026-01-26 02:27:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=742211) [2026-01-26 02:27:54] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=742211) [2026-01-26 02:27:54] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=742211) [2026-01-26 02:27:54] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=742211) [2026-01-26 02:27:54] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=742211) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=742211) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.04s/it]
(EngineCore_DP0 pid=742211) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.04s/it]
(EngineCore_DP0 pid=742211) 
(EngineCore_DP0 pid=742211) [2026-01-26 02:28:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=742211) [2026-01-26 02:28:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=742211) [2026-01-26 02:28:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=742211) [2026-01-26 02:28:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=742211) [2026-01-26 02:28:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=742211) [2026-01-26 02:28:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=742211) [2026-01-26 02:28:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=742211) [2026-01-26 02:28:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=742211) 2026-01-26 02:28:09,924 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=742211) 2026-01-26 02:28:09,931 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 2440.87it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:29,  4.29it/s, est. speed input: 1098.08 toks/s, output: 4.29 toks/s]
Processed prompts:   7%|         | 9/128 [00:00<00:03, 31.57it/s, est. speed input: 6668.47 toks/s, output: 26.05 toks/s]
Processed prompts:  13%|        | 17/128 [00:00<00:02, 46.40it/s, est. speed input: 9538.22 toks/s, output: 37.26 toks/s]
Processed prompts:  20%|        | 25/128 [00:00<00:01, 55.36it/s, est. speed input: 11300.35 toks/s, output: 44.14 toks/s]
Processed prompts:  26%|       | 33/128 [00:00<00:01, 61.34it/s, est. speed input: 12519.22 toks/s, output: 48.90 toks/s]
Processed prompts:  32%|      | 41/128 [00:00<00:01, 64.83it/s, est. speed input: 13360.47 toks/s, output: 52.19 toks/s]
Processed prompts:  38%|      | 49/128 [00:00<00:01, 67.30it/s, est. speed input: 14006.28 toks/s, output: 54.71 toks/s]
Processed prompts:  45%|     | 57/128 [00:01<00:01, 69.11it/s, est. speed input: 14520.23 toks/s, output: 56.72 toks/s]
Processed prompts:  51%|     | 65/128 [00:01<00:00, 69.37it/s, est. speed input: 14866.58 toks/s, output: 58.07 toks/s]
Processed prompts:  57%|    | 73/128 [00:01<00:00, 69.84it/s, est. speed input: 15166.85 toks/s, output: 59.24 toks/s]
Processed prompts:  63%|   | 81/128 [00:01<00:00, 70.79it/s, est. speed input: 15454.93 toks/s, output: 60.37 toks/s]
Processed prompts:  70%|   | 89/128 [00:01<00:00, 71.36it/s, est. speed input: 15694.02 toks/s, output: 61.30 toks/s]
Processed prompts:  76%|  | 97/128 [00:01<00:00, 71.67it/s, est. speed input: 15894.46 toks/s, output: 62.09 toks/s]
Processed prompts:  82%| | 105/128 [00:01<00:00, 72.13it/s, est. speed input: 16080.80 toks/s, output: 62.82 toks/s]
Processed prompts:  88%| | 113/128 [00:01<00:00, 72.26it/s, est. speed input: 16235.01 toks/s, output: 63.42 toks/s]
Processed prompts:  95%|| 121/128 [00:01<00:00, 72.34it/s, est. speed input: 16371.12 toks/s, output: 63.95 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 72.34it/s, est. speed input: 16473.26 toks/s, output: 64.35 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 64.34it/s, est. speed input: 16473.26 toks/s, output: 64.35 toks/s]
[rank0]:[W126 02:28:12.871679132 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 03:12:06
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:12:09 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:12:10 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=788677) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=788677) WARNING 01-26 03:12:29 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 50.68 requests/s, 25999.79 total tokens/s, 50.68 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 03:12:09] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:12:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:12:09] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:12:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:12:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:12:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:12:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:12:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:12:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:12:13] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:12:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:12:13] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:12:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:12:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:12:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:12:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:12:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:12:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=788677) [2026-01-26 03:12:14] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=788677) [2026-01-26 03:12:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=788677) [2026-01-26 03:12:14] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=788677) [2026-01-26 03:12:14] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=788677) [2026-01-26 03:12:14] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=788677) [2026-01-26 03:12:14] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=788677) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=788677) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.14s/it]
(EngineCore_DP0 pid=788677) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.14s/it]
(EngineCore_DP0 pid=788677) 
(EngineCore_DP0 pid=788677) [2026-01-26 03:12:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=788677) [2026-01-26 03:12:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=788677) [2026-01-26 03:12:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=788677) [2026-01-26 03:12:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=788677) [2026-01-26 03:12:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=788677) [2026-01-26 03:12:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=788677) [2026-01-26 03:12:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=788677) [2026-01-26 03:12:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=788677) 2026-01-26 03:12:29,369 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=788677) 2026-01-26 03:12:29,376 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  95%|| 121/128 [00:00<00:00, 1202.95it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1196.91it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:01, 66.71it/s, est. speed input: 34159.78 toks/s, output: 66.71 toks/s]
Processed prompts:  11%|         | 14/128 [00:00<00:01, 57.76it/s, est. speed input: 30183.36 toks/s, output: 58.95 toks/s]
Processed prompts:  16%|        | 20/128 [00:00<00:01, 54.90it/s, est. speed input: 28902.14 toks/s, output: 56.45 toks/s]
Processed prompts:  20%|        | 26/128 [00:00<00:01, 54.19it/s, est. speed input: 28481.74 toks/s, output: 55.63 toks/s]
Processed prompts:  25%|       | 32/128 [00:00<00:01, 53.55it/s, est. speed input: 28155.39 toks/s, output: 54.99 toks/s]
Processed prompts:  30%|       | 38/128 [00:00<00:01, 53.44it/s, est. speed input: 28009.06 toks/s, output: 54.70 toks/s]
Processed prompts:  34%|      | 44/128 [00:00<00:01, 53.34it/s, est. speed input: 27894.97 toks/s, output: 54.48 toks/s]
Processed prompts:  39%|      | 50/128 [00:00<00:01, 52.93it/s, est. speed input: 27740.11 toks/s, output: 54.18 toks/s]
Processed prompts:  44%|     | 56/128 [00:01<00:01, 51.83it/s, est. speed input: 27464.39 toks/s, output: 53.64 toks/s]
Processed prompts:  48%|     | 62/128 [00:01<00:01, 51.78it/s, est. speed input: 27362.92 toks/s, output: 53.44 toks/s]
Processed prompts:  53%|    | 68/128 [00:01<00:01, 51.89it/s, est. speed input: 27303.90 toks/s, output: 53.33 toks/s]
Processed prompts:  58%|    | 74/128 [00:01<00:01, 52.26it/s, est. speed input: 27294.91 toks/s, output: 53.31 toks/s]
Processed prompts:  62%|   | 80/128 [00:01<00:00, 52.30it/s, est. speed input: 27258.66 toks/s, output: 53.24 toks/s]
Processed prompts:  67%|   | 86/128 [00:01<00:00, 52.35it/s, est. speed input: 27231.00 toks/s, output: 53.18 toks/s]
Processed prompts:  72%|  | 92/128 [00:01<00:00, 52.52it/s, est. speed input: 27221.60 toks/s, output: 53.17 toks/s]
Processed prompts:  77%|  | 98/128 [00:01<00:00, 52.54it/s, est. speed input: 27203.60 toks/s, output: 53.13 toks/s]
Processed prompts:  81%| | 104/128 [00:01<00:00, 52.29it/s, est. speed input: 27160.46 toks/s, output: 53.05 toks/s]
Processed prompts:  86%| | 110/128 [00:02<00:00, 51.71it/s, est. speed input: 27082.89 toks/s, output: 52.90 toks/s]
Processed prompts:  91%| | 116/128 [00:02<00:00, 52.20it/s, est. speed input: 27096.14 toks/s, output: 52.92 toks/s]
Processed prompts:  95%|| 122/128 [00:02<00:00, 52.61it/s, est. speed input: 27112.63 toks/s, output: 52.95 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 52.65it/s, est. speed input: 27107.38 toks/s, output: 52.94 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 52.65it/s, est. speed input: 27107.38 toks/s, output: 52.94 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 52.94it/s, est. speed input: 27107.38 toks/s, output: 52.94 toks/s]
[rank0]:[W126 03:12:32.857699422 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 03:12:34
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:12:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:12:38 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=789275) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=789275) WARNING 01-26 03:12:58 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.24 requests/s, 28948.75 total tokens/s, 28.24 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 03:12:38] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:12:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:12:38] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:12:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:12:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:12:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:12:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:12:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:12:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:12:42] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:12:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:12:42] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:12:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:12:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:12:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:12:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:12:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:12:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:12:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=789275) [2026-01-26 03:12:43] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=789275) [2026-01-26 03:12:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=789275) [2026-01-26 03:12:43] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=789275) [2026-01-26 03:12:43] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=789275) [2026-01-26 03:12:43] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=789275) [2026-01-26 03:12:43] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=789275) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=789275) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.26s/it]
(EngineCore_DP0 pid=789275) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.26s/it]
(EngineCore_DP0 pid=789275) 
(EngineCore_DP0 pid=789275) [2026-01-26 03:12:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=789275) [2026-01-26 03:12:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=789275) [2026-01-26 03:12:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=789275) [2026-01-26 03:12:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=789275) [2026-01-26 03:12:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=789275) [2026-01-26 03:12:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=789275) [2026-01-26 03:12:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=789275) [2026-01-26 03:12:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=789275) 2026-01-26 03:12:58,434 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=789275) 2026-01-26 03:12:58,441 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  52%|    | 67/128 [00:00<00:00, 662.65it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 620.66it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:02, 60.09it/s, est. speed input: 61539.66 toks/s, output: 60.09 toks/s]
Processed prompts:  11%|         | 14/128 [00:00<00:03, 36.30it/s, est. speed input: 39525.05 toks/s, output: 38.60 toks/s]
Processed prompts:  15%|        | 19/128 [00:00<00:03, 33.16it/s, est. speed input: 36345.37 toks/s, output: 35.49 toks/s]
Processed prompts:  18%|        | 23/128 [00:00<00:03, 31.54it/s, est. speed input: 34814.14 toks/s, output: 34.00 toks/s]
Processed prompts:  21%|        | 27/128 [00:00<00:03, 30.51it/s, est. speed input: 33816.55 toks/s, output: 33.02 toks/s]
Processed prompts:  24%|       | 31/128 [00:00<00:03, 30.02it/s, est. speed input: 33210.12 toks/s, output: 32.43 toks/s]
Processed prompts:  27%|       | 35/128 [00:01<00:03, 29.65it/s, est. speed input: 32740.02 toks/s, output: 31.97 toks/s]
Processed prompts:  30%|       | 38/128 [00:01<00:03, 29.01it/s, est. speed input: 32292.32 toks/s, output: 31.53 toks/s]
Processed prompts:  32%|      | 41/128 [00:01<00:02, 29.03it/s, est. speed input: 32096.01 toks/s, output: 31.34 toks/s]
Processed prompts:  34%|      | 44/128 [00:01<00:02, 29.27it/s, est. speed input: 31991.97 toks/s, output: 31.24 toks/s]
Processed prompts:  37%|      | 47/128 [00:01<00:02, 29.06it/s, est. speed input: 31800.00 toks/s, output: 31.05 toks/s]
Processed prompts:  39%|      | 50/128 [00:01<00:02, 29.11it/s, est. speed input: 31680.44 toks/s, output: 30.94 toks/s]
Processed prompts:  41%|     | 53/128 [00:01<00:02, 28.94it/s, est. speed input: 31531.07 toks/s, output: 30.79 toks/s]
Processed prompts:  44%|     | 56/128 [00:01<00:02, 29.09it/s, est. speed input: 31455.35 toks/s, output: 30.72 toks/s]
Processed prompts:  46%|     | 59/128 [00:01<00:02, 29.20it/s, est. speed input: 31386.69 toks/s, output: 30.65 toks/s]
Processed prompts:  48%|     | 62/128 [00:02<00:02, 29.31it/s, est. speed input: 31331.25 toks/s, output: 30.60 toks/s]
Processed prompts:  51%|     | 65/128 [00:02<00:02, 29.14it/s, est. speed input: 31238.54 toks/s, output: 30.51 toks/s]
Processed prompts:  53%|    | 68/128 [00:02<00:02, 28.56it/s, est. speed input: 31076.74 toks/s, output: 30.35 toks/s]
Processed prompts:  55%|    | 71/128 [00:02<00:01, 28.68it/s, est. speed input: 31014.32 toks/s, output: 30.29 toks/s]
Processed prompts:  58%|    | 74/128 [00:02<00:01, 28.81it/s, est. speed input: 30963.73 toks/s, output: 30.24 toks/s]
Processed prompts:  60%|    | 77/128 [00:02<00:01, 28.83it/s, est. speed input: 30907.58 toks/s, output: 30.18 toks/s]
Processed prompts:  62%|   | 80/128 [00:02<00:01, 28.66it/s, est. speed input: 30829.19 toks/s, output: 30.11 toks/s]
Processed prompts:  65%|   | 83/128 [00:02<00:01, 28.82it/s, est. speed input: 30794.17 toks/s, output: 30.07 toks/s]
Processed prompts:  67%|   | 86/128 [00:02<00:01, 29.08it/s, est. speed input: 30780.93 toks/s, output: 30.06 toks/s]
Processed prompts:  70%|   | 89/128 [00:02<00:01, 29.03it/s, est. speed input: 30739.77 toks/s, output: 30.02 toks/s]
Processed prompts:  72%|  | 92/128 [00:03<00:01, 28.90it/s, est. speed input: 30689.92 toks/s, output: 29.97 toks/s]
Processed prompts:  74%|  | 95/128 [00:03<00:01, 28.90it/s, est. speed input: 30654.36 toks/s, output: 29.94 toks/s]
Processed prompts:  77%|  | 98/128 [00:03<00:01, 28.62it/s, est. speed input: 30588.86 toks/s, output: 29.87 toks/s]
Processed prompts:  79%|  | 101/128 [00:03<00:00, 28.87it/s, est. speed input: 30576.85 toks/s, output: 29.86 toks/s]
Processed prompts:  81%| | 104/128 [00:03<00:00, 28.93it/s, est. speed input: 30552.67 toks/s, output: 29.84 toks/s]
Processed prompts:  84%| | 107/128 [00:03<00:00, 28.95it/s, est. speed input: 30527.77 toks/s, output: 29.81 toks/s]
Processed prompts:  86%| | 110/128 [00:03<00:00, 28.78it/s, est. speed input: 30486.18 toks/s, output: 29.77 toks/s]
Processed prompts:  88%| | 113/128 [00:03<00:00, 28.73it/s, est. speed input: 30453.06 toks/s, output: 29.74 toks/s]
Processed prompts:  91%| | 116/128 [00:03<00:00, 29.00it/s, est. speed input: 30450.46 toks/s, output: 29.74 toks/s]
Processed prompts:  93%|| 119/128 [00:04<00:00, 28.82it/s, est. speed input: 30415.03 toks/s, output: 29.70 toks/s]
Processed prompts:  95%|| 122/128 [00:04<00:00, 28.63it/s, est. speed input: 30375.19 toks/s, output: 29.66 toks/s]
Processed prompts:  98%|| 125/128 [00:04<00:00, 28.68it/s, est. speed input: 30352.79 toks/s, output: 29.64 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 28.43it/s, est. speed input: 30307.44 toks/s, output: 29.60 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 28.43it/s, est. speed input: 30307.44 toks/s, output: 29.60 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 29.60it/s, est. speed input: 30307.44 toks/s, output: 29.60 toks/s]
[rank0]:[W126 03:13:03.907897239 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 03:13:05
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:13:10 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:13:10 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=789894) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=789894) WARNING 01-26 03:13:30 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 30.18 requests/s, 30932.95 total tokens/s, 30.18 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 03:13:10] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:13:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:13:10] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:13:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:13:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:13:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:13:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:13:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:13:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:13:13] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:13:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:13:13] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:13:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:13:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:13:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:13:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:13:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:13:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=789894) [2026-01-26 03:13:14] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=789894) [2026-01-26 03:13:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=789894) [2026-01-26 03:13:14] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=789894) [2026-01-26 03:13:14] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=789894) [2026-01-26 03:13:14] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=789894) [2026-01-26 03:13:14] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=789894) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=789894) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.21s/it]
(EngineCore_DP0 pid=789894) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.21s/it]
(EngineCore_DP0 pid=789894) 
(EngineCore_DP0 pid=789894) [2026-01-26 03:13:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=789894) [2026-01-26 03:13:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=789894) [2026-01-26 03:13:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=789894) [2026-01-26 03:13:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=789894) [2026-01-26 03:13:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=789894) [2026-01-26 03:13:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=789894) [2026-01-26 03:13:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=789894) [2026-01-26 03:13:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=789894) 2026-01-26 03:13:30,083 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=789894) 2026-01-26 03:13:30,092 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  23%|       | 60/256 [00:00<00:00, 591.10it/s]
Adding requests:  47%|     | 120/256 [00:00<00:00, 595.33it/s]
Adding requests:  70%|   | 180/256 [00:00<00:00, 584.29it/s]
Adding requests:  93%|| 239/256 [00:00<00:00, 566.82it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 572.39it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 12/256 [00:00<00:02, 103.71it/s, est. speed input: 106207.01 toks/s, output: 103.71 toks/s]
Processed prompts:   9%|         | 23/256 [00:00<00:04, 48.18it/s, est. speed input: 53849.84 toks/s, output: 52.59 toks/s]   
Processed prompts:  12%|        | 30/256 [00:00<00:05, 37.96it/s, est. speed input: 44036.06 toks/s, output: 43.00 toks/s]
Processed prompts:  14%|        | 35/256 [00:00<00:05, 38.00it/s, est. speed input: 43244.80 toks/s, output: 42.23 toks/s]
Processed prompts:  16%|        | 40/256 [00:01<00:06, 33.33it/s, est. speed input: 39812.03 toks/s, output: 38.88 toks/s]
Processed prompts:  17%|        | 44/256 [00:01<00:06, 32.71it/s, est. speed input: 38889.91 toks/s, output: 37.98 toks/s]
Processed prompts:  19%|        | 48/256 [00:01<00:06, 32.25it/s, est. speed input: 38169.31 toks/s, output: 37.27 toks/s]
Processed prompts:  20%|        | 52/256 [00:01<00:06, 31.73it/s, est. speed input: 37513.03 toks/s, output: 36.63 toks/s]
Processed prompts:  22%|       | 56/256 [00:01<00:06, 31.50it/s, est. speed input: 37022.87 toks/s, output: 36.15 toks/s]
Processed prompts:  23%|       | 60/256 [00:01<00:06, 31.33it/s, est. speed input: 36609.02 toks/s, output: 35.75 toks/s]
Processed prompts:  25%|       | 64/256 [00:01<00:06, 31.26it/s, est. speed input: 36270.16 toks/s, output: 35.42 toks/s]
Processed prompts:  27%|       | 68/256 [00:01<00:06, 30.73it/s, est. speed input: 35846.33 toks/s, output: 35.01 toks/s]
Processed prompts:  28%|       | 72/256 [00:02<00:05, 30.85it/s, est. speed input: 35600.47 toks/s, output: 34.77 toks/s]
Processed prompts:  30%|       | 76/256 [00:02<00:05, 30.74it/s, est. speed input: 35340.11 toks/s, output: 34.51 toks/s]
Processed prompts:  31%|      | 80/256 [00:02<00:05, 30.91it/s, est. speed input: 35160.97 toks/s, output: 34.34 toks/s]
Processed prompts:  33%|      | 84/256 [00:02<00:05, 30.76it/s, est. speed input: 34945.29 toks/s, output: 34.13 toks/s]
Processed prompts:  34%|      | 88/256 [00:02<00:05, 30.74it/s, est. speed input: 34769.31 toks/s, output: 33.95 toks/s]
Processed prompts:  36%|      | 92/256 [00:02<00:05, 30.84it/s, est. speed input: 34629.05 toks/s, output: 33.82 toks/s]
Processed prompts:  38%|      | 96/256 [00:02<00:05, 31.01it/s, est. speed input: 34519.05 toks/s, output: 33.71 toks/s]
Processed prompts:  39%|      | 100/256 [00:02<00:05, 30.66it/s, est. speed input: 34342.71 toks/s, output: 33.54 toks/s]
Processed prompts:  41%|      | 104/256 [00:03<00:04, 30.69it/s, est. speed input: 34223.79 toks/s, output: 33.42 toks/s]
Processed prompts:  42%|     | 108/256 [00:03<00:04, 30.88it/s, est. speed input: 34138.99 toks/s, output: 33.34 toks/s]
Processed prompts:  44%|     | 112/256 [00:03<00:04, 30.67it/s, est. speed input: 34013.60 toks/s, output: 33.22 toks/s]
Processed prompts:  45%|     | 116/256 [00:03<00:04, 30.75it/s, est. speed input: 33926.96 toks/s, output: 33.13 toks/s]
Processed prompts:  47%|     | 120/256 [00:03<00:04, 30.87it/s, est. speed input: 33854.77 toks/s, output: 33.06 toks/s]
Processed prompts:  48%|     | 124/256 [00:03<00:04, 30.84it/s, est. speed input: 33774.45 toks/s, output: 32.98 toks/s]
Processed prompts:  50%|     | 128/256 [00:03<00:04, 30.87it/s, est. speed input: 33705.00 toks/s, output: 32.91 toks/s]
Processed prompts:  52%|    | 132/256 [00:04<00:04, 30.56it/s, est. speed input: 33600.44 toks/s, output: 32.81 toks/s]
Processed prompts:  53%|    | 136/256 [00:04<00:03, 30.48it/s, est. speed input: 33518.75 toks/s, output: 32.73 toks/s]
Processed prompts:  55%|    | 140/256 [00:04<00:03, 30.47it/s, est. speed input: 33447.30 toks/s, output: 32.66 toks/s]
Processed prompts:  56%|    | 144/256 [00:04<00:03, 30.47it/s, est. speed input: 33380.01 toks/s, output: 32.60 toks/s]
Processed prompts:  58%|    | 148/256 [00:04<00:03, 30.71it/s, est. speed input: 33342.42 toks/s, output: 32.56 toks/s]
Processed prompts:  59%|    | 152/256 [00:04<00:03, 30.79it/s, est. speed input: 33297.82 toks/s, output: 32.52 toks/s]
Processed prompts:  61%|    | 156/256 [00:04<00:03, 30.69it/s, est. speed input: 33239.81 toks/s, output: 32.46 toks/s]
Processed prompts:  62%|   | 160/256 [00:04<00:03, 30.77it/s, est. speed input: 33199.61 toks/s, output: 32.42 toks/s]
Processed prompts:  64%|   | 164/256 [00:05<00:02, 30.74it/s, est. speed input: 33153.65 toks/s, output: 32.38 toks/s]
Processed prompts:  66%|   | 168/256 [00:05<00:02, 30.47it/s, est. speed input: 33087.13 toks/s, output: 32.31 toks/s]
Processed prompts:  67%|   | 172/256 [00:05<00:02, 30.32it/s, est. speed input: 33027.36 toks/s, output: 32.25 toks/s]
Processed prompts:  69%|   | 176/256 [00:05<00:02, 30.46it/s, est. speed input: 32991.45 toks/s, output: 32.22 toks/s]
Processed prompts:  70%|   | 180/256 [00:05<00:02, 30.71it/s, est. speed input: 32970.53 toks/s, output: 32.20 toks/s]
Processed prompts:  72%|  | 184/256 [00:05<00:02, 30.87it/s, est. speed input: 32948.35 toks/s, output: 32.18 toks/s]
Processed prompts:  73%|  | 188/256 [00:05<00:02, 30.79it/s, est. speed input: 32912.72 toks/s, output: 32.14 toks/s]
Processed prompts:  75%|  | 192/256 [00:05<00:02, 30.72it/s, est. speed input: 32877.47 toks/s, output: 32.11 toks/s]
Processed prompts:  77%|  | 196/256 [00:06<00:01, 30.78it/s, est. speed input: 32851.66 toks/s, output: 32.08 toks/s]
Processed prompts:  78%|  | 200/256 [00:06<00:01, 30.29it/s, est. speed input: 32787.06 toks/s, output: 32.02 toks/s]
Processed prompts:  80%|  | 204/256 [00:06<00:01, 30.23it/s, est. speed input: 32746.12 toks/s, output: 31.98 toks/s]
Processed prompts:  81%| | 208/256 [00:06<00:01, 30.18it/s, est. speed input: 32705.61 toks/s, output: 31.94 toks/s]
Processed prompts:  83%| | 212/256 [00:06<00:01, 30.57it/s, est. speed input: 32697.76 toks/s, output: 31.93 toks/s]
Processed prompts:  84%| | 216/256 [00:06<00:01, 30.79it/s, est. speed input: 32685.85 toks/s, output: 31.92 toks/s]
Processed prompts:  86%| | 220/256 [00:06<00:01, 30.72it/s, est. speed input: 32659.22 toks/s, output: 31.89 toks/s]
Processed prompts:  88%| | 224/256 [00:07<00:01, 30.77it/s, est. speed input: 32640.57 toks/s, output: 31.88 toks/s]
Processed prompts:  89%| | 228/256 [00:07<00:00, 30.84it/s, est. speed input: 32624.06 toks/s, output: 31.86 toks/s]
Processed prompts:  91%| | 232/256 [00:07<00:00, 30.55it/s, est. speed input: 32587.21 toks/s, output: 31.82 toks/s]
Processed prompts:  92%|| 236/256 [00:07<00:00, 30.80it/s, est. speed input: 32579.71 toks/s, output: 31.82 toks/s]
Processed prompts:  94%|| 240/256 [00:07<00:00, 30.72it/s, est. speed input: 32556.96 toks/s, output: 31.79 toks/s]
Processed prompts:  95%|| 244/256 [00:07<00:00, 30.87it/s, est. speed input: 32547.54 toks/s, output: 31.78 toks/s]
Processed prompts:  97%|| 248/256 [00:07<00:00, 30.98it/s, est. speed input: 32538.06 toks/s, output: 31.78 toks/s]
Processed prompts:  98%|| 252/256 [00:07<00:00, 31.02it/s, est. speed input: 32527.18 toks/s, output: 31.76 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 33.20it/s, est. speed input: 32629.43 toks/s, output: 31.86 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 33.20it/s, est. speed input: 32629.43 toks/s, output: 31.86 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 31.86it/s, est. speed input: 32629.43 toks/s, output: 31.86 toks/s]
[rank0]:[W126 03:13:39.553456909 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 03:13:41
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:13:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:13:46 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=790577) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=790577) WARNING 01-26 03:14:06 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 29.18 requests/s, 29914.11 total tokens/s, 29.18 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 03:13:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:13:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:13:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:13:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:13:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:13:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:13:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:13:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:13:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:13:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:13:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:13:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:13:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:13:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:13:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:13:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:13:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:13:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:13:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=790577) [2026-01-26 03:13:50] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=790577) [2026-01-26 03:13:50] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=790577) [2026-01-26 03:13:50] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=790577) [2026-01-26 03:13:50] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=790577) [2026-01-26 03:13:50] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=790577) [2026-01-26 03:13:50] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=790577) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=790577) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.20s/it]
(EngineCore_DP0 pid=790577) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.20s/it]
(EngineCore_DP0 pid=790577) 
(EngineCore_DP0 pid=790577) [2026-01-26 03:14:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=790577) [2026-01-26 03:14:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=790577) [2026-01-26 03:14:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=790577) [2026-01-26 03:14:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=790577) [2026-01-26 03:14:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=790577) [2026-01-26 03:14:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=790577) [2026-01-26 03:14:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=790577) [2026-01-26 03:14:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=790577) 2026-01-26 03:14:05,882 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=790577) 2026-01-26 03:14:05,920 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  13%|        | 65/512 [00:00<00:00, 646.76it/s]
Adding requests:  25%|       | 130/512 [00:00<00:00, 611.99it/s]
Adding requests:  38%|      | 192/512 [00:00<00:00, 579.59it/s]
Adding requests:  49%|     | 252/512 [00:00<00:00, 583.25it/s]
Adding requests:  61%|    | 311/512 [00:00<00:00, 572.77it/s]
Adding requests:  72%|  | 369/512 [00:00<00:00, 573.36it/s]
Adding requests:  83%| | 427/512 [00:00<00:00, 549.47it/s]
Adding requests:  94%|| 483/512 [00:00<00:00, 542.11it/s]
Adding requests: 100%|| 512/512 [00:00<00:00, 562.13it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|         | 22/512 [00:00<00:03, 150.74it/s, est. speed input: 154386.93 toks/s, output: 150.75 toks/s]
Processed prompts:   7%|         | 38/512 [00:00<00:09, 48.24it/s, est. speed input: 56015.30 toks/s, output: 54.70 toks/s]   
Processed prompts:   9%|         | 46/512 [00:00<00:11, 41.27it/s, est. speed input: 48785.54 toks/s, output: 47.64 toks/s]
Processed prompts:  10%|         | 52/512 [00:01<00:10, 41.87it/s, est. speed input: 48343.36 toks/s, output: 47.21 toks/s]
Processed prompts:  11%|        | 58/512 [00:01<00:13, 34.56it/s, est. speed input: 43335.49 toks/s, output: 42.32 toks/s]
Processed prompts:  12%|        | 63/512 [00:01<00:12, 34.89it/s, est. speed input: 42748.39 toks/s, output: 41.75 toks/s]
Processed prompts:  13%|        | 67/512 [00:01<00:13, 33.73it/s, est. speed input: 41755.98 toks/s, output: 40.78 toks/s]
Processed prompts:  14%|        | 71/512 [00:01<00:13, 32.77it/s, est. speed input: 40911.82 toks/s, output: 39.95 toks/s]
Processed prompts:  15%|        | 75/512 [00:01<00:13, 31.89it/s, est. speed input: 40144.84 toks/s, output: 39.20 toks/s]
Processed prompts:  15%|        | 79/512 [00:02<00:13, 31.34it/s, est. speed input: 39518.70 toks/s, output: 38.59 toks/s]
Processed prompts:  16%|        | 83/512 [00:02<00:13, 30.84it/s, est. speed input: 38944.38 toks/s, output: 38.03 toks/s]
Processed prompts:  17%|        | 87/512 [00:02<00:13, 30.49it/s, est. speed input: 38441.57 toks/s, output: 37.54 toks/s]
Processed prompts:  18%|        | 91/512 [00:02<00:13, 30.31it/s, est. speed input: 38013.60 toks/s, output: 37.12 toks/s]
Processed prompts:  19%|        | 95/512 [00:02<00:14, 29.72it/s, est. speed input: 37525.66 toks/s, output: 36.65 toks/s]
Processed prompts:  19%|        | 98/512 [00:02<00:14, 27.60it/s, est. speed input: 36811.86 toks/s, output: 35.95 toks/s]
Processed prompts:  20%|        | 102/512 [00:02<00:14, 28.24it/s, est. speed input: 36513.71 toks/s, output: 35.66 toks/s]
Processed prompts:  21%|        | 106/512 [00:02<00:14, 28.64it/s, est. speed input: 36233.75 toks/s, output: 35.38 toks/s]
Processed prompts:  21%|       | 110/512 [00:03<00:13, 29.16it/s, est. speed input: 36019.43 toks/s, output: 35.17 toks/s]
Processed prompts:  22%|       | 114/512 [00:03<00:13, 29.42it/s, est. speed input: 35805.44 toks/s, output: 34.97 toks/s]
Processed prompts:  23%|       | 118/512 [00:03<00:13, 29.60it/s, est. speed input: 35606.26 toks/s, output: 34.77 toks/s]
Processed prompts:  24%|       | 122/512 [00:03<00:13, 29.58it/s, est. speed input: 35400.61 toks/s, output: 34.57 toks/s]
Processed prompts:  25%|       | 126/512 [00:03<00:13, 29.30it/s, est. speed input: 35171.09 toks/s, output: 34.35 toks/s]
Processed prompts:  25%|       | 130/512 [00:03<00:12, 29.58it/s, est. speed input: 35024.86 toks/s, output: 34.20 toks/s]
Processed prompts:  26%|       | 134/512 [00:03<00:12, 29.70it/s, est. speed input: 34878.57 toks/s, output: 34.06 toks/s]
Processed prompts:  27%|       | 138/512 [00:04<00:12, 29.53it/s, est. speed input: 34708.51 toks/s, output: 33.89 toks/s]
Processed prompts:  28%|       | 142/512 [00:04<00:12, 29.51it/s, est. speed input: 34562.31 toks/s, output: 33.75 toks/s]
Processed prompts:  29%|       | 146/512 [00:04<00:12, 29.55it/s, est. speed input: 34431.20 toks/s, output: 33.62 toks/s]
Processed prompts:  29%|       | 150/512 [00:04<00:12, 29.38it/s, est. speed input: 34285.42 toks/s, output: 33.48 toks/s]
Processed prompts:  30%|       | 154/512 [00:04<00:12, 29.40it/s, est. speed input: 34163.77 toks/s, output: 33.36 toks/s]
Processed prompts:  31%|       | 158/512 [00:04<00:12, 29.02it/s, est. speed input: 34004.51 toks/s, output: 33.21 toks/s]
Processed prompts:  32%|      | 162/512 [00:04<00:12, 29.12it/s, est. speed input: 33895.22 toks/s, output: 33.10 toks/s]
Processed prompts:  32%|      | 166/512 [00:05<00:11, 29.41it/s, est. speed input: 33813.80 toks/s, output: 33.02 toks/s]
Processed prompts:  33%|      | 170/512 [00:05<00:11, 29.38it/s, est. speed input: 33713.85 toks/s, output: 32.92 toks/s]
Processed prompts:  34%|      | 174/512 [00:05<00:11, 29.51it/s, est. speed input: 33633.17 toks/s, output: 32.84 toks/s]
Processed prompts:  35%|      | 178/512 [00:05<00:11, 29.75it/s, est. speed input: 33570.53 toks/s, output: 32.78 toks/s]
Processed prompts:  36%|      | 182/512 [00:05<00:11, 29.56it/s, est. speed input: 33478.04 toks/s, output: 32.69 toks/s]
Processed prompts:  36%|      | 186/512 [00:05<00:11, 29.44it/s, est. speed input: 33390.74 toks/s, output: 32.61 toks/s]
Processed prompts:  37%|      | 190/512 [00:05<00:10, 29.43it/s, est. speed input: 33314.80 toks/s, output: 32.53 toks/s]
Processed prompts:  38%|      | 194/512 [00:05<00:10, 29.45it/s, est. speed input: 33244.30 toks/s, output: 32.47 toks/s]
Processed prompts:  39%|      | 198/512 [00:06<00:10, 29.61it/s, est. speed input: 33188.83 toks/s, output: 32.41 toks/s]
Processed prompts:  39%|      | 202/512 [00:06<00:10, 29.61it/s, est. speed input: 33126.93 toks/s, output: 32.35 toks/s]
Processed prompts:  40%|      | 206/512 [00:06<00:10, 29.70it/s, est. speed input: 33074.54 toks/s, output: 32.30 toks/s]
Processed prompts:  41%|      | 210/512 [00:06<00:10, 29.55it/s, est. speed input: 33007.77 toks/s, output: 32.23 toks/s]
Processed prompts:  42%|     | 214/512 [00:06<00:10, 29.62it/s, est. speed input: 32957.21 toks/s, output: 32.18 toks/s]
Processed prompts:  43%|     | 218/512 [00:06<00:10, 29.31it/s, est. speed input: 32882.11 toks/s, output: 32.11 toks/s]
Processed prompts:  43%|     | 222/512 [00:06<00:09, 29.51it/s, est. speed input: 32839.89 toks/s, output: 32.07 toks/s]
Processed prompts:  44%|     | 226/512 [00:07<00:09, 29.78it/s, est. speed input: 32808.51 toks/s, output: 32.04 toks/s]
Processed prompts:  45%|     | 230/512 [00:07<00:09, 29.77it/s, est. speed input: 32764.87 toks/s, output: 32.00 toks/s]
Processed prompts:  46%|     | 234/512 [00:07<00:09, 29.69it/s, est. speed input: 32717.55 toks/s, output: 31.95 toks/s]
Processed prompts:  46%|     | 238/512 [00:07<00:09, 29.81it/s, est. speed input: 32683.46 toks/s, output: 31.92 toks/s]
Processed prompts:  47%|     | 242/512 [00:07<00:09, 29.63it/s, est. speed input: 32633.99 toks/s, output: 31.87 toks/s]
Processed prompts:  48%|     | 246/512 [00:07<00:08, 29.58it/s, est. speed input: 32590.48 toks/s, output: 31.83 toks/s]
Processed prompts:  49%|     | 250/512 [00:07<00:08, 29.27it/s, est. speed input: 32531.14 toks/s, output: 31.77 toks/s]
Processed prompts:  50%|     | 254/512 [00:08<00:08, 29.32it/s, est. speed input: 32490.64 toks/s, output: 31.73 toks/s]
Processed prompts:  50%|     | 258/512 [00:08<00:08, 29.28it/s, est. speed input: 32446.51 toks/s, output: 31.69 toks/s]
Processed prompts:  51%|     | 262/512 [00:08<00:08, 29.23it/s, est. speed input: 32403.42 toks/s, output: 31.64 toks/s]
Processed prompts:  52%|    | 266/512 [00:08<00:08, 29.35it/s, est. speed input: 32370.29 toks/s, output: 31.61 toks/s]
Processed prompts:  53%|    | 270/512 [00:08<00:08, 29.51it/s, est. speed input: 32342.65 toks/s, output: 31.58 toks/s]
Processed prompts:  54%|    | 274/512 [00:08<00:08, 29.58it/s, est. speed input: 32313.57 toks/s, output: 31.56 toks/s]
Processed prompts:  54%|    | 278/512 [00:08<00:07, 29.68it/s, est. speed input: 32287.78 toks/s, output: 31.53 toks/s]
Processed prompts:  55%|    | 282/512 [00:08<00:07, 29.35it/s, est. speed input: 32241.39 toks/s, output: 31.49 toks/s]
Processed prompts:  56%|    | 286/512 [00:09<00:07, 29.64it/s, est. speed input: 32223.95 toks/s, output: 31.47 toks/s]
Processed prompts:  57%|    | 290/512 [00:09<00:07, 29.65it/s, est. speed input: 32197.04 toks/s, output: 31.44 toks/s]
Processed prompts:  57%|    | 294/512 [00:09<00:07, 29.64it/s, est. speed input: 32170.25 toks/s, output: 31.42 toks/s]
Processed prompts:  58%|    | 298/512 [00:09<00:07, 29.54it/s, est. speed input: 32139.35 toks/s, output: 31.39 toks/s]
Processed prompts:  59%|    | 302/512 [00:09<00:07, 29.61it/s, est. speed input: 32116.43 toks/s, output: 31.36 toks/s]
Processed prompts:  60%|    | 306/512 [00:09<00:06, 29.45it/s, est. speed input: 32083.36 toks/s, output: 31.33 toks/s]
Processed prompts:  61%|    | 310/512 [00:09<00:06, 29.63it/s, est. speed input: 32065.81 toks/s, output: 31.31 toks/s]
Processed prompts:  61%|   | 314/512 [00:10<00:06, 29.27it/s, est. speed input: 32024.81 toks/s, output: 31.27 toks/s]
Processed prompts:  62%|   | 318/512 [00:10<00:06, 29.43it/s, est. speed input: 32005.36 toks/s, output: 31.26 toks/s]
Processed prompts:  63%|   | 322/512 [00:10<00:06, 29.42it/s, est. speed input: 31980.26 toks/s, output: 31.23 toks/s]
Processed prompts:  64%|   | 326/512 [00:10<00:06, 29.61it/s, est. speed input: 31965.05 toks/s, output: 31.22 toks/s]
Processed prompts:  64%|   | 330/512 [00:10<00:06, 29.39it/s, est. speed input: 31933.79 toks/s, output: 31.19 toks/s]
Processed prompts:  65%|   | 334/512 [00:10<00:06, 29.35it/s, est. speed input: 31908.62 toks/s, output: 31.16 toks/s]
Processed prompts:  66%|   | 338/512 [00:10<00:05, 29.59it/s, est. speed input: 31895.91 toks/s, output: 31.15 toks/s]
Processed prompts:  67%|   | 342/512 [00:10<00:05, 30.52it/s, est. speed input: 31916.27 toks/s, output: 31.17 toks/s]
Processed prompts:  68%|   | 346/512 [00:11<00:05, 29.83it/s, est. speed input: 31879.34 toks/s, output: 31.13 toks/s]
Processed prompts:  68%|   | 350/512 [00:11<00:05, 29.65it/s, est. speed input: 31855.78 toks/s, output: 31.11 toks/s]
Processed prompts:  69%|   | 354/512 [00:11<00:05, 29.65it/s, est. speed input: 31838.28 toks/s, output: 31.09 toks/s]
Processed prompts:  70%|   | 358/512 [00:11<00:05, 29.59it/s, est. speed input: 31818.53 toks/s, output: 31.07 toks/s]
Processed prompts:  71%|   | 362/512 [00:11<00:05, 29.74it/s, est. speed input: 31807.02 toks/s, output: 31.06 toks/s]
Processed prompts:  71%|  | 366/512 [00:11<00:04, 29.65it/s, est. speed input: 31787.61 toks/s, output: 31.04 toks/s]
Processed prompts:  72%|  | 370/512 [00:11<00:04, 29.53it/s, est. speed input: 31766.63 toks/s, output: 31.02 toks/s]
Processed prompts:  73%|  | 374/512 [00:12<00:04, 29.48it/s, est. speed input: 31747.43 toks/s, output: 31.00 toks/s]
Processed prompts:  74%|  | 378/512 [00:12<00:04, 29.41it/s, est. speed input: 31727.43 toks/s, output: 30.98 toks/s]
Processed prompts:  75%|  | 382/512 [00:12<00:04, 29.54it/s, est. speed input: 31714.73 toks/s, output: 30.97 toks/s]
Processed prompts:  75%|  | 386/512 [00:12<00:04, 29.49it/s, est. speed input: 31696.89 toks/s, output: 30.95 toks/s]
Processed prompts:  76%|  | 390/512 [00:12<00:04, 29.50it/s, est. speed input: 31681.10 toks/s, output: 30.94 toks/s]
Processed prompts:  77%|  | 394/512 [00:12<00:04, 29.44it/s, est. speed input: 31663.29 toks/s, output: 30.92 toks/s]
Processed prompts:  78%|  | 398/512 [00:12<00:03, 29.38it/s, est. speed input: 31645.11 toks/s, output: 30.90 toks/s]
Processed prompts:  79%|  | 402/512 [00:13<00:03, 29.55it/s, est. speed input: 31635.11 toks/s, output: 30.89 toks/s]
Processed prompts:  79%|  | 406/512 [00:13<00:03, 29.11it/s, est. speed input: 31604.45 toks/s, output: 30.86 toks/s]
Processed prompts:  80%|  | 410/512 [00:13<00:03, 29.31it/s, est. speed input: 31593.27 toks/s, output: 30.85 toks/s]
Processed prompts:  81%|  | 414/512 [00:13<00:03, 29.61it/s, est. speed input: 31588.18 toks/s, output: 30.85 toks/s]
Processed prompts:  82%| | 418/512 [00:13<00:03, 29.57it/s, est. speed input: 31574.00 toks/s, output: 30.83 toks/s]
Processed prompts:  82%| | 422/512 [00:13<00:03, 29.67it/s, est. speed input: 31564.85 toks/s, output: 30.83 toks/s]
Processed prompts:  83%| | 426/512 [00:13<00:02, 29.60it/s, est. speed input: 31550.83 toks/s, output: 30.81 toks/s]
Processed prompts:  84%| | 430/512 [00:13<00:02, 29.67it/s, est. speed input: 31541.16 toks/s, output: 30.80 toks/s]
Processed prompts:  85%| | 434/512 [00:14<00:02, 29.68it/s, est. speed input: 31530.50 toks/s, output: 30.79 toks/s]
Processed prompts:  86%| | 438/512 [00:14<00:02, 29.17it/s, est. speed input: 31502.37 toks/s, output: 30.76 toks/s]
Processed prompts:  86%| | 442/512 [00:14<00:02, 29.18it/s, est. speed input: 31487.17 toks/s, output: 30.75 toks/s]
Processed prompts:  87%| | 446/512 [00:14<00:02, 29.23it/s, est. speed input: 31473.50 toks/s, output: 30.74 toks/s]
Processed prompts:  88%| | 450/512 [00:14<00:02, 30.60it/s, est. speed input: 31503.01 toks/s, output: 30.76 toks/s]
Processed prompts:  89%| | 454/512 [00:14<00:01, 30.20it/s, est. speed input: 31489.21 toks/s, output: 30.75 toks/s]
Processed prompts:  89%| | 458/512 [00:14<00:01, 30.13it/s, est. speed input: 31482.18 toks/s, output: 30.74 toks/s]
Processed prompts:  90%| | 462/512 [00:15<00:01, 30.07it/s, est. speed input: 31474.63 toks/s, output: 30.74 toks/s]
Processed prompts:  91%| | 466/512 [00:15<00:01, 30.01it/s, est. speed input: 31466.82 toks/s, output: 30.73 toks/s]
Processed prompts:  92%|| 470/512 [00:15<00:01, 29.57it/s, est. speed input: 31446.78 toks/s, output: 30.71 toks/s]
Processed prompts:  93%|| 474/512 [00:15<00:01, 29.76it/s, est. speed input: 31442.62 toks/s, output: 30.71 toks/s]
Processed prompts:  93%|| 478/512 [00:15<00:01, 29.80it/s, est. speed input: 31435.50 toks/s, output: 30.70 toks/s]
Processed prompts:  94%|| 482/512 [00:15<00:01, 29.67it/s, est. speed input: 31423.82 toks/s, output: 30.69 toks/s]
Processed prompts:  95%|| 486/512 [00:15<00:00, 29.78it/s, est. speed input: 31418.10 toks/s, output: 30.68 toks/s]
Processed prompts:  96%|| 490/512 [00:15<00:00, 29.76it/s, est. speed input: 31409.74 toks/s, output: 30.67 toks/s]
Processed prompts:  96%|| 494/512 [00:16<00:00, 29.82it/s, est. speed input: 31403.70 toks/s, output: 30.67 toks/s]
Processed prompts:  97%|| 498/512 [00:16<00:00, 29.69it/s, est. speed input: 31392.65 toks/s, output: 30.66 toks/s]
Processed prompts:  98%|| 502/512 [00:16<00:00, 29.30it/s, est. speed input: 31373.21 toks/s, output: 30.64 toks/s]
Processed prompts:  99%|| 506/512 [00:16<00:00, 29.39it/s, est. speed input: 31364.56 toks/s, output: 30.63 toks/s]
Processed prompts: 100%|| 510/512 [00:16<00:00, 31.09it/s, est. speed input: 31400.84 toks/s, output: 30.66 toks/s]
Processed prompts: 100%|| 512/512 [00:16<00:00, 31.09it/s, est. speed input: 31523.79 toks/s, output: 30.78 toks/s]
Processed prompts: 100%|| 512/512 [00:16<00:00, 30.78it/s, est. speed input: 31523.79 toks/s, output: 30.78 toks/s]
[rank0]:[W126 03:14:24.480583681 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 03:14:26
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:14:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:14:32 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=791418) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=791418) WARNING 01-26 03:14:53 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 29.28 requests/s, 30008.17 total tokens/s, 29.28 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 03:14:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:14:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:14:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:14:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:14:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:14:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:14:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:14:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:14:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:14:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:14:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:14:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:14:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:14:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:14:36] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:14:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:14:36] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:14:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:14:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:14:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:14:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:14:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:14:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:14:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:14:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:14:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:14:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:14:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=791418) [2026-01-26 03:14:37] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=791418) [2026-01-26 03:14:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=791418) [2026-01-26 03:14:37] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=791418) [2026-01-26 03:14:37] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=791418) [2026-01-26 03:14:37] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=791418) [2026-01-26 03:14:37] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=791418) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=791418) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.22s/it]
(EngineCore_DP0 pid=791418) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.22s/it]
(EngineCore_DP0 pid=791418) 
(EngineCore_DP0 pid=791418) [2026-01-26 03:14:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=791418) [2026-01-26 03:14:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=791418) [2026-01-26 03:14:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=791418) [2026-01-26 03:14:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=791418) [2026-01-26 03:14:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=791418) [2026-01-26 03:14:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=791418) [2026-01-26 03:14:46] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=791418) [2026-01-26 03:14:46] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=791418) 2026-01-26 03:14:52,404 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=791418) 2026-01-26 03:14:52,455 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   6%|         | 60/1024 [00:00<00:01, 594.51it/s]
Adding requests:  12%|        | 120/1024 [00:00<00:01, 574.82it/s]
Adding requests:  17%|        | 178/1024 [00:00<00:01, 538.39it/s]
Adding requests:  23%|       | 233/1024 [00:00<00:01, 540.15it/s]
Adding requests:  28%|       | 288/1024 [00:00<00:01, 525.86it/s]
Adding requests:  33%|      | 341/1024 [00:00<00:01, 525.28it/s]
Adding requests:  39%|      | 396/1024 [00:00<00:01, 530.94it/s]
Adding requests:  44%|     | 450/1024 [00:00<00:01, 527.21it/s]
Adding requests:  49%|     | 503/1024 [00:00<00:01, 520.94it/s]
Adding requests:  54%|    | 556/1024 [00:01<00:00, 500.48it/s]
Adding requests:  59%|    | 607/1024 [00:01<00:00, 502.23it/s]
Adding requests:  64%|   | 659/1024 [00:01<00:00, 507.36it/s]
Adding requests:  70%|   | 712/1024 [00:01<00:00, 512.76it/s]
Adding requests:  75%|  | 764/1024 [00:01<00:00, 510.82it/s]
Adding requests:  80%|  | 816/1024 [00:01<00:00, 505.28it/s]
Adding requests:  85%| | 867/1024 [00:01<00:00, 506.12it/s]
Adding requests:  90%| | 923/1024 [00:01<00:00, 519.67it/s]
Adding requests:  95%|| 976/1024 [00:01<00:00, 519.87it/s]
Adding requests: 100%|| 1024/1024 [00:01<00:00, 521.39it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 50/1024 [00:00<00:02, 464.72it/s, est. speed input: 475991.59 toks/s, output: 464.77 toks/s]
Processed prompts:   9%|         | 97/1024 [00:01<00:16, 57.14it/s, est. speed input: 67689.05 toks/s, output: 66.10 toks/s]   
Processed prompts:  12%|        | 119/1024 [00:02<00:20, 43.55it/s, est. speed input: 53301.25 toks/s, output: 52.05 toks/s]
Processed prompts:  13%|        | 132/1024 [00:02<00:23, 37.68it/s, est. speed input: 47768.19 toks/s, output: 46.65 toks/s]
Processed prompts:  14%|        | 141/1024 [00:03<00:23, 36.92it/s, est. speed input: 46581.24 toks/s, output: 45.49 toks/s]
Processed prompts:  14%|        | 148/1024 [00:03<00:25, 34.54it/s, est. speed input: 44879.60 toks/s, output: 43.83 toks/s]
Processed prompts:  15%|        | 154/1024 [00:03<00:27, 31.76it/s, est. speed input: 43219.17 toks/s, output: 42.21 toks/s]
Processed prompts:  16%|        | 162/1024 [00:03<00:27, 31.14it/s, est. speed input: 42286.95 toks/s, output: 41.30 toks/s]
Processed prompts:  17%|        | 170/1024 [00:04<00:27, 30.71it/s, est. speed input: 41501.71 toks/s, output: 40.53 toks/s]
Processed prompts:  17%|        | 178/1024 [00:04<00:27, 30.36it/s, est. speed input: 40809.68 toks/s, output: 39.85 toks/s]
Processed prompts:  18%|        | 186/1024 [00:04<00:27, 30.09it/s, est. speed input: 40191.19 toks/s, output: 39.25 toks/s]
Processed prompts:  19%|        | 194/1024 [00:05<00:27, 29.96it/s, est. speed input: 39660.46 toks/s, output: 38.73 toks/s]
Processed prompts:  20%|        | 202/1024 [00:05<00:27, 29.71it/s, est. speed input: 39148.45 toks/s, output: 38.23 toks/s]
Processed prompts:  21%|        | 210/1024 [00:05<00:27, 29.65it/s, est. speed input: 38711.19 toks/s, output: 37.80 toks/s]
Processed prompts:  21%|       | 218/1024 [00:05<00:27, 29.61it/s, est. speed input: 38316.08 toks/s, output: 37.42 toks/s]
Processed prompts:  22%|       | 226/1024 [00:06<00:26, 29.65it/s, est. speed input: 37970.56 toks/s, output: 37.08 toks/s]
Processed prompts:  23%|       | 234/1024 [00:06<00:26, 29.39it/s, est. speed input: 37600.73 toks/s, output: 36.72 toks/s]
Processed prompts:  24%|       | 242/1024 [00:06<00:26, 29.45it/s, est. speed input: 37303.82 toks/s, output: 36.43 toks/s]
Processed prompts:  24%|       | 250/1024 [00:06<00:26, 29.46it/s, est. speed input: 37023.58 toks/s, output: 36.16 toks/s]
Processed prompts:  25%|       | 258/1024 [00:07<00:25, 29.53it/s, est. speed input: 36776.55 toks/s, output: 35.91 toks/s]
Processed prompts:  26%|       | 266/1024 [00:07<00:25, 29.40it/s, est. speed input: 36519.25 toks/s, output: 35.66 toks/s]
Processed prompts:  27%|       | 274/1024 [00:07<00:25, 29.55it/s, est. speed input: 36315.60 toks/s, output: 35.46 toks/s]
Processed prompts:  28%|       | 282/1024 [00:07<00:25, 29.56it/s, est. speed input: 36111.36 toks/s, output: 35.26 toks/s]
Processed prompts:  28%|       | 290/1024 [00:08<00:24, 29.53it/s, est. speed input: 35916.58 toks/s, output: 35.07 toks/s]
Processed prompts:  29%|       | 298/1024 [00:08<00:24, 29.35it/s, est. speed input: 35712.58 toks/s, output: 34.88 toks/s]
Processed prompts:  30%|       | 306/1024 [00:08<00:24, 29.38it/s, est. speed input: 35541.65 toks/s, output: 34.71 toks/s]
Processed prompts:  31%|       | 314/1024 [00:09<00:24, 29.37it/s, est. speed input: 35377.07 toks/s, output: 34.55 toks/s]
Processed prompts:  31%|      | 322/1024 [00:09<00:23, 29.38it/s, est. speed input: 35224.46 toks/s, output: 34.40 toks/s]
Processed prompts:  32%|      | 330/1024 [00:09<00:23, 29.33it/s, est. speed input: 35073.12 toks/s, output: 34.25 toks/s]
Processed prompts:  33%|      | 338/1024 [00:09<00:22, 29.87it/s, est. speed input: 34992.42 toks/s, output: 34.17 toks/s]
Processed prompts:  34%|      | 346/1024 [00:10<00:22, 29.74it/s, est. speed input: 34862.38 toks/s, output: 34.05 toks/s]
Processed prompts:  35%|      | 354/1024 [00:10<00:22, 29.63it/s, est. speed input: 34737.96 toks/s, output: 33.92 toks/s]
Processed prompts:  35%|      | 362/1024 [00:10<00:22, 29.38it/s, est. speed input: 34601.92 toks/s, output: 33.79 toks/s]
Processed prompts:  36%|      | 370/1024 [00:10<00:22, 29.40it/s, est. speed input: 34492.03 toks/s, output: 33.68 toks/s]
Processed prompts:  37%|      | 378/1024 [00:11<00:21, 29.49it/s, est. speed input: 34394.66 toks/s, output: 33.59 toks/s]
Processed prompts:  38%|      | 386/1024 [00:11<00:21, 29.51it/s, est. speed input: 34297.93 toks/s, output: 33.49 toks/s]
Processed prompts:  38%|      | 394/1024 [00:11<00:21, 29.32it/s, est. speed input: 34186.99 toks/s, output: 33.39 toks/s]
Processed prompts:  39%|      | 402/1024 [00:12<00:21, 29.40it/s, est. speed input: 34099.97 toks/s, output: 33.30 toks/s]
Processed prompts:  40%|      | 410/1024 [00:12<00:20, 29.42it/s, est. speed input: 34013.32 toks/s, output: 33.22 toks/s]
Processed prompts:  41%|      | 418/1024 [00:12<00:20, 29.45it/s, est. speed input: 33932.00 toks/s, output: 33.14 toks/s]
Processed prompts:  42%|     | 426/1024 [00:12<00:20, 29.29it/s, est. speed input: 33839.24 toks/s, output: 33.05 toks/s]
Processed prompts:  42%|     | 434/1024 [00:13<00:20, 29.39it/s, est. speed input: 33767.19 toks/s, output: 32.98 toks/s]
Processed prompts:  43%|     | 442/1024 [00:13<00:19, 29.48it/s, est. speed input: 33699.73 toks/s, output: 32.91 toks/s]
Processed prompts:  44%|     | 450/1024 [00:13<00:18, 30.23it/s, est. speed input: 33685.40 toks/s, output: 32.90 toks/s]
Processed prompts:  45%|     | 458/1024 [00:13<00:18, 29.82it/s, est. speed input: 33604.37 toks/s, output: 32.82 toks/s]
Processed prompts:  46%|     | 466/1024 [00:14<00:18, 29.84it/s, est. speed input: 33547.81 toks/s, output: 32.76 toks/s]
Processed prompts:  46%|     | 474/1024 [00:14<00:18, 29.69it/s, est. speed input: 33482.13 toks/s, output: 32.70 toks/s]
Processed prompts:  47%|     | 482/1024 [00:14<00:18, 29.62it/s, est. speed input: 33420.88 toks/s, output: 32.64 toks/s]
Processed prompts:  48%|     | 490/1024 [00:15<00:18, 29.46it/s, est. speed input: 33354.75 toks/s, output: 32.57 toks/s]
Processed prompts:  49%|     | 498/1024 [00:15<00:17, 29.49it/s, est. speed input: 33300.19 toks/s, output: 32.52 toks/s]
Processed prompts:  49%|     | 506/1024 [00:15<00:17, 29.56it/s, est. speed input: 33250.76 toks/s, output: 32.47 toks/s]
Processed prompts:  50%|     | 514/1024 [00:15<00:17, 29.50it/s, est. speed input: 33196.12 toks/s, output: 32.42 toks/s]
Processed prompts:  51%|     | 522/1024 [00:16<00:17, 29.31it/s, est. speed input: 33134.16 toks/s, output: 32.36 toks/s]
Processed prompts:  52%|    | 530/1024 [00:16<00:16, 29.46it/s, est. speed input: 33091.10 toks/s, output: 32.32 toks/s]
Processed prompts:  53%|    | 538/1024 [00:16<00:16, 29.50it/s, est. speed input: 33046.26 toks/s, output: 32.27 toks/s]
Processed prompts:  53%|    | 546/1024 [00:16<00:16, 29.39it/s, est. speed input: 32993.84 toks/s, output: 32.22 toks/s]
Processed prompts:  54%|    | 554/1024 [00:17<00:15, 29.46it/s, est. speed input: 32952.56 toks/s, output: 32.18 toks/s]
Processed prompts:  55%|    | 562/1024 [00:17<00:15, 29.44it/s, est. speed input: 32908.15 toks/s, output: 32.14 toks/s]
Processed prompts:  56%|    | 570/1024 [00:17<00:15, 29.53it/s, est. speed input: 32870.94 toks/s, output: 32.10 toks/s]
Processed prompts:  56%|    | 578/1024 [00:18<00:15, 29.40it/s, est. speed input: 32824.28 toks/s, output: 32.05 toks/s]
Processed prompts:  57%|    | 586/1024 [00:18<00:14, 29.39it/s, est. speed input: 32783.43 toks/s, output: 32.02 toks/s]
Processed prompts:  58%|    | 594/1024 [00:18<00:14, 29.48it/s, est. speed input: 32748.53 toks/s, output: 31.98 toks/s]
Processed prompts:  59%|    | 602/1024 [00:18<00:14, 29.45it/s, est. speed input: 32710.24 toks/s, output: 31.94 toks/s]
Processed prompts:  60%|    | 610/1024 [00:19<00:14, 29.26it/s, est. speed input: 32663.80 toks/s, output: 31.90 toks/s]
Processed prompts:  60%|    | 618/1024 [00:19<00:13, 29.43it/s, est. speed input: 32634.55 toks/s, output: 31.87 toks/s]
Processed prompts:  61%|    | 626/1024 [00:19<00:13, 29.41it/s, est. speed input: 32598.84 toks/s, output: 31.83 toks/s]
Processed prompts:  62%|   | 634/1024 [00:19<00:13, 29.44it/s, est. speed input: 32566.62 toks/s, output: 31.80 toks/s]
Processed prompts:  63%|   | 642/1024 [00:20<00:13, 29.26it/s, est. speed input: 32525.28 toks/s, output: 31.76 toks/s]
Processed prompts:  63%|   | 650/1024 [00:20<00:12, 29.34it/s, est. speed input: 32494.78 toks/s, output: 31.73 toks/s]
Processed prompts:  64%|   | 658/1024 [00:20<00:12, 29.38it/s, est. speed input: 32464.65 toks/s, output: 31.70 toks/s]
Processed prompts:  65%|   | 666/1024 [00:21<00:12, 29.45it/s, est. speed input: 32436.89 toks/s, output: 31.68 toks/s]
Processed prompts:  66%|   | 674/1024 [00:21<00:11, 29.29it/s, est. speed input: 32400.63 toks/s, output: 31.64 toks/s]
Processed prompts:  67%|   | 682/1024 [00:21<00:11, 29.38it/s, est. speed input: 32374.29 toks/s, output: 31.62 toks/s]
Processed prompts:  67%|   | 690/1024 [00:21<00:11, 29.32it/s, est. speed input: 32342.73 toks/s, output: 31.58 toks/s]
Processed prompts:  68%|   | 698/1024 [00:22<00:11, 29.33it/s, est. speed input: 32314.94 toks/s, output: 31.56 toks/s]
Processed prompts:  69%|   | 706/1024 [00:22<00:10, 29.24it/s, est. speed input: 32282.86 toks/s, output: 31.53 toks/s]
Processed prompts:  70%|   | 714/1024 [00:22<00:10, 29.31it/s, est. speed input: 32257.63 toks/s, output: 31.50 toks/s]
Processed prompts:  71%|   | 722/1024 [00:22<00:10, 29.44it/s, est. speed input: 32236.87 toks/s, output: 31.48 toks/s]
Processed prompts:  71%|  | 730/1024 [00:23<00:09, 29.45it/s, est. speed input: 32212.57 toks/s, output: 31.46 toks/s]
Processed prompts:  72%|  | 738/1024 [00:23<00:09, 29.31it/s, est. speed input: 32183.14 toks/s, output: 31.43 toks/s]
Processed prompts:  73%|  | 746/1024 [00:23<00:09, 29.37it/s, est. speed input: 32160.56 toks/s, output: 31.41 toks/s]
Processed prompts:  74%|  | 754/1024 [00:24<00:09, 29.38it/s, est. speed input: 32137.25 toks/s, output: 31.38 toks/s]
Processed prompts:  74%|  | 762/1024 [00:24<00:08, 29.41it/s, est. speed input: 32115.66 toks/s, output: 31.36 toks/s]
Processed prompts:  75%|  | 770/1024 [00:24<00:08, 29.26it/s, est. speed input: 32087.27 toks/s, output: 31.34 toks/s]
Processed prompts:  76%|  | 778/1024 [00:24<00:08, 29.40it/s, est. speed input: 32069.64 toks/s, output: 31.32 toks/s]
Processed prompts:  77%|  | 786/1024 [00:25<00:08, 29.47it/s, est. speed input: 32051.06 toks/s, output: 31.30 toks/s]
Processed prompts:  78%|  | 794/1024 [00:25<00:07, 29.41it/s, est. speed input: 32028.63 toks/s, output: 31.28 toks/s]
Processed prompts:  78%|  | 802/1024 [00:25<00:07, 29.31it/s, est. speed input: 32004.70 toks/s, output: 31.25 toks/s]
Processed prompts:  79%|  | 810/1024 [00:25<00:07, 29.42it/s, est. speed input: 31987.90 toks/s, output: 31.24 toks/s]
Processed prompts:  80%|  | 818/1024 [00:26<00:06, 29.46it/s, est. speed input: 31970.05 toks/s, output: 31.22 toks/s]
Processed prompts:  81%|  | 826/1024 [00:26<00:06, 29.38it/s, est. speed input: 31948.59 toks/s, output: 31.20 toks/s]
Processed prompts:  81%| | 834/1024 [00:26<00:06, 29.18it/s, est. speed input: 31922.35 toks/s, output: 31.17 toks/s]
Processed prompts:  82%| | 842/1024 [00:27<00:06, 29.33it/s, est. speed input: 31907.08 toks/s, output: 31.16 toks/s]
Processed prompts:  83%| | 850/1024 [00:27<00:05, 29.40it/s, est. speed input: 31890.99 toks/s, output: 31.14 toks/s]
Processed prompts:  84%| | 858/1024 [00:27<00:05, 29.42it/s, est. speed input: 31874.13 toks/s, output: 31.13 toks/s]
Processed prompts:  85%| | 866/1024 [00:27<00:05, 29.35it/s, est. speed input: 31854.63 toks/s, output: 31.11 toks/s]
Processed prompts:  85%| | 874/1024 [00:28<00:05, 29.37it/s, est. speed input: 31837.86 toks/s, output: 31.09 toks/s]
Processed prompts:  86%| | 882/1024 [00:28<00:04, 29.41it/s, est. speed input: 31822.10 toks/s, output: 31.08 toks/s]
Processed prompts:  87%| | 890/1024 [00:28<00:04, 29.35it/s, est. speed input: 31803.84 toks/s, output: 31.06 toks/s]
Processed prompts:  88%| | 898/1024 [00:28<00:04, 29.33it/s, est. speed input: 31786.82 toks/s, output: 31.04 toks/s]
Processed prompts:  88%| | 906/1024 [00:29<00:04, 29.37it/s, est. speed input: 31771.60 toks/s, output: 31.03 toks/s]
Processed prompts:  89%| | 914/1024 [00:29<00:03, 29.39it/s, est. speed input: 31756.77 toks/s, output: 31.01 toks/s]
Processed prompts:  90%| | 922/1024 [00:29<00:03, 29.34it/s, est. speed input: 31739.99 toks/s, output: 31.00 toks/s]
Processed prompts:  91%| | 930/1024 [00:30<00:03, 29.40it/s, est. speed input: 31726.34 toks/s, output: 30.98 toks/s]
Processed prompts:  92%|| 938/1024 [00:30<00:03, 28.19it/s, est. speed input: 31671.06 toks/s, output: 30.93 toks/s]
Processed prompts:  92%|| 946/1024 [00:30<00:02, 28.19it/s, est. speed input: 31645.02 toks/s, output: 30.90 toks/s]
Processed prompts:  93%|| 954/1024 [00:30<00:02, 28.36it/s, est. speed input: 31625.51 toks/s, output: 30.88 toks/s]
Processed prompts:  94%|| 962/1024 [00:31<00:02, 28.66it/s, est. speed input: 31611.86 toks/s, output: 30.87 toks/s]
Processed prompts:  95%|| 970/1024 [00:31<00:01, 28.95it/s, est. speed input: 31601.22 toks/s, output: 30.86 toks/s]
Processed prompts:  96%|| 978/1024 [00:31<00:01, 29.17it/s, est. speed input: 31591.22 toks/s, output: 30.85 toks/s]
Processed prompts:  96%|| 986/1024 [00:31<00:01, 30.04it/s, est. speed input: 31602.66 toks/s, output: 30.86 toks/s]
Processed prompts:  97%|| 994/1024 [00:32<00:01, 29.85it/s, est. speed input: 31590.14 toks/s, output: 30.85 toks/s]
Processed prompts:  98%|| 1002/1024 [00:32<00:00, 29.85it/s, est. speed input: 31581.62 toks/s, output: 30.84 toks/s]
Processed prompts:  99%|| 1010/1024 [00:32<00:00, 29.75it/s, est. speed input: 31570.36 toks/s, output: 30.83 toks/s]
Processed prompts:  99%|| 1018/1024 [00:33<00:00, 30.32it/s, est. speed input: 31577.54 toks/s, output: 30.84 toks/s]
Processed prompts: 100%|| 1024/1024 [00:33<00:00, 30.32it/s, est. speed input: 31763.46 toks/s, output: 31.02 toks/s]
Processed prompts: 100%|| 1024/1024 [00:33<00:00, 31.02it/s, est. speed input: 31763.46 toks/s, output: 31.02 toks/s]
[rank0]:[W126 03:15:28.622804975 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 03:15:30
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:15:39 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:15:39 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=792531) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=792531) WARNING 01-26 03:16:00 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.97 requests/s, 29692.76 total tokens/s, 28.97 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 03:15:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:15:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:15:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:15:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:15:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:15:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:15:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:15:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:15:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:15:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:15:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:15:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:15:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:15:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:15:43] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:15:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:15:43] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:15:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:15:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:15:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:15:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:15:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:15:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:15:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:15:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:15:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:15:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:15:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=792531) [2026-01-26 03:15:44] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=792531) [2026-01-26 03:15:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=792531) [2026-01-26 03:15:44] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=792531) [2026-01-26 03:15:44] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=792531) [2026-01-26 03:15:44] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=792531) [2026-01-26 03:15:44] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=792531) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=792531) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.07s/it]
(EngineCore_DP0 pid=792531) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.07s/it]
(EngineCore_DP0 pid=792531) 
(EngineCore_DP0 pid=792531) [2026-01-26 03:15:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=792531) [2026-01-26 03:15:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=792531) [2026-01-26 03:15:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=792531) [2026-01-26 03:15:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=792531) [2026-01-26 03:15:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=792531) [2026-01-26 03:15:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=792531) [2026-01-26 03:15:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=792531) [2026-01-26 03:15:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=792531) 2026-01-26 03:15:59,548 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=792531) 2026-01-26 03:15:59,667 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 60/2048 [00:00<00:03, 592.86it/s]
Adding requests:   6%|         | 120/2048 [00:00<00:03, 574.92it/s]
Adding requests:   9%|         | 178/2048 [00:00<00:03, 533.33it/s]
Adding requests:  11%|        | 233/2048 [00:00<00:03, 536.54it/s]
Adding requests:  14%|        | 287/2048 [00:00<00:03, 534.33it/s]
Adding requests:  17%|        | 341/2048 [00:00<00:03, 532.96it/s]
Adding requests:  19%|        | 395/2048 [00:00<00:03, 533.46it/s]
Adding requests:  22%|       | 449/2048 [00:00<00:03, 527.06it/s]
Adding requests:  25%|       | 502/2048 [00:00<00:02, 520.34it/s]
Adding requests:  27%|       | 555/2048 [00:01<00:02, 516.49it/s]
Adding requests:  30%|       | 608/2048 [00:01<00:02, 519.90it/s]
Adding requests:  32%|      | 664/2048 [00:01<00:02, 530.33it/s]
Adding requests:  35%|      | 718/2048 [00:01<00:02, 527.70it/s]
Adding requests:  38%|      | 771/2048 [00:01<00:02, 526.00it/s]
Adding requests:  40%|      | 824/2048 [00:01<00:02, 516.15it/s]
Adding requests:  43%|     | 876/2048 [00:01<00:02, 501.01it/s]
Adding requests:  45%|     | 930/2048 [00:01<00:02, 510.77it/s]
Adding requests:  48%|     | 982/2048 [00:02<00:05, 195.03it/s]
Adding requests:  50%|     | 1034/2048 [00:02<00:04, 239.18it/s]
Adding requests:  53%|    | 1086/2048 [00:02<00:03, 284.71it/s]
Adding requests:  56%|    | 1138/2048 [00:02<00:02, 328.10it/s]
Adding requests:  58%|    | 1195/2048 [00:02<00:02, 377.83it/s]
Adding requests:  61%|    | 1248/2048 [00:02<00:01, 411.33it/s]
Adding requests:  63%|   | 1299/2048 [00:03<00:01, 429.96it/s]
Adding requests:  66%|   | 1352/2048 [00:03<00:01, 455.35it/s]
Adding requests:  69%|   | 1407/2048 [00:03<00:01, 479.02it/s]
Adding requests:  71%|  | 1460/2048 [00:03<00:01, 491.51it/s]
Adding requests:  74%|  | 1515/2048 [00:03<00:01, 506.33it/s]
Adding requests:  77%|  | 1568/2048 [00:03<00:00, 506.88it/s]
Adding requests:  79%|  | 1623/2048 [00:03<00:00, 517.30it/s]
Adding requests:  82%| | 1677/2048 [00:03<00:00, 523.29it/s]
Adding requests:  85%| | 1731/2048 [00:03<00:00, 522.93it/s]
Adding requests:  87%| | 1784/2048 [00:03<00:00, 520.13it/s]
Adding requests:  90%| | 1839/2048 [00:04<00:00, 526.77it/s]
Adding requests:  92%|| 1892/2048 [00:04<00:00, 519.27it/s]
Adding requests:  95%|| 1945/2048 [00:04<00:00, 515.27it/s]
Adding requests:  98%|| 1998/2048 [00:04<00:00, 518.69it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 458.19it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 114/2048 [00:00<00:02, 897.44it/s, est. speed input: 919083.80 toks/s, output: 897.47 toks/s]
Processed prompts:  10%|         | 204/2048 [00:02<00:31, 59.31it/s, est. speed input: 72005.45 toks/s, output: 70.32 toks/s]   
Processed prompts:  12%|        | 243/2048 [00:04<00:41, 43.13it/s, est. speed input: 54599.03 toks/s, output: 53.32 toks/s]
Processed prompts:  13%|        | 266/2048 [00:05<00:41, 42.83it/s, est. speed input: 53279.56 toks/s, output: 52.03 toks/s]
Processed prompts:  14%|        | 282/2048 [00:05<00:44, 40.06it/s, est. speed input: 50998.09 toks/s, output: 49.80 toks/s]
Processed prompts:  14%|        | 293/2048 [00:06<00:49, 35.45it/s, est. speed input: 48224.47 toks/s, output: 47.09 toks/s]
Processed prompts:  15%|        | 306/2048 [00:06<00:53, 32.63it/s, est. speed input: 46289.00 toks/s, output: 45.20 toks/s]
Processed prompts:  16%|        | 322/2048 [00:07<00:54, 31.62it/s, est. speed input: 45005.70 toks/s, output: 43.95 toks/s]
Processed prompts:  17%|        | 338/2048 [00:07<00:54, 31.13it/s, est. speed input: 44010.67 toks/s, output: 42.98 toks/s]
Processed prompts:  17%|        | 354/2048 [00:08<00:55, 30.39it/s, est. speed input: 43025.26 toks/s, output: 42.02 toks/s]
Processed prompts:  18%|        | 370/2048 [00:08<00:55, 30.02it/s, est. speed input: 42211.90 toks/s, output: 41.22 toks/s]
Processed prompts:  19%|        | 386/2048 [00:09<00:56, 29.67it/s, est. speed input: 41472.46 toks/s, output: 40.50 toks/s]
Processed prompts:  20%|        | 402/2048 [00:10<00:55, 29.53it/s, est. speed input: 40843.14 toks/s, output: 39.89 toks/s]
Processed prompts:  20%|        | 418/2048 [00:10<00:55, 29.32it/s, est. speed input: 40250.20 toks/s, output: 39.31 toks/s]
Processed prompts:  21%|        | 434/2048 [00:11<00:55, 29.21it/s, est. speed input: 39726.53 toks/s, output: 38.80 toks/s]
Processed prompts:  22%|       | 450/2048 [00:11<00:54, 29.42it/s, est. speed input: 39312.77 toks/s, output: 38.39 toks/s]
Processed prompts:  23%|       | 466/2048 [00:12<00:53, 29.34it/s, est. speed input: 38890.24 toks/s, output: 37.98 toks/s]
Processed prompts:  24%|       | 482/2048 [00:12<00:53, 29.22it/s, est. speed input: 38490.80 toks/s, output: 37.59 toks/s]
Processed prompts:  24%|       | 498/2048 [00:13<00:53, 29.13it/s, est. speed input: 38124.34 toks/s, output: 37.23 toks/s]
Processed prompts:  25%|       | 514/2048 [00:13<00:52, 29.04it/s, est. speed input: 37781.00 toks/s, output: 36.90 toks/s]
Processed prompts:  26%|       | 530/2048 [00:14<00:52, 29.04it/s, est. speed input: 37474.50 toks/s, output: 36.60 toks/s]
Processed prompts:  27%|       | 546/2048 [00:15<00:51, 28.92it/s, est. speed input: 37172.58 toks/s, output: 36.30 toks/s]
Processed prompts:  27%|       | 562/2048 [00:15<00:51, 28.87it/s, est. speed input: 36897.45 toks/s, output: 36.03 toks/s]
Processed prompts:  28%|       | 578/2048 [00:16<00:50, 28.92it/s, est. speed input: 36651.98 toks/s, output: 35.79 toks/s]
Processed prompts:  29%|       | 594/2048 [00:16<00:50, 28.89it/s, est. speed input: 36415.48 toks/s, output: 35.56 toks/s]
Processed prompts:  30%|       | 610/2048 [00:17<00:49, 28.97it/s, est. speed input: 36206.74 toks/s, output: 35.36 toks/s]
Processed prompts:  31%|       | 626/2048 [00:17<00:49, 28.88it/s, est. speed input: 35992.29 toks/s, output: 35.15 toks/s]
Processed prompts:  31%|      | 642/2048 [00:18<00:48, 28.96it/s, est. speed input: 35808.97 toks/s, output: 34.97 toks/s]
Processed prompts:  32%|      | 658/2048 [00:18<00:48, 28.87it/s, est. speed input: 35618.39 toks/s, output: 34.78 toks/s]
Processed prompts:  33%|      | 674/2048 [00:19<00:47, 28.98it/s, est. speed input: 35458.41 toks/s, output: 34.63 toks/s]
Processed prompts:  34%|      | 690/2048 [00:20<00:46, 28.96it/s, est. speed input: 35296.44 toks/s, output: 34.47 toks/s]
Processed prompts:  34%|      | 706/2048 [00:20<00:46, 28.97it/s, est. speed input: 35146.16 toks/s, output: 34.32 toks/s]
Processed prompts:  35%|      | 722/2048 [00:21<00:45, 28.94it/s, est. speed input: 34999.58 toks/s, output: 34.18 toks/s]
Processed prompts:  36%|      | 738/2048 [00:21<00:45, 28.93it/s, est. speed input: 34861.78 toks/s, output: 34.04 toks/s]
Processed prompts:  37%|      | 754/2048 [00:22<00:44, 28.87it/s, est. speed input: 34725.92 toks/s, output: 33.91 toks/s]
Processed prompts:  38%|      | 770/2048 [00:22<00:44, 28.94it/s, est. speed input: 34607.18 toks/s, output: 33.80 toks/s]
Processed prompts:  38%|      | 786/2048 [00:23<00:43, 28.91it/s, est. speed input: 34486.72 toks/s, output: 33.68 toks/s]
Processed prompts:  39%|      | 802/2048 [00:23<00:43, 28.94it/s, est. speed input: 34375.79 toks/s, output: 33.57 toks/s]
Processed prompts:  40%|      | 818/2048 [00:24<00:42, 28.87it/s, est. speed input: 34262.47 toks/s, output: 33.46 toks/s]
Processed prompts:  41%|      | 834/2048 [00:24<00:41, 28.93it/s, est. speed input: 34163.35 toks/s, output: 33.36 toks/s]
Processed prompts:  42%|     | 850/2048 [00:25<00:41, 28.83it/s, est. speed input: 34056.32 toks/s, output: 33.26 toks/s]
Processed prompts:  42%|     | 866/2048 [00:26<00:40, 28.92it/s, est. speed input: 33967.55 toks/s, output: 33.17 toks/s]
Processed prompts:  43%|     | 882/2048 [00:26<00:40, 28.89it/s, est. speed input: 33875.00 toks/s, output: 33.08 toks/s]
Processed prompts:  44%|     | 898/2048 [00:27<00:40, 28.43it/s, est. speed input: 33750.51 toks/s, output: 32.96 toks/s]
Processed prompts:  45%|     | 914/2048 [00:27<00:39, 28.52it/s, est. speed input: 33663.56 toks/s, output: 32.87 toks/s]
Processed prompts:  45%|     | 930/2048 [00:28<00:38, 29.17it/s, est. speed input: 33625.14 toks/s, output: 32.84 toks/s]
Processed prompts:  46%|     | 946/2048 [00:28<00:37, 29.01it/s, est. speed input: 33541.79 toks/s, output: 32.76 toks/s]
Processed prompts:  47%|     | 962/2048 [00:29<00:37, 28.92it/s, est. speed input: 33463.79 toks/s, output: 32.68 toks/s]
Processed prompts:  48%|     | 978/2048 [00:29<00:36, 29.40it/s, est. speed input: 33426.47 toks/s, output: 32.64 toks/s]
Processed prompts:  49%|     | 994/2048 [00:30<00:36, 29.25it/s, est. speed input: 33356.83 toks/s, output: 32.58 toks/s]
Processed prompts:  49%|     | 1010/2048 [00:31<00:35, 29.18it/s, est. speed input: 33292.23 toks/s, output: 32.51 toks/s]
Processed prompts:  50%|     | 1026/2048 [00:31<00:35, 29.06it/s, est. speed input: 33224.77 toks/s, output: 32.45 toks/s]
Processed prompts:  51%|     | 1042/2048 [00:32<00:34, 29.06it/s, est. speed input: 33165.94 toks/s, output: 32.39 toks/s]
Processed prompts:  52%|    | 1058/2048 [00:32<00:34, 28.95it/s, est. speed input: 33101.26 toks/s, output: 32.33 toks/s]
Processed prompts:  52%|    | 1074/2048 [00:33<00:33, 29.02it/s, est. speed input: 33048.52 toks/s, output: 32.27 toks/s]
Processed prompts:  53%|    | 1090/2048 [00:33<00:33, 28.92it/s, est. speed input: 32987.58 toks/s, output: 32.21 toks/s]
Processed prompts:  54%|    | 1106/2048 [00:34<00:32, 28.96it/s, est. speed input: 32935.70 toks/s, output: 32.16 toks/s]
Processed prompts:  55%|    | 1122/2048 [00:34<00:32, 28.87it/s, est. speed input: 32878.52 toks/s, output: 32.11 toks/s]
Processed prompts:  56%|    | 1138/2048 [00:35<00:31, 28.91it/s, est. speed input: 32829.10 toks/s, output: 32.06 toks/s]
Processed prompts:  56%|    | 1154/2048 [00:36<00:30, 29.38it/s, est. speed input: 32806.32 toks/s, output: 32.04 toks/s]
Processed prompts:  57%|    | 1170/2048 [00:36<00:29, 29.28it/s, est. speed input: 32760.03 toks/s, output: 31.99 toks/s]
Processed prompts:  58%|    | 1186/2048 [00:37<00:29, 29.13it/s, est. speed input: 32710.82 toks/s, output: 31.94 toks/s]
Processed prompts:  59%|    | 1202/2048 [00:37<00:29, 29.07it/s, est. speed input: 32665.79 toks/s, output: 31.90 toks/s]
Processed prompts:  59%|    | 1218/2048 [00:38<00:28, 28.97it/s, est. speed input: 32618.89 toks/s, output: 31.85 toks/s]
Processed prompts:  60%|    | 1234/2048 [00:38<00:28, 28.99it/s, est. speed input: 32577.78 toks/s, output: 31.81 toks/s]
Processed prompts:  61%|    | 1250/2048 [00:39<00:27, 28.93it/s, est. speed input: 32533.97 toks/s, output: 31.77 toks/s]
Processed prompts:  62%|   | 1266/2048 [00:39<00:26, 29.41it/s, est. speed input: 32518.44 toks/s, output: 31.76 toks/s]
Processed prompts:  63%|   | 1282/2048 [00:40<00:26, 29.21it/s, est. speed input: 32476.10 toks/s, output: 31.71 toks/s]
Processed prompts:  63%|   | 1298/2048 [00:40<00:25, 29.64it/s, est. speed input: 32462.73 toks/s, output: 31.70 toks/s]
Processed prompts:  64%|   | 1314/2048 [00:41<00:25, 29.36it/s, est. speed input: 32421.57 toks/s, output: 31.66 toks/s]
Processed prompts:  65%|   | 1330/2048 [00:42<00:24, 29.21it/s, est. speed input: 32384.03 toks/s, output: 31.62 toks/s]
Processed prompts:  66%|   | 1346/2048 [00:42<00:24, 29.10it/s, est. speed input: 32347.09 toks/s, output: 31.59 toks/s]
Processed prompts:  67%|   | 1362/2048 [00:43<00:23, 29.15it/s, est. speed input: 32317.04 toks/s, output: 31.56 toks/s]
Processed prompts:  67%|   | 1378/2048 [00:43<00:23, 29.07it/s, est. speed input: 32282.03 toks/s, output: 31.53 toks/s]
Processed prompts:  68%|   | 1394/2048 [00:44<00:22, 29.09it/s, est. speed input: 32251.97 toks/s, output: 31.50 toks/s]
Processed prompts:  69%|   | 1410/2048 [00:44<00:22, 28.97it/s, est. speed input: 32216.06 toks/s, output: 31.46 toks/s]
Processed prompts:  70%|   | 1426/2048 [00:45<00:21, 28.99it/s, est. speed input: 32185.93 toks/s, output: 31.43 toks/s]
Processed prompts:  70%|   | 1442/2048 [00:45<00:20, 28.88it/s, est. speed input: 32150.82 toks/s, output: 31.40 toks/s]
Processed prompts:  71%|   | 1458/2048 [00:46<00:20, 28.87it/s, est. speed input: 32119.94 toks/s, output: 31.37 toks/s]
Processed prompts:  72%|  | 1474/2048 [00:47<00:19, 28.90it/s, est. speed input: 32091.11 toks/s, output: 31.34 toks/s]
Processed prompts:  73%|  | 1490/2048 [00:47<00:19, 28.84it/s, est. speed input: 32059.51 toks/s, output: 31.31 toks/s]
Processed prompts:  74%|  | 1506/2048 [00:48<00:18, 28.85it/s, est. speed input: 32030.79 toks/s, output: 31.28 toks/s]
Processed prompts:  74%|  | 1522/2048 [00:48<00:18, 28.76it/s, est. speed input: 31998.80 toks/s, output: 31.25 toks/s]
Processed prompts:  75%|  | 1538/2048 [00:49<00:17, 28.83it/s, est. speed input: 31972.88 toks/s, output: 31.22 toks/s]
Processed prompts:  76%|  | 1554/2048 [00:49<00:17, 28.80it/s, est. speed input: 31944.29 toks/s, output: 31.20 toks/s]
Processed prompts:  77%|  | 1570/2048 [00:50<00:16, 28.83it/s, est. speed input: 31918.45 toks/s, output: 31.17 toks/s]
Processed prompts:  77%|  | 1586/2048 [00:50<00:15, 29.30it/s, est. speed input: 31910.99 toks/s, output: 31.16 toks/s]
Processed prompts:  78%|  | 1602/2048 [00:51<00:15, 29.18it/s, est. speed input: 31885.98 toks/s, output: 31.14 toks/s]
Processed prompts:  79%|  | 1618/2048 [00:52<00:14, 29.04it/s, est. speed input: 31859.55 toks/s, output: 31.11 toks/s]
Processed prompts:  80%|  | 1634/2048 [00:52<00:14, 29.02it/s, est. speed input: 31836.43 toks/s, output: 31.09 toks/s]
Processed prompts:  81%|  | 1650/2048 [00:53<00:13, 29.38it/s, est. speed input: 31828.02 toks/s, output: 31.08 toks/s]
Processed prompts:  81%| | 1666/2048 [00:53<00:13, 29.27it/s, est. speed input: 31806.36 toks/s, output: 31.06 toks/s]
Processed prompts:  82%| | 1682/2048 [00:54<00:12, 29.10it/s, est. speed input: 31781.41 toks/s, output: 31.04 toks/s]
Processed prompts:  83%| | 1698/2048 [00:54<00:12, 29.05it/s, est. speed input: 31759.90 toks/s, output: 31.02 toks/s]
Processed prompts:  84%| | 1714/2048 [00:55<00:11, 28.99it/s, est. speed input: 31737.59 toks/s, output: 30.99 toks/s]
Processed prompts:  84%| | 1730/2048 [00:55<00:10, 28.98it/s, est. speed input: 31716.96 toks/s, output: 30.97 toks/s]
Processed prompts:  85%| | 1746/2048 [00:56<00:10, 28.93it/s, est. speed input: 31695.16 toks/s, output: 30.95 toks/s]
Processed prompts:  86%| | 1762/2048 [00:56<00:09, 28.94it/s, est. speed input: 31675.32 toks/s, output: 30.93 toks/s]
Processed prompts:  87%| | 1778/2048 [00:57<00:09, 28.92it/s, est. speed input: 31655.08 toks/s, output: 30.91 toks/s]
Processed prompts:  88%| | 1794/2048 [00:58<00:08, 28.94it/s, est. speed input: 31636.38 toks/s, output: 30.89 toks/s]
Processed prompts:  88%| | 1810/2048 [00:58<00:08, 28.86it/s, est. speed input: 31614.71 toks/s, output: 30.87 toks/s]
Processed prompts:  89%| | 1826/2048 [00:59<00:07, 28.89it/s, est. speed input: 31596.27 toks/s, output: 30.86 toks/s]
Processed prompts:  90%| | 1842/2048 [00:59<00:07, 28.77it/s, est. speed input: 31573.47 toks/s, output: 30.83 toks/s]
Processed prompts:  91%| | 1858/2048 [01:00<00:06, 28.80it/s, est. speed input: 31555.03 toks/s, output: 30.82 toks/s]
Processed prompts:  92%|| 1874/2048 [01:00<00:05, 29.25it/s, est. speed input: 31550.93 toks/s, output: 30.81 toks/s]
Processed prompts:  92%|| 1890/2048 [01:01<00:05, 29.21it/s, est. speed input: 31535.56 toks/s, output: 30.80 toks/s]
Processed prompts:  93%|| 1906/2048 [01:01<00:04, 29.04it/s, est. speed input: 31515.58 toks/s, output: 30.78 toks/s]
Processed prompts:  94%|| 1922/2048 [01:02<00:04, 28.92it/s, est. speed input: 31496.18 toks/s, output: 30.76 toks/s]
Processed prompts:  95%|| 1938/2048 [01:03<00:03, 28.90it/s, est. speed input: 31478.88 toks/s, output: 30.74 toks/s]
Processed prompts:  95%|| 1954/2048 [01:03<00:03, 29.32it/s, est. speed input: 31475.50 toks/s, output: 30.74 toks/s]
Processed prompts:  96%|| 1970/2048 [01:04<00:02, 29.21it/s, est. speed input: 31459.83 toks/s, output: 30.72 toks/s]
Processed prompts:  97%|| 1986/2048 [01:04<00:02, 29.53it/s, est. speed input: 31456.42 toks/s, output: 30.72 toks/s]
Processed prompts:  98%|| 2002/2048 [01:05<00:01, 30.35it/s, est. speed input: 31469.88 toks/s, output: 30.73 toks/s]
Processed prompts:  99%|| 2018/2048 [01:05<00:01, 29.78it/s, est. speed input: 31450.46 toks/s, output: 30.71 toks/s]
Processed prompts:  99%|| 2034/2048 [01:06<00:00, 30.04it/s, est. speed input: 31450.13 toks/s, output: 30.71 toks/s]
Processed prompts: 100%|| 2048/2048 [01:06<00:00, 30.04it/s, est. speed input: 31666.46 toks/s, output: 30.92 toks/s]
Processed prompts: 100%|| 2048/2048 [01:06<00:00, 30.92it/s, est. speed input: 31666.46 toks/s, output: 30.92 toks/s]
[rank0]:[W126 03:17:11.949428737 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 03:17:14
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:17:28 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:17:28 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=794227) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=794227) WARNING 01-26 03:17:51 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 29.42 requests/s, 30150.89 total tokens/s, 29.42 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 03:17:28] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:17:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:17:28] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:17:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:17:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:17:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:17:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:17:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:17:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:17:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:17:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:17:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:17:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:17:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:17:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:17:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:17:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:17:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:17:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:17:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:17:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:17:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:17:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:17:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:17:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:17:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:17:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:17:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=794227) [2026-01-26 03:17:33] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=794227) [2026-01-26 03:17:33] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=794227) [2026-01-26 03:17:33] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=794227) [2026-01-26 03:17:33] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=794227) [2026-01-26 03:17:33] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=794227) [2026-01-26 03:17:33] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=794227) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=794227) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.08s/it]
(EngineCore_DP0 pid=794227) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.08s/it]
(EngineCore_DP0 pid=794227) 
(EngineCore_DP0 pid=794227) [2026-01-26 03:17:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=794227) [2026-01-26 03:17:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=794227) [2026-01-26 03:17:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=794227) [2026-01-26 03:17:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=794227) [2026-01-26 03:17:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=794227) [2026-01-26 03:17:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=794227) [2026-01-26 03:17:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=794227) [2026-01-26 03:17:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=794227) 2026-01-26 03:17:49,220 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=794227) 2026-01-26 03:17:49,523 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|         | 61/4096 [00:00<00:06, 609.85it/s]
Adding requests:   3%|         | 122/4096 [00:00<00:06, 586.98it/s]
Adding requests:   4%|         | 181/4096 [00:00<00:07, 555.14it/s]
Adding requests:   6%|         | 237/4096 [00:00<00:07, 543.04it/s]
Adding requests:   7%|         | 292/4096 [00:00<00:07, 537.97it/s]
Adding requests:   8%|         | 346/4096 [00:00<00:07, 519.03it/s]
Adding requests:  10%|         | 401/4096 [00:00<00:07, 524.75it/s]
Adding requests:  11%|         | 454/4096 [00:00<00:06, 522.20it/s]
Adding requests:  12%|        | 508/4096 [00:00<00:06, 522.43it/s]
Adding requests:  14%|        | 561/4096 [00:01<00:06, 520.18it/s]
Adding requests:  15%|        | 614/4096 [00:01<00:06, 522.04it/s]
Adding requests:  16%|        | 669/4096 [00:01<00:06, 529.06it/s]
Adding requests:  18%|        | 722/4096 [00:01<00:06, 527.95it/s]
Adding requests:  19%|        | 775/4096 [00:01<00:06, 523.45it/s]
Adding requests:  20%|        | 828/4096 [00:01<00:06, 519.28it/s]
Adding requests:  22%|       | 883/4096 [00:01<00:06, 527.32it/s]
Adding requests:  23%|       | 936/4096 [00:01<00:05, 527.94it/s]
Adding requests:  24%|       | 989/4096 [00:01<00:05, 521.46it/s]
Adding requests:  25%|       | 1043/4096 [00:01<00:05, 526.05it/s]
Adding requests:  27%|       | 1096/4096 [00:02<00:05, 526.09it/s]
Adding requests:  28%|       | 1150/4096 [00:02<00:05, 529.47it/s]
Adding requests:  29%|       | 1203/4096 [00:02<00:05, 516.09it/s]
Adding requests:  31%|       | 1255/4096 [00:02<00:05, 512.61it/s]
Adding requests:  32%|      | 1307/4096 [00:02<00:05, 504.93it/s]
Adding requests:  33%|      | 1363/4096 [00:02<00:05, 518.80it/s]
Adding requests:  35%|      | 1418/4096 [00:02<00:05, 525.57it/s]
Adding requests:  36%|      | 1472/4096 [00:02<00:04, 526.92it/s]
Adding requests:  37%|      | 1526/4096 [00:02<00:04, 529.25it/s]
Adding requests:  39%|      | 1580/4096 [00:02<00:04, 530.92it/s]
Adding requests:  40%|      | 1634/4096 [00:03<00:04, 530.19it/s]
Adding requests:  41%|      | 1688/4096 [00:03<00:04, 528.93it/s]
Adding requests:  43%|     | 1743/4096 [00:03<00:04, 534.87it/s]
Adding requests:  44%|     | 1798/4096 [00:03<00:04, 537.39it/s]
Adding requests:  45%|     | 1853/4096 [00:03<00:04, 536.95it/s]
Adding requests:  47%|     | 1907/4096 [00:03<00:04, 526.75it/s]
Adding requests:  48%|     | 1962/4096 [00:03<00:04, 530.32it/s]
Adding requests:  49%|     | 2016/4096 [00:03<00:03, 531.01it/s]
Adding requests:  51%|     | 2073/4096 [00:03<00:03, 538.08it/s]
Adding requests:  52%|    | 2127/4096 [00:04<00:03, 522.51it/s]
Adding requests:  53%|    | 2180/4096 [00:04<00:03, 514.41it/s]
Adding requests:  55%|    | 2235/4096 [00:04<00:03, 521.65it/s]
Adding requests:  56%|    | 2289/4096 [00:04<00:03, 525.17it/s]
Adding requests:  57%|    | 2345/4096 [00:04<00:03, 534.51it/s]
Adding requests:  59%|    | 2400/4096 [00:04<00:03, 538.83it/s]
Adding requests:  60%|    | 2454/4096 [00:04<00:03, 512.93it/s]
Adding requests:  61%|    | 2507/4096 [00:04<00:03, 516.34it/s]
Adding requests:  63%|   | 2561/4096 [00:04<00:02, 522.11it/s]
Adding requests:  64%|   | 2615/4096 [00:04<00:02, 526.23it/s]
Adding requests:  65%|   | 2668/4096 [00:05<00:02, 526.41it/s]
Adding requests:  66%|   | 2721/4096 [00:05<00:02, 523.32it/s]
Adding requests:  68%|   | 2775/4096 [00:05<00:02, 525.92it/s]
Adding requests:  69%|   | 2828/4096 [00:05<00:02, 524.97it/s]
Adding requests:  70%|   | 2883/4096 [00:05<00:02, 530.93it/s]
Adding requests:  72%|  | 2937/4096 [00:05<00:02, 527.03it/s]
Adding requests:  73%|  | 2992/4096 [00:05<00:02, 533.76it/s]
Adding requests:  74%|  | 3046/4096 [00:05<00:01, 527.45it/s]
Adding requests:  76%|  | 3099/4096 [00:05<00:01, 523.26it/s]
Adding requests:  77%|  | 3153/4096 [00:05<00:01, 526.74it/s]
Adding requests:  78%|  | 3206/4096 [00:06<00:01, 521.03it/s]
Adding requests:  80%|  | 3262/4096 [00:06<00:01, 531.94it/s]
Adding requests:  81%|  | 3316/4096 [00:06<00:01, 530.19it/s]
Adding requests:  82%| | 3370/4096 [00:06<00:01, 529.04it/s]
Adding requests:  84%| | 3425/4096 [00:06<00:01, 531.74it/s]
Adding requests:  85%| | 3479/4096 [00:06<00:01, 522.95it/s]
Adding requests:  86%| | 3533/4096 [00:06<00:01, 525.78it/s]
Adding requests:  88%| | 3588/4096 [00:06<00:00, 530.43it/s]
Adding requests:  89%| | 3642/4096 [00:06<00:00, 523.47it/s]
Adding requests:  90%| | 3698/4096 [00:07<00:00, 533.76it/s]
Adding requests:  92%|| 3752/4096 [00:07<00:00, 533.84it/s]
Adding requests:  93%|| 3806/4096 [00:07<00:00, 520.19it/s]
Adding requests:  94%|| 3861/4096 [00:07<00:00, 524.81it/s]
Adding requests:  96%|| 3915/4096 [00:07<00:00, 529.19it/s]
Adding requests:  97%|| 3971/4096 [00:07<00:00, 535.20it/s]
Adding requests:  98%|| 4026/4096 [00:07<00:00, 537.04it/s]
Adding requests: 100%|| 4080/4096 [00:07<00:00, 533.05it/s]
Adding requests: 100%|| 4096/4096 [00:07<00:00, 528.05it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 194/4096 [00:00<00:02, 1633.69it/s, est. speed input: 1673613.72 toks/s, output: 1633.91 toks/s]
Processed prompts:   9%|         | 358/4096 [00:05<01:09, 53.77it/s, est. speed input: 65335.48 toks/s, output: 63.80 toks/s]      
Processed prompts:  10%|         | 428/4096 [00:07<01:19, 45.87it/s, est. speed input: 56122.48 toks/s, output: 54.81 toks/s]
Processed prompts:  11%|        | 467/4096 [00:08<01:22, 43.89it/s, est. speed input: 53785.23 toks/s, output: 52.52 toks/s]
Processed prompts:  12%|        | 493/4096 [00:09<01:31, 39.27it/s, est. speed input: 50518.50 toks/s, output: 49.33 toks/s]
Processed prompts:  13%|        | 514/4096 [00:11<01:44, 34.37it/s, est. speed input: 47468.14 toks/s, output: 46.36 toks/s]
Processed prompts:  13%|        | 546/4096 [00:12<01:47, 33.03it/s, est. speed input: 45886.55 toks/s, output: 44.81 toks/s]
Processed prompts:  14%|        | 578/4096 [00:13<01:49, 32.03it/s, est. speed input: 44579.66 toks/s, output: 43.53 toks/s]
Processed prompts:  15%|        | 610/4096 [00:14<01:51, 31.23it/s, est. speed input: 43455.33 toks/s, output: 42.44 toks/s]
Processed prompts:  16%|        | 642/4096 [00:15<01:52, 30.63it/s, est. speed input: 42488.96 toks/s, output: 41.49 toks/s]
Processed prompts:  16%|        | 674/4096 [00:16<01:53, 30.21it/s, est. speed input: 41652.37 toks/s, output: 40.68 toks/s]
Processed prompts:  17%|        | 706/4096 [00:17<01:53, 29.89it/s, est. speed input: 40916.99 toks/s, output: 39.96 toks/s]
Processed prompts:  18%|        | 738/4096 [00:18<01:53, 29.65it/s, est. speed input: 40262.60 toks/s, output: 39.32 toks/s]
Processed prompts:  19%|        | 770/4096 [00:19<01:52, 29.46it/s, est. speed input: 39676.12 toks/s, output: 38.75 toks/s]
Processed prompts:  20%|        | 802/4096 [00:20<01:52, 29.35it/s, est. speed input: 39158.50 toks/s, output: 38.24 toks/s]
Processed prompts:  20%|        | 834/4096 [00:22<01:51, 29.31it/s, est. speed input: 38698.46 toks/s, output: 37.79 toks/s]
Processed prompts:  21%|        | 866/4096 [00:23<01:50, 29.22it/s, est. speed input: 38271.80 toks/s, output: 37.37 toks/s]
Processed prompts:  22%|       | 898/4096 [00:24<01:49, 29.17it/s, est. speed input: 37884.74 toks/s, output: 37.00 toks/s]
Processed prompts:  23%|       | 930/4096 [00:25<01:47, 29.33it/s, est. speed input: 37568.25 toks/s, output: 36.69 toks/s]
Processed prompts:  23%|       | 962/4096 [00:26<01:46, 29.47it/s, est. speed input: 37280.80 toks/s, output: 36.41 toks/s]
Processed prompts:  24%|       | 994/4096 [00:27<01:45, 29.42it/s, est. speed input: 36992.25 toks/s, output: 36.13 toks/s]
Processed prompts:  25%|       | 1026/4096 [00:28<01:44, 29.33it/s, est. speed input: 36716.53 toks/s, output: 35.86 toks/s]
Processed prompts:  26%|       | 1058/4096 [00:29<01:43, 29.29it/s, est. speed input: 36465.32 toks/s, output: 35.61 toks/s]
Processed prompts:  27%|       | 1090/4096 [00:30<01:42, 29.23it/s, est. speed input: 36227.48 toks/s, output: 35.38 toks/s]
Processed prompts:  27%|       | 1122/4096 [00:31<01:41, 29.18it/s, est. speed input: 36004.28 toks/s, output: 35.16 toks/s]
Processed prompts:  28%|       | 1154/4096 [00:32<01:40, 29.34it/s, est. speed input: 35822.54 toks/s, output: 34.98 toks/s]
Processed prompts:  29%|       | 1186/4096 [00:34<01:39, 29.29it/s, est. speed input: 35630.60 toks/s, output: 34.80 toks/s]
Processed prompts:  30%|       | 1218/4096 [00:35<01:38, 29.22it/s, est. speed input: 35446.91 toks/s, output: 34.62 toks/s]
Processed prompts:  31%|       | 1250/4096 [00:36<01:36, 29.36it/s, est. speed input: 35297.14 toks/s, output: 34.47 toks/s]
Processed prompts:  31%|      | 1282/4096 [00:37<01:35, 29.50it/s, est. speed input: 35160.92 toks/s, output: 34.34 toks/s]
Processed prompts:  32%|      | 1314/4096 [00:38<01:34, 29.39it/s, est. speed input: 35008.49 toks/s, output: 34.19 toks/s]
Processed prompts:  33%|      | 1346/4096 [00:39<01:33, 29.30it/s, est. speed input: 34862.89 toks/s, output: 34.05 toks/s]
Processed prompts:  34%|      | 1378/4096 [00:40<01:32, 29.23it/s, est. speed input: 34724.95 toks/s, output: 33.91 toks/s]
Processed prompts:  34%|      | 1410/4096 [00:41<01:32, 29.19it/s, est. speed input: 34595.59 toks/s, output: 33.78 toks/s]
Processed prompts:  35%|      | 1442/4096 [00:42<01:30, 29.18it/s, est. speed input: 34474.32 toks/s, output: 33.67 toks/s]
Processed prompts:  36%|      | 1474/4096 [00:43<01:29, 29.17it/s, est. speed input: 34357.80 toks/s, output: 33.55 toks/s]
Processed prompts:  37%|      | 1506/4096 [00:45<01:28, 29.15it/s, est. speed input: 34247.14 toks/s, output: 33.44 toks/s]
Processed prompts:  38%|      | 1538/4096 [00:46<01:27, 29.10it/s, est. speed input: 34137.85 toks/s, output: 33.34 toks/s]
Processed prompts:  38%|      | 1570/4096 [00:47<01:26, 29.27it/s, est. speed input: 34052.52 toks/s, output: 33.25 toks/s]
Processed prompts:  39%|      | 1602/4096 [00:48<01:25, 29.21it/s, est. speed input: 33954.19 toks/s, output: 33.16 toks/s]
Processed prompts:  40%|      | 1634/4096 [00:49<01:23, 29.34it/s, est. speed input: 33875.73 toks/s, output: 33.08 toks/s]
Processed prompts:  41%|      | 1666/4096 [00:50<01:22, 29.28it/s, est. speed input: 33788.05 toks/s, output: 33.00 toks/s]
Processed prompts:  41%|     | 1698/4096 [00:51<01:22, 29.21it/s, est. speed input: 33701.43 toks/s, output: 32.91 toks/s]
Processed prompts:  42%|     | 1730/4096 [00:52<01:21, 29.20it/s, est. speed input: 33621.91 toks/s, output: 32.83 toks/s]
Processed prompts:  43%|     | 1762/4096 [00:53<01:20, 29.17it/s, est. speed input: 33544.16 toks/s, output: 32.76 toks/s]
Processed prompts:  44%|     | 1794/4096 [00:54<01:19, 29.10it/s, est. speed input: 33465.23 toks/s, output: 32.68 toks/s]
Processed prompts:  45%|     | 1826/4096 [00:55<01:17, 29.10it/s, est. speed input: 33393.36 toks/s, output: 32.61 toks/s]
Processed prompts:  45%|     | 1858/4096 [00:57<01:16, 29.28it/s, est. speed input: 33337.15 toks/s, output: 32.56 toks/s]
Processed prompts:  46%|     | 1890/4096 [00:58<01:15, 29.24it/s, est. speed input: 33270.93 toks/s, output: 32.49 toks/s]
Processed prompts:  47%|     | 1922/4096 [00:59<01:14, 29.18it/s, est. speed input: 33205.62 toks/s, output: 32.43 toks/s]
Processed prompts:  48%|     | 1954/4096 [01:00<01:13, 29.29it/s, est. speed input: 33152.70 toks/s, output: 32.38 toks/s]
Processed prompts:  48%|     | 1986/4096 [01:01<01:10, 29.93it/s, est. speed input: 33138.55 toks/s, output: 32.36 toks/s]
Processed prompts:  49%|     | 2018/4096 [01:02<01:10, 29.67it/s, est. speed input: 33079.34 toks/s, output: 32.30 toks/s]
Processed prompts:  50%|     | 2050/4096 [01:03<01:08, 29.89it/s, est. speed input: 33047.03 toks/s, output: 32.27 toks/s]
Processed prompts:  51%|     | 2082/4096 [01:04<01:07, 29.82it/s, est. speed input: 33002.75 toks/s, output: 32.23 toks/s]
Processed prompts:  52%|    | 2114/4096 [01:05<01:07, 29.58it/s, est. speed input: 32947.44 toks/s, output: 32.18 toks/s]
Processed prompts:  52%|    | 2146/4096 [01:06<01:06, 29.38it/s, est. speed input: 32892.73 toks/s, output: 32.12 toks/s]
Processed prompts:  53%|    | 2178/4096 [01:07<01:04, 29.77it/s, est. speed input: 32870.76 toks/s, output: 32.10 toks/s]
Processed prompts:  54%|    | 2210/4096 [01:08<01:02, 30.05it/s, est. speed input: 32849.12 toks/s, output: 32.08 toks/s]
Processed prompts:  55%|    | 2242/4096 [01:09<01:02, 29.76it/s, est. speed input: 32801.16 toks/s, output: 32.03 toks/s]
Processed prompts:  56%|    | 2274/4096 [01:11<01:01, 29.73it/s, est. speed input: 32764.48 toks/s, output: 32.00 toks/s]
Processed prompts:  56%|    | 2306/4096 [01:12<01:00, 29.71it/s, est. speed input: 32728.96 toks/s, output: 31.96 toks/s]
Processed prompts:  57%|    | 2338/4096 [01:13<00:59, 29.70it/s, est. speed input: 32694.29 toks/s, output: 31.93 toks/s]
Processed prompts:  58%|    | 2370/4096 [01:14<00:56, 30.31it/s, est. speed input: 32693.05 toks/s, output: 31.93 toks/s]
Processed prompts:  59%|    | 2402/4096 [01:15<00:56, 30.13it/s, est. speed input: 32660.65 toks/s, output: 31.90 toks/s]
Processed prompts:  59%|    | 2434/4096 [01:16<00:55, 29.99it/s, est. speed input: 32628.50 toks/s, output: 31.86 toks/s]
Processed prompts:  60%|    | 2466/4096 [01:17<00:54, 29.90it/s, est. speed input: 32597.66 toks/s, output: 31.83 toks/s]
Processed prompts:  61%|    | 2498/4096 [01:18<00:53, 29.84it/s, est. speed input: 32567.46 toks/s, output: 31.80 toks/s]
Processed prompts:  62%|   | 2530/4096 [01:19<00:52, 29.59it/s, est. speed input: 32528.04 toks/s, output: 31.77 toks/s]
Processed prompts:  63%|   | 2562/4096 [01:20<00:51, 29.62it/s, est. speed input: 32499.69 toks/s, output: 31.74 toks/s]
Processed prompts:  63%|   | 2594/4096 [01:21<00:50, 29.65it/s, est. speed input: 32472.54 toks/s, output: 31.71 toks/s]
Processed prompts:  64%|   | 2626/4096 [01:22<00:49, 29.49it/s, est. speed input: 32437.54 toks/s, output: 31.68 toks/s]
Processed prompts:  65%|   | 2658/4096 [01:23<00:48, 29.37it/s, est. speed input: 32402.79 toks/s, output: 31.64 toks/s]
Processed prompts:  66%|   | 2690/4096 [01:25<00:47, 29.77it/s, est. speed input: 32391.70 toks/s, output: 31.63 toks/s]
Processed prompts:  66%|   | 2722/4096 [01:26<00:46, 29.55it/s, est. speed input: 32357.80 toks/s, output: 31.60 toks/s]
Processed prompts:  67%|   | 2754/4096 [01:27<00:45, 29.58it/s, est. speed input: 32333.12 toks/s, output: 31.58 toks/s]
Processed prompts:  68%|   | 2786/4096 [01:28<00:44, 29.26it/s, est. speed input: 32293.64 toks/s, output: 31.54 toks/s]
Processed prompts:  69%|   | 2818/4096 [01:29<00:43, 29.59it/s, est. speed input: 32279.82 toks/s, output: 31.52 toks/s]
Processed prompts:  70%|   | 2850/4096 [01:30<00:42, 29.62it/s, est. speed input: 32257.27 toks/s, output: 31.50 toks/s]
Processed prompts:  70%|   | 2882/4096 [01:31<00:41, 29.49it/s, est. speed input: 32229.02 toks/s, output: 31.47 toks/s]
Processed prompts:  71%|   | 2914/4096 [01:32<00:40, 29.31it/s, est. speed input: 32197.63 toks/s, output: 31.44 toks/s]
Processed prompts:  72%|  | 2946/4096 [01:33<00:39, 29.39it/s, est. speed input: 32175.64 toks/s, output: 31.42 toks/s]
Processed prompts:  73%|  | 2978/4096 [01:34<00:38, 29.30it/s, est. speed input: 32147.81 toks/s, output: 31.39 toks/s]
Processed prompts:  73%|  | 3010/4096 [01:35<00:36, 29.71it/s, est. speed input: 32140.23 toks/s, output: 31.39 toks/s]
Processed prompts:  74%|  | 3042/4096 [01:36<00:35, 29.72it/s, est. speed input: 32121.51 toks/s, output: 31.37 toks/s]
Processed prompts:  75%|  | 3074/4096 [01:38<00:34, 29.53it/s, est. speed input: 32095.60 toks/s, output: 31.34 toks/s]
Processed prompts:  76%|  | 3106/4096 [01:39<00:32, 30.14it/s, est. speed input: 32098.81 toks/s, output: 31.35 toks/s]
Processed prompts:  77%|  | 3138/4096 [01:40<00:31, 30.29it/s, est. speed input: 32091.51 toks/s, output: 31.34 toks/s]
Processed prompts:  77%|  | 3170/4096 [01:41<00:30, 29.92it/s, est. speed input: 32066.30 toks/s, output: 31.31 toks/s]
Processed prompts:  78%|  | 3202/4096 [01:42<00:29, 30.15it/s, est. speed input: 32059.95 toks/s, output: 31.31 toks/s]
Processed prompts:  79%|  | 3234/4096 [01:43<00:28, 29.99it/s, est. speed input: 32042.03 toks/s, output: 31.29 toks/s]
Processed prompts:  80%|  | 3266/4096 [01:44<00:27, 29.76it/s, est. speed input: 32019.74 toks/s, output: 31.27 toks/s]
Processed prompts:  81%|  | 3298/4096 [01:45<00:26, 29.73it/s, est. speed input: 32003.01 toks/s, output: 31.25 toks/s]
Processed prompts:  81%| | 3330/4096 [01:46<00:25, 29.99it/s, est. speed input: 31996.59 toks/s, output: 31.25 toks/s]
Processed prompts:  82%| | 3362/4096 [01:47<00:24, 29.76it/s, est. speed input: 31975.73 toks/s, output: 31.23 toks/s]
Processed prompts:  83%| | 3394/4096 [01:48<00:23, 29.54it/s, est. speed input: 31952.96 toks/s, output: 31.20 toks/s]
Processed prompts:  84%| | 3426/4096 [01:49<00:22, 29.55it/s, est. speed input: 31936.62 toks/s, output: 31.19 toks/s]
Processed prompts:  84%| | 3458/4096 [01:50<00:21, 29.57it/s, est. speed input: 31921.04 toks/s, output: 31.17 toks/s]
Processed prompts:  85%| | 3490/4096 [01:51<00:20, 29.90it/s, est. speed input: 31916.27 toks/s, output: 31.17 toks/s]
Processed prompts:  86%| | 3522/4096 [01:53<00:19, 29.63it/s, est. speed input: 31894.93 toks/s, output: 31.15 toks/s]
Processed prompts:  87%| | 3554/4096 [01:54<00:18, 29.45it/s, est. speed input: 31874.02 toks/s, output: 31.13 toks/s]
Processed prompts:  88%| | 3586/4096 [01:55<00:17, 29.39it/s, est. speed input: 31855.82 toks/s, output: 31.11 toks/s]
Processed prompts:  88%| | 3618/4096 [01:56<00:16, 29.29it/s, est. speed input: 31836.03 toks/s, output: 31.09 toks/s]
Processed prompts:  89%| | 3650/4096 [01:57<00:15, 29.40it/s, est. speed input: 31822.37 toks/s, output: 31.08 toks/s]
Processed prompts:  90%| | 3682/4096 [01:58<00:14, 29.50it/s, est. speed input: 31809.87 toks/s, output: 31.06 toks/s]
Processed prompts:  91%| | 3714/4096 [01:59<00:12, 29.52it/s, est. speed input: 31796.21 toks/s, output: 31.05 toks/s]
Processed prompts:  91%|| 3746/4096 [02:00<00:11, 29.41it/s, est. speed input: 31778.58 toks/s, output: 31.03 toks/s]
Processed prompts:  92%|| 3778/4096 [02:01<00:10, 29.33it/s, est. speed input: 31760.98 toks/s, output: 31.02 toks/s]
Processed prompts:  93%|| 3810/4096 [02:02<00:09, 29.46it/s, est. speed input: 31749.82 toks/s, output: 31.01 toks/s]
Processed prompts:  94%|| 3842/4096 [02:03<00:08, 29.82it/s, est. speed input: 31747.16 toks/s, output: 31.00 toks/s]
Processed prompts:  95%|| 3874/4096 [02:05<00:07, 29.60it/s, est. speed input: 31729.99 toks/s, output: 30.99 toks/s]
Processed prompts:  95%|| 3906/4096 [02:06<00:06, 29.44it/s, est. speed input: 31713.03 toks/s, output: 30.97 toks/s]
Processed prompts:  96%|| 3938/4096 [02:07<00:05, 29.55it/s, est. speed input: 31703.03 toks/s, output: 30.96 toks/s]
Processed prompts:  97%|| 3970/4096 [02:08<00:04, 29.41it/s, est. speed input: 31686.50 toks/s, output: 30.94 toks/s]
Processed prompts:  98%|| 4002/4096 [02:09<00:03, 29.31it/s, est. speed input: 31670.38 toks/s, output: 30.93 toks/s]
Processed prompts:  98%|| 4034/4096 [02:10<00:02, 29.95it/s, est. speed input: 31675.31 toks/s, output: 30.93 toks/s]
Processed prompts:  99%|| 4066/4096 [02:11<00:01, 29.89it/s, est. speed input: 31665.28 toks/s, output: 30.92 toks/s]
Processed prompts: 100%|| 4096/4096 [02:11<00:00, 29.89it/s, est. speed input: 31898.85 toks/s, output: 31.15 toks/s]
Processed prompts: 100%|| 4096/4096 [02:11<00:00, 31.15it/s, est. speed input: 31898.85 toks/s, output: 31.15 toks/s]
[rank0]:[W126 03:20:10.007515752 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 03:20:13
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:20:39 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:20:39 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=797041) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=797041) WARNING 01-26 03:21:03 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 29.38 requests/s, 30116.30 total tokens/s, 29.38 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 03:20:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:20:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:20:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:20:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:20:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:20:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:20:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:20:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:20:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:20:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:20:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:20:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:20:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:20:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:20:42] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 03:20:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 03:20:42] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 03:20:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:20:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:20:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:20:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:20:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 03:20:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 03:20:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:20:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:20:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:20:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:20:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=797041) [2026-01-26 03:20:43] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=797041) [2026-01-26 03:20:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=797041) [2026-01-26 03:20:43] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=797041) [2026-01-26 03:20:43] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=797041) [2026-01-26 03:20:43] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=797041) [2026-01-26 03:20:43] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=797041) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=797041) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.03s/it]
(EngineCore_DP0 pid=797041) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.03s/it]
(EngineCore_DP0 pid=797041) 
(EngineCore_DP0 pid=797041) [2026-01-26 03:20:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=797041) [2026-01-26 03:20:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=797041) [2026-01-26 03:20:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=797041) [2026-01-26 03:20:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=797041) [2026-01-26 03:20:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=797041) [2026-01-26 03:20:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=797041) [2026-01-26 03:20:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=797041) [2026-01-26 03:20:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=797041) 2026-01-26 03:21:00,760 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=797041) 2026-01-26 03:21:01,002 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 66/8192 [00:00<00:12, 651.85it/s]
Adding requests:   2%|         | 132/8192 [00:00<00:15, 532.98it/s]
Adding requests:   2%|         | 187/8192 [00:00<00:15, 512.46it/s]
Adding requests:   3%|         | 240/8192 [00:00<00:15, 518.26it/s]
Adding requests:   4%|         | 300/8192 [00:00<00:14, 541.79it/s]
Adding requests:   4%|         | 356/8192 [00:00<00:14, 544.58it/s]
Adding requests:   5%|         | 411/8192 [00:00<00:14, 534.35it/s]
Adding requests:   6%|         | 465/8192 [00:00<00:14, 526.85it/s]
Adding requests:   6%|         | 518/8192 [00:00<00:15, 511.06it/s]
Adding requests:   7%|         | 571/8192 [00:01<00:14, 513.34it/s]
Adding requests:   8%|         | 623/8192 [00:01<00:14, 512.35it/s]
Adding requests:   8%|         | 681/8192 [00:01<00:14, 531.45it/s]
Adding requests:   9%|         | 735/8192 [00:01<00:13, 533.45it/s]
Adding requests:  10%|         | 789/8192 [00:01<00:13, 529.12it/s]
Adding requests:  10%|         | 842/8192 [00:01<00:13, 528.57it/s]
Adding requests:  11%|         | 907/8192 [00:01<00:12, 562.59it/s]
Adding requests:  12%|        | 973/8192 [00:01<00:12, 588.50it/s]
Adding requests:  13%|        | 1032/8192 [00:01<00:13, 533.12it/s]
Adding requests:  13%|        | 1097/8192 [00:02<00:12, 563.79it/s]
Adding requests:  14%|        | 1157/8192 [00:02<00:12, 571.73it/s]
Adding requests:  15%|        | 1215/8192 [00:02<00:12, 559.95it/s]
Adding requests:  16%|        | 1272/8192 [00:02<00:12, 559.46it/s]
Adding requests:  16%|        | 1329/8192 [00:02<00:12, 544.52it/s]
Adding requests:  17%|        | 1384/8192 [00:02<00:12, 529.50it/s]
Adding requests:  18%|        | 1440/8192 [00:02<00:12, 537.54it/s]
Adding requests:  18%|        | 1494/8192 [00:02<00:12, 532.28it/s]
Adding requests:  19%|        | 1548/8192 [00:02<00:12, 533.01it/s]
Adding requests:  20%|        | 1603/8192 [00:02<00:12, 535.84it/s]
Adding requests:  20%|        | 1657/8192 [00:03<00:12, 532.83it/s]
Adding requests:  21%|        | 1713/8192 [00:03<00:12, 539.51it/s]
Adding requests:  22%|       | 1767/8192 [00:03<00:12, 533.32it/s]
Adding requests:  22%|       | 1821/8192 [00:03<00:11, 531.87it/s]
Adding requests:  23%|       | 1875/8192 [00:03<00:12, 508.62it/s]
Adding requests:  24%|       | 1927/8192 [00:03<00:12, 507.17it/s]
Adding requests:  24%|       | 1978/8192 [00:03<00:12, 505.15it/s]
Adding requests:  25%|       | 2029/8192 [00:03<00:12, 506.52it/s]
Adding requests:  25%|       | 2081/8192 [00:03<00:11, 509.39it/s]
Adding requests:  26%|       | 2134/8192 [00:04<00:11, 512.48it/s]
Adding requests:  27%|       | 2186/8192 [00:04<00:11, 511.63it/s]
Adding requests:  27%|       | 2240/8192 [00:04<00:11, 518.35it/s]
Adding requests:  28%|       | 2292/8192 [00:04<00:11, 515.96it/s]
Adding requests:  29%|       | 2348/8192 [00:04<00:11, 526.09it/s]
Adding requests:  29%|       | 2401/8192 [00:04<00:11, 522.07it/s]
Adding requests:  30%|       | 2454/8192 [00:04<00:11, 517.34it/s]
Adding requests:  31%|       | 2507/8192 [00:04<00:10, 521.02it/s]
Adding requests:  31%|      | 2562/8192 [00:04<00:10, 526.88it/s]
Adding requests:  32%|      | 2615/8192 [00:04<00:10, 526.96it/s]
Adding requests:  33%|      | 2669/8192 [00:05<00:10, 530.81it/s]
Adding requests:  33%|      | 2723/8192 [00:05<00:10, 525.92it/s]
Adding requests:  34%|      | 2778/8192 [00:05<00:10, 530.77it/s]
Adding requests:  35%|      | 2832/8192 [00:05<00:10, 532.32it/s]
Adding requests:  35%|      | 2887/8192 [00:05<00:09, 536.41it/s]
Adding requests:  36%|      | 2941/8192 [00:05<00:09, 527.75it/s]
Adding requests:  37%|      | 2996/8192 [00:05<00:09, 531.14it/s]
Adding requests:  37%|      | 3050/8192 [00:05<00:09, 526.11it/s]
Adding requests:  38%|      | 3103/8192 [00:05<00:09, 515.27it/s]
Adding requests:  39%|      | 3155/8192 [00:05<00:10, 502.78it/s]
Adding requests:  39%|      | 3210/8192 [00:06<00:10, 467.92it/s]
Adding requests:  40%|      | 3263/8192 [00:06<00:10, 483.39it/s]
Adding requests:  40%|      | 3313/8192 [00:06<00:10, 487.61it/s]
Adding requests:  41%|      | 3366/8192 [00:06<00:09, 498.85it/s]
Adding requests:  42%|     | 3418/8192 [00:06<00:09, 502.29it/s]
Adding requests:  42%|     | 3469/8192 [00:06<00:09, 502.26it/s]
Adding requests:  43%|     | 3520/8192 [00:06<00:09, 503.15it/s]
Adding requests:  44%|     | 3571/8192 [00:06<00:09, 500.47it/s]
Adding requests:  44%|     | 3622/8192 [00:06<00:09, 500.08it/s]
Adding requests:  45%|     | 3677/8192 [00:07<00:08, 512.57it/s]
Adding requests:  46%|     | 3729/8192 [00:07<00:08, 503.07it/s]
Adding requests:  46%|     | 3784/8192 [00:07<00:08, 514.49it/s]
Adding requests:  47%|     | 3836/8192 [00:07<00:08, 513.78it/s]
Adding requests:  48%|     | 3892/8192 [00:07<00:08, 526.43it/s]
Adding requests:  48%|     | 3945/8192 [00:07<00:08, 518.48it/s]
Adding requests:  49%|     | 3998/8192 [00:07<00:08, 519.62it/s]
Adding requests:  49%|     | 4051/8192 [00:07<00:08, 513.73it/s]
Adding requests:  50%|     | 4105/8192 [00:07<00:07, 520.32it/s]
Adding requests:  51%|     | 4158/8192 [00:07<00:07, 517.66it/s]
Adding requests:  51%|    | 4211/8192 [00:08<00:07, 519.50it/s]
Adding requests:  52%|    | 4263/8192 [00:08<00:07, 509.37it/s]
Adding requests:  53%|    | 4318/8192 [00:08<00:07, 519.49it/s]
Adding requests:  53%|    | 4371/8192 [00:08<00:07, 521.73it/s]
Adding requests:  54%|    | 4424/8192 [00:08<00:07, 523.45it/s]
Adding requests:  55%|    | 4478/8192 [00:08<00:07, 526.49it/s]
Adding requests:  55%|    | 4532/8192 [00:08<00:06, 528.71it/s]
Adding requests:  56%|    | 4585/8192 [00:08<00:07, 493.65it/s]
Adding requests:  57%|    | 4636/8192 [00:08<00:07, 496.14it/s]
Adding requests:  57%|    | 4687/8192 [00:08<00:07, 498.78it/s]
Adding requests:  58%|    | 4742/8192 [00:09<00:06, 512.41it/s]
Adding requests:  59%|    | 4794/8192 [00:09<00:06, 512.01it/s]
Adding requests:  59%|    | 4846/8192 [00:09<00:06, 488.68it/s]
Adding requests:  60%|    | 4896/8192 [00:09<00:06, 489.91it/s]
Adding requests:  60%|    | 4949/8192 [00:09<00:06, 498.16it/s]
Adding requests:  61%|    | 5006/8192 [00:09<00:06, 518.04it/s]
Adding requests:  62%|   | 5058/8192 [00:09<00:06, 513.73it/s]
Adding requests:  62%|   | 5113/8192 [00:09<00:05, 521.17it/s]
Adding requests:  63%|   | 5166/8192 [00:09<00:05, 517.74it/s]
Adding requests:  64%|   | 5223/8192 [00:10<00:05, 527.74it/s]
Adding requests:  64%|   | 5276/8192 [00:10<00:05, 524.27it/s]
Adding requests:  65%|   | 5333/8192 [00:10<00:05, 535.93it/s]
Adding requests:  66%|   | 5387/8192 [00:10<00:05, 528.41it/s]
Adding requests:  66%|   | 5444/8192 [00:10<00:05, 539.71it/s]
Adding requests:  67%|   | 5499/8192 [00:10<00:05, 537.24it/s]
Adding requests:  68%|   | 5553/8192 [00:10<00:04, 537.46it/s]
Adding requests:  68%|   | 5609/8192 [00:10<00:04, 540.44it/s]
Adding requests:  69%|   | 5664/8192 [00:10<00:04, 540.01it/s]
Adding requests:  70%|   | 5720/8192 [00:10<00:04, 543.91it/s]
Adding requests:  71%|   | 5777/8192 [00:11<00:04, 549.65it/s]
Adding requests:  71%|   | 5832/8192 [00:11<00:04, 542.72it/s]
Adding requests:  72%|  | 5889/8192 [00:11<00:04, 549.91it/s]
Adding requests:  73%|  | 5945/8192 [00:11<00:04, 552.24it/s]
Adding requests:  73%|  | 6001/8192 [00:11<00:04, 515.32it/s]
Adding requests:  74%|  | 6058/8192 [00:11<00:04, 528.86it/s]
Adding requests:  75%|  | 6117/8192 [00:11<00:03, 543.60it/s]
Adding requests:  75%|  | 6174/8192 [00:11<00:03, 548.90it/s]
Adding requests:  76%|  | 6232/8192 [00:11<00:03, 557.22it/s]
Adding requests:  77%|  | 6289/8192 [00:11<00:03, 558.78it/s]
Adding requests:  77%|  | 6347/8192 [00:12<00:03, 562.86it/s]
Adding requests:  78%|  | 6404/8192 [00:12<00:03, 557.83it/s]
Adding requests:  79%|  | 6462/8192 [00:12<00:03, 562.57it/s]
Adding requests:  80%|  | 6521/8192 [00:12<00:02, 570.31it/s]
Adding requests:  80%|  | 6579/8192 [00:12<00:02, 566.93it/s]
Adding requests:  81%|  | 6636/8192 [00:12<00:02, 551.89it/s]
Adding requests:  82%| | 6693/8192 [00:12<00:02, 556.50it/s]
Adding requests:  82%| | 6750/8192 [00:12<00:02, 556.47it/s]
Adding requests:  83%| | 6808/8192 [00:12<00:02, 562.97it/s]
Adding requests:  84%| | 6865/8192 [00:13<00:02, 561.25it/s]
Adding requests:  84%| | 6922/8192 [00:13<00:02, 555.48it/s]
Adding requests:  85%| | 6978/8192 [00:13<00:02, 556.33it/s]
Adding requests:  86%| | 7034/8192 [00:13<00:02, 556.44it/s]
Adding requests:  87%| | 7090/8192 [00:13<00:01, 551.28it/s]
Adding requests:  87%| | 7146/8192 [00:13<00:01, 552.68it/s]
Adding requests:  88%| | 7202/8192 [00:13<00:01, 550.68it/s]
Adding requests:  89%| | 7259/8192 [00:13<00:01, 556.22it/s]
Adding requests:  89%| | 7315/8192 [00:13<00:01, 528.92it/s]
Adding requests:  90%| | 7369/8192 [00:13<00:01, 530.59it/s]
Adding requests:  91%| | 7427/8192 [00:14<00:01, 544.26it/s]
Adding requests:  91%|| 7485/8192 [00:14<00:01, 553.93it/s]
Adding requests:  92%|| 7541/8192 [00:14<00:01, 550.58it/s]
Adding requests:  93%|| 7597/8192 [00:14<00:01, 545.82it/s]
Adding requests:  93%|| 7655/8192 [00:14<00:00, 554.59it/s]
Adding requests:  94%|| 7713/8192 [00:14<00:00, 560.66it/s]
Adding requests:  95%|| 7770/8192 [00:14<00:00, 548.85it/s]
Adding requests:  96%|| 7825/8192 [00:14<00:00, 543.43it/s]
Adding requests:  96%|| 7880/8192 [00:14<00:00, 541.13it/s]
Adding requests:  97%|| 7939/8192 [00:14<00:00, 553.48it/s]
Adding requests:  98%|| 7995/8192 [00:15<00:00, 540.61it/s]
Adding requests:  98%|| 8050/8192 [00:15<00:00, 528.78it/s]
Adding requests:  99%|| 8104/8192 [00:15<00:00, 529.96it/s]
Adding requests: 100%|| 8158/8192 [00:15<00:00, 529.05it/s]
Adding requests: 100%|| 8192/8192 [00:15<00:00, 530.33it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 386/8192 [00:01<00:27, 284.88it/s, est. speed input: 291725.30 toks/s, output: 284.89 toks/s]
Processed prompts:   5%|         | 450/8192 [00:03<01:12, 107.05it/s, est. speed input: 130597.78 toks/s, output: 127.54 toks/s]
Processed prompts:   6%|         | 514/8192 [00:05<01:52, 68.09it/s, est. speed input: 92040.35 toks/s, output: 89.88 toks/s]   
Processed prompts:   7%|         | 578/8192 [00:07<02:26, 51.86it/s, est. speed input: 74810.94 toks/s, output: 73.06 toks/s]
Processed prompts:   8%|         | 642/8192 [00:10<02:53, 43.41it/s, est. speed input: 65076.05 toks/s, output: 63.55 toks/s]
Processed prompts:   9%|         | 706/8192 [00:12<03:14, 38.45it/s, est. speed input: 58789.81 toks/s, output: 57.41 toks/s]
Processed prompts:   9%|         | 770/8192 [00:14<03:30, 35.34it/s, est. speed input: 54390.63 toks/s, output: 53.12 toks/s]
Processed prompts:  10%|         | 834/8192 [00:16<03:40, 33.38it/s, est. speed input: 51183.15 toks/s, output: 49.98 toks/s]
Processed prompts:  11%|         | 898/8192 [00:18<03:46, 32.17it/s, est. speed input: 48769.48 toks/s, output: 47.63 toks/s]
Processed prompts:  12%|        | 962/8192 [00:21<03:59, 30.13it/s, est. speed input: 46230.44 toks/s, output: 45.15 toks/s]
Processed prompts:  13%|        | 1026/8192 [00:23<03:59, 29.89it/s, est. speed input: 44726.10 toks/s, output: 43.68 toks/s]
Processed prompts:  13%|        | 1090/8192 [00:25<03:59, 29.69it/s, est. speed input: 43464.57 toks/s, output: 42.45 toks/s]
Processed prompts:  14%|        | 1154/8192 [00:27<03:57, 29.62it/s, est. speed input: 42426.79 toks/s, output: 41.43 toks/s]
Processed prompts:  15%|        | 1218/8192 [00:30<03:55, 29.57it/s, est. speed input: 41539.57 toks/s, output: 40.57 toks/s]
Processed prompts:  16%|        | 1282/8192 [00:32<03:53, 29.54it/s, est. speed input: 40773.80 toks/s, output: 39.82 toks/s]
Processed prompts:  16%|        | 1346/8192 [00:34<03:52, 29.46it/s, est. speed input: 40087.08 toks/s, output: 39.15 toks/s]
Processed prompts:  17%|        | 1410/8192 [00:36<03:50, 29.41it/s, est. speed input: 39484.84 toks/s, output: 38.56 toks/s]
Processed prompts:  18%|        | 1474/8192 [00:38<03:48, 29.35it/s, est. speed input: 38943.94 toks/s, output: 38.03 toks/s]
Processed prompts:  19%|        | 1538/8192 [00:40<03:46, 29.36it/s, est. speed input: 38473.08 toks/s, output: 37.57 toks/s]
Processed prompts:  20%|        | 1602/8192 [00:43<03:44, 29.39it/s, est. speed input: 38054.80 toks/s, output: 37.16 toks/s]
Processed prompts:  20%|        | 1666/8192 [00:45<03:42, 29.35it/s, est. speed input: 37662.22 toks/s, output: 36.78 toks/s]
Processed prompts:  21%|        | 1730/8192 [00:47<03:40, 29.34it/s, est. speed input: 37311.98 toks/s, output: 36.44 toks/s]
Processed prompts:  22%|       | 1794/8192 [00:49<03:38, 29.28it/s, est. speed input: 36980.64 toks/s, output: 36.11 toks/s]
Processed prompts:  23%|       | 1858/8192 [00:51<03:35, 29.35it/s, est. speed input: 36698.08 toks/s, output: 35.84 toks/s]
Processed prompts:  23%|       | 1922/8192 [00:54<03:36, 28.90it/s, est. speed input: 36353.69 toks/s, output: 35.50 toks/s]
Processed prompts:  24%|       | 1986/8192 [00:56<03:31, 29.30it/s, est. speed input: 36153.62 toks/s, output: 35.31 toks/s]
Processed prompts:  25%|       | 2050/8192 [00:58<03:27, 29.62it/s, est. speed input: 35971.89 toks/s, output: 35.13 toks/s]
Processed prompts:  26%|       | 2114/8192 [01:00<03:26, 29.50it/s, est. speed input: 35753.03 toks/s, output: 34.92 toks/s]
Processed prompts:  27%|       | 2178/8192 [01:02<03:21, 29.88it/s, est. speed input: 35613.48 toks/s, output: 34.78 toks/s]
Processed prompts:  27%|       | 2242/8192 [01:04<03:19, 29.75it/s, est. speed input: 35430.73 toks/s, output: 34.60 toks/s]
Processed prompts:  28%|       | 2306/8192 [01:06<03:17, 29.78it/s, est. speed input: 35274.94 toks/s, output: 34.45 toks/s]
Processed prompts:  29%|       | 2370/8192 [01:09<03:13, 30.12it/s, est. speed input: 35166.81 toks/s, output: 34.34 toks/s]
Processed prompts:  30%|       | 2434/8192 [01:11<03:11, 30.08it/s, est. speed input: 35033.42 toks/s, output: 34.21 toks/s]
Processed prompts:  30%|       | 2498/8192 [01:13<03:10, 29.89it/s, est. speed input: 34888.61 toks/s, output: 34.07 toks/s]
Processed prompts:  31%|      | 2562/8192 [01:15<03:08, 29.90it/s, est. speed input: 34768.81 toks/s, output: 33.95 toks/s]
Processed prompts:  32%|      | 2626/8192 [01:17<03:07, 29.71it/s, est. speed input: 34633.56 toks/s, output: 33.82 toks/s]
Processed prompts:  33%|      | 2690/8192 [01:19<03:04, 29.78it/s, est. speed input: 34527.05 toks/s, output: 33.72 toks/s]
Processed prompts:  34%|      | 2754/8192 [01:21<03:03, 29.67it/s, est. speed input: 34410.50 toks/s, output: 33.60 toks/s]
Processed prompts:  34%|      | 2818/8192 [01:24<02:59, 29.89it/s, est. speed input: 34328.72 toks/s, output: 33.52 toks/s]
Processed prompts:  35%|      | 2882/8192 [01:26<03:00, 29.36it/s, est. speed input: 34185.34 toks/s, output: 33.38 toks/s]
Processed prompts:  36%|      | 2946/8192 [01:28<02:58, 29.39it/s, est. speed input: 34086.24 toks/s, output: 33.29 toks/s]
Processed prompts:  37%|      | 3010/8192 [01:30<02:54, 29.66it/s, est. speed input: 34015.27 toks/s, output: 33.22 toks/s]
Processed prompts:  38%|      | 3074/8192 [01:32<02:51, 29.87it/s, est. speed input: 33948.87 toks/s, output: 33.15 toks/s]
Processed prompts:  38%|      | 3138/8192 [01:34<02:48, 29.92it/s, est. speed input: 33877.23 toks/s, output: 33.08 toks/s]
Processed prompts:  39%|      | 3202/8192 [01:36<02:46, 30.03it/s, est. speed input: 33815.19 toks/s, output: 33.02 toks/s]
Processed prompts:  40%|      | 3266/8192 [01:39<02:45, 29.83it/s, est. speed input: 33733.22 toks/s, output: 32.94 toks/s]
Processed prompts:  41%|      | 3330/8192 [01:41<02:42, 29.86it/s, est. speed input: 33668.16 toks/s, output: 32.88 toks/s]
Processed prompts:  41%|     | 3394/8192 [01:43<02:41, 29.72it/s, est. speed input: 33592.70 toks/s, output: 32.81 toks/s]
Processed prompts:  42%|     | 3458/8192 [01:45<02:38, 29.92it/s, est. speed input: 33543.43 toks/s, output: 32.76 toks/s]
Processed prompts:  43%|     | 3522/8192 [01:47<02:37, 29.71it/s, est. speed input: 33470.49 toks/s, output: 32.69 toks/s]
Processed prompts:  44%|     | 3586/8192 [01:49<02:35, 29.55it/s, est. speed input: 33399.08 toks/s, output: 32.62 toks/s]
Processed prompts:  45%|     | 3650/8192 [01:52<02:33, 29.65it/s, est. speed input: 33345.70 toks/s, output: 32.56 toks/s]
Processed prompts:  45%|     | 3714/8192 [01:54<02:31, 29.60it/s, est. speed input: 33285.54 toks/s, output: 32.51 toks/s]
Processed prompts:  46%|     | 3778/8192 [01:56<02:29, 29.54it/s, est. speed input: 33226.34 toks/s, output: 32.45 toks/s]
Processed prompts:  47%|     | 3842/8192 [01:58<02:29, 29.18it/s, est. speed input: 33146.61 toks/s, output: 32.37 toks/s]
Processed prompts:  48%|     | 3906/8192 [02:00<02:26, 29.26it/s, est. speed input: 33093.06 toks/s, output: 32.32 toks/s]
Processed prompts:  48%|     | 3970/8192 [02:03<02:24, 29.23it/s, est. speed input: 33035.14 toks/s, output: 32.26 toks/s]
Processed prompts:  49%|     | 4034/8192 [02:05<02:20, 29.56it/s, est. speed input: 33002.60 toks/s, output: 32.23 toks/s]
Processed prompts:  50%|     | 4098/8192 [02:07<02:19, 29.43it/s, est. speed input: 32947.98 toks/s, output: 32.18 toks/s]
Processed prompts:  51%|     | 4162/8192 [02:09<02:15, 29.82it/s, est. speed input: 32924.95 toks/s, output: 32.15 toks/s]
Processed prompts:  52%|    | 4226/8192 [02:11<02:12, 29.84it/s, est. speed input: 32887.22 toks/s, output: 32.12 toks/s]
Processed prompts:  52%|    | 4290/8192 [02:13<02:11, 29.75it/s, est. speed input: 32844.40 toks/s, output: 32.07 toks/s]
Processed prompts:  53%|    | 4354/8192 [02:15<02:09, 29.56it/s, est. speed input: 32795.46 toks/s, output: 32.03 toks/s]
Processed prompts:  54%|    | 4418/8192 [02:18<02:07, 29.65it/s, est. speed input: 32761.32 toks/s, output: 31.99 toks/s]
Processed prompts:  55%|    | 4482/8192 [02:20<02:05, 29.51it/s, est. speed input: 32716.41 toks/s, output: 31.95 toks/s]
Processed prompts:  55%|    | 4546/8192 [02:22<02:02, 29.77it/s, est. speed input: 32692.76 toks/s, output: 31.93 toks/s]
Processed prompts:  56%|    | 4610/8192 [02:24<02:00, 29.67it/s, est. speed input: 32654.35 toks/s, output: 31.89 toks/s]
Processed prompts:  57%|    | 4674/8192 [02:26<01:59, 29.49it/s, est. speed input: 32611.14 toks/s, output: 31.85 toks/s]
Processed prompts:  58%|    | 4738/8192 [02:28<01:56, 29.60it/s, est. speed input: 32582.18 toks/s, output: 31.82 toks/s]
Processed prompts:  59%|    | 4802/8192 [02:31<01:56, 29.21it/s, est. speed input: 32528.62 toks/s, output: 31.77 toks/s]
Processed prompts:  59%|    | 4866/8192 [02:33<01:53, 29.28it/s, est. speed input: 32495.16 toks/s, output: 31.73 toks/s]
Processed prompts:  60%|    | 4930/8192 [02:35<01:51, 29.32it/s, est. speed input: 32461.85 toks/s, output: 31.70 toks/s]
Processed prompts:  61%|    | 4994/8192 [02:37<01:48, 29.51it/s, est. speed input: 32437.78 toks/s, output: 31.68 toks/s]
Processed prompts:  62%|   | 5058/8192 [02:39<01:45, 29.73it/s, est. speed input: 32418.72 toks/s, output: 31.66 toks/s]
Processed prompts:  63%|   | 5122/8192 [02:41<01:43, 29.56it/s, est. speed input: 32384.14 toks/s, output: 31.63 toks/s]
Processed prompts:  63%|   | 5186/8192 [02:44<01:40, 29.78it/s, est. speed input: 32366.77 toks/s, output: 31.61 toks/s]
Processed prompts:  64%|   | 5250/8192 [02:46<01:38, 29.95it/s, est. speed input: 32350.46 toks/s, output: 31.59 toks/s]
Processed prompts:  65%|   | 5314/8192 [02:48<01:35, 30.08it/s, est. speed input: 32335.00 toks/s, output: 31.58 toks/s]
Processed prompts:  66%|   | 5378/8192 [02:50<01:34, 29.88it/s, est. speed input: 32306.71 toks/s, output: 31.55 toks/s]
Processed prompts:  66%|   | 5442/8192 [02:52<01:32, 29.86it/s, est. speed input: 32284.59 toks/s, output: 31.53 toks/s]
Processed prompts:  67%|   | 5506/8192 [02:54<01:30, 29.71it/s, est. speed input: 32257.21 toks/s, output: 31.50 toks/s]
Processed prompts:  68%|   | 5570/8192 [02:56<01:28, 29.57it/s, est. speed input: 32228.38 toks/s, output: 31.47 toks/s]
Processed prompts:  69%|   | 5634/8192 [02:59<01:26, 29.66it/s, est. speed input: 32209.02 toks/s, output: 31.45 toks/s]
Processed prompts:  70%|   | 5698/8192 [03:01<01:23, 29.74it/s, est. speed input: 32190.48 toks/s, output: 31.44 toks/s]
Processed prompts:  70%|   | 5762/8192 [03:03<01:22, 29.45it/s, est. speed input: 32157.93 toks/s, output: 31.40 toks/s]
Processed prompts:  71%|   | 5826/8192 [03:05<01:20, 29.42it/s, est. speed input: 32133.25 toks/s, output: 31.38 toks/s]
Processed prompts:  72%|  | 5890/8192 [03:07<01:17, 29.56it/s, est. speed input: 32115.81 toks/s, output: 31.36 toks/s]
Processed prompts:  73%|  | 5954/8192 [03:09<01:15, 29.45it/s, est. speed input: 32090.16 toks/s, output: 31.34 toks/s]
Processed prompts:  73%|  | 6018/8192 [03:12<01:13, 29.45it/s, est. speed input: 32068.25 toks/s, output: 31.32 toks/s]
Processed prompts:  74%|  | 6082/8192 [03:14<01:11, 29.37it/s, est. speed input: 32043.49 toks/s, output: 31.29 toks/s]
Processed prompts:  75%|  | 6146/8192 [03:16<01:09, 29.65it/s, est. speed input: 32032.86 toks/s, output: 31.28 toks/s]
Processed prompts:  76%|  | 6210/8192 [03:18<01:07, 29.57it/s, est. speed input: 32011.79 toks/s, output: 31.26 toks/s]
Processed prompts:  77%|  | 6274/8192 [03:20<01:05, 29.43it/s, est. speed input: 31987.63 toks/s, output: 31.24 toks/s]
Processed prompts:  77%|  | 6338/8192 [03:22<01:02, 29.62it/s, est. speed input: 31975.23 toks/s, output: 31.23 toks/s]
Processed prompts:  78%|  | 6402/8192 [03:25<01:00, 29.57it/s, est. speed input: 31955.98 toks/s, output: 31.21 toks/s]
Processed prompts:  79%|  | 6466/8192 [03:27<00:58, 29.47it/s, est. speed input: 31934.84 toks/s, output: 31.19 toks/s]
Processed prompts:  80%|  | 6530/8192 [03:29<00:56, 29.62it/s, est. speed input: 31922.08 toks/s, output: 31.17 toks/s]
Processed prompts:  80%|  | 6594/8192 [03:31<00:54, 29.57it/s, est. speed input: 31904.13 toks/s, output: 31.16 toks/s]
Processed prompts:  81%| | 6658/8192 [03:33<00:51, 29.67it/s, est. speed input: 31891.39 toks/s, output: 31.14 toks/s]
Processed prompts:  82%| | 6722/8192 [03:35<00:49, 29.52it/s, est. speed input: 31870.81 toks/s, output: 31.12 toks/s]
Processed prompts:  83%| | 6786/8192 [03:38<00:47, 29.47it/s, est. speed input: 31852.83 toks/s, output: 31.11 toks/s]
Processed prompts:  84%| | 6850/8192 [03:40<00:45, 29.45it/s, est. speed input: 31835.45 toks/s, output: 31.09 toks/s]
Processed prompts:  84%| | 6914/8192 [03:42<00:43, 29.43it/s, est. speed input: 31818.33 toks/s, output: 31.07 toks/s]
Processed prompts:  85%| | 6978/8192 [03:44<00:41, 29.56it/s, est. speed input: 31806.60 toks/s, output: 31.06 toks/s]
Processed prompts:  86%| | 7042/8192 [03:46<00:38, 29.54it/s, est. speed input: 31791.10 toks/s, output: 31.05 toks/s]
Processed prompts:  87%| | 7106/8192 [03:48<00:36, 29.94it/s, est. speed input: 31789.90 toks/s, output: 31.04 toks/s]
Processed prompts:  88%| | 7170/8192 [03:51<00:34, 29.76it/s, est. speed input: 31773.68 toks/s, output: 31.03 toks/s]
Processed prompts:  88%| | 7234/8192 [03:53<00:32, 29.81it/s, est. speed input: 31763.26 toks/s, output: 31.02 toks/s]
Processed prompts:  89%| | 7298/8192 [03:55<00:30, 29.69it/s, est. speed input: 31747.92 toks/s, output: 31.00 toks/s]
Processed prompts:  90%| | 7362/8192 [03:57<00:27, 29.78it/s, est. speed input: 31738.83 toks/s, output: 30.99 toks/s]
Processed prompts:  91%| | 7426/8192 [03:59<00:25, 29.71it/s, est. speed input: 31725.24 toks/s, output: 30.98 toks/s]
Processed prompts:  91%|| 7490/8192 [04:01<00:23, 29.89it/s, est. speed input: 31719.44 toks/s, output: 30.98 toks/s]
Processed prompts:  92%|| 7554/8192 [04:03<00:21, 30.03it/s, est. speed input: 31713.83 toks/s, output: 30.97 toks/s]
Processed prompts:  93%|| 7618/8192 [04:05<00:18, 30.25it/s, est. speed input: 31712.30 toks/s, output: 30.97 toks/s]
Processed prompts:  94%|| 7682/8192 [04:08<00:16, 30.00it/s, est. speed input: 31698.62 toks/s, output: 30.96 toks/s]
Processed prompts:  95%|| 7746/8192 [04:10<00:14, 29.85it/s, est. speed input: 31685.56 toks/s, output: 30.94 toks/s]
Processed prompts:  95%|| 7810/8192 [04:12<00:12, 29.64it/s, est. speed input: 31669.91 toks/s, output: 30.93 toks/s]
Processed prompts:  96%|| 7874/8192 [04:14<00:10, 29.51it/s, est. speed input: 31654.59 toks/s, output: 30.91 toks/s]
Processed prompts:  97%|| 7938/8192 [04:16<00:08, 29.46it/s, est. speed input: 31640.88 toks/s, output: 30.90 toks/s]
Processed prompts:  98%|| 8002/8192 [04:19<00:06, 29.46it/s, est. speed input: 31628.57 toks/s, output: 30.89 toks/s]
Processed prompts:  98%|| 8066/8192 [04:21<00:04, 29.56it/s, est. speed input: 31619.45 toks/s, output: 30.88 toks/s]
Processed prompts:  99%|| 8130/8192 [04:23<00:02, 29.65it/s, est. speed input: 31610.86 toks/s, output: 30.87 toks/s]
Processed prompts: 100%|| 8192/8192 [04:23<00:00, 29.65it/s, est. speed input: 31851.87 toks/s, output: 31.11 toks/s]
Processed prompts: 100%|| 8192/8192 [04:23<00:00, 31.11it/s, est. speed input: 31851.87 toks/s, output: 31.11 toks/s]
[rank0]:[W126 03:25:42.978630120 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 07:06:17
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:06:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:06:21 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=997557) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=997557) WARNING 01-26 07:06:41 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 49.83 requests/s, 25563.44 total tokens/s, 49.83 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 07:06:21] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:06:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:06:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:06:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:06:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:06:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:06:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:06:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:06:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:06:24] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:06:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:06:24] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:06:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:06:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:06:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:06:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:06:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:06:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=997557) [2026-01-26 07:06:25] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=997557) [2026-01-26 07:06:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=997557) [2026-01-26 07:06:25] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=997557) [2026-01-26 07:06:25] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=997557) [2026-01-26 07:06:25] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=997557) [2026-01-26 07:06:25] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=997557) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=997557) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.28s/it]
(EngineCore_DP0 pid=997557) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.28s/it]
(EngineCore_DP0 pid=997557) 
(EngineCore_DP0 pid=997557) [2026-01-26 07:06:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=997557) [2026-01-26 07:06:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=997557) [2026-01-26 07:06:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=997557) [2026-01-26 07:06:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=997557) [2026-01-26 07:06:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=997557) [2026-01-26 07:06:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=997557) [2026-01-26 07:06:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=997557) [2026-01-26 07:06:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=997557) 2026-01-26 07:06:40,890 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=997557) 2026-01-26 07:06:40,897 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1313.15it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 6/128 [00:00<00:02, 54.70it/s, est. speed input: 28015.41 toks/s, output: 54.71 toks/s]
Processed prompts:   9%|         | 12/128 [00:00<00:02, 52.50it/s, est. speed input: 27049.18 toks/s, output: 52.82 toks/s]
Processed prompts:  14%|        | 18/128 [00:00<00:02, 52.28it/s, est. speed input: 26907.49 toks/s, output: 52.55 toks/s]
Processed prompts:  19%|        | 24/128 [00:00<00:02, 51.03it/s, est. speed input: 26458.90 toks/s, output: 51.68 toks/s]
Processed prompts:  23%|       | 30/128 [00:00<00:01, 51.18it/s, est. speed input: 26436.52 toks/s, output: 51.63 toks/s]
Processed prompts:  28%|       | 36/128 [00:00<00:01, 51.39it/s, est. speed input: 26451.45 toks/s, output: 51.66 toks/s]
Processed prompts:  33%|      | 42/128 [00:00<00:01, 51.74it/s, est. speed input: 26510.72 toks/s, output: 51.78 toks/s]
Processed prompts:  38%|      | 48/128 [00:00<00:01, 51.76it/s, est. speed input: 26511.05 toks/s, output: 51.78 toks/s]
Processed prompts:  42%|     | 54/128 [00:01<00:01, 51.86it/s, est. speed input: 26527.82 toks/s, output: 51.81 toks/s]
Processed prompts:  47%|     | 60/128 [00:01<00:01, 52.04it/s, est. speed input: 26559.97 toks/s, output: 51.87 toks/s]
Processed prompts:  52%|    | 66/128 [00:01<00:01, 52.10it/s, est. speed input: 26576.52 toks/s, output: 51.91 toks/s]
Processed prompts:  56%|    | 72/128 [00:01<00:01, 52.10it/s, est. speed input: 26585.31 toks/s, output: 51.92 toks/s]
Processed prompts:  61%|    | 78/128 [00:01<00:00, 51.23it/s, est. speed input: 26478.03 toks/s, output: 51.71 toks/s]
Processed prompts:  66%|   | 84/128 [00:01<00:00, 51.30it/s, est. speed input: 26469.09 toks/s, output: 51.70 toks/s]
Processed prompts:  70%|   | 90/128 [00:01<00:00, 51.63it/s, est. speed input: 26493.04 toks/s, output: 51.74 toks/s]
Processed prompts:  75%|  | 96/128 [00:01<00:00, 51.66it/s, est. speed input: 26492.27 toks/s, output: 51.74 toks/s]
Processed prompts:  80%|  | 102/128 [00:01<00:00, 51.67it/s, est. speed input: 26491.16 toks/s, output: 51.74 toks/s]
Processed prompts:  84%| | 108/128 [00:02<00:00, 51.90it/s, est. speed input: 26510.69 toks/s, output: 51.78 toks/s]
Processed prompts:  89%| | 114/128 [00:02<00:00, 51.92it/s, est. speed input: 26515.37 toks/s, output: 51.79 toks/s]
Processed prompts:  94%|| 120/128 [00:02<00:00, 52.02it/s, est. speed input: 26527.10 toks/s, output: 51.81 toks/s]
Processed prompts:  98%|| 126/128 [00:02<00:00, 51.84it/s, est. speed input: 26517.49 toks/s, output: 51.79 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 51.84it/s, est. speed input: 26531.77 toks/s, output: 51.82 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 51.82it/s, est. speed input: 26531.77 toks/s, output: 51.82 toks/s]
[rank0]:[W126 07:06:44.374269322 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 07:06:46
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:06:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:06:50 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=998184) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=998184) WARNING 01-26 07:07:09 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.16 requests/s, 28865.76 total tokens/s, 28.16 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 07:06:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:06:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:06:50] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:06:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:06:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:06:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:06:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:06:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:06:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:06:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:06:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:06:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:06:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:06:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:06:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:06:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:06:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:06:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:06:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=998184) [2026-01-26 07:06:54] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=998184) [2026-01-26 07:06:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=998184) [2026-01-26 07:06:54] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=998184) [2026-01-26 07:06:54] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=998184) [2026-01-26 07:06:54] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=998184) [2026-01-26 07:06:54] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=998184) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=998184) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.16s/it]
(EngineCore_DP0 pid=998184) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.16s/it]
(EngineCore_DP0 pid=998184) 
(EngineCore_DP0 pid=998184) [2026-01-26 07:07:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=998184) [2026-01-26 07:07:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=998184) [2026-01-26 07:07:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=998184) [2026-01-26 07:07:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=998184) [2026-01-26 07:07:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=998184) [2026-01-26 07:07:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=998184) [2026-01-26 07:07:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=998184) [2026-01-26 07:07:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=998184) 2026-01-26 07:07:09,420 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=998184) 2026-01-26 07:07:09,427 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  33%|      | 42/128 [00:00<00:00, 416.38it/s]
Adding requests:  78%|  | 100/128 [00:00<00:00, 506.49it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 499.74it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:01, 79.41it/s, est. speed input: 81328.29 toks/s, output: 79.42 toks/s]
Processed prompts:  12%|        | 16/128 [00:00<00:02, 39.21it/s, est. speed input: 43447.97 toks/s, output: 42.43 toks/s]
Processed prompts:  16%|        | 21/128 [00:00<00:03, 34.72it/s, est. speed input: 38927.73 toks/s, output: 38.01 toks/s]
Processed prompts:  20%|        | 26/128 [00:00<00:03, 32.34it/s, est. speed input: 36543.57 toks/s, output: 35.69 toks/s]
Processed prompts:  23%|       | 30/128 [00:00<00:03, 31.30it/s, est. speed input: 35421.51 toks/s, output: 34.59 toks/s]
Processed prompts:  27%|       | 34/128 [00:01<00:03, 30.54it/s, est. speed input: 34592.87 toks/s, output: 33.78 toks/s]
Processed prompts:  30%|       | 38/128 [00:01<00:03, 29.86it/s, est. speed input: 33901.82 toks/s, output: 33.11 toks/s]
Processed prompts:  33%|      | 42/128 [00:01<00:02, 29.39it/s, est. speed input: 33362.08 toks/s, output: 32.58 toks/s]
Processed prompts:  35%|      | 45/128 [00:01<00:02, 29.40it/s, est. speed input: 33126.11 toks/s, output: 32.35 toks/s]
Processed prompts:  38%|      | 48/128 [00:01<00:02, 29.29it/s, est. speed input: 32886.78 toks/s, output: 32.12 toks/s]
Processed prompts:  40%|      | 51/128 [00:01<00:02, 29.14it/s, est. speed input: 32660.43 toks/s, output: 31.89 toks/s]
Processed prompts:  42%|     | 54/128 [00:01<00:02, 29.05it/s, est. speed input: 32467.76 toks/s, output: 31.71 toks/s]
Processed prompts:  45%|     | 57/128 [00:01<00:02, 29.02it/s, est. speed input: 32304.62 toks/s, output: 31.55 toks/s]
Processed prompts:  47%|     | 60/128 [00:01<00:02, 29.01it/s, est. speed input: 32161.94 toks/s, output: 31.41 toks/s]
Processed prompts:  49%|     | 63/128 [00:02<00:02, 28.90it/s, est. speed input: 32015.99 toks/s, output: 31.27 toks/s]
Processed prompts:  52%|    | 66/128 [00:02<00:02, 28.87it/s, est. speed input: 31890.21 toks/s, output: 31.14 toks/s]
Processed prompts:  54%|    | 69/128 [00:02<00:02, 28.40it/s, est. speed input: 31699.03 toks/s, output: 30.96 toks/s]
Processed prompts:  56%|    | 72/128 [00:02<00:01, 28.66it/s, est. speed input: 31624.57 toks/s, output: 30.88 toks/s]
Processed prompts:  59%|    | 75/128 [00:02<00:01, 28.45it/s, est. speed input: 31492.45 toks/s, output: 30.75 toks/s]
Processed prompts:  61%|    | 78/128 [00:02<00:01, 28.63it/s, est. speed input: 31422.08 toks/s, output: 30.69 toks/s]
Processed prompts:  63%|   | 81/128 [00:02<00:01, 28.79it/s, est. speed input: 31362.54 toks/s, output: 30.63 toks/s]
Processed prompts:  66%|   | 84/128 [00:02<00:01, 28.70it/s, est. speed input: 31278.27 toks/s, output: 30.54 toks/s]
Processed prompts:  68%|   | 87/128 [00:02<00:01, 28.66it/s, est. speed input: 31203.33 toks/s, output: 30.47 toks/s]
Processed prompts:  70%|   | 90/128 [00:02<00:01, 28.86it/s, est. speed input: 31163.11 toks/s, output: 30.43 toks/s]
Processed prompts:  73%|  | 93/128 [00:03<00:01, 28.90it/s, est. speed input: 31113.57 toks/s, output: 30.38 toks/s]
Processed prompts:  75%|  | 96/128 [00:03<00:01, 28.92it/s, est. speed input: 31066.28 toks/s, output: 30.34 toks/s]
Processed prompts:  77%|  | 99/128 [00:03<00:01, 28.27it/s, est. speed input: 30944.28 toks/s, output: 30.22 toks/s]
Processed prompts:  80%|  | 102/128 [00:03<00:00, 28.37it/s, est. speed input: 30893.80 toks/s, output: 30.17 toks/s]
Processed prompts:  82%| | 105/128 [00:03<00:00, 28.74it/s, est. speed input: 30877.70 toks/s, output: 30.15 toks/s]
Processed prompts:  84%| | 108/128 [00:03<00:00, 28.65it/s, est. speed input: 30826.16 toks/s, output: 30.10 toks/s]
Processed prompts:  87%| | 111/128 [00:03<00:00, 28.71it/s, est. speed input: 30789.90 toks/s, output: 30.07 toks/s]
Processed prompts:  89%| | 114/128 [00:03<00:00, 28.94it/s, est. speed input: 30774.37 toks/s, output: 30.05 toks/s]
Processed prompts:  91%|| 117/128 [00:03<00:00, 28.92it/s, est. speed input: 30741.56 toks/s, output: 30.02 toks/s]
Processed prompts:  94%|| 120/128 [00:04<00:00, 28.67it/s, est. speed input: 30689.69 toks/s, output: 29.97 toks/s]
Processed prompts:  96%|| 123/128 [00:04<00:00, 28.82it/s, est. speed input: 30668.80 toks/s, output: 29.95 toks/s]
Processed prompts:  98%|| 126/128 [00:04<00:00, 28.59it/s, est. speed input: 30620.05 toks/s, output: 29.90 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 28.59it/s, est. speed input: 30567.79 toks/s, output: 29.85 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 29.85it/s, est. speed input: 30567.79 toks/s, output: 29.85 toks/s]
[rank0]:[W126 07:07:14.910246787 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 07:07:16
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:07:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:07:21 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=998873) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=998873) WARNING 01-26 07:07:40 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 30.21 requests/s, 30965.96 total tokens/s, 30.21 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 07:07:21] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:07:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:07:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:07:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:07:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:07:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:07:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:07:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:07:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:07:24] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:07:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:07:24] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:07:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:07:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:07:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:07:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:07:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:07:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=998873) [2026-01-26 07:07:25] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=998873) [2026-01-26 07:07:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=998873) [2026-01-26 07:07:25] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=998873) [2026-01-26 07:07:25] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=998873) [2026-01-26 07:07:25] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=998873) [2026-01-26 07:07:25] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=998873) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=998873) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.96s/it]
(EngineCore_DP0 pid=998873) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.96s/it]
(EngineCore_DP0 pid=998873) 
(EngineCore_DP0 pid=998873) [2026-01-26 07:07:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=998873) [2026-01-26 07:07:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=998873) [2026-01-26 07:07:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=998873) [2026-01-26 07:07:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=998873) [2026-01-26 07:07:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=998873) [2026-01-26 07:07:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=998873) [2026-01-26 07:07:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=998873) [2026-01-26 07:07:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=998873) 2026-01-26 07:07:40,102 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=998873) 2026-01-26 07:07:40,108 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  24%|       | 61/256 [00:00<00:00, 608.04it/s]
Adding requests:  48%|     | 122/256 [00:00<00:00, 585.16it/s]
Adding requests:  71%|   | 181/256 [00:00<00:00, 568.36it/s]
Adding requests:  93%|| 238/256 [00:00<00:00, 568.69it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 572.46it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 12/256 [00:00<00:02, 118.16it/s, est. speed input: 121025.05 toks/s, output: 118.17 toks/s]
Processed prompts:   9%|         | 24/256 [00:00<00:05, 43.94it/s, est. speed input: 49676.73 toks/s, output: 48.51 toks/s]   
Processed prompts:  12%|        | 31/256 [00:00<00:05, 41.07it/s, est. speed input: 46146.11 toks/s, output: 45.06 toks/s]
Processed prompts:  14%|        | 37/256 [00:00<00:05, 37.67it/s, est. speed input: 43060.99 toks/s, output: 42.05 toks/s]
Processed prompts:  16%|        | 42/256 [00:01<00:06, 33.88it/s, est. speed input: 40161.48 toks/s, output: 39.22 toks/s]
Processed prompts:  18%|        | 46/256 [00:01<00:06, 33.02it/s, est. speed input: 39167.17 toks/s, output: 38.25 toks/s]
Processed prompts:  20%|        | 50/256 [00:01<00:06, 32.48it/s, est. speed input: 38439.11 toks/s, output: 37.54 toks/s]
Processed prompts:  21%|        | 54/256 [00:01<00:06, 32.12it/s, est. speed input: 37861.18 toks/s, output: 36.97 toks/s]
Processed prompts:  23%|       | 58/256 [00:01<00:06, 31.33it/s, est. speed input: 37199.41 toks/s, output: 36.33 toks/s]
Processed prompts:  24%|       | 62/256 [00:01<00:06, 31.26it/s, est. speed input: 36798.37 toks/s, output: 35.94 toks/s]
Processed prompts:  26%|       | 66/256 [00:01<00:06, 31.29it/s, est. speed input: 36476.16 toks/s, output: 35.62 toks/s]
Processed prompts:  27%|       | 70/256 [00:01<00:05, 31.28it/s, est. speed input: 36186.26 toks/s, output: 35.34 toks/s]
Processed prompts:  29%|       | 74/256 [00:02<00:05, 31.18it/s, est. speed input: 35910.98 toks/s, output: 35.07 toks/s]
Processed prompts:  30%|       | 78/256 [00:02<00:05, 31.00it/s, est. speed input: 35643.25 toks/s, output: 34.81 toks/s]
Processed prompts:  32%|      | 82/256 [00:02<00:05, 30.90it/s, est. speed input: 35409.87 toks/s, output: 34.58 toks/s]
Processed prompts:  34%|      | 86/256 [00:02<00:05, 31.12it/s, est. speed input: 35258.68 toks/s, output: 34.43 toks/s]
Processed prompts:  35%|      | 90/256 [00:02<00:05, 30.53it/s, est. speed input: 34981.53 toks/s, output: 34.16 toks/s]
Processed prompts:  37%|      | 94/256 [00:02<00:05, 30.56it/s, est. speed input: 34810.01 toks/s, output: 33.99 toks/s]
Processed prompts:  38%|      | 98/256 [00:02<00:05, 30.65it/s, est. speed input: 34666.44 toks/s, output: 33.85 toks/s]
Processed prompts:  40%|      | 102/256 [00:03<00:05, 30.70it/s, est. speed input: 34533.49 toks/s, output: 33.72 toks/s]
Processed prompts:  41%|     | 106/256 [00:03<00:04, 30.70it/s, est. speed input: 34404.85 toks/s, output: 33.60 toks/s]
Processed prompts:  43%|     | 110/256 [00:03<00:04, 30.77it/s, est. speed input: 34297.37 toks/s, output: 33.49 toks/s]
Processed prompts:  45%|     | 114/256 [00:03<00:04, 30.90it/s, est. speed input: 34209.31 toks/s, output: 33.41 toks/s]
Processed prompts:  46%|     | 118/256 [00:03<00:04, 30.94it/s, est. speed input: 34121.08 toks/s, output: 33.32 toks/s]
Processed prompts:  48%|     | 122/256 [00:03<00:04, 30.56it/s, est. speed input: 33985.08 toks/s, output: 33.19 toks/s]
Processed prompts:  49%|     | 126/256 [00:03<00:04, 30.59it/s, est. speed input: 33896.45 toks/s, output: 33.10 toks/s]
Processed prompts:  51%|     | 130/256 [00:03<00:04, 30.83it/s, est. speed input: 33839.85 toks/s, output: 33.05 toks/s]
Processed prompts:  52%|    | 134/256 [00:04<00:03, 30.71it/s, est. speed input: 33753.27 toks/s, output: 32.96 toks/s]
Processed prompts:  54%|    | 138/256 [00:04<00:03, 30.73it/s, est. speed input: 33683.92 toks/s, output: 32.89 toks/s]
Processed prompts:  55%|    | 142/256 [00:04<00:03, 30.79it/s, est. speed input: 33623.94 toks/s, output: 32.84 toks/s]
Processed prompts:  57%|    | 146/256 [00:04<00:03, 30.90it/s, est. speed input: 33574.50 toks/s, output: 32.79 toks/s]
Processed prompts:  59%|    | 150/256 [00:04<00:03, 31.05it/s, est. speed input: 33534.68 toks/s, output: 32.75 toks/s]
Processed prompts:  60%|    | 154/256 [00:04<00:03, 30.63it/s, est. speed input: 33445.75 toks/s, output: 32.66 toks/s]
Processed prompts:  62%|   | 158/256 [00:04<00:03, 30.67it/s, est. speed input: 33393.73 toks/s, output: 32.61 toks/s]
Processed prompts:  63%|   | 162/256 [00:04<00:03, 30.93it/s, est. speed input: 33365.81 toks/s, output: 32.58 toks/s]
Processed prompts:  65%|   | 166/256 [00:05<00:02, 31.02it/s, est. speed input: 33331.56 toks/s, output: 32.55 toks/s]
Processed prompts:  66%|   | 170/256 [00:05<00:02, 31.02it/s, est. speed input: 33292.47 toks/s, output: 32.51 toks/s]
Processed prompts:  68%|   | 174/256 [00:05<00:02, 30.74it/s, est. speed input: 33231.60 toks/s, output: 32.45 toks/s]
Processed prompts:  70%|   | 178/256 [00:05<00:02, 30.64it/s, est. speed input: 33181.47 toks/s, output: 32.40 toks/s]
Processed prompts:  71%|   | 182/256 [00:05<00:02, 30.59it/s, est. speed input: 33135.59 toks/s, output: 32.36 toks/s]
Processed prompts:  73%|  | 186/256 [00:05<00:02, 30.28it/s, est. speed input: 33068.56 toks/s, output: 32.29 toks/s]
Processed prompts:  74%|  | 190/256 [00:05<00:02, 30.47it/s, est. speed input: 33038.12 toks/s, output: 32.26 toks/s]
Processed prompts:  76%|  | 194/256 [00:06<00:02, 30.60it/s, est. speed input: 33007.72 toks/s, output: 32.23 toks/s]
Processed prompts:  77%|  | 198/256 [00:06<00:01, 30.51it/s, est. speed input: 32965.76 toks/s, output: 32.19 toks/s]
Processed prompts:  79%|  | 202/256 [00:06<00:01, 30.62it/s, est. speed input: 32937.84 toks/s, output: 32.17 toks/s]
Processed prompts:  80%|  | 206/256 [00:06<00:01, 30.46it/s, est. speed input: 32893.73 toks/s, output: 32.12 toks/s]
Processed prompts:  82%| | 210/256 [00:06<00:01, 30.38it/s, est. speed input: 32854.03 toks/s, output: 32.08 toks/s]
Processed prompts:  84%| | 214/256 [00:06<00:01, 30.49it/s, est. speed input: 32827.41 toks/s, output: 32.06 toks/s]
Processed prompts:  85%| | 218/256 [00:06<00:01, 30.32it/s, est. speed input: 32784.64 toks/s, output: 32.02 toks/s]
Processed prompts:  87%| | 222/256 [00:06<00:01, 30.56it/s, est. speed input: 32767.68 toks/s, output: 32.00 toks/s]
Processed prompts:  88%| | 226/256 [00:07<00:00, 30.70it/s, est. speed input: 32749.79 toks/s, output: 31.98 toks/s]
Processed prompts:  90%| | 230/256 [00:07<00:00, 30.86it/s, est. speed input: 32736.49 toks/s, output: 31.97 toks/s]
Processed prompts:  91%|| 234/256 [00:07<00:00, 30.66it/s, est. speed input: 32703.62 toks/s, output: 31.94 toks/s]
Processed prompts:  93%|| 238/256 [00:07<00:00, 30.50it/s, est. speed input: 32671.02 toks/s, output: 31.91 toks/s]
Processed prompts:  95%|| 242/256 [00:07<00:00, 30.59it/s, est. speed input: 32651.56 toks/s, output: 31.89 toks/s]
Processed prompts:  96%|| 246/256 [00:07<00:00, 30.45it/s, est. speed input: 32620.50 toks/s, output: 31.86 toks/s]
Processed prompts:  98%|| 250/256 [00:07<00:00, 30.16it/s, est. speed input: 32578.99 toks/s, output: 31.82 toks/s]
Processed prompts:  99%|| 254/256 [00:07<00:00, 30.17it/s, est. speed input: 32551.25 toks/s, output: 31.79 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 30.17it/s, est. speed input: 32666.32 toks/s, output: 31.90 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 31.90it/s, est. speed input: 32666.32 toks/s, output: 31.90 toks/s]
[rank0]:[W126 07:07:49.546582984 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 07:07:51
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:07:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:07:56 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=999642) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=999642) WARNING 01-26 07:08:16 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 29.71 requests/s, 30454.65 total tokens/s, 29.71 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 07:07:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:07:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:07:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:07:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:07:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:07:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:07:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:07:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:07:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:07:59] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:07:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:07:59] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:07:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:07:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:07:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:07:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:07:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:07:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:07:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=999642) [2026-01-26 07:08:00] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=999642) [2026-01-26 07:08:00] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=999642) [2026-01-26 07:08:00] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=999642) [2026-01-26 07:08:00] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=999642) [2026-01-26 07:08:00] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=999642) [2026-01-26 07:08:00] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=999642) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=999642) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.18s/it]
(EngineCore_DP0 pid=999642) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.18s/it]
(EngineCore_DP0 pid=999642) 
(EngineCore_DP0 pid=999642) [2026-01-26 07:08:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=999642) [2026-01-26 07:08:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=999642) [2026-01-26 07:08:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=999642) [2026-01-26 07:08:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=999642) [2026-01-26 07:08:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=999642) [2026-01-26 07:08:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=999642) [2026-01-26 07:08:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=999642) [2026-01-26 07:08:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=999642) 2026-01-26 07:08:15,824 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=999642) 2026-01-26 07:08:15,842 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  12%|        | 62/512 [00:00<00:00, 615.93it/s]
Adding requests:  24%|       | 124/512 [00:00<00:00, 600.16it/s]
Adding requests:  36%|      | 185/512 [00:00<00:00, 566.15it/s]
Adding requests:  47%|     | 242/512 [00:00<00:00, 565.09it/s]
Adding requests:  58%|    | 299/512 [00:00<00:00, 546.89it/s]
Adding requests:  69%|   | 355/512 [00:00<00:00, 550.37it/s]
Adding requests:  80%|  | 411/512 [00:00<00:00, 545.27it/s]
Adding requests:  91%|| 468/512 [00:00<00:00, 550.09it/s]
Adding requests: 100%|| 512/512 [00:00<00:00, 552.49it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 26/512 [00:00<00:03, 148.18it/s, est. speed input: 151746.45 toks/s, output: 148.18 toks/s]
Processed prompts:   8%|         | 41/512 [00:00<00:07, 63.58it/s, est. speed input: 73036.06 toks/s, output: 71.32 toks/s]   
Processed prompts:  10%|         | 50/512 [00:00<00:10, 42.12it/s, est. speed input: 52531.28 toks/s, output: 51.30 toks/s]
Processed prompts:  11%|         | 56/512 [00:01<00:10, 42.68it/s, est. speed input: 51744.01 toks/s, output: 50.53 toks/s]
Processed prompts:  12%|        | 62/512 [00:01<00:12, 35.38it/s, est. speed input: 46190.78 toks/s, output: 45.11 toks/s]
Processed prompts:  13%|        | 67/512 [00:01<00:12, 35.84it/s, est. speed input: 45515.48 toks/s, output: 44.45 toks/s]
Processed prompts:  14%|        | 71/512 [00:01<00:12, 34.49it/s, est. speed input: 44299.99 toks/s, output: 43.26 toks/s]
Processed prompts:  15%|        | 75/512 [00:01<00:13, 33.35it/s, est. speed input: 43264.66 toks/s, output: 42.25 toks/s]
Processed prompts:  15%|        | 79/512 [00:01<00:13, 32.50it/s, est. speed input: 42393.24 toks/s, output: 41.40 toks/s]
Processed prompts:  16%|        | 83/512 [00:02<00:13, 31.41it/s, est. speed input: 41500.54 toks/s, output: 40.53 toks/s]
Processed prompts:  17%|        | 87/512 [00:02<00:13, 31.07it/s, est. speed input: 40854.81 toks/s, output: 39.90 toks/s]
Processed prompts:  18%|        | 91/512 [00:02<00:13, 30.84it/s, est. speed input: 40290.93 toks/s, output: 39.35 toks/s]
Processed prompts:  19%|        | 95/512 [00:02<00:13, 30.55it/s, est. speed input: 39757.74 toks/s, output: 38.83 toks/s]
Processed prompts:  19%|        | 99/512 [00:02<00:13, 30.40it/s, est. speed input: 39292.86 toks/s, output: 38.37 toks/s]
Processed prompts:  20%|        | 103/512 [00:02<00:13, 30.25it/s, est. speed input: 38863.91 toks/s, output: 37.95 toks/s]
Processed prompts:  21%|        | 107/512 [00:02<00:13, 30.18it/s, est. speed input: 38484.23 toks/s, output: 37.58 toks/s]
Processed prompts:  22%|       | 111/512 [00:02<00:13, 30.15it/s, est. speed input: 38140.46 toks/s, output: 37.25 toks/s]
Processed prompts:  22%|       | 115/512 [00:03<00:13, 29.81it/s, est. speed input: 37768.88 toks/s, output: 36.88 toks/s]
Processed prompts:  23%|       | 118/512 [00:03<00:14, 27.75it/s, est. speed input: 37185.12 toks/s, output: 36.31 toks/s]
Processed prompts:  24%|       | 122/512 [00:03<00:13, 28.64it/s, est. speed input: 36967.05 toks/s, output: 36.10 toks/s]
Processed prompts:  25%|       | 126/512 [00:03<00:13, 29.05it/s, est. speed input: 36730.35 toks/s, output: 35.87 toks/s]
Processed prompts:  25%|       | 130/512 [00:03<00:13, 29.31it/s, est. speed input: 36506.43 toks/s, output: 35.65 toks/s]
Processed prompts:  26%|       | 134/512 [00:03<00:12, 29.55it/s, est. speed input: 36307.53 toks/s, output: 35.46 toks/s]
Processed prompts:  27%|       | 138/512 [00:03<00:12, 29.65it/s, est. speed input: 36111.97 toks/s, output: 35.27 toks/s]
Processed prompts:  28%|       | 142/512 [00:04<00:12, 29.84it/s, est. speed input: 35946.25 toks/s, output: 35.10 toks/s]
Processed prompts:  29%|       | 146/512 [00:04<00:12, 29.65it/s, est. speed input: 35748.42 toks/s, output: 34.91 toks/s]
Processed prompts:  29%|       | 150/512 [00:04<00:12, 29.86it/s, est. speed input: 35606.37 toks/s, output: 34.77 toks/s]
Processed prompts:  30%|       | 154/512 [00:04<00:11, 30.14it/s, est. speed input: 35488.58 toks/s, output: 34.66 toks/s]
Processed prompts:  31%|       | 158/512 [00:04<00:11, 29.96it/s, est. speed input: 35333.13 toks/s, output: 34.50 toks/s]
Processed prompts:  32%|      | 162/512 [00:04<00:11, 29.94it/s, est. speed input: 35199.53 toks/s, output: 34.37 toks/s]
Processed prompts:  32%|      | 166/512 [00:04<00:11, 29.82it/s, est. speed input: 35061.39 toks/s, output: 34.24 toks/s]
Processed prompts:  33%|      | 170/512 [00:04<00:11, 29.93it/s, est. speed input: 34950.92 toks/s, output: 34.13 toks/s]
Processed prompts:  34%|      | 174/512 [00:05<00:11, 29.93it/s, est. speed input: 34838.02 toks/s, output: 34.02 toks/s]
Processed prompts:  35%|      | 178/512 [00:05<00:11, 29.57it/s, est. speed input: 34695.85 toks/s, output: 33.88 toks/s]
Processed prompts:  36%|      | 182/512 [00:05<00:11, 29.67it/s, est. speed input: 34594.77 toks/s, output: 33.78 toks/s]
Processed prompts:  36%|      | 186/512 [00:05<00:10, 29.72it/s, est. speed input: 34496.80 toks/s, output: 33.69 toks/s]
Processed prompts:  37%|      | 190/512 [00:05<00:10, 29.74it/s, est. speed input: 34402.16 toks/s, output: 33.60 toks/s]
Processed prompts:  38%|      | 194/512 [00:05<00:10, 29.69it/s, est. speed input: 34305.54 toks/s, output: 33.50 toks/s]
Processed prompts:  39%|      | 198/512 [00:05<00:10, 29.73it/s, est. speed input: 34220.07 toks/s, output: 33.42 toks/s]
Processed prompts:  39%|      | 202/512 [00:06<00:10, 29.84it/s, est. speed input: 34145.65 toks/s, output: 33.35 toks/s]
Processed prompts:  40%|      | 206/512 [00:06<00:10, 30.02it/s, est. speed input: 34083.16 toks/s, output: 33.28 toks/s]
Processed prompts:  41%|      | 210/512 [00:06<00:10, 29.73it/s, est. speed input: 33989.22 toks/s, output: 33.19 toks/s]
Processed prompts:  42%|     | 214/512 [00:06<00:09, 29.82it/s, est. speed input: 33922.17 toks/s, output: 33.13 toks/s]
Processed prompts:  43%|     | 218/512 [00:06<00:09, 29.92it/s, est. speed input: 33860.76 toks/s, output: 33.07 toks/s]
Processed prompts:  43%|     | 222/512 [00:06<00:09, 29.98it/s, est. speed input: 33801.37 toks/s, output: 33.01 toks/s]
Processed prompts:  44%|     | 226/512 [00:06<00:09, 29.99it/s, est. speed input: 33741.58 toks/s, output: 32.95 toks/s]
Processed prompts:  45%|     | 230/512 [00:06<00:09, 30.10it/s, est. speed input: 33692.05 toks/s, output: 32.90 toks/s]
Processed prompts:  46%|     | 234/512 [00:07<00:09, 29.98it/s, est. speed input: 33629.89 toks/s, output: 32.84 toks/s]
Processed prompts:  46%|     | 238/512 [00:07<00:09, 30.02it/s, est. speed input: 33578.94 toks/s, output: 32.79 toks/s]
Processed prompts:  47%|     | 242/512 [00:07<00:09, 29.69it/s, est. speed input: 33504.96 toks/s, output: 32.72 toks/s]
Processed prompts:  48%|     | 246/512 [00:07<00:08, 29.83it/s, est. speed input: 33459.29 toks/s, output: 32.68 toks/s]
Processed prompts:  49%|     | 250/512 [00:07<00:08, 29.96it/s, est. speed input: 33416.74 toks/s, output: 32.63 toks/s]
Processed prompts:  50%|     | 254/512 [00:07<00:08, 29.94it/s, est. speed input: 33368.62 toks/s, output: 32.59 toks/s]
Processed prompts:  50%|     | 258/512 [00:07<00:08, 29.91it/s, est. speed input: 33320.94 toks/s, output: 32.54 toks/s]
Processed prompts:  51%|     | 262/512 [00:08<00:08, 30.13it/s, est. speed input: 33289.67 toks/s, output: 32.51 toks/s]
Processed prompts:  52%|    | 266/512 [00:08<00:08, 30.12it/s, est. speed input: 33249.71 toks/s, output: 32.47 toks/s]
Processed prompts:  53%|    | 270/512 [00:08<00:08, 30.17it/s, est. speed input: 33214.25 toks/s, output: 32.44 toks/s]
Processed prompts:  54%|    | 274/512 [00:08<00:08, 29.74it/s, est. speed input: 33152.80 toks/s, output: 32.38 toks/s]
Processed prompts:  54%|    | 278/512 [00:08<00:07, 29.81it/s, est. speed input: 33114.75 toks/s, output: 32.34 toks/s]
Processed prompts:  55%|    | 282/512 [00:08<00:07, 29.92it/s, est. speed input: 33081.28 toks/s, output: 32.31 toks/s]
Processed prompts:  56%|    | 286/512 [00:08<00:07, 29.98it/s, est. speed input: 33047.60 toks/s, output: 32.27 toks/s]
Processed prompts:  57%|    | 290/512 [00:08<00:07, 30.11it/s, est. speed input: 33019.78 toks/s, output: 32.25 toks/s]
Processed prompts:  57%|    | 294/512 [00:09<00:07, 30.08it/s, est. speed input: 32986.12 toks/s, output: 32.21 toks/s]
Processed prompts:  58%|    | 298/512 [00:09<00:07, 29.99it/s, est. speed input: 32950.38 toks/s, output: 32.18 toks/s]
Processed prompts:  59%|    | 302/512 [00:09<00:07, 29.94it/s, est. speed input: 32915.71 toks/s, output: 32.14 toks/s]
Processed prompts:  60%|    | 306/512 [00:09<00:06, 29.72it/s, est. speed input: 32873.10 toks/s, output: 32.10 toks/s]
Processed prompts:  61%|    | 310/512 [00:09<00:06, 29.85it/s, est. speed input: 32845.34 toks/s, output: 32.08 toks/s]
Processed prompts:  61%|   | 314/512 [00:09<00:06, 29.98it/s, est. speed input: 32820.99 toks/s, output: 32.05 toks/s]
Processed prompts:  62%|   | 318/512 [00:09<00:06, 30.09it/s, est. speed input: 32797.71 toks/s, output: 32.03 toks/s]
Processed prompts:  63%|   | 322/512 [00:10<00:06, 30.04it/s, est. speed input: 32768.97 toks/s, output: 32.00 toks/s]
Processed prompts:  64%|   | 326/512 [00:10<00:06, 30.08it/s, est. speed input: 32744.56 toks/s, output: 31.98 toks/s]
Processed prompts:  64%|   | 330/512 [00:10<00:06, 30.02it/s, est. speed input: 32716.59 toks/s, output: 31.95 toks/s]
Processed prompts:  65%|   | 334/512 [00:10<00:05, 29.78it/s, est. speed input: 32680.39 toks/s, output: 31.91 toks/s]
Processed prompts:  66%|   | 338/512 [00:10<00:05, 29.37it/s, est. speed input: 32633.64 toks/s, output: 31.87 toks/s]
Processed prompts:  67%|   | 342/512 [00:10<00:05, 30.50it/s, est. speed input: 32652.17 toks/s, output: 31.89 toks/s]
Processed prompts:  68%|   | 346/512 [00:10<00:05, 30.32it/s, est. speed input: 32627.40 toks/s, output: 31.86 toks/s]
Processed prompts:  68%|   | 350/512 [00:10<00:05, 30.19it/s, est. speed input: 32602.82 toks/s, output: 31.84 toks/s]
Processed prompts:  69%|   | 354/512 [00:11<00:05, 29.96it/s, est. speed input: 32572.51 toks/s, output: 31.81 toks/s]
Processed prompts:  70%|   | 358/512 [00:11<00:05, 30.01it/s, est. speed input: 32552.36 toks/s, output: 31.79 toks/s]
Processed prompts:  71%|   | 362/512 [00:11<00:04, 30.02it/s, est. speed input: 32531.55 toks/s, output: 31.77 toks/s]
Processed prompts:  71%|  | 366/512 [00:11<00:04, 29.97it/s, est. speed input: 32508.90 toks/s, output: 31.75 toks/s]
Processed prompts:  72%|  | 370/512 [00:11<00:04, 29.57it/s, est. speed input: 32471.31 toks/s, output: 31.71 toks/s]
Processed prompts:  73%|  | 374/512 [00:11<00:04, 29.74it/s, est. speed input: 32453.07 toks/s, output: 31.69 toks/s]
Processed prompts:  74%|  | 378/512 [00:11<00:04, 29.67it/s, est. speed input: 32427.92 toks/s, output: 31.67 toks/s]
Processed prompts:  75%|  | 382/512 [00:12<00:04, 29.86it/s, est. speed input: 32412.55 toks/s, output: 31.65 toks/s]
Processed prompts:  75%|  | 386/512 [00:12<00:04, 29.99it/s, est. speed input: 32397.66 toks/s, output: 31.64 toks/s]
Processed prompts:  76%|  | 390/512 [00:12<00:04, 30.05it/s, est. speed input: 32381.72 toks/s, output: 31.62 toks/s]
Processed prompts:  77%|  | 394/512 [00:12<00:03, 30.14it/s, est. speed input: 32368.10 toks/s, output: 31.61 toks/s]
Processed prompts:  78%|  | 398/512 [00:12<00:03, 29.93it/s, est. speed input: 32344.00 toks/s, output: 31.59 toks/s]
Processed prompts:  79%|  | 402/512 [00:12<00:03, 29.72it/s, est. speed input: 32318.46 toks/s, output: 31.56 toks/s]
Processed prompts:  79%|  | 406/512 [00:12<00:03, 29.92it/s, est. speed input: 32306.22 toks/s, output: 31.55 toks/s]
Processed prompts:  80%|  | 410/512 [00:13<00:03, 29.91it/s, est. speed input: 32288.78 toks/s, output: 31.53 toks/s]
Processed prompts:  81%|  | 414/512 [00:13<00:03, 29.99it/s, est. speed input: 32274.67 toks/s, output: 31.52 toks/s]
Processed prompts:  82%| | 418/512 [00:13<00:03, 29.99it/s, est. speed input: 32258.95 toks/s, output: 31.50 toks/s]
Processed prompts:  82%| | 422/512 [00:13<00:03, 29.99it/s, est. speed input: 32243.53 toks/s, output: 31.49 toks/s]
Processed prompts:  83%| | 426/512 [00:13<00:02, 29.93it/s, est. speed input: 32226.30 toks/s, output: 31.47 toks/s]
Processed prompts:  84%| | 430/512 [00:13<00:02, 29.54it/s, est. speed input: 32196.95 toks/s, output: 31.44 toks/s]
Processed prompts:  85%| | 434/512 [00:13<00:02, 29.69it/s, est. speed input: 32183.13 toks/s, output: 31.43 toks/s]
Processed prompts:  86%| | 438/512 [00:13<00:02, 29.90it/s, est. speed input: 32173.13 toks/s, output: 31.42 toks/s]
Processed prompts:  86%| | 442/512 [00:14<00:02, 29.82it/s, est. speed input: 32155.73 toks/s, output: 31.40 toks/s]
Processed prompts:  87%| | 446/512 [00:14<00:02, 29.96it/s, est. speed input: 32144.96 toks/s, output: 31.39 toks/s]
Processed prompts:  88%| | 450/512 [00:14<00:01, 31.26it/s, est. speed input: 32172.92 toks/s, output: 31.42 toks/s]
Processed prompts:  89%| | 454/512 [00:14<00:01, 30.82it/s, est. speed input: 32157.83 toks/s, output: 31.40 toks/s]
Processed prompts:  89%| | 458/512 [00:14<00:01, 30.64it/s, est. speed input: 32146.96 toks/s, output: 31.39 toks/s]
Processed prompts:  90%| | 462/512 [00:14<00:01, 30.11it/s, est. speed input: 32123.42 toks/s, output: 31.37 toks/s]
Processed prompts:  91%| | 466/512 [00:14<00:01, 30.19it/s, est. speed input: 32114.34 toks/s, output: 31.36 toks/s]
Processed prompts:  92%|| 470/512 [00:14<00:01, 30.10it/s, est. speed input: 32100.99 toks/s, output: 31.35 toks/s]
Processed prompts:  93%|| 474/512 [00:15<00:01, 30.05it/s, est. speed input: 32088.14 toks/s, output: 31.34 toks/s]
Processed prompts:  93%|| 478/512 [00:15<00:01, 30.02it/s, est. speed input: 32075.72 toks/s, output: 31.32 toks/s]
Processed prompts:  94%|| 482/512 [00:15<00:00, 30.18it/s, est. speed input: 32069.04 toks/s, output: 31.32 toks/s]
Processed prompts:  95%|| 486/512 [00:15<00:00, 30.13it/s, est. speed input: 32057.49 toks/s, output: 31.31 toks/s]
Processed prompts:  96%|| 490/512 [00:15<00:00, 30.19it/s, est. speed input: 32049.09 toks/s, output: 31.30 toks/s]
Processed prompts:  96%|| 494/512 [00:15<00:00, 29.77it/s, est. speed input: 32026.95 toks/s, output: 31.28 toks/s]
Processed prompts:  97%|| 498/512 [00:15<00:00, 29.84it/s, est. speed input: 32015.93 toks/s, output: 31.27 toks/s]
Processed prompts:  98%|| 502/512 [00:16<00:00, 29.95it/s, est. speed input: 32006.99 toks/s, output: 31.26 toks/s]
Processed prompts:  99%|| 506/512 [00:16<00:00, 30.01it/s, est. speed input: 31997.84 toks/s, output: 31.25 toks/s]
Processed prompts: 100%|| 510/512 [00:16<00:00, 31.61it/s, est. speed input: 32031.62 toks/s, output: 31.28 toks/s]
Processed prompts: 100%|| 512/512 [00:16<00:00, 31.61it/s, est. speed input: 32157.01 toks/s, output: 31.40 toks/s]
Processed prompts: 100%|| 512/512 [00:16<00:00, 31.40it/s, est. speed input: 32157.01 toks/s, output: 31.40 toks/s]
[rank0]:[W126 07:08:33.093127726 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 07:08:36
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:08:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:08:42 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1000472) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1000472) WARNING 01-26 07:09:02 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 29.18 requests/s, 29909.91 total tokens/s, 29.18 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 07:08:42] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:08:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:08:42] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:08:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:08:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:08:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:08:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:08:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:08:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:08:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:08:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:08:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:08:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:08:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:08:45] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:08:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:08:45] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:08:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:08:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:08:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:08:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:08:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:08:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:08:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:08:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:08:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:08:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:08:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1000472) [2026-01-26 07:08:46] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1000472) [2026-01-26 07:08:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1000472) [2026-01-26 07:08:46] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1000472) [2026-01-26 07:08:46] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1000472) [2026-01-26 07:08:46] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1000472) [2026-01-26 07:08:46] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1000472) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1000472) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.02s/it]
(EngineCore_DP0 pid=1000472) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.02s/it]
(EngineCore_DP0 pid=1000472) 
(EngineCore_DP0 pid=1000472) [2026-01-26 07:08:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1000472) [2026-01-26 07:08:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=1000472) [2026-01-26 07:08:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1000472) [2026-01-26 07:08:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=1000472) [2026-01-26 07:08:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1000472) [2026-01-26 07:08:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=1000472) [2026-01-26 07:08:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1000472) [2026-01-26 07:08:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=1000472) 2026-01-26 07:09:01,703 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1000472) 2026-01-26 07:09:01,753 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   6%|         | 61/1024 [00:00<00:01, 601.54it/s]
Adding requests:  12%|        | 122/1024 [00:00<00:01, 581.33it/s]
Adding requests:  18%|        | 181/1024 [00:00<00:01, 543.12it/s]
Adding requests:  23%|       | 236/1024 [00:00<00:01, 543.34it/s]
Adding requests:  28%|       | 291/1024 [00:00<00:01, 527.76it/s]
Adding requests:  34%|      | 344/1024 [00:00<00:01, 519.86it/s]
Adding requests:  39%|      | 397/1024 [00:00<00:01, 513.97it/s]
Adding requests:  44%|     | 449/1024 [00:00<00:01, 508.72it/s]
Adding requests:  49%|     | 500/1024 [00:00<00:01, 503.66it/s]
Adding requests:  54%|    | 551/1024 [00:01<00:00, 480.83it/s]
Adding requests:  59%|    | 603/1024 [00:01<00:00, 490.22it/s]
Adding requests:  64%|   | 656/1024 [00:01<00:00, 498.99it/s]
Adding requests:  69%|   | 709/1024 [00:01<00:00, 506.54it/s]
Adding requests:  74%|  | 760/1024 [00:01<00:00, 500.28it/s]
Adding requests:  79%|  | 811/1024 [00:01<00:00, 494.83it/s]
Adding requests:  84%| | 861/1024 [00:01<00:00, 491.21it/s]
Adding requests:  89%| | 913/1024 [00:01<00:00, 497.71it/s]
Adding requests:  94%|| 964/1024 [00:01<00:00, 499.10it/s]
Adding requests:  99%|| 1015/1024 [00:01<00:00, 501.94it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 507.98it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 58/1024 [00:00<00:05, 168.49it/s, est. speed input: 172544.20 toks/s, output: 168.49 toks/s]
Processed prompts:   7%|         | 75/1024 [00:00<00:12, 73.16it/s, est. speed input: 86236.75 toks/s, output: 84.22 toks/s]   
Processed prompts:   8%|         | 84/1024 [00:01<00:15, 59.85it/s, est. speed input: 73929.57 toks/s, output: 72.20 toks/s]
Processed prompts:   9%|         | 91/1024 [00:01<00:19, 48.51it/s, est. speed input: 64593.97 toks/s, output: 63.08 toks/s]
Processed prompts:  10%|         | 98/1024 [00:01<00:22, 41.43it/s, est. speed input: 58546.26 toks/s, output: 57.17 toks/s]
Processed prompts:  10%|         | 106/1024 [00:01<00:24, 37.77it/s, est. speed input: 54686.40 toks/s, output: 53.40 toks/s]
Processed prompts:  11%|         | 114/1024 [00:02<00:25, 35.19it/s, est. speed input: 51712.57 toks/s, output: 50.50 toks/s]
Processed prompts:  12%|        | 122/1024 [00:02<00:27, 33.23it/s, est. speed input: 49285.51 toks/s, output: 48.13 toks/s]
Processed prompts:  13%|        | 130/1024 [00:02<00:27, 32.01it/s, est. speed input: 47393.98 toks/s, output: 46.28 toks/s]
Processed prompts:  13%|        | 138/1024 [00:03<00:28, 31.23it/s, est. speed input: 45869.02 toks/s, output: 44.79 toks/s]
Processed prompts:  14%|        | 146/1024 [00:03<00:28, 30.50it/s, est. speed input: 44518.77 toks/s, output: 43.48 toks/s]
Processed prompts:  15%|        | 154/1024 [00:03<00:28, 30.14it/s, est. speed input: 43428.49 toks/s, output: 42.41 toks/s]
Processed prompts:  16%|        | 162/1024 [00:03<00:28, 29.94it/s, est. speed input: 42505.70 toks/s, output: 41.51 toks/s]
Processed prompts:  17%|        | 170/1024 [00:04<00:28, 29.76it/s, est. speed input: 41690.91 toks/s, output: 40.71 toks/s]
Processed prompts:  17%|        | 178/1024 [00:04<00:28, 29.49it/s, est. speed input: 40935.63 toks/s, output: 39.98 toks/s]
Processed prompts:  18%|        | 186/1024 [00:04<00:28, 29.47it/s, est. speed input: 40315.27 toks/s, output: 39.37 toks/s]
Processed prompts:  19%|        | 194/1024 [00:04<00:28, 29.39it/s, est. speed input: 39744.40 toks/s, output: 38.81 toks/s]
Processed prompts:  20%|        | 202/1024 [00:05<00:27, 29.47it/s, est. speed input: 39264.37 toks/s, output: 38.34 toks/s]
Processed prompts:  21%|        | 210/1024 [00:05<00:27, 29.21it/s, est. speed input: 38762.89 toks/s, output: 37.85 toks/s]
Processed prompts:  21%|       | 218/1024 [00:05<00:27, 29.33it/s, est. speed input: 38371.04 toks/s, output: 37.47 toks/s]
Processed prompts:  22%|       | 226/1024 [00:06<00:27, 29.30it/s, est. speed input: 37992.05 toks/s, output: 37.10 toks/s]
Processed prompts:  23%|       | 234/1024 [00:06<00:26, 29.32it/s, est. speed input: 37652.71 toks/s, output: 36.77 toks/s]
Processed prompts:  24%|       | 242/1024 [00:06<00:26, 29.14it/s, est. speed input: 37307.21 toks/s, output: 36.43 toks/s]
Processed prompts:  24%|       | 250/1024 [00:06<00:26, 29.29it/s, est. speed input: 37035.49 toks/s, output: 36.17 toks/s]
Processed prompts:  25%|       | 258/1024 [00:07<00:26, 29.33it/s, est. speed input: 36774.07 toks/s, output: 35.91 toks/s]
Processed prompts:  26%|       | 266/1024 [00:07<00:25, 29.37it/s, est. speed input: 36533.55 toks/s, output: 35.68 toks/s]
Processed prompts:  27%|       | 274/1024 [00:07<00:25, 29.15it/s, est. speed input: 36274.45 toks/s, output: 35.42 toks/s]
Processed prompts:  28%|       | 282/1024 [00:08<00:25, 29.23it/s, est. speed input: 36065.52 toks/s, output: 35.22 toks/s]
Processed prompts:  28%|       | 290/1024 [00:08<00:25, 29.28it/s, est. speed input: 35870.00 toks/s, output: 35.03 toks/s]
Processed prompts:  29%|       | 298/1024 [00:08<00:24, 29.37it/s, est. speed input: 35693.13 toks/s, output: 34.86 toks/s]
Processed prompts:  30%|       | 306/1024 [00:08<00:24, 29.14it/s, est. speed input: 35490.72 toks/s, output: 34.66 toks/s]
Processed prompts:  31%|       | 314/1024 [00:09<00:24, 29.13it/s, est. speed input: 35319.64 toks/s, output: 34.49 toks/s]
Processed prompts:  31%|      | 322/1024 [00:09<00:24, 29.20it/s, est. speed input: 35166.16 toks/s, output: 34.34 toks/s]
Processed prompts:  32%|      | 330/1024 [00:09<00:23, 29.26it/s, est. speed input: 35023.68 toks/s, output: 34.20 toks/s]
Processed prompts:  33%|      | 338/1024 [00:09<00:23, 29.49it/s, est. speed input: 34909.36 toks/s, output: 34.09 toks/s]
Processed prompts:  34%|      | 346/1024 [00:10<00:23, 29.46it/s, est. speed input: 34781.15 toks/s, output: 33.97 toks/s]
Processed prompts:  35%|      | 354/1024 [00:10<00:22, 29.46it/s, est. speed input: 34660.97 toks/s, output: 33.85 toks/s]
Processed prompts:  35%|      | 362/1024 [00:10<00:22, 29.42it/s, est. speed input: 34543.79 toks/s, output: 33.73 toks/s]
Processed prompts:  36%|      | 370/1024 [00:11<00:22, 29.15it/s, est. speed input: 34408.55 toks/s, output: 33.60 toks/s]
Processed prompts:  37%|      | 378/1024 [00:11<00:22, 29.27it/s, est. speed input: 34308.99 toks/s, output: 33.50 toks/s]
Processed prompts:  38%|      | 386/1024 [00:11<00:21, 29.29it/s, est. speed input: 34208.29 toks/s, output: 33.41 toks/s]
Processed prompts:  38%|      | 394/1024 [00:11<00:21, 29.39it/s, est. speed input: 34119.43 toks/s, output: 33.32 toks/s]
Processed prompts:  39%|      | 402/1024 [00:12<00:21, 29.18it/s, est. speed input: 34010.91 toks/s, output: 33.21 toks/s]
Processed prompts:  40%|      | 410/1024 [00:12<00:20, 29.29it/s, est. speed input: 33928.46 toks/s, output: 33.13 toks/s]
Processed prompts:  41%|      | 418/1024 [00:12<00:20, 29.29it/s, est. speed input: 33843.30 toks/s, output: 33.05 toks/s]
Processed prompts:  42%|     | 426/1024 [00:12<00:20, 29.25it/s, est. speed input: 33758.92 toks/s, output: 32.97 toks/s]
Processed prompts:  42%|     | 434/1024 [00:13<00:20, 29.13it/s, est. speed input: 33670.77 toks/s, output: 32.88 toks/s]
Processed prompts:  43%|     | 442/1024 [00:13<00:19, 29.10it/s, est. speed input: 33590.10 toks/s, output: 32.80 toks/s]
Processed prompts:  44%|     | 450/1024 [00:13<00:19, 29.76it/s, est. speed input: 33563.85 toks/s, output: 32.78 toks/s]
Processed prompts:  45%|     | 458/1024 [00:14<00:19, 29.50it/s, est. speed input: 33485.63 toks/s, output: 32.70 toks/s]
Processed prompts:  46%|     | 466/1024 [00:14<00:18, 29.44it/s, est. speed input: 33418.94 toks/s, output: 32.64 toks/s]
Processed prompts:  46%|     | 474/1024 [00:14<00:18, 29.41it/s, est. speed input: 33355.68 toks/s, output: 32.57 toks/s]
Processed prompts:  47%|     | 482/1024 [00:14<00:18, 29.38it/s, est. speed input: 33294.01 toks/s, output: 32.51 toks/s]
Processed prompts:  48%|     | 490/1024 [00:15<00:18, 29.30it/s, est. speed input: 33231.12 toks/s, output: 32.45 toks/s]
Processed prompts:  49%|     | 498/1024 [00:15<00:17, 29.24it/s, est. speed input: 33169.59 toks/s, output: 32.39 toks/s]
Processed prompts:  49%|     | 506/1024 [00:15<00:17, 29.28it/s, est. speed input: 33115.48 toks/s, output: 32.34 toks/s]
Processed prompts:  50%|     | 514/1024 [00:15<00:17, 29.44it/s, est. speed input: 33072.22 toks/s, output: 32.30 toks/s]
Processed prompts:  51%|     | 522/1024 [00:16<00:17, 29.19it/s, est. speed input: 33007.19 toks/s, output: 32.23 toks/s]
Processed prompts:  52%|    | 530/1024 [00:16<00:16, 29.25it/s, est. speed input: 32958.91 toks/s, output: 32.19 toks/s]
Processed prompts:  53%|    | 538/1024 [00:16<00:16, 29.27it/s, est. speed input: 32911.38 toks/s, output: 32.14 toks/s]
Processed prompts:  53%|    | 546/1024 [00:17<00:16, 29.40it/s, est. speed input: 32871.58 toks/s, output: 32.10 toks/s]
Processed prompts:  54%|    | 554/1024 [00:17<00:16, 29.24it/s, est. speed input: 32818.94 toks/s, output: 32.05 toks/s]
Processed prompts:  55%|    | 562/1024 [00:17<00:15, 29.22it/s, est. speed input: 32773.10 toks/s, output: 32.00 toks/s]
Processed prompts:  56%|    | 570/1024 [00:17<00:15, 29.22it/s, est. speed input: 32729.20 toks/s, output: 31.96 toks/s]
Processed prompts:  56%|    | 578/1024 [00:18<00:15, 29.29it/s, est. speed input: 32690.93 toks/s, output: 31.92 toks/s]
Processed prompts:  57%|    | 586/1024 [00:18<00:15, 29.16it/s, est. speed input: 32643.44 toks/s, output: 31.88 toks/s]
Processed prompts:  58%|    | 594/1024 [00:18<00:14, 29.18it/s, est. speed input: 32603.52 toks/s, output: 31.84 toks/s]
Processed prompts:  59%|    | 602/1024 [00:18<00:14, 29.23it/s, est. speed input: 32566.77 toks/s, output: 31.80 toks/s]
Processed prompts:  60%|    | 610/1024 [00:19<00:14, 29.25it/s, est. speed input: 32530.25 toks/s, output: 31.77 toks/s]
Processed prompts:  60%|    | 618/1024 [00:19<00:13, 29.08it/s, est. speed input: 32485.01 toks/s, output: 31.72 toks/s]
Processed prompts:  61%|    | 626/1024 [00:19<00:13, 29.11it/s, est. speed input: 32448.75 toks/s, output: 31.69 toks/s]
Processed prompts:  62%|   | 634/1024 [00:20<00:13, 29.16it/s, est. speed input: 32415.07 toks/s, output: 31.66 toks/s]
Processed prompts:  63%|   | 642/1024 [00:20<00:13, 29.26it/s, est. speed input: 32385.78 toks/s, output: 31.63 toks/s]
Processed prompts:  63%|   | 650/1024 [00:20<00:12, 29.20it/s, est. speed input: 32350.54 toks/s, output: 31.59 toks/s]
Processed prompts:  64%|   | 658/1024 [00:20<00:12, 29.25it/s, est. speed input: 32320.93 toks/s, output: 31.56 toks/s]
Processed prompts:  65%|   | 666/1024 [00:21<00:12, 29.36it/s, est. speed input: 32295.42 toks/s, output: 31.54 toks/s]
Processed prompts:  66%|   | 674/1024 [00:21<00:11, 29.33it/s, est. speed input: 32265.65 toks/s, output: 31.51 toks/s]
Processed prompts:  67%|   | 682/1024 [00:21<00:11, 29.13it/s, est. speed input: 32228.13 toks/s, output: 31.47 toks/s]
Processed prompts:  67%|   | 690/1024 [00:21<00:11, 29.27it/s, est. speed input: 32204.72 toks/s, output: 31.45 toks/s]
Processed prompts:  68%|   | 698/1024 [00:22<00:11, 29.34it/s, est. speed input: 32180.30 toks/s, output: 31.43 toks/s]
Processed prompts:  69%|   | 706/1024 [00:22<00:10, 29.26it/s, est. speed input: 32150.63 toks/s, output: 31.40 toks/s]
Processed prompts:  70%|   | 714/1024 [00:22<00:10, 29.13it/s, est. speed input: 32118.81 toks/s, output: 31.37 toks/s]
Processed prompts:  71%|   | 722/1024 [00:23<00:10, 29.21it/s, est. speed input: 32095.13 toks/s, output: 31.34 toks/s]
Processed prompts:  71%|  | 730/1024 [00:23<00:10, 29.31it/s, est. speed input: 32073.49 toks/s, output: 31.32 toks/s]
Processed prompts:  72%|  | 738/1024 [00:23<00:09, 29.11it/s, est. speed input: 32041.16 toks/s, output: 31.29 toks/s]
Processed prompts:  73%|  | 746/1024 [00:23<00:09, 29.11it/s, est. speed input: 32015.34 toks/s, output: 31.26 toks/s]
Processed prompts:  74%|  | 754/1024 [00:24<00:09, 29.23it/s, est. speed input: 31995.47 toks/s, output: 31.25 toks/s]
Processed prompts:  74%|  | 762/1024 [00:24<00:08, 29.22it/s, est. speed input: 31971.81 toks/s, output: 31.22 toks/s]
Processed prompts:  75%|  | 770/1024 [00:24<00:08, 29.03it/s, est. speed input: 31941.42 toks/s, output: 31.19 toks/s]
Processed prompts:  76%|  | 778/1024 [00:24<00:08, 29.20it/s, est. speed input: 31923.86 toks/s, output: 31.18 toks/s]
Processed prompts:  77%|  | 786/1024 [00:25<00:08, 29.18it/s, est. speed input: 31901.21 toks/s, output: 31.15 toks/s]
Processed prompts:  78%|  | 794/1024 [00:25<00:07, 29.29it/s, est. speed input: 31883.64 toks/s, output: 31.14 toks/s]
Processed prompts:  78%|  | 802/1024 [00:25<00:07, 29.18it/s, est. speed input: 31859.50 toks/s, output: 31.11 toks/s]
Processed prompts:  79%|  | 810/1024 [00:26<00:07, 29.24it/s, est. speed input: 31840.94 toks/s, output: 31.09 toks/s]
Processed prompts:  80%|  | 818/1024 [00:26<00:07, 29.24it/s, est. speed input: 31821.08 toks/s, output: 31.08 toks/s]
Processed prompts:  81%|  | 826/1024 [00:26<00:06, 29.31it/s, est. speed input: 31804.25 toks/s, output: 31.06 toks/s]
Processed prompts:  81%| | 834/1024 [00:26<00:06, 29.19it/s, est. speed input: 31781.62 toks/s, output: 31.04 toks/s]
Processed prompts:  82%| | 842/1024 [00:27<00:06, 29.32it/s, est. speed input: 31767.28 toks/s, output: 31.02 toks/s]
Processed prompts:  83%| | 850/1024 [00:27<00:05, 29.41it/s, est. speed input: 31753.25 toks/s, output: 31.01 toks/s]
Processed prompts:  84%| | 858/1024 [00:27<00:05, 29.34it/s, est. speed input: 31734.81 toks/s, output: 30.99 toks/s]
Processed prompts:  85%| | 866/1024 [00:27<00:05, 29.11it/s, est. speed input: 31710.16 toks/s, output: 30.97 toks/s]
Processed prompts:  85%| | 874/1024 [00:28<00:05, 29.23it/s, est. speed input: 31695.97 toks/s, output: 30.95 toks/s]
Processed prompts:  86%| | 882/1024 [00:28<00:04, 29.33it/s, est. speed input: 31682.25 toks/s, output: 30.94 toks/s]
Processed prompts:  87%| | 890/1024 [00:28<00:04, 29.26it/s, est. speed input: 31664.47 toks/s, output: 30.92 toks/s]
Processed prompts:  88%| | 898/1024 [00:29<00:04, 29.16it/s, est. speed input: 31644.90 toks/s, output: 30.90 toks/s]
Processed prompts:  88%| | 906/1024 [00:29<00:04, 29.20it/s, est. speed input: 31629.58 toks/s, output: 30.89 toks/s]
Processed prompts:  89%| | 914/1024 [00:29<00:03, 29.23it/s, est. speed input: 31614.54 toks/s, output: 30.87 toks/s]
Processed prompts:  90%| | 922/1024 [00:29<00:03, 29.22it/s, est. speed input: 31598.84 toks/s, output: 30.86 toks/s]
Processed prompts:  91%| | 930/1024 [00:30<00:03, 29.06it/s, est. speed input: 31578.38 toks/s, output: 30.84 toks/s]
Processed prompts:  92%|| 938/1024 [00:30<00:02, 30.21it/s, est. speed input: 31598.13 toks/s, output: 30.86 toks/s]
Processed prompts:  92%|| 946/1024 [00:30<00:02, 29.87it/s, est. speed input: 31582.13 toks/s, output: 30.84 toks/s]
Processed prompts:  93%|| 954/1024 [00:30<00:02, 29.69it/s, est. speed input: 31567.81 toks/s, output: 30.83 toks/s]
Processed prompts:  94%|| 962/1024 [00:31<00:02, 29.42it/s, est. speed input: 31549.37 toks/s, output: 30.81 toks/s]
Processed prompts:  95%|| 970/1024 [00:31<00:01, 29.39it/s, est. speed input: 31536.11 toks/s, output: 30.80 toks/s]
Processed prompts:  96%|| 978/1024 [00:31<00:01, 29.40it/s, est. speed input: 31524.21 toks/s, output: 30.79 toks/s]
Processed prompts:  96%|| 986/1024 [00:32<00:01, 30.40it/s, est. speed input: 31541.60 toks/s, output: 30.80 toks/s]
Processed prompts:  97%|| 994/1024 [00:32<00:01, 29.96it/s, est. speed input: 31525.62 toks/s, output: 30.79 toks/s]
Processed prompts:  98%|| 1002/1024 [00:32<00:00, 29.80it/s, est. speed input: 31514.01 toks/s, output: 30.78 toks/s]
Processed prompts:  99%|| 1010/1024 [00:32<00:00, 29.74it/s, est. speed input: 31504.00 toks/s, output: 30.77 toks/s]
Processed prompts:  99%|| 1018/1024 [00:33<00:00, 30.51it/s, est. speed input: 31517.09 toks/s, output: 30.78 toks/s]
Processed prompts: 100%|| 1024/1024 [00:33<00:00, 30.51it/s, est. speed input: 31702.73 toks/s, output: 30.96 toks/s]
Processed prompts: 100%|| 1024/1024 [00:33<00:00, 30.96it/s, est. speed input: 31702.73 toks/s, output: 30.96 toks/s]
[rank0]:[W126 07:09:37.979280632 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 07:09:39
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:09:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:09:49 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1001586) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1001586) WARNING 01-26 07:10:09 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 29.22 requests/s, 29954.42 total tokens/s, 29.22 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 07:09:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:09:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:09:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:09:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:09:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:09:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:09:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:09:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:09:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:09:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:09:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:09:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:09:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:09:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:09:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:09:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:09:52] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:09:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:09:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:09:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:09:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:09:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:09:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:09:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:09:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:09:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:09:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:09:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1001586) [2026-01-26 07:09:53] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1001586) [2026-01-26 07:09:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1001586) [2026-01-26 07:09:53] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1001586) [2026-01-26 07:09:53] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1001586) [2026-01-26 07:09:53] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1001586) [2026-01-26 07:09:53] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1001586) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1001586) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.26s/it]
(EngineCore_DP0 pid=1001586) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.26s/it]
(EngineCore_DP0 pid=1001586) 
(EngineCore_DP0 pid=1001586) [2026-01-26 07:10:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1001586) [2026-01-26 07:10:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=1001586) [2026-01-26 07:10:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1001586) [2026-01-26 07:10:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=1001586) [2026-01-26 07:10:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1001586) [2026-01-26 07:10:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=1001586) [2026-01-26 07:10:03] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1001586) [2026-01-26 07:10:03] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=1001586) 2026-01-26 07:10:08,922 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1001586) 2026-01-26 07:10:09,036 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 59/2048 [00:00<00:03, 589.23it/s]
Adding requests:   6%|         | 119/2048 [00:00<00:03, 592.18it/s]
Adding requests:   9%|         | 179/2048 [00:00<00:03, 539.03it/s]
Adding requests:  11%|        | 234/2048 [00:00<00:03, 538.96it/s]
Adding requests:  14%|        | 289/2048 [00:00<00:03, 531.33it/s]
Adding requests:  17%|        | 343/2048 [00:00<00:03, 526.15it/s]
Adding requests:  19%|        | 398/2048 [00:00<00:03, 531.36it/s]
Adding requests:  22%|       | 452/2048 [00:00<00:03, 528.80it/s]
Adding requests:  25%|       | 505/2048 [00:00<00:02, 524.70it/s]
Adding requests:  27%|       | 558/2048 [00:01<00:02, 526.23it/s]
Adding requests:  30%|       | 611/2048 [00:01<00:02, 526.26it/s]
Adding requests:  33%|      | 666/2048 [00:01<00:02, 532.91it/s]
Adding requests:  35%|      | 722/2048 [00:01<00:02, 536.58it/s]
Adding requests:  38%|      | 776/2048 [00:01<00:02, 505.88it/s]
Adding requests:  40%|      | 827/2048 [00:01<00:02, 506.81it/s]
Adding requests:  43%|     | 878/2048 [00:02<00:05, 198.92it/s]
Adding requests:  45%|     | 931/2048 [00:02<00:04, 244.62it/s]
Adding requests:  48%|     | 982/2048 [00:02<00:03, 288.14it/s]
Adding requests:  50%|     | 1034/2048 [00:02<00:03, 332.24it/s]
Adding requests:  53%|    | 1087/2048 [00:02<00:02, 373.40it/s]
Adding requests:  56%|    | 1139/2048 [00:02<00:02, 407.06it/s]
Adding requests:  58%|    | 1194/2048 [00:02<00:01, 442.18it/s]
Adding requests:  61%|    | 1245/2048 [00:02<00:01, 457.70it/s]
Adding requests:  63%|   | 1296/2048 [00:03<00:01, 467.78it/s]
Adding requests:  66%|   | 1350/2048 [00:03<00:01, 487.02it/s]
Adding requests:  69%|   | 1405/2048 [00:03<00:01, 502.91it/s]
Adding requests:  71%|   | 1458/2048 [00:03<00:01, 509.15it/s]
Adding requests:  74%|  | 1512/2048 [00:03<00:01, 518.06it/s]
Adding requests:  76%|  | 1565/2048 [00:03<00:00, 521.54it/s]
Adding requests:  79%|  | 1619/2048 [00:03<00:00, 526.08it/s]
Adding requests:  82%| | 1673/2048 [00:03<00:00, 526.65it/s]
Adding requests:  84%| | 1728/2048 [00:03<00:00, 531.81it/s]
Adding requests:  87%| | 1782/2048 [00:03<00:00, 528.27it/s]
Adding requests:  90%| | 1837/2048 [00:04<00:00, 534.00it/s]
Adding requests:  92%|| 1891/2048 [00:04<00:00, 528.69it/s]
Adding requests:  95%|| 1944/2048 [00:04<00:00, 526.79it/s]
Adding requests:  98%|| 1999/2048 [00:04<00:00, 531.64it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 459.97it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 114/2048 [00:00<00:02, 933.22it/s, est. speed input: 956192.99 toks/s, output: 933.38 toks/s]
Processed prompts:  10%|         | 208/2048 [00:02<00:29, 61.41it/s, est. speed input: 74291.39 toks/s, output: 72.55 toks/s]   
Processed prompts:  12%|        | 249/2048 [00:04<00:40, 44.82it/s, est. speed input: 56471.73 toks/s, output: 55.15 toks/s]
Processed prompts:  13%|        | 273/2048 [00:05<00:39, 44.61it/s, est. speed input: 55192.80 toks/s, output: 53.90 toks/s]
Processed prompts:  14%|        | 289/2048 [00:05<00:42, 41.47it/s, est. speed input: 52710.26 toks/s, output: 51.47 toks/s]
Processed prompts:  15%|        | 301/2048 [00:06<00:47, 37.12it/s, est. speed input: 50034.01 toks/s, output: 48.86 toks/s]
Processed prompts:  15%|        | 310/2048 [00:06<00:54, 32.05it/s, est. speed input: 47295.56 toks/s, output: 46.19 toks/s]
Processed prompts:  16%|        | 322/2048 [00:07<00:58, 29.45it/s, est. speed input: 45423.79 toks/s, output: 44.36 toks/s]
Processed prompts:  17%|        | 338/2048 [00:07<00:57, 29.56it/s, est. speed input: 44402.13 toks/s, output: 43.36 toks/s]
Processed prompts:  17%|        | 354/2048 [00:08<00:57, 29.48it/s, est. speed input: 43455.92 toks/s, output: 42.44 toks/s]
Processed prompts:  18%|        | 370/2048 [00:08<00:57, 29.36it/s, est. speed input: 42607.38 toks/s, output: 41.61 toks/s]
Processed prompts:  19%|        | 386/2048 [00:09<00:56, 29.30it/s, est. speed input: 41867.51 toks/s, output: 40.89 toks/s]
Processed prompts:  20%|        | 402/2048 [00:09<00:56, 29.21it/s, est. speed input: 41195.59 toks/s, output: 40.23 toks/s]
Processed prompts:  20%|        | 418/2048 [00:10<00:55, 29.24it/s, est. speed input: 40616.18 toks/s, output: 39.66 toks/s]
Processed prompts:  21%|        | 434/2048 [00:11<00:55, 29.16it/s, est. speed input: 40070.71 toks/s, output: 39.13 toks/s]
Processed prompts:  22%|       | 450/2048 [00:11<00:54, 29.56it/s, est. speed input: 39674.19 toks/s, output: 38.74 toks/s]
Processed prompts:  23%|       | 466/2048 [00:12<00:53, 29.34it/s, est. speed input: 39211.11 toks/s, output: 38.29 toks/s]
Processed prompts:  24%|       | 482/2048 [00:12<00:53, 29.36it/s, est. speed input: 38821.45 toks/s, output: 37.91 toks/s]
Processed prompts:  24%|       | 498/2048 [00:13<00:52, 29.26it/s, est. speed input: 38443.38 toks/s, output: 37.54 toks/s]
Processed prompts:  25%|       | 514/2048 [00:13<00:52, 29.25it/s, est. speed input: 38106.30 toks/s, output: 37.21 toks/s]
Processed prompts:  26%|       | 530/2048 [00:14<00:52, 29.16it/s, est. speed input: 37780.58 toks/s, output: 36.90 toks/s]
Processed prompts:  27%|       | 546/2048 [00:14<00:51, 29.21it/s, est. speed input: 37497.51 toks/s, output: 36.62 toks/s]
Processed prompts:  27%|       | 562/2048 [00:15<00:50, 29.16it/s, est. speed input: 37220.15 toks/s, output: 36.35 toks/s]
Processed prompts:  28%|       | 578/2048 [00:16<00:50, 29.17it/s, est. speed input: 36969.56 toks/s, output: 36.10 toks/s]
Processed prompts:  29%|       | 594/2048 [00:16<00:49, 29.09it/s, est. speed input: 36723.93 toks/s, output: 35.86 toks/s]
Processed prompts:  30%|       | 610/2048 [00:17<00:49, 29.20it/s, est. speed input: 36514.96 toks/s, output: 35.66 toks/s]
Processed prompts:  31%|       | 626/2048 [00:17<00:48, 29.16it/s, est. speed input: 36304.62 toks/s, output: 35.45 toks/s]
Processed prompts:  31%|      | 642/2048 [00:18<00:48, 29.18it/s, est. speed input: 36113.13 toks/s, output: 35.27 toks/s]
Processed prompts:  32%|      | 658/2048 [00:18<00:47, 29.15it/s, est. speed input: 35926.99 toks/s, output: 35.08 toks/s]
Processed prompts:  33%|      | 674/2048 [00:19<00:46, 29.23it/s, est. speed input: 35764.15 toks/s, output: 34.93 toks/s]
Processed prompts:  34%|      | 690/2048 [00:19<00:46, 29.17it/s, est. speed input: 35596.63 toks/s, output: 34.76 toks/s]
Processed prompts:  34%|      | 706/2048 [00:20<00:45, 29.18it/s, est. speed input: 35443.50 toks/s, output: 34.61 toks/s]
Processed prompts:  35%|      | 722/2048 [00:20<00:45, 29.12it/s, est. speed input: 35291.73 toks/s, output: 34.46 toks/s]
Processed prompts:  36%|      | 738/2048 [00:21<00:44, 29.18it/s, est. speed input: 35157.85 toks/s, output: 34.33 toks/s]
Processed prompts:  37%|      | 754/2048 [00:22<00:44, 29.15it/s, est. speed input: 35023.24 toks/s, output: 34.20 toks/s]
Processed prompts:  38%|      | 770/2048 [00:22<00:43, 29.07it/s, est. speed input: 34889.79 toks/s, output: 34.07 toks/s]
Processed prompts:  38%|      | 786/2048 [00:23<00:43, 29.10it/s, est. speed input: 34770.86 toks/s, output: 33.96 toks/s]
Processed prompts:  39%|      | 802/2048 [00:23<00:42, 29.07it/s, est. speed input: 34652.99 toks/s, output: 33.84 toks/s]
Processed prompts:  40%|      | 818/2048 [00:24<00:42, 29.12it/s, est. speed input: 34546.40 toks/s, output: 33.74 toks/s]
Processed prompts:  41%|      | 834/2048 [00:24<00:41, 29.05it/s, est. speed input: 34435.76 toks/s, output: 33.63 toks/s]
Processed prompts:  42%|     | 850/2048 [00:25<00:41, 29.12it/s, est. speed input: 34340.06 toks/s, output: 33.54 toks/s]
Processed prompts:  42%|     | 866/2048 [00:25<00:40, 29.07it/s, est. speed input: 34239.93 toks/s, output: 33.44 toks/s]
Processed prompts:  43%|     | 882/2048 [00:26<00:40, 29.15it/s, est. speed input: 34152.91 toks/s, output: 33.35 toks/s]
Processed prompts:  44%|     | 898/2048 [00:26<00:39, 29.07it/s, est. speed input: 34059.00 toks/s, output: 33.26 toks/s]
Processed prompts:  45%|     | 914/2048 [00:27<00:38, 29.14it/s, est. speed input: 33979.07 toks/s, output: 33.18 toks/s]
Processed prompts:  45%|     | 930/2048 [00:28<00:37, 29.59it/s, est. speed input: 33931.95 toks/s, output: 33.14 toks/s]
Processed prompts:  46%|     | 946/2048 [00:28<00:37, 29.51it/s, est. speed input: 33857.44 toks/s, output: 33.06 toks/s]
Processed prompts:  47%|     | 962/2048 [00:29<00:36, 29.36it/s, est. speed input: 33778.69 toks/s, output: 32.99 toks/s]
Processed prompts:  48%|     | 978/2048 [00:29<00:35, 29.88it/s, est. speed input: 33746.96 toks/s, output: 32.96 toks/s]
Processed prompts:  49%|     | 994/2048 [00:30<00:35, 29.63it/s, est. speed input: 33674.27 toks/s, output: 32.89 toks/s]
Processed prompts:  49%|     | 1010/2048 [00:30<00:35, 29.50it/s, est. speed input: 33607.09 toks/s, output: 32.82 toks/s]
Processed prompts:  50%|     | 1026/2048 [00:31<00:34, 29.37it/s, est. speed input: 33539.40 toks/s, output: 32.75 toks/s]
Processed prompts:  51%|     | 1042/2048 [00:31<00:34, 29.32it/s, est. speed input: 33476.87 toks/s, output: 32.69 toks/s]
Processed prompts:  52%|    | 1058/2048 [00:32<00:33, 29.21it/s, est. speed input: 33411.66 toks/s, output: 32.63 toks/s]
Processed prompts:  52%|    | 1074/2048 [00:32<00:33, 29.17it/s, est. speed input: 33350.82 toks/s, output: 32.57 toks/s]
Processed prompts:  53%|    | 1090/2048 [00:33<00:32, 29.13it/s, est. speed input: 33291.40 toks/s, output: 32.51 toks/s]
Processed prompts:  54%|    | 1106/2048 [00:34<00:32, 29.11it/s, est. speed input: 33234.30 toks/s, output: 32.46 toks/s]
Processed prompts:  55%|    | 1122/2048 [00:34<00:31, 29.09it/s, est. speed input: 33178.74 toks/s, output: 32.40 toks/s]
Processed prompts:  56%|    | 1138/2048 [00:35<00:31, 29.15it/s, est. speed input: 33129.63 toks/s, output: 32.35 toks/s]
Processed prompts:  56%|    | 1154/2048 [00:35<00:30, 29.63it/s, est. speed input: 33106.56 toks/s, output: 32.33 toks/s]
Processed prompts:  57%|    | 1170/2048 [00:36<00:29, 29.51it/s, est. speed input: 33058.51 toks/s, output: 32.28 toks/s]
Processed prompts:  58%|    | 1186/2048 [00:36<00:29, 29.32it/s, est. speed input: 33006.26 toks/s, output: 32.23 toks/s]
Processed prompts:  59%|    | 1202/2048 [00:37<00:28, 29.32it/s, est. speed input: 32962.85 toks/s, output: 32.19 toks/s]
Processed prompts:  59%|    | 1218/2048 [00:37<00:28, 29.20it/s, est. speed input: 32914.10 toks/s, output: 32.14 toks/s]
Processed prompts:  60%|    | 1234/2048 [00:38<00:27, 29.22it/s, est. speed input: 32871.78 toks/s, output: 32.10 toks/s]
Processed prompts:  61%|    | 1250/2048 [00:38<00:27, 29.12it/s, est. speed input: 32825.46 toks/s, output: 32.06 toks/s]
Processed prompts:  62%|   | 1266/2048 [00:39<00:26, 29.71it/s, est. speed input: 32813.61 toks/s, output: 32.04 toks/s]
Processed prompts:  63%|   | 1282/2048 [00:40<00:25, 29.48it/s, est. speed input: 32770.28 toks/s, output: 32.00 toks/s]
Processed prompts:  63%|   | 1298/2048 [00:40<00:25, 29.92it/s, est. speed input: 32756.88 toks/s, output: 31.99 toks/s]
Processed prompts:  64%|   | 1314/2048 [00:41<00:24, 29.68it/s, est. speed input: 32718.06 toks/s, output: 31.95 toks/s]
Processed prompts:  65%|   | 1330/2048 [00:41<00:24, 29.56it/s, est. speed input: 32682.30 toks/s, output: 31.92 toks/s]
Processed prompts:  66%|   | 1346/2048 [00:42<00:23, 29.36it/s, est. speed input: 32641.76 toks/s, output: 31.88 toks/s]
Processed prompts:  67%|   | 1362/2048 [00:42<00:23, 29.38it/s, est. speed input: 32610.09 toks/s, output: 31.85 toks/s]
Processed prompts:  67%|   | 1378/2048 [00:43<00:22, 29.25it/s, est. speed input: 32572.32 toks/s, output: 31.81 toks/s]
Processed prompts:  68%|   | 1394/2048 [00:43<00:22, 29.19it/s, est. speed input: 32536.51 toks/s, output: 31.77 toks/s]
Processed prompts:  69%|   | 1410/2048 [00:44<00:21, 29.18it/s, est. speed input: 32503.34 toks/s, output: 31.74 toks/s]
Processed prompts:  70%|   | 1426/2048 [00:44<00:21, 29.08it/s, est. speed input: 32466.77 toks/s, output: 31.71 toks/s]
Processed prompts:  70%|   | 1442/2048 [00:45<00:20, 29.09it/s, est. speed input: 32434.85 toks/s, output: 31.67 toks/s]
Processed prompts:  71%|   | 1458/2048 [00:46<00:20, 29.07it/s, est. speed input: 32402.21 toks/s, output: 31.64 toks/s]
Processed prompts:  72%|  | 1474/2048 [00:46<00:19, 29.13it/s, est. speed input: 32373.63 toks/s, output: 31.61 toks/s]
Processed prompts:  73%|  | 1490/2048 [00:47<00:19, 29.11it/s, est. speed input: 32343.27 toks/s, output: 31.59 toks/s]
Processed prompts:  74%|  | 1506/2048 [00:47<00:18, 29.14it/s, est. speed input: 32315.23 toks/s, output: 31.56 toks/s]
Processed prompts:  74%|  | 1522/2048 [00:48<00:18, 29.12it/s, est. speed input: 32286.42 toks/s, output: 31.53 toks/s]
Processed prompts:  75%|  | 1538/2048 [00:48<00:17, 29.16it/s, est. speed input: 32260.24 toks/s, output: 31.50 toks/s]
Processed prompts:  76%|  | 1554/2048 [00:49<00:16, 29.16it/s, est. speed input: 32233.49 toks/s, output: 31.48 toks/s]
Processed prompts:  77%|  | 1570/2048 [00:49<00:16, 29.14it/s, est. speed input: 32206.55 toks/s, output: 31.45 toks/s]
Processed prompts:  77%|  | 1586/2048 [00:50<00:15, 29.58it/s, est. speed input: 32198.36 toks/s, output: 31.44 toks/s]
Processed prompts:  78%|  | 1602/2048 [00:50<00:15, 29.45it/s, est. speed input: 32173.03 toks/s, output: 31.42 toks/s]
Processed prompts:  79%|  | 1618/2048 [00:51<00:14, 29.26it/s, est. speed input: 32144.51 toks/s, output: 31.39 toks/s]
Processed prompts:  80%|  | 1634/2048 [00:52<00:14, 29.23it/s, est. speed input: 32120.49 toks/s, output: 31.37 toks/s]
Processed prompts:  81%|  | 1650/2048 [00:52<00:13, 29.68it/s, est. speed input: 32114.48 toks/s, output: 31.36 toks/s]
Processed prompts:  81%| | 1666/2048 [00:53<00:12, 29.56it/s, est. speed input: 32092.79 toks/s, output: 31.34 toks/s]
Processed prompts:  82%| | 1682/2048 [00:53<00:12, 29.36it/s, est. speed input: 32066.90 toks/s, output: 31.32 toks/s]
Processed prompts:  83%| | 1698/2048 [00:54<00:11, 29.33it/s, est. speed input: 32045.92 toks/s, output: 31.29 toks/s]
Processed prompts:  84%| | 1714/2048 [00:54<00:11, 29.22it/s, est. speed input: 32021.72 toks/s, output: 31.27 toks/s]
Processed prompts:  84%| | 1730/2048 [00:55<00:10, 29.28it/s, est. speed input: 32003.19 toks/s, output: 31.25 toks/s]
Processed prompts:  85%| | 1746/2048 [00:55<00:10, 29.21it/s, est. speed input: 31981.01 toks/s, output: 31.23 toks/s]
Processed prompts:  86%| | 1762/2048 [00:56<00:09, 29.22it/s, est. speed input: 31961.12 toks/s, output: 31.21 toks/s]
Processed prompts:  87%| | 1778/2048 [00:57<00:09, 29.13it/s, est. speed input: 31938.56 toks/s, output: 31.19 toks/s]
Processed prompts:  88%| | 1794/2048 [00:57<00:08, 29.14it/s, est. speed input: 31918.56 toks/s, output: 31.17 toks/s]
Processed prompts:  88%| | 1810/2048 [00:58<00:08, 29.05it/s, est. speed input: 31895.97 toks/s, output: 31.15 toks/s]
Processed prompts:  89%| | 1826/2048 [00:58<00:07, 29.11it/s, est. speed input: 31877.95 toks/s, output: 31.13 toks/s]
Processed prompts:  90%| | 1842/2048 [00:59<00:07, 29.09it/s, est. speed input: 31857.82 toks/s, output: 31.11 toks/s]
Processed prompts:  91%| | 1858/2048 [00:59<00:06, 29.13it/s, est. speed input: 31840.03 toks/s, output: 31.09 toks/s]
Processed prompts:  92%|| 1874/2048 [01:00<00:05, 29.59it/s, est. speed input: 31836.74 toks/s, output: 31.09 toks/s]
Processed prompts:  92%|| 1890/2048 [01:00<00:05, 29.53it/s, est. speed input: 31821.29 toks/s, output: 31.08 toks/s]
Processed prompts:  93%|| 1906/2048 [01:01<00:04, 29.33it/s, est. speed input: 31800.77 toks/s, output: 31.06 toks/s]
Processed prompts:  94%|| 1922/2048 [01:01<00:04, 29.31it/s, est. speed input: 31784.80 toks/s, output: 31.04 toks/s]
Processed prompts:  95%|| 1938/2048 [01:02<00:03, 29.21it/s, est. speed input: 31765.98 toks/s, output: 31.02 toks/s]
Processed prompts:  95%|| 1954/2048 [01:02<00:03, 29.78it/s, est. speed input: 31767.53 toks/s, output: 31.02 toks/s]
Processed prompts:  96%|| 1970/2048 [01:03<00:02, 29.49it/s, est. speed input: 31747.80 toks/s, output: 31.00 toks/s]
Processed prompts:  97%|| 1986/2048 [01:04<00:02, 29.92it/s, est. speed input: 31747.70 toks/s, output: 31.00 toks/s]
Processed prompts:  98%|| 2002/2048 [01:04<00:01, 30.65it/s, est. speed input: 31759.45 toks/s, output: 31.02 toks/s]
Processed prompts:  99%|| 2018/2048 [01:05<00:00, 30.15it/s, est. speed input: 31742.35 toks/s, output: 31.00 toks/s]
Processed prompts:  99%|| 2034/2048 [01:05<00:00, 30.24it/s, est. speed input: 31737.91 toks/s, output: 30.99 toks/s]
Processed prompts: 100%|| 2048/2048 [01:05<00:00, 30.24it/s, est. speed input: 31956.28 toks/s, output: 31.21 toks/s]
Processed prompts: 100%|| 2048/2048 [01:05<00:00, 31.21it/s, est. speed input: 31956.28 toks/s, output: 31.21 toks/s]
[rank0]:[W126 07:11:20.503302866 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 07:11:22
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:11:37 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:11:37 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1003255) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1003255) WARNING 01-26 07:11:59 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 29.55 requests/s, 30285.27 total tokens/s, 29.55 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 07:11:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:11:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:11:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:11:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:11:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:11:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:11:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:11:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:11:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:11:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:11:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:11:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:11:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:11:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:11:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:11:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:11:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:11:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:11:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:11:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:11:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:11:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:11:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:11:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:11:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:11:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:11:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:11:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1003255) [2026-01-26 07:11:42] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1003255) [2026-01-26 07:11:42] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1003255) [2026-01-26 07:11:42] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1003255) [2026-01-26 07:11:42] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1003255) [2026-01-26 07:11:42] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1003255) [2026-01-26 07:11:42] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1003255) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1003255) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.16s/it]
(EngineCore_DP0 pid=1003255) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.16s/it]
(EngineCore_DP0 pid=1003255) 
(EngineCore_DP0 pid=1003255) [2026-01-26 07:11:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1003255) [2026-01-26 07:11:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=1003255) [2026-01-26 07:11:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1003255) [2026-01-26 07:11:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=1003255) [2026-01-26 07:11:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1003255) [2026-01-26 07:11:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=1003255) [2026-01-26 07:11:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1003255) [2026-01-26 07:11:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=1003255) 2026-01-26 07:11:57,995 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1003255) 2026-01-26 07:11:58,203 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   2%|         | 63/4096 [00:00<00:06, 628.07it/s]
Adding requests:   3%|         | 128/4096 [00:00<00:06, 635.43it/s]
Adding requests:   5%|         | 192/4096 [00:00<00:06, 571.67it/s]
Adding requests:   6%|         | 250/4096 [00:00<00:07, 541.07it/s]
Adding requests:   7%|         | 305/4096 [00:00<00:07, 526.79it/s]
Adding requests:   9%|         | 358/4096 [00:00<00:07, 521.77it/s]
Adding requests:  10%|         | 411/4096 [00:00<00:07, 521.76it/s]
Adding requests:  11%|        | 466/4096 [00:00<00:06, 529.57it/s]
Adding requests:  13%|        | 520/4096 [00:00<00:06, 513.59it/s]
Adding requests:  14%|        | 574/4096 [00:01<00:06, 519.52it/s]
Adding requests:  15%|        | 627/4096 [00:01<00:06, 518.20it/s]
Adding requests:  17%|        | 683/4096 [00:01<00:06, 528.61it/s]
Adding requests:  18%|        | 736/4096 [00:01<00:06, 517.76it/s]
Adding requests:  19%|        | 788/4096 [00:01<00:06, 512.43it/s]
Adding requests:  21%|        | 840/4096 [00:01<00:06, 506.60it/s]
Adding requests:  22%|       | 897/4096 [00:01<00:06, 523.05it/s]
Adding requests:  23%|       | 950/4096 [00:01<00:06, 515.15it/s]
Adding requests:  25%|       | 1004/4096 [00:01<00:05, 521.97it/s]
Adding requests:  26%|       | 1057/4096 [00:02<00:05, 517.28it/s]
Adding requests:  27%|       | 1109/4096 [00:02<00:05, 514.74it/s]
Adding requests:  28%|       | 1162/4096 [00:02<00:05, 517.26it/s]
Adding requests:  30%|       | 1214/4096 [00:02<00:05, 494.38it/s]
Adding requests:  31%|       | 1264/4096 [00:02<00:05, 491.09it/s]
Adding requests:  32%|      | 1316/4096 [00:02<00:05, 497.68it/s]
Adding requests:  33%|      | 1367/4096 [00:02<00:05, 501.04it/s]
Adding requests:  35%|      | 1421/4096 [00:02<00:05, 511.77it/s]
Adding requests:  36%|      | 1473/4096 [00:02<00:05, 513.68it/s]
Adding requests:  37%|      | 1529/4096 [00:02<00:04, 526.30it/s]
Adding requests:  39%|      | 1582/4096 [00:03<00:04, 525.99it/s]
Adding requests:  40%|      | 1638/4096 [00:03<00:04, 535.52it/s]
Adding requests:  41%|     | 1692/4096 [00:03<00:04, 528.63it/s]
Adding requests:  43%|     | 1745/4096 [00:03<00:04, 527.06it/s]
Adding requests:  44%|     | 1798/4096 [00:03<00:04, 515.68it/s]
Adding requests:  45%|     | 1851/4096 [00:03<00:04, 517.28it/s]
Adding requests:  46%|     | 1903/4096 [00:03<00:04, 511.78it/s]
Adding requests:  48%|     | 1955/4096 [00:03<00:04, 514.09it/s]
Adding requests:  49%|     | 2007/4096 [00:03<00:04, 513.88it/s]
Adding requests:  50%|     | 2060/4096 [00:03<00:03, 516.38it/s]
Adding requests:  52%|    | 2112/4096 [00:04<00:03, 506.26it/s]
Adding requests:  53%|    | 2163/4096 [00:04<00:03, 505.36it/s]
Adding requests:  54%|    | 2215/4096 [00:04<00:03, 507.72it/s]
Adding requests:  55%|    | 2270/4096 [00:04<00:03, 518.94it/s]
Adding requests:  57%|    | 2323/4096 [00:04<00:03, 520.17it/s]
Adding requests:  58%|    | 2377/4096 [00:04<00:03, 522.91it/s]
Adding requests:  59%|    | 2430/4096 [00:04<00:03, 490.96it/s]
Adding requests:  61%|    | 2483/4096 [00:04<00:03, 501.26it/s]
Adding requests:  62%|   | 2534/4096 [00:04<00:03, 500.78it/s]
Adding requests:  63%|   | 2588/4096 [00:04<00:02, 509.55it/s]
Adding requests:  64%|   | 2641/4096 [00:05<00:02, 515.43it/s]
Adding requests:  66%|   | 2695/4096 [00:05<00:02, 521.65it/s]
Adding requests:  67%|   | 2748/4096 [00:05<00:02, 519.68it/s]
Adding requests:  68%|   | 2801/4096 [00:05<00:02, 519.39it/s]
Adding requests:  70%|   | 2853/4096 [00:05<00:02, 513.86it/s]
Adding requests:  71%|   | 2906/4096 [00:05<00:02, 515.47it/s]
Adding requests:  72%|  | 2958/4096 [00:05<00:02, 507.33it/s]
Adding requests:  74%|  | 3011/4096 [00:05<00:02, 512.75it/s]
Adding requests:  75%|  | 3063/4096 [00:05<00:02, 509.73it/s]
Adding requests:  76%|  | 3118/4096 [00:06<00:01, 518.17it/s]
Adding requests:  77%|  | 3170/4096 [00:06<00:01, 516.66it/s]
Adding requests:  79%|  | 3226/4096 [00:06<00:01, 529.00it/s]
Adding requests:  80%|  | 3280/4096 [00:06<00:01, 528.24it/s]
Adding requests:  81%| | 3334/4096 [00:06<00:01, 531.02it/s]
Adding requests:  83%| | 3388/4096 [00:06<00:01, 526.98it/s]
Adding requests:  84%| | 3443/4096 [00:06<00:01, 528.76it/s]
Adding requests:  85%| | 3496/4096 [00:06<00:01, 519.21it/s]
Adding requests:  87%| | 3548/4096 [00:06<00:01, 517.84it/s]
Adding requests:  88%| | 3600/4096 [00:06<00:00, 515.61it/s]
Adding requests:  89%| | 3653/4096 [00:07<00:00, 518.36it/s]
Adding requests:  90%| | 3705/4096 [00:07<00:00, 513.47it/s]
Adding requests:  92%|| 3761/4096 [00:07<00:00, 525.51it/s]
Adding requests:  93%|| 3814/4096 [00:07<00:00, 494.05it/s]
Adding requests:  94%|| 3868/4096 [00:07<00:00, 506.38it/s]
Adding requests:  96%|| 3919/4096 [00:07<00:00, 506.70it/s]
Adding requests:  97%|| 3972/4096 [00:07<00:00, 513.29it/s]
Adding requests:  98%|| 4024/4096 [00:07<00:00, 509.18it/s]
Adding requests: 100%|| 4077/4096 [00:07<00:00, 513.45it/s]
Adding requests: 100%|| 4096/4096 [00:07<00:00, 517.26it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 226/4096 [00:01<00:17, 221.35it/s, est. speed input: 226679.27 toks/s, output: 221.36 toks/s]
Processed prompts:   6%|         | 258/4096 [00:02<00:36, 105.31it/s, est. speed input: 125071.82 toks/s, output: 122.14 toks/s]
Processed prompts:   7%|         | 290/4096 [00:03<00:54, 70.10it/s, est. speed input: 92685.18 toks/s, output: 90.51 toks/s]   
Processed prompts:   8%|         | 322/4096 [00:04<01:09, 53.95it/s, est. speed input: 76848.37 toks/s, output: 75.05 toks/s]
Processed prompts:   9%|         | 354/4096 [00:05<01:23, 45.06it/s, est. speed input: 67394.59 toks/s, output: 65.81 toks/s]
Processed prompts:   9%|         | 386/4096 [00:06<01:33, 39.68it/s, est. speed input: 61088.04 toks/s, output: 59.66 toks/s]
Processed prompts:  10%|         | 418/4096 [00:07<01:41, 36.22it/s, est. speed input: 56561.88 toks/s, output: 55.24 toks/s]
Processed prompts:  11%|         | 450/4096 [00:08<01:46, 34.17it/s, est. speed input: 53310.53 toks/s, output: 52.06 toks/s]
Processed prompts:  12%|        | 482/4096 [00:09<01:50, 32.64it/s, est. speed input: 50694.99 toks/s, output: 49.51 toks/s]
Processed prompts:  13%|        | 514/4096 [00:10<01:53, 31.61it/s, est. speed input: 48608.90 toks/s, output: 47.47 toks/s]
Processed prompts:  13%|        | 546/4096 [00:11<01:54, 30.87it/s, est. speed input: 46890.45 toks/s, output: 45.79 toks/s]
Processed prompts:  14%|        | 578/4096 [00:13<01:55, 30.37it/s, est. speed input: 45465.71 toks/s, output: 44.40 toks/s]
Processed prompts:  15%|        | 610/4096 [00:14<01:56, 30.01it/s, est. speed input: 44253.62 toks/s, output: 43.22 toks/s]
Processed prompts:  16%|        | 642/4096 [00:15<01:56, 29.76it/s, est. speed input: 43219.11 toks/s, output: 42.21 toks/s]
Processed prompts:  16%|        | 674/4096 [00:16<01:55, 29.61it/s, est. speed input: 42328.69 toks/s, output: 41.34 toks/s]
Processed prompts:  17%|        | 706/4096 [00:17<01:54, 29.52it/s, est. speed input: 41555.41 toks/s, output: 40.58 toks/s]
Processed prompts:  18%|        | 738/4096 [00:18<01:53, 29.46it/s, est. speed input: 40874.90 toks/s, output: 39.92 toks/s]
Processed prompts:  19%|        | 770/4096 [00:19<01:53, 29.39it/s, est. speed input: 40263.98 toks/s, output: 39.32 toks/s]
Processed prompts:  20%|        | 802/4096 [00:20<01:52, 29.36it/s, est. speed input: 39720.75 toks/s, output: 38.79 toks/s]
Processed prompts:  20%|        | 834/4096 [00:21<01:51, 29.34it/s, est. speed input: 39232.49 toks/s, output: 38.31 toks/s]
Processed prompts:  21%|        | 866/4096 [00:22<01:50, 29.33it/s, est. speed input: 38792.44 toks/s, output: 37.88 toks/s]
Processed prompts:  22%|       | 898/4096 [00:23<01:49, 29.27it/s, est. speed input: 38381.34 toks/s, output: 37.48 toks/s]
Processed prompts:  23%|       | 930/4096 [00:25<01:47, 29.42it/s, est. speed input: 38043.11 toks/s, output: 37.15 toks/s]
Processed prompts:  23%|       | 962/4096 [00:26<01:45, 29.60it/s, est. speed input: 37744.55 toks/s, output: 36.86 toks/s]
Processed prompts:  24%|       | 994/4096 [00:27<01:45, 29.46it/s, est. speed input: 37425.60 toks/s, output: 36.55 toks/s]
Processed prompts:  25%|       | 1026/4096 [00:28<01:44, 29.38it/s, est. speed input: 37134.31 toks/s, output: 36.26 toks/s]
Processed prompts:  26%|       | 1058/4096 [00:29<01:43, 29.34it/s, est. speed input: 36865.76 toks/s, output: 36.00 toks/s]
Processed prompts:  27%|       | 1090/4096 [00:30<01:42, 29.31it/s, est. speed input: 36617.41 toks/s, output: 35.76 toks/s]
Processed prompts:  27%|       | 1122/4096 [00:31<01:41, 29.26it/s, est. speed input: 36381.64 toks/s, output: 35.53 toks/s]
Processed prompts:  28%|       | 1154/4096 [00:32<01:39, 29.42it/s, est. speed input: 36188.99 toks/s, output: 35.34 toks/s]
Processed prompts:  29%|       | 1186/4096 [00:33<01:39, 29.37it/s, est. speed input: 35986.50 toks/s, output: 35.14 toks/s]
Processed prompts:  30%|       | 1218/4096 [00:34<01:38, 29.34it/s, est. speed input: 35798.46 toks/s, output: 34.96 toks/s]
Processed prompts:  31%|       | 1250/4096 [00:35<01:36, 29.47it/s, est. speed input: 35639.99 toks/s, output: 34.80 toks/s]
Processed prompts:  31%|      | 1282/4096 [00:36<01:35, 29.59it/s, est. speed input: 35493.36 toks/s, output: 34.66 toks/s]
Processed prompts:  32%|      | 1314/4096 [00:38<01:34, 29.47it/s, est. speed input: 35331.69 toks/s, output: 34.50 toks/s]
Processed prompts:  33%|      | 1346/4096 [00:39<01:33, 29.36it/s, est. speed input: 35177.26 toks/s, output: 34.35 toks/s]
Processed prompts:  34%|      | 1378/4096 [00:40<01:32, 29.32it/s, est. speed input: 35034.20 toks/s, output: 34.21 toks/s]
Processed prompts:  34%|      | 1410/4096 [00:41<01:31, 29.31it/s, est. speed input: 34900.82 toks/s, output: 34.08 toks/s]
Processed prompts:  35%|      | 1442/4096 [00:42<01:30, 29.27it/s, est. speed input: 34770.86 toks/s, output: 33.96 toks/s]
Processed prompts:  36%|      | 1474/4096 [00:43<01:29, 29.24it/s, est. speed input: 34647.78 toks/s, output: 33.84 toks/s]
Processed prompts:  37%|      | 1506/4096 [00:44<01:28, 29.23it/s, est. speed input: 34531.14 toks/s, output: 33.72 toks/s]
Processed prompts:  38%|      | 1538/4096 [00:45<01:27, 29.22it/s, est. speed input: 34420.51 toks/s, output: 33.61 toks/s]
Processed prompts:  38%|      | 1570/4096 [00:46<01:25, 29.41it/s, est. speed input: 34332.57 toks/s, output: 33.53 toks/s]
Processed prompts:  39%|      | 1602/4096 [00:47<01:24, 29.35it/s, est. speed input: 34231.74 toks/s, output: 33.43 toks/s]
Processed prompts:  40%|      | 1634/4096 [00:48<01:23, 29.51it/s, est. speed input: 34152.12 toks/s, output: 33.35 toks/s]
Processed prompts:  41%|      | 1666/4096 [00:50<01:22, 29.45it/s, est. speed input: 34061.78 toks/s, output: 33.26 toks/s]
Processed prompts:  41%|     | 1698/4096 [00:51<01:21, 29.38it/s, est. speed input: 33973.08 toks/s, output: 33.18 toks/s]
Processed prompts:  42%|     | 1730/4096 [00:52<01:20, 29.30it/s, est. speed input: 33885.71 toks/s, output: 33.09 toks/s]
Processed prompts:  43%|     | 1762/4096 [00:53<01:19, 29.26it/s, est. speed input: 33803.15 toks/s, output: 33.01 toks/s]
Processed prompts:  44%|     | 1794/4096 [00:54<01:18, 29.20it/s, est. speed input: 33721.79 toks/s, output: 32.93 toks/s]
Processed prompts:  45%|     | 1826/4096 [00:55<01:17, 29.19it/s, est. speed input: 33645.13 toks/s, output: 32.86 toks/s]
Processed prompts:  45%|     | 1858/4096 [00:56<01:16, 29.38it/s, est. speed input: 33587.04 toks/s, output: 32.80 toks/s]
Processed prompts:  46%|     | 1890/4096 [00:57<01:15, 29.31it/s, est. speed input: 33515.59 toks/s, output: 32.73 toks/s]
Processed prompts:  47%|     | 1922/4096 [00:58<01:14, 29.28it/s, est. speed input: 33448.64 toks/s, output: 32.66 toks/s]
Processed prompts:  48%|     | 1954/4096 [00:59<01:12, 29.45it/s, est. speed input: 33397.25 toks/s, output: 32.61 toks/s]
Processed prompts:  48%|     | 1986/4096 [01:00<01:10, 30.05it/s, est. speed input: 33378.95 toks/s, output: 32.60 toks/s]
Processed prompts:  49%|     | 2018/4096 [01:02<01:09, 29.80it/s, est. speed input: 33318.21 toks/s, output: 32.54 toks/s]
Processed prompts:  50%|     | 2050/4096 [01:03<01:08, 30.03it/s, est. speed input: 33284.94 toks/s, output: 32.50 toks/s]
Processed prompts:  51%|     | 2082/4096 [01:04<01:07, 29.97it/s, est. speed input: 33238.90 toks/s, output: 32.46 toks/s]
Processed prompts:  52%|    | 2114/4096 [01:05<01:06, 29.72it/s, est. speed input: 33182.23 toks/s, output: 32.40 toks/s]
Processed prompts:  52%|    | 2146/4096 [01:06<01:05, 29.58it/s, est. speed input: 33128.91 toks/s, output: 32.35 toks/s]
Processed prompts:  53%|    | 2178/4096 [01:07<01:04, 29.94it/s, est. speed input: 33104.68 toks/s, output: 32.33 toks/s]
Processed prompts:  54%|    | 2210/4096 [01:08<01:02, 30.20it/s, est. speed input: 33081.41 toks/s, output: 32.31 toks/s]
Processed prompts:  55%|    | 2242/4096 [01:09<01:02, 29.87it/s, est. speed input: 33030.05 toks/s, output: 32.26 toks/s]
Processed prompts:  56%|    | 2274/4096 [01:10<01:01, 29.84it/s, est. speed input: 32991.20 toks/s, output: 32.22 toks/s]
Processed prompts:  56%|    | 2306/4096 [01:11<00:59, 29.86it/s, est. speed input: 32956.00 toks/s, output: 32.18 toks/s]
Processed prompts:  57%|    | 2338/4096 [01:12<00:58, 29.85it/s, est. speed input: 32920.16 toks/s, output: 32.15 toks/s]
Processed prompts:  58%|    | 2370/4096 [01:13<00:56, 30.44it/s, est. speed input: 32916.81 toks/s, output: 32.15 toks/s]
Processed prompts:  59%|    | 2402/4096 [01:14<00:55, 30.25it/s, est. speed input: 32882.81 toks/s, output: 32.11 toks/s]
Processed prompts:  59%|    | 2434/4096 [01:15<00:55, 30.08it/s, est. speed input: 32847.59 toks/s, output: 32.08 toks/s]
Processed prompts:  60%|    | 2466/4096 [01:16<00:54, 30.00it/s, est. speed input: 32815.19 toks/s, output: 32.05 toks/s]
Processed prompts:  61%|    | 2498/4096 [01:18<00:53, 29.93it/s, est. speed input: 32783.14 toks/s, output: 32.01 toks/s]
Processed prompts:  62%|   | 2530/4096 [01:19<00:52, 29.70it/s, est. speed input: 32743.04 toks/s, output: 31.98 toks/s]
Processed prompts:  63%|   | 2562/4096 [01:20<00:51, 29.72it/s, est. speed input: 32712.79 toks/s, output: 31.95 toks/s]
Processed prompts:  63%|   | 2594/4096 [01:21<00:50, 29.75it/s, est. speed input: 32683.67 toks/s, output: 31.92 toks/s]
Processed prompts:  64%|   | 2626/4096 [01:22<00:49, 29.62it/s, est. speed input: 32648.64 toks/s, output: 31.88 toks/s]
Processed prompts:  65%|   | 2658/4096 [01:23<00:48, 29.48it/s, est. speed input: 32612.11 toks/s, output: 31.85 toks/s]
Processed prompts:  66%|   | 2690/4096 [01:24<00:47, 29.91it/s, est. speed input: 32600.76 toks/s, output: 31.84 toks/s]
Processed prompts:  66%|   | 2722/4096 [01:25<00:46, 29.70it/s, est. speed input: 32566.56 toks/s, output: 31.80 toks/s]
Processed prompts:  67%|   | 2754/4096 [01:26<00:45, 29.73it/s, est. speed input: 32541.08 toks/s, output: 31.78 toks/s]
Processed prompts:  68%|   | 2786/4096 [01:27<00:44, 29.56it/s, est. speed input: 32507.94 toks/s, output: 31.75 toks/s]
Processed prompts:  69%|   | 2818/4096 [01:28<00:42, 29.96it/s, est. speed input: 32498.36 toks/s, output: 31.74 toks/s]
Processed prompts:  70%|   | 2850/4096 [01:29<00:41, 29.90it/s, est. speed input: 32474.21 toks/s, output: 31.71 toks/s]
Processed prompts:  70%|   | 2882/4096 [01:30<00:40, 29.70it/s, est. speed input: 32443.78 toks/s, output: 31.68 toks/s]
Processed prompts:  71%|   | 2914/4096 [01:32<00:39, 29.55it/s, est. speed input: 32413.71 toks/s, output: 31.65 toks/s]
Processed prompts:  72%|  | 2946/4096 [01:33<00:38, 29.61it/s, est. speed input: 32391.18 toks/s, output: 31.63 toks/s]
Processed prompts:  73%|  | 2978/4096 [01:34<00:37, 29.51it/s, est. speed input: 32363.29 toks/s, output: 31.60 toks/s]
Processed prompts:  73%|  | 3010/4096 [01:35<00:36, 29.88it/s, est. speed input: 32353.87 toks/s, output: 31.60 toks/s]
Processed prompts:  74%|  | 3042/4096 [01:36<00:35, 29.85it/s, est. speed input: 32333.01 toks/s, output: 31.58 toks/s]
Processed prompts:  75%|  | 3074/4096 [01:37<00:34, 29.66it/s, est. speed input: 32306.20 toks/s, output: 31.55 toks/s]
Processed prompts:  76%|  | 3106/4096 [01:38<00:32, 30.31it/s, est. speed input: 32310.24 toks/s, output: 31.55 toks/s]
Processed prompts:  77%|  | 3138/4096 [01:39<00:31, 30.44it/s, est. speed input: 32301.74 toks/s, output: 31.54 toks/s]
Processed prompts:  77%|  | 3170/4096 [01:40<00:30, 30.06it/s, est. speed input: 32275.57 toks/s, output: 31.52 toks/s]
Processed prompts:  78%|  | 3202/4096 [01:41<00:29, 30.31it/s, est. speed input: 32269.24 toks/s, output: 31.51 toks/s]
Processed prompts:  79%|  | 3234/4096 [01:42<00:28, 30.15it/s, est. speed input: 32250.81 toks/s, output: 31.49 toks/s]
Processed prompts:  80%|  | 3266/4096 [01:43<00:27, 29.87it/s, est. speed input: 32226.52 toks/s, output: 31.47 toks/s]
Processed prompts:  81%|  | 3298/4096 [01:44<00:26, 29.84it/s, est. speed input: 32208.35 toks/s, output: 31.45 toks/s]
Processed prompts:  81%| | 3330/4096 [01:45<00:25, 30.14it/s, est. speed input: 32202.55 toks/s, output: 31.45 toks/s]
Processed prompts:  82%| | 3362/4096 [01:46<00:24, 29.82it/s, est. speed input: 32177.86 toks/s, output: 31.42 toks/s]
Processed prompts:  83%| | 3394/4096 [01:48<00:23, 29.65it/s, est. speed input: 32155.31 toks/s, output: 31.40 toks/s]
Processed prompts:  84%| | 3426/4096 [01:49<00:22, 29.70it/s, est. speed input: 32139.56 toks/s, output: 31.39 toks/s]
Processed prompts:  84%| | 3458/4096 [01:50<00:21, 29.70it/s, est. speed input: 32122.74 toks/s, output: 31.37 toks/s]
Processed prompts:  85%| | 3490/4096 [01:51<00:20, 30.03it/s, est. speed input: 32117.59 toks/s, output: 31.36 toks/s]
Processed prompts:  86%| | 3522/4096 [01:52<00:19, 29.77it/s, est. speed input: 32095.67 toks/s, output: 31.34 toks/s]
Processed prompts:  87%| | 3554/4096 [01:53<00:18, 29.61it/s, est. speed input: 32074.77 toks/s, output: 31.32 toks/s]
Processed prompts:  88%| | 3586/4096 [01:54<00:17, 29.48it/s, est. speed input: 32053.81 toks/s, output: 31.30 toks/s]
Processed prompts:  88%| | 3618/4096 [01:55<00:16, 29.40it/s, est. speed input: 32033.73 toks/s, output: 31.28 toks/s]
Processed prompts:  89%| | 3650/4096 [01:56<00:15, 29.55it/s, est. speed input: 32020.78 toks/s, output: 31.27 toks/s]
Processed prompts:  90%| | 3682/4096 [01:57<00:13, 29.61it/s, est. speed input: 32006.38 toks/s, output: 31.26 toks/s]
Processed prompts:  91%| | 3714/4096 [01:58<00:12, 29.67it/s, est. speed input: 31993.16 toks/s, output: 31.24 toks/s]
Processed prompts:  91%|| 3746/4096 [01:59<00:11, 29.54it/s, est. speed input: 31974.39 toks/s, output: 31.22 toks/s]
Processed prompts:  92%|| 3778/4096 [02:01<00:10, 29.44it/s, est. speed input: 31955.78 toks/s, output: 31.21 toks/s]
Processed prompts:  93%|| 3810/4096 [02:02<00:09, 29.55it/s, est. speed input: 31943.25 toks/s, output: 31.19 toks/s]
Processed prompts:  94%|| 3842/4096 [02:03<00:08, 29.90it/s, est. speed input: 31939.39 toks/s, output: 31.19 toks/s]
Processed prompts:  95%|| 3874/4096 [02:04<00:07, 29.68it/s, est. speed input: 31921.08 toks/s, output: 31.17 toks/s]
Processed prompts:  95%|| 3906/4096 [02:05<00:06, 29.57it/s, est. speed input: 31904.47 toks/s, output: 31.16 toks/s]
Processed prompts:  96%|| 3938/4096 [02:06<00:05, 29.65it/s, est. speed input: 31892.97 toks/s, output: 31.15 toks/s]
Processed prompts:  97%|| 3970/4096 [02:07<00:04, 29.52it/s, est. speed input: 31876.28 toks/s, output: 31.13 toks/s]
Processed prompts:  98%|| 4002/4096 [02:08<00:03, 29.40it/s, est. speed input: 31858.61 toks/s, output: 31.11 toks/s]
Processed prompts:  98%|| 4034/4096 [02:09<00:02, 30.11it/s, est. speed input: 31864.95 toks/s, output: 31.12 toks/s]
Processed prompts:  99%|| 4066/4096 [02:10<00:00, 30.04it/s, est. speed input: 31854.43 toks/s, output: 31.11 toks/s]
Processed prompts: 100%|| 4096/4096 [02:10<00:00, 30.04it/s, est. speed input: 32089.33 toks/s, output: 31.34 toks/s]
Processed prompts: 100%|| 4096/4096 [02:10<00:00, 31.34it/s, est. speed input: 32089.33 toks/s, output: 31.34 toks/s]
[rank0]:[W126 07:14:18.851875299 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 07:14:20
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:14:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:14:47 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1006045) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1006045) WARNING 01-26 07:15:11 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 29.18 requests/s, 29904.68 total tokens/s, 29.18 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 07:14:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:14:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:14:47] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:14:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:14:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:14:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:14:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:14:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:14:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:14:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:14:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:14:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:14:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:14:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:14:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 07:14:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 07:14:50] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 07:14:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:14:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:14:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:14:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:14:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 07:14:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 07:14:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:14:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:14:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:14:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:14:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1006045) [2026-01-26 07:14:51] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1006045) [2026-01-26 07:14:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1006045) [2026-01-26 07:14:51] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1006045) [2026-01-26 07:14:51] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1006045) [2026-01-26 07:14:51] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=1006045) [2026-01-26 07:14:51] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1006045) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1006045) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.18s/it]
(EngineCore_DP0 pid=1006045) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.18s/it]
(EngineCore_DP0 pid=1006045) 
(EngineCore_DP0 pid=1006045) [2026-01-26 07:15:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1006045) [2026-01-26 07:15:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6389760 bytes
(EngineCore_DP0 pid=1006045) [2026-01-26 07:15:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1006045) [2026-01-26 07:15:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4259840 bytes
(EngineCore_DP0 pid=1006045) [2026-01-26 07:15:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1006045) [2026-01-26 07:15:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 34078720 bytes
(EngineCore_DP0 pid=1006045) [2026-01-26 07:15:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1006045) [2026-01-26 07:15:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16842752 bytes
(EngineCore_DP0 pid=1006045) 2026-01-26 07:15:08,462 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1006045) 2026-01-26 07:15:08,703 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 65/8192 [00:00<00:12, 645.06it/s]
Adding requests:   2%|         | 130/8192 [00:00<00:15, 513.98it/s]
Adding requests:   2%|         | 194/8192 [00:00<00:14, 561.49it/s]
Adding requests:   3%|         | 258/8192 [00:00<00:13, 589.01it/s]
Adding requests:   4%|         | 323/8192 [00:00<00:12, 609.26it/s]
Adding requests:   5%|         | 391/8192 [00:00<00:12, 631.69it/s]
Adding requests:   6%|         | 459/8192 [00:00<00:12, 644.37it/s]
Adding requests:   6%|         | 524/8192 [00:00<00:11, 642.82it/s]
Adding requests:   7%|         | 595/8192 [00:00<00:11, 662.85it/s]
Adding requests:   8%|         | 664/8192 [00:01<00:11, 670.31it/s]
Adding requests:   9%|         | 734/8192 [00:01<00:11, 677.78it/s]
Adding requests:  10%|         | 802/8192 [00:01<00:11, 670.26it/s]
Adding requests:  11%|         | 871/8192 [00:01<00:10, 675.37it/s]
Adding requests:  11%|        | 940/8192 [00:01<00:10, 677.75it/s]
Adding requests:  12%|        | 1009/8192 [00:01<00:10, 679.72it/s]
Adding requests:  13%|        | 1078/8192 [00:01<00:11, 645.10it/s]
Adding requests:  14%|        | 1143/8192 [00:01<00:10, 645.35it/s]
Adding requests:  15%|        | 1209/8192 [00:01<00:10, 647.58it/s]
Adding requests:  16%|        | 1276/8192 [00:01<00:10, 651.24it/s]
Adding requests:  16%|        | 1342/8192 [00:02<00:10, 650.96it/s]
Adding requests:  17%|        | 1408/8192 [00:02<00:11, 599.50it/s]
Adding requests:  18%|        | 1469/8192 [00:02<00:11, 578.60it/s]
Adding requests:  19%|        | 1528/8192 [00:02<00:11, 557.92it/s]
Adding requests:  19%|        | 1585/8192 [00:02<00:12, 542.54it/s]
Adding requests:  20%|        | 1648/8192 [00:02<00:11, 564.33it/s]
Adding requests:  21%|        | 1710/8192 [00:02<00:11, 579.42it/s]
Adding requests:  22%|       | 1776/8192 [00:02<00:10, 601.99it/s]
Adding requests:  23%|       | 1849/8192 [00:02<00:09, 638.43it/s]
Adding requests:  23%|       | 1916/8192 [00:03<00:09, 645.65it/s]
Adding requests:  24%|       | 1981/8192 [00:03<00:09, 641.80it/s]
Adding requests:  25%|       | 2051/8192 [00:03<00:09, 657.52it/s]
Adding requests:  26%|       | 2125/8192 [00:03<00:08, 679.37it/s]
Adding requests:  27%|       | 2194/8192 [00:03<00:09, 663.50it/s]
Adding requests:  28%|       | 2262/8192 [00:03<00:08, 667.67it/s]
Adding requests:  28%|       | 2334/8192 [00:03<00:08, 680.73it/s]
Adding requests:  29%|       | 2403/8192 [00:03<00:08, 673.36it/s]
Adding requests:  30%|       | 2471/8192 [00:03<00:08, 664.52it/s]
Adding requests:  31%|       | 2543/8192 [00:03<00:08, 676.92it/s]
Adding requests:  32%|      | 2611/8192 [00:04<00:08, 676.14it/s]
Adding requests:  33%|      | 2679/8192 [00:04<00:08, 662.74it/s]
Adding requests:  34%|      | 2749/8192 [00:04<00:08, 671.86it/s]
Adding requests:  34%|      | 2818/8192 [00:04<00:07, 674.00it/s]
Adding requests:  35%|      | 2886/8192 [00:04<00:08, 658.58it/s]
Adding requests:  36%|      | 2953/8192 [00:04<00:07, 660.28it/s]
Adding requests:  37%|      | 3026/8192 [00:04<00:07, 677.22it/s]
Adding requests:  38%|      | 3094/8192 [00:04<00:07, 658.94it/s]
Adding requests:  39%|      | 3161/8192 [00:04<00:07, 652.60it/s]
Adding requests:  39%|      | 3230/8192 [00:05<00:07, 662.93it/s]
Adding requests:  40%|      | 3297/8192 [00:05<00:07, 657.80it/s]
Adding requests:  41%|      | 3363/8192 [00:05<00:07, 657.34it/s]
Adding requests:  42%|     | 3435/8192 [00:05<00:07, 675.31it/s]
Adding requests:  43%|     | 3503/8192 [00:05<00:07, 665.96it/s]
Adding requests:  44%|     | 3570/8192 [00:05<00:07, 650.49it/s]
Adding requests:  44%|     | 3636/8192 [00:05<00:07, 641.15it/s]
Adding requests:  45%|     | 3709/8192 [00:05<00:06, 666.84it/s]
Adding requests:  46%|     | 3776/8192 [00:05<00:06, 655.77it/s]
Adding requests:  47%|     | 3844/8192 [00:05<00:06, 661.47it/s]
Adding requests:  48%|     | 3917/8192 [00:06<00:06, 679.32it/s]
Adding requests:  49%|     | 3986/8192 [00:06<00:06, 659.09it/s]
Adding requests:  49%|     | 4053/8192 [00:06<00:06, 661.54it/s]
Adding requests:  50%|     | 4126/8192 [00:06<00:05, 680.57it/s]
Adding requests:  51%|     | 4195/8192 [00:06<00:05, 677.13it/s]
Adding requests:  52%|    | 4263/8192 [00:06<00:06, 650.90it/s]
Adding requests:  53%|    | 4336/8192 [00:06<00:05, 672.10it/s]
Adding requests:  54%|    | 4410/8192 [00:06<00:05, 690.39it/s]
Adding requests:  55%|    | 4480/8192 [00:06<00:05, 669.85it/s]
Adding requests:  56%|    | 4548/8192 [00:07<00:05, 666.44it/s]
Adding requests:  56%|    | 4616/8192 [00:07<00:05, 669.59it/s]
Adding requests:  57%|    | 4684/8192 [00:07<00:05, 650.88it/s]
Adding requests:  58%|    | 4752/8192 [00:07<00:05, 656.15it/s]
Adding requests:  59%|    | 4825/8192 [00:07<00:04, 675.01it/s]
Adding requests:  60%|    | 4893/8192 [00:07<00:04, 668.74it/s]
Adding requests:  61%|    | 4960/8192 [00:07<00:04, 650.35it/s]
Adding requests:  61%|   | 5032/8192 [00:07<00:04, 669.81it/s]
Adding requests:  62%|   | 5100/8192 [00:07<00:04, 668.15it/s]
Adding requests:  63%|   | 5167/8192 [00:07<00:04, 660.01it/s]
Adding requests:  64%|   | 5234/8192 [00:08<00:04, 659.42it/s]
Adding requests:  65%|   | 5307/8192 [00:08<00:04, 677.58it/s]
Adding requests:  66%|   | 5375/8192 [00:08<00:04, 664.60it/s]
Adding requests:  66%|   | 5443/8192 [00:08<00:04, 667.39it/s]
Adding requests:  67%|   | 5515/8192 [00:08<00:03, 680.75it/s]
Adding requests:  68%|   | 5584/8192 [00:08<00:03, 676.00it/s]
Adding requests:  69%|   | 5652/8192 [00:08<00:03, 658.62it/s]
Adding requests:  70%|   | 5725/8192 [00:08<00:03, 678.14it/s]
Adding requests:  71%|   | 5796/8192 [00:08<00:03, 686.56it/s]
Adding requests:  72%|  | 5865/8192 [00:08<00:03, 629.52it/s]
Adding requests:  72%|  | 5929/8192 [00:09<00:03, 615.84it/s]
Adding requests:  73%|  | 5992/8192 [00:09<00:03, 567.90it/s]
Adding requests:  74%|  | 6051/8192 [00:09<00:03, 571.38it/s]
Adding requests:  75%|  | 6109/8192 [00:09<00:04, 519.23it/s]
Adding requests:  75%|  | 6163/8192 [00:09<00:03, 518.37it/s]
Adding requests:  76%|  | 6221/8192 [00:09<00:03, 534.27it/s]
Adding requests:  77%|  | 6281/8192 [00:09<00:03, 550.02it/s]
Adding requests:  77%|  | 6337/8192 [00:09<00:03, 550.66it/s]
Adding requests:  78%|  | 6394/8192 [00:09<00:03, 555.19it/s]
Adding requests:  79%|  | 6451/8192 [00:10<00:03, 557.58it/s]
Adding requests:  79%|  | 6512/8192 [00:10<00:02, 570.49it/s]
Adding requests:  80%|  | 6570/8192 [00:10<00:02, 563.06it/s]
Adding requests:  81%|  | 6627/8192 [00:10<00:02, 562.95it/s]
Adding requests:  82%| | 6684/8192 [00:10<00:02, 554.48it/s]
Adding requests:  82%| | 6741/8192 [00:10<00:02, 558.91it/s]
Adding requests:  83%| | 6797/8192 [00:10<00:02, 557.08it/s]
Adding requests:  84%| | 6853/8192 [00:10<00:02, 552.35it/s]
Adding requests:  84%| | 6910/8192 [00:10<00:02, 556.23it/s]
Adding requests:  85%| | 6970/8192 [00:11<00:02, 567.41it/s]
Adding requests:  86%| | 7027/8192 [00:11<00:02, 553.58it/s]
Adding requests:  86%| | 7083/8192 [00:11<00:02, 552.02it/s]
Adding requests:  87%| | 7140/8192 [00:11<00:01, 552.75it/s]
Adding requests:  88%| | 7198/8192 [00:11<00:01, 558.43it/s]
Adding requests:  89%| | 7254/8192 [00:11<00:01, 548.15it/s]
Adding requests:  89%| | 7309/8192 [00:11<00:01, 545.89it/s]
Adding requests:  90%| | 7364/8192 [00:11<00:01, 494.66it/s]
Adding requests:  91%| | 7419/8192 [00:11<00:01, 507.19it/s]
Adding requests:  91%|| 7477/8192 [00:11<00:01, 526.70it/s]
Adding requests:  92%|| 7531/8192 [00:12<00:01, 529.02it/s]
Adding requests:  93%|| 7585/8192 [00:12<00:01, 522.44it/s]
Adding requests:  93%|| 7638/8192 [00:12<00:01, 523.43it/s]
Adding requests:  94%|| 7695/8192 [00:12<00:00, 535.57it/s]
Adding requests:  95%|| 7751/8192 [00:12<00:00, 542.20it/s]
Adding requests:  95%|| 7806/8192 [00:12<00:00, 535.75it/s]
Adding requests:  96%|| 7860/8192 [00:12<00:00, 534.40it/s]
Adding requests:  97%|| 7915/8192 [00:12<00:00, 537.21it/s]
Adding requests:  97%|| 7969/8192 [00:12<00:00, 532.51it/s]
Adding requests:  98%|| 8023/8192 [00:13<00:00, 527.66it/s]
Adding requests:  99%|| 8076/8192 [00:13<00:00, 527.76it/s]
Adding requests:  99%|| 8132/8192 [00:13<00:00, 535.84it/s]
Adding requests: 100%|| 8186/8192 [00:13<00:00, 534.40it/s]
Adding requests: 100%|| 8192/8192 [00:13<00:00, 615.32it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 194/8192 [00:01<00:59, 134.46it/s, est. speed input: 137685.71 toks/s, output: 134.46 toks/s]
Processed prompts:   3%|         | 258/8192 [00:03<02:06, 62.69it/s, est. speed input: 72984.91 toks/s, output: 71.27 toks/s]   
Processed prompts:   4%|         | 322/8192 [00:05<02:49, 46.39it/s, est. speed input: 57011.23 toks/s, output: 55.67 toks/s]
Processed prompts:   5%|         | 386/8192 [00:07<03:18, 39.39it/s, est. speed input: 49690.89 toks/s, output: 48.53 toks/s]
Processed prompts:   5%|         | 450/8192 [00:10<03:36, 35.79it/s, est. speed input: 45569.27 toks/s, output: 44.50 toks/s]
Processed prompts:   6%|         | 514/8192 [00:12<03:48, 33.56it/s, est. speed input: 42823.86 toks/s, output: 41.82 toks/s]
Processed prompts:   7%|         | 578/8192 [00:14<03:56, 32.18it/s, est. speed input: 40910.22 toks/s, output: 39.95 toks/s]
Processed prompts:   8%|         | 642/8192 [00:16<04:01, 31.31it/s, est. speed input: 39512.45 toks/s, output: 38.59 toks/s]
Processed prompts:   9%|         | 706/8192 [00:18<04:03, 30.74it/s, est. speed input: 38436.12 toks/s, output: 37.54 toks/s]
Processed prompts:   9%|         | 770/8192 [00:20<04:04, 30.35it/s, est. speed input: 37584.80 toks/s, output: 36.70 toks/s]
Processed prompts:  10%|         | 834/8192 [00:23<04:04, 30.08it/s, est. speed input: 36888.80 toks/s, output: 36.02 toks/s]
Processed prompts:  11%|         | 898/8192 [00:25<04:03, 29.98it/s, est. speed input: 36343.31 toks/s, output: 35.49 toks/s]
Processed prompts:  12%|        | 962/8192 [00:27<04:01, 29.88it/s, est. speed input: 35872.55 toks/s, output: 35.03 toks/s]
Processed prompts:  13%|        | 1026/8192 [00:29<04:01, 29.71it/s, est. speed input: 35443.15 toks/s, output: 34.61 toks/s]
Processed prompts:  13%|        | 1090/8192 [00:31<03:59, 29.62it/s, est. speed input: 35079.64 toks/s, output: 34.26 toks/s]
Processed prompts:  14%|        | 1154/8192 [00:33<03:57, 29.66it/s, est. speed input: 34787.79 toks/s, output: 33.97 toks/s]
Processed prompts:  15%|        | 1218/8192 [00:36<03:55, 29.65it/s, est. speed input: 34520.25 toks/s, output: 33.71 toks/s]
Processed prompts:  16%|        | 1282/8192 [00:38<03:52, 29.67it/s, est. speed input: 34289.62 toks/s, output: 33.49 toks/s]
Processed prompts:  16%|        | 1346/8192 [00:40<03:51, 29.56it/s, est. speed input: 34058.44 toks/s, output: 33.26 toks/s]
Processed prompts:  17%|        | 1410/8192 [00:42<03:49, 29.50it/s, est. speed input: 33855.18 toks/s, output: 33.06 toks/s]
Processed prompts:  18%|        | 1474/8192 [00:44<03:47, 29.52it/s, est. speed input: 33681.62 toks/s, output: 32.89 toks/s]
Processed prompts:  19%|        | 1538/8192 [00:46<03:45, 29.56it/s, est. speed input: 33530.32 toks/s, output: 32.74 toks/s]
Processed prompts:  20%|        | 1602/8192 [00:49<03:42, 29.61it/s, est. speed input: 33395.06 toks/s, output: 32.61 toks/s]
Processed prompts:  20%|        | 1666/8192 [00:51<03:40, 29.57it/s, est. speed input: 33259.05 toks/s, output: 32.48 toks/s]
Processed prompts:  21%|        | 1730/8192 [00:53<03:38, 29.55it/s, est. speed input: 33135.83 toks/s, output: 32.36 toks/s]
Processed prompts:  22%|       | 1794/8192 [00:55<03:36, 29.51it/s, est. speed input: 33017.84 toks/s, output: 32.24 toks/s]
Processed prompts:  23%|       | 1858/8192 [00:57<03:34, 29.57it/s, est. speed input: 32920.77 toks/s, output: 32.15 toks/s]
Processed prompts:  23%|       | 1922/8192 [00:59<03:32, 29.57it/s, est. speed input: 32826.00 toks/s, output: 32.06 toks/s]
Processed prompts:  24%|       | 1986/8192 [01:02<03:28, 29.83it/s, est. speed input: 32770.02 toks/s, output: 32.00 toks/s]
Processed prompts:  25%|       | 2050/8192 [01:04<03:24, 30.06it/s, est. speed input: 32723.50 toks/s, output: 31.96 toks/s]
Processed prompts:  26%|       | 2114/8192 [01:06<03:23, 29.84it/s, est. speed input: 32635.69 toks/s, output: 31.87 toks/s]
Processed prompts:  27%|       | 2178/8192 [01:08<03:19, 30.20it/s, est. speed input: 32611.44 toks/s, output: 31.85 toks/s]
Processed prompts:  27%|       | 2242/8192 [01:10<03:18, 30.03it/s, est. speed input: 32542.18 toks/s, output: 31.78 toks/s]
Processed prompts:  28%|       | 2306/8192 [01:12<03:16, 29.98it/s, est. speed input: 32484.35 toks/s, output: 31.72 toks/s]
Processed prompts:  29%|       | 2370/8192 [01:14<03:11, 30.33it/s, est. speed input: 32469.16 toks/s, output: 31.71 toks/s]
Processed prompts:  30%|       | 2434/8192 [01:16<03:10, 30.29it/s, est. speed input: 32426.56 toks/s, output: 31.67 toks/s]
Processed prompts:  30%|       | 2498/8192 [01:19<03:09, 30.09it/s, est. speed input: 32369.86 toks/s, output: 31.61 toks/s]
Processed prompts:  31%|      | 2562/8192 [01:21<03:06, 30.12it/s, est. speed input: 32331.59 toks/s, output: 31.57 toks/s]
Processed prompts:  32%|      | 2626/8192 [01:23<03:06, 29.88it/s, est. speed input: 32271.45 toks/s, output: 31.52 toks/s]
Processed prompts:  33%|      | 2690/8192 [01:25<03:03, 29.93it/s, est. speed input: 32234.32 toks/s, output: 31.48 toks/s]
Processed prompts:  34%|      | 2754/8192 [01:27<03:02, 29.86it/s, est. speed input: 32189.27 toks/s, output: 31.43 toks/s]
Processed prompts:  34%|      | 2818/8192 [01:29<02:58, 30.06it/s, est. speed input: 32168.15 toks/s, output: 31.41 toks/s]
Processed prompts:  35%|      | 2882/8192 [01:31<02:57, 29.86it/s, est. speed input: 32119.22 toks/s, output: 31.37 toks/s]
Processed prompts:  36%|      | 2946/8192 [01:34<02:56, 29.79it/s, est. speed input: 32078.49 toks/s, output: 31.33 toks/s]
Processed prompts:  37%|      | 3010/8192 [01:36<02:52, 30.06it/s, est. speed input: 32064.89 toks/s, output: 31.31 toks/s]
Processed prompts:  38%|      | 3074/8192 [01:38<02:49, 30.23it/s, est. speed input: 32050.11 toks/s, output: 31.30 toks/s]
Processed prompts:  38%|      | 3138/8192 [01:40<02:47, 30.18it/s, est. speed input: 32023.05 toks/s, output: 31.27 toks/s]
Processed prompts:  39%|      | 3202/8192 [01:42<02:44, 30.31it/s, est. speed input: 32009.08 toks/s, output: 31.26 toks/s]
Processed prompts:  40%|      | 3266/8192 [01:44<02:43, 30.09it/s, est. speed input: 31974.21 toks/s, output: 31.22 toks/s]
Processed prompts:  41%|      | 3330/8192 [01:46<02:41, 30.09it/s, est. speed input: 31950.60 toks/s, output: 31.20 toks/s]
Processed prompts:  41%|     | 3394/8192 [01:48<02:40, 29.93it/s, est. speed input: 31917.58 toks/s, output: 31.17 toks/s]
Processed prompts:  42%|     | 3458/8192 [01:50<02:37, 30.11it/s, est. speed input: 31905.07 toks/s, output: 31.16 toks/s]
Processed prompts:  43%|     | 3522/8192 [01:53<02:36, 29.91it/s, est. speed input: 31871.53 toks/s, output: 31.12 toks/s]
Processed prompts:  44%|     | 3586/8192 [01:55<02:34, 29.73it/s, est. speed input: 31836.60 toks/s, output: 31.09 toks/s]
Processed prompts:  45%|     | 3650/8192 [01:57<02:32, 29.85it/s, est. speed input: 31818.95 toks/s, output: 31.07 toks/s]
Processed prompts:  45%|     | 3714/8192 [01:59<02:30, 29.79it/s, est. speed input: 31792.38 toks/s, output: 31.05 toks/s]
Processed prompts:  46%|     | 3778/8192 [02:01<02:28, 29.76it/s, est. speed input: 31768.22 toks/s, output: 31.02 toks/s]
Processed prompts:  47%|     | 3842/8192 [02:03<02:25, 29.86it/s, est. speed input: 31751.56 toks/s, output: 31.01 toks/s]
Processed prompts:  48%|     | 3906/8192 [02:06<02:23, 29.79it/s, est. speed input: 31727.45 toks/s, output: 30.98 toks/s]
Processed prompts:  48%|     | 3970/8192 [02:08<02:22, 29.63it/s, est. speed input: 31697.65 toks/s, output: 30.95 toks/s]
Processed prompts:  49%|     | 4034/8192 [02:10<02:18, 29.94it/s, est. speed input: 31692.98 toks/s, output: 30.95 toks/s]
Processed prompts:  50%|     | 4098/8192 [02:12<02:17, 29.74it/s, est. speed input: 31665.11 toks/s, output: 30.92 toks/s]
Processed prompts:  51%|     | 4162/8192 [02:14<02:14, 30.02it/s, est. speed input: 31661.40 toks/s, output: 30.92 toks/s]
Processed prompts:  52%|    | 4226/8192 [02:16<02:12, 30.02it/s, est. speed input: 31647.25 toks/s, output: 30.91 toks/s]
Processed prompts:  52%|    | 4290/8192 [02:18<02:10, 29.91it/s, est. speed input: 31627.41 toks/s, output: 30.89 toks/s]
Processed prompts:  53%|    | 4354/8192 [02:21<02:09, 29.73it/s, est. speed input: 31602.21 toks/s, output: 30.86 toks/s]
Processed prompts:  54%|    | 4418/8192 [02:23<02:06, 29.84it/s, est. speed input: 31590.66 toks/s, output: 30.85 toks/s]
Processed prompts:  55%|    | 4482/8192 [02:25<02:05, 29.67it/s, est. speed input: 31566.80 toks/s, output: 30.83 toks/s]
Processed prompts:  55%|    | 4546/8192 [02:27<02:01, 29.99it/s, est. speed input: 31565.60 toks/s, output: 30.83 toks/s]
Processed prompts:  56%|    | 4610/8192 [02:29<01:59, 29.89it/s, est. speed input: 31548.62 toks/s, output: 30.81 toks/s]
Processed prompts:  57%|    | 4674/8192 [02:31<01:58, 29.71it/s, est. speed input: 31526.22 toks/s, output: 30.79 toks/s]
Processed prompts:  58%|    | 4738/8192 [02:33<01:55, 29.82it/s, est. speed input: 31516.41 toks/s, output: 30.78 toks/s]
Processed prompts:  59%|    | 4802/8192 [02:36<01:53, 29.75it/s, est. speed input: 31499.64 toks/s, output: 30.76 toks/s]
Processed prompts:  59%|    | 4866/8192 [02:38<01:51, 29.73it/s, est. speed input: 31484.40 toks/s, output: 30.75 toks/s]
Processed prompts:  60%|    | 4930/8192 [02:40<01:49, 29.70it/s, est. speed input: 31469.25 toks/s, output: 30.73 toks/s]
Processed prompts:  61%|    | 4994/8192 [02:42<01:47, 29.83it/s, est. speed input: 31461.12 toks/s, output: 30.72 toks/s]
Processed prompts:  62%|   | 5058/8192 [02:44<01:44, 30.09it/s, est. speed input: 31460.87 toks/s, output: 30.72 toks/s]
Processed prompts:  63%|   | 5122/8192 [02:46<01:42, 29.89it/s, est. speed input: 31443.86 toks/s, output: 30.71 toks/s]
Processed prompts:  63%|   | 5186/8192 [02:48<01:39, 30.10it/s, est. speed input: 31442.64 toks/s, output: 30.71 toks/s]
Processed prompts:  64%|   | 5250/8192 [02:50<01:37, 30.27it/s, est. speed input: 31441.97 toks/s, output: 30.71 toks/s]
Processed prompts:  65%|   | 5314/8192 [02:53<01:34, 30.34it/s, est. speed input: 31439.42 toks/s, output: 30.70 toks/s]
Processed prompts:  66%|   | 5378/8192 [02:55<01:33, 30.12it/s, est. speed input: 31425.99 toks/s, output: 30.69 toks/s]
Processed prompts:  66%|   | 5442/8192 [02:57<01:31, 30.09it/s, est. speed input: 31417.45 toks/s, output: 30.68 toks/s]
Processed prompts:  67%|   | 5506/8192 [02:59<01:29, 29.94it/s, est. speed input: 31404.35 toks/s, output: 30.67 toks/s]
Processed prompts:  68%|   | 5570/8192 [03:01<01:28, 29.77it/s, est. speed input: 31388.50 toks/s, output: 30.65 toks/s]
Processed prompts:  69%|   | 5634/8192 [03:03<01:25, 29.87it/s, est. speed input: 31382.11 toks/s, output: 30.65 toks/s]
Processed prompts:  70%|   | 5698/8192 [03:05<01:23, 29.94it/s, est. speed input: 31375.69 toks/s, output: 30.64 toks/s]
Processed prompts:  70%|   | 5762/8192 [03:08<01:21, 29.84it/s, est. speed input: 31363.69 toks/s, output: 30.63 toks/s]
Processed prompts:  71%|   | 5826/8192 [03:10<01:19, 29.79it/s, est. speed input: 31352.36 toks/s, output: 30.62 toks/s]
Processed prompts:  72%|  | 5890/8192 [03:12<01:17, 29.88it/s, est. speed input: 31346.48 toks/s, output: 30.61 toks/s]
Processed prompts:  73%|  | 5954/8192 [03:14<01:15, 29.72it/s, est. speed input: 31332.11 toks/s, output: 30.60 toks/s]
Processed prompts:  73%|  | 6018/8192 [03:16<01:13, 29.68it/s, est. speed input: 31320.86 toks/s, output: 30.59 toks/s]
Processed prompts:  74%|  | 6082/8192 [03:18<01:11, 29.61it/s, est. speed input: 31307.89 toks/s, output: 30.57 toks/s]
Processed prompts:  75%|  | 6146/8192 [03:21<01:08, 29.88it/s, est. speed input: 31307.46 toks/s, output: 30.57 toks/s]
Processed prompts:  76%|  | 6210/8192 [03:23<01:06, 29.83it/s, est. speed input: 31298.06 toks/s, output: 30.56 toks/s]
Processed prompts:  77%|  | 6274/8192 [03:25<01:04, 29.70it/s, est. speed input: 31285.34 toks/s, output: 30.55 toks/s]
Processed prompts:  77%|  | 6338/8192 [03:27<01:02, 29.79it/s, est. speed input: 31279.70 toks/s, output: 30.55 toks/s]
Processed prompts:  78%|  | 6402/8192 [03:29<01:00, 29.74it/s, est. speed input: 31269.83 toks/s, output: 30.54 toks/s]
Processed prompts:  79%|  | 6466/8192 [03:31<00:58, 29.63it/s, est. speed input: 31257.56 toks/s, output: 30.52 toks/s]
Processed prompts:  80%|  | 6530/8192 [03:33<00:55, 29.75it/s, est. speed input: 31252.70 toks/s, output: 30.52 toks/s]
Processed prompts:  80%|  | 6594/8192 [03:36<00:53, 29.70it/s, est. speed input: 31243.08 toks/s, output: 30.51 toks/s]
Processed prompts:  81%| | 6658/8192 [03:38<00:51, 29.80it/s, est. speed input: 31238.30 toks/s, output: 30.51 toks/s]
Processed prompts:  82%| | 6722/8192 [03:40<00:49, 29.68it/s, est. speed input: 31227.04 toks/s, output: 30.50 toks/s]
Processed prompts:  83%| | 6786/8192 [03:42<00:47, 29.69it/s, est. speed input: 31219.30 toks/s, output: 30.49 toks/s]
Processed prompts:  84%| | 6850/8192 [03:44<00:45, 29.69it/s, est. speed input: 31211.57 toks/s, output: 30.48 toks/s]
Processed prompts:  84%| | 6914/8192 [03:46<00:43, 29.67it/s, est. speed input: 31203.14 toks/s, output: 30.47 toks/s]
Processed prompts:  85%| | 6978/8192 [03:49<00:40, 29.77it/s, est. speed input: 31198.85 toks/s, output: 30.47 toks/s]
Processed prompts:  86%| | 7042/8192 [03:51<00:38, 29.71it/s, est. speed input: 31190.31 toks/s, output: 30.46 toks/s]
Processed prompts:  87%| | 7106/8192 [03:53<00:36, 30.13it/s, est. speed input: 31196.48 toks/s, output: 30.47 toks/s]
Processed prompts:  88%| | 7170/8192 [03:55<00:34, 30.00it/s, est. speed input: 31189.41 toks/s, output: 30.46 toks/s]
Processed prompts:  88%| | 7234/8192 [03:57<00:31, 30.02it/s, est. speed input: 31185.80 toks/s, output: 30.45 toks/s]
Processed prompts:  89%| | 7298/8192 [03:59<00:29, 29.91it/s, est. speed input: 31178.40 toks/s, output: 30.45 toks/s]
Processed prompts:  90%| | 7362/8192 [04:01<00:27, 29.94it/s, est. speed input: 31174.43 toks/s, output: 30.44 toks/s]
Processed prompts:  91%| | 7426/8192 [04:03<00:25, 29.83it/s, est. speed input: 31166.49 toks/s, output: 30.44 toks/s]
Processed prompts:  91%|| 7490/8192 [04:06<00:23, 30.09it/s, est. speed input: 31168.97 toks/s, output: 30.44 toks/s]
Processed prompts:  92%|| 7554/8192 [04:08<00:21, 30.23it/s, est. speed input: 31170.09 toks/s, output: 30.44 toks/s]
Processed prompts:  93%|| 7618/8192 [04:10<00:18, 30.48it/s, est. speed input: 31175.45 toks/s, output: 30.44 toks/s]
Processed prompts:  94%|| 7682/8192 [04:12<00:16, 30.21it/s, est. speed input: 31168.00 toks/s, output: 30.44 toks/s]
Processed prompts:  95%|| 7746/8192 [04:14<00:14, 30.02it/s, est. speed input: 31160.69 toks/s, output: 30.43 toks/s]
Processed prompts:  95%|| 7810/8192 [04:16<00:12, 29.85it/s, est. speed input: 31152.15 toks/s, output: 30.42 toks/s]
Processed prompts:  96%|| 7874/8192 [04:18<00:10, 29.70it/s, est. speed input: 31143.13 toks/s, output: 30.41 toks/s]
Processed prompts:  97%|| 7938/8192 [04:21<00:08, 29.71it/s, est. speed input: 31137.23 toks/s, output: 30.41 toks/s]
Processed prompts:  98%|| 8002/8192 [04:23<00:06, 29.70it/s, est. speed input: 31131.28 toks/s, output: 30.40 toks/s]
Processed prompts:  98%|| 8066/8192 [04:25<00:04, 29.80it/s, est. speed input: 31128.24 toks/s, output: 30.40 toks/s]
Processed prompts:  99%|| 8130/8192 [04:27<00:02, 29.88it/s, est. speed input: 31125.53 toks/s, output: 30.40 toks/s]
Processed prompts: 100%|| 8192/8192 [04:27<00:00, 29.88it/s, est. speed input: 31362.84 toks/s, output: 30.63 toks/s]
Processed prompts: 100%|| 8192/8192 [04:27<00:00, 30.63it/s, est. speed input: 31362.84 toks/s, output: 30.63 toks/s]
[rank0]:[W126 07:19:52.637430687 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 10:05:37
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:05:41 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:05:41 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1161530) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1161530) WARNING 01-26 10:06:18 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 23.30 requests/s, 11954.00 total tokens/s, 23.30 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 10:05:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:05:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:05:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:05:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:05:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:05:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:05:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:05:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:05:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:05:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:05:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:05:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:05:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:05:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:05:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:05:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:05:44] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:05:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:05:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:05:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:05:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:05:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:05:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:05:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:05:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:05:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:05:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:05:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1161530) [2026-01-26 10:05:45] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1161530) [2026-01-26 10:05:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1161530) [2026-01-26 10:05:45] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1161530) [2026-01-26 10:05:45] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1161530) [2026-01-26 10:05:45] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1161530) [2026-01-26 10:05:45] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1161530) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1161530) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.45s/it]
(EngineCore_DP0 pid=1161530) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.45s/it]
(EngineCore_DP0 pid=1161530) 
(EngineCore_DP0 pid=1161530) [2026-01-26 10:06:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1161530) [2026-01-26 10:06:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=1161530) [2026-01-26 10:06:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1161530) [2026-01-26 10:06:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9437184 bytes
(EngineCore_DP0 pid=1161530) [2026-01-26 10:06:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1161530) [2026-01-26 10:06:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50331648 bytes
(EngineCore_DP0 pid=1161530) [2026-01-26 10:06:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1161530) [2026-01-26 10:06:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25264128 bytes
(EngineCore_DP0 pid=1161530) 2026-01-26 10:06:18,131 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1161530) 2026-01-26 10:06:18,143 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  70%|   | 89/128 [00:00<00:00, 888.78it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 982.75it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:18,  6.91it/s, est. speed input: 3540.91 toks/s, output: 6.92 toks/s]
Processed prompts:   3%|         | 4/128 [00:00<00:07, 16.35it/s, est. speed input: 7596.17 toks/s, output: 14.84 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:06, 19.74it/s, est. speed input: 9086.16 toks/s, output: 17.75 toks/s]
Processed prompts:   8%|         | 10/128 [00:00<00:05, 21.04it/s, est. speed input: 9756.44 toks/s, output: 19.05 toks/s]
Processed prompts:  10%|         | 13/128 [00:00<00:05, 22.30it/s, est. speed input: 10297.99 toks/s, output: 20.11 toks/s]
Processed prompts:  12%|        | 16/128 [00:00<00:04, 23.01it/s, est. speed input: 10650.37 toks/s, output: 20.80 toks/s]
Processed prompts:  15%|        | 19/128 [00:00<00:04, 23.45it/s, est. speed input: 10904.21 toks/s, output: 21.30 toks/s]
Processed prompts:  17%|        | 22/128 [00:01<00:04, 23.81it/s, est. speed input: 11106.44 toks/s, output: 21.69 toks/s]
Processed prompts:  20%|        | 25/128 [00:01<00:04, 24.02it/s, est. speed input: 11261.00 toks/s, output: 21.99 toks/s]
Processed prompts:  22%|       | 28/128 [00:01<00:04, 24.37it/s, est. speed input: 11416.46 toks/s, output: 22.30 toks/s]
Processed prompts:  24%|       | 31/128 [00:01<00:03, 24.56it/s, est. speed input: 11537.05 toks/s, output: 22.53 toks/s]
Processed prompts:  27%|       | 34/128 [00:01<00:03, 24.51it/s, est. speed input: 11614.77 toks/s, output: 22.68 toks/s]
Processed prompts:  29%|       | 37/128 [00:01<00:03, 24.24it/s, est. speed input: 11653.63 toks/s, output: 22.76 toks/s]
Processed prompts:  31%|      | 40/128 [00:01<00:03, 24.33it/s, est. speed input: 11716.52 toks/s, output: 22.88 toks/s]
Processed prompts:  34%|      | 43/128 [00:01<00:03, 24.30it/s, est. speed input: 11761.99 toks/s, output: 22.97 toks/s]
Processed prompts:  36%|      | 46/128 [00:01<00:03, 24.33it/s, est. speed input: 11807.82 toks/s, output: 23.06 toks/s]
Processed prompts:  38%|      | 49/128 [00:02<00:03, 24.26it/s, est. speed input: 11838.77 toks/s, output: 23.12 toks/s]
Processed prompts:  41%|      | 52/128 [00:02<00:03, 24.27it/s, est. speed input: 11871.55 toks/s, output: 23.19 toks/s]
Processed prompts:  43%|     | 55/128 [00:02<00:03, 24.27it/s, est. speed input: 11900.30 toks/s, output: 23.24 toks/s]
Processed prompts:  45%|     | 58/128 [00:02<00:02, 24.44it/s, est. speed input: 11940.23 toks/s, output: 23.32 toks/s]
Processed prompts:  48%|     | 61/128 [00:02<00:02, 24.19it/s, est. speed input: 11948.05 toks/s, output: 23.34 toks/s]
Processed prompts:  50%|     | 64/128 [00:02<00:02, 24.44it/s, est. speed input: 11985.95 toks/s, output: 23.41 toks/s]
Processed prompts:  52%|    | 67/128 [00:02<00:02, 24.60it/s, est. speed input: 12020.16 toks/s, output: 23.48 toks/s]
Processed prompts:  55%|    | 70/128 [00:02<00:02, 24.81it/s, est. speed input: 12057.71 toks/s, output: 23.55 toks/s]
Processed prompts:  57%|    | 73/128 [00:03<00:02, 24.59it/s, est. speed input: 12068.82 toks/s, output: 23.57 toks/s]
Processed prompts:  59%|    | 76/128 [00:03<00:02, 24.46it/s, est. speed input: 12080.64 toks/s, output: 23.59 toks/s]
Processed prompts:  62%|   | 79/128 [00:03<00:02, 24.40it/s, est. speed input: 12092.81 toks/s, output: 23.62 toks/s]
Processed prompts:  64%|   | 82/128 [00:03<00:01, 24.34it/s, est. speed input: 12103.38 toks/s, output: 23.64 toks/s]
Processed prompts:  66%|   | 85/128 [00:03<00:01, 24.30it/s, est. speed input: 12113.56 toks/s, output: 23.66 toks/s]
Processed prompts:  69%|   | 88/128 [00:03<00:01, 24.01it/s, est. speed input: 12108.12 toks/s, output: 23.65 toks/s]
Processed prompts:  71%|   | 91/128 [00:03<00:01, 24.06it/s, est. speed input: 12117.00 toks/s, output: 23.67 toks/s]
Processed prompts:  73%|  | 94/128 [00:03<00:01, 24.15it/s, est. speed input: 12128.01 toks/s, output: 23.69 toks/s]
Processed prompts:  76%|  | 97/128 [00:04<00:01, 24.17it/s, est. speed input: 12136.44 toks/s, output: 23.70 toks/s]
Processed prompts:  78%|  | 100/128 [00:04<00:01, 24.09it/s, est. speed input: 12139.51 toks/s, output: 23.71 toks/s]
Processed prompts:  80%|  | 103/128 [00:04<00:01, 24.18it/s, est. speed input: 12149.36 toks/s, output: 23.73 toks/s]
Processed prompts:  83%| | 106/128 [00:04<00:00, 24.14it/s, est. speed input: 12153.96 toks/s, output: 23.74 toks/s]
Processed prompts:  85%| | 109/128 [00:04<00:00, 24.37it/s, est. speed input: 12169.84 toks/s, output: 23.77 toks/s]
Processed prompts:  88%| | 112/128 [00:04<00:00, 24.18it/s, est. speed input: 12169.46 toks/s, output: 23.77 toks/s]
Processed prompts:  90%| | 115/128 [00:04<00:00, 24.50it/s, est. speed input: 12188.38 toks/s, output: 23.81 toks/s]
Processed prompts:  92%|| 118/128 [00:04<00:00, 24.68it/s, est. speed input: 12204.40 toks/s, output: 23.84 toks/s]
Processed prompts:  95%|| 121/128 [00:05<00:00, 24.73it/s, est. speed input: 12216.96 toks/s, output: 23.86 toks/s]
Processed prompts:  97%|| 124/128 [00:05<00:00, 24.45it/s, est. speed input: 12216.38 toks/s, output: 23.86 toks/s]
Processed prompts:  99%|| 127/128 [00:05<00:00, 24.45it/s, est. speed input: 12223.19 toks/s, output: 23.87 toks/s]
Processed prompts: 100%|| 128/128 [00:05<00:00, 24.45it/s, est. speed input: 12222.92 toks/s, output: 23.87 toks/s]
Processed prompts: 100%|| 128/128 [00:05<00:00, 23.87it/s, est. speed input: 12222.92 toks/s, output: 23.87 toks/s]
[rank0]:[W126 10:06:24.704837364 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 10:06:26
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:06:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:06:30 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1162417) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1162417) WARNING 01-26 10:07:06 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 13.11 requests/s, 13440.96 total tokens/s, 13.11 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 10:06:30] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:06:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:06:30] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:06:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:06:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:06:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:06:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:06:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:06:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:06:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:06:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:06:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:06:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:06:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:06:33] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:06:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:06:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:06:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:06:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:06:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:06:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:06:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:06:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:06:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:06:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:06:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:06:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:06:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1162417) [2026-01-26 10:06:34] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1162417) [2026-01-26 10:06:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1162417) [2026-01-26 10:06:34] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1162417) [2026-01-26 10:06:34] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1162417) [2026-01-26 10:06:34] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1162417) [2026-01-26 10:06:34] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1162417) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1162417) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.10s/it]
(EngineCore_DP0 pid=1162417) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.10s/it]
(EngineCore_DP0 pid=1162417) 
(EngineCore_DP0 pid=1162417) [2026-01-26 10:06:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1162417) [2026-01-26 10:06:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=1162417) [2026-01-26 10:06:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1162417) [2026-01-26 10:06:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9437184 bytes
(EngineCore_DP0 pid=1162417) [2026-01-26 10:06:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1162417) [2026-01-26 10:06:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50331648 bytes
(EngineCore_DP0 pid=1162417) [2026-01-26 10:06:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1162417) [2026-01-26 10:06:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25264128 bytes
(EngineCore_DP0 pid=1162417) 2026-01-26 10:07:06,013 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1162417) 2026-01-26 10:07:06,026 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  47%|     | 60/128 [00:00<00:00, 599.17it/s]
Adding requests:  94%|| 120/128 [00:00<00:00, 561.37it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 560.56it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 4/128 [00:00<00:04, 26.25it/s, est. speed input: 26880.04 toks/s, output: 26.25 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:07, 17.28it/s, est. speed input: 18795.31 toks/s, output: 18.35 toks/s]
Processed prompts:   7%|         | 9/128 [00:00<00:07, 15.74it/s, est. speed input: 17344.66 toks/s, output: 16.94 toks/s]
Processed prompts:   9%|         | 11/128 [00:00<00:07, 14.83it/s, est. speed input: 16497.49 toks/s, output: 16.11 toks/s]
Processed prompts:  10%|         | 13/128 [00:00<00:08, 14.25it/s, est. speed input: 15938.93 toks/s, output: 15.56 toks/s]
Processed prompts:  12%|        | 15/128 [00:00<00:08, 14.00it/s, est. speed input: 15615.76 toks/s, output: 15.25 toks/s]
Processed prompts:  13%|        | 17/128 [00:01<00:08, 13.78it/s, est. speed input: 15351.31 toks/s, output: 14.99 toks/s]
Processed prompts:  15%|        | 19/128 [00:01<00:08, 13.44it/s, est. speed input: 15069.47 toks/s, output: 14.72 toks/s]
Processed prompts:  16%|        | 21/128 [00:01<00:07, 13.44it/s, est. speed input: 14933.29 toks/s, output: 14.58 toks/s]
Processed prompts:  18%|        | 23/128 [00:01<00:07, 13.40it/s, est. speed input: 14810.21 toks/s, output: 14.46 toks/s]
Processed prompts:  20%|        | 25/128 [00:01<00:07, 13.34it/s, est. speed input: 14699.39 toks/s, output: 14.35 toks/s]
Processed prompts:  21%|        | 27/128 [00:01<00:07, 13.30it/s, est. speed input: 14603.16 toks/s, output: 14.26 toks/s]
Processed prompts:  23%|       | 29/128 [00:02<00:07, 13.38it/s, est. speed input: 14552.30 toks/s, output: 14.21 toks/s]
Processed prompts:  24%|       | 31/128 [00:02<00:07, 13.40it/s, est. speed input: 14500.45 toks/s, output: 14.16 toks/s]
Processed prompts:  26%|       | 33/128 [00:02<00:07, 13.12it/s, est. speed input: 14385.71 toks/s, output: 14.05 toks/s]
Processed prompts:  27%|       | 35/128 [00:02<00:07, 13.15it/s, est. speed input: 14334.19 toks/s, output: 14.00 toks/s]
Processed prompts:  29%|       | 37/128 [00:02<00:06, 13.22it/s, est. speed input: 14298.52 toks/s, output: 13.96 toks/s]
Processed prompts:  30%|       | 39/128 [00:02<00:06, 13.21it/s, est. speed input: 14255.28 toks/s, output: 13.92 toks/s]
Processed prompts:  32%|      | 41/128 [00:02<00:06, 13.27it/s, est. speed input: 14229.91 toks/s, output: 13.90 toks/s]
Processed prompts:  34%|      | 43/128 [00:03<00:06, 13.30it/s, est. speed input: 14203.33 toks/s, output: 13.87 toks/s]
Processed prompts:  35%|      | 45/128 [00:03<00:06, 13.40it/s, est. speed input: 14192.50 toks/s, output: 13.86 toks/s]
Processed prompts:  37%|      | 47/128 [00:03<00:06, 13.16it/s, est. speed input: 14134.16 toks/s, output: 13.80 toks/s]
Processed prompts:  38%|      | 49/128 [00:03<00:05, 13.24it/s, est. speed input: 14118.41 toks/s, output: 13.79 toks/s]
Processed prompts:  40%|      | 51/128 [00:03<00:05, 13.30it/s, est. speed input: 14103.88 toks/s, output: 13.77 toks/s]
Processed prompts:  41%|     | 53/128 [00:03<00:05, 13.34it/s, est. speed input: 14090.15 toks/s, output: 13.76 toks/s]
Processed prompts:  43%|     | 55/128 [00:04<00:05, 13.32it/s, est. speed input: 14071.23 toks/s, output: 13.74 toks/s]
Processed prompts:  45%|     | 57/128 [00:04<00:05, 13.32it/s, est. speed input: 14055.74 toks/s, output: 13.73 toks/s]
Processed prompts:  46%|     | 59/128 [00:04<00:05, 13.24it/s, est. speed input: 14031.13 toks/s, output: 13.70 toks/s]
Processed prompts:  48%|     | 61/128 [00:04<00:05, 13.08it/s, est. speed input: 13996.01 toks/s, output: 13.67 toks/s]
Processed prompts:  49%|     | 63/128 [00:04<00:04, 13.12it/s, est. speed input: 13980.47 toks/s, output: 13.65 toks/s]
Processed prompts:  51%|     | 65/128 [00:04<00:04, 13.24it/s, est. speed input: 13977.19 toks/s, output: 13.65 toks/s]
Processed prompts:  52%|    | 67/128 [00:04<00:04, 13.29it/s, est. speed input: 13969.58 toks/s, output: 13.64 toks/s]
Processed prompts:  54%|    | 69/128 [00:05<00:04, 13.33it/s, est. speed input: 13962.91 toks/s, output: 13.64 toks/s]
Processed prompts:  55%|    | 71/128 [00:05<00:04, 13.35it/s, est. speed input: 13955.46 toks/s, output: 13.63 toks/s]
Processed prompts:  57%|    | 73/128 [00:05<00:04, 13.34it/s, est. speed input: 13946.37 toks/s, output: 13.62 toks/s]
Processed prompts:  59%|    | 75/128 [00:05<00:04, 13.17it/s, est. speed input: 13922.08 toks/s, output: 13.60 toks/s]
Processed prompts:  60%|    | 77/128 [00:05<00:03, 13.16it/s, est. speed input: 13910.03 toks/s, output: 13.58 toks/s]
Processed prompts:  62%|   | 79/128 [00:05<00:03, 13.21it/s, est. speed input: 13902.76 toks/s, output: 13.58 toks/s]
Processed prompts:  63%|   | 81/128 [00:05<00:03, 13.29it/s, est. speed input: 13900.68 toks/s, output: 13.57 toks/s]
Processed prompts:  65%|   | 83/128 [00:06<00:03, 13.35it/s, est. speed input: 13898.71 toks/s, output: 13.57 toks/s]
Processed prompts:  66%|   | 85/128 [00:06<00:03, 13.33it/s, est. speed input: 13891.19 toks/s, output: 13.57 toks/s]
Processed prompts:  68%|   | 87/128 [00:06<00:03, 13.32it/s, est. speed input: 13884.55 toks/s, output: 13.56 toks/s]
Processed prompts:  70%|   | 89/128 [00:06<00:02, 13.11it/s, est. speed input: 13862.59 toks/s, output: 13.54 toks/s]
Processed prompts:  71%|   | 91/128 [00:06<00:02, 13.15it/s, est. speed input: 13855.51 toks/s, output: 13.53 toks/s]
Processed prompts:  73%|  | 93/128 [00:06<00:02, 13.15it/s, est. speed input: 13846.59 toks/s, output: 13.52 toks/s]
Processed prompts:  74%|  | 95/128 [00:07<00:02, 13.22it/s, est. speed input: 13843.79 toks/s, output: 13.52 toks/s]
Processed prompts:  76%|  | 97/128 [00:07<00:02, 13.21it/s, est. speed input: 13836.73 toks/s, output: 13.51 toks/s]
Processed prompts:  77%|  | 99/128 [00:07<00:02, 13.14it/s, est. speed input: 13825.50 toks/s, output: 13.50 toks/s]
Processed prompts:  79%|  | 101/128 [00:07<00:02, 13.13it/s, est. speed input: 13817.27 toks/s, output: 13.49 toks/s]
Processed prompts:  80%|  | 103/128 [00:07<00:01, 13.12it/s, est. speed input: 13809.29 toks/s, output: 13.49 toks/s]
Processed prompts:  82%| | 105/128 [00:07<00:01, 13.16it/s, est. speed input: 13804.65 toks/s, output: 13.48 toks/s]
Processed prompts:  84%| | 107/128 [00:07<00:01, 13.19it/s, est. speed input: 13800.17 toks/s, output: 13.48 toks/s]
Processed prompts:  85%| | 109/128 [00:08<00:01, 13.23it/s, est. speed input: 13797.65 toks/s, output: 13.47 toks/s]
Processed prompts:  87%| | 111/128 [00:08<00:01, 13.28it/s, est. speed input: 13795.96 toks/s, output: 13.47 toks/s]
Processed prompts:  88%| | 113/128 [00:08<00:01, 13.19it/s, est. speed input: 13786.67 toks/s, output: 13.46 toks/s]
Processed prompts:  90%| | 115/128 [00:08<00:00, 13.09it/s, est. speed input: 13775.33 toks/s, output: 13.45 toks/s]
Processed prompts:  91%|| 117/128 [00:08<00:00, 13.08it/s, est. speed input: 13768.43 toks/s, output: 13.45 toks/s]
Processed prompts:  93%|| 119/128 [00:08<00:00, 13.14it/s, est. speed input: 13765.61 toks/s, output: 13.44 toks/s]
Processed prompts:  95%|| 121/128 [00:09<00:00, 13.23it/s, est. speed input: 13765.58 toks/s, output: 13.44 toks/s]
Processed prompts:  96%|| 123/128 [00:09<00:00, 13.25it/s, est. speed input: 13763.35 toks/s, output: 13.44 toks/s]
Processed prompts:  98%|| 125/128 [00:09<00:00, 13.20it/s, est. speed input: 13757.28 toks/s, output: 13.43 toks/s]
Processed prompts:  99%|| 127/128 [00:09<00:00, 13.18it/s, est. speed input: 13752.28 toks/s, output: 13.43 toks/s]
Processed prompts: 100%|| 128/128 [00:09<00:00, 13.18it/s, est. speed input: 13751.23 toks/s, output: 13.43 toks/s]
Processed prompts: 100%|| 128/128 [00:09<00:00, 13.43it/s, est. speed input: 13751.23 toks/s, output: 13.43 toks/s]
[rank0]:[W126 10:07:16.721336744 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 10:07:18
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:07:22 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:07:23 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1163349) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1163349) WARNING 01-26 10:07:59 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 13.66 requests/s, 14004.50 total tokens/s, 13.66 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 10:07:22] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:07:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:07:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:07:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:07:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:07:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:07:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:07:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:07:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:07:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:07:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:07:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:07:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:07:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:07:26] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:07:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:07:26] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:07:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:07:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:07:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:07:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:07:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:07:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:07:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:07:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:07:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:07:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:07:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1163349) [2026-01-26 10:07:27] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1163349) [2026-01-26 10:07:27] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1163349) [2026-01-26 10:07:27] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1163349) [2026-01-26 10:07:27] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1163349) [2026-01-26 10:07:27] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1163349) [2026-01-26 10:07:27] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1163349) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1163349) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.46s/it]
(EngineCore_DP0 pid=1163349) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.46s/it]
(EngineCore_DP0 pid=1163349) 
(EngineCore_DP0 pid=1163349) [2026-01-26 10:07:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1163349) [2026-01-26 10:07:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=1163349) [2026-01-26 10:07:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1163349) [2026-01-26 10:07:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9437184 bytes
(EngineCore_DP0 pid=1163349) [2026-01-26 10:07:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1163349) [2026-01-26 10:07:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50331648 bytes
(EngineCore_DP0 pid=1163349) [2026-01-26 10:07:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1163349) [2026-01-26 10:07:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25264128 bytes
(EngineCore_DP0 pid=1163349) 2026-01-26 10:07:58,759 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1163349) 2026-01-26 10:07:58,771 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  24%|       | 61/256 [00:00<00:00, 605.54it/s]
Adding requests:  48%|     | 122/256 [00:00<00:00, 578.77it/s]
Adding requests:  70%|   | 180/256 [00:00<00:00, 568.17it/s]
Adding requests:  93%|| 238/256 [00:00<00:00, 569.71it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 573.23it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 6/256 [00:00<00:06, 36.69it/s, est. speed input: 37577.58 toks/s, output: 36.69 toks/s]
Processed prompts:   4%|         | 10/256 [00:00<00:12, 20.33it/s, est. speed input: 22640.72 toks/s, output: 22.11 toks/s]
Processed prompts:   5%|         | 13/256 [00:00<00:11, 20.50it/s, est. speed input: 22322.04 toks/s, output: 21.80 toks/s]
Processed prompts:   6%|         | 16/256 [00:00<00:15, 15.32it/s, est. speed input: 18343.67 toks/s, output: 17.91 toks/s]
Processed prompts:   7%|         | 18/256 [00:01<00:15, 14.97it/s, est. speed input: 17786.71 toks/s, output: 17.37 toks/s]
Processed prompts:   8%|         | 20/256 [00:01<00:16, 14.68it/s, est. speed input: 17350.95 toks/s, output: 16.94 toks/s]
Processed prompts:   9%|         | 22/256 [00:01<00:16, 14.42it/s, est. speed input: 16992.39 toks/s, output: 16.59 toks/s]
Processed prompts:   9%|         | 24/256 [00:01<00:16, 14.19it/s, est. speed input: 16687.99 toks/s, output: 16.30 toks/s]
Processed prompts:  10%|         | 26/256 [00:01<00:16, 14.12it/s, est. speed input: 16474.57 toks/s, output: 16.09 toks/s]
Processed prompts:  11%|         | 28/256 [00:01<00:16, 13.99it/s, est. speed input: 16271.00 toks/s, output: 15.89 toks/s]
Processed prompts:  12%|        | 30/256 [00:01<00:16, 13.79it/s, est. speed input: 16065.39 toks/s, output: 15.69 toks/s]
Processed prompts:  12%|        | 32/256 [00:02<00:16, 13.88it/s, est. speed input: 15951.17 toks/s, output: 15.58 toks/s]
Processed prompts:  13%|        | 34/256 [00:02<00:16, 13.82it/s, est. speed input: 15823.42 toks/s, output: 15.45 toks/s]
Processed prompts:  14%|        | 36/256 [00:02<00:15, 13.85it/s, est. speed input: 15727.20 toks/s, output: 15.36 toks/s]
Processed prompts:  15%|        | 38/256 [00:02<00:15, 13.87it/s, est. speed input: 15641.39 toks/s, output: 15.27 toks/s]
Processed prompts:  16%|        | 40/256 [00:02<00:15, 13.84it/s, est. speed input: 15556.05 toks/s, output: 15.19 toks/s]
Processed prompts:  16%|        | 42/256 [00:02<00:15, 13.82it/s, est. speed input: 15480.66 toks/s, output: 15.12 toks/s]
Processed prompts:  17%|        | 44/256 [00:02<00:15, 13.65it/s, est. speed input: 15382.21 toks/s, output: 15.02 toks/s]
Processed prompts:  18%|        | 46/256 [00:03<00:15, 13.73it/s, est. speed input: 15330.28 toks/s, output: 14.97 toks/s]
Processed prompts:  19%|        | 48/256 [00:03<00:15, 13.77it/s, est. speed input: 15279.58 toks/s, output: 14.92 toks/s]
Processed prompts:  20%|        | 50/256 [00:03<00:14, 13.77it/s, est. speed input: 15229.00 toks/s, output: 14.87 toks/s]
Processed prompts:  20%|        | 52/256 [00:03<00:14, 13.80it/s, est. speed input: 15186.15 toks/s, output: 14.83 toks/s]
Processed prompts:  21%|        | 54/256 [00:03<00:14, 13.76it/s, est. speed input: 15138.88 toks/s, output: 14.78 toks/s]
Processed prompts:  22%|       | 56/256 [00:03<00:14, 13.73it/s, est. speed input: 15094.45 toks/s, output: 14.74 toks/s]
Processed prompts:  23%|       | 58/256 [00:03<00:14, 13.62it/s, est. speed input: 15041.10 toks/s, output: 14.69 toks/s]
Processed prompts:  23%|       | 60/256 [00:04<00:14, 13.70it/s, est. speed input: 15012.87 toks/s, output: 14.66 toks/s]
Processed prompts:  24%|       | 62/256 [00:04<00:14, 13.71it/s, est. speed input: 14980.01 toks/s, output: 14.63 toks/s]
Processed prompts:  25%|       | 64/256 [00:04<00:13, 13.82it/s, est. speed input: 14961.53 toks/s, output: 14.61 toks/s]
Processed prompts:  26%|       | 66/256 [00:04<00:13, 13.86it/s, est. speed input: 14939.99 toks/s, output: 14.59 toks/s]
Processed prompts:  27%|       | 68/256 [00:04<00:13, 13.83it/s, est. speed input: 14913.73 toks/s, output: 14.56 toks/s]
Processed prompts:  27%|       | 70/256 [00:04<00:13, 13.75it/s, est. speed input: 14882.83 toks/s, output: 14.53 toks/s]
Processed prompts:  28%|       | 72/256 [00:04<00:13, 13.73it/s, est. speed input: 14857.24 toks/s, output: 14.51 toks/s]
Processed prompts:  29%|       | 74/256 [00:05<00:13, 13.67it/s, est. speed input: 14828.25 toks/s, output: 14.48 toks/s]
Processed prompts:  30%|       | 76/256 [00:05<00:13, 13.73it/s, est. speed input: 14811.37 toks/s, output: 14.46 toks/s]
Processed prompts:  30%|       | 78/256 [00:05<00:12, 13.72it/s, est. speed input: 14789.59 toks/s, output: 14.44 toks/s]
Processed prompts:  31%|      | 80/256 [00:05<00:12, 13.78it/s, est. speed input: 14776.04 toks/s, output: 14.43 toks/s]
Processed prompts:  32%|      | 82/256 [00:05<00:12, 13.79it/s, est. speed input: 14759.72 toks/s, output: 14.41 toks/s]
Processed prompts:  33%|      | 84/256 [00:05<00:12, 13.83it/s, est. speed input: 14747.89 toks/s, output: 14.40 toks/s]
Processed prompts:  34%|      | 86/256 [00:05<00:12, 13.82it/s, est. speed input: 14732.49 toks/s, output: 14.39 toks/s]
Processed prompts:  34%|      | 88/256 [00:06<00:12, 13.62it/s, est. speed input: 14702.19 toks/s, output: 14.36 toks/s]
Processed prompts:  35%|      | 90/256 [00:06<00:12, 13.72it/s, est. speed input: 14692.67 toks/s, output: 14.35 toks/s]
Processed prompts:  36%|      | 92/256 [00:06<00:11, 13.77it/s, est. speed input: 14682.38 toks/s, output: 14.34 toks/s]
Processed prompts:  37%|      | 94/256 [00:06<00:11, 13.77it/s, est. speed input: 14669.46 toks/s, output: 14.33 toks/s]
Processed prompts:  38%|      | 96/256 [00:06<00:11, 13.77it/s, est. speed input: 14656.95 toks/s, output: 14.31 toks/s]
Processed prompts:  38%|      | 98/256 [00:06<00:11, 13.77it/s, est. speed input: 14645.17 toks/s, output: 14.30 toks/s]
Processed prompts:  39%|      | 100/256 [00:06<00:11, 13.83it/s, est. speed input: 14638.05 toks/s, output: 14.29 toks/s]
Processed prompts:  40%|      | 102/256 [00:07<00:11, 13.60it/s, est. speed input: 14612.09 toks/s, output: 14.27 toks/s]
Processed prompts:  41%|      | 104/256 [00:07<00:11, 13.67it/s, est. speed input: 14603.55 toks/s, output: 14.26 toks/s]
Processed prompts:  41%|     | 106/256 [00:07<00:10, 13.74it/s, est. speed input: 14596.45 toks/s, output: 14.25 toks/s]
Processed prompts:  42%|     | 108/256 [00:07<00:10, 13.74it/s, est. speed input: 14586.18 toks/s, output: 14.24 toks/s]
Processed prompts:  43%|     | 110/256 [00:07<00:10, 13.75it/s, est. speed input: 14577.20 toks/s, output: 14.24 toks/s]
Processed prompts:  44%|     | 112/256 [00:07<00:10, 13.82it/s, est. speed input: 14572.51 toks/s, output: 14.23 toks/s]
Processed prompts:  45%|     | 114/256 [00:08<00:10, 13.92it/s, est. speed input: 14571.25 toks/s, output: 14.23 toks/s]
Processed prompts:  45%|     | 116/256 [00:08<00:10, 13.70it/s, est. speed input: 14551.92 toks/s, output: 14.21 toks/s]
Processed prompts:  46%|     | 118/256 [00:08<00:10, 13.70it/s, est. speed input: 14542.78 toks/s, output: 14.20 toks/s]
Processed prompts:  47%|     | 120/256 [00:08<00:09, 13.73it/s, est. speed input: 14535.86 toks/s, output: 14.20 toks/s]
Processed prompts:  48%|     | 122/256 [00:08<00:09, 13.75it/s, est. speed input: 14528.62 toks/s, output: 14.19 toks/s]
Processed prompts:  48%|     | 124/256 [00:08<00:09, 13.76it/s, est. speed input: 14521.62 toks/s, output: 14.18 toks/s]
Processed prompts:  49%|     | 126/256 [00:08<00:09, 13.85it/s, est. speed input: 14519.99 toks/s, output: 14.18 toks/s]
Processed prompts:  50%|     | 128/256 [00:09<00:09, 13.81it/s, est. speed input: 14512.43 toks/s, output: 14.17 toks/s]
Processed prompts:  51%|     | 130/256 [00:09<00:09, 13.76it/s, est. speed input: 14503.66 toks/s, output: 14.16 toks/s]
Processed prompts:  52%|    | 132/256 [00:09<00:09, 13.65it/s, est. speed input: 14491.00 toks/s, output: 14.15 toks/s]
Processed prompts:  52%|    | 134/256 [00:09<00:08, 13.70it/s, est. speed input: 14486.07 toks/s, output: 14.15 toks/s]
Processed prompts:  53%|    | 136/256 [00:09<00:08, 13.79it/s, est. speed input: 14484.01 toks/s, output: 14.14 toks/s]
Processed prompts:  54%|    | 138/256 [00:09<00:08, 13.78it/s, est. speed input: 14477.89 toks/s, output: 14.14 toks/s]
Processed prompts:  55%|    | 140/256 [00:09<00:08, 13.73it/s, est. speed input: 14470.12 toks/s, output: 14.13 toks/s]
Processed prompts:  55%|    | 142/256 [00:10<00:08, 13.76it/s, est. speed input: 14465.34 toks/s, output: 14.13 toks/s]
Processed prompts:  56%|    | 144/256 [00:10<00:08, 13.82it/s, est. speed input: 14463.18 toks/s, output: 14.12 toks/s]
Processed prompts:  57%|    | 146/256 [00:10<00:08, 13.65it/s, est. speed input: 14450.37 toks/s, output: 14.11 toks/s]
Processed prompts:  58%|    | 148/256 [00:10<00:07, 13.73it/s, est. speed input: 14447.89 toks/s, output: 14.11 toks/s]
Processed prompts:  59%|    | 150/256 [00:10<00:07, 13.71it/s, est. speed input: 14441.64 toks/s, output: 14.10 toks/s]
Processed prompts:  59%|    | 152/256 [00:10<00:07, 13.75it/s, est. speed input: 14437.73 toks/s, output: 14.10 toks/s]
Processed prompts:  60%|    | 154/256 [00:10<00:07, 13.79it/s, est. speed input: 14435.06 toks/s, output: 14.10 toks/s]
Processed prompts:  61%|    | 156/256 [00:11<00:07, 13.80it/s, est. speed input: 14431.56 toks/s, output: 14.09 toks/s]
Processed prompts:  62%|   | 158/256 [00:11<00:07, 13.78it/s, est. speed input: 14426.68 toks/s, output: 14.09 toks/s]
Processed prompts:  62%|   | 160/256 [00:11<00:07, 13.63it/s, est. speed input: 14415.67 toks/s, output: 14.08 toks/s]
Processed prompts:  63%|   | 162/256 [00:11<00:06, 13.69it/s, est. speed input: 14412.73 toks/s, output: 14.07 toks/s]
Processed prompts:  64%|   | 164/256 [00:11<00:06, 13.74it/s, est. speed input: 14409.95 toks/s, output: 14.07 toks/s]
Processed prompts:  65%|   | 166/256 [00:11<00:06, 13.78it/s, est. speed input: 14407.25 toks/s, output: 14.07 toks/s]
Processed prompts:  66%|   | 168/256 [00:11<00:06, 13.81it/s, est. speed input: 14405.15 toks/s, output: 14.07 toks/s]
Processed prompts:  66%|   | 170/256 [00:12<00:06, 13.82it/s, est. speed input: 14402.28 toks/s, output: 14.06 toks/s]
Processed prompts:  67%|   | 172/256 [00:12<00:06, 13.79it/s, est. speed input: 14398.13 toks/s, output: 14.06 toks/s]
Processed prompts:  68%|   | 174/256 [00:12<00:06, 13.62it/s, est. speed input: 14387.89 toks/s, output: 14.05 toks/s]
Processed prompts:  69%|   | 176/256 [00:12<00:05, 13.66it/s, est. speed input: 14384.21 toks/s, output: 14.05 toks/s]
Processed prompts:  70%|   | 178/256 [00:12<00:05, 13.63it/s, est. speed input: 14378.67 toks/s, output: 14.04 toks/s]
Processed prompts:  70%|   | 180/256 [00:12<00:05, 13.66it/s, est. speed input: 14374.74 toks/s, output: 14.04 toks/s]
Processed prompts:  71%|   | 182/256 [00:12<00:05, 13.69it/s, est. speed input: 14371.70 toks/s, output: 14.03 toks/s]
Processed prompts:  72%|  | 184/256 [00:13<00:05, 13.74it/s, est. speed input: 14369.73 toks/s, output: 14.03 toks/s]
Processed prompts:  73%|  | 186/256 [00:13<00:05, 13.71it/s, est. speed input: 14365.20 toks/s, output: 14.03 toks/s]
Processed prompts:  73%|  | 188/256 [00:13<00:04, 13.67it/s, est. speed input: 14360.23 toks/s, output: 14.02 toks/s]
Processed prompts:  74%|  | 190/256 [00:13<00:04, 13.63it/s, est. speed input: 14354.78 toks/s, output: 14.02 toks/s]
Processed prompts:  75%|  | 192/256 [00:13<00:04, 13.68it/s, est. speed input: 14352.36 toks/s, output: 14.02 toks/s]
Processed prompts:  76%|  | 194/256 [00:13<00:04, 13.76it/s, est. speed input: 14351.63 toks/s, output: 14.02 toks/s]
Processed prompts:  77%|  | 196/256 [00:13<00:04, 13.72it/s, est. speed input: 14347.46 toks/s, output: 14.01 toks/s]
Processed prompts:  77%|  | 198/256 [00:14<00:04, 13.79it/s, est. speed input: 14346.85 toks/s, output: 14.01 toks/s]
Processed prompts:  78%|  | 200/256 [00:14<00:04, 13.75it/s, est. speed input: 14343.27 toks/s, output: 14.01 toks/s]
Processed prompts:  79%|  | 202/256 [00:14<00:03, 13.83it/s, est. speed input: 14343.28 toks/s, output: 14.01 toks/s]
Processed prompts:  80%|  | 204/256 [00:14<00:03, 13.63it/s, est. speed input: 14334.63 toks/s, output: 14.00 toks/s]
Processed prompts:  80%|  | 206/256 [00:14<00:03, 13.61it/s, est. speed input: 14330.02 toks/s, output: 13.99 toks/s]
Processed prompts:  81%| | 208/256 [00:14<00:03, 13.66it/s, est. speed input: 14327.75 toks/s, output: 13.99 toks/s]
Processed prompts:  82%| | 210/256 [00:15<00:03, 13.66it/s, est. speed input: 14324.45 toks/s, output: 13.99 toks/s]
Processed prompts:  83%| | 212/256 [00:15<00:03, 13.69it/s, est. speed input: 14322.36 toks/s, output: 13.99 toks/s]
Processed prompts:  84%| | 214/256 [00:15<00:03, 13.70it/s, est. speed input: 14319.59 toks/s, output: 13.98 toks/s]
Processed prompts:  84%| | 216/256 [00:15<00:02, 13.71it/s, est. speed input: 14317.34 toks/s, output: 13.98 toks/s]
Processed prompts:  85%| | 218/256 [00:15<00:02, 13.54it/s, est. speed input: 14309.06 toks/s, output: 13.97 toks/s]
Processed prompts:  86%| | 220/256 [00:15<00:02, 13.58it/s, est. speed input: 14306.40 toks/s, output: 13.97 toks/s]
Processed prompts:  87%| | 222/256 [00:15<00:02, 13.66it/s, est. speed input: 14305.13 toks/s, output: 13.97 toks/s]
Processed prompts:  88%| | 224/256 [00:16<00:02, 13.73it/s, est. speed input: 14304.42 toks/s, output: 13.97 toks/s]
Processed prompts:  88%| | 226/256 [00:16<00:02, 13.73it/s, est. speed input: 14302.37 toks/s, output: 13.97 toks/s]
Processed prompts:  89%| | 228/256 [00:16<00:02, 13.77it/s, est. speed input: 14301.28 toks/s, output: 13.97 toks/s]
Processed prompts:  90%| | 230/256 [00:16<00:01, 13.87it/s, est. speed input: 14302.52 toks/s, output: 13.97 toks/s]
Processed prompts:  91%| | 232/256 [00:16<00:01, 13.65it/s, est. speed input: 14295.13 toks/s, output: 13.96 toks/s]
Processed prompts:  91%|| 234/256 [00:16<00:01, 13.65it/s, est. speed input: 14292.43 toks/s, output: 13.96 toks/s]
Processed prompts:  92%|| 236/256 [00:16<00:01, 13.69it/s, est. speed input: 14290.80 toks/s, output: 13.96 toks/s]
Processed prompts:  93%|| 238/256 [00:17<00:01, 13.80it/s, est. speed input: 14291.77 toks/s, output: 13.96 toks/s]
Processed prompts:  94%|| 240/256 [00:17<00:01, 13.74it/s, est. speed input: 14288.51 toks/s, output: 13.95 toks/s]
Processed prompts:  95%|| 242/256 [00:17<00:01, 13.75it/s, est. speed input: 14287.02 toks/s, output: 13.95 toks/s]
Processed prompts:  95%|| 244/256 [00:17<00:00, 13.81it/s, est. speed input: 14287.04 toks/s, output: 13.95 toks/s]
Processed prompts:  96%|| 246/256 [00:17<00:00, 13.72it/s, est. speed input: 14283.15 toks/s, output: 13.95 toks/s]
Processed prompts:  97%|| 248/256 [00:17<00:00, 13.70it/s, est. speed input: 14280.69 toks/s, output: 13.95 toks/s]
Processed prompts:  98%|| 250/256 [00:17<00:00, 13.82it/s, est. speed input: 14282.11 toks/s, output: 13.95 toks/s]
Processed prompts:  98%|| 252/256 [00:18<00:00, 13.76it/s, est. speed input: 14279.30 toks/s, output: 13.94 toks/s]
Processed prompts:  99%|| 254/256 [00:18<00:00, 13.80it/s, est. speed input: 14278.99 toks/s, output: 13.94 toks/s]
Processed prompts: 100%|| 256/256 [00:18<00:00, 13.80it/s, est. speed input: 14333.20 toks/s, output: 14.00 toks/s]
Processed prompts: 100%|| 256/256 [00:18<00:00, 14.00it/s, est. speed input: 14333.20 toks/s, output: 14.00 toks/s]
[rank0]:[W126 10:08:18.607811536 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 10:08:20
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:08:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:08:25 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1164418) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1164418) WARNING 01-26 10:09:02 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 13.19 requests/s, 13515.05 total tokens/s, 13.19 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 10:08:25] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:08:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:08:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:08:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:08:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:08:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:08:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:08:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:08:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:08:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:08:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:08:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:08:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:08:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:08:28] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:08:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:08:28] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:08:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:08:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:08:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:08:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:08:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:08:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:08:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:08:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:08:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:08:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:08:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1164418) [2026-01-26 10:08:29] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1164418) [2026-01-26 10:08:29] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1164418) [2026-01-26 10:08:29] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1164418) [2026-01-26 10:08:29] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1164418) [2026-01-26 10:08:29] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1164418) [2026-01-26 10:08:29] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1164418) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1164418) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.73s/it]
(EngineCore_DP0 pid=1164418) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.73s/it]
(EngineCore_DP0 pid=1164418) 
(EngineCore_DP0 pid=1164418) [2026-01-26 10:08:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1164418) [2026-01-26 10:08:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=1164418) [2026-01-26 10:08:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1164418) [2026-01-26 10:08:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9437184 bytes
(EngineCore_DP0 pid=1164418) [2026-01-26 10:08:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1164418) [2026-01-26 10:08:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50331648 bytes
(EngineCore_DP0 pid=1164418) [2026-01-26 10:08:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1164418) [2026-01-26 10:08:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25264128 bytes
(EngineCore_DP0 pid=1164418) 2026-01-26 10:09:01,395 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1164418) 2026-01-26 10:09:01,405 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  12%|        | 62/512 [00:00<00:00, 612.79it/s]
Adding requests:  24%|       | 124/512 [00:00<00:00, 576.30it/s]
Adding requests:  36%|      | 182/512 [00:00<00:00, 548.77it/s]
Adding requests:  46%|     | 238/512 [00:00<00:00, 541.06it/s]
Adding requests:  57%|    | 293/512 [00:00<00:00, 539.71it/s]
Adding requests:  68%|   | 348/512 [00:00<00:00, 535.84it/s]
Adding requests:  79%|  | 403/512 [00:00<00:00, 539.34it/s]
Adding requests:  89%| | 457/512 [00:00<00:00, 534.71it/s]
Adding requests: 100%|| 511/512 [00:00<00:00, 526.92it/s]
Adding requests: 100%|| 512/512 [00:00<00:00, 539.44it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 10/512 [00:00<00:06, 82.45it/s, est. speed input: 84453.17 toks/s, output: 82.46 toks/s]
Processed prompts:   4%|         | 19/512 [00:00<00:21, 23.16it/s, est. speed input: 26752.70 toks/s, output: 26.13 toks/s]
Processed prompts:   5%|         | 24/512 [00:01<00:23, 20.55it/s, est. speed input: 23814.11 toks/s, output: 23.26 toks/s]
Processed prompts:   5%|         | 28/512 [00:01<00:26, 18.02it/s, est. speed input: 21531.36 toks/s, output: 21.03 toks/s]
Processed prompts:   6%|         | 31/512 [00:01<00:31, 15.21it/s, est. speed input: 19372.11 toks/s, output: 18.92 toks/s]
Processed prompts:   7%|         | 34/512 [00:01<00:35, 13.56it/s, est. speed input: 17975.65 toks/s, output: 17.55 toks/s]
Processed prompts:   7%|         | 38/512 [00:02<00:35, 13.48it/s, est. speed input: 17392.53 toks/s, output: 16.98 toks/s]
Processed prompts:   8%|         | 42/512 [00:02<00:35, 13.42it/s, est. speed input: 16941.30 toks/s, output: 16.54 toks/s]
Processed prompts:   9%|         | 46/512 [00:02<00:35, 13.26it/s, est. speed input: 16535.98 toks/s, output: 16.15 toks/s]
Processed prompts:  10%|         | 50/512 [00:03<00:34, 13.29it/s, est. speed input: 16266.21 toks/s, output: 15.88 toks/s]
Processed prompts:  11%|         | 54/512 [00:03<00:34, 13.26it/s, est. speed input: 16022.69 toks/s, output: 15.65 toks/s]
Processed prompts:  11%|        | 58/512 [00:03<00:34, 13.23it/s, est. speed input: 15817.93 toks/s, output: 15.45 toks/s]
Processed prompts:  12%|        | 62/512 [00:04<00:33, 13.26it/s, est. speed input: 15657.17 toks/s, output: 15.29 toks/s]
Processed prompts:  13%|        | 66/512 [00:04<00:33, 13.30it/s, est. speed input: 15523.98 toks/s, output: 15.16 toks/s]
Processed prompts:  14%|        | 70/512 [00:04<00:33, 13.29it/s, est. speed input: 15397.21 toks/s, output: 15.04 toks/s]
Processed prompts:  14%|        | 74/512 [00:04<00:33, 13.15it/s, est. speed input: 15256.61 toks/s, output: 14.90 toks/s]
Processed prompts:  15%|        | 78/512 [00:05<00:33, 13.11it/s, est. speed input: 15145.27 toks/s, output: 14.79 toks/s]
Processed prompts:  16%|        | 82/512 [00:05<00:32, 13.20it/s, est. speed input: 15069.27 toks/s, output: 14.72 toks/s]
Processed prompts:  17%|        | 86/512 [00:05<00:32, 13.17it/s, est. speed input: 14983.70 toks/s, output: 14.63 toks/s]
Processed prompts:  18%|        | 90/512 [00:06<00:32, 13.17it/s, est. speed input: 14910.14 toks/s, output: 14.56 toks/s]
Processed prompts:  18%|        | 94/512 [00:06<00:31, 13.21it/s, est. speed input: 14850.95 toks/s, output: 14.50 toks/s]
Processed prompts:  19%|        | 98/512 [00:06<00:31, 13.28it/s, est. speed input: 14802.81 toks/s, output: 14.46 toks/s]
Processed prompts:  20%|        | 102/512 [00:07<00:31, 13.21it/s, est. speed input: 14740.57 toks/s, output: 14.39 toks/s]
Processed prompts:  21%|        | 106/512 [00:07<00:30, 13.21it/s, est. speed input: 14691.03 toks/s, output: 14.35 toks/s]
Processed prompts:  21%|       | 110/512 [00:07<00:30, 13.27it/s, est. speed input: 14653.67 toks/s, output: 14.31 toks/s]
Processed prompts:  22%|       | 114/512 [00:07<00:30, 13.19it/s, est. speed input: 14603.04 toks/s, output: 14.26 toks/s]
Processed prompts:  23%|       | 118/512 [00:08<00:29, 13.23it/s, est. speed input: 14567.39 toks/s, output: 14.23 toks/s]
Processed prompts:  24%|       | 122/512 [00:08<00:29, 13.32it/s, est. speed input: 14543.71 toks/s, output: 14.20 toks/s]
Processed prompts:  25%|       | 126/512 [00:08<00:28, 13.37it/s, est. speed input: 14519.07 toks/s, output: 14.18 toks/s]
Processed prompts:  25%|       | 130/512 [00:09<00:28, 13.21it/s, est. speed input: 14473.23 toks/s, output: 14.13 toks/s]
Processed prompts:  26%|       | 134/512 [00:09<00:28, 13.22it/s, est. speed input: 14444.46 toks/s, output: 14.11 toks/s]
Processed prompts:  27%|       | 138/512 [00:09<00:28, 13.28it/s, est. speed input: 14422.80 toks/s, output: 14.08 toks/s]
Processed prompts:  28%|       | 142/512 [00:10<00:28, 13.21it/s, est. speed input: 14390.48 toks/s, output: 14.05 toks/s]
Processed prompts:  29%|       | 146/512 [00:10<00:27, 13.23it/s, est. speed input: 14367.28 toks/s, output: 14.03 toks/s]
Processed prompts:  29%|       | 150/512 [00:10<00:27, 13.21it/s, est. speed input: 14341.91 toks/s, output: 14.01 toks/s]
Processed prompts:  30%|       | 154/512 [00:11<00:27, 13.21it/s, est. speed input: 14320.10 toks/s, output: 13.98 toks/s]
Processed prompts:  31%|       | 158/512 [00:11<00:26, 13.14it/s, est. speed input: 14292.30 toks/s, output: 13.96 toks/s]
Processed prompts:  32%|      | 162/512 [00:11<00:26, 13.15it/s, est. speed input: 14270.93 toks/s, output: 13.94 toks/s]
Processed prompts:  32%|      | 166/512 [00:11<00:26, 13.20it/s, est. speed input: 14254.80 toks/s, output: 13.92 toks/s]
Processed prompts:  33%|      | 170/512 [00:12<00:26, 13.12it/s, est. speed input: 14229.29 toks/s, output: 13.90 toks/s]
Processed prompts:  34%|      | 174/512 [00:12<00:25, 13.20it/s, est. speed input: 14217.19 toks/s, output: 13.88 toks/s]
Processed prompts:  35%|      | 178/512 [00:12<00:25, 13.22it/s, est. speed input: 14202.56 toks/s, output: 13.87 toks/s]
Processed prompts:  36%|      | 182/512 [00:13<00:24, 13.28it/s, est. speed input: 14191.70 toks/s, output: 13.86 toks/s]
Processed prompts:  36%|      | 186/512 [00:13<00:24, 13.18it/s, est. speed input: 14170.52 toks/s, output: 13.84 toks/s]
Processed prompts:  37%|      | 190/512 [00:13<00:24, 13.23it/s, est. speed input: 14159.74 toks/s, output: 13.83 toks/s]
Processed prompts:  38%|      | 194/512 [00:14<00:24, 13.20it/s, est. speed input: 14144.12 toks/s, output: 13.81 toks/s]
Processed prompts:  39%|      | 198/512 [00:14<00:23, 13.15it/s, est. speed input: 14126.78 toks/s, output: 13.80 toks/s]
Processed prompts:  39%|      | 202/512 [00:14<00:23, 13.17it/s, est. speed input: 14114.39 toks/s, output: 13.78 toks/s]
Processed prompts:  40%|      | 206/512 [00:14<00:23, 13.23it/s, est. speed input: 14106.32 toks/s, output: 13.78 toks/s]
Processed prompts:  41%|      | 210/512 [00:15<00:22, 13.31it/s, est. speed input: 14100.69 toks/s, output: 13.77 toks/s]
Processed prompts:  42%|     | 214/512 [00:15<00:22, 13.21it/s, est. speed input: 14084.44 toks/s, output: 13.75 toks/s]
Processed prompts:  43%|     | 218/512 [00:15<00:22, 13.24it/s, est. speed input: 14076.16 toks/s, output: 13.75 toks/s]
Processed prompts:  43%|     | 222/512 [00:16<00:21, 13.23it/s, est. speed input: 14065.55 toks/s, output: 13.74 toks/s]
Processed prompts:  44%|     | 226/512 [00:16<00:21, 13.13it/s, est. speed input: 14049.64 toks/s, output: 13.72 toks/s]
Processed prompts:  45%|     | 230/512 [00:16<00:21, 13.18it/s, est. speed input: 14042.01 toks/s, output: 13.71 toks/s]
Processed prompts:  46%|     | 234/512 [00:17<00:21, 13.20it/s, est. speed input: 14033.55 toks/s, output: 13.70 toks/s]
Processed prompts:  46%|     | 238/512 [00:17<00:20, 13.19it/s, est. speed input: 14023.99 toks/s, output: 13.70 toks/s]
Processed prompts:  47%|     | 242/512 [00:17<00:20, 13.08it/s, est. speed input: 14008.43 toks/s, output: 13.68 toks/s]
Processed prompts:  48%|     | 246/512 [00:17<00:20, 13.13it/s, est. speed input: 14000.68 toks/s, output: 13.67 toks/s]
Processed prompts:  49%|     | 250/512 [00:18<00:19, 13.19it/s, est. speed input: 13995.11 toks/s, output: 13.67 toks/s]
Processed prompts:  50%|     | 254/512 [00:18<00:19, 13.11it/s, est. speed input: 13982.74 toks/s, output: 13.66 toks/s]
Processed prompts:  50%|     | 258/512 [00:18<00:19, 13.18it/s, est. speed input: 13977.49 toks/s, output: 13.65 toks/s]
Processed prompts:  51%|     | 262/512 [00:19<00:18, 13.17it/s, est. speed input: 13969.36 toks/s, output: 13.64 toks/s]
Processed prompts:  52%|    | 266/512 [00:19<00:18, 13.23it/s, est. speed input: 13965.38 toks/s, output: 13.64 toks/s]
Processed prompts:  53%|    | 270/512 [00:19<00:18, 13.20it/s, est. speed input: 13957.15 toks/s, output: 13.63 toks/s]
Processed prompts:  54%|    | 274/512 [00:20<00:18, 13.21it/s, est. speed input: 13951.02 toks/s, output: 13.62 toks/s]
Processed prompts:  54%|    | 278/512 [00:20<00:17, 13.17it/s, est. speed input: 13942.90 toks/s, output: 13.62 toks/s]
Processed prompts:  55%|    | 282/512 [00:20<00:17, 13.11it/s, est. speed input: 13932.78 toks/s, output: 13.61 toks/s]
Processed prompts:  56%|    | 286/512 [00:21<00:17, 13.18it/s, est. speed input: 13929.00 toks/s, output: 13.60 toks/s]
Processed prompts:  57%|    | 290/512 [00:21<00:16, 13.18it/s, est. speed input: 13922.87 toks/s, output: 13.60 toks/s]
Processed prompts:  57%|    | 294/512 [00:21<00:16, 13.21it/s, est. speed input: 13918.24 toks/s, output: 13.59 toks/s]
Processed prompts:  58%|    | 298/512 [00:21<00:16, 13.10it/s, est. speed input: 13907.56 toks/s, output: 13.58 toks/s]
Processed prompts:  59%|    | 302/512 [00:22<00:15, 13.15it/s, est. speed input: 13902.98 toks/s, output: 13.58 toks/s]
Processed prompts:  60%|    | 306/512 [00:22<00:15, 13.22it/s, est. speed input: 13900.69 toks/s, output: 13.57 toks/s]
Processed prompts:  61%|    | 310/512 [00:22<00:15, 13.15it/s, est. speed input: 13892.66 toks/s, output: 13.57 toks/s]
Processed prompts:  61%|   | 314/512 [00:23<00:15, 13.17it/s, est. speed input: 13887.94 toks/s, output: 13.56 toks/s]
Processed prompts:  62%|   | 318/512 [00:23<00:14, 13.19it/s, est. speed input: 13883.45 toks/s, output: 13.56 toks/s]
Processed prompts:  63%|   | 322/512 [00:23<00:14, 13.20it/s, est. speed input: 13879.26 toks/s, output: 13.55 toks/s]
Processed prompts:  64%|   | 326/512 [00:24<00:14, 13.12it/s, est. speed input: 13871.27 toks/s, output: 13.55 toks/s]
Processed prompts:  64%|   | 330/512 [00:24<00:13, 13.16it/s, est. speed input: 13867.32 toks/s, output: 13.54 toks/s]
Processed prompts:  65%|   | 334/512 [00:24<00:13, 13.18it/s, est. speed input: 13863.47 toks/s, output: 13.54 toks/s]
Processed prompts:  66%|   | 338/512 [00:24<00:13, 13.10it/s, est. speed input: 13855.69 toks/s, output: 13.53 toks/s]
Processed prompts:  67%|   | 342/512 [00:25<00:12, 13.71it/s, est. speed input: 13875.01 toks/s, output: 13.55 toks/s]
Processed prompts:  68%|   | 346/512 [00:25<00:12, 13.56it/s, est. speed input: 13871.16 toks/s, output: 13.55 toks/s]
Processed prompts:  68%|   | 350/512 [00:25<00:12, 13.50it/s, est. speed input: 13868.83 toks/s, output: 13.54 toks/s]
Processed prompts:  69%|   | 354/512 [00:26<00:11, 13.33it/s, est. speed input: 13861.58 toks/s, output: 13.54 toks/s]
Processed prompts:  70%|   | 358/512 [00:26<00:11, 13.32it/s, est. speed input: 13858.77 toks/s, output: 13.53 toks/s]
Processed prompts:  71%|   | 362/512 [00:26<00:11, 13.30it/s, est. speed input: 13855.44 toks/s, output: 13.53 toks/s]
Processed prompts:  71%|  | 366/512 [00:27<00:11, 13.25it/s, est. speed input: 13851.18 toks/s, output: 13.53 toks/s]
Processed prompts:  72%|  | 370/512 [00:27<00:10, 13.21it/s, est. speed input: 13846.47 toks/s, output: 13.52 toks/s]
Processed prompts:  73%|  | 374/512 [00:27<00:10, 13.26it/s, est. speed input: 13844.91 toks/s, output: 13.52 toks/s]
Processed prompts:  74%|  | 378/512 [00:27<00:10, 13.31it/s, est. speed input: 13843.87 toks/s, output: 13.52 toks/s]
Processed prompts:  75%|  | 382/512 [00:28<00:09, 13.18it/s, est. speed input: 13836.57 toks/s, output: 13.51 toks/s]
Processed prompts:  75%|  | 386/512 [00:28<00:09, 13.20it/s, est. speed input: 13833.83 toks/s, output: 13.51 toks/s]
Processed prompts:  76%|  | 390/512 [00:28<00:09, 13.19it/s, est. speed input: 13830.24 toks/s, output: 13.51 toks/s]
Processed prompts:  77%|  | 394/512 [00:29<00:08, 13.11it/s, est. speed input: 13823.97 toks/s, output: 13.50 toks/s]
Processed prompts:  78%|  | 398/512 [00:29<00:08, 13.10it/s, est. speed input: 13819.44 toks/s, output: 13.50 toks/s]
Processed prompts:  79%|  | 402/512 [00:29<00:08, 13.14it/s, est. speed input: 13816.74 toks/s, output: 13.49 toks/s]
Processed prompts:  79%|  | 406/512 [00:30<00:08, 13.20it/s, est. speed input: 13815.13 toks/s, output: 13.49 toks/s]
Processed prompts:  80%|  | 410/512 [00:30<00:07, 13.14it/s, est. speed input: 13810.11 toks/s, output: 13.49 toks/s]
Processed prompts:  81%|  | 414/512 [00:30<00:07, 13.16it/s, est. speed input: 13807.45 toks/s, output: 13.48 toks/s]
Processed prompts:  82%| | 418/512 [00:31<00:07, 13.21it/s, est. speed input: 13805.85 toks/s, output: 13.48 toks/s]
Processed prompts:  82%| | 422/512 [00:31<00:06, 13.18it/s, est. speed input: 13802.17 toks/s, output: 13.48 toks/s]
Processed prompts:  83%| | 426/512 [00:31<00:06, 13.25it/s, est. speed input: 13801.42 toks/s, output: 13.48 toks/s]
Processed prompts:  84%| | 430/512 [00:31<00:06, 13.30it/s, est. speed input: 13800.79 toks/s, output: 13.48 toks/s]
Processed prompts:  85%| | 434/512 [00:32<00:05, 13.28it/s, est. speed input: 13798.48 toks/s, output: 13.48 toks/s]
Processed prompts:  86%| | 438/512 [00:32<00:05, 13.22it/s, est. speed input: 13794.86 toks/s, output: 13.47 toks/s]
Processed prompts:  86%| | 442/512 [00:32<00:05, 13.19it/s, est. speed input: 13791.58 toks/s, output: 13.47 toks/s]
Processed prompts:  87%| | 446/512 [00:33<00:05, 13.17it/s, est. speed input: 13788.22 toks/s, output: 13.47 toks/s]
Processed prompts:  88%| | 450/512 [00:33<00:04, 13.91it/s, est. speed input: 13807.76 toks/s, output: 13.48 toks/s]
Processed prompts:  89%| | 454/512 [00:33<00:04, 13.73it/s, est. speed input: 13806.24 toks/s, output: 13.48 toks/s]
Processed prompts:  89%| | 458/512 [00:33<00:03, 13.55it/s, est. speed input: 13803.22 toks/s, output: 13.48 toks/s]
Processed prompts:  90%| | 462/512 [00:34<00:03, 13.40it/s, est. speed input: 13799.31 toks/s, output: 13.48 toks/s]
Processed prompts:  91%| | 466/512 [00:34<00:03, 13.23it/s, est. speed input: 13793.59 toks/s, output: 13.47 toks/s]
Processed prompts:  92%|| 470/512 [00:34<00:03, 13.21it/s, est. speed input: 13790.76 toks/s, output: 13.47 toks/s]
Processed prompts:  93%|| 474/512 [00:35<00:02, 13.23it/s, est. speed input: 13789.12 toks/s, output: 13.47 toks/s]
Processed prompts:  93%|| 478/512 [00:35<00:02, 13.13it/s, est. speed input: 13784.11 toks/s, output: 13.46 toks/s]
Processed prompts:  94%|| 482/512 [00:35<00:02, 13.18it/s, est. speed input: 13782.57 toks/s, output: 13.46 toks/s]
Processed prompts:  95%|| 486/512 [00:36<00:01, 13.17it/s, est. speed input: 13780.12 toks/s, output: 13.46 toks/s]
Processed prompts:  96%|| 490/512 [00:36<00:01, 13.23it/s, est. speed input: 13779.24 toks/s, output: 13.46 toks/s]
Processed prompts:  96%|| 494/512 [00:36<00:01, 13.14it/s, est. speed input: 13774.76 toks/s, output: 13.45 toks/s]
Processed prompts:  97%|| 498/512 [00:37<00:01, 13.10it/s, est. speed input: 13770.86 toks/s, output: 13.45 toks/s]
Processed prompts:  98%|| 502/512 [00:37<00:00, 13.13it/s, est. speed input: 13768.91 toks/s, output: 13.45 toks/s]
Processed prompts:  99%|| 506/512 [00:37<00:00, 13.05it/s, est. speed input: 13764.09 toks/s, output: 13.44 toks/s]
Processed prompts: 100%|| 510/512 [00:37<00:00, 14.03it/s, est. speed input: 13786.71 toks/s, output: 13.46 toks/s]
Processed prompts: 100%|| 512/512 [00:37<00:00, 14.03it/s, est. speed input: 13840.74 toks/s, output: 13.52 toks/s]
Processed prompts: 100%|| 512/512 [00:37<00:00, 13.52it/s, est. speed input: 13840.74 toks/s, output: 13.52 toks/s]
[rank0]:[W126 10:09:41.380667326 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 10:09:43
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:09:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:09:49 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1165769) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1165769) WARNING 01-26 10:10:26 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 13.13 requests/s, 13460.93 total tokens/s, 13.13 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 10:09:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:09:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:09:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:09:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:09:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:09:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:09:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:09:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:09:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:09:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:09:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:09:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:09:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:09:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:09:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:09:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:09:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:09:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:09:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:09:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:09:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:09:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:09:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:09:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:09:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:09:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:09:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:09:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1165769) [2026-01-26 10:09:54] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1165769) [2026-01-26 10:09:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1165769) [2026-01-26 10:09:54] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1165769) [2026-01-26 10:09:54] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1165769) [2026-01-26 10:09:54] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1165769) [2026-01-26 10:09:54] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1165769) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1165769) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.82s/it]
(EngineCore_DP0 pid=1165769) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.82s/it]
(EngineCore_DP0 pid=1165769) 
(EngineCore_DP0 pid=1165769) [2026-01-26 10:10:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1165769) [2026-01-26 10:10:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=1165769) [2026-01-26 10:10:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1165769) [2026-01-26 10:10:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9437184 bytes
(EngineCore_DP0 pid=1165769) [2026-01-26 10:10:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1165769) [2026-01-26 10:10:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50331648 bytes
(EngineCore_DP0 pid=1165769) [2026-01-26 10:10:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1165769) [2026-01-26 10:10:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25264128 bytes
(EngineCore_DP0 pid=1165769) 2026-01-26 10:10:25,782 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1165769) 2026-01-26 10:10:25,832 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   6%|         | 66/1024 [00:00<00:01, 659.25it/s]
Adding requests:  13%|        | 132/1024 [00:00<00:01, 600.89it/s]
Adding requests:  19%|        | 193/1024 [00:00<00:01, 561.37it/s]
Adding requests:  24%|       | 250/1024 [00:00<00:01, 557.64it/s]
Adding requests:  30%|       | 306/1024 [00:00<00:01, 548.42it/s]
Adding requests:  35%|      | 361/1024 [00:00<00:01, 544.04it/s]
Adding requests:  41%|      | 416/1024 [00:00<00:01, 543.69it/s]
Adding requests:  46%|     | 471/1024 [00:00<00:01, 538.43it/s]
Adding requests:  51%|    | 525/1024 [00:00<00:00, 526.29it/s]
Adding requests:  56%|    | 578/1024 [00:01<00:00, 516.17it/s]
Adding requests:  62%|   | 631/1024 [00:01<00:00, 519.78it/s]
Adding requests:  67%|   | 686/1024 [00:01<00:00, 526.50it/s]
Adding requests:  72%|  | 739/1024 [00:01<00:00, 526.08it/s]
Adding requests:  77%|  | 792/1024 [00:01<00:00, 514.09it/s]
Adding requests:  82%| | 844/1024 [00:01<00:00, 503.53it/s]
Adding requests:  88%| | 901/1024 [00:01<00:00, 520.66it/s]
Adding requests:  93%|| 956/1024 [00:01<00:00, 527.69it/s]
Adding requests:  99%|| 1012/1024 [00:01<00:00, 536.62it/s]
Adding requests: 100%|| 1024/1024 [00:01<00:00, 535.22it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 26/1024 [00:00<00:26, 38.10it/s, est. speed input: 39020.83 toks/s, output: 38.11 toks/s]
Processed prompts:   3%|         | 34/1024 [00:01<00:40, 24.16it/s, est. speed input: 27008.50 toks/s, output: 26.38 toks/s]
Processed prompts:   4%|         | 42/1024 [00:01<00:50, 19.47it/s, est. speed input: 22844.63 toks/s, output: 22.31 toks/s]
Processed prompts:   5%|         | 50/1024 [00:02<00:57, 16.97it/s, est. speed input: 20529.37 toks/s, output: 20.05 toks/s]
Processed prompts:   6%|         | 58/1024 [00:03<01:01, 15.66it/s, est. speed input: 19181.00 toks/s, output: 18.73 toks/s]
Processed prompts:   6%|         | 66/1024 [00:03<01:04, 14.89it/s, est. speed input: 18293.34 toks/s, output: 17.86 toks/s]
Processed prompts:   7%|         | 74/1024 [00:04<01:06, 14.37it/s, est. speed input: 17635.21 toks/s, output: 17.22 toks/s]
Processed prompts:   8%|         | 82/1024 [00:04<01:07, 14.01it/s, est. speed input: 17132.91 toks/s, output: 16.73 toks/s]
Processed prompts:   9%|         | 90/1024 [00:05<01:08, 13.73it/s, est. speed input: 16722.12 toks/s, output: 16.33 toks/s]
Processed prompts:  10%|         | 98/1024 [00:06<01:07, 13.63it/s, est. speed input: 16432.11 toks/s, output: 16.05 toks/s]
Processed prompts:  10%|         | 106/1024 [00:06<01:08, 13.46it/s, est. speed input: 16155.71 toks/s, output: 15.78 toks/s]
Processed prompts:  11%|         | 114/1024 [00:07<01:07, 13.47it/s, est. speed input: 15965.45 toks/s, output: 15.59 toks/s]
Processed prompts:  12%|        | 122/1024 [00:07<01:07, 13.34it/s, est. speed input: 15764.33 toks/s, output: 15.39 toks/s]
Processed prompts:  13%|        | 130/1024 [00:08<01:07, 13.27it/s, est. speed input: 15595.47 toks/s, output: 15.23 toks/s]
Processed prompts:  13%|        | 138/1024 [00:09<01:06, 13.25it/s, est. speed input: 15458.23 toks/s, output: 15.10 toks/s]
Processed prompts:  14%|        | 146/1024 [00:09<01:06, 13.20it/s, est. speed input: 15329.47 toks/s, output: 14.97 toks/s]
Processed prompts:  15%|        | 154/1024 [00:10<01:05, 13.22it/s, est. speed input: 15227.86 toks/s, output: 14.87 toks/s]
Processed prompts:  16%|        | 162/1024 [00:10<01:05, 13.21it/s, est. speed input: 15133.08 toks/s, output: 14.78 toks/s]
Processed prompts:  17%|        | 170/1024 [00:11<01:04, 13.19it/s, est. speed input: 15044.30 toks/s, output: 14.69 toks/s]
Processed prompts:  17%|        | 178/1024 [00:12<01:04, 13.18it/s, est. speed input: 14965.79 toks/s, output: 14.62 toks/s]
Processed prompts:  18%|        | 186/1024 [00:12<01:03, 13.18it/s, est. speed input: 14895.59 toks/s, output: 14.55 toks/s]
Processed prompts:  19%|        | 194/1024 [00:13<01:02, 13.18it/s, est. speed input: 14832.63 toks/s, output: 14.48 toks/s]
Processed prompts:  20%|        | 202/1024 [00:14<01:02, 13.16it/s, est. speed input: 14771.78 toks/s, output: 14.43 toks/s]
Processed prompts:  21%|        | 210/1024 [00:14<01:01, 13.24it/s, est. speed input: 14730.34 toks/s, output: 14.39 toks/s]
Processed prompts:  21%|       | 218/1024 [00:15<01:00, 13.22it/s, est. speed input: 14679.93 toks/s, output: 14.34 toks/s]
Processed prompts:  22%|       | 226/1024 [00:15<01:00, 13.21it/s, est. speed input: 14635.15 toks/s, output: 14.29 toks/s]
Processed prompts:  23%|       | 234/1024 [00:16<00:59, 13.24it/s, est. speed input: 14597.76 toks/s, output: 14.26 toks/s]
Processed prompts:  24%|       | 242/1024 [00:17<00:59, 13.21it/s, est. speed input: 14557.10 toks/s, output: 14.22 toks/s]
Processed prompts:  24%|       | 250/1024 [00:17<00:58, 13.28it/s, est. speed input: 14530.37 toks/s, output: 14.19 toks/s]
Processed prompts:  25%|       | 258/1024 [00:18<00:57, 13.28it/s, est. speed input: 14500.07 toks/s, output: 14.16 toks/s]
Processed prompts:  26%|       | 266/1024 [00:18<00:57, 13.26it/s, est. speed input: 14468.39 toks/s, output: 14.13 toks/s]
Processed prompts:  27%|       | 274/1024 [00:19<00:56, 13.24it/s, est. speed input: 14438.41 toks/s, output: 14.10 toks/s]
Processed prompts:  28%|       | 282/1024 [00:20<00:55, 13.28it/s, est. speed input: 14416.43 toks/s, output: 14.08 toks/s]
Processed prompts:  28%|       | 290/1024 [00:20<00:55, 13.25it/s, est. speed input: 14389.09 toks/s, output: 14.05 toks/s]
Processed prompts:  29%|       | 298/1024 [00:21<00:54, 13.20it/s, est. speed input: 14360.90 toks/s, output: 14.02 toks/s]
Processed prompts:  30%|       | 306/1024 [00:21<00:54, 13.23it/s, est. speed input: 14340.62 toks/s, output: 14.00 toks/s]
Processed prompts:  31%|       | 314/1024 [00:22<00:53, 13.23it/s, est. speed input: 14319.36 toks/s, output: 13.98 toks/s]
Processed prompts:  31%|      | 322/1024 [00:23<00:52, 13.25it/s, est. speed input: 14300.75 toks/s, output: 13.97 toks/s]
Processed prompts:  32%|      | 330/1024 [00:23<00:52, 13.17it/s, est. speed input: 14274.66 toks/s, output: 13.94 toks/s]
Processed prompts:  33%|      | 338/1024 [00:24<00:50, 13.46it/s, est. speed input: 14280.30 toks/s, output: 13.95 toks/s]
Processed prompts:  34%|      | 346/1024 [00:24<00:50, 13.34it/s, est. speed input: 14258.10 toks/s, output: 13.92 toks/s]
Processed prompts:  35%|      | 354/1024 [00:25<00:50, 13.30it/s, est. speed input: 14240.86 toks/s, output: 13.91 toks/s]
Processed prompts:  35%|      | 362/1024 [00:26<00:49, 13.28it/s, est. speed input: 14224.78 toks/s, output: 13.89 toks/s]
Processed prompts:  36%|      | 370/1024 [00:26<00:49, 13.20it/s, est. speed input: 14204.61 toks/s, output: 13.87 toks/s]
Processed prompts:  37%|      | 378/1024 [00:27<00:48, 13.21it/s, est. speed input: 14190.04 toks/s, output: 13.86 toks/s]
Processed prompts:  38%|      | 386/1024 [00:27<00:48, 13.14it/s, est. speed input: 14169.83 toks/s, output: 13.84 toks/s]
Processed prompts:  38%|      | 394/1024 [00:28<00:47, 13.19it/s, est. speed input: 14158.54 toks/s, output: 13.83 toks/s]
Processed prompts:  39%|      | 402/1024 [00:29<00:47, 13.19it/s, est. speed input: 14144.69 toks/s, output: 13.81 toks/s]
Processed prompts:  40%|      | 410/1024 [00:29<00:46, 13.20it/s, est. speed input: 14132.84 toks/s, output: 13.80 toks/s]
Processed prompts:  41%|      | 418/1024 [00:30<00:52, 11.63it/s, est. speed input: 13994.89 toks/s, output: 13.67 toks/s]
Processed prompts:  42%|     | 426/1024 [00:31<00:50, 11.87it/s, est. speed input: 13969.06 toks/s, output: 13.64 toks/s]
Processed prompts:  42%|     | 434/1024 [00:31<00:48, 12.20it/s, est. speed input: 13957.16 toks/s, output: 13.63 toks/s]
Processed prompts:  43%|     | 442/1024 [00:32<00:46, 12.49it/s, est. speed input: 13949.75 toks/s, output: 13.62 toks/s]
Processed prompts:  44%|     | 450/1024 [00:33<00:44, 12.99it/s, est. speed input: 13962.13 toks/s, output: 13.63 toks/s]
Processed prompts:  45%|     | 458/1024 [00:33<00:43, 13.06it/s, est. speed input: 13954.74 toks/s, output: 13.63 toks/s]
Processed prompts:  46%|     | 466/1024 [00:34<00:42, 13.12it/s, est. speed input: 13947.93 toks/s, output: 13.62 toks/s]
Processed prompts:  46%|     | 474/1024 [00:34<00:41, 13.23it/s, est. speed input: 13945.95 toks/s, output: 13.62 toks/s]
Processed prompts:  47%|     | 482/1024 [00:35<00:41, 13.17it/s, est. speed input: 13935.51 toks/s, output: 13.61 toks/s]
Processed prompts:  48%|     | 490/1024 [00:36<00:40, 13.17it/s, est. speed input: 13927.80 toks/s, output: 13.60 toks/s]
Processed prompts:  49%|     | 498/1024 [00:36<00:39, 13.21it/s, est. speed input: 13922.67 toks/s, output: 13.60 toks/s]
Processed prompts:  49%|     | 506/1024 [00:37<00:39, 13.14it/s, est. speed input: 13912.41 toks/s, output: 13.59 toks/s]
Processed prompts:  50%|     | 514/1024 [00:37<00:38, 13.19it/s, est. speed input: 13908.01 toks/s, output: 13.58 toks/s]
Processed prompts:  51%|     | 522/1024 [00:38<00:38, 13.13it/s, est. speed input: 13898.24 toks/s, output: 13.57 toks/s]
Processed prompts:  52%|    | 530/1024 [00:39<00:37, 13.16it/s, est. speed input: 13892.78 toks/s, output: 13.57 toks/s]
Processed prompts:  53%|    | 538/1024 [00:39<00:36, 13.18it/s, est. speed input: 13887.47 toks/s, output: 13.56 toks/s]
Processed prompts:  53%|    | 546/1024 [00:40<00:36, 13.16it/s, est. speed input: 13880.68 toks/s, output: 13.56 toks/s]
Processed prompts:  54%|    | 554/1024 [00:40<00:35, 13.14it/s, est. speed input: 13873.65 toks/s, output: 13.55 toks/s]
Processed prompts:  55%|    | 562/1024 [00:41<00:35, 13.13it/s, est. speed input: 13867.07 toks/s, output: 13.54 toks/s]
Processed prompts:  56%|    | 570/1024 [00:42<00:34, 13.20it/s, est. speed input: 13864.40 toks/s, output: 13.54 toks/s]
Processed prompts:  56%|    | 578/1024 [00:42<00:33, 13.20it/s, est. speed input: 13859.69 toks/s, output: 13.53 toks/s]
Processed prompts:  57%|    | 586/1024 [00:43<00:33, 13.24it/s, est. speed input: 13856.92 toks/s, output: 13.53 toks/s]
Processed prompts:  58%|    | 594/1024 [00:43<00:32, 13.24it/s, est. speed input: 13852.76 toks/s, output: 13.53 toks/s]
Processed prompts:  59%|    | 602/1024 [00:44<00:31, 13.23it/s, est. speed input: 13848.08 toks/s, output: 13.52 toks/s]
Processed prompts:  60%|    | 610/1024 [00:45<00:31, 13.18it/s, est. speed input: 13841.99 toks/s, output: 13.52 toks/s]
Processed prompts:  60%|    | 618/1024 [00:45<00:30, 13.18it/s, est. speed input: 13837.07 toks/s, output: 13.51 toks/s]
Processed prompts:  61%|    | 626/1024 [00:46<00:30, 13.21it/s, est. speed input: 13834.18 toks/s, output: 13.51 toks/s]
Processed prompts:  62%|   | 634/1024 [00:46<00:29, 13.16it/s, est. speed input: 13828.07 toks/s, output: 13.50 toks/s]
Processed prompts:  63%|   | 642/1024 [00:47<00:28, 13.21it/s, est. speed input: 13825.78 toks/s, output: 13.50 toks/s]
Processed prompts:  63%|   | 650/1024 [00:48<00:28, 13.19it/s, est. speed input: 13821.04 toks/s, output: 13.50 toks/s]
Processed prompts:  64%|   | 658/1024 [00:48<00:27, 13.17it/s, est. speed input: 13816.20 toks/s, output: 13.49 toks/s]
Processed prompts:  65%|   | 666/1024 [00:49<00:27, 13.13it/s, est. speed input: 13810.43 toks/s, output: 13.49 toks/s]
Processed prompts:  66%|   | 674/1024 [00:49<00:26, 13.16it/s, est. speed input: 13807.21 toks/s, output: 13.48 toks/s]
Processed prompts:  67%|   | 682/1024 [00:50<00:25, 13.19it/s, est. speed input: 13804.52 toks/s, output: 13.48 toks/s]
Processed prompts:  67%|   | 690/1024 [00:51<00:25, 13.18it/s, est. speed input: 13800.79 toks/s, output: 13.48 toks/s]
Processed prompts:  68%|   | 698/1024 [00:51<00:24, 13.19it/s, est. speed input: 13797.56 toks/s, output: 13.47 toks/s]
Processed prompts:  69%|   | 706/1024 [00:52<00:24, 13.17it/s, est. speed input: 13793.50 toks/s, output: 13.47 toks/s]
Processed prompts:  70%|   | 714/1024 [00:53<00:23, 13.12it/s, est. speed input: 13787.73 toks/s, output: 13.46 toks/s]
Processed prompts:  71%|   | 722/1024 [00:53<00:22, 13.17it/s, est. speed input: 13785.74 toks/s, output: 13.46 toks/s]
Processed prompts:  71%|  | 730/1024 [00:54<00:22, 13.11it/s, est. speed input: 13780.02 toks/s, output: 13.46 toks/s]
Processed prompts:  72%|  | 738/1024 [00:54<00:21, 13.13it/s, est. speed input: 13777.08 toks/s, output: 13.45 toks/s]
Processed prompts:  73%|  | 746/1024 [00:55<00:21, 13.09it/s, est. speed input: 13771.57 toks/s, output: 13.45 toks/s]
Processed prompts:  74%|  | 754/1024 [00:56<00:20, 13.10it/s, est. speed input: 13768.19 toks/s, output: 13.45 toks/s]
Processed prompts:  74%|  | 762/1024 [00:56<00:20, 13.05it/s, est. speed input: 13762.57 toks/s, output: 13.44 toks/s]
Processed prompts:  75%|  | 770/1024 [00:57<00:19, 13.07it/s, est. speed input: 13758.91 toks/s, output: 13.44 toks/s]
Processed prompts:  76%|  | 778/1024 [00:57<00:18, 13.09it/s, est. speed input: 13755.84 toks/s, output: 13.43 toks/s]
Processed prompts:  77%|  | 786/1024 [00:58<00:18, 13.06it/s, est. speed input: 13750.84 toks/s, output: 13.43 toks/s]
Processed prompts:  78%|  | 794/1024 [00:59<00:17, 13.11it/s, est. speed input: 13748.83 toks/s, output: 13.43 toks/s]
Processed prompts:  78%|  | 802/1024 [00:59<00:16, 13.12it/s, est. speed input: 13745.93 toks/s, output: 13.42 toks/s]
Processed prompts:  79%|  | 810/1024 [01:00<00:16, 13.14it/s, est. speed input: 13743.48 toks/s, output: 13.42 toks/s]
Processed prompts:  80%|  | 818/1024 [01:00<00:15, 13.11it/s, est. speed input: 13739.51 toks/s, output: 13.42 toks/s]
Processed prompts:  81%|  | 826/1024 [01:01<00:15, 13.13it/s, est. speed input: 13737.03 toks/s, output: 13.42 toks/s]
Processed prompts:  81%| | 834/1024 [01:02<00:14, 13.13it/s, est. speed input: 13734.22 toks/s, output: 13.41 toks/s]
Processed prompts:  82%| | 842/1024 [01:02<00:13, 13.13it/s, est. speed input: 13731.54 toks/s, output: 13.41 toks/s]
Processed prompts:  83%| | 850/1024 [01:03<00:13, 12.96it/s, est. speed input: 13722.89 toks/s, output: 13.40 toks/s]
Processed prompts:  84%| | 858/1024 [01:04<00:12, 13.00it/s, est. speed input: 13719.78 toks/s, output: 13.40 toks/s]
Processed prompts:  85%| | 866/1024 [01:04<00:12, 13.06it/s, est. speed input: 13717.97 toks/s, output: 13.40 toks/s]
Processed prompts:  85%| | 874/1024 [01:05<00:11, 13.09it/s, est. speed input: 13715.84 toks/s, output: 13.39 toks/s]
Processed prompts:  86%| | 882/1024 [01:05<00:10, 13.05it/s, est. speed input: 13711.55 toks/s, output: 13.39 toks/s]
Processed prompts:  87%| | 890/1024 [01:06<00:10, 13.15it/s, est. speed input: 13711.64 toks/s, output: 13.39 toks/s]
Processed prompts:  88%| | 898/1024 [01:07<00:09, 13.10it/s, est. speed input: 13707.64 toks/s, output: 13.39 toks/s]
Processed prompts:  88%| | 906/1024 [01:07<00:08, 13.13it/s, est. speed input: 13705.89 toks/s, output: 13.38 toks/s]
Processed prompts:  89%| | 914/1024 [01:08<00:08, 13.11it/s, est. speed input: 13703.04 toks/s, output: 13.38 toks/s]
Processed prompts:  90%| | 922/1024 [01:08<00:07, 13.10it/s, est. speed input: 13700.18 toks/s, output: 13.38 toks/s]
Processed prompts:  91%| | 930/1024 [01:09<00:07, 13.08it/s, est. speed input: 13697.04 toks/s, output: 13.38 toks/s]
Processed prompts:  92%|| 938/1024 [01:10<00:06, 13.48it/s, est. speed input: 13706.26 toks/s, output: 13.39 toks/s]
Processed prompts:  92%|| 946/1024 [01:10<00:05, 13.42it/s, est. speed input: 13705.37 toks/s, output: 13.38 toks/s]
Processed prompts:  93%|| 954/1024 [01:11<00:05, 13.34it/s, est. speed input: 13703.37 toks/s, output: 13.38 toks/s]
Processed prompts:  94%|| 962/1024 [01:11<00:04, 13.26it/s, est. speed input: 13700.67 toks/s, output: 13.38 toks/s]
Processed prompts:  95%|| 970/1024 [01:12<00:04, 13.15it/s, est. speed input: 13696.53 toks/s, output: 13.38 toks/s]
Processed prompts:  96%|| 978/1024 [01:13<00:03, 13.10it/s, est. speed input: 13693.02 toks/s, output: 13.37 toks/s]
Processed prompts:  96%|| 986/1024 [01:13<00:02, 13.55it/s, est. speed input: 13703.36 toks/s, output: 13.38 toks/s]
Processed prompts:  97%|| 994/1024 [01:14<00:02, 13.39it/s, est. speed input: 13700.38 toks/s, output: 13.38 toks/s]
Processed prompts:  98%|| 1002/1024 [01:14<00:01, 13.34it/s, est. speed input: 13699.17 toks/s, output: 13.38 toks/s]
Processed prompts:  99%|| 1010/1024 [01:15<00:01, 13.24it/s, est. speed input: 13696.21 toks/s, output: 13.38 toks/s]
Processed prompts:  99%|| 1018/1024 [01:16<00:00, 13.64it/s, est. speed input: 13705.54 toks/s, output: 13.38 toks/s]
Processed prompts: 100%|| 1024/1024 [01:16<00:00, 13.64it/s, est. speed input: 13786.28 toks/s, output: 13.46 toks/s]
Processed prompts: 100%|| 1024/1024 [01:16<00:00, 13.46it/s, est. speed input: 13786.28 toks/s, output: 13.46 toks/s]
[rank0]:[W126 10:11:45.273285983 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 10:11:47
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:11:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:11:56 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1167701) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1167701) WARNING 01-26 10:12:35 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 13.05 requests/s, 13372.87 total tokens/s, 13.05 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 10:11:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:11:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:11:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:11:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:11:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:11:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:11:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:11:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:11:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:11:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:11:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:11:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:11:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:11:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:11:59] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:11:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:11:59] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:11:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:11:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:11:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:11:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:11:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:11:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:11:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:11:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:11:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:11:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:11:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1167701) [2026-01-26 10:12:01] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1167701) [2026-01-26 10:12:01] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1167701) [2026-01-26 10:12:01] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1167701) [2026-01-26 10:12:01] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1167701) [2026-01-26 10:12:01] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1167701) [2026-01-26 10:12:01] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1167701) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1167701) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.65s/it]
(EngineCore_DP0 pid=1167701) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.65s/it]
(EngineCore_DP0 pid=1167701) 
(EngineCore_DP0 pid=1167701) [2026-01-26 10:12:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1167701) [2026-01-26 10:12:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=1167701) [2026-01-26 10:12:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1167701) [2026-01-26 10:12:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9437184 bytes
(EngineCore_DP0 pid=1167701) [2026-01-26 10:12:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1167701) [2026-01-26 10:12:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50331648 bytes
(EngineCore_DP0 pid=1167701) [2026-01-26 10:12:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1167701) [2026-01-26 10:12:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25264128 bytes
(EngineCore_DP0 pid=1167701) 2026-01-26 10:12:33,281 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1167701) 2026-01-26 10:12:33,412 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 59/2048 [00:00<00:03, 586.30it/s]
Adding requests:   6%|         | 118/2048 [00:00<00:03, 574.93it/s]
Adding requests:   9%|         | 176/2048 [00:00<00:03, 529.85it/s]
Adding requests:  11%|         | 230/2048 [00:00<00:03, 526.76it/s]
Adding requests:  14%|        | 283/2048 [00:00<00:03, 517.94it/s]
Adding requests:  16%|        | 335/2048 [00:00<00:03, 517.64it/s]
Adding requests:  19%|        | 387/2048 [00:00<00:03, 513.91it/s]
Adding requests:  21%|       | 439/2048 [00:00<00:03, 513.08it/s]
Adding requests:  24%|       | 491/2048 [00:00<00:03, 506.53it/s]
Adding requests:  26%|       | 542/2048 [00:01<00:03, 497.03it/s]
Adding requests:  29%|       | 595/2048 [00:01<00:02, 503.24it/s]
Adding requests:  32%|      | 649/2048 [00:01<00:02, 512.18it/s]
Adding requests:  34%|      | 702/2048 [00:01<00:02, 515.75it/s]
Adding requests:  37%|      | 754/2048 [00:01<00:02, 506.96it/s]
Adding requests:  39%|      | 805/2048 [00:01<00:02, 490.66it/s]
Adding requests:  42%|     | 855/2048 [00:02<00:05, 213.39it/s]
Adding requests:  44%|     | 901/2048 [00:02<00:04, 250.62it/s]
Adding requests:  47%|     | 953/2048 [00:02<00:03, 298.28it/s]
Adding requests:  49%|     | 1006/2048 [00:02<00:03, 343.64it/s]
Adding requests:  52%|    | 1058/2048 [00:02<00:02, 381.85it/s]
Adding requests:  54%|    | 1109/2048 [00:02<00:02, 412.42it/s]
Adding requests:  57%|    | 1161/2048 [00:02<00:02, 438.71it/s]
Adding requests:  59%|    | 1214/2048 [00:02<00:01, 461.68it/s]
Adding requests:  62%|   | 1265/2048 [00:02<00:01, 464.91it/s]
Adding requests:  64%|   | 1316/2048 [00:03<00:01, 477.23it/s]
Adding requests:  67%|   | 1367/2048 [00:03<00:01, 484.78it/s]
Adding requests:  69%|   | 1420/2048 [00:03<00:01, 496.00it/s]
Adding requests:  72%|  | 1471/2048 [00:03<00:01, 499.74it/s]
Adding requests:  74%|  | 1525/2048 [00:03<00:01, 510.98it/s]
Adding requests:  77%|  | 1578/2048 [00:03<00:00, 515.76it/s]
Adding requests:  80%|  | 1632/2048 [00:03<00:00, 521.64it/s]
Adding requests:  82%| | 1685/2048 [00:03<00:00, 513.52it/s]
Adding requests:  85%| | 1737/2048 [00:03<00:00, 514.60it/s]
Adding requests:  87%| | 1789/2048 [00:03<00:00, 506.28it/s]
Adding requests:  90%| | 1841/2048 [00:04<00:00, 507.86it/s]
Adding requests:  92%|| 1894/2048 [00:04<00:00, 510.75it/s]
Adding requests:  95%|| 1946/2048 [00:04<00:00, 509.43it/s]
Adding requests:  98%|| 1998/2048 [00:04<00:00, 512.36it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 457.35it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 50/2048 [00:00<00:23, 85.27it/s, est. speed input: 87331.16 toks/s, output: 85.28 toks/s]
Processed prompts:   3%|         | 66/2048 [00:01<01:03, 31.18it/s, est. speed input: 37308.84 toks/s, output: 36.43 toks/s]
Processed prompts:   4%|         | 82/2048 [00:03<01:29, 21.96it/s, est. speed input: 27795.97 toks/s, output: 27.14 toks/s]
Processed prompts:   5%|         | 98/2048 [00:04<01:47, 18.19it/s, est. speed input: 23658.79 toks/s, output: 23.10 toks/s]
Processed prompts:   6%|         | 114/2048 [00:05<01:59, 16.24it/s, est. speed input: 21345.87 toks/s, output: 20.85 toks/s]
Processed prompts:   6%|         | 130/2048 [00:06<02:06, 15.16it/s, est. speed input: 19911.09 toks/s, output: 19.44 toks/s]
Processed prompts:   7%|         | 146/2048 [00:07<02:11, 14.45it/s, est. speed input: 18895.36 toks/s, output: 18.45 toks/s]
Processed prompts:   8%|         | 162/2048 [00:09<02:14, 14.01it/s, est. speed input: 18161.15 toks/s, output: 17.74 toks/s]
Processed prompts:   9%|         | 178/2048 [00:10<02:16, 13.72it/s, est. speed input: 17599.12 toks/s, output: 17.19 toks/s]
Processed prompts:   9%|         | 194/2048 [00:11<02:17, 13.51it/s, est. speed input: 17151.48 toks/s, output: 16.75 toks/s]
Processed prompts:  10%|         | 210/2048 [00:12<02:17, 13.34it/s, est. speed input: 16777.02 toks/s, output: 16.38 toks/s]
Processed prompts:  11%|         | 226/2048 [00:14<02:17, 13.23it/s, est. speed input: 16470.22 toks/s, output: 16.08 toks/s]
Processed prompts:  12%|        | 242/2048 [00:15<02:17, 13.17it/s, est. speed input: 16219.36 toks/s, output: 15.84 toks/s]
Processed prompts:  13%|        | 258/2048 [00:16<02:16, 13.13it/s, est. speed input: 16007.50 toks/s, output: 15.63 toks/s]
Processed prompts:  13%|        | 274/2048 [00:17<02:15, 13.10it/s, est. speed input: 15823.35 toks/s, output: 15.45 toks/s]
Processed prompts:  14%|        | 290/2048 [00:18<02:14, 13.07it/s, est. speed input: 15658.99 toks/s, output: 15.29 toks/s]
Processed prompts:  15%|        | 306/2048 [00:20<02:13, 13.05it/s, est. speed input: 15517.69 toks/s, output: 15.15 toks/s]
Processed prompts:  16%|        | 322/2048 [00:21<02:12, 13.05it/s, est. speed input: 15394.56 toks/s, output: 15.03 toks/s]
Processed prompts:  17%|        | 338/2048 [00:22<02:09, 13.18it/s, est. speed input: 15310.52 toks/s, output: 14.95 toks/s]
Processed prompts:  17%|        | 354/2048 [00:23<02:08, 13.15it/s, est. speed input: 15212.16 toks/s, output: 14.86 toks/s]
Processed prompts:  18%|        | 370/2048 [00:25<02:07, 13.11it/s, est. speed input: 15120.68 toks/s, output: 14.77 toks/s]
Processed prompts:  19%|        | 386/2048 [00:26<02:07, 13.08it/s, est. speed input: 15035.55 toks/s, output: 14.68 toks/s]
Processed prompts:  20%|        | 402/2048 [00:27<02:06, 13.05it/s, est. speed input: 14957.86 toks/s, output: 14.61 toks/s]
Processed prompts:  20%|        | 418/2048 [00:28<02:05, 13.01it/s, est. speed input: 14883.18 toks/s, output: 14.53 toks/s]
Processed prompts:  21%|        | 434/2048 [00:29<02:04, 13.01it/s, est. speed input: 14819.38 toks/s, output: 14.47 toks/s]
Processed prompts:  22%|       | 450/2048 [00:31<02:01, 13.18it/s, est. speed input: 14785.42 toks/s, output: 14.44 toks/s]
Processed prompts:  23%|       | 466/2048 [00:32<01:59, 13.19it/s, est. speed input: 14737.92 toks/s, output: 14.39 toks/s]
Processed prompts:  24%|       | 482/2048 [00:33<01:59, 13.12it/s, est. speed input: 14685.06 toks/s, output: 14.34 toks/s]
Processed prompts:  24%|       | 498/2048 [00:34<01:58, 13.10it/s, est. speed input: 14638.25 toks/s, output: 14.30 toks/s]
Processed prompts:  25%|       | 514/2048 [00:36<01:57, 13.09it/s, est. speed input: 14595.84 toks/s, output: 14.25 toks/s]
Processed prompts:  26%|       | 530/2048 [00:37<01:56, 13.05it/s, est. speed input: 14551.69 toks/s, output: 14.21 toks/s]
Processed prompts:  27%|       | 546/2048 [00:38<01:55, 13.03it/s, est. speed input: 14511.76 toks/s, output: 14.17 toks/s]
Processed prompts:  27%|       | 562/2048 [00:39<01:53, 13.04it/s, est. speed input: 14476.21 toks/s, output: 14.14 toks/s]
Processed prompts:  28%|       | 578/2048 [00:40<01:52, 13.03it/s, est. speed input: 14441.77 toks/s, output: 14.10 toks/s]
Processed prompts:  29%|       | 594/2048 [00:42<01:51, 13.02it/s, est. speed input: 14409.03 toks/s, output: 14.07 toks/s]
Processed prompts:  30%|       | 610/2048 [00:43<01:50, 13.01it/s, est. speed input: 14377.36 toks/s, output: 14.04 toks/s]
Processed prompts:  31%|       | 626/2048 [00:44<01:49, 13.00it/s, est. speed input: 14346.97 toks/s, output: 14.01 toks/s]
Processed prompts:  31%|      | 642/2048 [00:45<01:47, 13.04it/s, est. speed input: 14323.31 toks/s, output: 13.99 toks/s]
Processed prompts:  32%|      | 658/2048 [00:47<01:46, 13.05it/s, est. speed input: 14298.70 toks/s, output: 13.96 toks/s]
Processed prompts:  33%|      | 674/2048 [00:48<01:45, 13.05it/s, est. speed input: 14275.41 toks/s, output: 13.94 toks/s]
Processed prompts:  34%|      | 690/2048 [00:49<01:44, 13.04it/s, est. speed input: 14251.60 toks/s, output: 13.92 toks/s]
Processed prompts:  34%|      | 706/2048 [00:50<01:42, 13.04it/s, est. speed input: 14230.27 toks/s, output: 13.90 toks/s]
Processed prompts:  35%|      | 722/2048 [00:52<01:41, 13.04it/s, est. speed input: 14209.67 toks/s, output: 13.88 toks/s]
Processed prompts:  36%|      | 738/2048 [00:53<01:40, 13.03it/s, est. speed input: 14188.80 toks/s, output: 13.86 toks/s]
Processed prompts:  37%|      | 754/2048 [00:54<01:39, 13.01it/s, est. speed input: 14168.50 toks/s, output: 13.84 toks/s]
Processed prompts:  38%|      | 770/2048 [00:55<01:38, 12.99it/s, est. speed input: 14147.84 toks/s, output: 13.82 toks/s]
Processed prompts:  38%|      | 786/2048 [00:56<01:36, 13.02it/s, est. speed input: 14132.08 toks/s, output: 13.80 toks/s]
Processed prompts:  39%|      | 802/2048 [00:58<01:35, 13.03it/s, est. speed input: 14115.79 toks/s, output: 13.78 toks/s]
Processed prompts:  40%|      | 818/2048 [00:59<01:34, 13.01it/s, est. speed input: 14098.09 toks/s, output: 13.77 toks/s]
Processed prompts:  41%|      | 834/2048 [01:00<01:33, 12.99it/s, est. speed input: 14080.92 toks/s, output: 13.75 toks/s]
Processed prompts:  42%|     | 850/2048 [01:01<01:32, 13.01it/s, est. speed input: 14066.94 toks/s, output: 13.74 toks/s]
Processed prompts:  42%|     | 866/2048 [01:03<01:30, 13.03it/s, est. speed input: 14054.11 toks/s, output: 13.72 toks/s]
Processed prompts:  43%|     | 882/2048 [01:04<01:29, 13.06it/s, est. speed input: 14042.21 toks/s, output: 13.71 toks/s]
Processed prompts:  44%|     | 898/2048 [01:05<01:28, 13.06it/s, est. speed input: 14029.55 toks/s, output: 13.70 toks/s]
Processed prompts:  45%|     | 914/2048 [01:06<01:27, 13.01it/s, est. speed input: 14014.66 toks/s, output: 13.69 toks/s]
Processed prompts:  45%|     | 930/2048 [01:07<01:24, 13.20it/s, est. speed input: 14014.25 toks/s, output: 13.69 toks/s]
Processed prompts:  46%|     | 946/2048 [01:09<01:23, 13.15it/s, est. speed input: 14002.38 toks/s, output: 13.67 toks/s]
Processed prompts:  47%|     | 962/2048 [01:10<01:22, 13.11it/s, est. speed input: 13990.56 toks/s, output: 13.66 toks/s]
Processed prompts:  48%|     | 978/2048 [01:11<01:20, 13.26it/s, est. speed input: 13990.08 toks/s, output: 13.66 toks/s]
Processed prompts:  49%|     | 994/2048 [01:12<01:19, 13.20it/s, est. speed input: 13979.38 toks/s, output: 13.65 toks/s]
Processed prompts:  49%|     | 1010/2048 [01:14<01:18, 13.14it/s, est. speed input: 13968.66 toks/s, output: 13.64 toks/s]
Processed prompts:  50%|     | 1026/2048 [01:15<01:18, 13.09it/s, est. speed input: 13957.21 toks/s, output: 13.63 toks/s]
Processed prompts:  51%|     | 1042/2048 [01:16<01:16, 13.07it/s, est. speed input: 13947.30 toks/s, output: 13.62 toks/s]
Processed prompts:  52%|    | 1058/2048 [01:17<01:15, 13.04it/s, est. speed input: 13936.91 toks/s, output: 13.61 toks/s]
Processed prompts:  52%|    | 1074/2048 [01:18<01:14, 13.03it/s, est. speed input: 13927.22 toks/s, output: 13.60 toks/s]
Processed prompts:  53%|    | 1090/2048 [01:20<01:13, 13.01it/s, est. speed input: 13917.25 toks/s, output: 13.59 toks/s]
Processed prompts:  54%|    | 1106/2048 [01:21<01:12, 13.00it/s, est. speed input: 13907.51 toks/s, output: 13.58 toks/s]
Processed prompts:  55%|    | 1122/2048 [01:22<01:11, 13.02it/s, est. speed input: 13899.67 toks/s, output: 13.57 toks/s]
Processed prompts:  56%|    | 1138/2048 [01:23<01:09, 13.03it/s, est. speed input: 13891.81 toks/s, output: 13.57 toks/s]
Processed prompts:  56%|    | 1154/2048 [01:25<01:07, 13.20it/s, est. speed input: 13892.61 toks/s, output: 13.57 toks/s]
Processed prompts:  57%|    | 1170/2048 [01:26<01:06, 13.13it/s, est. speed input: 13884.02 toks/s, output: 13.56 toks/s]
Processed prompts:  58%|    | 1186/2048 [01:27<01:05, 13.09it/s, est. speed input: 13875.63 toks/s, output: 13.55 toks/s]
Processed prompts:  59%|    | 1202/2048 [01:28<01:04, 13.05it/s, est. speed input: 13867.57 toks/s, output: 13.54 toks/s]
Processed prompts:  59%|    | 1218/2048 [01:29<01:03, 13.03it/s, est. speed input: 13859.54 toks/s, output: 13.53 toks/s]
Processed prompts:  60%|    | 1234/2048 [01:31<01:02, 12.97it/s, est. speed input: 13849.70 toks/s, output: 13.53 toks/s]
Processed prompts:  61%|    | 1250/2048 [01:32<01:01, 12.97it/s, est. speed input: 13842.04 toks/s, output: 13.52 toks/s]
Processed prompts:  62%|   | 1266/2048 [01:33<00:59, 13.17it/s, est. speed input: 13843.97 toks/s, output: 13.52 toks/s]
Processed prompts:  63%|   | 1282/2048 [01:34<00:58, 13.12it/s, est. speed input: 13837.04 toks/s, output: 13.51 toks/s]
Processed prompts:  63%|   | 1298/2048 [01:36<00:57, 13.06it/s, est. speed input: 13829.45 toks/s, output: 13.51 toks/s]
Processed prompts:  64%|   | 1314/2048 [01:37<00:56, 13.04it/s, est. speed input: 13822.55 toks/s, output: 13.50 toks/s]
Processed prompts:  65%|   | 1330/2048 [01:38<00:55, 13.02it/s, est. speed input: 13815.73 toks/s, output: 13.49 toks/s]
Processed prompts:  66%|   | 1346/2048 [01:39<00:54, 12.99it/s, est. speed input: 13808.72 toks/s, output: 13.49 toks/s]
Processed prompts:  67%|   | 1362/2048 [01:41<00:52, 12.99it/s, est. speed input: 13802.30 toks/s, output: 13.48 toks/s]
Processed prompts:  67%|   | 1378/2048 [01:42<00:51, 12.98it/s, est. speed input: 13795.94 toks/s, output: 13.47 toks/s]
Processed prompts:  68%|   | 1394/2048 [01:43<00:50, 13.03it/s, est. speed input: 13791.90 toks/s, output: 13.47 toks/s]
Processed prompts:  69%|   | 1410/2048 [01:44<00:49, 13.00it/s, est. speed input: 13785.54 toks/s, output: 13.46 toks/s]
Processed prompts:  70%|   | 1426/2048 [01:45<00:47, 13.00it/s, est. speed input: 13780.07 toks/s, output: 13.46 toks/s]
Processed prompts:  70%|   | 1442/2048 [01:47<00:46, 13.00it/s, est. speed input: 13774.59 toks/s, output: 13.45 toks/s]
Processed prompts:  71%|   | 1458/2048 [01:48<00:45, 12.97it/s, est. speed input: 13768.25 toks/s, output: 13.45 toks/s]
Processed prompts:  72%|  | 1474/2048 [01:49<00:44, 13.00it/s, est. speed input: 13764.00 toks/s, output: 13.44 toks/s]
Processed prompts:  73%|  | 1490/2048 [01:50<00:42, 13.00it/s, est. speed input: 13759.10 toks/s, output: 13.44 toks/s]
Processed prompts:  74%|  | 1506/2048 [01:52<00:41, 13.01it/s, est. speed input: 13754.31 toks/s, output: 13.43 toks/s]
Processed prompts:  74%|  | 1522/2048 [01:53<00:40, 13.01it/s, est. speed input: 13749.55 toks/s, output: 13.43 toks/s]
Processed prompts:  75%|  | 1538/2048 [01:54<00:39, 13.00it/s, est. speed input: 13744.64 toks/s, output: 13.42 toks/s]
Processed prompts:  76%|  | 1554/2048 [01:55<00:38, 12.98it/s, est. speed input: 13739.32 toks/s, output: 13.42 toks/s]
Processed prompts:  77%|  | 1570/2048 [01:57<00:36, 12.97it/s, est. speed input: 13734.32 toks/s, output: 13.41 toks/s]
Processed prompts:  77%|  | 1586/2048 [01:58<00:35, 13.16it/s, est. speed input: 13736.42 toks/s, output: 13.41 toks/s]
Processed prompts:  78%|  | 1602/2048 [01:59<00:33, 13.14it/s, est. speed input: 13733.06 toks/s, output: 13.41 toks/s]
Processed prompts:  79%|  | 1618/2048 [02:00<00:32, 13.13it/s, est. speed input: 13729.78 toks/s, output: 13.41 toks/s]
Processed prompts:  80%|  | 1634/2048 [02:01<00:31, 13.09it/s, est. speed input: 13725.59 toks/s, output: 13.40 toks/s]
Processed prompts:  81%|  | 1650/2048 [02:03<00:30, 13.06it/s, est. speed input: 13721.31 toks/s, output: 13.40 toks/s]
Processed prompts:  81%| | 1666/2048 [02:04<00:29, 13.01it/s, est. speed input: 13716.20 toks/s, output: 13.39 toks/s]
Processed prompts:  82%| | 1682/2048 [02:05<00:28, 12.99it/s, est. speed input: 13711.53 toks/s, output: 13.39 toks/s]
Processed prompts:  83%| | 1698/2048 [02:06<00:26, 13.00it/s, est. speed input: 13708.00 toks/s, output: 13.39 toks/s]
Processed prompts:  84%| | 1714/2048 [02:08<00:25, 12.97it/s, est. speed input: 13703.16 toks/s, output: 13.38 toks/s]
Processed prompts:  84%| | 1730/2048 [02:09<00:24, 12.97it/s, est. speed input: 13699.26 toks/s, output: 13.38 toks/s]
Processed prompts:  85%| | 1746/2048 [02:10<00:23, 12.99it/s, est. speed input: 13695.88 toks/s, output: 13.37 toks/s]
Processed prompts:  86%| | 1762/2048 [02:11<00:22, 12.96it/s, est. speed input: 13691.28 toks/s, output: 13.37 toks/s]
Processed prompts:  87%| | 1778/2048 [02:13<00:20, 12.98it/s, est. speed input: 13688.07 toks/s, output: 13.37 toks/s]
Processed prompts:  88%| | 1794/2048 [02:14<00:19, 13.02it/s, est. speed input: 13685.61 toks/s, output: 13.36 toks/s]
Processed prompts:  88%| | 1810/2048 [02:15<00:18, 13.02it/s, est. speed input: 13682.42 toks/s, output: 13.36 toks/s]
Processed prompts:  89%| | 1826/2048 [02:16<00:17, 13.01it/s, est. speed input: 13679.06 toks/s, output: 13.36 toks/s]
Processed prompts:  90%| | 1842/2048 [02:17<00:15, 13.01it/s, est. speed input: 13675.90 toks/s, output: 13.36 toks/s]
Processed prompts:  91%| | 1858/2048 [02:19<00:14, 13.00it/s, est. speed input: 13672.38 toks/s, output: 13.35 toks/s]
Processed prompts:  92%|| 1874/2048 [02:20<00:13, 13.18it/s, est. speed input: 13674.61 toks/s, output: 13.35 toks/s]
Processed prompts:  92%|| 1890/2048 [02:21<00:12, 13.14it/s, est. speed input: 13672.10 toks/s, output: 13.35 toks/s]
Processed prompts:  93%|| 1906/2048 [02:22<00:10, 13.10it/s, est. speed input: 13668.91 toks/s, output: 13.35 toks/s]
Processed prompts:  94%|| 1922/2048 [02:24<00:09, 13.07it/s, est. speed input: 13666.03 toks/s, output: 13.35 toks/s]
Processed prompts:  95%|| 1938/2048 [02:25<00:08, 13.04it/s, est. speed input: 13662.81 toks/s, output: 13.34 toks/s]
Processed prompts:  95%|| 1954/2048 [02:26<00:07, 13.22it/s, est. speed input: 13665.37 toks/s, output: 13.35 toks/s]
Processed prompts:  96%|| 1970/2048 [02:27<00:05, 13.12it/s, est. speed input: 13661.46 toks/s, output: 13.34 toks/s]
Processed prompts:  97%|| 1986/2048 [02:28<00:04, 13.10it/s, est. speed input: 13659.12 toks/s, output: 13.34 toks/s]
Processed prompts:  98%|| 2002/2048 [02:30<00:03, 13.11it/s, est. speed input: 13657.36 toks/s, output: 13.34 toks/s]
Processed prompts:  99%|| 2018/2048 [02:31<00:02, 13.10it/s, est. speed input: 13655.10 toks/s, output: 13.34 toks/s]
Processed prompts:  99%|| 2034/2048 [02:32<00:01, 13.29it/s, est. speed input: 13658.35 toks/s, output: 13.34 toks/s]
Processed prompts: 100%|| 2048/2048 [02:32<00:00, 13.29it/s, est. speed input: 13752.34 toks/s, output: 13.43 toks/s]
Processed prompts: 100%|| 2048/2048 [02:32<00:00, 13.43it/s, est. speed input: 13752.34 toks/s, output: 13.43 toks/s]
[rank0]:[W126 10:15:12.579130159 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 10:15:14
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:15:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:15:29 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1170832) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1170832) WARNING 01-26 10:16:10 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 12.86 requests/s, 13180.20 total tokens/s, 12.86 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 10:15:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:15:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:15:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:15:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:15:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:15:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:15:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:15:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:15:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:15:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:15:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:15:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:15:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:15:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:15:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:15:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:15:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:15:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:15:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:15:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:15:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:15:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:15:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:15:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:15:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:15:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:15:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:15:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1170832) [2026-01-26 10:15:33] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1170832) [2026-01-26 10:15:33] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1170832) [2026-01-26 10:15:33] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1170832) [2026-01-26 10:15:33] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1170832) [2026-01-26 10:15:33] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1170832) [2026-01-26 10:15:33] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1170832) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1170832) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.78s/it]
(EngineCore_DP0 pid=1170832) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.78s/it]
(EngineCore_DP0 pid=1170832) 
(EngineCore_DP0 pid=1170832) [2026-01-26 10:15:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1170832) [2026-01-26 10:15:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=1170832) [2026-01-26 10:15:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1170832) [2026-01-26 10:15:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9437184 bytes
(EngineCore_DP0 pid=1170832) [2026-01-26 10:15:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1170832) [2026-01-26 10:15:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50331648 bytes
(EngineCore_DP0 pid=1170832) [2026-01-26 10:15:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1170832) [2026-01-26 10:15:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25264128 bytes
(EngineCore_DP0 pid=1170832) 2026-01-26 10:16:07,468 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1170832) 2026-01-26 10:16:07,623 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|         | 60/4096 [00:00<00:06, 590.65it/s]
Adding requests:   3%|         | 120/4096 [00:00<00:07, 531.16it/s]
Adding requests:   4%|         | 175/4096 [00:00<00:07, 533.58it/s]
Adding requests:   6%|         | 229/4096 [00:00<00:07, 487.57it/s]
Adding requests:   7%|         | 279/4096 [00:00<00:08, 458.90it/s]
Adding requests:   8%|         | 329/4096 [00:00<00:08, 470.20it/s]
Adding requests:   9%|         | 385/4096 [00:00<00:07, 494.99it/s]
Adding requests:  11%|         | 436/4096 [00:00<00:07, 498.04it/s]
Adding requests:  12%|        | 488/4096 [00:00<00:07, 503.41it/s]
Adding requests:  13%|        | 539/4096 [00:01<00:07, 497.24it/s]
Adding requests:  15%|        | 605/4096 [00:01<00:06, 543.30it/s]
Adding requests:  16%|        | 665/4096 [00:01<00:06, 559.17it/s]
Adding requests:  18%|        | 738/4096 [00:01<00:05, 606.95it/s]
Adding requests:  20%|        | 799/4096 [00:01<00:05, 580.66it/s]
Adding requests:  21%|        | 858/4096 [00:01<00:05, 554.59it/s]
Adding requests:  22%|       | 920/4096 [00:01<00:05, 572.35it/s]
Adding requests:  24%|       | 980/4096 [00:01<00:05, 569.27it/s]
Adding requests:  25%|       | 1038/4096 [00:01<00:05, 548.97it/s]
Adding requests:  27%|       | 1094/4096 [00:02<00:05, 525.51it/s]
Adding requests:  28%|       | 1147/4096 [00:02<00:05, 515.41it/s]
Adding requests:  29%|       | 1199/4096 [00:02<00:05, 511.15it/s]
Adding requests:  31%|       | 1252/4096 [00:02<00:05, 514.92it/s]
Adding requests:  32%|      | 1304/4096 [00:02<00:05, 487.24it/s]
Adding requests:  33%|      | 1356/4096 [00:02<00:05, 495.42it/s]
Adding requests:  34%|      | 1413/4096 [00:02<00:05, 515.62it/s]
Adding requests:  36%|      | 1468/4096 [00:02<00:05, 524.74it/s]
Adding requests:  37%|      | 1522/4096 [00:02<00:04, 528.57it/s]
Adding requests:  39%|      | 1577/4096 [00:02<00:04, 534.84it/s]
Adding requests:  40%|      | 1631/4096 [00:03<00:04, 531.18it/s]
Adding requests:  41%|      | 1685/4096 [00:03<00:04, 526.99it/s]
Adding requests:  42%|     | 1738/4096 [00:03<00:04, 524.28it/s]
Adding requests:  44%|     | 1791/4096 [00:03<00:04, 524.38it/s]
Adding requests:  45%|     | 1844/4096 [00:03<00:04, 515.02it/s]
Adding requests:  46%|     | 1897/4096 [00:03<00:04, 517.20it/s]
Adding requests:  48%|     | 1950/4096 [00:03<00:04, 517.76it/s]
Adding requests:  49%|     | 2002/4096 [00:03<00:04, 518.21it/s]
Adding requests:  50%|     | 2059/4096 [00:03<00:03, 532.00it/s]
Adding requests:  52%|    | 2113/4096 [00:04<00:03, 526.13it/s]
Adding requests:  53%|    | 2166/4096 [00:04<00:03, 521.47it/s]
Adding requests:  54%|    | 2219/4096 [00:04<00:03, 522.11it/s]
Adding requests:  56%|    | 2274/4096 [00:04<00:03, 527.38it/s]
Adding requests:  57%|    | 2327/4096 [00:04<00:03, 526.93it/s]
Adding requests:  58%|    | 2381/4096 [00:04<00:03, 528.47it/s]
Adding requests:  59%|    | 2434/4096 [00:04<00:03, 528.05it/s]
Adding requests:  61%|    | 2487/4096 [00:04<00:03, 527.24it/s]
Adding requests:  62%|   | 2541/4096 [00:04<00:02, 529.12it/s]
Adding requests:  63%|   | 2594/4096 [00:04<00:02, 513.97it/s]
Adding requests:  65%|   | 2646/4096 [00:05<00:02, 513.99it/s]
Adding requests:  66%|   | 2698/4096 [00:05<00:02, 515.58it/s]
Adding requests:  67%|   | 2752/4096 [00:05<00:02, 520.45it/s]
Adding requests:  69%|   | 2806/4096 [00:05<00:02, 523.16it/s]
Adding requests:  70%|   | 2860/4096 [00:05<00:02, 525.34it/s]
Adding requests:  71%|   | 2915/4096 [00:05<00:02, 531.18it/s]
Adding requests:  72%|  | 2969/4096 [00:05<00:02, 531.90it/s]
Adding requests:  74%|  | 3023/4096 [00:05<00:02, 525.13it/s]
Adding requests:  75%|  | 3076/4096 [00:05<00:01, 521.98it/s]
Adding requests:  76%|  | 3129/4096 [00:05<00:01, 522.38it/s]
Adding requests:  78%|  | 3182/4096 [00:06<00:01, 521.49it/s]
Adding requests:  79%|  | 3235/4096 [00:06<00:01, 522.22it/s]
Adding requests:  80%|  | 3290/4096 [00:06<00:01, 529.06it/s]
Adding requests:  82%| | 3345/4096 [00:06<00:01, 533.89it/s]
Adding requests:  83%| | 3399/4096 [00:06<00:01, 534.81it/s]
Adding requests:  84%| | 3453/4096 [00:06<00:01, 532.92it/s]
Adding requests:  86%| | 3507/4096 [00:06<00:01, 527.62it/s]
Adding requests:  87%| | 3561/4096 [00:06<00:01, 529.17it/s]
Adding requests:  88%| | 3614/4096 [00:06<00:00, 526.69it/s]
Adding requests:  90%| | 3667/4096 [00:06<00:00, 525.95it/s]
Adding requests:  91%| | 3721/4096 [00:07<00:00, 528.80it/s]
Adding requests:  92%|| 3779/4096 [00:07<00:00, 541.24it/s]
Adding requests:  94%|| 3834/4096 [00:07<00:00, 535.06it/s]
Adding requests:  95%|| 3889/4096 [00:07<00:00, 536.28it/s]
Adding requests:  96%|| 3943/4096 [00:07<00:00, 501.34it/s]
Adding requests:  98%|| 3997/4096 [00:07<00:00, 510.80it/s]
Adding requests:  99%|| 4051/4096 [00:07<00:00, 515.81it/s]
Adding requests: 100%|| 4096/4096 [00:07<00:00, 524.97it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 66/4096 [00:00<00:34, 115.64it/s, est. speed input: 118423.80 toks/s, output: 115.64 toks/s]
Processed prompts:   2%|         | 98/4096 [00:03<02:29, 26.78it/s, est. speed input: 32462.75 toks/s, output: 31.70 toks/s]   
Processed prompts:   3%|         | 130/4096 [00:05<03:27, 19.16it/s, est. speed input: 23879.26 toks/s, output: 23.32 toks/s]
Processed prompts:   4%|         | 162/4096 [00:08<04:00, 16.35it/s, est. speed input: 20543.17 toks/s, output: 20.06 toks/s]
Processed prompts:   5%|         | 194/4096 [00:10<04:20, 14.96it/s, est. speed input: 18772.09 toks/s, output: 18.33 toks/s]
Processed prompts:   6%|         | 226/4096 [00:13<04:32, 14.22it/s, est. speed input: 17708.03 toks/s, output: 17.29 toks/s]
Processed prompts:   6%|         | 258/4096 [00:15<04:38, 13.76it/s, est. speed input: 16981.02 toks/s, output: 16.58 toks/s]
Processed prompts:   7%|         | 290/4096 [00:18<04:42, 13.46it/s, est. speed input: 16449.27 toks/s, output: 16.06 toks/s]
Processed prompts:   8%|         | 322/4096 [00:20<04:42, 13.35it/s, est. speed input: 16089.15 toks/s, output: 15.71 toks/s]
Processed prompts:   9%|         | 354/4096 [00:22<04:43, 13.19it/s, est. speed input: 15772.02 toks/s, output: 15.40 toks/s]
Processed prompts:   9%|         | 386/4096 [00:25<04:43, 13.09it/s, est. speed input: 15516.36 toks/s, output: 15.15 toks/s]
Processed prompts:  10%|         | 418/4096 [00:27<04:43, 13.00it/s, est. speed input: 15299.74 toks/s, output: 14.94 toks/s]
Processed prompts:  11%|         | 450/4096 [00:30<04:39, 13.04it/s, est. speed input: 15151.31 toks/s, output: 14.80 toks/s]
Processed prompts:  12%|        | 482/4096 [00:32<04:38, 12.99it/s, est. speed input: 15002.19 toks/s, output: 14.65 toks/s]
Processed prompts:  13%|        | 514/4096 [00:35<04:36, 12.95it/s, est. speed input: 14873.71 toks/s, output: 14.53 toks/s]
Processed prompts:  13%|        | 546/4096 [00:37<04:34, 12.91it/s, est. speed input: 14758.86 toks/s, output: 14.41 toks/s]
Processed prompts:  14%|        | 578/4096 [00:40<04:32, 12.90it/s, est. speed input: 14660.81 toks/s, output: 14.32 toks/s]
Processed prompts:  15%|        | 610/4096 [00:42<04:30, 12.88it/s, est. speed input: 14573.90 toks/s, output: 14.23 toks/s]
Processed prompts:  16%|        | 642/4096 [00:45<04:28, 12.87it/s, est. speed input: 14496.35 toks/s, output: 14.16 toks/s]
Processed prompts:  16%|        | 674/4096 [00:47<04:25, 12.87it/s, est. speed input: 14427.58 toks/s, output: 14.09 toks/s]
Processed prompts:  17%|        | 706/4096 [00:50<04:23, 12.86it/s, est. speed input: 14364.38 toks/s, output: 14.03 toks/s]
Processed prompts:  18%|        | 738/4096 [00:52<04:21, 12.86it/s, est. speed input: 14307.11 toks/s, output: 13.97 toks/s]
Processed prompts:  19%|        | 770/4096 [00:55<04:18, 12.86it/s, est. speed input: 14256.02 toks/s, output: 13.92 toks/s]
Processed prompts:  20%|        | 802/4096 [00:57<04:16, 12.85it/s, est. speed input: 14207.86 toks/s, output: 13.87 toks/s]
Processed prompts:  20%|        | 834/4096 [01:00<04:14, 12.84it/s, est. speed input: 14163.29 toks/s, output: 13.83 toks/s]
Processed prompts:  21%|        | 866/4096 [01:02<04:11, 12.84it/s, est. speed input: 14123.13 toks/s, output: 13.79 toks/s]
Processed prompts:  22%|       | 898/4096 [01:05<04:09, 12.84it/s, est. speed input: 14085.01 toks/s, output: 13.75 toks/s]
Processed prompts:  23%|       | 930/4096 [01:07<04:05, 12.92it/s, est. speed input: 14061.98 toks/s, output: 13.73 toks/s]
Processed prompts:  23%|       | 962/4096 [01:10<04:01, 13.00it/s, est. speed input: 14042.03 toks/s, output: 13.71 toks/s]
Processed prompts:  24%|       | 994/4096 [01:12<03:59, 12.95it/s, est. speed input: 14011.41 toks/s, output: 13.68 toks/s]
Processed prompts:  25%|       | 1026/4096 [01:15<03:57, 12.92it/s, est. speed input: 13983.39 toks/s, output: 13.66 toks/s]
Processed prompts:  26%|       | 1058/4096 [01:17<03:55, 12.89it/s, est. speed input: 13956.28 toks/s, output: 13.63 toks/s]
Processed prompts:  27%|       | 1090/4096 [01:20<03:53, 12.89it/s, est. speed input: 13932.30 toks/s, output: 13.61 toks/s]
Processed prompts:  27%|       | 1122/4096 [01:22<03:51, 12.86it/s, est. speed input: 13907.28 toks/s, output: 13.58 toks/s]
Processed prompts:  28%|       | 1154/4096 [01:25<03:47, 12.94it/s, est. speed input: 13894.44 toks/s, output: 13.57 toks/s]
Processed prompts:  29%|       | 1186/4096 [01:27<03:45, 12.91it/s, est. speed input: 13872.76 toks/s, output: 13.55 toks/s]
Processed prompts:  30%|       | 1218/4096 [01:30<03:43, 12.88it/s, est. speed input: 13851.94 toks/s, output: 13.53 toks/s]
Processed prompts:  31%|       | 1250/4096 [01:32<03:39, 12.97it/s, est. speed input: 13842.86 toks/s, output: 13.52 toks/s]
Processed prompts:  31%|      | 1282/4096 [01:34<03:37, 12.93it/s, est. speed input: 13824.61 toks/s, output: 13.50 toks/s]
Processed prompts:  32%|      | 1314/4096 [01:37<03:35, 12.88it/s, est. speed input: 13805.52 toks/s, output: 13.48 toks/s]
Processed prompts:  33%|      | 1346/4096 [01:39<03:33, 12.87it/s, est. speed input: 13788.88 toks/s, output: 13.47 toks/s]
Processed prompts:  34%|      | 1378/4096 [01:42<03:31, 12.86it/s, est. speed input: 13773.30 toks/s, output: 13.45 toks/s]
Processed prompts:  34%|      | 1410/4096 [01:44<03:29, 12.85it/s, est. speed input: 13757.99 toks/s, output: 13.44 toks/s]
Processed prompts:  35%|      | 1442/4096 [01:47<03:26, 12.84it/s, est. speed input: 13743.29 toks/s, output: 13.42 toks/s]
Processed prompts:  36%|      | 1474/4096 [01:49<03:24, 12.85it/s, est. speed input: 13730.52 toks/s, output: 13.41 toks/s]
Processed prompts:  37%|      | 1506/4096 [01:52<03:21, 12.85it/s, est. speed input: 13717.65 toks/s, output: 13.40 toks/s]
Processed prompts:  38%|      | 1538/4096 [01:54<03:19, 12.85it/s, est. speed input: 13705.60 toks/s, output: 13.38 toks/s]
Processed prompts:  38%|      | 1570/4096 [01:57<03:15, 12.94it/s, est. speed input: 13700.87 toks/s, output: 13.38 toks/s]
Processed prompts:  39%|      | 1602/4096 [01:59<03:13, 12.90it/s, est. speed input: 13688.65 toks/s, output: 13.37 toks/s]
Processed prompts:  40%|      | 1634/4096 [02:02<03:10, 12.89it/s, est. speed input: 13678.34 toks/s, output: 13.36 toks/s]
Processed prompts:  41%|      | 1666/4096 [02:04<03:08, 12.89it/s, est. speed input: 13668.48 toks/s, output: 13.35 toks/s]
Processed prompts:  41%|     | 1698/4096 [02:07<03:06, 12.86it/s, est. speed input: 13657.59 toks/s, output: 13.34 toks/s]
Processed prompts:  42%|     | 1730/4096 [02:09<03:03, 12.86it/s, est. speed input: 13648.33 toks/s, output: 13.33 toks/s]
Processed prompts:  43%|     | 1762/4096 [02:12<03:01, 12.86it/s, est. speed input: 13638.93 toks/s, output: 13.32 toks/s]
Processed prompts:  44%|     | 1794/4096 [02:14<02:59, 12.84it/s, est. speed input: 13629.34 toks/s, output: 13.31 toks/s]
Processed prompts:  45%|     | 1826/4096 [02:17<02:56, 12.84it/s, est. speed input: 13620.25 toks/s, output: 13.30 toks/s]
Processed prompts:  45%|     | 1858/4096 [02:19<02:53, 12.92it/s, est. speed input: 13617.27 toks/s, output: 13.30 toks/s]
Processed prompts:  46%|     | 1890/4096 [02:22<02:51, 12.89it/s, est. speed input: 13608.47 toks/s, output: 13.29 toks/s]
Processed prompts:  47%|     | 1922/4096 [02:24<02:48, 12.88it/s, est. speed input: 13600.77 toks/s, output: 13.28 toks/s]
Processed prompts:  48%|     | 1954/4096 [02:27<02:45, 12.96it/s, est. speed input: 13598.47 toks/s, output: 13.28 toks/s]
Processed prompts:  48%|     | 1986/4096 [02:29<02:43, 12.91it/s, est. speed input: 13590.43 toks/s, output: 13.27 toks/s]
Processed prompts:  49%|     | 2018/4096 [02:32<02:41, 12.89it/s, est. speed input: 13583.31 toks/s, output: 13.26 toks/s]
Processed prompts:  50%|     | 2050/4096 [02:34<02:38, 12.88it/s, est. speed input: 13576.56 toks/s, output: 13.26 toks/s]
Processed prompts:  51%|     | 2082/4096 [02:37<02:36, 12.87it/s, est. speed input: 13569.96 toks/s, output: 13.25 toks/s]
Processed prompts:  52%|    | 2114/4096 [02:39<02:34, 12.86it/s, est. speed input: 13563.47 toks/s, output: 13.25 toks/s]
Processed prompts:  52%|    | 2146/4096 [02:42<02:31, 12.85it/s, est. speed input: 13556.55 toks/s, output: 13.24 toks/s]
Processed prompts:  53%|    | 2178/4096 [02:44<02:29, 12.84it/s, est. speed input: 13550.26 toks/s, output: 13.23 toks/s]
Processed prompts:  54%|    | 2210/4096 [02:46<02:24, 13.05it/s, est. speed input: 13554.81 toks/s, output: 13.24 toks/s]
Processed prompts:  55%|    | 2242/4096 [02:49<02:22, 12.98it/s, est. speed input: 13548.70 toks/s, output: 13.23 toks/s]
Processed prompts:  56%|    | 2274/4096 [02:51<02:19, 13.03it/s, est. speed input: 13547.60 toks/s, output: 13.23 toks/s]
Processed prompts:  56%|    | 2306/4096 [02:54<02:17, 12.97it/s, est. speed input: 13541.75 toks/s, output: 13.22 toks/s]
Processed prompts:  57%|    | 2338/4096 [02:56<02:14, 13.02it/s, est. speed input: 13540.67 toks/s, output: 13.22 toks/s]
Processed prompts:  58%|    | 2370/4096 [02:59<02:10, 13.20it/s, est. speed input: 13546.10 toks/s, output: 13.23 toks/s]
Processed prompts:  59%|    | 2402/4096 [03:01<02:09, 13.08it/s, est. speed input: 13540.41 toks/s, output: 13.22 toks/s]
Processed prompts:  59%|    | 2434/4096 [03:04<02:07, 13.01it/s, est. speed input: 13535.03 toks/s, output: 13.22 toks/s]
Processed prompts:  60%|    | 2466/4096 [03:06<02:05, 12.96it/s, est. speed input: 13529.78 toks/s, output: 13.21 toks/s]
Processed prompts:  61%|    | 2498/4096 [03:09<02:02, 13.02it/s, est. speed input: 13529.08 toks/s, output: 13.21 toks/s]
Processed prompts:  62%|   | 2530/4096 [03:11<02:00, 12.96it/s, est. speed input: 13523.89 toks/s, output: 13.21 toks/s]
Processed prompts:  63%|   | 2562/4096 [03:14<01:57, 13.01it/s, est. speed input: 13523.11 toks/s, output: 13.21 toks/s]
Processed prompts:  63%|   | 2594/4096 [03:16<01:55, 12.97it/s, est. speed input: 13518.64 toks/s, output: 13.20 toks/s]
Processed prompts:  64%|   | 2626/4096 [03:18<01:53, 12.93it/s, est. speed input: 13513.87 toks/s, output: 13.20 toks/s]
Processed prompts:  65%|   | 2658/4096 [03:21<01:51, 12.89it/s, est. speed input: 13509.11 toks/s, output: 13.19 toks/s]
Processed prompts:  66%|   | 2690/4096 [03:23<01:49, 12.88it/s, est. speed input: 13504.58 toks/s, output: 13.19 toks/s]
Processed prompts:  66%|   | 2722/4096 [03:26<01:46, 12.86it/s, est. speed input: 13500.18 toks/s, output: 13.18 toks/s]
Processed prompts:  67%|   | 2754/4096 [03:28<01:44, 12.85it/s, est. speed input: 13495.89 toks/s, output: 13.18 toks/s]
Processed prompts:  68%|   | 2786/4096 [03:31<01:41, 12.85it/s, est. speed input: 13491.94 toks/s, output: 13.18 toks/s]
Processed prompts:  69%|   | 2818/4096 [03:33<01:39, 12.85it/s, est. speed input: 13487.82 toks/s, output: 13.17 toks/s]
Processed prompts:  70%|   | 2850/4096 [03:36<01:37, 12.84it/s, est. speed input: 13483.80 toks/s, output: 13.17 toks/s]
Processed prompts:  70%|   | 2882/4096 [03:38<01:34, 12.84it/s, est. speed input: 13480.12 toks/s, output: 13.16 toks/s]
Processed prompts:  71%|   | 2914/4096 [03:41<01:32, 12.84it/s, est. speed input: 13476.21 toks/s, output: 13.16 toks/s]
Processed prompts:  72%|  | 2946/4096 [03:43<01:29, 12.85it/s, est. speed input: 13472.86 toks/s, output: 13.16 toks/s]
Processed prompts:  73%|  | 2978/4096 [03:46<01:27, 12.84it/s, est. speed input: 13469.06 toks/s, output: 13.15 toks/s]
Processed prompts:  73%|  | 3010/4096 [03:48<01:24, 12.83it/s, est. speed input: 13465.36 toks/s, output: 13.15 toks/s]
Processed prompts:  74%|  | 3042/4096 [03:51<01:22, 12.83it/s, est. speed input: 13461.80 toks/s, output: 13.15 toks/s]
Processed prompts:  75%|  | 3074/4096 [03:53<01:19, 12.84it/s, est. speed input: 13458.60 toks/s, output: 13.14 toks/s]
Processed prompts:  76%|  | 3106/4096 [03:56<01:17, 12.83it/s, est. speed input: 13454.88 toks/s, output: 13.14 toks/s]
Processed prompts:  77%|  | 3138/4096 [03:58<01:14, 12.93it/s, est. speed input: 13455.25 toks/s, output: 13.14 toks/s]
Processed prompts:  77%|  | 3170/4096 [04:01<01:11, 12.91it/s, est. speed input: 13452.23 toks/s, output: 13.14 toks/s]
Processed prompts:  78%|  | 3202/4096 [04:03<01:09, 12.87it/s, est. speed input: 13448.69 toks/s, output: 13.13 toks/s]
Processed prompts:  79%|  | 3234/4096 [04:06<01:07, 12.86it/s, est. speed input: 13445.63 toks/s, output: 13.13 toks/s]
Processed prompts:  80%|  | 3266/4096 [04:08<01:04, 12.86it/s, est. speed input: 13442.83 toks/s, output: 13.13 toks/s]
Processed prompts:  81%|  | 3298/4096 [04:11<01:02, 12.85it/s, est. speed input: 13439.74 toks/s, output: 13.12 toks/s]
Processed prompts:  81%| | 3330/4096 [04:13<00:59, 12.86it/s, est. speed input: 13437.15 toks/s, output: 13.12 toks/s]
Processed prompts:  82%| | 3362/4096 [04:16<00:57, 12.85it/s, est. speed input: 13434.33 toks/s, output: 13.12 toks/s]
Processed prompts:  83%| | 3394/4096 [04:18<00:54, 12.85it/s, est. speed input: 13431.54 toks/s, output: 13.12 toks/s]
Processed prompts:  84%| | 3426/4096 [04:21<00:52, 12.84it/s, est. speed input: 13428.83 toks/s, output: 13.11 toks/s]
Processed prompts:  84%| | 3458/4096 [04:23<00:49, 12.85it/s, est. speed input: 13426.25 toks/s, output: 13.11 toks/s]
Processed prompts:  85%| | 3490/4096 [04:26<00:46, 13.04it/s, est. speed input: 13430.04 toks/s, output: 13.12 toks/s]
Processed prompts:  86%| | 3522/4096 [04:28<00:44, 12.99it/s, est. speed input: 13427.56 toks/s, output: 13.11 toks/s]
Processed prompts:  87%| | 3554/4096 [04:31<00:41, 12.94it/s, est. speed input: 13425.08 toks/s, output: 13.11 toks/s]
Processed prompts:  88%| | 3586/4096 [04:33<00:39, 12.90it/s, est. speed input: 13422.21 toks/s, output: 13.11 toks/s]
Processed prompts:  88%| | 3618/4096 [04:36<00:37, 12.89it/s, est. speed input: 13419.92 toks/s, output: 13.11 toks/s]
Processed prompts:  89%| | 3650/4096 [04:38<00:34, 12.87it/s, est. speed input: 13417.41 toks/s, output: 13.10 toks/s]
Processed prompts:  90%| | 3682/4096 [04:41<00:32, 12.85it/s, est. speed input: 13414.77 toks/s, output: 13.10 toks/s]
Processed prompts:  91%| | 3714/4096 [04:43<00:29, 12.95it/s, est. speed input: 13415.41 toks/s, output: 13.10 toks/s]
Processed prompts:  91%|| 3746/4096 [04:45<00:27, 12.92it/s, est. speed input: 13413.07 toks/s, output: 13.10 toks/s]
Processed prompts:  92%|| 3778/4096 [04:48<00:24, 12.88it/s, est. speed input: 13410.35 toks/s, output: 13.10 toks/s]
Processed prompts:  93%|| 3810/4096 [04:50<00:22, 12.86it/s, est. speed input: 13408.04 toks/s, output: 13.09 toks/s]
Processed prompts:  94%|| 3842/4096 [04:53<00:19, 12.95it/s, est. speed input: 13408.62 toks/s, output: 13.09 toks/s]
Processed prompts:  95%|| 3874/4096 [04:55<00:17, 12.91it/s, est. speed input: 13406.09 toks/s, output: 13.09 toks/s]
Processed prompts:  95%|| 3906/4096 [04:58<00:14, 12.89it/s, est. speed input: 13403.92 toks/s, output: 13.09 toks/s]
Processed prompts:  96%|| 3938/4096 [05:00<00:12, 12.88it/s, est. speed input: 13401.97 toks/s, output: 13.09 toks/s]
Processed prompts:  97%|| 3970/4096 [05:03<00:09, 12.86it/s, est. speed input: 13399.64 toks/s, output: 13.09 toks/s]
Processed prompts:  98%|| 4002/4096 [05:05<00:07, 12.86it/s, est. speed input: 13397.71 toks/s, output: 13.08 toks/s]
Processed prompts:  98%|| 4034/4096 [05:08<00:04, 12.95it/s, est. speed input: 13398.42 toks/s, output: 13.08 toks/s]
Processed prompts:  99%|| 4066/4096 [05:10<00:02, 13.02it/s, est. speed input: 13399.19 toks/s, output: 13.09 toks/s]
Processed prompts: 100%|| 4096/4096 [05:10<00:00, 13.02it/s, est. speed input: 13498.04 toks/s, output: 13.18 toks/s]
Processed prompts: 100%|| 4096/4096 [05:10<00:00, 13.18it/s, est. speed input: 13498.04 toks/s, output: 13.18 toks/s]
[rank0]:[W126 10:21:29.598717925 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 10:21:31
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:21:58 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:21:58 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1176350) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1176350) WARNING 01-26 10:22:43 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 12.84 requests/s, 13159.70 total tokens/s, 12.84 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 10:21:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:21:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:21:58] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:21:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:21:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:21:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:21:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:21:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:21:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:21:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:21:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:21:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:21:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:21:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:22:01] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 10:22:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 10:22:01] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 10:22:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:22:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:22:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:22:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:22:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 10:22:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 10:22:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:22:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:22:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:22:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:22:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1176350) [2026-01-26 10:22:02] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1176350) [2026-01-26 10:22:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1176350) [2026-01-26 10:22:02] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1176350) [2026-01-26 10:22:02] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1176350) [2026-01-26 10:22:02] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=1176350) [2026-01-26 10:22:02] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1176350) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1176350) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.36s/it]
(EngineCore_DP0 pid=1176350) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.36s/it]
(EngineCore_DP0 pid=1176350) 
(EngineCore_DP0 pid=1176350) [2026-01-26 10:22:27] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1176350) [2026-01-26 10:22:27] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15728640 bytes
(EngineCore_DP0 pid=1176350) [2026-01-26 10:22:27] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1176350) [2026-01-26 10:22:27] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9437184 bytes
(EngineCore_DP0 pid=1176350) [2026-01-26 10:22:27] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1176350) [2026-01-26 10:22:27] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50331648 bytes
(EngineCore_DP0 pid=1176350) [2026-01-26 10:22:27] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1176350) [2026-01-26 10:22:27] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25264128 bytes
(EngineCore_DP0 pid=1176350) 2026-01-26 10:22:38,058 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1176350) 2026-01-26 10:22:38,353 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 61/8192 [00:00<00:13, 602.17it/s]
Adding requests:   1%|         | 122/8192 [00:00<00:14, 560.76it/s]
Adding requests:   2%|         | 179/8192 [00:00<00:15, 525.16it/s]
Adding requests:   3%|         | 233/8192 [00:00<00:15, 528.07it/s]
Adding requests:   3%|         | 286/8192 [00:00<00:15, 523.20it/s]
Adding requests:   4%|         | 339/8192 [00:00<00:15, 523.06it/s]
Adding requests:   5%|         | 392/8192 [00:00<00:15, 507.93it/s]
Adding requests:   5%|         | 443/8192 [00:00<00:15, 506.33it/s]
Adding requests:   6%|         | 496/8192 [00:00<00:15, 511.88it/s]
Adding requests:   7%|         | 548/8192 [00:01<00:14, 512.80it/s]
Adding requests:   7%|         | 600/8192 [00:01<00:14, 512.99it/s]
Adding requests:   8%|         | 652/8192 [00:01<00:14, 514.95it/s]
Adding requests:   9%|         | 704/8192 [00:01<00:14, 509.82it/s]
Adding requests:   9%|         | 756/8192 [00:01<00:14, 497.98it/s]
Adding requests:  10%|         | 806/8192 [00:01<00:15, 491.21it/s]
Adding requests:  10%|         | 858/8192 [00:01<00:14, 499.07it/s]
Adding requests:  11%|         | 910/8192 [00:01<00:14, 504.16it/s]
Adding requests:  12%|        | 965/8192 [00:01<00:14, 514.75it/s]
Adding requests:  12%|        | 1017/8192 [00:01<00:14, 503.73it/s]
Adding requests:  13%|        | 1068/8192 [00:02<00:14, 500.75it/s]
Adding requests:  14%|        | 1119/8192 [00:02<00:14, 495.45it/s]
Adding requests:  14%|        | 1169/8192 [00:02<00:14, 494.34it/s]
Adding requests:  15%|        | 1223/8192 [00:02<00:13, 505.21it/s]
Adding requests:  16%|        | 1274/8192 [00:02<00:14, 491.22it/s]
Adding requests:  16%|        | 1325/8192 [00:02<00:13, 492.93it/s]
Adding requests:  17%|        | 1377/8192 [00:02<00:13, 500.70it/s]
Adding requests:  17%|        | 1428/8192 [00:02<00:13, 498.76it/s]
Adding requests:  18%|        | 1484/8192 [00:02<00:12, 516.24it/s]
Adding requests:  19%|        | 1536/8192 [00:03<00:13, 504.04it/s]
Adding requests:  19%|        | 1587/8192 [00:03<00:13, 503.64it/s]
Adding requests:  20%|        | 1641/8192 [00:03<00:12, 513.92it/s]
Adding requests:  21%|        | 1693/8192 [00:03<00:12, 508.17it/s]
Adding requests:  21%|       | 1747/8192 [00:03<00:12, 516.82it/s]
Adding requests:  22%|       | 1799/8192 [00:03<00:12, 509.10it/s]
Adding requests:  23%|       | 1854/8192 [00:03<00:12, 517.81it/s]
Adding requests:  23%|       | 1906/8192 [00:03<00:12, 490.36it/s]
Adding requests:  24%|       | 1957/8192 [00:03<00:12, 495.46it/s]
Adding requests:  25%|       | 2009/8192 [00:03<00:12, 501.93it/s]
Adding requests:  25%|       | 2060/8192 [00:04<00:12, 501.55it/s]
Adding requests:  26%|       | 2114/8192 [00:04<00:11, 508.94it/s]
Adding requests:  26%|       | 2165/8192 [00:04<00:12, 501.34it/s]
Adding requests:  27%|       | 2216/8192 [00:04<00:11, 502.45it/s]
Adding requests:  28%|       | 2268/8192 [00:04<00:11, 504.08it/s]
Adding requests:  28%|       | 2322/8192 [00:04<00:11, 511.99it/s]
Adding requests:  29%|       | 2375/8192 [00:04<00:11, 515.59it/s]
Adding requests:  30%|       | 2427/8192 [00:04<00:11, 504.77it/s]
Adding requests:  30%|       | 2478/8192 [00:04<00:11, 505.18it/s]
Adding requests:  31%|       | 2530/8192 [00:04<00:11, 507.14it/s]
Adding requests:  32%|      | 2582/8192 [00:05<00:11, 509.93it/s]
Adding requests:  32%|      | 2634/8192 [00:05<00:10, 506.71it/s]
Adding requests:  33%|      | 2689/8192 [00:05<00:10, 516.96it/s]
Adding requests:  33%|      | 2741/8192 [00:05<00:10, 515.94it/s]
Adding requests:  34%|      | 2793/8192 [00:05<00:10, 505.70it/s]
Adding requests:  35%|      | 2847/8192 [00:05<00:10, 512.85it/s]
Adding requests:  35%|      | 2899/8192 [00:05<00:10, 506.30it/s]
Adding requests:  36%|      | 2950/8192 [00:05<00:10, 504.02it/s]
Adding requests:  37%|      | 3001/8192 [00:05<00:10, 503.36it/s]
Adding requests:  37%|      | 3052/8192 [00:06<00:10, 499.88it/s]
Adding requests:  38%|      | 3105/8192 [00:06<00:10, 508.58it/s]
Adding requests:  39%|      | 3156/8192 [00:06<00:10, 503.31it/s]
Adding requests:  39%|      | 3209/8192 [00:06<00:09, 511.01it/s]
Adding requests:  40%|      | 3261/8192 [00:06<00:10, 492.61it/s]
Adding requests:  40%|      | 3313/8192 [00:06<00:09, 499.39it/s]
Adding requests:  41%|      | 3368/8192 [00:06<00:09, 513.67it/s]
Adding requests:  42%|     | 3420/8192 [00:06<00:09, 511.82it/s]
Adding requests:  42%|     | 3472/8192 [00:06<00:09, 502.87it/s]
Adding requests:  43%|     | 3525/8192 [00:06<00:09, 508.04it/s]
Adding requests:  44%|     | 3577/8192 [00:07<00:09, 510.07it/s]
Adding requests:  44%|     | 3629/8192 [00:07<00:08, 511.08it/s]
Adding requests:  45%|     | 3681/8192 [00:07<00:08, 511.31it/s]
Adding requests:  46%|     | 3735/8192 [00:07<00:08, 516.18it/s]
Adding requests:  46%|     | 3788/8192 [00:07<00:08, 519.62it/s]
Adding requests:  47%|     | 3840/8192 [00:07<00:08, 517.47it/s]
Adding requests:  48%|     | 3894/8192 [00:07<00:08, 523.36it/s]
Adding requests:  48%|     | 3948/8192 [00:07<00:08, 525.84it/s]
Adding requests:  49%|     | 4001/8192 [00:07<00:07, 524.48it/s]
Adding requests:  49%|     | 4054/8192 [00:07<00:08, 510.63it/s]
Adding requests:  50%|     | 4106/8192 [00:08<00:08, 503.76it/s]
Adding requests:  51%|     | 4158/8192 [00:08<00:07, 505.40it/s]
Adding requests:  51%|    | 4211/8192 [00:08<00:07, 510.43it/s]
Adding requests:  52%|    | 4264/8192 [00:08<00:07, 514.20it/s]
Adding requests:  53%|    | 4316/8192 [00:08<00:07, 508.77it/s]
Adding requests:  53%|    | 4374/8192 [00:08<00:07, 528.70it/s]
Adding requests:  54%|    | 4427/8192 [00:08<00:07, 512.90it/s]
Adding requests:  55%|    | 4479/8192 [00:08<00:07, 512.27it/s]
Adding requests:  55%|    | 4531/8192 [00:08<00:07, 510.37it/s]
Adding requests:  56%|    | 4584/8192 [00:09<00:07, 514.33it/s]
Adding requests:  57%|    | 4636/8192 [00:09<00:07, 477.59it/s]
Adding requests:  57%|    | 4688/8192 [00:09<00:07, 486.70it/s]
Adding requests:  58%|    | 4741/8192 [00:09<00:06, 497.68it/s]
Adding requests:  59%|    | 4796/8192 [00:09<00:06, 511.04it/s]
Adding requests:  59%|    | 4848/8192 [00:09<00:06, 508.19it/s]
Adding requests:  60%|    | 4902/8192 [00:09<00:06, 514.05it/s]
Adding requests:  60%|    | 4954/8192 [00:09<00:06, 511.24it/s]
Adding requests:  61%|    | 5007/8192 [00:09<00:06, 515.12it/s]
Adding requests:  62%|   | 5060/8192 [00:09<00:06, 518.12it/s]
Adding requests:  62%|   | 5117/8192 [00:10<00:05, 531.01it/s]
Adding requests:  63%|   | 5171/8192 [00:10<00:05, 521.75it/s]
Adding requests:  64%|   | 5224/8192 [00:10<00:05, 513.53it/s]
Adding requests:  64%|   | 5278/8192 [00:10<00:05, 518.10it/s]
Adding requests:  65%|   | 5330/8192 [00:10<00:05, 517.40it/s]
Adding requests:  66%|   | 5385/8192 [00:10<00:05, 525.33it/s]
Adding requests:  66%|   | 5439/8192 [00:10<00:05, 528.55it/s]
Adding requests:  67%|   | 5492/8192 [00:10<00:05, 525.10it/s]
Adding requests:  68%|   | 5547/8192 [00:10<00:04, 530.75it/s]
Adding requests:  68%|   | 5601/8192 [00:10<00:04, 530.43it/s]
Adding requests:  69%|   | 5655/8192 [00:11<00:04, 532.39it/s]
Adding requests:  70%|   | 5709/8192 [00:11<00:04, 530.03it/s]
Adding requests:  70%|   | 5763/8192 [00:11<00:04, 526.92it/s]
Adding requests:  71%|   | 5816/8192 [00:11<00:04, 526.31it/s]
Adding requests:  72%|  | 5872/8192 [00:11<00:04, 533.38it/s]
Adding requests:  72%|  | 5931/8192 [00:11<00:04, 549.93it/s]
Adding requests:  73%|  | 5987/8192 [00:11<00:04, 524.57it/s]
Adding requests:  74%|  | 6043/8192 [00:11<00:04, 530.82it/s]
Adding requests:  74%|  | 6097/8192 [00:11<00:03, 528.72it/s]
Adding requests:  75%|  | 6153/8192 [00:12<00:03, 536.90it/s]
Adding requests:  76%|  | 6207/8192 [00:12<00:03, 536.79it/s]
Adding requests:  76%|  | 6262/8192 [00:12<00:03, 538.93it/s]
Adding requests:  77%|  | 6319/8192 [00:12<00:03, 547.50it/s]
Adding requests:  78%|  | 6374/8192 [00:12<00:03, 539.50it/s]
Adding requests:  78%|  | 6430/8192 [00:12<00:03, 544.41it/s]
Adding requests:  79%|  | 6487/8192 [00:12<00:03, 550.26it/s]
Adding requests:  80%|  | 6545/8192 [00:12<00:02, 558.15it/s]
Adding requests:  81%|  | 6601/8192 [00:12<00:02, 554.15it/s]
Adding requests:  81%| | 6657/8192 [00:12<00:02, 548.16it/s]
Adding requests:  82%| | 6713/8192 [00:13<00:02, 551.39it/s]
Adding requests:  83%| | 6769/8192 [00:13<00:02, 541.72it/s]
Adding requests:  83%| | 6825/8192 [00:13<00:02, 544.84it/s]
Adding requests:  84%| | 6884/8192 [00:13<00:02, 556.47it/s]
Adding requests:  85%| | 6940/8192 [00:13<00:02, 552.93it/s]
Adding requests:  85%| | 6997/8192 [00:13<00:02, 555.98it/s]
Adding requests:  86%| | 7053/8192 [00:13<00:02, 544.66it/s]
Adding requests:  87%| | 7110/8192 [00:13<00:01, 549.56it/s]
Adding requests:  87%| | 7166/8192 [00:13<00:01, 547.79it/s]
Adding requests:  88%| | 7222/8192 [00:13<00:01, 548.64it/s]
Adding requests:  89%| | 7283/8192 [00:14<00:01, 564.29it/s]
Adding requests:  90%| | 7340/8192 [00:14<00:01, 552.68it/s]
Adding requests:  90%| | 7396/8192 [00:14<00:01, 519.04it/s]
Adding requests:  91%| | 7457/8192 [00:14<00:01, 543.95it/s]
Adding requests:  92%|| 7512/8192 [00:14<00:01, 542.01it/s]
Adding requests:  92%|| 7571/8192 [00:14<00:01, 555.68it/s]
Adding requests:  93%|| 7627/8192 [00:14<00:01, 541.35it/s]
Adding requests:  94%|| 7684/8192 [00:14<00:00, 549.56it/s]
Adding requests:  94%|| 7740/8192 [00:14<00:00, 549.69it/s]
Adding requests:  95%|| 7796/8192 [00:15<00:00, 541.77it/s]
Adding requests:  96%|| 7851/8192 [00:15<00:00, 538.74it/s]
Adding requests:  96%|| 7905/8192 [00:15<00:00, 532.34it/s]
Adding requests:  97%|| 7963/8192 [00:15<00:00, 543.51it/s]
Adding requests:  98%|| 8018/8192 [00:15<00:00, 536.77it/s]
Adding requests:  99%|| 8073/8192 [00:15<00:00, 538.37it/s]
Adding requests:  99%|| 8129/8192 [00:15<00:00, 542.35it/s]
Adding requests: 100%|| 8186/8192 [00:15<00:00, 548.47it/s]
Adding requests: 100%|| 8192/8192 [00:15<00:00, 520.51it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 194/8192 [00:04<02:54, 45.95it/s, est. speed input: 47057.82 toks/s, output: 45.95 toks/s]
Processed prompts:   3%|         | 258/8192 [00:09<05:13, 25.30it/s, est. speed input: 28830.39 toks/s, output: 28.15 toks/s]
Processed prompts:   4%|         | 322/8192 [00:14<06:41, 19.58it/s, est. speed input: 23473.22 toks/s, output: 22.92 toks/s]
Processed prompts:   5%|         | 386/8192 [00:18<07:41, 16.91it/s, est. speed input: 20821.92 toks/s, output: 20.33 toks/s]
Processed prompts:   5%|         | 450/8192 [00:23<08:18, 15.54it/s, est. speed input: 19315.57 toks/s, output: 18.86 toks/s]
Processed prompts:   6%|         | 514/8192 [00:28<08:44, 14.65it/s, est. speed input: 18277.19 toks/s, output: 17.85 toks/s]
Processed prompts:   7%|         | 578/8192 [00:33<09:00, 14.09it/s, est. speed input: 17543.55 toks/s, output: 17.13 toks/s]
Processed prompts:   8%|         | 642/8192 [00:38<09:10, 13.73it/s, est. speed input: 16997.09 toks/s, output: 16.60 toks/s]
Processed prompts:   9%|         | 706/8192 [00:43<09:15, 13.48it/s, est. speed input: 16571.44 toks/s, output: 16.18 toks/s]
Processed prompts:   9%|         | 770/8192 [00:48<09:17, 13.31it/s, est. speed input: 16234.41 toks/s, output: 15.85 toks/s]
Processed prompts:  10%|         | 834/8192 [00:53<09:17, 13.19it/s, est. speed input: 15957.06 toks/s, output: 15.58 toks/s]
Processed prompts:  11%|         | 898/8192 [00:58<09:13, 13.18it/s, est. speed input: 15747.72 toks/s, output: 15.38 toks/s]
Processed prompts:  12%|        | 962/8192 [01:03<09:08, 13.17it/s, est. speed input: 15573.20 toks/s, output: 15.21 toks/s]
Processed prompts:  13%|        | 1026/8192 [01:08<09:07, 13.10it/s, est. speed input: 15404.35 toks/s, output: 15.04 toks/s]
Processed prompts:  13%|        | 1090/8192 [01:13<09:03, 13.06it/s, est. speed input: 15259.75 toks/s, output: 14.90 toks/s]
Processed prompts:  14%|        | 1154/8192 [01:18<08:57, 13.08it/s, est. speed input: 15147.46 toks/s, output: 14.79 toks/s]
Processed prompts:  15%|        | 1218/8192 [01:22<08:52, 13.09it/s, est. speed input: 15046.21 toks/s, output: 14.69 toks/s]
Processed prompts:  16%|        | 1282/8192 [01:27<08:49, 13.05it/s, est. speed input: 14945.39 toks/s, output: 14.60 toks/s]
Processed prompts:  16%|        | 1346/8192 [01:32<08:45, 13.02it/s, est. speed input: 14855.55 toks/s, output: 14.51 toks/s]
Processed prompts:  17%|        | 1410/8192 [01:37<08:42, 12.99it/s, est. speed input: 14773.15 toks/s, output: 14.43 toks/s]
Processed prompts:  18%|        | 1474/8192 [01:42<08:37, 12.98it/s, est. speed input: 14700.48 toks/s, output: 14.36 toks/s]
Processed prompts:  19%|        | 1538/8192 [01:47<08:30, 13.02it/s, est. speed input: 14643.96 toks/s, output: 14.30 toks/s]
Processed prompts:  20%|        | 1602/8192 [01:52<08:27, 12.99it/s, est. speed input: 14581.88 toks/s, output: 14.24 toks/s]
Processed prompts:  20%|        | 1666/8192 [01:57<08:22, 12.98it/s, est. speed input: 14525.79 toks/s, output: 14.19 toks/s]
Processed prompts:  21%|        | 1730/8192 [02:02<08:18, 12.96it/s, est. speed input: 14473.55 toks/s, output: 14.13 toks/s]
Processed prompts:  22%|       | 1794/8192 [02:07<08:13, 12.96it/s, est. speed input: 14426.80 toks/s, output: 14.09 toks/s]
Processed prompts:  23%|       | 1858/8192 [02:12<08:06, 13.01it/s, est. speed input: 14390.40 toks/s, output: 14.05 toks/s]
Processed prompts:  23%|       | 1922/8192 [02:17<08:00, 13.04it/s, est. speed input: 14356.47 toks/s, output: 14.02 toks/s]
Processed prompts:  24%|       | 1986/8192 [02:22<07:56, 13.01it/s, est. speed input: 14317.80 toks/s, output: 13.98 toks/s]
Processed prompts:  25%|       | 2050/8192 [02:26<07:52, 12.99it/s, est. speed input: 14282.01 toks/s, output: 13.95 toks/s]
Processed prompts:  26%|       | 2114/8192 [02:31<07:48, 12.97it/s, est. speed input: 14247.79 toks/s, output: 13.91 toks/s]
Processed prompts:  27%|       | 2178/8192 [02:39<08:48, 11.38it/s, est. speed input: 14012.34 toks/s, output: 13.68 toks/s]
Processed prompts:  27%|       | 2242/8192 [02:44<08:23, 11.81it/s, est. speed input: 13989.38 toks/s, output: 13.66 toks/s]
Processed prompts:  28%|       | 2306/8192 [02:49<08:04, 12.14it/s, est. speed input: 13968.96 toks/s, output: 13.64 toks/s]
Processed prompts:  29%|       | 2370/8192 [02:53<07:47, 12.44it/s, est. speed input: 13957.14 toks/s, output: 13.63 toks/s]
Processed prompts:  30%|       | 2434/8192 [02:58<07:39, 12.54it/s, est. speed input: 13932.79 toks/s, output: 13.61 toks/s]
Processed prompts:  30%|       | 2498/8192 [03:03<07:29, 12.67it/s, est. speed input: 13915.05 toks/s, output: 13.59 toks/s]
Processed prompts:  31%|      | 2562/8192 [03:08<07:21, 12.76it/s, est. speed input: 13899.25 toks/s, output: 13.57 toks/s]
Processed prompts:  32%|      | 2626/8192 [03:13<07:15, 12.77it/s, est. speed input: 13878.16 toks/s, output: 13.55 toks/s]
Processed prompts:  33%|      | 2690/8192 [03:18<07:11, 12.76it/s, est. speed input: 13857.52 toks/s, output: 13.53 toks/s]
Processed prompts:  34%|      | 2754/8192 [03:23<07:05, 12.77it/s, est. speed input: 13838.72 toks/s, output: 13.51 toks/s]
Processed prompts:  34%|      | 2818/8192 [03:28<07:00, 12.77it/s, est. speed input: 13820.35 toks/s, output: 13.50 toks/s]
Processed prompts:  35%|      | 2882/8192 [03:33<06:55, 12.77it/s, est. speed input: 13803.24 toks/s, output: 13.48 toks/s]
Processed prompts:  36%|      | 2946/8192 [03:38<06:50, 12.78it/s, est. speed input: 13787.48 toks/s, output: 13.46 toks/s]
Processed prompts:  37%|      | 3010/8192 [03:43<06:45, 12.78it/s, est. speed input: 13771.89 toks/s, output: 13.45 toks/s]
Processed prompts:  38%|      | 3074/8192 [03:48<06:40, 12.78it/s, est. speed input: 13756.63 toks/s, output: 13.43 toks/s]
Processed prompts:  38%|      | 3138/8192 [03:53<06:33, 12.84it/s, est. speed input: 13746.59 toks/s, output: 13.42 toks/s]
Processed prompts:  39%|      | 3202/8192 [03:58<06:29, 12.82it/s, est. speed input: 13733.06 toks/s, output: 13.41 toks/s]
Processed prompts:  40%|      | 3266/8192 [04:03<06:24, 12.81it/s, est. speed input: 13719.87 toks/s, output: 13.40 toks/s]
Processed prompts:  41%|      | 3330/8192 [04:08<06:19, 12.81it/s, est. speed input: 13707.55 toks/s, output: 13.39 toks/s]
Processed prompts:  41%|     | 3394/8192 [04:13<06:14, 12.80it/s, est. speed input: 13695.19 toks/s, output: 13.37 toks/s]
Processed prompts:  42%|     | 3458/8192 [04:18<06:06, 12.93it/s, est. speed input: 13692.48 toks/s, output: 13.37 toks/s]
Processed prompts:  43%|     | 3522/8192 [04:23<06:02, 12.88it/s, est. speed input: 13680.78 toks/s, output: 13.36 toks/s]
Processed prompts:  44%|     | 3586/8192 [04:28<05:58, 12.85it/s, est. speed input: 13669.74 toks/s, output: 13.35 toks/s]
Processed prompts:  45%|     | 3650/8192 [04:33<05:54, 12.83it/s, est. speed input: 13658.88 toks/s, output: 13.34 toks/s]
Processed prompts:  45%|     | 3714/8192 [04:38<05:48, 12.86it/s, est. speed input: 13651.88 toks/s, output: 13.33 toks/s]
Processed prompts:  46%|     | 3778/8192 [04:43<05:43, 12.83it/s, est. speed input: 13641.57 toks/s, output: 13.32 toks/s]
Processed prompts:  47%|     | 3842/8192 [04:48<05:39, 12.82it/s, est. speed input: 13631.85 toks/s, output: 13.31 toks/s]
Processed prompts:  48%|     | 3906/8192 [04:53<05:34, 12.81it/s, est. speed input: 13623.03 toks/s, output: 13.30 toks/s]
Processed prompts:  48%|     | 3970/8192 [04:58<05:29, 12.80it/s, est. speed input: 13613.87 toks/s, output: 13.29 toks/s]
Processed prompts:  49%|     | 4034/8192 [05:03<05:23, 12.85it/s, est. speed input: 13608.21 toks/s, output: 13.29 toks/s]
Processed prompts:  50%|     | 4098/8192 [05:08<05:19, 12.83it/s, est. speed input: 13599.87 toks/s, output: 13.28 toks/s]
Processed prompts:  51%|     | 4162/8192 [05:13<05:14, 12.81it/s, est. speed input: 13591.61 toks/s, output: 13.27 toks/s]
Processed prompts:  52%|    | 4226/8192 [05:18<05:06, 12.94it/s, est. speed input: 13590.96 toks/s, output: 13.27 toks/s]
Processed prompts:  52%|    | 4290/8192 [05:23<05:01, 12.94it/s, est. speed input: 13586.19 toks/s, output: 13.27 toks/s]
Processed prompts:  53%|    | 4354/8192 [05:28<04:57, 12.89it/s, est. speed input: 13578.35 toks/s, output: 13.26 toks/s]
Processed prompts:  54%|    | 4418/8192 [05:33<04:53, 12.86it/s, est. speed input: 13571.03 toks/s, output: 13.25 toks/s]
Processed prompts:  55%|    | 4482/8192 [05:38<04:49, 12.84it/s, est. speed input: 13563.98 toks/s, output: 13.25 toks/s]
Processed prompts:  55%|    | 4546/8192 [05:43<04:44, 12.82it/s, est. speed input: 13557.04 toks/s, output: 13.24 toks/s]
Processed prompts:  56%|    | 4610/8192 [05:48<04:39, 12.81it/s, est. speed input: 13550.37 toks/s, output: 13.23 toks/s]
Processed prompts:  57%|    | 4674/8192 [05:53<04:34, 12.80it/s, est. speed input: 13543.71 toks/s, output: 13.23 toks/s]
Processed prompts:  58%|    | 4738/8192 [05:58<04:28, 12.85it/s, est. speed input: 13539.91 toks/s, output: 13.22 toks/s]
Processed prompts:  59%|    | 4802/8192 [06:03<04:23, 12.88it/s, est. speed input: 13536.37 toks/s, output: 13.22 toks/s]
Processed prompts:  59%|    | 4866/8192 [06:08<04:18, 12.85it/s, est. speed input: 13530.01 toks/s, output: 13.21 toks/s]
Processed prompts:  60%|    | 4930/8192 [06:13<04:14, 12.82it/s, est. speed input: 13523.98 toks/s, output: 13.21 toks/s]
Processed prompts:  61%|    | 4994/8192 [06:18<04:07, 12.94it/s, est. speed input: 13524.23 toks/s, output: 13.21 toks/s]
Processed prompts:  62%|   | 5058/8192 [06:23<04:03, 12.89it/s, est. speed input: 13518.43 toks/s, output: 13.20 toks/s]
Processed prompts:  63%|   | 5122/8192 [06:28<03:58, 12.85it/s, est. speed input: 13512.65 toks/s, output: 13.20 toks/s]
Processed prompts:  63%|   | 5186/8192 [06:33<03:53, 12.89it/s, est. speed input: 13509.82 toks/s, output: 13.19 toks/s]
Processed prompts:  64%|   | 5250/8192 [06:38<03:48, 12.85it/s, est. speed input: 13504.18 toks/s, output: 13.19 toks/s]
Processed prompts:  65%|   | 5314/8192 [06:43<03:43, 12.88it/s, est. speed input: 13501.35 toks/s, output: 13.18 toks/s]
Processed prompts:  66%|   | 5378/8192 [06:47<03:38, 12.91it/s, est. speed input: 13498.58 toks/s, output: 13.18 toks/s]
Processed prompts:  66%|   | 5442/8192 [06:52<03:33, 12.87it/s, est. speed input: 13493.50 toks/s, output: 13.18 toks/s]
Processed prompts:  67%|   | 5506/8192 [06:57<03:28, 12.90it/s, est. speed input: 13491.01 toks/s, output: 13.17 toks/s]
Processed prompts:  68%|   | 5570/8192 [07:02<03:23, 12.86it/s, est. speed input: 13486.17 toks/s, output: 13.17 toks/s]
Processed prompts:  69%|   | 5634/8192 [07:07<03:18, 12.89it/s, est. speed input: 13483.80 toks/s, output: 13.17 toks/s]
Processed prompts:  70%|   | 5698/8192 [07:12<03:13, 12.86it/s, est. speed input: 13479.13 toks/s, output: 13.16 toks/s]
Processed prompts:  70%|   | 5762/8192 [07:17<03:09, 12.84it/s, est. speed input: 13474.72 toks/s, output: 13.16 toks/s]
Processed prompts:  71%|   | 5826/8192 [07:22<03:04, 12.81it/s, est. speed input: 13470.14 toks/s, output: 13.15 toks/s]
Processed prompts:  72%|  | 5890/8192 [07:27<02:59, 12.80it/s, est. speed input: 13465.59 toks/s, output: 13.15 toks/s]
Processed prompts:  73%|  | 5954/8192 [07:32<02:54, 12.79it/s, est. speed input: 13461.45 toks/s, output: 13.15 toks/s]
Processed prompts:  73%|  | 6018/8192 [07:37<02:50, 12.79it/s, est. speed input: 13457.20 toks/s, output: 13.14 toks/s]
Processed prompts:  74%|  | 6082/8192 [07:42<02:44, 12.79it/s, est. speed input: 13453.40 toks/s, output: 13.14 toks/s]
Processed prompts:  75%|  | 6146/8192 [07:47<02:39, 12.79it/s, est. speed input: 13449.61 toks/s, output: 13.13 toks/s]
Processed prompts:  76%|  | 6210/8192 [07:52<02:35, 12.78it/s, est. speed input: 13445.52 toks/s, output: 13.13 toks/s]
Processed prompts:  77%|  | 6274/8192 [07:57<02:30, 12.77it/s, est. speed input: 13441.56 toks/s, output: 13.13 toks/s]
Processed prompts:  77%|  | 6338/8192 [08:02<02:25, 12.78it/s, est. speed input: 13437.90 toks/s, output: 13.12 toks/s]
Processed prompts:  78%|  | 6402/8192 [08:07<02:20, 12.77it/s, est. speed input: 13434.10 toks/s, output: 13.12 toks/s]
Processed prompts:  79%|  | 6466/8192 [08:12<02:15, 12.78it/s, est. speed input: 13430.60 toks/s, output: 13.12 toks/s]
Processed prompts:  80%|  | 6530/8192 [08:17<02:09, 12.79it/s, est. speed input: 13427.48 toks/s, output: 13.11 toks/s]
Processed prompts:  80%|  | 6594/8192 [08:22<02:04, 12.84it/s, est. speed input: 13425.87 toks/s, output: 13.11 toks/s]
Processed prompts:  81%| | 6658/8192 [08:27<01:59, 12.87it/s, est. speed input: 13424.31 toks/s, output: 13.11 toks/s]
Processed prompts:  82%| | 6722/8192 [08:32<01:54, 12.85it/s, est. speed input: 13421.14 toks/s, output: 13.11 toks/s]
Processed prompts:  83%| | 6786/8192 [08:37<01:49, 12.83it/s, est. speed input: 13417.94 toks/s, output: 13.10 toks/s]
Processed prompts:  84%| | 6850/8192 [08:42<01:44, 12.81it/s, est. speed input: 13414.49 toks/s, output: 13.10 toks/s]
Processed prompts:  84%| | 6914/8192 [08:47<01:39, 12.79it/s, est. speed input: 13411.25 toks/s, output: 13.10 toks/s]
Processed prompts:  85%| | 6978/8192 [08:52<01:34, 12.78it/s, est. speed input: 13408.01 toks/s, output: 13.09 toks/s]
Processed prompts:  86%| | 7042/8192 [08:57<01:29, 12.78it/s, est. speed input: 13404.89 toks/s, output: 13.09 toks/s]
Processed prompts:  87%| | 7106/8192 [09:02<01:24, 12.84it/s, est. speed input: 13403.77 toks/s, output: 13.09 toks/s]
Processed prompts:  88%| | 7170/8192 [09:07<01:19, 12.82it/s, est. speed input: 13400.82 toks/s, output: 13.09 toks/s]
Processed prompts:  88%| | 7234/8192 [09:12<01:14, 12.86it/s, est. speed input: 13399.69 toks/s, output: 13.09 toks/s]
Processed prompts:  89%| | 7298/8192 [09:17<01:09, 12.84it/s, est. speed input: 13397.03 toks/s, output: 13.08 toks/s]
Processed prompts:  90%| | 7362/8192 [09:22<01:04, 12.82it/s, est. speed input: 13394.15 toks/s, output: 13.08 toks/s]
Processed prompts:  91%| | 7426/8192 [09:27<00:59, 12.85it/s, est. speed input: 13392.81 toks/s, output: 13.08 toks/s]
Processed prompts:  91%|| 7490/8192 [09:32<00:54, 12.83it/s, est. speed input: 13390.13 toks/s, output: 13.08 toks/s]
Processed prompts:  92%|| 7554/8192 [09:37<00:49, 12.95it/s, est. speed input: 13391.52 toks/s, output: 13.08 toks/s]
Processed prompts:  93%|| 7618/8192 [09:42<00:44, 12.90it/s, est. speed input: 13388.91 toks/s, output: 13.08 toks/s]
Processed prompts:  94%|| 7682/8192 [09:47<00:39, 12.92it/s, est. speed input: 13387.94 toks/s, output: 13.07 toks/s]
Processed prompts:  95%|| 7746/8192 [09:52<00:34, 12.87it/s, est. speed input: 13385.23 toks/s, output: 13.07 toks/s]
Processed prompts:  95%|| 7810/8192 [09:57<00:29, 12.84it/s, est. speed input: 13382.73 toks/s, output: 13.07 toks/s]
Processed prompts:  96%|| 7874/8192 [10:02<00:24, 12.83it/s, est. speed input: 13380.40 toks/s, output: 13.07 toks/s]
Processed prompts:  97%|| 7938/8192 [10:07<00:19, 12.86it/s, est. speed input: 13379.42 toks/s, output: 13.07 toks/s]
Processed prompts:  98%|| 8002/8192 [10:12<00:14, 12.84it/s, est. speed input: 13376.99 toks/s, output: 13.06 toks/s]
Processed prompts:  98%|| 8066/8192 [10:17<00:09, 12.88it/s, est. speed input: 13376.21 toks/s, output: 13.06 toks/s]
Processed prompts:  99%|| 8130/8192 [10:22<00:04, 12.97it/s, est. speed input: 13377.38 toks/s, output: 13.06 toks/s]
Processed prompts: 100%|| 8192/8192 [10:22<00:00, 12.97it/s, est. speed input: 13479.39 toks/s, output: 13.16 toks/s]
Processed prompts: 100%|| 8192/8192 [10:22<00:00, 13.16it/s, est. speed input: 13479.39 toks/s, output: 13.16 toks/s]
[rank0]:[W126 10:33:21.103885961 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 15:19:20
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:19:24 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 15:19:24 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1436036) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1436036) WARNING 01-26 15:20:36 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 10.35 requests/s, 5309.06 total tokens/s, 10.35 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 15:19:24] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:19:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:19:24] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:19:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:19:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:19:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:19:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:19:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:19:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:19:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:19:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:19:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:19:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:19:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:19:27] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:19:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:19:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:19:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:19:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:19:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:19:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:19:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:19:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:19:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:19:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:19:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:19:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:19:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1436036) [2026-01-26 15:19:28] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1436036) [2026-01-26 15:19:28] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1436036) [2026-01-26 15:19:28] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1436036) [2026-01-26 15:19:28] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1436036) [2026-01-26 15:19:28] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1436036) [2026-01-26 15:19:28] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1436036) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1436036) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:24<00:24, 24.13s/it]
(EngineCore_DP0 pid=1436036) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:57<00:00, 29.62s/it]
(EngineCore_DP0 pid=1436036) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:57<00:00, 28.80s/it]
(EngineCore_DP0 pid=1436036) 
(EngineCore_DP0 pid=1436036) [2026-01-26 15:20:27] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1436036) [2026-01-26 15:20:27] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=1436036) [2026-01-26 15:20:27] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1436036) [2026-01-26 15:20:27] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=1436036) [2026-01-26 15:20:27] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1436036) [2026-01-26 15:20:27] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=1436036) [2026-01-26 15:20:27] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1436036) [2026-01-26 15:20:27] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=1436036) 2026-01-26 15:20:35,568 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1436036) 2026-01-26 15:20:35,615 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:   1%|          | 1/128 [00:00<01:21,  1.56it/s]
Adding requests:   2%|         | 2/128 [00:00<00:46,  2.71it/s]
Adding requests:   3%|         | 4/128 [00:00<00:22,  5.47it/s]
Adding requests:   5%|         | 7/128 [00:01<00:12,  9.62it/s]
Adding requests:   9%|         | 11/128 [00:01<00:07, 15.85it/s]
Adding requests:  12%|        | 15/128 [00:01<00:05, 21.02it/s]
Adding requests:  16%|        | 21/128 [00:01<00:03, 29.43it/s]
Adding requests:  24%|       | 31/128 [00:01<00:02, 46.93it/s]
Adding requests:  46%|     | 59/128 [00:01<00:00, 108.00it/s]
Adding requests:  72%|  | 92/128 [00:01<00:00, 167.28it/s]
Adding requests: 100%|| 128/128 [00:01<00:00, 70.18it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  10%|         | 13/128 [00:00<00:01, 86.68it/s, est. speed input: 44387.06 toks/s, output: 86.68 toks/s]
Processed prompts:  17%|        | 22/128 [00:00<00:05, 19.81it/s, est. speed input: 11752.68 toks/s, output: 22.95 toks/s]
Processed prompts:  21%|        | 27/128 [00:01<00:06, 16.30it/s, est. speed input: 9851.60 toks/s, output: 19.24 toks/s] 
Processed prompts:  23%|       | 30/128 [00:01<00:06, 14.97it/s, est. speed input: 9192.14 toks/s, output: 17.95 toks/s]
Processed prompts:  26%|       | 33/128 [00:01<00:06, 13.91it/s, est. speed input: 8702.61 toks/s, output: 17.00 toks/s]
Processed prompts:  27%|       | 35/128 [00:02<00:06, 13.40it/s, est. speed input: 8465.87 toks/s, output: 16.53 toks/s]
Processed prompts:  29%|       | 37/128 [00:02<00:07, 12.87it/s, est. speed input: 8245.65 toks/s, output: 16.10 toks/s]
Processed prompts:  30%|       | 39/128 [00:02<00:07, 12.50it/s, est. speed input: 8072.99 toks/s, output: 15.77 toks/s]
Processed prompts:  32%|      | 41/128 [00:02<00:07, 12.18it/s, est. speed input: 7917.80 toks/s, output: 15.46 toks/s]
Processed prompts:  34%|      | 43/128 [00:02<00:07, 11.91it/s, est. speed input: 7779.58 toks/s, output: 15.19 toks/s]
Processed prompts:  35%|      | 45/128 [00:03<00:07, 11.62it/s, est. speed input: 7645.49 toks/s, output: 14.93 toks/s]
Processed prompts:  37%|      | 47/128 [00:03<00:07, 11.51it/s, est. speed input: 7539.60 toks/s, output: 14.73 toks/s]
Processed prompts:  38%|      | 49/128 [00:03<00:06, 11.52it/s, est. speed input: 7456.27 toks/s, output: 14.56 toks/s]
Processed prompts:  40%|      | 51/128 [00:03<00:06, 11.43it/s, est. speed input: 7369.92 toks/s, output: 14.39 toks/s]
Processed prompts:  41%|     | 53/128 [00:03<00:06, 11.43it/s, est. speed input: 7298.73 toks/s, output: 14.26 toks/s]
Processed prompts:  43%|     | 55/128 [00:03<00:06, 11.38it/s, est. speed input: 7228.09 toks/s, output: 14.12 toks/s]
Processed prompts:  45%|     | 57/128 [00:04<00:06, 11.18it/s, est. speed input: 7148.94 toks/s, output: 13.96 toks/s]
Processed prompts:  46%|     | 59/128 [00:04<00:06, 11.19it/s, est. speed input: 7089.80 toks/s, output: 13.85 toks/s]
Processed prompts:  48%|     | 61/128 [00:04<00:05, 11.20it/s, est. speed input: 7036.55 toks/s, output: 13.74 toks/s]
Processed prompts:  49%|     | 63/128 [00:04<00:05, 11.24it/s, est. speed input: 6989.43 toks/s, output: 13.65 toks/s]
Processed prompts:  51%|     | 65/128 [00:04<00:05, 11.23it/s, est. speed input: 6942.62 toks/s, output: 13.56 toks/s]
Processed prompts:  52%|    | 67/128 [00:04<00:05, 11.14it/s, est. speed input: 6893.18 toks/s, output: 13.46 toks/s]
Processed prompts:  54%|    | 69/128 [00:05<00:05, 11.08it/s, est. speed input: 6847.44 toks/s, output: 13.37 toks/s]
Processed prompts:  55%|    | 71/128 [00:05<00:05, 11.16it/s, est. speed input: 6813.47 toks/s, output: 13.31 toks/s]
Processed prompts:  57%|    | 73/128 [00:05<00:04, 11.21it/s, est. speed input: 6780.86 toks/s, output: 13.24 toks/s]
Processed prompts:  59%|    | 75/128 [00:05<00:04, 11.20it/s, est. speed input: 6747.69 toks/s, output: 13.18 toks/s]
Processed prompts:  60%|    | 77/128 [00:05<00:04, 11.22it/s, est. speed input: 6717.77 toks/s, output: 13.12 toks/s]
Processed prompts:  62%|   | 79/128 [00:06<00:04, 11.16it/s, est. speed input: 6685.68 toks/s, output: 13.06 toks/s]
Processed prompts:  63%|   | 81/128 [00:06<00:04, 11.17it/s, est. speed input: 6658.05 toks/s, output: 13.00 toks/s]
Processed prompts:  65%|   | 83/128 [00:06<00:04, 11.22it/s, est. speed input: 6634.51 toks/s, output: 12.96 toks/s]
Processed prompts:  66%|   | 85/128 [00:06<00:03, 11.28it/s, est. speed input: 6613.83 toks/s, output: 12.92 toks/s]
Processed prompts:  68%|   | 87/128 [00:06<00:03, 11.21it/s, est. speed input: 6588.43 toks/s, output: 12.87 toks/s]
Processed prompts:  70%|   | 89/128 [00:06<00:03, 11.31it/s, est. speed input: 6571.43 toks/s, output: 12.83 toks/s]
Processed prompts:  71%|   | 91/128 [00:07<00:03, 11.19it/s, est. speed input: 6546.10 toks/s, output: 12.79 toks/s]
Processed prompts:  73%|  | 93/128 [00:07<00:03, 11.19it/s, est. speed input: 6525.92 toks/s, output: 12.75 toks/s]
Processed prompts:  74%|  | 95/128 [00:07<00:02, 11.25it/s, est. speed input: 6509.70 toks/s, output: 12.71 toks/s]
Processed prompts:  76%|  | 97/128 [00:07<00:02, 11.25it/s, est. speed input: 6492.24 toks/s, output: 12.68 toks/s]
Processed prompts:  77%|  | 99/128 [00:07<00:02, 11.20it/s, est. speed input: 6473.70 toks/s, output: 12.64 toks/s]
Processed prompts:  79%|  | 101/128 [00:08<00:02, 11.18it/s, est. speed input: 6456.40 toks/s, output: 12.61 toks/s]
Processed prompts:  80%|  | 103/128 [00:08<00:02, 11.13it/s, est. speed input: 6438.27 toks/s, output: 12.57 toks/s]
Processed prompts:  82%| | 105/128 [00:08<00:02, 11.18it/s, est. speed input: 6424.28 toks/s, output: 12.55 toks/s]
Processed prompts:  84%| | 107/128 [00:08<00:01, 11.18it/s, est. speed input: 6409.61 toks/s, output: 12.52 toks/s]
Processed prompts:  85%| | 109/128 [00:08<00:01, 11.21it/s, est. speed input: 6396.92 toks/s, output: 12.49 toks/s]
Processed prompts:  87%| | 111/128 [00:08<00:01, 11.17it/s, est. speed input: 6382.14 toks/s, output: 12.47 toks/s]
Processed prompts:  88%| | 113/128 [00:09<00:01, 11.20it/s, est. speed input: 6370.29 toks/s, output: 12.44 toks/s]
Processed prompts:  90%| | 115/128 [00:09<00:01, 11.06it/s, est. speed input: 6352.96 toks/s, output: 12.41 toks/s]
Processed prompts:  91%|| 117/128 [00:09<00:00, 11.12it/s, est. speed input: 6341.70 toks/s, output: 12.39 toks/s]
Processed prompts:  93%|| 119/128 [00:09<00:00, 11.15it/s, est. speed input: 6330.60 toks/s, output: 12.36 toks/s]
Processed prompts:  95%|| 121/128 [00:09<00:00, 11.14it/s, est. speed input: 6318.90 toks/s, output: 12.34 toks/s]
Processed prompts:  96%|| 123/128 [00:09<00:00, 11.17it/s, est. speed input: 6308.85 toks/s, output: 12.32 toks/s]
Processed prompts:  98%|| 125/128 [00:10<00:00, 11.20it/s, est. speed input: 6299.45 toks/s, output: 12.30 toks/s]
Processed prompts:  99%|| 127/128 [00:10<00:00, 11.04it/s, est. speed input: 6284.54 toks/s, output: 12.27 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 11.04it/s, est. speed input: 6273.81 toks/s, output: 12.25 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 12.25it/s, est. speed input: 6273.81 toks/s, output: 12.25 toks/s]
[rank0]:[W126 15:20:49.559457279 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 15:21:02
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:21:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 15:21:06 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1437668) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1437668) WARNING 01-26 15:22:19 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 6.37 requests/s, 6525.70 total tokens/s, 6.37 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 15:21:06] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:21:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:21:06] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:21:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:21:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:21:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:21:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:21:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:21:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:21:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:21:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:21:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:21:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:21:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:21:10] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:21:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:21:10] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:21:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:21:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:21:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:21:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:21:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:21:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:21:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:21:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:21:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:21:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:21:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1437668) [2026-01-26 15:21:11] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1437668) [2026-01-26 15:21:11] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1437668) [2026-01-26 15:21:11] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1437668) [2026-01-26 15:21:11] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1437668) [2026-01-26 15:21:11] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1437668) [2026-01-26 15:21:11] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1437668) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1437668) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:24<00:24, 24.93s/it]
(EngineCore_DP0 pid=1437668) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:59<00:00, 30.58s/it]
(EngineCore_DP0 pid=1437668) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:59<00:00, 29.73s/it]
(EngineCore_DP0 pid=1437668) 
(EngineCore_DP0 pid=1437668) [2026-01-26 15:22:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1437668) [2026-01-26 15:22:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=1437668) [2026-01-26 15:22:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1437668) [2026-01-26 15:22:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=1437668) [2026-01-26 15:22:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1437668) [2026-01-26 15:22:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=1437668) [2026-01-26 15:22:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1437668) [2026-01-26 15:22:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=1437668) 2026-01-26 15:22:19,096 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1437668) 2026-01-26 15:22:19,129 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  23%|       | 30/128 [00:00<00:00, 294.21it/s]
Adding requests:  53%|    | 68/128 [00:00<00:00, 343.19it/s]
Adding requests:  80%|  | 103/128 [00:00<00:00, 341.97it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 339.04it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 3/128 [00:00<00:06, 18.26it/s, est. speed input: 18699.49 toks/s, output: 18.26 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:12,  9.63it/s, est. speed input: 10775.24 toks/s, output: 10.52 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:15,  7.90it/s, est. speed input: 9037.65 toks/s, output: 8.83 toks/s]  
Processed prompts:   6%|         | 8/128 [00:00<00:15,  7.51it/s, est. speed input: 8633.56 toks/s, output: 8.43 toks/s]
Processed prompts:   7%|         | 9/128 [00:01<00:16,  7.24it/s, est. speed input: 8357.93 toks/s, output: 8.16 toks/s]
Processed prompts:   8%|         | 10/128 [00:01<00:16,  6.97it/s, est. speed input: 8121.04 toks/s, output: 7.93 toks/s]
Processed prompts:   9%|         | 11/128 [00:01<00:17,  6.88it/s, est. speed input: 7978.18 toks/s, output: 7.79 toks/s]
Processed prompts:   9%|         | 12/128 [00:01<00:17,  6.76it/s, est. speed input: 7846.34 toks/s, output: 7.66 toks/s]
Processed prompts:  10%|         | 13/128 [00:01<00:17,  6.67it/s, est. speed input: 7733.72 toks/s, output: 7.55 toks/s]
Processed prompts:  11%|         | 14/128 [00:01<00:17,  6.52it/s, est. speed input: 7614.62 toks/s, output: 7.44 toks/s]
Processed prompts:  12%|        | 15/128 [00:02<00:17,  6.50it/s, est. speed input: 7538.05 toks/s, output: 7.36 toks/s]
Processed prompts:  12%|        | 16/128 [00:02<00:17,  6.47it/s, est. speed input: 7466.87 toks/s, output: 7.29 toks/s]
Processed prompts:  13%|        | 17/128 [00:02<00:17,  6.46it/s, est. speed input: 7408.76 toks/s, output: 7.24 toks/s]
Processed prompts:  14%|        | 18/128 [00:02<00:17,  6.45it/s, est. speed input: 7357.73 toks/s, output: 7.19 toks/s]
Processed prompts:  15%|        | 19/128 [00:02<00:16,  6.42it/s, est. speed input: 7307.16 toks/s, output: 7.14 toks/s]
Processed prompts:  16%|        | 20/128 [00:02<00:16,  6.35it/s, est. speed input: 7252.53 toks/s, output: 7.08 toks/s]
Processed prompts:  16%|        | 21/128 [00:02<00:16,  6.38it/s, est. speed input: 7218.43 toks/s, output: 7.05 toks/s]
Processed prompts:  17%|        | 22/128 [00:03<00:16,  6.40it/s, est. speed input: 7187.75 toks/s, output: 7.02 toks/s]
Processed prompts:  18%|        | 23/128 [00:03<00:16,  6.42it/s, est. speed input: 7160.44 toks/s, output: 6.99 toks/s]
Processed prompts:  19%|        | 24/128 [00:03<00:16,  6.41it/s, est. speed input: 7133.55 toks/s, output: 6.97 toks/s]
Processed prompts:  20%|        | 25/128 [00:03<00:16,  6.41it/s, est. speed input: 7107.57 toks/s, output: 6.94 toks/s]
Processed prompts:  20%|        | 26/128 [00:03<00:15,  6.41it/s, est. speed input: 7084.82 toks/s, output: 6.92 toks/s]
Processed prompts:  21%|        | 27/128 [00:03<00:15,  6.35it/s, est. speed input: 7056.39 toks/s, output: 6.89 toks/s]
Processed prompts:  22%|       | 28/128 [00:04<00:15,  6.35it/s, est. speed input: 7034.47 toks/s, output: 6.87 toks/s]
Processed prompts:  23%|       | 29/128 [00:04<00:15,  6.40it/s, est. speed input: 7022.12 toks/s, output: 6.86 toks/s]
Processed prompts:  23%|       | 30/128 [00:04<00:15,  6.43it/s, est. speed input: 7008.49 toks/s, output: 6.84 toks/s]
Processed prompts:  24%|       | 31/128 [00:04<00:15,  6.44it/s, est. speed input: 6995.62 toks/s, output: 6.83 toks/s]
Processed prompts:  25%|       | 32/128 [00:04<00:14,  6.42it/s, est. speed input: 6980.15 toks/s, output: 6.82 toks/s]
Processed prompts:  26%|       | 33/128 [00:04<00:14,  6.43it/s, est. speed input: 6967.99 toks/s, output: 6.80 toks/s]
Processed prompts:  27%|       | 34/128 [00:05<00:14,  6.35it/s, est. speed input: 6946.71 toks/s, output: 6.78 toks/s]
Processed prompts:  27%|       | 35/128 [00:05<00:14,  6.32it/s, est. speed input: 6930.39 toks/s, output: 6.77 toks/s]
Processed prompts:  28%|       | 36/128 [00:05<00:14,  6.36it/s, est. speed input: 6920.50 toks/s, output: 6.76 toks/s]
Processed prompts:  29%|       | 37/128 [00:05<00:14,  6.39it/s, est. speed input: 6912.49 toks/s, output: 6.75 toks/s]
Processed prompts:  30%|       | 38/128 [00:05<00:14,  6.42it/s, est. speed input: 6905.37 toks/s, output: 6.74 toks/s]
Processed prompts:  30%|       | 39/128 [00:05<00:13,  6.40it/s, est. speed input: 6894.08 toks/s, output: 6.73 toks/s]
Processed prompts:  31%|      | 40/128 [00:05<00:13,  6.40it/s, est. speed input: 6885.14 toks/s, output: 6.72 toks/s]
Processed prompts:  32%|      | 41/128 [00:06<00:13,  6.36it/s, est. speed input: 6872.97 toks/s, output: 6.71 toks/s]
Processed prompts:  33%|      | 42/128 [00:06<00:13,  6.35it/s, est. speed input: 6863.26 toks/s, output: 6.70 toks/s]
Processed prompts:  34%|      | 43/128 [00:06<00:13,  6.39it/s, est. speed input: 6858.02 toks/s, output: 6.70 toks/s]
Processed prompts:  34%|      | 44/128 [00:06<00:13,  6.39it/s, est. speed input: 6850.55 toks/s, output: 6.69 toks/s]
Processed prompts:  35%|      | 45/128 [00:06<00:12,  6.41it/s, est. speed input: 6844.76 toks/s, output: 6.68 toks/s]
Processed prompts:  36%|      | 46/128 [00:06<00:12,  6.38it/s, est. speed input: 6836.45 toks/s, output: 6.68 toks/s]
Processed prompts:  37%|      | 47/128 [00:07<00:12,  6.33it/s, est. speed input: 6825.46 toks/s, output: 6.67 toks/s]
Processed prompts:  38%|      | 48/128 [00:07<00:12,  6.36it/s, est. speed input: 6820.16 toks/s, output: 6.66 toks/s]
Processed prompts:  38%|      | 49/128 [00:07<00:12,  6.39it/s, est. speed input: 6816.10 toks/s, output: 6.66 toks/s]
Processed prompts:  39%|      | 50/128 [00:07<00:12,  6.41it/s, est. speed input: 6811.67 toks/s, output: 6.65 toks/s]
Processed prompts:  40%|      | 51/128 [00:07<00:12,  6.39it/s, est. speed input: 6805.12 toks/s, output: 6.65 toks/s]
Processed prompts:  41%|      | 52/128 [00:07<00:11,  6.43it/s, est. speed input: 6802.59 toks/s, output: 6.64 toks/s]
Processed prompts:  41%|     | 53/128 [00:07<00:11,  6.47it/s, est. speed input: 6801.39 toks/s, output: 6.64 toks/s]
Processed prompts:  42%|     | 54/128 [00:08<00:11,  6.38it/s, est. speed input: 6792.01 toks/s, output: 6.63 toks/s]
Processed prompts:  43%|     | 55/128 [00:08<00:11,  6.41it/s, est. speed input: 6788.88 toks/s, output: 6.63 toks/s]
Processed prompts:  44%|     | 56/128 [00:08<00:11,  6.43it/s, est. speed input: 6786.07 toks/s, output: 6.63 toks/s]
Processed prompts:  45%|     | 57/128 [00:08<00:10,  6.46it/s, est. speed input: 6784.25 toks/s, output: 6.63 toks/s]
Processed prompts:  45%|     | 58/128 [00:08<00:10,  6.46it/s, est. speed input: 6781.61 toks/s, output: 6.62 toks/s]
Processed prompts:  46%|     | 59/128 [00:08<00:10,  6.48it/s, est. speed input: 6779.65 toks/s, output: 6.62 toks/s]
Processed prompts:  47%|     | 60/128 [00:09<00:10,  6.48it/s, est. speed input: 6777.31 toks/s, output: 6.62 toks/s]
Processed prompts:  48%|     | 61/128 [00:09<00:10,  6.40it/s, est. speed input: 6770.02 toks/s, output: 6.61 toks/s]
Processed prompts:  48%|     | 62/128 [00:09<00:10,  6.42it/s, est. speed input: 6767.51 toks/s, output: 6.61 toks/s]
Processed prompts:  49%|     | 63/128 [00:09<00:10,  6.40it/s, est. speed input: 6763.29 toks/s, output: 6.60 toks/s]
Processed prompts:  50%|     | 64/128 [00:09<00:09,  6.41it/s, est. speed input: 6760.37 toks/s, output: 6.60 toks/s]
Processed prompts:  51%|     | 65/128 [00:09<00:09,  6.41it/s, est. speed input: 6757.28 toks/s, output: 6.60 toks/s]
Processed prompts:  52%|    | 66/128 [00:10<00:09,  6.43it/s, est. speed input: 6755.49 toks/s, output: 6.60 toks/s]
Processed prompts:  52%|    | 67/128 [00:10<00:09,  6.38it/s, est. speed input: 6750.30 toks/s, output: 6.59 toks/s]
Processed prompts:  53%|    | 68/128 [00:10<00:09,  6.35it/s, est. speed input: 6745.33 toks/s, output: 6.59 toks/s]
Processed prompts:  54%|    | 69/128 [00:10<00:09,  6.40it/s, est. speed input: 6744.11 toks/s, output: 6.59 toks/s]
Processed prompts:  55%|    | 70/128 [00:10<00:09,  6.39it/s, est. speed input: 6740.82 toks/s, output: 6.58 toks/s]
Processed prompts:  55%|    | 71/128 [00:10<00:08,  6.37it/s, est. speed input: 6737.11 toks/s, output: 6.58 toks/s]
Processed prompts:  56%|    | 72/128 [00:10<00:08,  6.36it/s, est. speed input: 6733.48 toks/s, output: 6.58 toks/s]
Processed prompts:  57%|    | 73/128 [00:11<00:08,  6.39it/s, est. speed input: 6731.59 toks/s, output: 6.57 toks/s]
Processed prompts:  58%|    | 74/128 [00:11<00:08,  6.32it/s, est. speed input: 6725.67 toks/s, output: 6.57 toks/s]
Processed prompts:  59%|    | 75/128 [00:11<00:08,  6.36it/s, est. speed input: 6724.14 toks/s, output: 6.57 toks/s]
Processed prompts:  59%|    | 76/128 [00:11<00:08,  6.38it/s, est. speed input: 6722.14 toks/s, output: 6.56 toks/s]
Processed prompts:  60%|    | 77/128 [00:11<00:07,  6.38it/s, est. speed input: 6719.72 toks/s, output: 6.56 toks/s]
Processed prompts:  61%|    | 78/128 [00:11<00:07,  6.39it/s, est. speed input: 6717.74 toks/s, output: 6.56 toks/s]
Processed prompts:  62%|   | 79/128 [00:12<00:07,  6.46it/s, est. speed input: 6718.39 toks/s, output: 6.56 toks/s]
Processed prompts:  62%|   | 80/128 [00:12<00:07,  6.45it/s, est. speed input: 6716.68 toks/s, output: 6.56 toks/s]
Processed prompts:  63%|   | 81/128 [00:12<00:07,  6.37it/s, est. speed input: 6711.64 toks/s, output: 6.55 toks/s]
Processed prompts:  64%|   | 82/128 [00:12<00:07,  6.40it/s, est. speed input: 6710.84 toks/s, output: 6.55 toks/s]
Processed prompts:  65%|   | 83/128 [00:12<00:07,  6.40it/s, est. speed input: 6708.70 toks/s, output: 6.55 toks/s]
Processed prompts:  66%|   | 84/128 [00:12<00:06,  6.39it/s, est. speed input: 6706.60 toks/s, output: 6.55 toks/s]
Processed prompts:  66%|   | 85/128 [00:12<00:06,  6.41it/s, est. speed input: 6705.30 toks/s, output: 6.55 toks/s]
Processed prompts:  67%|   | 86/128 [00:13<00:06,  6.43it/s, est. speed input: 6704.41 toks/s, output: 6.55 toks/s]
Processed prompts:  68%|   | 87/128 [00:13<00:06,  6.42it/s, est. speed input: 6702.53 toks/s, output: 6.55 toks/s]
Processed prompts:  69%|   | 88/128 [00:13<00:06,  6.34it/s, est. speed input: 6697.88 toks/s, output: 6.54 toks/s]
Processed prompts:  70%|   | 89/128 [00:13<00:06,  6.37it/s, est. speed input: 6696.83 toks/s, output: 6.54 toks/s]
Processed prompts:  70%|   | 90/128 [00:13<00:05,  6.38it/s, est. speed input: 6695.21 toks/s, output: 6.54 toks/s]
Processed prompts:  71%|   | 91/128 [00:13<00:05,  6.41it/s, est. speed input: 6694.64 toks/s, output: 6.54 toks/s]
Processed prompts:  72%|  | 92/128 [00:14<00:05,  6.41it/s, est. speed input: 6693.04 toks/s, output: 6.54 toks/s]
Processed prompts:  73%|  | 93/128 [00:14<00:05,  6.40it/s, est. speed input: 6691.25 toks/s, output: 6.53 toks/s]
Processed prompts:  73%|  | 94/128 [00:14<00:05,  6.31it/s, est. speed input: 6686.27 toks/s, output: 6.53 toks/s]
Processed prompts:  74%|  | 95/128 [00:14<00:05,  6.31it/s, est. speed input: 6683.67 toks/s, output: 6.53 toks/s]
Processed prompts:  75%|  | 96/128 [00:14<00:05,  6.36it/s, est. speed input: 6683.41 toks/s, output: 6.53 toks/s]
Processed prompts:  76%|  | 97/128 [00:14<00:04,  6.37it/s, est. speed input: 6681.88 toks/s, output: 6.53 toks/s]
Processed prompts:  77%|  | 98/128 [00:15<00:04,  6.39it/s, est. speed input: 6680.85 toks/s, output: 6.52 toks/s]
Processed prompts:  77%|  | 99/128 [00:15<00:04,  6.40it/s, est. speed input: 6679.98 toks/s, output: 6.52 toks/s]
Processed prompts:  78%|  | 100/128 [00:15<00:04,  6.42it/s, est. speed input: 6679.24 toks/s, output: 6.52 toks/s]
Processed prompts:  79%|  | 101/128 [00:15<00:04,  6.33it/s, est. speed input: 6675.00 toks/s, output: 6.52 toks/s]
Processed prompts:  80%|  | 102/128 [00:15<00:04,  6.38it/s, est. speed input: 6674.87 toks/s, output: 6.52 toks/s]
Processed prompts:  80%|  | 103/128 [00:15<00:03,  6.40it/s, est. speed input: 6673.99 toks/s, output: 6.52 toks/s]
Processed prompts:  81%| | 104/128 [00:15<00:03,  6.43it/s, est. speed input: 6673.92 toks/s, output: 6.52 toks/s]
Processed prompts:  82%| | 105/128 [00:16<00:03,  6.43it/s, est. speed input: 6673.05 toks/s, output: 6.52 toks/s]
Processed prompts:  83%| | 106/128 [00:16<00:03,  6.44it/s, est. speed input: 6672.50 toks/s, output: 6.52 toks/s]
Processed prompts:  84%| | 107/128 [00:16<00:03,  6.44it/s, est. speed input: 6671.90 toks/s, output: 6.52 toks/s]
Processed prompts:  84%| | 108/128 [00:16<00:03,  6.33it/s, est. speed input: 6667.46 toks/s, output: 6.51 toks/s]
Processed prompts:  85%| | 109/128 [00:16<00:02,  6.34it/s, est. speed input: 6666.11 toks/s, output: 6.51 toks/s]
Processed prompts:  86%| | 110/128 [00:16<00:02,  6.34it/s, est. speed input: 6664.61 toks/s, output: 6.51 toks/s]
Processed prompts:  87%| | 111/128 [00:17<00:02,  6.39it/s, est. speed input: 6664.51 toks/s, output: 6.51 toks/s]
Processed prompts:  88%| | 112/128 [00:17<00:02,  6.37it/s, est. speed input: 6662.72 toks/s, output: 6.51 toks/s]
Processed prompts:  88%| | 113/128 [00:17<00:02,  6.42it/s, est. speed input: 6662.94 toks/s, output: 6.51 toks/s]
Processed prompts:  89%| | 114/128 [00:17<00:02,  6.34it/s, est. speed input: 6659.64 toks/s, output: 6.50 toks/s]
Processed prompts:  90%| | 115/128 [00:17<00:02,  6.35it/s, est. speed input: 6658.63 toks/s, output: 6.50 toks/s]
Processed prompts:  91%| | 116/128 [00:17<00:01,  6.38it/s, est. speed input: 6658.14 toks/s, output: 6.50 toks/s]
Processed prompts:  91%|| 117/128 [00:17<00:01,  6.41it/s, est. speed input: 6657.97 toks/s, output: 6.50 toks/s]
Processed prompts:  92%|| 118/128 [00:18<00:01,  6.39it/s, est. speed input: 6656.41 toks/s, output: 6.50 toks/s]
Processed prompts:  93%|| 119/128 [00:18<00:01,  6.40it/s, est. speed input: 6655.92 toks/s, output: 6.50 toks/s]
Processed prompts:  94%|| 120/128 [00:18<00:01,  6.40it/s, est. speed input: 6655.08 toks/s, output: 6.50 toks/s]
Processed prompts:  95%|| 121/128 [00:18<00:01,  6.32it/s, est. speed input: 6651.77 toks/s, output: 6.50 toks/s]
Processed prompts:  95%|| 122/128 [00:18<00:00,  6.32it/s, est. speed input: 6650.26 toks/s, output: 6.49 toks/s]
Processed prompts:  96%|| 123/128 [00:18<00:00,  6.36it/s, est. speed input: 6649.84 toks/s, output: 6.49 toks/s]
Processed prompts:  97%|| 124/128 [00:19<00:00,  6.38it/s, est. speed input: 6649.46 toks/s, output: 6.49 toks/s]
Processed prompts:  98%|| 125/128 [00:19<00:00,  6.36it/s, est. speed input: 6647.99 toks/s, output: 6.49 toks/s]
Processed prompts:  98%|| 126/128 [00:19<00:00,  6.40it/s, est. speed input: 6648.03 toks/s, output: 6.49 toks/s]
Processed prompts:  99%|| 127/128 [00:19<00:00,  6.41it/s, est. speed input: 6647.51 toks/s, output: 6.49 toks/s]
Processed prompts: 100%|| 128/128 [00:19<00:00,  6.34it/s, est. speed input: 6644.76 toks/s, output: 6.49 toks/s]
Processed prompts: 100%|| 128/128 [00:19<00:00,  6.34it/s, est. speed input: 6644.76 toks/s, output: 6.49 toks/s]
Processed prompts: 100%|| 128/128 [00:19<00:00,  6.49it/s, est. speed input: 6644.76 toks/s, output: 6.49 toks/s]
[rank0]:[W126 15:22:40.381264062 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 15:22:42
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:22:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 15:22:47 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1439256) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1439256) WARNING 01-26 15:24:00 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 6.44 requests/s, 6598.71 total tokens/s, 6.44 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 15:22:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:22:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:22:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:22:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:22:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:22:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:22:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:22:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:22:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:22:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:22:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:22:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:22:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:22:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:22:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:22:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:22:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:22:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:22:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:22:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:22:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:22:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:22:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:22:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:22:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:22:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:22:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:22:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1439256) [2026-01-26 15:22:51] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1439256) [2026-01-26 15:22:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1439256) [2026-01-26 15:22:51] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1439256) [2026-01-26 15:22:51] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1439256) [2026-01-26 15:22:51] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1439256) [2026-01-26 15:22:51] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1439256) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1439256) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:24<00:24, 24.69s/it]
(EngineCore_DP0 pid=1439256) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:59<00:00, 30.41s/it]
(EngineCore_DP0 pid=1439256) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:59<00:00, 29.55s/it]
(EngineCore_DP0 pid=1439256) 
(EngineCore_DP0 pid=1439256) [2026-01-26 15:23:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1439256) [2026-01-26 15:23:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=1439256) [2026-01-26 15:23:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1439256) [2026-01-26 15:23:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=1439256) [2026-01-26 15:23:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1439256) [2026-01-26 15:23:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=1439256) [2026-01-26 15:23:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1439256) [2026-01-26 15:23:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=1439256) 2026-01-26 15:23:59,259 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1439256) 2026-01-26 15:23:59,330 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  11%|         | 28/256 [00:00<00:00, 269.54it/s]
Adding requests:  25%|       | 64/256 [00:00<00:00, 318.07it/s]
Adding requests:  40%|      | 102/256 [00:00<00:00, 345.22it/s]
Adding requests:  55%|    | 140/256 [00:00<00:00, 358.65it/s]
Adding requests:  71%|   | 181/256 [00:00<00:00, 376.80it/s]
Adding requests:  87%| | 223/256 [00:00<00:00, 389.63it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 369.54it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 4/256 [00:00<00:11, 22.32it/s, est. speed input: 22854.78 toks/s, output: 22.32 toks/s]
Processed prompts:   3%|         | 7/256 [00:00<00:18, 13.33it/s, est. speed input: 14658.88 toks/s, output: 14.32 toks/s]
Processed prompts:   4%|         | 9/256 [00:00<00:24,  9.89it/s, est. speed input: 11564.35 toks/s, output: 11.29 toks/s]
Processed prompts:   4%|         | 11/256 [00:01<00:28,  8.54it/s, est. speed input: 10246.56 toks/s, output: 10.01 toks/s]
Processed prompts:   5%|         | 12/256 [00:01<00:37,  6.54it/s, est. speed input: 8720.68 toks/s, output: 8.52 toks/s]  
Processed prompts:   5%|         | 14/256 [00:01<00:37,  6.53it/s, est. speed input: 8357.01 toks/s, output: 8.16 toks/s]
Processed prompts:   6%|         | 16/256 [00:02<00:36,  6.52it/s, est. speed input: 8095.02 toks/s, output: 7.91 toks/s]
Processed prompts:   7%|         | 18/256 [00:02<00:36,  6.44it/s, est. speed input: 7871.13 toks/s, output: 7.69 toks/s]
Processed prompts:   8%|         | 20/256 [00:02<00:36,  6.45it/s, est. speed input: 7726.49 toks/s, output: 7.55 toks/s]
Processed prompts:   9%|         | 22/256 [00:02<00:36,  6.46it/s, est. speed input: 7611.54 toks/s, output: 7.43 toks/s]
Processed prompts:   9%|         | 24/256 [00:03<00:35,  6.46it/s, est. speed input: 7519.25 toks/s, output: 7.34 toks/s]
Processed prompts:  10%|         | 26/256 [00:03<00:35,  6.45it/s, est. speed input: 7435.99 toks/s, output: 7.26 toks/s]
Processed prompts:  11%|         | 28/256 [00:03<00:35,  6.45it/s, est. speed input: 7369.84 toks/s, output: 7.20 toks/s]
Processed prompts:  12%|        | 30/256 [00:04<00:34,  6.49it/s, est. speed input: 7324.45 toks/s, output: 7.15 toks/s]
Processed prompts:  12%|        | 32/256 [00:04<00:34,  6.46it/s, est. speed input: 7270.68 toks/s, output: 7.10 toks/s]
Processed prompts:  13%|        | 34/256 [00:04<00:34,  6.49it/s, est. speed input: 7234.91 toks/s, output: 7.07 toks/s]
Processed prompts:  14%|        | 36/256 [00:05<00:33,  6.51it/s, est. speed input: 7203.81 toks/s, output: 7.03 toks/s]
Processed prompts:  15%|        | 38/256 [00:05<00:33,  6.45it/s, est. speed input: 7161.92 toks/s, output: 6.99 toks/s]
Processed prompts:  16%|        | 40/256 [00:05<00:33,  6.47it/s, est. speed input: 7136.20 toks/s, output: 6.97 toks/s]
Processed prompts:  16%|        | 42/256 [00:06<00:33,  6.47it/s, est. speed input: 7109.93 toks/s, output: 6.94 toks/s]
Processed prompts:  17%|        | 44/256 [00:06<00:32,  6.50it/s, est. speed input: 7091.44 toks/s, output: 6.93 toks/s]
Processed prompts:  18%|        | 46/256 [00:06<00:32,  6.48it/s, est. speed input: 7067.91 toks/s, output: 6.90 toks/s]
Processed prompts:  19%|        | 48/256 [00:06<00:31,  6.52it/s, est. speed input: 7054.70 toks/s, output: 6.89 toks/s]
Processed prompts:  20%|        | 50/256 [00:07<00:31,  6.52it/s, est. speed input: 7038.92 toks/s, output: 6.87 toks/s]
Processed prompts:  20%|        | 52/256 [00:07<00:31,  6.47it/s, est. speed input: 7017.39 toks/s, output: 6.85 toks/s]
Processed prompts:  21%|        | 54/256 [00:07<00:31,  6.51it/s, est. speed input: 7007.97 toks/s, output: 6.84 toks/s]
Processed prompts:  22%|       | 56/256 [00:08<00:30,  6.50it/s, est. speed input: 6993.34 toks/s, output: 6.83 toks/s]
Processed prompts:  23%|       | 58/256 [00:08<00:30,  6.50it/s, est. speed input: 6980.63 toks/s, output: 6.82 toks/s]
Processed prompts:  23%|       | 60/256 [00:08<00:30,  6.49it/s, est. speed input: 6968.03 toks/s, output: 6.80 toks/s]
Processed prompts:  24%|       | 62/256 [00:09<00:29,  6.48it/s, est. speed input: 6956.70 toks/s, output: 6.79 toks/s]
Processed prompts:  25%|       | 64/256 [00:09<00:29,  6.48it/s, est. speed input: 6945.76 toks/s, output: 6.78 toks/s]
Processed prompts:  26%|       | 66/256 [00:09<00:29,  6.40it/s, est. speed input: 6927.27 toks/s, output: 6.76 toks/s]
Processed prompts:  27%|       | 68/256 [00:10<00:29,  6.42it/s, est. speed input: 6917.12 toks/s, output: 6.75 toks/s]
Processed prompts:  27%|       | 70/256 [00:10<00:28,  6.46it/s, est. speed input: 6911.27 toks/s, output: 6.75 toks/s]
Processed prompts:  28%|       | 72/256 [00:10<00:28,  6.48it/s, est. speed input: 6904.56 toks/s, output: 6.74 toks/s]
Processed prompts:  29%|       | 74/256 [00:10<00:28,  6.42it/s, est. speed input: 6891.49 toks/s, output: 6.73 toks/s]
Processed prompts:  30%|       | 76/256 [00:11<00:27,  6.44it/s, est. speed input: 6884.48 toks/s, output: 6.72 toks/s]
Processed prompts:  30%|       | 78/256 [00:11<00:27,  6.47it/s, est. speed input: 6879.38 toks/s, output: 6.72 toks/s]
Processed prompts:  31%|      | 80/256 [00:11<00:27,  6.43it/s, est. speed input: 6868.80 toks/s, output: 6.71 toks/s]
Processed prompts:  32%|      | 82/256 [00:12<00:26,  6.45it/s, est. speed input: 6863.93 toks/s, output: 6.70 toks/s]
Processed prompts:  33%|      | 84/256 [00:12<00:26,  6.44it/s, est. speed input: 6856.89 toks/s, output: 6.70 toks/s]
Processed prompts:  34%|      | 86/256 [00:12<00:26,  6.40it/s, est. speed input: 6847.12 toks/s, output: 6.69 toks/s]
Processed prompts:  34%|      | 88/256 [00:13<00:26,  6.41it/s, est. speed input: 6840.50 toks/s, output: 6.68 toks/s]
Processed prompts:  35%|      | 90/256 [00:13<00:25,  6.41it/s, est. speed input: 6834.38 toks/s, output: 6.67 toks/s]
Processed prompts:  36%|      | 92/256 [00:13<00:25,  6.46it/s, est. speed input: 6831.90 toks/s, output: 6.67 toks/s]
Processed prompts:  37%|      | 94/256 [00:14<00:25,  6.41it/s, est. speed input: 6823.75 toks/s, output: 6.66 toks/s]
Processed prompts:  38%|      | 96/256 [00:14<00:24,  6.42it/s, est. speed input: 6819.06 toks/s, output: 6.66 toks/s]
Processed prompts:  38%|      | 98/256 [00:14<00:24,  6.44it/s, est. speed input: 6814.97 toks/s, output: 6.66 toks/s]
Processed prompts:  39%|      | 100/256 [00:15<00:24,  6.40it/s, est. speed input: 6807.59 toks/s, output: 6.65 toks/s]
Processed prompts:  40%|      | 102/256 [00:15<00:23,  6.44it/s, est. speed input: 6805.02 toks/s, output: 6.65 toks/s]
Processed prompts:  41%|      | 104/256 [00:15<00:23,  6.44it/s, est. speed input: 6801.31 toks/s, output: 6.64 toks/s]
Processed prompts:  41%|     | 106/256 [00:15<00:23,  6.46it/s, est. speed input: 6798.73 toks/s, output: 6.64 toks/s]
Processed prompts:  42%|     | 108/256 [00:16<00:22,  6.44it/s, est. speed input: 6793.98 toks/s, output: 6.63 toks/s]
Processed prompts:  43%|     | 110/256 [00:16<00:22,  6.43it/s, est. speed input: 6789.43 toks/s, output: 6.63 toks/s]
Processed prompts:  44%|     | 112/256 [00:16<00:22,  6.43it/s, est. speed input: 6785.82 toks/s, output: 6.63 toks/s]
Processed prompts:  45%|     | 114/256 [00:17<00:22,  6.41it/s, est. speed input: 6780.66 toks/s, output: 6.62 toks/s]
Processed prompts:  45%|     | 116/256 [00:17<00:21,  6.46it/s, est. speed input: 6780.29 toks/s, output: 6.62 toks/s]
Processed prompts:  46%|     | 118/256 [00:17<00:21,  6.46it/s, est. speed input: 6777.44 toks/s, output: 6.62 toks/s]
Processed prompts:  47%|     | 120/256 [00:18<00:21,  6.42it/s, est. speed input: 6772.24 toks/s, output: 6.61 toks/s]
Processed prompts:  48%|     | 122/256 [00:18<00:20,  6.46it/s, est. speed input: 6771.16 toks/s, output: 6.61 toks/s]
Processed prompts:  48%|     | 124/256 [00:18<00:20,  6.49it/s, est. speed input: 6770.02 toks/s, output: 6.61 toks/s]
Processed prompts:  49%|     | 126/256 [00:19<00:20,  6.45it/s, est. speed input: 6765.71 toks/s, output: 6.61 toks/s]
Processed prompts:  50%|     | 128/256 [00:19<00:20,  6.40it/s, est. speed input: 6760.36 toks/s, output: 6.60 toks/s]
Processed prompts:  51%|     | 130/256 [00:19<00:19,  6.40it/s, est. speed input: 6757.31 toks/s, output: 6.60 toks/s]
Processed prompts:  52%|    | 132/256 [00:20<00:19,  6.42it/s, est. speed input: 6755.04 toks/s, output: 6.60 toks/s]
Processed prompts:  52%|    | 134/256 [00:20<00:19,  6.40it/s, est. speed input: 6751.48 toks/s, output: 6.59 toks/s]
Processed prompts:  53%|    | 136/256 [00:20<00:18,  6.44it/s, est. speed input: 6750.21 toks/s, output: 6.59 toks/s]
Processed prompts:  54%|    | 138/256 [00:20<00:18,  6.42it/s, est. speed input: 6746.97 toks/s, output: 6.59 toks/s]
Processed prompts:  55%|    | 140/256 [00:21<00:18,  6.40it/s, est. speed input: 6743.40 toks/s, output: 6.59 toks/s]
Processed prompts:  55%|    | 142/256 [00:21<00:17,  6.40it/s, est. speed input: 6740.58 toks/s, output: 6.58 toks/s]
Processed prompts:  56%|    | 144/256 [00:21<00:17,  6.43it/s, est. speed input: 6739.49 toks/s, output: 6.58 toks/s]
Processed prompts:  57%|    | 146/256 [00:22<00:17,  6.42it/s, est. speed input: 6736.69 toks/s, output: 6.58 toks/s]
Processed prompts:  58%|    | 148/256 [00:22<00:16,  6.38it/s, est. speed input: 6732.57 toks/s, output: 6.57 toks/s]
Processed prompts:  59%|    | 150/256 [00:22<00:16,  6.38it/s, est. speed input: 6729.98 toks/s, output: 6.57 toks/s]
Processed prompts:  59%|    | 152/256 [00:23<00:16,  6.41it/s, est. speed input: 6728.54 toks/s, output: 6.57 toks/s]
Processed prompts:  60%|    | 154/256 [00:23<00:15,  6.39it/s, est. speed input: 6725.51 toks/s, output: 6.57 toks/s]
Processed prompts:  61%|    | 156/256 [00:23<00:15,  6.42it/s, est. speed input: 6724.48 toks/s, output: 6.57 toks/s]
Processed prompts:  62%|   | 158/256 [00:24<00:15,  6.43it/s, est. speed input: 6723.01 toks/s, output: 6.57 toks/s]
Processed prompts:  62%|   | 160/256 [00:24<00:14,  6.44it/s, est. speed input: 6721.64 toks/s, output: 6.56 toks/s]
Processed prompts:  63%|   | 162/256 [00:24<00:14,  6.41it/s, est. speed input: 6718.84 toks/s, output: 6.56 toks/s]
Processed prompts:  64%|   | 164/256 [00:25<00:14,  6.40it/s, est. speed input: 6716.61 toks/s, output: 6.56 toks/s]
Processed prompts:  65%|   | 166/256 [00:25<00:14,  6.42it/s, est. speed input: 6715.25 toks/s, output: 6.56 toks/s]
Processed prompts:  66%|   | 168/256 [00:25<00:13,  6.40it/s, est. speed input: 6712.65 toks/s, output: 6.56 toks/s]
Processed prompts:  66%|   | 170/256 [00:25<00:13,  6.43it/s, est. speed input: 6711.85 toks/s, output: 6.55 toks/s]
Processed prompts:  67%|   | 172/256 [00:26<00:13,  6.42it/s, est. speed input: 6710.05 toks/s, output: 6.55 toks/s]
Processed prompts:  68%|   | 174/256 [00:26<00:12,  6.42it/s, est. speed input: 6708.26 toks/s, output: 6.55 toks/s]
Processed prompts:  69%|   | 176/256 [00:26<00:12,  6.45it/s, est. speed input: 6708.19 toks/s, output: 6.55 toks/s]
Processed prompts:  70%|   | 178/256 [00:27<00:12,  6.46it/s, est. speed input: 6707.14 toks/s, output: 6.55 toks/s]
Processed prompts:  70%|   | 180/256 [00:27<00:11,  6.46it/s, est. speed input: 6706.03 toks/s, output: 6.55 toks/s]
Processed prompts:  71%|   | 182/256 [00:27<00:11,  6.44it/s, est. speed input: 6704.47 toks/s, output: 6.55 toks/s]
Processed prompts:  72%|  | 184/256 [00:28<00:11,  6.43it/s, est. speed input: 6702.74 toks/s, output: 6.55 toks/s]
Processed prompts:  73%|  | 186/256 [00:28<00:10,  6.46it/s, est. speed input: 6702.77 toks/s, output: 6.55 toks/s]
Processed prompts:  73%|  | 188/256 [00:28<00:10,  6.42it/s, est. speed input: 6700.37 toks/s, output: 6.54 toks/s]
Processed prompts:  74%|  | 190/256 [00:29<00:10,  6.44it/s, est. speed input: 6699.54 toks/s, output: 6.54 toks/s]
Processed prompts:  75%|  | 192/256 [00:29<00:09,  6.46it/s, est. speed input: 6699.31 toks/s, output: 6.54 toks/s]
Processed prompts:  76%|  | 194/256 [00:29<00:09,  6.47it/s, est. speed input: 6698.73 toks/s, output: 6.54 toks/s]
Processed prompts:  77%|  | 196/256 [00:29<00:09,  6.44it/s, est. speed input: 6696.83 toks/s, output: 6.54 toks/s]
Processed prompts:  77%|  | 198/256 [00:30<00:08,  6.47it/s, est. speed input: 6696.96 toks/s, output: 6.54 toks/s]
Processed prompts:  78%|  | 200/256 [00:30<00:08,  6.45it/s, est. speed input: 6695.62 toks/s, output: 6.54 toks/s]
Processed prompts:  79%|  | 202/256 [00:30<00:07,  7.18it/s, est. speed input: 6717.49 toks/s, output: 6.56 toks/s]
Processed prompts:  80%|  | 204/256 [00:31<00:07,  7.01it/s, est. speed input: 6718.16 toks/s, output: 6.56 toks/s]
Processed prompts:  80%|  | 206/256 [00:31<00:07,  6.57it/s, est. speed input: 6708.74 toks/s, output: 6.55 toks/s]
Processed prompts:  81%| | 208/256 [00:31<00:07,  6.55it/s, est. speed input: 6708.25 toks/s, output: 6.55 toks/s]
Processed prompts:  82%| | 210/256 [00:32<00:07,  6.45it/s, est. speed input: 6704.94 toks/s, output: 6.55 toks/s]
Processed prompts:  83%| | 212/256 [00:32<00:06,  6.43it/s, est. speed input: 6703.31 toks/s, output: 6.55 toks/s]
Processed prompts:  84%| | 214/256 [00:32<00:06,  6.46it/s, est. speed input: 6703.22 toks/s, output: 6.55 toks/s]
Processed prompts:  84%| | 216/256 [00:33<00:06,  6.40it/s, est. speed input: 6700.49 toks/s, output: 6.54 toks/s]
Processed prompts:  85%| | 218/256 [00:33<00:05,  6.43it/s, est. speed input: 6700.13 toks/s, output: 6.54 toks/s]
Processed prompts:  86%| | 220/256 [00:33<00:05,  6.46it/s, est. speed input: 6699.88 toks/s, output: 6.54 toks/s]
Processed prompts:  87%| | 222/256 [00:33<00:05,  6.46it/s, est. speed input: 6699.22 toks/s, output: 6.54 toks/s]
Processed prompts:  88%| | 224/256 [00:34<00:04,  6.48it/s, est. speed input: 6698.90 toks/s, output: 6.54 toks/s]
Processed prompts:  88%| | 226/256 [00:34<00:04,  6.45it/s, est. speed input: 6697.61 toks/s, output: 6.54 toks/s]
Processed prompts:  89%| | 228/256 [00:34<00:04,  6.47it/s, est. speed input: 6697.46 toks/s, output: 6.54 toks/s]
Processed prompts:  90%| | 230/256 [00:35<00:04,  6.45it/s, est. speed input: 6696.20 toks/s, output: 6.54 toks/s]
Processed prompts:  91%| | 232/256 [00:35<00:03,  6.48it/s, est. speed input: 6696.19 toks/s, output: 6.54 toks/s]
Processed prompts:  91%|| 234/256 [00:35<00:03,  6.48it/s, est. speed input: 6695.61 toks/s, output: 6.54 toks/s]
Processed prompts:  92%|| 236/256 [00:36<00:03,  6.43it/s, est. speed input: 6693.58 toks/s, output: 6.54 toks/s]
Processed prompts:  93%|| 238/256 [00:36<00:02,  6.44it/s, est. speed input: 6693.06 toks/s, output: 6.54 toks/s]
Processed prompts:  94%|| 240/256 [00:36<00:02,  6.42it/s, est. speed input: 6691.53 toks/s, output: 6.53 toks/s]
Processed prompts:  95%|| 242/256 [00:37<00:02,  6.39it/s, est. speed input: 6689.69 toks/s, output: 6.53 toks/s]
Processed prompts:  95%|| 244/256 [00:37<00:01,  6.38it/s, est. speed input: 6688.27 toks/s, output: 6.53 toks/s]
Processed prompts:  96%|| 246/256 [00:37<00:01,  6.42it/s, est. speed input: 6687.94 toks/s, output: 6.53 toks/s]
Processed prompts:  97%|| 248/256 [00:37<00:01,  6.43it/s, est. speed input: 6687.26 toks/s, output: 6.53 toks/s]
Processed prompts:  98%|| 250/256 [00:38<00:00,  6.39it/s, est. speed input: 6685.50 toks/s, output: 6.53 toks/s]
Processed prompts:  98%|| 252/256 [00:38<00:00,  6.39it/s, est. speed input: 6684.33 toks/s, output: 6.53 toks/s]
Processed prompts:  99%|| 254/256 [00:38<00:00,  6.41it/s, est. speed input: 6683.68 toks/s, output: 6.53 toks/s]
Processed prompts: 100%|| 256/256 [00:39<00:00,  7.54it/s, est. speed input: 6709.37 toks/s, output: 6.55 toks/s]
Processed prompts: 100%|| 256/256 [00:39<00:00,  7.54it/s, est. speed input: 6709.37 toks/s, output: 6.55 toks/s]
Processed prompts: 100%|| 256/256 [00:39<00:00,  6.55it/s, est. speed input: 6709.37 toks/s, output: 6.55 toks/s]
[rank0]:[W126 15:24:40.466024224 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 15:24:42
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:24:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 15:24:48 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1441129) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1441129) WARNING 01-26 15:26:01 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 6.28 requests/s, 6438.48 total tokens/s, 6.28 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 15:24:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:24:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:24:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:24:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:24:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:24:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:24:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:24:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:24:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:24:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:24:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:24:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:24:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:24:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:24:51] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:24:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:24:51] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:24:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:24:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:24:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:24:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:24:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:24:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:24:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:24:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:24:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:24:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:24:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1441129) [2026-01-26 15:24:52] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1441129) [2026-01-26 15:24:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1441129) [2026-01-26 15:24:52] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1441129) [2026-01-26 15:24:52] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1441129) [2026-01-26 15:24:52] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1441129) [2026-01-26 15:24:52] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1441129) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1441129) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:24<00:24, 24.69s/it]
(EngineCore_DP0 pid=1441129) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:58<00:00, 30.27s/it]
(EngineCore_DP0 pid=1441129) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:58<00:00, 29.43s/it]
(EngineCore_DP0 pid=1441129) 
(EngineCore_DP0 pid=1441129) [2026-01-26 15:25:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1441129) [2026-01-26 15:25:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=1441129) [2026-01-26 15:25:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1441129) [2026-01-26 15:25:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=1441129) [2026-01-26 15:25:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1441129) [2026-01-26 15:25:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=1441129) [2026-01-26 15:25:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1441129) [2026-01-26 15:25:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=1441129) 2026-01-26 15:25:59,952 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1441129) 2026-01-26 15:26:00,080 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   8%|         | 41/512 [00:00<00:01, 409.28it/s]
Adding requests:  16%|        | 82/512 [00:00<00:01, 397.19it/s]
Adding requests:  24%|       | 123/512 [00:00<00:00, 402.06it/s]
Adding requests:  32%|      | 165/512 [00:00<00:00, 406.62it/s]
Adding requests:  41%|      | 210/512 [00:00<00:00, 421.10it/s]
Adding requests:  50%|     | 254/512 [00:00<00:00, 424.14it/s]
Adding requests:  58%|    | 298/512 [00:00<00:00, 427.54it/s]
Adding requests:  67%|   | 344/512 [00:00<00:00, 435.58it/s]
Adding requests:  76%|  | 389/512 [00:00<00:00, 437.81it/s]
Adding requests:  85%| | 434/512 [00:01<00:00, 441.51it/s]
Adding requests:  94%|| 479/512 [00:01<00:00, 435.03it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 428.11it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 6/512 [00:00<00:26, 18.97it/s, est. speed input: 19425.33 toks/s, output: 18.97 toks/s]
Processed prompts:   2%|         | 10/512 [00:00<00:52,  9.53it/s, est. speed input: 10722.56 toks/s, output: 10.47 toks/s]
Processed prompts:   3%|         | 14/512 [00:01<01:02,  7.91it/s, est. speed input: 9052.02 toks/s, output: 8.84 toks/s]  
Processed prompts:   4%|         | 18/512 [00:02<01:08,  7.23it/s, est. speed input: 8310.19 toks/s, output: 8.12 toks/s]
Processed prompts:   4%|         | 22/512 [00:02<01:11,  6.88it/s, est. speed input: 7893.25 toks/s, output: 7.71 toks/s]
Processed prompts:   5%|         | 26/512 [00:03<01:12,  6.69it/s, est. speed input: 7641.51 toks/s, output: 7.46 toks/s]
Processed prompts:   6%|         | 30/512 [00:04<01:13,  6.57it/s, est. speed input: 7460.89 toks/s, output: 7.29 toks/s]
Processed prompts:   7%|         | 34/512 [00:04<01:13,  6.51it/s, est. speed input: 7338.48 toks/s, output: 7.17 toks/s]
Processed prompts:   7%|         | 38/512 [00:05<01:13,  6.43it/s, est. speed input: 7226.95 toks/s, output: 7.06 toks/s]
Processed prompts:   8%|         | 42/512 [00:06<01:13,  6.39it/s, est. speed input: 7144.73 toks/s, output: 6.98 toks/s]
Processed prompts:   9%|         | 46/512 [00:06<01:13,  6.37it/s, est. speed input: 7082.57 toks/s, output: 6.92 toks/s]
Processed prompts:  10%|         | 50/512 [00:07<01:12,  6.34it/s, est. speed input: 7025.50 toks/s, output: 6.86 toks/s]
Processed prompts:  11%|         | 54/512 [00:07<01:11,  6.37it/s, est. speed input: 6991.48 toks/s, output: 6.83 toks/s]
Processed prompts:  11%|        | 58/512 [00:08<01:11,  6.34it/s, est. speed input: 6947.85 toks/s, output: 6.79 toks/s]
Processed prompts:  12%|        | 62/512 [00:09<01:11,  6.31it/s, est. speed input: 6909.65 toks/s, output: 6.75 toks/s]
Processed prompts:  13%|        | 66/512 [00:09<01:10,  6.31it/s, est. speed input: 6880.03 toks/s, output: 6.72 toks/s]
Processed prompts:  14%|        | 70/512 [00:10<01:10,  6.30it/s, est. speed input: 6852.48 toks/s, output: 6.69 toks/s]
Processed prompts:  14%|        | 74/512 [00:11<01:09,  6.32it/s, est. speed input: 6833.77 toks/s, output: 6.67 toks/s]
Processed prompts:  15%|        | 78/512 [00:11<01:08,  6.31it/s, est. speed input: 6811.64 toks/s, output: 6.65 toks/s]
Processed prompts:  16%|        | 82/512 [00:12<01:08,  6.29it/s, est. speed input: 6790.01 toks/s, output: 6.63 toks/s]
Processed prompts:  17%|        | 86/512 [00:12<01:07,  6.31it/s, est. speed input: 6776.85 toks/s, output: 6.62 toks/s]
Processed prompts:  18%|        | 90/512 [00:13<01:07,  6.29it/s, est. speed input: 6757.98 toks/s, output: 6.60 toks/s]
Processed prompts:  18%|        | 94/512 [00:14<01:06,  6.32it/s, est. speed input: 6749.53 toks/s, output: 6.59 toks/s]
Processed prompts:  19%|        | 98/512 [00:14<01:05,  6.31it/s, est. speed input: 6736.50 toks/s, output: 6.58 toks/s]
Processed prompts:  20%|        | 102/512 [00:15<01:05,  6.30it/s, est. speed input: 6723.24 toks/s, output: 6.57 toks/s]
Processed prompts:  21%|        | 106/512 [00:16<01:04,  6.31it/s, est. speed input: 6713.53 toks/s, output: 6.56 toks/s]
Processed prompts:  21%|       | 110/512 [00:16<01:04,  6.28it/s, est. speed input: 6699.71 toks/s, output: 6.54 toks/s]
Processed prompts:  22%|       | 114/512 [00:17<01:03,  6.29it/s, est. speed input: 6692.02 toks/s, output: 6.54 toks/s]
Processed prompts:  23%|       | 118/512 [00:18<01:02,  6.28it/s, est. speed input: 6681.06 toks/s, output: 6.52 toks/s]
Processed prompts:  24%|       | 122/512 [00:18<01:02,  6.27it/s, est. speed input: 6671.16 toks/s, output: 6.51 toks/s]
Processed prompts:  25%|       | 126/512 [00:19<01:01,  6.27it/s, est. speed input: 6663.06 toks/s, output: 6.51 toks/s]
Processed prompts:  25%|       | 130/512 [00:20<01:01,  6.25it/s, est. speed input: 6653.26 toks/s, output: 6.50 toks/s]
Processed prompts:  26%|       | 134/512 [00:20<01:00,  6.26it/s, est. speed input: 6646.06 toks/s, output: 6.49 toks/s]
Processed prompts:  27%|       | 138/512 [00:21<00:59,  6.26it/s, est. speed input: 6639.56 toks/s, output: 6.48 toks/s]
Processed prompts:  28%|       | 142/512 [00:21<00:59,  6.26it/s, est. speed input: 6633.15 toks/s, output: 6.48 toks/s]
Processed prompts:  29%|       | 146/512 [00:22<00:58,  6.28it/s, est. speed input: 6628.76 toks/s, output: 6.47 toks/s]
Processed prompts:  29%|       | 150/512 [00:23<00:57,  6.28it/s, est. speed input: 6623.20 toks/s, output: 6.47 toks/s]
Processed prompts:  30%|       | 154/512 [00:23<00:57,  6.26it/s, est. speed input: 6616.09 toks/s, output: 6.46 toks/s]
Processed prompts:  31%|       | 158/512 [00:24<00:56,  6.26it/s, est. speed input: 6610.99 toks/s, output: 6.46 toks/s]
Processed prompts:  32%|      | 162/512 [00:25<00:56,  6.24it/s, est. speed input: 6604.21 toks/s, output: 6.45 toks/s]
Processed prompts:  32%|      | 166/512 [00:25<00:55,  6.27it/s, est. speed input: 6601.02 toks/s, output: 6.45 toks/s]
Processed prompts:  33%|      | 170/512 [00:26<00:54,  6.26it/s, est. speed input: 6596.19 toks/s, output: 6.44 toks/s]
Processed prompts:  34%|      | 174/512 [00:27<00:54,  6.25it/s, est. speed input: 6590.70 toks/s, output: 6.44 toks/s]
Processed prompts:  35%|      | 178/512 [00:27<00:53,  6.26it/s, est. speed input: 6587.45 toks/s, output: 6.43 toks/s]
Processed prompts:  36%|      | 182/512 [00:28<00:52,  6.26it/s, est. speed input: 6583.16 toks/s, output: 6.43 toks/s]
Processed prompts:  36%|      | 186/512 [00:28<00:51,  6.29it/s, est. speed input: 6581.61 toks/s, output: 6.43 toks/s]
Processed prompts:  37%|      | 190/512 [00:29<00:51,  6.28it/s, est. speed input: 6578.15 toks/s, output: 6.42 toks/s]
Processed prompts:  38%|      | 194/512 [00:30<00:50,  6.26it/s, est. speed input: 6573.65 toks/s, output: 6.42 toks/s]
Processed prompts:  39%|      | 198/512 [00:30<00:51,  6.09it/s, est. speed input: 6557.39 toks/s, output: 6.40 toks/s]
Processed prompts:  39%|      | 202/512 [00:31<00:47,  6.47it/s, est. speed input: 6577.67 toks/s, output: 6.42 toks/s]
Processed prompts:  40%|      | 206/512 [00:32<00:47,  6.43it/s, est. speed input: 6575.75 toks/s, output: 6.42 toks/s]
Processed prompts:  41%|      | 210/512 [00:32<00:47,  6.38it/s, est. speed input: 6572.57 toks/s, output: 6.42 toks/s]
Processed prompts:  42%|     | 214/512 [00:33<00:46,  6.35it/s, est. speed input: 6569.72 toks/s, output: 6.42 toks/s]
Processed prompts:  43%|     | 218/512 [00:34<00:46,  6.30it/s, est. speed input: 6565.57 toks/s, output: 6.41 toks/s]
Processed prompts:  43%|     | 222/512 [00:34<00:46,  6.28it/s, est. speed input: 6562.08 toks/s, output: 6.41 toks/s]
Processed prompts:  44%|     | 226/512 [00:35<00:45,  6.30it/s, est. speed input: 6560.75 toks/s, output: 6.41 toks/s]
Processed prompts:  45%|     | 230/512 [00:35<00:45,  6.26it/s, est. speed input: 6556.49 toks/s, output: 6.40 toks/s]
Processed prompts:  46%|     | 234/512 [00:36<00:44,  6.25it/s, est. speed input: 6553.61 toks/s, output: 6.40 toks/s]
Processed prompts:  46%|     | 238/512 [00:37<00:43,  6.24it/s, est. speed input: 6550.37 toks/s, output: 6.40 toks/s]
Processed prompts:  47%|     | 242/512 [00:37<00:43,  6.23it/s, est. speed input: 6547.15 toks/s, output: 6.39 toks/s]
Processed prompts:  48%|     | 246/512 [00:38<00:42,  6.24it/s, est. speed input: 6544.97 toks/s, output: 6.39 toks/s]
Processed prompts:  49%|     | 250/512 [00:39<00:41,  6.25it/s, est. speed input: 6542.85 toks/s, output: 6.39 toks/s]
Processed prompts:  50%|     | 254/512 [00:39<00:41,  6.26it/s, est. speed input: 6541.23 toks/s, output: 6.39 toks/s]
Processed prompts:  50%|     | 258/512 [00:40<00:40,  6.28it/s, est. speed input: 6540.10 toks/s, output: 6.39 toks/s]
Processed prompts:  51%|     | 262/512 [00:41<00:39,  6.27it/s, est. speed input: 6537.70 toks/s, output: 6.38 toks/s]
Processed prompts:  52%|    | 266/512 [00:41<00:39,  6.27it/s, est. speed input: 6535.93 toks/s, output: 6.38 toks/s]
Processed prompts:  53%|    | 270/512 [00:42<00:38,  6.26it/s, est. speed input: 6533.52 toks/s, output: 6.38 toks/s]
Processed prompts:  54%|    | 274/512 [00:42<00:38,  6.26it/s, est. speed input: 6531.70 toks/s, output: 6.38 toks/s]
Processed prompts:  54%|    | 278/512 [00:43<00:37,  6.28it/s, est. speed input: 6531.04 toks/s, output: 6.38 toks/s]
Processed prompts:  55%|    | 282/512 [00:44<00:36,  6.26it/s, est. speed input: 6528.42 toks/s, output: 6.38 toks/s]
Processed prompts:  56%|    | 286/512 [00:44<00:36,  6.26it/s, est. speed input: 6526.85 toks/s, output: 6.37 toks/s]
Processed prompts:  57%|    | 290/512 [00:45<00:35,  6.24it/s, est. speed input: 6524.43 toks/s, output: 6.37 toks/s]
Processed prompts:  57%|    | 294/512 [00:46<00:34,  6.23it/s, est. speed input: 6522.00 toks/s, output: 6.37 toks/s]
Processed prompts:  58%|    | 298/512 [00:46<00:34,  6.26it/s, est. speed input: 6521.46 toks/s, output: 6.37 toks/s]
Processed prompts:  59%|    | 302/512 [00:47<00:33,  6.25it/s, est. speed input: 6519.63 toks/s, output: 6.37 toks/s]
Processed prompts:  60%|    | 306/512 [00:47<00:30,  6.67it/s, est. speed input: 6536.19 toks/s, output: 6.38 toks/s]
Processed prompts:  61%|    | 310/512 [00:48<00:30,  6.53it/s, est. speed input: 6534.05 toks/s, output: 6.38 toks/s]
Processed prompts:  61%|   | 314/512 [00:49<00:30,  6.46it/s, est. speed input: 6532.96 toks/s, output: 6.38 toks/s]
Processed prompts:  62%|   | 318/512 [00:49<00:30,  6.40it/s, est. speed input: 6531.63 toks/s, output: 6.38 toks/s]
Processed prompts:  63%|   | 322/512 [00:50<00:29,  6.35it/s, est. speed input: 6529.62 toks/s, output: 6.38 toks/s]
Processed prompts:  64%|   | 326/512 [00:51<00:29,  6.32it/s, est. speed input: 6527.92 toks/s, output: 6.37 toks/s]
Processed prompts:  64%|   | 330/512 [00:51<00:28,  6.29it/s, est. speed input: 6526.16 toks/s, output: 6.37 toks/s]
Processed prompts:  65%|   | 334/512 [00:52<00:28,  6.30it/s, est. speed input: 6525.39 toks/s, output: 6.37 toks/s]
Processed prompts:  66%|   | 338/512 [00:53<00:27,  6.29it/s, est. speed input: 6524.07 toks/s, output: 6.37 toks/s]
Processed prompts:  67%|   | 342/512 [00:53<00:27,  6.25it/s, est. speed input: 6521.43 toks/s, output: 6.37 toks/s]
Processed prompts:  68%|   | 346/512 [00:54<00:26,  6.25it/s, est. speed input: 6520.19 toks/s, output: 6.37 toks/s]
Processed prompts:  68%|   | 350/512 [00:54<00:25,  6.23it/s, est. speed input: 6517.92 toks/s, output: 6.37 toks/s]
Processed prompts:  69%|   | 354/512 [00:55<00:25,  6.22it/s, est. speed input: 6515.87 toks/s, output: 6.36 toks/s]
Processed prompts:  70%|   | 358/512 [00:56<00:24,  6.25it/s, est. speed input: 6515.20 toks/s, output: 6.36 toks/s]
Processed prompts:  71%|   | 362/512 [00:56<00:24,  6.24it/s, est. speed input: 6513.78 toks/s, output: 6.36 toks/s]
Processed prompts:  71%|  | 366/512 [00:57<00:23,  6.27it/s, est. speed input: 6513.37 toks/s, output: 6.36 toks/s]
Processed prompts:  72%|  | 370/512 [00:58<00:22,  6.25it/s, est. speed input: 6511.63 toks/s, output: 6.36 toks/s]
Processed prompts:  73%|  | 374/512 [00:58<00:22,  6.23it/s, est. speed input: 6509.76 toks/s, output: 6.36 toks/s]
Processed prompts:  74%|  | 378/512 [00:59<00:21,  6.24it/s, est. speed input: 6508.73 toks/s, output: 6.36 toks/s]
Processed prompts:  75%|  | 382/512 [01:00<00:20,  6.25it/s, est. speed input: 6507.79 toks/s, output: 6.36 toks/s]
Processed prompts:  75%|  | 386/512 [01:00<00:20,  6.26it/s, est. speed input: 6506.89 toks/s, output: 6.35 toks/s]
Processed prompts:  76%|  | 390/512 [01:01<00:19,  6.25it/s, est. speed input: 6505.58 toks/s, output: 6.35 toks/s]
Processed prompts:  77%|  | 394/512 [01:02<00:18,  6.25it/s, est. speed input: 6504.34 toks/s, output: 6.35 toks/s]
Processed prompts:  78%|  | 398/512 [01:02<00:18,  6.24it/s, est. speed input: 6503.16 toks/s, output: 6.35 toks/s]
Processed prompts:  79%|  | 402/512 [01:03<00:17,  6.23it/s, est. speed input: 6501.65 toks/s, output: 6.35 toks/s]
Processed prompts:  79%|  | 406/512 [01:03<00:16,  6.25it/s, est. speed input: 6501.11 toks/s, output: 6.35 toks/s]
Processed prompts:  80%|  | 410/512 [01:04<00:16,  6.25it/s, est. speed input: 6499.98 toks/s, output: 6.35 toks/s]
Processed prompts:  81%|  | 414/512 [01:05<00:15,  6.24it/s, est. speed input: 6498.75 toks/s, output: 6.35 toks/s]
Processed prompts:  82%| | 418/512 [01:05<00:15,  6.26it/s, est. speed input: 6498.20 toks/s, output: 6.35 toks/s]
Processed prompts:  82%| | 422/512 [01:06<00:14,  6.24it/s, est. speed input: 6496.69 toks/s, output: 6.34 toks/s]
Processed prompts:  83%| | 426/512 [01:07<00:13,  6.25it/s, est. speed input: 6496.08 toks/s, output: 6.34 toks/s]
Processed prompts:  84%| | 430/512 [01:07<00:13,  6.25it/s, est. speed input: 6495.12 toks/s, output: 6.34 toks/s]
Processed prompts:  85%| | 434/512 [01:08<00:11,  6.65it/s, est. speed input: 6506.51 toks/s, output: 6.35 toks/s]
Processed prompts:  86%| | 438/512 [01:08<00:11,  6.53it/s, est. speed input: 6505.57 toks/s, output: 6.35 toks/s]
Processed prompts:  86%| | 442/512 [01:09<00:10,  6.42it/s, est. speed input: 6503.99 toks/s, output: 6.35 toks/s]
Processed prompts:  87%| | 446/512 [01:10<00:10,  6.40it/s, est. speed input: 6504.04 toks/s, output: 6.35 toks/s]
Processed prompts:  88%| | 450/512 [01:10<00:09,  6.35it/s, est. speed input: 6502.83 toks/s, output: 6.35 toks/s]
Processed prompts:  89%| | 454/512 [01:11<00:09,  6.31it/s, est. speed input: 6501.73 toks/s, output: 6.35 toks/s]
Processed prompts:  89%| | 458/512 [01:12<00:08,  6.29it/s, est. speed input: 6500.83 toks/s, output: 6.35 toks/s]
Processed prompts:  90%| | 462/512 [01:12<00:07,  6.28it/s, est. speed input: 6499.81 toks/s, output: 6.35 toks/s]
Processed prompts:  91%| | 466/512 [01:13<00:07,  6.29it/s, est. speed input: 6499.49 toks/s, output: 6.35 toks/s]
Processed prompts:  92%|| 470/512 [01:14<00:06,  6.27it/s, est. speed input: 6498.56 toks/s, output: 6.35 toks/s]
Processed prompts:  93%|| 474/512 [01:14<00:06,  6.27it/s, est. speed input: 6497.93 toks/s, output: 6.35 toks/s]
Processed prompts:  93%|| 478/512 [01:15<00:05,  6.27it/s, est. speed input: 6497.09 toks/s, output: 6.34 toks/s]
Processed prompts:  94%|| 482/512 [01:15<00:04,  6.25it/s, est. speed input: 6495.95 toks/s, output: 6.34 toks/s]
Processed prompts:  95%|| 486/512 [01:16<00:04,  6.27it/s, est. speed input: 6495.62 toks/s, output: 6.34 toks/s]
Processed prompts:  96%|| 490/512 [01:17<00:03,  6.24it/s, est. speed input: 6494.35 toks/s, output: 6.34 toks/s]
Processed prompts:  96%|| 494/512 [01:17<00:02,  6.23it/s, est. speed input: 6493.16 toks/s, output: 6.34 toks/s]
Processed prompts:  97%|| 498/512 [01:18<00:02,  6.26it/s, est. speed input: 6493.03 toks/s, output: 6.34 toks/s]
Processed prompts:  98%|| 502/512 [01:19<00:01,  6.24it/s, est. speed input: 6491.92 toks/s, output: 6.34 toks/s]
Processed prompts:  99%|| 506/512 [01:19<00:00,  6.24it/s, est. speed input: 6491.05 toks/s, output: 6.34 toks/s]
Processed prompts: 100%|| 510/512 [01:20<00:00,  6.72it/s, est. speed input: 6502.57 toks/s, output: 6.35 toks/s]
Processed prompts: 100%|| 512/512 [01:20<00:00,  6.72it/s, est. speed input: 6528.06 toks/s, output: 6.38 toks/s]
Processed prompts: 100%|| 512/512 [01:20<00:00,  6.38it/s, est. speed input: 6528.06 toks/s, output: 6.38 toks/s]
[rank0]:[W126 15:27:22.114990975 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 15:27:25
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:27:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 15:27:32 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1443585) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1443585) WARNING 01-26 15:28:47 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 6.27 requests/s, 6426.66 total tokens/s, 6.27 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 15:27:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:27:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:27:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:27:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:27:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:27:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:27:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:27:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:27:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:27:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:27:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:27:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:27:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:27:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:27:35] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:27:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:27:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:27:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:27:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:27:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:27:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:27:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:27:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:27:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:27:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:27:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:27:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:27:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1443585) [2026-01-26 15:27:36] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1443585) [2026-01-26 15:27:36] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1443585) [2026-01-26 15:27:36] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1443585) [2026-01-26 15:27:36] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1443585) [2026-01-26 15:27:36] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1443585) [2026-01-26 15:27:36] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1443585) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1443585) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:24<00:24, 24.86s/it]
(EngineCore_DP0 pid=1443585) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:59<00:00, 30.55s/it]
(EngineCore_DP0 pid=1443585) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:59<00:00, 29.69s/it]
(EngineCore_DP0 pid=1443585) 
(EngineCore_DP0 pid=1443585) [2026-01-26 15:28:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1443585) [2026-01-26 15:28:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=1443585) [2026-01-26 15:28:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1443585) [2026-01-26 15:28:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=1443585) [2026-01-26 15:28:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1443585) [2026-01-26 15:28:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=1443585) [2026-01-26 15:28:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1443585) [2026-01-26 15:28:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=1443585) 2026-01-26 15:28:45,063 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1443585) 2026-01-26 15:28:45,423 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|         | 33/1024 [00:00<00:03, 327.01it/s]
Adding requests:   7%|         | 70/1024 [00:00<00:02, 344.75it/s]
Adding requests:  11%|         | 111/1024 [00:00<00:02, 373.40it/s]
Adding requests:  15%|        | 150/1024 [00:00<00:02, 376.78it/s]
Adding requests:  19%|        | 194/1024 [00:00<00:02, 397.73it/s]
Adding requests:  23%|       | 238/1024 [00:00<00:01, 410.88it/s]
Adding requests:  27%|       | 280/1024 [00:00<00:01, 407.33it/s]
Adding requests:  32%|      | 323/1024 [00:00<00:01, 413.02it/s]
Adding requests:  36%|      | 368/1024 [00:00<00:01, 423.49it/s]
Adding requests:  40%|      | 412/1024 [00:01<00:01, 427.18it/s]
Adding requests:  44%|     | 455/1024 [00:01<00:01, 425.74it/s]
Adding requests:  49%|     | 499/1024 [00:01<00:01, 429.43it/s]
Adding requests:  53%|    | 542/1024 [00:01<00:01, 429.25it/s]
Adding requests:  57%|    | 585/1024 [00:01<00:01, 427.31it/s]
Adding requests:  61%|   | 629/1024 [00:01<00:00, 427.59it/s]
Adding requests:  66%|   | 672/1024 [00:01<00:00, 399.45it/s]
Adding requests:  70%|   | 717/1024 [00:01<00:00, 410.39it/s]
Adding requests:  74%|  | 759/1024 [00:01<00:00, 405.34it/s]
Adding requests:  78%|  | 801/1024 [00:01<00:00, 409.04it/s]
Adding requests:  83%| | 845/1024 [00:02<00:00, 415.50it/s]
Adding requests:  87%| | 889/1024 [00:02<00:00, 422.41it/s]
Adding requests:  91%| | 932/1024 [00:02<00:00, 417.81it/s]
Adding requests:  95%|| 975/1024 [00:02<00:00, 421.30it/s]
Adding requests:  99%|| 1018/1024 [00:02<00:00, 416.89it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 412.03it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 10/1024 [00:00<00:33, 30.40it/s, est. speed input: 31129.00 toks/s, output: 30.40 toks/s]
Processed prompts:   2%|         | 18/1024 [00:01<01:40,  9.99it/s, est. speed input: 11517.60 toks/s, output: 11.25 toks/s]
Processed prompts:   3%|         | 26/1024 [00:02<02:04,  8.00it/s, est. speed input: 9300.09 toks/s, output: 9.08 toks/s]  
Processed prompts:   3%|         | 34/1024 [00:04<02:16,  7.26it/s, est. speed input: 8432.36 toks/s, output: 8.23 toks/s]
Processed prompts:   4%|         | 42/1024 [00:05<02:22,  6.89it/s, est. speed input: 7963.98 toks/s, output: 7.78 toks/s]
Processed prompts:   5%|         | 50/1024 [00:06<02:26,  6.67it/s, est. speed input: 7670.64 toks/s, output: 7.49 toks/s]
Processed prompts:   6%|         | 58/1024 [00:07<02:27,  6.54it/s, est. speed input: 7472.65 toks/s, output: 7.30 toks/s]
Processed prompts:   6%|         | 66/1024 [00:09<02:28,  6.46it/s, est. speed input: 7329.23 toks/s, output: 7.16 toks/s]
Processed prompts:   7%|         | 74/1024 [00:10<02:28,  6.40it/s, est. speed input: 7221.56 toks/s, output: 7.05 toks/s]
Processed prompts:   8%|         | 82/1024 [00:11<02:27,  6.37it/s, est. speed input: 7137.49 toks/s, output: 6.97 toks/s]
Processed prompts:   9%|         | 90/1024 [00:13<02:27,  6.34it/s, est. speed input: 7066.38 toks/s, output: 6.90 toks/s]
Processed prompts:  10%|         | 98/1024 [00:14<02:26,  6.32it/s, est. speed input: 7009.80 toks/s, output: 6.85 toks/s]
Processed prompts:  10%|         | 106/1024 [00:15<02:25,  6.31it/s, est. speed input: 6963.34 toks/s, output: 6.80 toks/s]
Processed prompts:  11%|         | 114/1024 [00:16<02:24,  6.30it/s, est. speed input: 6923.26 toks/s, output: 6.76 toks/s]
Processed prompts:  12%|        | 122/1024 [00:18<02:23,  6.30it/s, est. speed input: 6889.39 toks/s, output: 6.73 toks/s]
Processed prompts:  13%|        | 130/1024 [00:19<02:22,  6.28it/s, est. speed input: 6857.25 toks/s, output: 6.70 toks/s]
Processed prompts:  13%|        | 138/1024 [00:20<02:21,  6.28it/s, est. speed input: 6830.12 toks/s, output: 6.67 toks/s]
Processed prompts:  14%|        | 146/1024 [00:21<02:19,  6.28it/s, est. speed input: 6806.40 toks/s, output: 6.65 toks/s]
Processed prompts:  15%|        | 154/1024 [00:23<02:18,  6.27it/s, est. speed input: 6785.13 toks/s, output: 6.63 toks/s]
Processed prompts:  16%|        | 162/1024 [00:24<02:17,  6.28it/s, est. speed input: 6766.70 toks/s, output: 6.61 toks/s]
Processed prompts:  17%|        | 170/1024 [00:25<02:16,  6.27it/s, est. speed input: 6748.74 toks/s, output: 6.59 toks/s]
Processed prompts:  17%|        | 178/1024 [00:27<02:14,  6.27it/s, est. speed input: 6733.95 toks/s, output: 6.58 toks/s]
Processed prompts:  18%|        | 186/1024 [00:28<02:13,  6.28it/s, est. speed input: 6720.89 toks/s, output: 6.56 toks/s]
Processed prompts:  19%|        | 194/1024 [00:29<02:12,  6.27it/s, est. speed input: 6707.68 toks/s, output: 6.55 toks/s]
Processed prompts:  20%|        | 202/1024 [00:30<02:12,  6.20it/s, est. speed input: 6684.62 toks/s, output: 6.53 toks/s]
Processed prompts:  21%|        | 210/1024 [00:32<02:11,  6.21it/s, est. speed input: 6672.84 toks/s, output: 6.52 toks/s]
Processed prompts:  21%|       | 218/1024 [00:33<02:09,  6.23it/s, est. speed input: 6662.92 toks/s, output: 6.51 toks/s]
Processed prompts:  22%|       | 226/1024 [00:34<02:07,  6.24it/s, est. speed input: 6654.58 toks/s, output: 6.50 toks/s]
Processed prompts:  23%|       | 234/1024 [00:36<02:06,  6.25it/s, est. speed input: 6646.41 toks/s, output: 6.49 toks/s]
Processed prompts:  24%|       | 242/1024 [00:37<02:04,  6.26it/s, est. speed input: 6638.62 toks/s, output: 6.48 toks/s]
Processed prompts:  24%|       | 250/1024 [00:38<02:03,  6.25it/s, est. speed input: 6630.67 toks/s, output: 6.48 toks/s]
Processed prompts:  25%|       | 258/1024 [00:39<02:02,  6.26it/s, est. speed input: 6624.03 toks/s, output: 6.47 toks/s]
Processed prompts:  26%|       | 266/1024 [00:41<02:00,  6.27it/s, est. speed input: 6618.04 toks/s, output: 6.46 toks/s]
Processed prompts:  27%|       | 274/1024 [00:42<01:59,  6.27it/s, est. speed input: 6612.31 toks/s, output: 6.46 toks/s]
Processed prompts:  28%|       | 282/1024 [00:43<01:58,  6.27it/s, est. speed input: 6606.61 toks/s, output: 6.45 toks/s]
Processed prompts:  28%|       | 290/1024 [00:44<01:57,  6.27it/s, est. speed input: 6600.98 toks/s, output: 6.45 toks/s]
Processed prompts:  29%|       | 298/1024 [00:46<01:55,  6.26it/s, est. speed input: 6595.60 toks/s, output: 6.44 toks/s]
Processed prompts:  30%|       | 306/1024 [00:47<01:51,  6.46it/s, est. speed input: 6609.08 toks/s, output: 6.45 toks/s]
Processed prompts:  31%|       | 314/1024 [00:48<01:50,  6.41it/s, est. speed input: 6604.26 toks/s, output: 6.45 toks/s]
Processed prompts:  31%|      | 322/1024 [00:49<01:50,  6.36it/s, est. speed input: 6599.54 toks/s, output: 6.44 toks/s]
Processed prompts:  32%|      | 330/1024 [00:51<01:49,  6.33it/s, est. speed input: 6594.25 toks/s, output: 6.44 toks/s]
Processed prompts:  33%|      | 338/1024 [00:52<01:48,  6.31it/s, est. speed input: 6590.40 toks/s, output: 6.44 toks/s]
Processed prompts:  34%|      | 346/1024 [00:53<01:47,  6.30it/s, est. speed input: 6586.45 toks/s, output: 6.43 toks/s]
Processed prompts:  35%|      | 354/1024 [00:55<01:46,  6.29it/s, est. speed input: 6582.53 toks/s, output: 6.43 toks/s]
Processed prompts:  35%|      | 362/1024 [00:56<01:45,  6.29it/s, est. speed input: 6578.96 toks/s, output: 6.42 toks/s]
Processed prompts:  36%|      | 370/1024 [00:57<01:44,  6.27it/s, est. speed input: 6574.85 toks/s, output: 6.42 toks/s]
Processed prompts:  37%|      | 378/1024 [00:58<01:42,  6.27it/s, est. speed input: 6571.59 toks/s, output: 6.42 toks/s]
Processed prompts:  38%|      | 386/1024 [01:00<01:41,  6.27it/s, est. speed input: 6568.48 toks/s, output: 6.41 toks/s]
Processed prompts:  38%|      | 394/1024 [01:01<01:40,  6.27it/s, est. speed input: 6565.39 toks/s, output: 6.41 toks/s]
Processed prompts:  39%|      | 402/1024 [01:02<01:39,  6.27it/s, est. speed input: 6562.49 toks/s, output: 6.41 toks/s]
Processed prompts:  40%|      | 410/1024 [01:04<01:38,  6.23it/s, est. speed input: 6556.67 toks/s, output: 6.40 toks/s]
Processed prompts:  41%|      | 418/1024 [01:05<01:37,  6.24it/s, est. speed input: 6553.65 toks/s, output: 6.40 toks/s]
Processed prompts:  42%|     | 426/1024 [01:06<01:35,  6.24it/s, est. speed input: 6550.65 toks/s, output: 6.40 toks/s]
Processed prompts:  42%|     | 434/1024 [01:07<01:31,  6.45it/s, est. speed input: 6561.03 toks/s, output: 6.41 toks/s]
Processed prompts:  43%|     | 442/1024 [01:09<01:31,  6.39it/s, est. speed input: 6558.37 toks/s, output: 6.40 toks/s]
Processed prompts:  44%|     | 450/1024 [01:10<01:30,  6.34it/s, est. speed input: 6555.15 toks/s, output: 6.40 toks/s]
Processed prompts:  45%|     | 458/1024 [01:11<01:29,  6.32it/s, est. speed input: 6552.64 toks/s, output: 6.40 toks/s]
Processed prompts:  46%|     | 466/1024 [01:12<01:28,  6.30it/s, est. speed input: 6550.19 toks/s, output: 6.40 toks/s]
Processed prompts:  46%|     | 474/1024 [01:14<01:27,  6.29it/s, est. speed input: 6548.03 toks/s, output: 6.39 toks/s]
Processed prompts:  47%|     | 482/1024 [01:15<01:26,  6.29it/s, est. speed input: 6545.80 toks/s, output: 6.39 toks/s]
Processed prompts:  48%|     | 490/1024 [01:16<01:25,  6.27it/s, est. speed input: 6543.11 toks/s, output: 6.39 toks/s]
Processed prompts:  49%|     | 498/1024 [01:17<01:23,  6.27it/s, est. speed input: 6540.93 toks/s, output: 6.39 toks/s]
Processed prompts:  49%|     | 506/1024 [01:19<01:22,  6.27it/s, est. speed input: 6538.90 toks/s, output: 6.39 toks/s]
Processed prompts:  50%|     | 514/1024 [01:20<01:21,  6.27it/s, est. speed input: 6536.92 toks/s, output: 6.38 toks/s]
Processed prompts:  51%|     | 522/1024 [01:21<01:20,  6.26it/s, est. speed input: 6534.95 toks/s, output: 6.38 toks/s]
Processed prompts:  52%|    | 530/1024 [01:23<01:18,  6.26it/s, est. speed input: 6532.71 toks/s, output: 6.38 toks/s]
Processed prompts:  53%|    | 538/1024 [01:24<01:17,  6.26it/s, est. speed input: 6530.99 toks/s, output: 6.38 toks/s]
Processed prompts:  53%|    | 546/1024 [01:25<01:16,  6.26it/s, est. speed input: 6529.09 toks/s, output: 6.38 toks/s]
Processed prompts:  54%|    | 554/1024 [01:26<01:15,  6.26it/s, est. speed input: 6527.40 toks/s, output: 6.37 toks/s]
Processed prompts:  55%|    | 562/1024 [01:28<01:13,  6.26it/s, est. speed input: 6525.65 toks/s, output: 6.37 toks/s]
Processed prompts:  56%|    | 570/1024 [01:29<01:12,  6.25it/s, est. speed input: 6523.61 toks/s, output: 6.37 toks/s]
Processed prompts:  56%|    | 578/1024 [01:30<01:11,  6.25it/s, est. speed input: 6521.86 toks/s, output: 6.37 toks/s]
Processed prompts:  57%|    | 586/1024 [01:32<01:10,  6.26it/s, est. speed input: 6520.48 toks/s, output: 6.37 toks/s]
Processed prompts:  58%|    | 594/1024 [01:33<01:08,  6.26it/s, est. speed input: 6519.01 toks/s, output: 6.37 toks/s]
Processed prompts:  59%|    | 602/1024 [01:34<01:07,  6.25it/s, est. speed input: 6517.30 toks/s, output: 6.36 toks/s]
Processed prompts:  60%|    | 610/1024 [01:35<01:06,  6.24it/s, est. speed input: 6514.93 toks/s, output: 6.36 toks/s]
Processed prompts:  60%|    | 618/1024 [01:37<01:05,  6.24it/s, est. speed input: 6513.54 toks/s, output: 6.36 toks/s]
Processed prompts:  61%|    | 626/1024 [01:38<01:03,  6.25it/s, est. speed input: 6512.29 toks/s, output: 6.36 toks/s]
Processed prompts:  62%|   | 634/1024 [01:39<01:02,  6.25it/s, est. speed input: 6510.85 toks/s, output: 6.36 toks/s]
Processed prompts:  63%|   | 642/1024 [01:40<01:01,  6.25it/s, est. speed input: 6509.31 toks/s, output: 6.36 toks/s]
Processed prompts:  63%|   | 650/1024 [01:42<00:59,  6.25it/s, est. speed input: 6508.23 toks/s, output: 6.36 toks/s]
Processed prompts:  64%|   | 658/1024 [01:43<00:58,  6.25it/s, est. speed input: 6506.84 toks/s, output: 6.35 toks/s]
Processed prompts:  65%|   | 666/1024 [01:44<00:57,  6.26it/s, est. speed input: 6505.77 toks/s, output: 6.35 toks/s]
Processed prompts:  66%|   | 674/1024 [01:46<00:55,  6.25it/s, est. speed input: 6504.45 toks/s, output: 6.35 toks/s]
Processed prompts:  67%|   | 682/1024 [01:47<00:54,  6.24it/s, est. speed input: 6502.79 toks/s, output: 6.35 toks/s]
Processed prompts:  67%|   | 690/1024 [01:48<00:53,  6.25it/s, est. speed input: 6501.65 toks/s, output: 6.35 toks/s]
Processed prompts:  68%|   | 698/1024 [01:49<00:52,  6.25it/s, est. speed input: 6500.54 toks/s, output: 6.35 toks/s]
Processed prompts:  69%|   | 706/1024 [01:51<00:50,  6.26it/s, est. speed input: 6499.65 toks/s, output: 6.35 toks/s]
Processed prompts:  70%|   | 714/1024 [01:52<00:49,  6.26it/s, est. speed input: 6498.64 toks/s, output: 6.35 toks/s]
Processed prompts:  71%|   | 722/1024 [01:53<00:48,  6.25it/s, est. speed input: 6497.46 toks/s, output: 6.35 toks/s]
Processed prompts:  71%|  | 730/1024 [01:55<00:47,  6.26it/s, est. speed input: 6496.49 toks/s, output: 6.34 toks/s]
Processed prompts:  72%|  | 738/1024 [01:56<00:45,  6.25it/s, est. speed input: 6495.36 toks/s, output: 6.34 toks/s]
Processed prompts:  73%|  | 746/1024 [01:57<00:44,  6.26it/s, est. speed input: 6494.48 toks/s, output: 6.34 toks/s]
Processed prompts:  74%|  | 754/1024 [01:58<00:43,  6.26it/s, est. speed input: 6493.72 toks/s, output: 6.34 toks/s]
Processed prompts:  74%|  | 762/1024 [02:00<00:41,  6.25it/s, est. speed input: 6492.50 toks/s, output: 6.34 toks/s]
Processed prompts:  75%|  | 770/1024 [02:01<00:40,  6.25it/s, est. speed input: 6491.66 toks/s, output: 6.34 toks/s]
Processed prompts:  76%|  | 778/1024 [02:02<00:39,  6.26it/s, est. speed input: 6490.87 toks/s, output: 6.34 toks/s]
Processed prompts:  77%|  | 786/1024 [02:03<00:36,  6.45it/s, est. speed input: 6496.59 toks/s, output: 6.34 toks/s]
Processed prompts:  78%|  | 794/1024 [02:05<00:35,  6.39it/s, est. speed input: 6495.71 toks/s, output: 6.34 toks/s]
Processed prompts:  78%|  | 802/1024 [02:06<00:34,  6.34it/s, est. speed input: 6494.61 toks/s, output: 6.34 toks/s]
Processed prompts:  79%|  | 810/1024 [02:07<00:33,  6.30it/s, est. speed input: 6493.26 toks/s, output: 6.34 toks/s]
Processed prompts:  80%|  | 818/1024 [02:09<00:32,  6.29it/s, est. speed input: 6492.57 toks/s, output: 6.34 toks/s]
Processed prompts:  81%|  | 826/1024 [02:10<00:31,  6.28it/s, est. speed input: 6491.59 toks/s, output: 6.34 toks/s]
Processed prompts:  81%| | 834/1024 [02:11<00:30,  6.28it/s, est. speed input: 6490.91 toks/s, output: 6.34 toks/s]
Processed prompts:  82%| | 842/1024 [02:12<00:29,  6.27it/s, est. speed input: 6489.98 toks/s, output: 6.34 toks/s]
Processed prompts:  83%| | 850/1024 [02:14<00:27,  6.27it/s, est. speed input: 6489.31 toks/s, output: 6.34 toks/s]
Processed prompts:  84%| | 858/1024 [02:15<00:26,  6.26it/s, est. speed input: 6488.51 toks/s, output: 6.34 toks/s]
Processed prompts:  85%| | 866/1024 [02:16<00:25,  6.26it/s, est. speed input: 6487.82 toks/s, output: 6.34 toks/s]
Processed prompts:  85%| | 874/1024 [02:17<00:23,  6.27it/s, est. speed input: 6487.30 toks/s, output: 6.34 toks/s]
Processed prompts:  86%| | 882/1024 [02:19<00:22,  6.26it/s, est. speed input: 6486.37 toks/s, output: 6.33 toks/s]
Processed prompts:  87%| | 890/1024 [02:20<00:21,  6.26it/s, est. speed input: 6485.62 toks/s, output: 6.33 toks/s]
Processed prompts:  88%| | 898/1024 [02:21<00:20,  6.26it/s, est. speed input: 6484.94 toks/s, output: 6.33 toks/s]
Processed prompts:  88%| | 906/1024 [02:23<00:18,  6.26it/s, est. speed input: 6484.37 toks/s, output: 6.33 toks/s]
Processed prompts:  89%| | 914/1024 [02:24<00:17,  6.26it/s, est. speed input: 6483.81 toks/s, output: 6.33 toks/s]
Processed prompts:  90%| | 922/1024 [02:25<00:16,  6.25it/s, est. speed input: 6482.88 toks/s, output: 6.33 toks/s]
Processed prompts:  91%| | 930/1024 [02:26<00:15,  6.26it/s, est. speed input: 6482.25 toks/s, output: 6.33 toks/s]
Processed prompts:  92%|| 938/1024 [02:28<00:13,  6.26it/s, est. speed input: 6481.78 toks/s, output: 6.33 toks/s]
Processed prompts:  92%|| 946/1024 [02:29<00:12,  6.26it/s, est. speed input: 6481.25 toks/s, output: 6.33 toks/s]
Processed prompts:  93%|| 954/1024 [02:30<00:11,  6.27it/s, est. speed input: 6480.73 toks/s, output: 6.33 toks/s]
Processed prompts:  94%|| 962/1024 [02:32<00:09,  6.26it/s, est. speed input: 6479.93 toks/s, output: 6.33 toks/s]
Processed prompts:  95%|| 970/1024 [02:33<00:08,  6.26it/s, est. speed input: 6479.36 toks/s, output: 6.33 toks/s]
Processed prompts:  96%|| 978/1024 [02:34<00:07,  6.26it/s, est. speed input: 6478.76 toks/s, output: 6.33 toks/s]
Processed prompts:  96%|| 986/1024 [02:35<00:06,  6.26it/s, est. speed input: 6478.23 toks/s, output: 6.33 toks/s]
Processed prompts:  97%|| 994/1024 [02:37<00:04,  6.26it/s, est. speed input: 6477.62 toks/s, output: 6.33 toks/s]
Processed prompts:  98%|| 1002/1024 [02:38<00:03,  6.26it/s, est. speed input: 6477.00 toks/s, output: 6.33 toks/s]
Processed prompts:  99%|| 1010/1024 [02:39<00:02,  6.24it/s, est. speed input: 6475.94 toks/s, output: 6.32 toks/s]
Processed prompts:  99%|| 1018/1024 [02:40<00:00,  6.47it/s, est. speed input: 6481.47 toks/s, output: 6.33 toks/s]
Processed prompts: 100%|| 1024/1024 [02:40<00:00,  6.47it/s, est. speed input: 6519.66 toks/s, output: 6.37 toks/s]
Processed prompts: 100%|| 1024/1024 [02:40<00:00,  6.37it/s, est. speed input: 6519.66 toks/s, output: 6.37 toks/s]
[rank0]:[W126 15:31:31.214754476 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 15:31:34
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:31:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 15:31:47 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1447287) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1447287) WARNING 01-26 15:33:06 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 6.30 requests/s, 6456.41 total tokens/s, 6.30 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 15:31:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:31:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:31:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:31:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:31:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:31:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:31:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:31:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:31:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:31:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:31:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:31:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:31:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:31:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:31:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:31:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:31:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:31:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:31:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:31:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:31:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:31:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:31:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:31:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:31:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:31:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:31:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:31:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1447287) [2026-01-26 15:31:51] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1447287) [2026-01-26 15:31:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1447287) [2026-01-26 15:31:51] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1447287) [2026-01-26 15:31:51] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1447287) [2026-01-26 15:31:51] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1447287) [2026-01-26 15:31:51] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1447287) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1447287) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:24<00:24, 24.93s/it]
(EngineCore_DP0 pid=1447287) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 31.06s/it]
(EngineCore_DP0 pid=1447287) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.14s/it]
(EngineCore_DP0 pid=1447287) 
(EngineCore_DP0 pid=1447287) [2026-01-26 15:32:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1447287) [2026-01-26 15:32:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=1447287) [2026-01-26 15:32:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1447287) [2026-01-26 15:32:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=1447287) [2026-01-26 15:32:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1447287) [2026-01-26 15:32:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=1447287) [2026-01-26 15:32:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1447287) [2026-01-26 15:32:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=1447287) 2026-01-26 15:33:02,288 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1447287) 2026-01-26 15:33:02,989 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|         | 34/2048 [00:00<00:06, 331.18it/s]
Adding requests:   3%|         | 69/2048 [00:00<00:05, 341.69it/s]
Adding requests:   5%|         | 110/2048 [00:00<00:05, 372.37it/s]
Adding requests:   7%|         | 149/2048 [00:00<00:05, 377.02it/s]
Adding requests:   9%|         | 191/2048 [00:00<00:04, 391.41it/s]
Adding requests:  11%|        | 234/2048 [00:00<00:04, 401.85it/s]
Adding requests:  13%|        | 275/2048 [00:00<00:04, 404.03it/s]
Adding requests:  16%|        | 318/2048 [00:00<00:04, 411.04it/s]
Adding requests:  18%|        | 362/2048 [00:00<00:04, 418.99it/s]
Adding requests:  20%|        | 405/2048 [00:01<00:03, 419.12it/s]
Adding requests:  22%|       | 448/2048 [00:01<00:03, 420.75it/s]
Adding requests:  24%|       | 493/2048 [00:01<00:03, 426.97it/s]
Adding requests:  26%|       | 537/2048 [00:01<00:03, 427.75it/s]
Adding requests:  28%|       | 580/2048 [00:01<00:03, 423.19it/s]
Adding requests:  30%|       | 623/2048 [00:01<00:03, 416.06it/s]
Adding requests:  32%|      | 665/2048 [00:01<00:03, 410.47it/s]
Adding requests:  35%|      | 707/2048 [00:01<00:03, 411.61it/s]
Adding requests:  37%|      | 749/2048 [00:01<00:03, 411.83it/s]
Adding requests:  39%|      | 791/2048 [00:01<00:03, 385.16it/s]
Adding requests:  41%|      | 834/2048 [00:02<00:03, 397.48it/s]
Adding requests:  43%|     | 875/2048 [00:02<00:07, 152.62it/s]
Adding requests:  45%|     | 914/2048 [00:02<00:06, 184.36it/s]
Adding requests:  47%|     | 954/2048 [00:02<00:04, 218.88it/s]
Adding requests:  49%|     | 995/2048 [00:03<00:04, 253.94it/s]
Adding requests:  51%|     | 1037/2048 [00:03<00:03, 286.63it/s]
Adding requests:  53%|    | 1077/2048 [00:03<00:03, 311.55it/s]
Adding requests:  55%|    | 1117/2048 [00:03<00:02, 332.21it/s]
Adding requests:  57%|    | 1158/2048 [00:03<00:02, 350.82it/s]
Adding requests:  59%|    | 1201/2048 [00:03<00:02, 369.56it/s]
Adding requests:  61%|    | 1242/2048 [00:03<00:02, 380.28it/s]
Adding requests:  63%|   | 1283/2048 [00:03<00:01, 384.25it/s]
Adding requests:  65%|   | 1326/2048 [00:03<00:01, 397.25it/s]
Adding requests:  67%|   | 1367/2048 [00:03<00:01, 397.50it/s]
Adding requests:  69%|   | 1408/2048 [00:04<00:01, 398.94it/s]
Adding requests:  71%|   | 1449/2048 [00:04<00:01, 402.03it/s]
Adding requests:  73%|  | 1492/2048 [00:04<00:01, 408.74it/s]
Adding requests:  75%|  | 1534/2048 [00:04<00:01, 406.95it/s]
Adding requests:  77%|  | 1576/2048 [00:04<00:01, 406.65it/s]
Adding requests:  79%|  | 1618/2048 [00:04<00:01, 407.07it/s]
Adding requests:  81%|  | 1659/2048 [00:04<00:01, 384.48it/s]
Adding requests:  83%| | 1698/2048 [00:04<00:00, 375.58it/s]
Adding requests:  85%| | 1736/2048 [00:04<00:00, 370.12it/s]
Adding requests:  87%| | 1778/2048 [00:05<00:00, 382.76it/s]
Adding requests:  89%| | 1818/2048 [00:05<00:00, 387.44it/s]
Adding requests:  91%| | 1860/2048 [00:05<00:00, 395.76it/s]
Adding requests:  93%|| 1903/2048 [00:05<00:00, 404.34it/s]
Adding requests:  95%|| 1946/2048 [00:05<00:00, 408.77it/s]
Adding requests:  97%|| 1987/2048 [00:05<00:00, 406.93it/s]
Adding requests:  99%|| 2028/2048 [00:05<00:00, 368.96it/s]
Adding requests: 100%|| 2048/2048 [00:05<00:00, 359.25it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 34/2048 [00:02<02:10, 15.41it/s, est. speed input: 15780.14 toks/s, output: 15.41 toks/s]
Processed prompts:   2%|         | 50/2048 [00:04<03:25,  9.70it/s, est. speed input: 10745.23 toks/s, output: 10.49 toks/s]
Processed prompts:   3%|         | 66/2048 [00:07<04:04,  8.10it/s, est. speed input: 9247.38 toks/s, output: 9.03 toks/s]  
Processed prompts:   4%|         | 82/2048 [00:09<04:26,  7.37it/s, est. speed input: 8519.16 toks/s, output: 8.32 toks/s]
Processed prompts:   5%|         | 98/2048 [00:12<04:39,  6.97it/s, est. speed input: 8088.44 toks/s, output: 7.90 toks/s]
Processed prompts:   6%|         | 114/2048 [00:14<04:47,  6.73it/s, est. speed input: 7807.07 toks/s, output: 7.62 toks/s]
Processed prompts:   6%|         | 130/2048 [00:17<04:51,  6.58it/s, est. speed input: 7605.67 toks/s, output: 7.43 toks/s]
Processed prompts:   7%|         | 146/2048 [00:20<04:53,  6.48it/s, est. speed input: 7454.86 toks/s, output: 7.28 toks/s]
Processed prompts:   8%|         | 162/2048 [00:22<04:53,  6.42it/s, est. speed input: 7340.82 toks/s, output: 7.17 toks/s]
Processed prompts:   9%|         | 178/2048 [00:25<05:00,  6.22it/s, est. speed input: 7189.71 toks/s, output: 7.02 toks/s]
Processed prompts:   9%|         | 194/2048 [00:27<04:53,  6.32it/s, est. speed input: 7146.59 toks/s, output: 6.98 toks/s]
Processed prompts:  10%|         | 210/2048 [00:30<04:51,  6.30it/s, est. speed input: 7084.61 toks/s, output: 6.92 toks/s]
Processed prompts:  11%|         | 226/2048 [00:32<04:49,  6.30it/s, est. speed input: 7035.04 toks/s, output: 6.87 toks/s]
Processed prompts:  12%|        | 242/2048 [00:35<04:47,  6.29it/s, est. speed input: 6990.67 toks/s, output: 6.83 toks/s]
Processed prompts:  13%|        | 258/2048 [00:38<04:45,  6.28it/s, est. speed input: 6951.25 toks/s, output: 6.79 toks/s]
Processed prompts:  13%|        | 274/2048 [00:40<04:42,  6.28it/s, est. speed input: 6918.06 toks/s, output: 6.76 toks/s]
Processed prompts:  14%|        | 290/2048 [00:43<04:40,  6.27it/s, est. speed input: 6887.21 toks/s, output: 6.73 toks/s]
Processed prompts:  15%|        | 306/2048 [00:45<04:33,  6.36it/s, est. speed input: 6879.50 toks/s, output: 6.72 toks/s]
Processed prompts:  16%|        | 322/2048 [00:48<04:32,  6.33it/s, est. speed input: 6855.30 toks/s, output: 6.69 toks/s]
Processed prompts:  17%|        | 338/2048 [00:50<04:31,  6.31it/s, est. speed input: 6832.46 toks/s, output: 6.67 toks/s]
Processed prompts:  17%|        | 354/2048 [00:53<04:29,  6.29it/s, est. speed input: 6812.02 toks/s, output: 6.65 toks/s]
Processed prompts:  18%|        | 370/2048 [00:55<04:26,  6.29it/s, est. speed input: 6793.99 toks/s, output: 6.63 toks/s]
Processed prompts:  19%|        | 386/2048 [00:58<04:24,  6.28it/s, est. speed input: 6777.67 toks/s, output: 6.62 toks/s]
Processed prompts:  20%|        | 402/2048 [01:00<04:22,  6.28it/s, est. speed input: 6763.01 toks/s, output: 6.60 toks/s]
Processed prompts:  20%|        | 418/2048 [01:03<04:20,  6.27it/s, est. speed input: 6747.98 toks/s, output: 6.59 toks/s]
Processed prompts:  21%|        | 434/2048 [01:05<04:13,  6.36it/s, est. speed input: 6747.83 toks/s, output: 6.59 toks/s]
Processed prompts:  22%|       | 450/2048 [01:08<04:12,  6.33it/s, est. speed input: 6735.53 toks/s, output: 6.58 toks/s]
Processed prompts:  23%|       | 466/2048 [01:10<04:10,  6.31it/s, est. speed input: 6723.16 toks/s, output: 6.57 toks/s]
Processed prompts:  24%|       | 482/2048 [01:13<04:08,  6.29it/s, est. speed input: 6712.17 toks/s, output: 6.55 toks/s]
Processed prompts:  24%|       | 498/2048 [01:16<04:06,  6.28it/s, est. speed input: 6701.47 toks/s, output: 6.54 toks/s]
Processed prompts:  25%|       | 514/2048 [01:18<04:04,  6.27it/s, est. speed input: 6692.09 toks/s, output: 6.54 toks/s]
Processed prompts:  26%|       | 530/2048 [01:21<04:01,  6.28it/s, est. speed input: 6683.99 toks/s, output: 6.53 toks/s]
Processed prompts:  27%|       | 546/2048 [01:23<03:59,  6.27it/s, est. speed input: 6675.85 toks/s, output: 6.52 toks/s]
Processed prompts:  27%|       | 562/2048 [01:26<03:56,  6.27it/s, est. speed input: 6668.40 toks/s, output: 6.51 toks/s]
Processed prompts:  28%|       | 578/2048 [01:28<03:54,  6.27it/s, est. speed input: 6660.86 toks/s, output: 6.50 toks/s]
Processed prompts:  29%|       | 594/2048 [01:31<03:52,  6.27it/s, est. speed input: 6653.93 toks/s, output: 6.50 toks/s]
Processed prompts:  30%|       | 610/2048 [01:33<03:49,  6.26it/s, est. speed input: 6646.76 toks/s, output: 6.49 toks/s]
Processed prompts:  31%|       | 626/2048 [01:36<03:47,  6.26it/s, est. speed input: 6640.78 toks/s, output: 6.49 toks/s]
Processed prompts:  31%|      | 642/2048 [01:39<03:44,  6.27it/s, est. speed input: 6635.37 toks/s, output: 6.48 toks/s]
Processed prompts:  32%|      | 658/2048 [01:41<03:41,  6.26it/s, est. speed input: 6629.51 toks/s, output: 6.47 toks/s]
Processed prompts:  33%|      | 674/2048 [01:44<03:39,  6.27it/s, est. speed input: 6624.66 toks/s, output: 6.47 toks/s]
Processed prompts:  34%|      | 690/2048 [01:46<03:36,  6.26it/s, est. speed input: 6619.40 toks/s, output: 6.46 toks/s]
Processed prompts:  34%|      | 706/2048 [01:49<03:34,  6.26it/s, est. speed input: 6614.29 toks/s, output: 6.46 toks/s]
Processed prompts:  35%|      | 722/2048 [01:51<03:31,  6.26it/s, est. speed input: 6609.56 toks/s, output: 6.45 toks/s]
Processed prompts:  36%|      | 738/2048 [01:54<03:29,  6.26it/s, est. speed input: 6605.08 toks/s, output: 6.45 toks/s]
Processed prompts:  37%|      | 754/2048 [01:56<03:26,  6.26it/s, est. speed input: 6601.00 toks/s, output: 6.45 toks/s]
Processed prompts:  38%|      | 770/2048 [01:59<03:24,  6.26it/s, est. speed input: 6596.67 toks/s, output: 6.44 toks/s]
Processed prompts:  38%|      | 786/2048 [02:01<03:18,  6.35it/s, est. speed input: 6599.30 toks/s, output: 6.44 toks/s]
Processed prompts:  39%|      | 802/2048 [02:04<03:16,  6.33it/s, est. speed input: 6595.80 toks/s, output: 6.44 toks/s]
Processed prompts:  40%|      | 818/2048 [02:07<03:15,  6.31it/s, est. speed input: 6592.06 toks/s, output: 6.44 toks/s]
Processed prompts:  41%|      | 834/2048 [02:09<03:13,  6.29it/s, est. speed input: 6588.10 toks/s, output: 6.43 toks/s]
Processed prompts:  42%|     | 850/2048 [02:12<03:11,  6.27it/s, est. speed input: 6584.15 toks/s, output: 6.43 toks/s]
Processed prompts:  42%|     | 866/2048 [02:14<03:08,  6.27it/s, est. speed input: 6580.71 toks/s, output: 6.43 toks/s]
Processed prompts:  43%|     | 882/2048 [02:17<03:06,  6.26it/s, est. speed input: 6577.59 toks/s, output: 6.42 toks/s]
Processed prompts:  44%|     | 898/2048 [02:19<03:03,  6.26it/s, est. speed input: 6574.43 toks/s, output: 6.42 toks/s]
Processed prompts:  45%|     | 914/2048 [02:22<03:01,  6.26it/s, est. speed input: 6571.63 toks/s, output: 6.42 toks/s]
Processed prompts:  45%|     | 930/2048 [02:24<02:58,  6.26it/s, est. speed input: 6568.79 toks/s, output: 6.41 toks/s]
Processed prompts:  46%|     | 946/2048 [02:27<02:55,  6.27it/s, est. speed input: 6566.27 toks/s, output: 6.41 toks/s]
Processed prompts:  47%|     | 962/2048 [02:30<02:53,  6.26it/s, est. speed input: 6563.54 toks/s, output: 6.41 toks/s]
Processed prompts:  48%|     | 978/2048 [02:32<02:50,  6.27it/s, est. speed input: 6561.24 toks/s, output: 6.41 toks/s]
Processed prompts:  49%|     | 994/2048 [02:35<02:48,  6.27it/s, est. speed input: 6558.94 toks/s, output: 6.41 toks/s]
Processed prompts:  49%|     | 1010/2048 [02:37<02:45,  6.26it/s, est. speed input: 6556.23 toks/s, output: 6.40 toks/s]
Processed prompts:  50%|     | 1026/2048 [02:40<02:43,  6.26it/s, est. speed input: 6553.94 toks/s, output: 6.40 toks/s]
Processed prompts:  51%|     | 1042/2048 [02:42<02:40,  6.26it/s, est. speed input: 6551.86 toks/s, output: 6.40 toks/s]
Processed prompts:  52%|    | 1058/2048 [02:45<02:37,  6.27it/s, est. speed input: 6550.10 toks/s, output: 6.40 toks/s]
Processed prompts:  52%|    | 1074/2048 [02:47<02:35,  6.27it/s, est. speed input: 6548.29 toks/s, output: 6.39 toks/s]
Processed prompts:  53%|    | 1090/2048 [02:50<02:32,  6.27it/s, est. speed input: 6546.03 toks/s, output: 6.39 toks/s]
Processed prompts:  54%|    | 1106/2048 [02:53<02:30,  6.26it/s, est. speed input: 6544.07 toks/s, output: 6.39 toks/s]
Processed prompts:  55%|    | 1122/2048 [02:55<02:27,  6.26it/s, est. speed input: 6542.15 toks/s, output: 6.39 toks/s]
Processed prompts:  56%|    | 1138/2048 [02:58<02:25,  6.27it/s, est. speed input: 6540.49 toks/s, output: 6.39 toks/s]
Processed prompts:  56%|    | 1154/2048 [03:00<02:22,  6.27it/s, est. speed input: 6538.96 toks/s, output: 6.39 toks/s]
Processed prompts:  57%|    | 1170/2048 [03:03<02:19,  6.27it/s, est. speed input: 6537.48 toks/s, output: 6.38 toks/s]
Processed prompts:  58%|    | 1186/2048 [03:05<02:17,  6.27it/s, est. speed input: 6535.74 toks/s, output: 6.38 toks/s]
Processed prompts:  59%|    | 1202/2048 [03:08<02:13,  6.36it/s, est. speed input: 6538.37 toks/s, output: 6.39 toks/s]
Processed prompts:  59%|    | 1218/2048 [03:10<02:11,  6.33it/s, est. speed input: 6536.87 toks/s, output: 6.38 toks/s]
Processed prompts:  60%|    | 1234/2048 [03:13<02:07,  6.41it/s, est. speed input: 6539.49 toks/s, output: 6.39 toks/s]
Processed prompts:  61%|    | 1250/2048 [03:15<02:05,  6.36it/s, est. speed input: 6537.60 toks/s, output: 6.38 toks/s]
Processed prompts:  62%|   | 1266/2048 [03:18<02:03,  6.33it/s, est. speed input: 6536.11 toks/s, output: 6.38 toks/s]
Processed prompts:  63%|   | 1282/2048 [03:20<02:01,  6.31it/s, est. speed input: 6534.64 toks/s, output: 6.38 toks/s]
Processed prompts:  63%|   | 1298/2048 [03:23<01:59,  6.30it/s, est. speed input: 6533.03 toks/s, output: 6.38 toks/s]
Processed prompts:  64%|   | 1314/2048 [03:25<01:56,  6.29it/s, est. speed input: 6531.76 toks/s, output: 6.38 toks/s]
Processed prompts:  65%|   | 1330/2048 [03:28<01:52,  6.37it/s, est. speed input: 6534.08 toks/s, output: 6.38 toks/s]
Processed prompts:  66%|   | 1346/2048 [03:30<01:50,  6.34it/s, est. speed input: 6532.69 toks/s, output: 6.38 toks/s]
Processed prompts:  67%|   | 1362/2048 [03:33<01:48,  6.32it/s, est. speed input: 6531.34 toks/s, output: 6.38 toks/s]
Processed prompts:  67%|   | 1378/2048 [03:36<01:46,  6.30it/s, est. speed input: 6529.72 toks/s, output: 6.38 toks/s]
Processed prompts:  68%|   | 1394/2048 [03:38<01:43,  6.29it/s, est. speed input: 6528.54 toks/s, output: 6.38 toks/s]
Processed prompts:  69%|   | 1410/2048 [03:41<01:41,  6.28it/s, est. speed input: 6526.91 toks/s, output: 6.37 toks/s]
Processed prompts:  70%|   | 1426/2048 [03:43<01:39,  6.27it/s, est. speed input: 6525.74 toks/s, output: 6.37 toks/s]
Processed prompts:  70%|   | 1442/2048 [03:46<01:35,  6.36it/s, est. speed input: 6528.03 toks/s, output: 6.38 toks/s]
Processed prompts:  71%|   | 1458/2048 [03:48<01:31,  6.43it/s, est. speed input: 6530.21 toks/s, output: 6.38 toks/s]
Processed prompts:  72%|  | 1474/2048 [03:51<01:29,  6.38it/s, est. speed input: 6529.02 toks/s, output: 6.38 toks/s]
Processed prompts:  73%|  | 1490/2048 [03:53<01:27,  6.34it/s, est. speed input: 6527.69 toks/s, output: 6.37 toks/s]
Processed prompts:  74%|  | 1506/2048 [03:56<01:25,  6.32it/s, est. speed input: 6526.42 toks/s, output: 6.37 toks/s]
Processed prompts:  74%|  | 1522/2048 [03:58<01:22,  6.39it/s, est. speed input: 6528.56 toks/s, output: 6.38 toks/s]
Processed prompts:  75%|  | 1538/2048 [04:01<01:20,  6.35it/s, est. speed input: 6527.22 toks/s, output: 6.37 toks/s]
Processed prompts:  76%|  | 1554/2048 [04:03<01:16,  6.42it/s, est. speed input: 6529.36 toks/s, output: 6.38 toks/s]
Processed prompts:  77%|  | 1570/2048 [04:06<01:14,  6.38it/s, est. speed input: 6528.43 toks/s, output: 6.38 toks/s]
Processed prompts:  77%|  | 1586/2048 [04:08<01:12,  6.34it/s, est. speed input: 6527.14 toks/s, output: 6.37 toks/s]
Processed prompts:  78%|  | 1602/2048 [04:11<01:10,  6.32it/s, est. speed input: 6525.92 toks/s, output: 6.37 toks/s]
Processed prompts:  79%|  | 1618/2048 [04:13<01:07,  6.40it/s, est. speed input: 6528.18 toks/s, output: 6.38 toks/s]
Processed prompts:  80%|  | 1634/2048 [04:16<01:05,  6.36it/s, est. speed input: 6527.03 toks/s, output: 6.37 toks/s]
Processed prompts:  81%|  | 1650/2048 [04:18<01:02,  6.33it/s, est. speed input: 6526.06 toks/s, output: 6.37 toks/s]
Processed prompts:  81%| | 1666/2048 [04:21<01:00,  6.32it/s, est. speed input: 6525.17 toks/s, output: 6.37 toks/s]
Processed prompts:  82%| | 1682/2048 [04:24<00:58,  6.30it/s, est. speed input: 6524.00 toks/s, output: 6.37 toks/s]
Processed prompts:  83%| | 1698/2048 [04:26<00:55,  6.29it/s, est. speed input: 6522.90 toks/s, output: 6.37 toks/s]
Processed prompts:  84%| | 1714/2048 [04:29<00:53,  6.28it/s, est. speed input: 6521.86 toks/s, output: 6.37 toks/s]
Processed prompts:  84%| | 1730/2048 [04:31<00:49,  6.37it/s, est. speed input: 6523.80 toks/s, output: 6.37 toks/s]
Processed prompts:  85%| | 1746/2048 [04:33<00:46,  6.55it/s, est. speed input: 6529.41 toks/s, output: 6.38 toks/s]
Processed prompts:  86%| | 1762/2048 [04:36<00:44,  6.46it/s, est. speed input: 6528.36 toks/s, output: 6.38 toks/s]
Processed prompts:  87%| | 1778/2048 [04:38<00:42,  6.40it/s, est. speed input: 6527.27 toks/s, output: 6.37 toks/s]
Processed prompts:  88%| | 1794/2048 [04:41<00:39,  6.36it/s, est. speed input: 6526.23 toks/s, output: 6.37 toks/s]
Processed prompts:  88%| | 1810/2048 [04:44<00:37,  6.33it/s, est. speed input: 6525.11 toks/s, output: 6.37 toks/s]
Processed prompts:  89%| | 1826/2048 [04:46<00:35,  6.31it/s, est. speed input: 6524.13 toks/s, output: 6.37 toks/s]
Processed prompts:  90%| | 1842/2048 [04:49<00:32,  6.29it/s, est. speed input: 6523.16 toks/s, output: 6.37 toks/s]
Processed prompts:  91%| | 1858/2048 [04:51<00:30,  6.29it/s, est. speed input: 6522.34 toks/s, output: 6.37 toks/s]
Processed prompts:  92%|| 1874/2048 [04:54<00:27,  6.28it/s, est. speed input: 6521.41 toks/s, output: 6.37 toks/s]
Processed prompts:  92%|| 1890/2048 [04:56<00:24,  6.36it/s, est. speed input: 6523.05 toks/s, output: 6.37 toks/s]
Processed prompts:  93%|| 1906/2048 [04:59<00:22,  6.34it/s, est. speed input: 6522.24 toks/s, output: 6.37 toks/s]
Processed prompts:  94%|| 1922/2048 [05:01<00:19,  6.31it/s, est. speed input: 6521.03 toks/s, output: 6.37 toks/s]
Processed prompts:  95%|| 1938/2048 [05:04<00:17,  6.29it/s, est. speed input: 6520.06 toks/s, output: 6.37 toks/s]
Processed prompts:  95%|| 1954/2048 [05:06<00:14,  6.28it/s, est. speed input: 6519.07 toks/s, output: 6.37 toks/s]
Processed prompts:  96%|| 1970/2048 [05:09<00:12,  6.27it/s, est. speed input: 6518.18 toks/s, output: 6.37 toks/s]
Processed prompts:  97%|| 1986/2048 [05:11<00:09,  6.37it/s, est. speed input: 6519.99 toks/s, output: 6.37 toks/s]
Processed prompts:  98%|| 2002/2048 [05:14<00:07,  6.33it/s, est. speed input: 6518.99 toks/s, output: 6.37 toks/s]
Processed prompts:  99%|| 2018/2048 [05:17<00:04,  6.31it/s, est. speed input: 6518.13 toks/s, output: 6.37 toks/s]
Processed prompts:  99%|| 2034/2048 [05:19<00:02,  6.41it/s, est. speed input: 6520.40 toks/s, output: 6.37 toks/s]
Processed prompts: 100%|| 2048/2048 [05:19<00:00,  6.41it/s, est. speed input: 6565.28 toks/s, output: 6.41 toks/s]
Processed prompts: 100%|| 2048/2048 [05:19<00:00,  6.41it/s, est. speed input: 6565.28 toks/s, output: 6.41 toks/s]
[rank0]:[W126 15:38:31.065881454 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 15:38:34
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:38:52 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 15:38:52 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1453309) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1453309) WARNING 01-26 15:40:17 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 6.33 requests/s, 6483.84 total tokens/s, 6.33 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 15:38:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:38:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:38:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:38:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:38:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:38:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:38:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:38:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:38:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:38:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:38:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:38:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:38:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:38:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:38:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:38:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:38:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:38:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:38:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:38:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:38:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:38:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:38:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:38:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:38:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:38:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:38:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:38:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1453309) [2026-01-26 15:38:57] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1453309) [2026-01-26 15:38:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1453309) [2026-01-26 15:38:57] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1453309) [2026-01-26 15:38:57] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1453309) [2026-01-26 15:38:57] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1453309) [2026-01-26 15:38:57] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1453309) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1453309) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:24<00:24, 24.89s/it]
(EngineCore_DP0 pid=1453309) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:59<00:00, 30.36s/it]
(EngineCore_DP0 pid=1453309) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:59<00:00, 29.54s/it]
(EngineCore_DP0 pid=1453309) 
(EngineCore_DP0 pid=1453309) [2026-01-26 15:39:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1453309) [2026-01-26 15:39:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=1453309) [2026-01-26 15:39:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1453309) [2026-01-26 15:39:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=1453309) [2026-01-26 15:39:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1453309) [2026-01-26 15:39:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=1453309) [2026-01-26 15:39:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1453309) [2026-01-26 15:39:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=1453309) 2026-01-26 15:40:09,072 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1453309) 2026-01-26 15:40:10,440 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 45/4096 [00:00<00:09, 448.11it/s]
Adding requests:   2%|         | 90/4096 [00:00<00:09, 423.61it/s]
Adding requests:   3%|         | 133/4096 [00:00<00:09, 407.08it/s]
Adding requests:   4%|         | 174/4096 [00:00<00:09, 398.45it/s]
Adding requests:   5%|         | 217/4096 [00:00<00:09, 409.05it/s]
Adding requests:   6%|         | 258/4096 [00:00<00:09, 392.97it/s]
Adding requests:   7%|         | 301/4096 [00:00<00:09, 402.00it/s]
Adding requests:   8%|         | 342/4096 [00:00<00:09, 401.94it/s]
Adding requests:   9%|         | 386/4096 [00:00<00:08, 412.74it/s]
Adding requests:  11%|         | 431/4096 [00:01<00:08, 423.97it/s]
Adding requests:  12%|        | 474/4096 [00:01<00:08, 420.22it/s]
Adding requests:  13%|        | 525/4096 [00:01<00:08, 443.28it/s]
Adding requests:  14%|        | 570/4096 [00:01<00:08, 433.27it/s]
Adding requests:  15%|        | 614/4096 [00:01<00:08, 423.61it/s]
Adding requests:  16%|        | 657/4096 [00:01<00:08, 421.34it/s]
Adding requests:  17%|        | 701/4096 [00:01<00:07, 425.74it/s]
Adding requests:  18%|        | 744/4096 [00:01<00:07, 424.40it/s]
Adding requests:  19%|        | 787/4096 [00:01<00:07, 420.73it/s]
Adding requests:  20%|        | 831/4096 [00:01<00:07, 423.60it/s]
Adding requests:  21%|       | 874/4096 [00:02<00:07, 416.46it/s]
Adding requests:  22%|       | 916/4096 [00:02<00:07, 416.82it/s]
Adding requests:  23%|       | 958/4096 [00:02<00:07, 416.22it/s]
Adding requests:  24%|       | 1000/4096 [00:02<00:07, 409.54it/s]
Adding requests:  25%|       | 1043/4096 [00:02<00:07, 414.24it/s]
Adding requests:  26%|       | 1085/4096 [00:02<00:07, 402.94it/s]
Adding requests:  27%|       | 1126/4096 [00:02<00:07, 404.05it/s]
Adding requests:  28%|       | 1167/4096 [00:02<00:07, 397.31it/s]
Adding requests:  29%|       | 1207/4096 [00:02<00:07, 366.59it/s]
Adding requests:  31%|       | 1251/4096 [00:03<00:07, 386.72it/s]
Adding requests:  32%|      | 1291/4096 [00:03<00:07, 377.74it/s]
Adding requests:  33%|      | 1333/4096 [00:03<00:07, 385.66it/s]
Adding requests:  34%|      | 1376/4096 [00:03<00:06, 397.01it/s]
Adding requests:  35%|      | 1417/4096 [00:03<00:06, 398.42it/s]
Adding requests:  36%|      | 1462/4096 [00:03<00:06, 412.72it/s]
Adding requests:  37%|      | 1504/4096 [00:03<00:06, 410.92it/s]
Adding requests:  38%|      | 1549/4096 [00:03<00:06, 421.56it/s]
Adding requests:  39%|      | 1592/4096 [00:03<00:06, 410.43it/s]
Adding requests:  40%|      | 1634/4096 [00:03<00:06, 406.46it/s]
Adding requests:  41%|      | 1675/4096 [00:04<00:06, 400.41it/s]
Adding requests:  42%|     | 1716/4096 [00:04<00:05, 401.64it/s]
Adding requests:  43%|     | 1759/4096 [00:04<00:05, 408.99it/s]
Adding requests:  44%|     | 1801/4096 [00:04<00:05, 409.35it/s]
Adding requests:  45%|     | 1845/4096 [00:04<00:05, 416.72it/s]
Adding requests:  46%|     | 1887/4096 [00:04<00:05, 413.34it/s]
Adding requests:  47%|     | 1930/4096 [00:04<00:05, 414.78it/s]
Adding requests:  48%|     | 1972/4096 [00:04<00:05, 406.91it/s]
Adding requests:  49%|     | 2013/4096 [00:04<00:05, 396.85it/s]
Adding requests:  50%|     | 2056/4096 [00:05<00:05, 403.94it/s]
Adding requests:  51%|     | 2097/4096 [00:05<00:05, 396.62it/s]
Adding requests:  52%|    | 2140/4096 [00:05<00:04, 402.82it/s]
Adding requests:  53%|    | 2181/4096 [00:05<00:04, 396.45it/s]
Adding requests:  54%|    | 2221/4096 [00:05<00:04, 386.59it/s]
Adding requests:  55%|    | 2262/4096 [00:05<00:04, 391.30it/s]
Adding requests:  56%|    | 2307/4096 [00:05<00:04, 405.76it/s]
Adding requests:  57%|    | 2353/4096 [00:05<00:04, 420.02it/s]
Adding requests:  58%|    | 2396/4096 [00:05<00:04, 418.24it/s]
Adding requests:  60%|    | 2438/4096 [00:05<00:04, 412.25it/s]
Adding requests:  61%|    | 2480/4096 [00:06<00:04, 400.56it/s]
Adding requests:  62%|   | 2524/4096 [00:06<00:03, 411.46it/s]
Adding requests:  63%|   | 2570/4096 [00:06<00:03, 422.74it/s]
Adding requests:  64%|   | 2613/4096 [00:06<00:03, 420.61it/s]
Adding requests:  65%|   | 2656/4096 [00:06<00:03, 422.81it/s]
Adding requests:  66%|   | 2699/4096 [00:06<00:03, 406.47it/s]
Adding requests:  67%|   | 2743/4096 [00:06<00:03, 415.86it/s]
Adding requests:  68%|   | 2785/4096 [00:06<00:03, 416.09it/s]
Adding requests:  69%|   | 2827/4096 [00:06<00:03, 416.60it/s]
Adding requests:  70%|   | 2869/4096 [00:07<00:02, 416.77it/s]
Adding requests:  71%|   | 2911/4096 [00:07<00:02, 416.35it/s]
Adding requests:  72%|  | 2957/4096 [00:07<00:02, 428.77it/s]
Adding requests:  73%|  | 3000/4096 [00:07<00:02, 424.41it/s]
Adding requests:  74%|  | 3046/4096 [00:07<00:02, 434.59it/s]
Adding requests:  75%|  | 3090/4096 [00:07<00:02, 428.56it/s]
Adding requests:  76%|  | 3133/4096 [00:07<00:02, 428.55it/s]
Adding requests:  78%|  | 3176/4096 [00:07<00:02, 414.59it/s]
Adding requests:  79%|  | 3220/4096 [00:07<00:02, 419.97it/s]
Adding requests:  80%|  | 3263/4096 [00:07<00:01, 417.57it/s]
Adding requests:  81%|  | 3305/4096 [00:08<00:01, 404.54it/s]
Adding requests:  82%| | 3350/4096 [00:08<00:01, 417.10it/s]
Adding requests:  83%| | 3392/4096 [00:08<00:01, 408.26it/s]
Adding requests:  84%| | 3435/4096 [00:08<00:01, 412.46it/s]
Adding requests:  85%| | 3479/4096 [00:08<00:01, 419.27it/s]
Adding requests:  86%| | 3522/4096 [00:08<00:01, 408.81it/s]
Adding requests:  87%| | 3569/4096 [00:08<00:01, 425.56it/s]
Adding requests:  88%| | 3612/4096 [00:08<00:01, 414.79it/s]
Adding requests:  89%| | 3657/4096 [00:08<00:01, 423.11it/s]
Adding requests:  90%| | 3700/4096 [00:08<00:00, 406.34it/s]
Adding requests:  91%|| 3741/4096 [00:09<00:00, 406.49it/s]
Adding requests:  92%|| 3782/4096 [00:09<00:00, 406.29it/s]
Adding requests:  93%|| 3823/4096 [00:09<00:00, 369.63it/s]
Adding requests:  94%|| 3864/4096 [00:09<00:00, 376.92it/s]
Adding requests:  95%|| 3904/4096 [00:09<00:00, 382.79it/s]
Adding requests:  96%|| 3944/4096 [00:09<00:00, 387.24it/s]
Adding requests:  97%|| 3988/4096 [00:09<00:00, 400.07it/s]
Adding requests:  98%|| 4030/4096 [00:09<00:00, 403.07it/s]
Adding requests:  99%|| 4074/4096 [00:09<00:00, 410.22it/s]
Adding requests: 100%|| 4096/4096 [00:10<00:00, 409.27it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 34/4096 [00:00<00:48, 82.95it/s, est. speed input: 84951.93 toks/s, output: 82.95 toks/s]
Processed prompts:   2%|         | 66/4096 [00:05<06:27, 10.39it/s, est. speed input: 12303.42 toks/s, output: 12.01 toks/s]
Processed prompts:   2%|         | 98/4096 [00:10<08:16,  8.05it/s, est. speed input: 9504.61 toks/s, output: 9.28 toks/s]  
Processed prompts:   3%|         | 130/4096 [00:15<09:05,  7.26it/s, est. speed input: 8514.56 toks/s, output: 8.31 toks/s]
Processed prompts:   4%|         | 162/4096 [00:21<10:18,  6.36it/s, est. speed input: 7612.58 toks/s, output: 7.43 toks/s]
Processed prompts:   5%|         | 194/4096 [00:26<10:10,  6.39it/s, est. speed input: 7425.55 toks/s, output: 7.25 toks/s]
Processed prompts:   6%|         | 226/4096 [00:31<10:08,  6.36it/s, est. speed input: 7271.67 toks/s, output: 7.10 toks/s]
Processed prompts:   6%|         | 258/4096 [00:36<10:05,  6.34it/s, est. speed input: 7158.97 toks/s, output: 6.99 toks/s]
Processed prompts:   7%|         | 290/4096 [00:41<09:56,  6.38it/s, est. speed input: 7094.29 toks/s, output: 6.93 toks/s]
Processed prompts:   8%|         | 322/4096 [00:46<09:53,  6.36it/s, est. speed input: 7026.05 toks/s, output: 6.86 toks/s]
Processed prompts:   9%|         | 354/4096 [00:52<09:51,  6.33it/s, est. speed input: 6966.84 toks/s, output: 6.80 toks/s]
Processed prompts:   9%|         | 386/4096 [00:57<09:47,  6.32it/s, est. speed input: 6919.62 toks/s, output: 6.76 toks/s]
Processed prompts:  10%|         | 418/4096 [01:02<09:39,  6.35it/s, est. speed input: 6893.02 toks/s, output: 6.73 toks/s]
Processed prompts:  11%|         | 450/4096 [01:07<09:35,  6.33it/s, est. speed input: 6858.99 toks/s, output: 6.70 toks/s]
Processed prompts:  12%|        | 482/4096 [01:12<09:31,  6.32it/s, est. speed input: 6830.01 toks/s, output: 6.67 toks/s]
Processed prompts:  13%|        | 514/4096 [01:17<09:27,  6.31it/s, est. speed input: 6804.93 toks/s, output: 6.65 toks/s]
Processed prompts:  13%|        | 546/4096 [01:22<09:22,  6.31it/s, est. speed input: 6782.46 toks/s, output: 6.62 toks/s]
Processed prompts:  14%|        | 578/4096 [01:27<09:18,  6.30it/s, est. speed input: 6761.34 toks/s, output: 6.60 toks/s]
Processed prompts:  15%|        | 610/4096 [01:32<09:14,  6.29it/s, est. speed input: 6743.37 toks/s, output: 6.59 toks/s]
Processed prompts:  16%|        | 642/4096 [01:37<09:09,  6.29it/s, est. speed input: 6727.56 toks/s, output: 6.57 toks/s]
Processed prompts:  16%|        | 674/4096 [01:42<09:04,  6.29it/s, est. speed input: 6713.15 toks/s, output: 6.56 toks/s]
Processed prompts:  17%|        | 706/4096 [01:47<08:58,  6.29it/s, est. speed input: 6700.27 toks/s, output: 6.54 toks/s]
Processed prompts:  18%|        | 738/4096 [01:52<08:53,  6.29it/s, est. speed input: 6688.84 toks/s, output: 6.53 toks/s]
Processed prompts:  19%|        | 770/4096 [01:57<08:45,  6.33it/s, est. speed input: 6683.74 toks/s, output: 6.53 toks/s]
Processed prompts:  20%|        | 802/4096 [02:03<08:41,  6.32it/s, est. speed input: 6673.85 toks/s, output: 6.52 toks/s]
Processed prompts:  20%|        | 834/4096 [02:08<08:37,  6.31it/s, est. speed input: 6664.43 toks/s, output: 6.51 toks/s]
Processed prompts:  21%|        | 866/4096 [02:13<08:32,  6.30it/s, est. speed input: 6656.09 toks/s, output: 6.50 toks/s]
Processed prompts:  22%|       | 898/4096 [02:18<08:27,  6.30it/s, est. speed input: 6648.62 toks/s, output: 6.49 toks/s]
Processed prompts:  23%|       | 930/4096 [02:23<08:22,  6.30it/s, est. speed input: 6641.51 toks/s, output: 6.49 toks/s]
Processed prompts:  23%|       | 962/4096 [02:28<08:18,  6.29it/s, est. speed input: 6633.42 toks/s, output: 6.48 toks/s]
Processed prompts:  24%|       | 994/4096 [02:33<08:13,  6.29it/s, est. speed input: 6627.38 toks/s, output: 6.47 toks/s]
Processed prompts:  25%|       | 1026/4096 [02:38<08:08,  6.29it/s, est. speed input: 6621.30 toks/s, output: 6.47 toks/s]
Processed prompts:  26%|       | 1058/4096 [02:43<08:02,  6.29it/s, est. speed input: 6615.72 toks/s, output: 6.46 toks/s]
Processed prompts:  27%|       | 1090/4096 [02:48<07:57,  6.29it/s, est. speed input: 6610.55 toks/s, output: 6.46 toks/s]
Processed prompts:  27%|       | 1122/4096 [02:53<07:53,  6.29it/s, est. speed input: 6605.20 toks/s, output: 6.45 toks/s]
Processed prompts:  28%|       | 1154/4096 [02:59<07:47,  6.29it/s, est. speed input: 6600.38 toks/s, output: 6.45 toks/s]
Processed prompts:  29%|       | 1186/4096 [03:04<07:39,  6.33it/s, est. speed input: 6600.27 toks/s, output: 6.45 toks/s]
Processed prompts:  30%|       | 1218/4096 [03:08<07:32,  6.36it/s, est. speed input: 6599.97 toks/s, output: 6.45 toks/s]
Processed prompts:  31%|       | 1250/4096 [03:14<07:28,  6.34it/s, est. speed input: 6595.94 toks/s, output: 6.44 toks/s]
Processed prompts:  31%|      | 1282/4096 [03:19<07:24,  6.33it/s, est. speed input: 6592.06 toks/s, output: 6.44 toks/s]
Processed prompts:  32%|      | 1314/4096 [03:24<07:17,  6.36it/s, est. speed input: 6592.08 toks/s, output: 6.44 toks/s]
Processed prompts:  33%|      | 1346/4096 [03:29<07:13,  6.34it/s, est. speed input: 6588.59 toks/s, output: 6.43 toks/s]
Processed prompts:  34%|      | 1378/4096 [03:34<07:10,  6.31it/s, est. speed input: 6583.49 toks/s, output: 6.43 toks/s]
Processed prompts:  34%|      | 1410/4096 [03:39<07:06,  6.30it/s, est. speed input: 6579.74 toks/s, output: 6.43 toks/s]
Processed prompts:  35%|      | 1442/4096 [03:44<06:54,  6.40it/s, est. speed input: 6585.01 toks/s, output: 6.43 toks/s]
Processed prompts:  36%|      | 1474/4096 [03:49<06:51,  6.37it/s, est. speed input: 6581.92 toks/s, output: 6.43 toks/s]
Processed prompts:  37%|      | 1506/4096 [03:54<06:45,  6.39it/s, est. speed input: 6582.37 toks/s, output: 6.43 toks/s]
Processed prompts:  38%|      | 1538/4096 [03:59<06:39,  6.41it/s, est. speed input: 6582.72 toks/s, output: 6.43 toks/s]
Processed prompts:  38%|      | 1570/4096 [04:04<06:36,  6.38it/s, est. speed input: 6580.05 toks/s, output: 6.43 toks/s]
Processed prompts:  39%|      | 1602/4096 [04:09<06:29,  6.40it/s, est. speed input: 6580.35 toks/s, output: 6.43 toks/s]
Processed prompts:  40%|      | 1634/4096 [04:14<06:26,  6.37it/s, est. speed input: 6577.72 toks/s, output: 6.42 toks/s]
Processed prompts:  41%|      | 1666/4096 [04:19<06:23,  6.34it/s, est. speed input: 6575.09 toks/s, output: 6.42 toks/s]
Processed prompts:  41%|     | 1698/4096 [04:24<06:19,  6.33it/s, est. speed input: 6572.36 toks/s, output: 6.42 toks/s]
Processed prompts:  42%|     | 1730/4096 [04:29<06:05,  6.48it/s, est. speed input: 6580.46 toks/s, output: 6.43 toks/s]
Processed prompts:  43%|     | 1762/4096 [04:34<06:03,  6.42it/s, est. speed input: 6577.85 toks/s, output: 6.42 toks/s]
Processed prompts:  44%|     | 1794/4096 [04:39<06:01,  6.37it/s, est. speed input: 6574.79 toks/s, output: 6.42 toks/s]
Processed prompts:  45%|     | 1826/4096 [04:44<05:57,  6.35it/s, est. speed input: 6572.30 toks/s, output: 6.42 toks/s]
Processed prompts:  45%|     | 1858/4096 [04:49<05:53,  6.33it/s, est. speed input: 6570.03 toks/s, output: 6.42 toks/s]
Processed prompts:  46%|     | 1890/4096 [04:54<05:46,  6.37it/s, est. speed input: 6570.62 toks/s, output: 6.42 toks/s]
Processed prompts:  47%|     | 1922/4096 [04:59<05:42,  6.34it/s, est. speed input: 6568.38 toks/s, output: 6.41 toks/s]
Processed prompts:  48%|     | 1954/4096 [05:04<05:38,  6.33it/s, est. speed input: 6566.26 toks/s, output: 6.41 toks/s]
Processed prompts:  48%|     | 1986/4096 [05:09<05:31,  6.36it/s, est. speed input: 6566.64 toks/s, output: 6.41 toks/s]
Processed prompts:  49%|     | 2018/4096 [05:14<05:27,  6.34it/s, est. speed input: 6564.68 toks/s, output: 6.41 toks/s]
Processed prompts:  50%|     | 2050/4096 [05:19<05:21,  6.37it/s, est. speed input: 6564.99 toks/s, output: 6.41 toks/s]
Processed prompts:  51%|     | 2082/4096 [05:24<05:17,  6.34it/s, est. speed input: 6563.13 toks/s, output: 6.41 toks/s]
Processed prompts:  52%|    | 2114/4096 [05:29<05:13,  6.33it/s, est. speed input: 6561.29 toks/s, output: 6.41 toks/s]
Processed prompts:  52%|    | 2146/4096 [05:35<05:08,  6.31it/s, est. speed input: 6559.18 toks/s, output: 6.41 toks/s]
Processed prompts:  53%|    | 2178/4096 [05:39<05:01,  6.35it/s, est. speed input: 6559.78 toks/s, output: 6.41 toks/s]
Processed prompts:  54%|    | 2210/4096 [05:45<04:58,  6.33it/s, est. speed input: 6557.63 toks/s, output: 6.40 toks/s]
Processed prompts:  55%|    | 2242/4096 [05:50<04:53,  6.32it/s, est. speed input: 6556.08 toks/s, output: 6.40 toks/s]
Processed prompts:  56%|    | 2274/4096 [05:55<04:48,  6.31it/s, est. speed input: 6554.57 toks/s, output: 6.40 toks/s]
Processed prompts:  56%|    | 2306/4096 [06:00<04:43,  6.30it/s, est. speed input: 6552.87 toks/s, output: 6.40 toks/s]
Processed prompts:  57%|    | 2338/4096 [06:05<04:37,  6.34it/s, est. speed input: 6553.35 toks/s, output: 6.40 toks/s]
Processed prompts:  58%|    | 2370/4096 [06:10<04:32,  6.33it/s, est. speed input: 6551.89 toks/s, output: 6.40 toks/s]
Processed prompts:  59%|    | 2402/4096 [06:15<04:28,  6.31it/s, est. speed input: 6549.86 toks/s, output: 6.40 toks/s]
Processed prompts:  59%|    | 2434/4096 [06:20<04:23,  6.30it/s, est. speed input: 6548.47 toks/s, output: 6.39 toks/s]
Processed prompts:  60%|    | 2466/4096 [06:25<04:18,  6.30it/s, est. speed input: 6546.99 toks/s, output: 6.39 toks/s]
Processed prompts:  61%|    | 2498/4096 [06:30<04:13,  6.30it/s, est. speed input: 6545.66 toks/s, output: 6.39 toks/s]
Processed prompts:  62%|   | 2530/4096 [06:35<04:06,  6.34it/s, est. speed input: 6546.39 toks/s, output: 6.39 toks/s]
Processed prompts:  63%|   | 2562/4096 [06:40<04:02,  6.33it/s, est. speed input: 6545.21 toks/s, output: 6.39 toks/s]
Processed prompts:  63%|   | 2594/4096 [06:45<03:56,  6.36it/s, est. speed input: 6545.87 toks/s, output: 6.39 toks/s]
Processed prompts:  64%|   | 2626/4096 [06:50<03:52,  6.33it/s, est. speed input: 6544.05 toks/s, output: 6.39 toks/s]
Processed prompts:  65%|   | 2658/4096 [06:55<03:45,  6.36it/s, est. speed input: 6544.76 toks/s, output: 6.39 toks/s]
Processed prompts:  66%|   | 2690/4096 [07:00<03:41,  6.34it/s, est. speed input: 6543.44 toks/s, output: 6.39 toks/s]
Processed prompts:  66%|   | 2722/4096 [07:05<03:35,  6.37it/s, est. speed input: 6544.12 toks/s, output: 6.39 toks/s]
Processed prompts:  67%|   | 2754/4096 [07:11<03:31,  6.35it/s, est. speed input: 6542.94 toks/s, output: 6.39 toks/s]
Processed prompts:  68%|   | 2786/4096 [07:16<03:26,  6.33it/s, est. speed input: 6541.77 toks/s, output: 6.39 toks/s]
Processed prompts:  69%|   | 2818/4096 [07:21<03:22,  6.31it/s, est. speed input: 6540.41 toks/s, output: 6.39 toks/s]
Processed prompts:  70%|   | 2850/4096 [07:26<03:17,  6.30it/s, est. speed input: 6539.21 toks/s, output: 6.39 toks/s]
Processed prompts:  70%|   | 2882/4096 [07:30<03:07,  6.46it/s, est. speed input: 6544.19 toks/s, output: 6.39 toks/s]
Processed prompts:  71%|   | 2914/4096 [07:35<03:03,  6.45it/s, est. speed input: 6544.67 toks/s, output: 6.39 toks/s]
Processed prompts:  72%|  | 2946/4096 [07:41<02:59,  6.40it/s, est. speed input: 6543.48 toks/s, output: 6.39 toks/s]
Processed prompts:  73%|  | 2978/4096 [07:45<02:54,  6.42it/s, est. speed input: 6544.12 toks/s, output: 6.39 toks/s]
Processed prompts:  73%|  | 3010/4096 [07:51<02:50,  6.37it/s, est. speed input: 6542.71 toks/s, output: 6.39 toks/s]
Processed prompts:  74%|  | 3042/4096 [07:56<02:46,  6.35it/s, est. speed input: 6541.66 toks/s, output: 6.39 toks/s]
Processed prompts:  75%|  | 3074/4096 [08:01<02:41,  6.33it/s, est. speed input: 6540.60 toks/s, output: 6.39 toks/s]
Processed prompts:  76%|  | 3106/4096 [08:06<02:36,  6.32it/s, est. speed input: 6539.49 toks/s, output: 6.39 toks/s]
Processed prompts:  77%|  | 3138/4096 [08:11<02:31,  6.31it/s, est. speed input: 6538.59 toks/s, output: 6.39 toks/s]
Processed prompts:  77%|  | 3170/4096 [08:16<02:25,  6.35it/s, est. speed input: 6539.08 toks/s, output: 6.39 toks/s]
Processed prompts:  78%|  | 3202/4096 [08:21<02:21,  6.33it/s, est. speed input: 6538.17 toks/s, output: 6.38 toks/s]
Processed prompts:  79%|  | 3234/4096 [08:26<02:16,  6.31it/s, est. speed input: 6537.01 toks/s, output: 6.38 toks/s]
Processed prompts:  80%|  | 3266/4096 [08:31<02:11,  6.30it/s, est. speed input: 6535.98 toks/s, output: 6.38 toks/s]
Processed prompts:  81%|  | 3298/4096 [08:36<02:06,  6.30it/s, est. speed input: 6534.94 toks/s, output: 6.38 toks/s]
Processed prompts:  81%| | 3330/4096 [08:41<02:01,  6.30it/s, est. speed input: 6534.03 toks/s, output: 6.38 toks/s]
Processed prompts:  82%| | 3362/4096 [08:46<01:56,  6.30it/s, est. speed input: 6533.30 toks/s, output: 6.38 toks/s]
Processed prompts:  83%| | 3394/4096 [08:51<01:50,  6.34it/s, est. speed input: 6533.97 toks/s, output: 6.38 toks/s]
Processed prompts:  84%| | 3426/4096 [08:57<01:46,  6.32it/s, est. speed input: 6532.75 toks/s, output: 6.38 toks/s]
Processed prompts:  84%| | 3458/4096 [09:02<01:41,  6.31it/s, est. speed input: 6531.82 toks/s, output: 6.38 toks/s]
Processed prompts:  85%| | 3490/4096 [09:07<01:36,  6.30it/s, est. speed input: 6531.04 toks/s, output: 6.38 toks/s]
Processed prompts:  86%| | 3522/4096 [09:12<01:31,  6.30it/s, est. speed input: 6530.17 toks/s, output: 6.38 toks/s]
Processed prompts:  87%| | 3554/4096 [09:17<01:25,  6.35it/s, est. speed input: 6530.91 toks/s, output: 6.38 toks/s]
Processed prompts:  88%| | 3586/4096 [09:22<01:20,  6.33it/s, est. speed input: 6530.17 toks/s, output: 6.38 toks/s]
Processed prompts:  88%| | 3618/4096 [09:27<01:15,  6.36it/s, est. speed input: 6530.57 toks/s, output: 6.38 toks/s]
Processed prompts:  89%| | 3650/4096 [09:32<01:10,  6.33it/s, est. speed input: 6529.65 toks/s, output: 6.38 toks/s]
Processed prompts:  90%| | 3682/4096 [09:37<01:04,  6.43it/s, est. speed input: 6532.01 toks/s, output: 6.38 toks/s]
Processed prompts:  91%| | 3714/4096 [09:42<00:59,  6.39it/s, est. speed input: 6531.32 toks/s, output: 6.38 toks/s]
Processed prompts:  91%|| 3746/4096 [09:47<00:55,  6.36it/s, est. speed input: 6530.47 toks/s, output: 6.38 toks/s]
Processed prompts:  92%|| 3778/4096 [09:52<00:50,  6.33it/s, est. speed input: 6529.67 toks/s, output: 6.38 toks/s]
Processed prompts:  93%|| 3810/4096 [09:57<00:45,  6.32it/s, est. speed input: 6528.91 toks/s, output: 6.38 toks/s]
Processed prompts:  94%|| 3842/4096 [10:02<00:40,  6.31it/s, est. speed input: 6528.07 toks/s, output: 6.38 toks/s]
Processed prompts:  95%|| 3874/4096 [10:07<00:35,  6.30it/s, est. speed input: 6527.37 toks/s, output: 6.37 toks/s]
Processed prompts:  95%|| 3906/4096 [10:12<00:29,  6.35it/s, est. speed input: 6528.01 toks/s, output: 6.38 toks/s]
Processed prompts:  96%|| 3938/4096 [10:17<00:24,  6.37it/s, est. speed input: 6528.54 toks/s, output: 6.38 toks/s]
Processed prompts:  97%|| 3970/4096 [10:22<00:19,  6.35it/s, est. speed input: 6527.84 toks/s, output: 6.37 toks/s]
Processed prompts:  98%|| 4002/4096 [10:27<00:14,  6.38it/s, est. speed input: 6528.45 toks/s, output: 6.38 toks/s]
Processed prompts:  98%|| 4034/4096 [10:32<00:09,  6.39it/s, est. speed input: 6528.79 toks/s, output: 6.38 toks/s]
Processed prompts:  99%|| 4066/4096 [10:37<00:04,  6.47it/s, est. speed input: 6531.05 toks/s, output: 6.38 toks/s]
Processed prompts: 100%|| 4096/4096 [10:37<00:00,  6.47it/s, est. speed input: 6579.23 toks/s, output: 6.43 toks/s]
Processed prompts: 100%|| 4096/4096 [10:37<00:00,  6.43it/s, est. speed input: 6579.23 toks/s, output: 6.43 toks/s]
[rank0]:[W126 15:51:05.662764521 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 15:51:07
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 15:51:39 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 15:51:39 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1464015) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 303, in forward
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     hidden_states = self.mlp(hidden_states)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 108, in forward
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     x, _ = self.down_proj(x)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1405, in forward
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     output_parallel = self.quant_method.apply(self, input_parallel, bias_)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 349, in quant_slide_int8_triton
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]     out = torch.zeros(M_padded, K_out_padded, dtype=torch.int8, device=x.device)
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866] Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=1464015) ERROR 01-26 15:52:46 [core.py:866] 

STDERR:
[2026-01-26 15:51:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:51:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:51:39] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:51:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:51:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:51:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:51:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:51:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:51:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:51:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:51:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:51:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:51:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:51:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 15:51:43] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 15:51:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:51:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 15:51:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:51:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:51:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:51:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:51:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 15:51:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 15:51:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 15:51:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 15:51:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 15:51:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 15:51:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1464015) [2026-01-26 15:51:44] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1464015) [2026-01-26 15:51:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1464015) [2026-01-26 15:51:44] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1464015) [2026-01-26 15:51:44] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1464015) [2026-01-26 15:51:44] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=1464015) [2026-01-26 15:51:44] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1464015) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1464015) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:24<00:24, 24.65s/it]
(EngineCore_DP0 pid=1464015) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:58<00:00, 30.28s/it]
(EngineCore_DP0 pid=1464015) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:58<00:00, 29.44s/it]
(EngineCore_DP0 pid=1464015) 
(EngineCore_DP0 pid=1464015) [2026-01-26 15:52:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1464015) [2026-01-26 15:52:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=1464015) [2026-01-26 15:52:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1464015) [2026-01-26 15:52:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=1464015) [2026-01-26 15:52:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1464015) [2026-01-26 15:52:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=1464015) [2026-01-26 15:52:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1464015) [2026-01-26 15:52:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=1464015) Process EngineCore_DP0:
(EngineCore_DP0 pid=1464015) Traceback (most recent call last):
(EngineCore_DP0 pid=1464015)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=1464015)     self.run()
(EngineCore_DP0 pid=1464015)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=1464015)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=1464015)     raise e
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1464015)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1464015)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1464015)     super().__init__(
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1464015)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1464015)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1464015)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1464015)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1464015)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1464015)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1464015)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1464015)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1464015)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1464015)     self.model_runner.profile_run()
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1464015)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1464015)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1464015)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1464015)     outputs = self.model(
(EngineCore_DP0 pid=1464015)               ^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1464015)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1464015)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1464015)     hidden_states = self.model(
(EngineCore_DP0 pid=1464015)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=1464015)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=1464015)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=1464015)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1464015)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1464015)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 303, in forward
(EngineCore_DP0 pid=1464015)     hidden_states = self.mlp(hidden_states)
(EngineCore_DP0 pid=1464015)                     ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1464015)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1464015)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 108, in forward
(EngineCore_DP0 pid=1464015)     x, _ = self.down_proj(x)
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1464015)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1464015)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1405, in forward
(EngineCore_DP0 pid=1464015)     output_parallel = self.quant_method.apply(self, input_parallel, bias_)
(EngineCore_DP0 pid=1464015)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=1464015)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 745, in apply_weights
(EngineCore_DP0 pid=1464015)     return self.slidesparse_int8_linear.apply(
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 534, in apply
(EngineCore_DP0 pid=1464015)     return self._linear_fn(
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 289, in cuSPARSELt_INT8_linear
(EngineCore_DP0 pid=1464015)     qinput, scale_a_pad = quant_slide_int8_kernel(input, model_name, L)
(EngineCore_DP0 pid=1464015)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/slidesparse/core/kernels.py", line 432, in quant_slide_int8_kernel
(EngineCore_DP0 pid=1464015)     return torch.ops.slidesparse.quant_slide_int8(input, model_name, L)
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=1464015)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=1464015)     return fn(input, L)
(EngineCore_DP0 pid=1464015)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 349, in quant_slide_int8_triton
(EngineCore_DP0 pid=1464015)     out = torch.zeros(M_padded, K_out_padded, dtype=torch.int8, device=x.device)
(EngineCore_DP0 pid=1464015)           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1464015) torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=1464015) Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=1464015) CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=1464015) For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=1464015) Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=1464015) 
[rank0]:[W126 15:52:47.527466682 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-27 00:47:32
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 00:47:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 00:47:38 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1922134) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1922134) WARNING 01-27 00:49:42 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 6.39 requests/s, 3277.38 total tokens/s, 6.39 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-27 00:47:38] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 00:47:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 00:47:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 00:47:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:47:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:47:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:47:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:47:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:47:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 00:47:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 00:47:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 00:47:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 00:47:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 00:47:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 00:47:42] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 00:47:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 00:47:42] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 00:47:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:47:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:47:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:47:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:47:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:47:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 00:47:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 00:47:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 00:47:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 00:47:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 00:47:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1922134) [2026-01-27 00:47:43] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1922134) [2026-01-27 00:47:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1922134) [2026-01-27 00:47:43] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1922134) [2026-01-27 00:47:43] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1922134) [2026-01-27 00:47:43] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1922134) [2026-01-27 00:47:43] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1922134) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1922134) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.55s/it]
(EngineCore_DP0 pid=1922134) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:42<00:46, 23.31s/it]
(EngineCore_DP0 pid=1922134) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:14<00:27, 27.24s/it]
(EngineCore_DP0 pid=1922134) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:47<00:00, 29.65s/it]
(EngineCore_DP0 pid=1922134) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:47<00:00, 26.86s/it]
(EngineCore_DP0 pid=1922134) 
(EngineCore_DP0 pid=1922134) [2026-01-27 00:49:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1922134) [2026-01-27 00:49:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36929536 bytes
(EngineCore_DP0 pid=1922134) [2026-01-27 00:49:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1922134) [2026-01-27 00:49:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26378240 bytes
(EngineCore_DP0 pid=1922134) [2026-01-27 00:49:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1922134) [2026-01-27 00:49:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 142442496 bytes
(EngineCore_DP0 pid=1922134) [2026-01-27 00:49:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1922134) [2026-01-27 00:49:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70778880 bytes
(EngineCore_DP0 pid=1922134) 2026-01-27 00:49:41,405 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1922134) 2026-01-27 00:49:41,460 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  70%|   | 90/128 [00:00<00:00, 893.45it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 904.47it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:39,  3.19it/s, est. speed input: 1634.90 toks/s, output: 3.19 toks/s]
Processed prompts:   2%|         | 2/128 [00:00<00:27,  4.52it/s, est. speed input: 2180.33 toks/s, output: 4.26 toks/s]
Processed prompts:   2%|         | 3/128 [00:00<00:23,  5.26it/s, est. speed input: 2466.55 toks/s, output: 4.82 toks/s]
Processed prompts:   3%|         | 4/128 [00:00<00:21,  5.68it/s, est. speed input: 2635.28 toks/s, output: 5.15 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:20,  5.98it/s, est. speed input: 2756.83 toks/s, output: 5.38 toks/s]
Processed prompts:   5%|         | 6/128 [00:01<00:20,  6.08it/s, est. speed input: 2824.63 toks/s, output: 5.52 toks/s]
Processed prompts:   5%|         | 7/128 [00:01<00:19,  6.26it/s, est. speed input: 2896.18 toks/s, output: 5.66 toks/s]
Processed prompts:   6%|         | 8/128 [00:01<00:18,  6.36it/s, est. speed input: 2947.40 toks/s, output: 5.76 toks/s]
Processed prompts:   7%|         | 9/128 [00:01<00:18,  6.43it/s, est. speed input: 2989.53 toks/s, output: 5.84 toks/s]
Processed prompts:   8%|         | 10/128 [00:01<00:18,  6.46it/s, est. speed input: 3021.67 toks/s, output: 5.90 toks/s]
Processed prompts:   9%|         | 11/128 [00:01<00:17,  6.50it/s, est. speed input: 3050.79 toks/s, output: 5.96 toks/s]
Processed prompts:   9%|         | 12/128 [00:02<00:17,  6.48it/s, est. speed input: 3069.31 toks/s, output: 5.99 toks/s]
Processed prompts:  10%|         | 13/128 [00:02<00:17,  6.41it/s, est. speed input: 3079.89 toks/s, output: 6.02 toks/s]
Processed prompts:  11%|         | 14/128 [00:02<00:17,  6.44it/s, est. speed input: 3096.69 toks/s, output: 6.05 toks/s]
Processed prompts:  12%|        | 15/128 [00:02<00:17,  6.48it/s, est. speed input: 3113.20 toks/s, output: 6.08 toks/s]
Processed prompts:  12%|        | 16/128 [00:02<00:17,  6.49it/s, est. speed input: 3126.01 toks/s, output: 6.11 toks/s]
Processed prompts:  13%|        | 17/128 [00:02<00:17,  6.51it/s, est. speed input: 3138.60 toks/s, output: 6.13 toks/s]
Processed prompts:  14%|        | 18/128 [00:02<00:16,  6.51it/s, est. speed input: 3149.01 toks/s, output: 6.15 toks/s]
Processed prompts:  15%|        | 19/128 [00:03<00:16,  6.44it/s, est. speed input: 3152.41 toks/s, output: 6.16 toks/s]
Processed prompts:  16%|        | 20/128 [00:03<00:16,  6.47it/s, est. speed input: 3161.81 toks/s, output: 6.18 toks/s]
Processed prompts:  16%|        | 21/128 [00:03<00:16,  6.47it/s, est. speed input: 3168.73 toks/s, output: 6.19 toks/s]
Processed prompts:  17%|        | 22/128 [00:03<00:16,  6.48it/s, est. speed input: 3175.54 toks/s, output: 6.20 toks/s]
Processed prompts:  18%|        | 23/128 [00:03<00:16,  6.50it/s, est. speed input: 3182.82 toks/s, output: 6.22 toks/s]
Processed prompts:  19%|        | 24/128 [00:03<00:15,  6.52it/s, est. speed input: 3190.17 toks/s, output: 6.23 toks/s]
Processed prompts:  20%|        | 25/128 [00:04<00:15,  6.54it/s, est. speed input: 3196.91 toks/s, output: 6.24 toks/s]
Processed prompts:  20%|        | 26/128 [00:04<00:15,  6.47it/s, est. speed input: 3198.38 toks/s, output: 6.25 toks/s]
Processed prompts:  21%|        | 27/128 [00:04<00:15,  6.53it/s, est. speed input: 3205.71 toks/s, output: 6.26 toks/s]
Processed prompts:  22%|       | 28/128 [00:04<00:15,  6.52it/s, est. speed input: 3209.97 toks/s, output: 6.27 toks/s]
Processed prompts:  23%|       | 29/128 [00:04<00:15,  6.52it/s, est. speed input: 3214.13 toks/s, output: 6.28 toks/s]
Processed prompts:  23%|       | 30/128 [00:04<00:15,  6.53it/s, est. speed input: 3218.84 toks/s, output: 6.29 toks/s]
Processed prompts:  24%|       | 31/128 [00:04<00:14,  6.52it/s, est. speed input: 3222.02 toks/s, output: 6.29 toks/s]
Processed prompts:  25%|       | 32/128 [00:05<00:14,  6.51it/s, est. speed input: 3225.19 toks/s, output: 6.30 toks/s]
Processed prompts:  26%|       | 33/128 [00:05<00:14,  6.46it/s, est. speed input: 3225.98 toks/s, output: 6.30 toks/s]
Processed prompts:  27%|       | 34/128 [00:05<00:14,  6.50it/s, est. speed input: 3229.94 toks/s, output: 6.31 toks/s]
Processed prompts:  27%|       | 35/128 [00:05<00:14,  6.54it/s, est. speed input: 3234.72 toks/s, output: 6.32 toks/s]
Processed prompts:  28%|       | 36/128 [00:05<00:14,  6.52it/s, est. speed input: 3236.88 toks/s, output: 6.32 toks/s]
Processed prompts:  29%|       | 37/128 [00:05<00:13,  6.50it/s, est. speed input: 3238.73 toks/s, output: 6.33 toks/s]
Processed prompts:  30%|       | 38/128 [00:06<00:13,  6.52it/s, est. speed input: 3241.82 toks/s, output: 6.33 toks/s]
Processed prompts:  30%|       | 39/128 [00:06<00:13,  6.53it/s, est. speed input: 3244.48 toks/s, output: 6.34 toks/s]
Processed prompts:  31%|      | 40/128 [00:06<00:13,  6.44it/s, est. speed input: 3243.39 toks/s, output: 6.33 toks/s]
Processed prompts:  32%|      | 41/128 [00:06<00:13,  6.45it/s, est. speed input: 3244.97 toks/s, output: 6.34 toks/s]
Processed prompts:  33%|      | 42/128 [00:06<00:13,  6.49it/s, est. speed input: 3247.98 toks/s, output: 6.34 toks/s]
Processed prompts:  34%|      | 43/128 [00:06<00:13,  6.50it/s, est. speed input: 3250.12 toks/s, output: 6.35 toks/s]
Processed prompts:  34%|      | 44/128 [00:06<00:12,  6.47it/s, est. speed input: 3250.57 toks/s, output: 6.35 toks/s]
Processed prompts:  35%|      | 45/128 [00:07<00:12,  6.49it/s, est. speed input: 3252.87 toks/s, output: 6.35 toks/s]
Processed prompts:  36%|      | 46/128 [00:07<00:12,  6.51it/s, est. speed input: 3255.10 toks/s, output: 6.36 toks/s]
Processed prompts:  37%|      | 47/128 [00:07<00:12,  6.44it/s, est. speed input: 3254.03 toks/s, output: 6.36 toks/s]
Processed prompts:  38%|      | 48/128 [00:07<00:12,  6.46it/s, est. speed input: 3255.79 toks/s, output: 6.36 toks/s]
Processed prompts:  38%|      | 49/128 [00:07<00:12,  6.48it/s, est. speed input: 3257.46 toks/s, output: 6.36 toks/s]
Processed prompts:  39%|      | 50/128 [00:07<00:12,  6.49it/s, est. speed input: 3259.12 toks/s, output: 6.37 toks/s]
Processed prompts:  40%|      | 51/128 [00:08<00:11,  6.47it/s, est. speed input: 3259.72 toks/s, output: 6.37 toks/s]
Processed prompts:  41%|      | 52/128 [00:08<00:11,  6.52it/s, est. speed input: 3262.21 toks/s, output: 6.37 toks/s]
Processed prompts:  41%|     | 53/128 [00:08<00:11,  6.49it/s, est. speed input: 3262.54 toks/s, output: 6.37 toks/s]
Processed prompts:  42%|     | 54/128 [00:08<00:11,  6.44it/s, est. speed input: 3262.11 toks/s, output: 6.37 toks/s]
Processed prompts:  43%|     | 55/128 [00:08<00:11,  6.44it/s, est. speed input: 3262.87 toks/s, output: 6.37 toks/s]
Processed prompts:  44%|     | 56/128 [00:08<00:11,  6.47it/s, est. speed input: 3264.21 toks/s, output: 6.38 toks/s]
Processed prompts:  45%|     | 57/128 [00:08<00:10,  6.49it/s, est. speed input: 3265.70 toks/s, output: 6.38 toks/s]
Processed prompts:  45%|     | 58/128 [00:09<00:10,  6.50it/s, est. speed input: 3267.02 toks/s, output: 6.38 toks/s]
Processed prompts:  46%|     | 59/128 [00:09<00:10,  6.52it/s, est. speed input: 3268.59 toks/s, output: 6.38 toks/s]
Processed prompts:  47%|     | 60/128 [00:09<00:10,  6.43it/s, est. speed input: 3267.19 toks/s, output: 6.38 toks/s]
Processed prompts:  48%|     | 61/128 [00:09<00:10,  6.47it/s, est. speed input: 3268.60 toks/s, output: 6.38 toks/s]
Processed prompts:  48%|     | 62/128 [00:09<00:10,  6.49it/s, est. speed input: 3269.98 toks/s, output: 6.39 toks/s]
Processed prompts:  49%|     | 63/128 [00:09<00:10,  6.49it/s, est. speed input: 3270.65 toks/s, output: 6.39 toks/s]
Processed prompts:  50%|     | 64/128 [00:10<00:09,  6.47it/s, est. speed input: 3271.07 toks/s, output: 6.39 toks/s]
Processed prompts:  51%|     | 65/128 [00:10<00:09,  6.50it/s, est. speed input: 3272.30 toks/s, output: 6.39 toks/s]
Processed prompts:  52%|    | 66/128 [00:10<00:09,  6.53it/s, est. speed input: 3273.87 toks/s, output: 6.39 toks/s]
Processed prompts:  52%|    | 67/128 [00:10<00:09,  6.43it/s, est. speed input: 3272.45 toks/s, output: 6.39 toks/s]
Processed prompts:  53%|    | 68/128 [00:10<00:09,  6.47it/s, est. speed input: 3273.76 toks/s, output: 6.39 toks/s]
Processed prompts:  54%|    | 69/128 [00:10<00:09,  6.49it/s, est. speed input: 3274.75 toks/s, output: 6.40 toks/s]
Processed prompts:  55%|    | 70/128 [00:10<00:08,  6.53it/s, est. speed input: 3276.34 toks/s, output: 6.40 toks/s]
Processed prompts:  55%|    | 71/128 [00:11<00:08,  6.55it/s, est. speed input: 3277.88 toks/s, output: 6.40 toks/s]
Processed prompts:  56%|    | 72/128 [00:11<00:08,  6.52it/s, est. speed input: 3278.11 toks/s, output: 6.40 toks/s]
Processed prompts:  57%|    | 73/128 [00:11<00:08,  6.53it/s, est. speed input: 3279.11 toks/s, output: 6.40 toks/s]
Processed prompts:  58%|    | 74/128 [00:11<00:08,  6.44it/s, est. speed input: 3277.97 toks/s, output: 6.40 toks/s]
Processed prompts:  59%|    | 75/128 [00:11<00:08,  6.46it/s, est. speed input: 3278.79 toks/s, output: 6.40 toks/s]
Processed prompts:  59%|    | 76/128 [00:11<00:08,  6.48it/s, est. speed input: 3279.57 toks/s, output: 6.41 toks/s]
Processed prompts:  60%|    | 77/128 [00:12<00:07,  6.43it/s, est. speed input: 3278.93 toks/s, output: 6.40 toks/s]
Processed prompts:  61%|    | 78/128 [00:12<00:07,  6.44it/s, est. speed input: 3279.28 toks/s, output: 6.40 toks/s]
Processed prompts:  62%|   | 79/128 [00:12<00:07,  6.46it/s, est. speed input: 3279.86 toks/s, output: 6.41 toks/s]
Processed prompts:  62%|   | 80/128 [00:12<00:07,  6.48it/s, est. speed input: 3280.74 toks/s, output: 6.41 toks/s]
Processed prompts:  63%|   | 81/128 [00:12<00:07,  6.44it/s, est. speed input: 3280.26 toks/s, output: 6.41 toks/s]
Processed prompts:  64%|   | 82/128 [00:12<00:07,  6.47it/s, est. speed input: 3281.03 toks/s, output: 6.41 toks/s]
Processed prompts:  65%|   | 83/128 [00:12<00:06,  6.47it/s, est. speed input: 3281.45 toks/s, output: 6.41 toks/s]
Processed prompts:  66%|   | 84/128 [00:13<00:06,  6.50it/s, est. speed input: 3282.43 toks/s, output: 6.41 toks/s]
Processed prompts:  66%|   | 85/128 [00:13<00:06,  6.52it/s, est. speed input: 3283.26 toks/s, output: 6.41 toks/s]
Processed prompts:  67%|   | 86/128 [00:13<00:06,  6.49it/s, est. speed input: 3283.31 toks/s, output: 6.41 toks/s]
Processed prompts:  68%|   | 87/128 [00:13<00:06,  6.50it/s, est. speed input: 3284.07 toks/s, output: 6.41 toks/s]
Processed prompts:  69%|   | 88/128 [00:13<00:06,  6.43it/s, est. speed input: 3283.19 toks/s, output: 6.41 toks/s]
Processed prompts:  70%|   | 89/128 [00:13<00:06,  6.47it/s, est. speed input: 3283.98 toks/s, output: 6.41 toks/s]
Processed prompts:  70%|   | 90/128 [00:14<00:05,  6.48it/s, est. speed input: 3284.43 toks/s, output: 6.41 toks/s]
Processed prompts:  71%|   | 91/128 [00:14<00:05,  6.49it/s, est. speed input: 3284.96 toks/s, output: 6.42 toks/s]
Processed prompts:  72%|  | 92/128 [00:14<00:05,  6.47it/s, est. speed input: 3285.13 toks/s, output: 6.42 toks/s]
Processed prompts:  73%|  | 93/128 [00:14<00:05,  6.49it/s, est. speed input: 3285.68 toks/s, output: 6.42 toks/s]
Processed prompts:  73%|  | 94/128 [00:14<00:05,  6.43it/s, est. speed input: 3284.95 toks/s, output: 6.42 toks/s]
Processed prompts:  74%|  | 95/128 [00:14<00:05,  6.45it/s, est. speed input: 3285.44 toks/s, output: 6.42 toks/s]
Processed prompts:  75%|  | 96/128 [00:14<00:04,  6.48it/s, est. speed input: 3286.20 toks/s, output: 6.42 toks/s]
Processed prompts:  76%|  | 97/128 [00:15<00:04,  6.50it/s, est. speed input: 3286.83 toks/s, output: 6.42 toks/s]
Processed prompts:  77%|  | 98/128 [00:15<00:04,  6.53it/s, est. speed input: 3287.72 toks/s, output: 6.42 toks/s]
Processed prompts:  77%|  | 99/128 [00:15<00:04,  6.50it/s, est. speed input: 3287.82 toks/s, output: 6.42 toks/s]
Processed prompts:  78%|  | 100/128 [00:15<00:04,  6.52it/s, est. speed input: 3288.52 toks/s, output: 6.42 toks/s]
Processed prompts:  79%|  | 101/128 [00:15<00:04,  6.48it/s, est. speed input: 3288.28 toks/s, output: 6.42 toks/s]
Processed prompts:  80%|  | 102/128 [00:15<00:04,  6.48it/s, est. speed input: 3288.67 toks/s, output: 6.42 toks/s]
Processed prompts:  80%|  | 103/128 [00:16<00:03,  6.51it/s, est. speed input: 3289.43 toks/s, output: 6.42 toks/s]
Processed prompts:  81%| | 104/128 [00:16<00:03,  6.50it/s, est. speed input: 3289.66 toks/s, output: 6.43 toks/s]
Processed prompts:  82%| | 105/128 [00:16<00:03,  6.50it/s, est. speed input: 3290.02 toks/s, output: 6.43 toks/s]
Processed prompts:  83%| | 106/128 [00:16<00:03,  6.51it/s, est. speed input: 3290.58 toks/s, output: 6.43 toks/s]
Processed prompts:  84%| | 107/128 [00:16<00:03,  6.53it/s, est. speed input: 3291.19 toks/s, output: 6.43 toks/s]
Processed prompts:  84%| | 108/128 [00:16<00:03,  6.44it/s, est. speed input: 3290.36 toks/s, output: 6.43 toks/s]
Processed prompts:  85%| | 109/128 [00:16<00:02,  6.45it/s, est. speed input: 3290.53 toks/s, output: 6.43 toks/s]
Processed prompts:  86%| | 110/128 [00:17<00:02,  6.47it/s, est. speed input: 3290.94 toks/s, output: 6.43 toks/s]
Processed prompts:  87%| | 111/128 [00:17<00:02,  6.49it/s, est. speed input: 3291.52 toks/s, output: 6.43 toks/s]
Processed prompts:  88%| | 112/128 [00:17<00:02,  6.47it/s, est. speed input: 3291.50 toks/s, output: 6.43 toks/s]
Processed prompts:  88%| | 113/128 [00:17<00:02,  6.50it/s, est. speed input: 3292.04 toks/s, output: 6.43 toks/s]
Processed prompts:  89%| | 114/128 [00:17<00:02,  6.48it/s, est. speed input: 3292.13 toks/s, output: 6.43 toks/s]
Processed prompts:  90%| | 115/128 [00:17<00:02,  6.40it/s, est. speed input: 3291.20 toks/s, output: 6.43 toks/s]
Processed prompts:  91%| | 116/128 [00:18<00:01,  6.42it/s, est. speed input: 3291.31 toks/s, output: 6.43 toks/s]
Processed prompts:  91%|| 117/128 [00:18<00:01,  6.47it/s, est. speed input: 3291.97 toks/s, output: 6.43 toks/s]
Processed prompts:  92%|| 118/128 [00:18<00:01,  6.50it/s, est. speed input: 3292.61 toks/s, output: 6.43 toks/s]
Processed prompts:  93%|| 119/128 [00:18<00:01,  6.54it/s, est. speed input: 3293.45 toks/s, output: 6.43 toks/s]
Processed prompts:  94%|| 120/128 [00:18<00:01,  6.54it/s, est. speed input: 3293.93 toks/s, output: 6.43 toks/s]
Processed prompts:  95%|| 121/128 [00:18<00:01,  6.53it/s, est. speed input: 3294.21 toks/s, output: 6.43 toks/s]
Processed prompts:  95%|| 122/128 [00:18<00:00,  6.43it/s, est. speed input: 3293.24 toks/s, output: 6.43 toks/s]
Processed prompts:  96%|| 123/128 [00:19<00:00,  6.45it/s, est. speed input: 3293.57 toks/s, output: 6.43 toks/s]
Processed prompts:  97%|| 124/128 [00:19<00:00,  6.48it/s, est. speed input: 3294.03 toks/s, output: 6.43 toks/s]
Processed prompts:  98%|| 125/128 [00:19<00:00,  6.48it/s, est. speed input: 3294.23 toks/s, output: 6.43 toks/s]
Processed prompts:  98%|| 126/128 [00:19<00:00,  6.51it/s, est. speed input: 3294.73 toks/s, output: 6.44 toks/s]
Processed prompts:  99%|| 127/128 [00:19<00:00,  6.51it/s, est. speed input: 3295.10 toks/s, output: 6.44 toks/s]
Processed prompts: 100%|| 128/128 [00:19<00:00,  6.44it/s, est. speed input: 3294.44 toks/s, output: 6.43 toks/s]
Processed prompts: 100%|| 128/128 [00:19<00:00,  6.44it/s, est. speed input: 3294.44 toks/s, output: 6.43 toks/s]
Processed prompts: 100%|| 128/128 [00:19<00:00,  6.43it/s, est. speed input: 3294.44 toks/s, output: 6.43 toks/s]
[rank0]:[W127 00:50:02.720685913 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-27 00:50:05
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 00:50:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 00:50:12 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1924461) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1924461) WARNING 01-27 00:52:19 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.64 requests/s, 3730.30 total tokens/s, 3.64 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-27 00:50:12] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 00:50:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 00:50:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 00:50:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:50:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:50:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:50:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:50:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:50:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 00:50:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 00:50:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 00:50:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 00:50:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 00:50:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 00:50:15] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 00:50:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 00:50:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 00:50:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:50:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:50:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:50:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:50:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:50:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 00:50:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 00:50:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 00:50:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 00:50:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 00:50:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1924461) [2026-01-27 00:50:16] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1924461) [2026-01-27 00:50:16] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1924461) [2026-01-27 00:50:16] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1924461) [2026-01-27 00:50:16] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1924461) [2026-01-27 00:50:16] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1924461) [2026-01-27 00:50:16] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1924461) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1924461) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.47s/it]
(EngineCore_DP0 pid=1924461) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:43<00:48, 24.22s/it]
(EngineCore_DP0 pid=1924461) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:16<00:28, 28.09s/it]
(EngineCore_DP0 pid=1924461) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:50<00:00, 30.47s/it]
(EngineCore_DP0 pid=1924461) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:50<00:00, 27.63s/it]
(EngineCore_DP0 pid=1924461) 
(EngineCore_DP0 pid=1924461) [2026-01-27 00:52:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1924461) [2026-01-27 00:52:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36929536 bytes
(EngineCore_DP0 pid=1924461) [2026-01-27 00:52:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1924461) [2026-01-27 00:52:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26378240 bytes
(EngineCore_DP0 pid=1924461) [2026-01-27 00:52:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1924461) [2026-01-27 00:52:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 142442496 bytes
(EngineCore_DP0 pid=1924461) [2026-01-27 00:52:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1924461) [2026-01-27 00:52:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70778880 bytes
(EngineCore_DP0 pid=1924461) 2026-01-27 00:52:18,284 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1924461) 2026-01-27 00:52:18,380 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  38%|      | 49/128 [00:00<00:00, 483.59it/s]
Adding requests:  80%|  | 103/128 [00:00<00:00, 512.82it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 500.34it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:30,  4.18it/s, est. speed input: 4284.45 toks/s, output: 4.18 toks/s]
Processed prompts:   2%|         | 2/128 [00:00<00:32,  3.88it/s, est. speed input: 4016.87 toks/s, output: 3.92 toks/s]
Processed prompts:   2%|         | 3/128 [00:00<00:32,  3.81it/s, est. speed input: 3951.34 toks/s, output: 3.86 toks/s]
Processed prompts:   3%|         | 4/128 [00:01<00:33,  3.74it/s, est. speed input: 3890.72 toks/s, output: 3.80 toks/s]
Processed prompts:   4%|         | 5/128 [00:01<00:33,  3.72it/s, est. speed input: 3867.95 toks/s, output: 3.78 toks/s]
Processed prompts:   5%|         | 6/128 [00:01<00:32,  3.71it/s, est. speed input: 3854.42 toks/s, output: 3.76 toks/s]
Processed prompts:   5%|         | 7/128 [00:01<00:32,  3.68it/s, est. speed input: 3832.69 toks/s, output: 3.74 toks/s]
Processed prompts:   6%|         | 8/128 [00:02<00:32,  3.68it/s, est. speed input: 3823.26 toks/s, output: 3.73 toks/s]
Processed prompts:   7%|         | 9/128 [00:02<00:32,  3.70it/s, est. speed input: 3824.57 toks/s, output: 3.73 toks/s]
Processed prompts:   8%|         | 10/128 [00:02<00:31,  3.70it/s, est. speed input: 3820.51 toks/s, output: 3.73 toks/s]
Processed prompts:   9%|         | 11/128 [00:02<00:31,  3.68it/s, est. speed input: 3810.93 toks/s, output: 3.72 toks/s]
Processed prompts:   9%|         | 12/128 [00:03<00:31,  3.68it/s, est. speed input: 3807.18 toks/s, output: 3.72 toks/s]
Processed prompts:  10%|         | 13/128 [00:03<00:31,  3.68it/s, est. speed input: 3804.17 toks/s, output: 3.71 toks/s]
Processed prompts:  11%|         | 14/128 [00:03<00:30,  3.70it/s, est. speed input: 3807.91 toks/s, output: 3.72 toks/s]
Processed prompts:  12%|        | 15/128 [00:04<00:30,  3.67it/s, est. speed input: 3798.50 toks/s, output: 3.71 toks/s]
Processed prompts:  12%|        | 16/128 [00:04<00:30,  3.69it/s, est. speed input: 3800.03 toks/s, output: 3.71 toks/s]
Processed prompts:  13%|        | 17/128 [00:04<00:30,  3.68it/s, est. speed input: 3797.83 toks/s, output: 3.71 toks/s]
Processed prompts:  14%|        | 18/128 [00:04<00:29,  3.69it/s, est. speed input: 3797.51 toks/s, output: 3.71 toks/s]
Processed prompts:  15%|        | 19/128 [00:05<00:29,  3.67it/s, est. speed input: 3792.51 toks/s, output: 3.70 toks/s]
Processed prompts:  16%|        | 20/128 [00:05<00:29,  3.67it/s, est. speed input: 3790.83 toks/s, output: 3.70 toks/s]
Processed prompts:  16%|        | 21/128 [00:05<00:29,  3.67it/s, est. speed input: 3789.92 toks/s, output: 3.70 toks/s]
Processed prompts:  17%|        | 22/128 [00:05<00:28,  3.67it/s, est. speed input: 3788.44 toks/s, output: 3.70 toks/s]
Processed prompts:  18%|        | 23/128 [00:06<00:28,  3.67it/s, est. speed input: 3786.60 toks/s, output: 3.70 toks/s]
Processed prompts:  19%|        | 24/128 [00:06<00:28,  3.67it/s, est. speed input: 3785.48 toks/s, output: 3.70 toks/s]
Processed prompts:  20%|        | 25/128 [00:06<00:27,  3.69it/s, est. speed input: 3786.92 toks/s, output: 3.70 toks/s]
Processed prompts:  20%|        | 26/128 [00:07<00:27,  3.69it/s, est. speed input: 3787.09 toks/s, output: 3.70 toks/s]
Processed prompts:  21%|        | 27/128 [00:07<00:27,  3.67it/s, est. speed input: 3784.34 toks/s, output: 3.70 toks/s]
Processed prompts:  22%|       | 28/128 [00:07<00:27,  3.67it/s, est. speed input: 3783.05 toks/s, output: 3.69 toks/s]
Processed prompts:  23%|       | 29/128 [00:07<00:26,  3.68it/s, est. speed input: 3783.08 toks/s, output: 3.69 toks/s]
Processed prompts:  23%|       | 30/128 [00:08<00:26,  3.68it/s, est. speed input: 3783.29 toks/s, output: 3.69 toks/s]
Processed prompts:  24%|       | 31/128 [00:08<00:26,  3.66it/s, est. speed input: 3779.96 toks/s, output: 3.69 toks/s]
Processed prompts:  25%|       | 32/128 [00:08<00:26,  3.67it/s, est. speed input: 3779.90 toks/s, output: 3.69 toks/s]
Processed prompts:  26%|       | 33/128 [00:08<00:25,  3.66it/s, est. speed input: 3778.79 toks/s, output: 3.69 toks/s]
Processed prompts:  27%|       | 34/128 [00:09<00:25,  3.66it/s, est. speed input: 3777.45 toks/s, output: 3.69 toks/s]
Processed prompts:  27%|       | 35/128 [00:09<00:25,  3.66it/s, est. speed input: 3777.14 toks/s, output: 3.69 toks/s]
Processed prompts:  28%|       | 36/128 [00:09<00:25,  3.66it/s, est. speed input: 3775.73 toks/s, output: 3.69 toks/s]
Processed prompts:  29%|       | 37/128 [00:10<00:24,  3.66it/s, est. speed input: 3775.35 toks/s, output: 3.69 toks/s]
Processed prompts:  30%|       | 38/128 [00:10<00:24,  3.63it/s, est. speed input: 3772.18 toks/s, output: 3.68 toks/s]
Processed prompts:  30%|       | 39/128 [00:10<00:24,  3.64it/s, est. speed input: 3771.27 toks/s, output: 3.68 toks/s]
Processed prompts:  31%|      | 40/128 [00:10<00:24,  3.65it/s, est. speed input: 3770.88 toks/s, output: 3.68 toks/s]
Processed prompts:  32%|      | 41/128 [00:11<00:23,  3.65it/s, est. speed input: 3770.00 toks/s, output: 3.68 toks/s]
Processed prompts:  33%|      | 42/128 [00:11<00:23,  3.63it/s, est. speed input: 3767.79 toks/s, output: 3.68 toks/s]
Processed prompts:  34%|      | 43/128 [00:11<00:23,  3.65it/s, est. speed input: 3768.38 toks/s, output: 3.68 toks/s]
Processed prompts:  34%|      | 44/128 [00:11<00:23,  3.64it/s, est. speed input: 3767.12 toks/s, output: 3.68 toks/s]
Processed prompts:  35%|      | 45/128 [00:12<00:22,  3.65it/s, est. speed input: 3766.80 toks/s, output: 3.68 toks/s]
Processed prompts:  36%|      | 46/128 [00:12<00:22,  3.63it/s, est. speed input: 3764.65 toks/s, output: 3.68 toks/s]
Processed prompts:  37%|      | 47/128 [00:12<00:22,  3.65it/s, est. speed input: 3764.99 toks/s, output: 3.68 toks/s]
Processed prompts:  38%|      | 48/128 [00:13<00:21,  3.66it/s, est. speed input: 3764.84 toks/s, output: 3.68 toks/s]
Processed prompts:  38%|      | 49/128 [00:13<00:21,  3.67it/s, est. speed input: 3765.23 toks/s, output: 3.68 toks/s]
Processed prompts:  39%|      | 50/128 [00:13<00:21,  3.64it/s, est. speed input: 3762.91 toks/s, output: 3.67 toks/s]
Processed prompts:  40%|      | 51/128 [00:13<00:21,  3.66it/s, est. speed input: 3763.88 toks/s, output: 3.68 toks/s]
Processed prompts:  41%|      | 52/128 [00:14<00:20,  3.66it/s, est. speed input: 3763.42 toks/s, output: 3.68 toks/s]
Processed prompts:  41%|     | 53/128 [00:14<00:20,  3.67it/s, est. speed input: 3763.68 toks/s, output: 3.68 toks/s]
Processed prompts:  42%|     | 54/128 [00:14<00:20,  3.64it/s, est. speed input: 3761.99 toks/s, output: 3.67 toks/s]
Processed prompts:  43%|     | 55/128 [00:14<00:19,  3.66it/s, est. speed input: 3762.70 toks/s, output: 3.67 toks/s]
Processed prompts:  44%|     | 56/128 [00:15<00:19,  3.68it/s, est. speed input: 3763.40 toks/s, output: 3.68 toks/s]
Processed prompts:  45%|     | 57/128 [00:15<00:19,  3.65it/s, est. speed input: 3761.81 toks/s, output: 3.67 toks/s]
Processed prompts:  45%|     | 58/128 [00:15<00:19,  3.65it/s, est. speed input: 3761.58 toks/s, output: 3.67 toks/s]
Processed prompts:  46%|     | 59/128 [00:16<00:18,  3.67it/s, est. speed input: 3761.99 toks/s, output: 3.67 toks/s]
Processed prompts:  47%|     | 60/128 [00:16<00:18,  3.67it/s, est. speed input: 3762.21 toks/s, output: 3.67 toks/s]
Processed prompts:  48%|     | 61/128 [00:16<00:18,  3.65it/s, est. speed input: 3760.76 toks/s, output: 3.67 toks/s]
Processed prompts:  48%|     | 62/128 [00:16<00:18,  3.66it/s, est. speed input: 3761.24 toks/s, output: 3.67 toks/s]
Processed prompts:  49%|     | 63/128 [00:17<00:17,  3.67it/s, est. speed input: 3761.59 toks/s, output: 3.67 toks/s]
Processed prompts:  50%|     | 64/128 [00:17<00:17,  3.68it/s, est. speed input: 3761.78 toks/s, output: 3.67 toks/s]
Processed prompts:  51%|     | 65/128 [00:17<00:17,  3.64it/s, est. speed input: 3760.10 toks/s, output: 3.67 toks/s]
Processed prompts:  52%|    | 66/128 [00:17<00:16,  3.66it/s, est. speed input: 3760.48 toks/s, output: 3.67 toks/s]
Processed prompts:  52%|    | 67/128 [00:18<00:16,  3.65it/s, est. speed input: 3759.76 toks/s, output: 3.67 toks/s]
Processed prompts:  53%|    | 68/128 [00:18<00:16,  3.67it/s, est. speed input: 3760.37 toks/s, output: 3.67 toks/s]
Processed prompts:  54%|    | 69/128 [00:18<00:16,  3.64it/s, est. speed input: 3758.96 toks/s, output: 3.67 toks/s]
Processed prompts:  55%|    | 70/128 [00:19<00:15,  3.65it/s, est. speed input: 3758.91 toks/s, output: 3.67 toks/s]
Processed prompts:  55%|    | 71/128 [00:19<00:15,  3.67it/s, est. speed input: 3759.68 toks/s, output: 3.67 toks/s]
Processed prompts:  56%|    | 72/128 [00:19<00:15,  3.68it/s, est. speed input: 3760.09 toks/s, output: 3.67 toks/s]
Processed prompts:  57%|    | 73/128 [00:19<00:15,  3.65it/s, est. speed input: 3758.95 toks/s, output: 3.67 toks/s]
Processed prompts:  58%|    | 74/128 [00:20<00:14,  3.66it/s, est. speed input: 3759.06 toks/s, output: 3.67 toks/s]
Processed prompts:  59%|    | 75/128 [00:20<00:14,  3.68it/s, est. speed input: 3759.79 toks/s, output: 3.67 toks/s]
Processed prompts:  59%|    | 76/128 [00:20<00:14,  3.67it/s, est. speed input: 3759.48 toks/s, output: 3.67 toks/s]
Processed prompts:  60%|    | 77/128 [00:20<00:13,  3.65it/s, est. speed input: 3758.54 toks/s, output: 3.67 toks/s]
Processed prompts:  61%|    | 78/128 [00:21<00:13,  3.66it/s, est. speed input: 3758.51 toks/s, output: 3.67 toks/s]
Processed prompts:  62%|   | 79/128 [00:21<00:13,  3.67it/s, est. speed input: 3758.95 toks/s, output: 3.67 toks/s]
Processed prompts:  62%|   | 80/128 [00:21<00:13,  3.67it/s, est. speed input: 3758.76 toks/s, output: 3.67 toks/s]
Processed prompts:  63%|   | 81/128 [00:22<00:12,  3.67it/s, est. speed input: 3758.79 toks/s, output: 3.67 toks/s]
Processed prompts:  64%|   | 82/128 [00:22<00:12,  3.67it/s, est. speed input: 3759.02 toks/s, output: 3.67 toks/s]
Processed prompts:  65%|   | 83/128 [00:22<00:12,  3.67it/s, est. speed input: 3758.97 toks/s, output: 3.67 toks/s]
Processed prompts:  66%|   | 84/128 [00:22<00:12,  3.64it/s, est. speed input: 3757.69 toks/s, output: 3.67 toks/s]
Processed prompts:  66%|   | 85/128 [00:23<00:11,  3.64it/s, est. speed input: 3757.33 toks/s, output: 3.67 toks/s]
Processed prompts:  67%|   | 86/128 [00:23<00:11,  3.65it/s, est. speed input: 3757.35 toks/s, output: 3.67 toks/s]
Processed prompts:  68%|   | 87/128 [00:23<00:11,  3.66it/s, est. speed input: 3757.64 toks/s, output: 3.67 toks/s]
Processed prompts:  69%|   | 88/128 [00:23<00:11,  3.63it/s, est. speed input: 3756.45 toks/s, output: 3.67 toks/s]
Processed prompts:  70%|   | 89/128 [00:24<00:10,  3.66it/s, est. speed input: 3757.02 toks/s, output: 3.67 toks/s]
Processed prompts:  70%|   | 90/128 [00:24<00:10,  3.67it/s, est. speed input: 3757.46 toks/s, output: 3.67 toks/s]
Processed prompts:  71%|   | 91/128 [00:24<00:10,  3.68it/s, est. speed input: 3757.78 toks/s, output: 3.67 toks/s]
Processed prompts:  72%|  | 92/128 [00:25<00:09,  3.66it/s, est. speed input: 3757.01 toks/s, output: 3.67 toks/s]
Processed prompts:  73%|  | 93/128 [00:25<00:09,  3.64it/s, est. speed input: 3756.41 toks/s, output: 3.67 toks/s]
Processed prompts:  73%|  | 94/128 [00:25<00:09,  3.67it/s, est. speed input: 3757.12 toks/s, output: 3.67 toks/s]
Processed prompts:  74%|  | 95/128 [00:25<00:08,  3.67it/s, est. speed input: 3757.22 toks/s, output: 3.67 toks/s]
Processed prompts:  75%|  | 96/128 [00:26<00:08,  3.65it/s, est. speed input: 3756.40 toks/s, output: 3.67 toks/s]
Processed prompts:  76%|  | 97/128 [00:26<00:08,  3.66it/s, est. speed input: 3756.45 toks/s, output: 3.67 toks/s]
Processed prompts:  77%|  | 98/128 [00:26<00:08,  3.67it/s, est. speed input: 3756.77 toks/s, output: 3.67 toks/s]
Processed prompts:  77%|  | 99/128 [00:26<00:07,  3.68it/s, est. speed input: 3757.07 toks/s, output: 3.67 toks/s]
Processed prompts:  78%|  | 100/128 [00:27<00:07,  3.65it/s, est. speed input: 3756.25 toks/s, output: 3.67 toks/s]
Processed prompts:  79%|  | 101/128 [00:27<00:07,  3.66it/s, est. speed input: 3756.51 toks/s, output: 3.67 toks/s]
Processed prompts:  80%|  | 102/128 [00:27<00:07,  3.68it/s, est. speed input: 3757.12 toks/s, output: 3.67 toks/s]
Processed prompts:  80%|  | 103/128 [00:28<00:06,  3.69it/s, est. speed input: 3757.36 toks/s, output: 3.67 toks/s]
Processed prompts:  81%| | 104/128 [00:28<00:06,  3.65it/s, est. speed input: 3756.46 toks/s, output: 3.67 toks/s]
Processed prompts:  82%| | 105/128 [00:28<00:06,  3.64it/s, est. speed input: 3755.96 toks/s, output: 3.67 toks/s]
Processed prompts:  83%| | 106/128 [00:28<00:06,  3.64it/s, est. speed input: 3755.59 toks/s, output: 3.67 toks/s]
Processed prompts:  84%| | 107/128 [00:29<00:05,  3.61it/s, est. speed input: 3754.30 toks/s, output: 3.67 toks/s]
Processed prompts:  84%| | 108/128 [00:29<00:05,  3.63it/s, est. speed input: 3754.39 toks/s, output: 3.67 toks/s]
Processed prompts:  85%| | 109/128 [00:29<00:05,  3.63it/s, est. speed input: 3754.19 toks/s, output: 3.67 toks/s]
Processed prompts:  86%| | 110/128 [00:30<00:04,  3.64it/s, est. speed input: 3754.11 toks/s, output: 3.67 toks/s]
Processed prompts:  87%| | 111/128 [00:30<00:04,  3.62it/s, est. speed input: 3753.27 toks/s, output: 3.67 toks/s]
Processed prompts:  88%| | 112/128 [00:30<00:04,  3.64it/s, est. speed input: 3753.36 toks/s, output: 3.67 toks/s]
Processed prompts:  88%| | 113/128 [00:30<00:04,  3.65it/s, est. speed input: 3753.61 toks/s, output: 3.67 toks/s]
Processed prompts:  89%| | 114/128 [00:31<00:03,  3.67it/s, est. speed input: 3753.86 toks/s, output: 3.67 toks/s]
Processed prompts:  90%| | 115/128 [00:31<00:03,  3.65it/s, est. speed input: 3753.35 toks/s, output: 3.67 toks/s]
Processed prompts:  91%| | 116/128 [00:31<00:03,  3.66it/s, est. speed input: 3753.63 toks/s, output: 3.67 toks/s]
Processed prompts:  91%|| 117/128 [00:31<00:02,  3.68it/s, est. speed input: 3754.12 toks/s, output: 3.67 toks/s]
Processed prompts:  92%|| 118/128 [00:32<00:02,  3.67it/s, est. speed input: 3753.98 toks/s, output: 3.67 toks/s]
Processed prompts:  93%|| 119/128 [00:32<00:02,  3.64it/s, est. speed input: 3753.20 toks/s, output: 3.67 toks/s]
Processed prompts:  94%|| 120/128 [00:32<00:02,  3.66it/s, est. speed input: 3753.54 toks/s, output: 3.67 toks/s]
Processed prompts:  95%|| 121/128 [00:33<00:01,  3.67it/s, est. speed input: 3753.64 toks/s, output: 3.67 toks/s]
Processed prompts:  95%|| 122/128 [00:33<00:01,  3.68it/s, est. speed input: 3753.90 toks/s, output: 3.67 toks/s]
Processed prompts:  96%|| 123/128 [00:33<00:01,  3.64it/s, est. speed input: 3753.12 toks/s, output: 3.67 toks/s]
Processed prompts:  97%|| 124/128 [00:33<00:01,  3.66it/s, est. speed input: 3753.39 toks/s, output: 3.67 toks/s]
Processed prompts:  98%|| 125/128 [00:34<00:00,  3.68it/s, est. speed input: 3753.79 toks/s, output: 3.67 toks/s]
Processed prompts:  98%|| 126/128 [00:34<00:00,  3.69it/s, est. speed input: 3754.22 toks/s, output: 3.67 toks/s]
Processed prompts:  99%|| 127/128 [00:34<00:00,  3.66it/s, est. speed input: 3753.62 toks/s, output: 3.67 toks/s]
Processed prompts: 100%|| 128/128 [00:34<00:00,  3.68it/s, est. speed input: 3754.08 toks/s, output: 3.67 toks/s]
Processed prompts: 100%|| 128/128 [00:34<00:00,  3.68it/s, est. speed input: 3754.08 toks/s, output: 3.67 toks/s]
Processed prompts: 100%|| 128/128 [00:34<00:00,  3.67it/s, est. speed input: 3754.08 toks/s, output: 3.67 toks/s]
[rank0]:[W127 00:52:54.729006757 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-27 00:52:57
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 00:53:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 00:53:05 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1927024) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1927024) WARNING 01-27 00:55:21 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.48 requests/s, 3571.26 total tokens/s, 3.48 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-27 00:53:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 00:53:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 00:53:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 00:53:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:53:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:53:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:53:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:53:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:53:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 00:53:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 00:53:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 00:53:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 00:53:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 00:53:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 00:53:08] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 00:53:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 00:53:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 00:53:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:53:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:53:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:53:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:53:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:53:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 00:53:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 00:53:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 00:53:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 00:53:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 00:53:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1927024) [2026-01-27 00:53:09] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1927024) [2026-01-27 00:53:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1927024) [2026-01-27 00:53:09] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1927024) [2026-01-27 00:53:09] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1927024) [2026-01-27 00:53:09] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1927024) [2026-01-27 00:53:09] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1927024) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1927024) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:26,  8.67s/it]
(EngineCore_DP0 pid=1927024) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:43<00:48, 24.33s/it]
(EngineCore_DP0 pid=1927024) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:16<00:27, 27.94s/it]
(EngineCore_DP0 pid=1927024) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:50<00:00, 30.28s/it]
(EngineCore_DP0 pid=1927024) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:50<00:00, 27.52s/it]
(EngineCore_DP0 pid=1927024) 
(EngineCore_DP0 pid=1927024) [2026-01-27 00:55:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1927024) [2026-01-27 00:55:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36929536 bytes
(EngineCore_DP0 pid=1927024) [2026-01-27 00:55:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1927024) [2026-01-27 00:55:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26378240 bytes
(EngineCore_DP0 pid=1927024) [2026-01-27 00:55:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1927024) [2026-01-27 00:55:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 142442496 bytes
(EngineCore_DP0 pid=1927024) [2026-01-27 00:55:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1927024) [2026-01-27 00:55:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70778880 bytes
(EngineCore_DP0 pid=1927024) 2026-01-27 00:55:12,301 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1927024) 2026-01-27 00:55:12,754 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/256 [00:01<05:04,  1.20s/it]
Adding requests:   1%|          | 2/256 [00:01<02:43,  1.55it/s]
Adding requests:   1%|          | 3/256 [00:01<01:45,  2.39it/s]
Adding requests:   2%|         | 5/256 [00:01<00:58,  4.29it/s]
Adding requests:   3%|         | 7/256 [00:01<00:38,  6.46it/s]
Adding requests:   4%|         | 10/256 [00:02<00:24, 10.10it/s]
Adding requests:   5%|         | 13/256 [00:02<00:18, 13.37it/s]
Adding requests:   8%|         | 20/256 [00:02<00:09, 24.84it/s]
Adding requests:  14%|        | 37/256 [00:02<00:03, 57.69it/s]
Adding requests:  21%|        | 54/256 [00:02<00:02, 84.18it/s]
Adding requests:  32%|      | 81/256 [00:02<00:01, 131.51it/s]
Adding requests:  46%|     | 118/256 [00:02<00:00, 194.63it/s]
Adding requests:  62%|   | 160/256 [00:02<00:00, 254.61it/s]
Adding requests:  79%|  | 202/256 [00:02<00:00, 300.47it/s]
Adding requests:  91%|| 234/256 [00:03<00:00, 210.42it/s]
Adding requests: 100%|| 256/256 [00:03<00:00, 80.60it/s] 

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 6/256 [00:00<00:05, 48.58it/s, est. speed input: 49749.52 toks/s, output: 48.58 toks/s]
Processed prompts:   4%|         | 11/256 [00:01<00:32,  7.64it/s, est. speed input: 9073.57 toks/s, output: 8.86 toks/s] 
Processed prompts:   5%|         | 14/256 [00:02<00:50,  4.80it/s, est. speed input: 6066.64 toks/s, output: 5.92 toks/s]
Processed prompts:   6%|         | 16/256 [00:02<00:53,  4.46it/s, est. speed input: 5614.20 toks/s, output: 5.48 toks/s]
Processed prompts:   7%|         | 18/256 [00:03<00:56,  4.19it/s, est. speed input: 5295.60 toks/s, output: 5.17 toks/s]
Processed prompts:   8%|         | 20/256 [00:04<00:58,  4.02it/s, est. speed input: 5072.79 toks/s, output: 4.95 toks/s]
Processed prompts:   9%|         | 22/256 [00:04<01:00,  3.88it/s, est. speed input: 4896.89 toks/s, output: 4.78 toks/s]
Processed prompts:   9%|         | 24/256 [00:05<01:01,  3.80it/s, est. speed input: 4766.35 toks/s, output: 4.65 toks/s]
Processed prompts:  10%|         | 26/256 [00:05<01:01,  3.72it/s, est. speed input: 4655.57 toks/s, output: 4.55 toks/s]
Processed prompts:  11%|         | 28/256 [00:06<01:01,  3.69it/s, est. speed input: 4569.45 toks/s, output: 4.46 toks/s]
Processed prompts:  12%|        | 30/256 [00:06<01:02,  3.64it/s, est. speed input: 4491.11 toks/s, output: 4.39 toks/s]
Processed prompts:  12%|        | 32/256 [00:07<01:01,  3.63it/s, est. speed input: 4429.89 toks/s, output: 4.33 toks/s]
Processed prompts:  13%|        | 34/256 [00:07<01:01,  3.60it/s, est. speed input: 4371.42 toks/s, output: 4.27 toks/s]
Processed prompts:  14%|        | 36/256 [00:08<01:01,  3.59it/s, est. speed input: 4324.79 toks/s, output: 4.22 toks/s]
Processed prompts:  15%|        | 38/256 [00:09<01:00,  3.59it/s, est. speed input: 4284.54 toks/s, output: 4.18 toks/s]
Processed prompts:  16%|        | 40/256 [00:09<01:00,  3.57it/s, est. speed input: 4245.12 toks/s, output: 4.15 toks/s]
Processed prompts:  16%|        | 42/256 [00:10<00:59,  3.58it/s, est. speed input: 4215.73 toks/s, output: 4.12 toks/s]
Processed prompts:  17%|        | 44/256 [00:10<00:59,  3.57it/s, est. speed input: 4183.92 toks/s, output: 4.09 toks/s]
Processed prompts:  18%|        | 46/256 [00:11<00:58,  3.57it/s, est. speed input: 4158.23 toks/s, output: 4.06 toks/s]
Processed prompts:  19%|        | 48/256 [00:11<00:58,  3.56it/s, est. speed input: 4133.09 toks/s, output: 4.04 toks/s]
Processed prompts:  20%|        | 50/256 [00:12<00:57,  3.57it/s, est. speed input: 4112.26 toks/s, output: 4.02 toks/s]
Processed prompts:  20%|        | 52/256 [00:13<00:57,  3.56it/s, est. speed input: 4091.75 toks/s, output: 4.00 toks/s]
Processed prompts:  21%|        | 54/256 [00:13<00:56,  3.57it/s, est. speed input: 4074.61 toks/s, output: 3.98 toks/s]
Processed prompts:  22%|       | 56/256 [00:14<00:56,  3.57it/s, est. speed input: 4057.60 toks/s, output: 3.96 toks/s]
Processed prompts:  23%|       | 58/256 [00:14<00:55,  3.58it/s, est. speed input: 4043.35 toks/s, output: 3.95 toks/s]
Processed prompts:  23%|       | 60/256 [00:15<00:55,  3.56it/s, est. speed input: 4027.00 toks/s, output: 3.93 toks/s]
Processed prompts:  24%|       | 62/256 [00:15<00:54,  3.56it/s, est. speed input: 4013.79 toks/s, output: 3.92 toks/s]
Processed prompts:  25%|       | 64/256 [00:16<00:54,  3.55it/s, est. speed input: 3999.54 toks/s, output: 3.91 toks/s]
Processed prompts:  26%|       | 66/256 [00:16<00:53,  3.55it/s, est. speed input: 3987.31 toks/s, output: 3.89 toks/s]
Processed prompts:  27%|       | 68/256 [00:17<00:53,  3.55it/s, est. speed input: 3975.78 toks/s, output: 3.88 toks/s]
Processed prompts:  27%|       | 70/256 [00:18<00:52,  3.54it/s, est. speed input: 3964.38 toks/s, output: 3.87 toks/s]
Processed prompts:  28%|       | 72/256 [00:18<00:51,  3.55it/s, est. speed input: 3954.85 toks/s, output: 3.86 toks/s]
Processed prompts:  29%|       | 74/256 [00:19<00:51,  3.55it/s, est. speed input: 3945.66 toks/s, output: 3.85 toks/s]
Processed prompts:  30%|       | 76/256 [00:19<00:50,  3.56it/s, est. speed input: 3938.28 toks/s, output: 3.85 toks/s]
Processed prompts:  30%|       | 78/256 [00:20<00:50,  3.55it/s, est. speed input: 3928.67 toks/s, output: 3.84 toks/s]
Processed prompts:  31%|      | 80/256 [00:20<00:49,  3.55it/s, est. speed input: 3921.10 toks/s, output: 3.83 toks/s]
Processed prompts:  32%|      | 82/256 [00:21<00:49,  3.55it/s, est. speed input: 3913.02 toks/s, output: 3.82 toks/s]
Processed prompts:  33%|      | 84/256 [00:22<00:48,  3.56it/s, est. speed input: 3906.96 toks/s, output: 3.82 toks/s]
Processed prompts:  34%|      | 86/256 [00:22<00:47,  3.55it/s, est. speed input: 3899.68 toks/s, output: 3.81 toks/s]
Processed prompts:  34%|      | 88/256 [00:23<00:47,  3.55it/s, est. speed input: 3893.34 toks/s, output: 3.80 toks/s]
Processed prompts:  35%|      | 90/256 [00:23<00:46,  3.55it/s, est. speed input: 3886.99 toks/s, output: 3.80 toks/s]
Processed prompts:  36%|      | 92/256 [00:24<00:46,  3.55it/s, est. speed input: 3881.15 toks/s, output: 3.79 toks/s]
Processed prompts:  37%|      | 94/256 [00:24<00:45,  3.55it/s, est. speed input: 3875.76 toks/s, output: 3.78 toks/s]
Processed prompts:  38%|      | 96/256 [00:25<00:45,  3.55it/s, est. speed input: 3870.42 toks/s, output: 3.78 toks/s]
Processed prompts:  38%|      | 98/256 [00:25<00:44,  3.55it/s, est. speed input: 3865.23 toks/s, output: 3.77 toks/s]
Processed prompts:  39%|      | 100/256 [00:26<00:44,  3.54it/s, est. speed input: 3859.79 toks/s, output: 3.77 toks/s]
Processed prompts:  40%|      | 102/256 [00:27<00:43,  3.55it/s, est. speed input: 3855.41 toks/s, output: 3.77 toks/s]
Processed prompts:  41%|      | 104/256 [00:27<00:42,  3.54it/s, est. speed input: 3850.09 toks/s, output: 3.76 toks/s]
Processed prompts:  41%|     | 106/256 [00:28<00:42,  3.54it/s, est. speed input: 3845.87 toks/s, output: 3.76 toks/s]
Processed prompts:  42%|     | 108/256 [00:28<00:41,  3.54it/s, est. speed input: 3841.27 toks/s, output: 3.75 toks/s]
Processed prompts:  43%|     | 110/256 [00:29<00:41,  3.54it/s, est. speed input: 3836.88 toks/s, output: 3.75 toks/s]
Processed prompts:  44%|     | 112/256 [00:29<00:40,  3.54it/s, est. speed input: 3832.81 toks/s, output: 3.74 toks/s]
Processed prompts:  45%|     | 114/256 [00:30<00:40,  3.54it/s, est. speed input: 3829.42 toks/s, output: 3.74 toks/s]
Processed prompts:  45%|     | 116/256 [00:31<00:39,  3.54it/s, est. speed input: 3825.42 toks/s, output: 3.74 toks/s]
Processed prompts:  46%|     | 118/256 [00:31<00:38,  3.54it/s, est. speed input: 3822.10 toks/s, output: 3.73 toks/s]
Processed prompts:  47%|     | 120/256 [00:32<00:38,  3.53it/s, est. speed input: 3818.12 toks/s, output: 3.73 toks/s]
Processed prompts:  48%|     | 122/256 [00:32<00:37,  3.54it/s, est. speed input: 3815.05 toks/s, output: 3.73 toks/s]
Processed prompts:  48%|     | 124/256 [00:33<00:37,  3.53it/s, est. speed input: 3811.18 toks/s, output: 3.72 toks/s]
Processed prompts:  49%|     | 126/256 [00:33<00:36,  3.52it/s, est. speed input: 3807.46 toks/s, output: 3.72 toks/s]
Processed prompts:  50%|     | 128/256 [00:34<00:36,  3.53it/s, est. speed input: 3804.80 toks/s, output: 3.72 toks/s]
Processed prompts:  51%|     | 130/256 [00:35<00:35,  3.53it/s, est. speed input: 3801.61 toks/s, output: 3.71 toks/s]
Processed prompts:  52%|    | 132/256 [00:35<00:34,  3.54it/s, est. speed input: 3799.46 toks/s, output: 3.71 toks/s]
Processed prompts:  52%|    | 134/256 [00:36<00:34,  3.54it/s, est. speed input: 3796.39 toks/s, output: 3.71 toks/s]
Processed prompts:  53%|    | 136/256 [00:36<00:33,  3.54it/s, est. speed input: 3794.12 toks/s, output: 3.71 toks/s]
Processed prompts:  54%|    | 138/256 [00:37<00:33,  3.54it/s, est. speed input: 3791.35 toks/s, output: 3.70 toks/s]
Processed prompts:  55%|    | 140/256 [00:37<00:32,  3.54it/s, est. speed input: 3789.02 toks/s, output: 3.70 toks/s]
Processed prompts:  55%|    | 142/256 [00:38<00:32,  3.54it/s, est. speed input: 3786.26 toks/s, output: 3.70 toks/s]
Processed prompts:  56%|    | 144/256 [00:38<00:31,  3.55it/s, est. speed input: 3784.42 toks/s, output: 3.70 toks/s]
Processed prompts:  57%|    | 146/256 [00:39<00:31,  3.54it/s, est. speed input: 3782.01 toks/s, output: 3.69 toks/s]
Processed prompts:  58%|    | 148/256 [00:40<00:30,  3.55it/s, est. speed input: 3780.15 toks/s, output: 3.69 toks/s]
Processed prompts:  59%|    | 150/256 [00:40<00:29,  3.54it/s, est. speed input: 3777.68 toks/s, output: 3.69 toks/s]
Processed prompts:  59%|    | 152/256 [00:41<00:29,  3.55it/s, est. speed input: 3775.94 toks/s, output: 3.69 toks/s]
Processed prompts:  60%|    | 154/256 [00:41<00:28,  3.54it/s, est. speed input: 3773.71 toks/s, output: 3.69 toks/s]
Processed prompts:  61%|    | 156/256 [00:42<00:28,  3.53it/s, est. speed input: 3771.20 toks/s, output: 3.68 toks/s]
Processed prompts:  62%|   | 158/256 [00:42<00:27,  3.53it/s, est. speed input: 3769.29 toks/s, output: 3.68 toks/s]
Processed prompts:  62%|   | 160/256 [00:43<00:27,  3.53it/s, est. speed input: 3767.03 toks/s, output: 3.68 toks/s]
Processed prompts:  63%|   | 162/256 [00:44<00:26,  3.54it/s, est. speed input: 3765.53 toks/s, output: 3.68 toks/s]
Processed prompts:  64%|   | 164/256 [00:44<00:26,  3.53it/s, est. speed input: 3763.47 toks/s, output: 3.68 toks/s]
Processed prompts:  65%|   | 166/256 [00:45<00:25,  3.53it/s, est. speed input: 3761.67 toks/s, output: 3.67 toks/s]
Processed prompts:  66%|   | 168/256 [00:45<00:24,  3.54it/s, est. speed input: 3760.05 toks/s, output: 3.67 toks/s]
Processed prompts:  66%|   | 170/256 [00:46<00:24,  3.54it/s, est. speed input: 3758.68 toks/s, output: 3.67 toks/s]
Processed prompts:  67%|   | 172/256 [00:46<00:23,  3.54it/s, est. speed input: 3757.13 toks/s, output: 3.67 toks/s]
Processed prompts:  68%|   | 174/256 [00:47<00:23,  3.55it/s, est. speed input: 3755.95 toks/s, output: 3.67 toks/s]
Processed prompts:  69%|   | 176/256 [00:48<00:22,  3.54it/s, est. speed input: 3754.15 toks/s, output: 3.67 toks/s]
Processed prompts:  70%|   | 178/256 [00:48<00:21,  3.55it/s, est. speed input: 3752.84 toks/s, output: 3.66 toks/s]
Processed prompts:  70%|   | 180/256 [00:49<00:21,  3.54it/s, est. speed input: 3751.12 toks/s, output: 3.66 toks/s]
Processed prompts:  71%|   | 182/256 [00:49<00:20,  3.54it/s, est. speed input: 3749.64 toks/s, output: 3.66 toks/s]
Processed prompts:  72%|  | 184/256 [00:50<00:20,  3.54it/s, est. speed input: 3748.31 toks/s, output: 3.66 toks/s]
Processed prompts:  73%|  | 186/256 [00:50<00:19,  3.54it/s, est. speed input: 3746.74 toks/s, output: 3.66 toks/s]
Processed prompts:  73%|  | 188/256 [00:51<00:19,  3.54it/s, est. speed input: 3745.65 toks/s, output: 3.66 toks/s]
Processed prompts:  74%|  | 190/256 [00:51<00:18,  3.53it/s, est. speed input: 3743.91 toks/s, output: 3.66 toks/s]
Processed prompts:  75%|  | 192/256 [00:52<00:18,  3.54it/s, est. speed input: 3742.82 toks/s, output: 3.66 toks/s]
Processed prompts:  76%|  | 194/256 [00:53<00:17,  3.53it/s, est. speed input: 3741.13 toks/s, output: 3.65 toks/s]
Processed prompts:  77%|  | 196/256 [00:53<00:17,  3.53it/s, est. speed input: 3739.82 toks/s, output: 3.65 toks/s]
Processed prompts:  77%|  | 198/256 [00:54<00:16,  3.53it/s, est. speed input: 3738.62 toks/s, output: 3.65 toks/s]
Processed prompts:  78%|  | 200/256 [00:54<00:15,  3.54it/s, est. speed input: 3737.70 toks/s, output: 3.65 toks/s]
Processed prompts:  79%|  | 202/256 [00:55<00:13,  4.00it/s, est. speed input: 3751.09 toks/s, output: 3.66 toks/s]
Processed prompts:  80%|  | 204/256 [00:55<00:13,  3.86it/s, est. speed input: 3750.06 toks/s, output: 3.66 toks/s]
Processed prompts:  80%|  | 206/256 [00:56<00:13,  3.75it/s, est. speed input: 3748.61 toks/s, output: 3.66 toks/s]
Processed prompts:  81%| | 208/256 [00:56<00:13,  3.69it/s, est. speed input: 3747.57 toks/s, output: 3.66 toks/s]
Processed prompts:  82%| | 210/256 [00:57<00:12,  3.63it/s, est. speed input: 3746.03 toks/s, output: 3.66 toks/s]
Processed prompts:  83%| | 212/256 [00:57<00:12,  3.61it/s, est. speed input: 3745.04 toks/s, output: 3.66 toks/s]
Processed prompts:  84%| | 214/256 [00:58<00:11,  3.58it/s, est. speed input: 3743.60 toks/s, output: 3.66 toks/s]
Processed prompts:  84%| | 216/256 [00:59<00:11,  3.57it/s, est. speed input: 3742.50 toks/s, output: 3.65 toks/s]
Processed prompts:  85%| | 218/256 [00:59<00:10,  3.55it/s, est. speed input: 3741.11 toks/s, output: 3.65 toks/s]
Processed prompts:  86%| | 220/256 [01:00<00:10,  3.55it/s, est. speed input: 3740.02 toks/s, output: 3.65 toks/s]
Processed prompts:  87%| | 222/256 [01:00<00:09,  3.54it/s, est. speed input: 3738.87 toks/s, output: 3.65 toks/s]
Processed prompts:  88%| | 224/256 [01:01<00:09,  3.54it/s, est. speed input: 3737.70 toks/s, output: 3.65 toks/s]
Processed prompts:  88%| | 226/256 [01:01<00:08,  3.55it/s, est. speed input: 3736.89 toks/s, output: 3.65 toks/s]
Processed prompts:  89%| | 228/256 [01:02<00:07,  3.53it/s, est. speed input: 3735.49 toks/s, output: 3.65 toks/s]
Processed prompts:  90%| | 230/256 [01:03<00:07,  3.54it/s, est. speed input: 3734.61 toks/s, output: 3.65 toks/s]
Processed prompts:  91%| | 232/256 [01:03<00:06,  3.54it/s, est. speed input: 3733.56 toks/s, output: 3.65 toks/s]
Processed prompts:  91%|| 234/256 [01:04<00:06,  3.54it/s, est. speed input: 3732.56 toks/s, output: 3.65 toks/s]
Processed prompts:  92%|| 236/256 [01:04<00:05,  3.53it/s, est. speed input: 3731.46 toks/s, output: 3.64 toks/s]
Processed prompts:  93%|| 238/256 [01:05<00:05,  3.53it/s, est. speed input: 3730.45 toks/s, output: 3.64 toks/s]
Processed prompts:  94%|| 240/256 [01:05<00:04,  3.52it/s, est. speed input: 3729.21 toks/s, output: 3.64 toks/s]
Processed prompts:  95%|| 242/256 [01:06<00:03,  3.53it/s, est. speed input: 3728.46 toks/s, output: 3.64 toks/s]
Processed prompts:  95%|| 244/256 [01:07<00:03,  3.53it/s, est. speed input: 3727.38 toks/s, output: 3.64 toks/s]
Processed prompts:  96%|| 246/256 [01:07<00:02,  3.54it/s, est. speed input: 3726.85 toks/s, output: 3.64 toks/s]
Processed prompts:  97%|| 248/256 [01:08<00:02,  3.52it/s, est. speed input: 3725.25 toks/s, output: 3.64 toks/s]
Processed prompts:  98%|| 250/256 [01:08<00:01,  3.51it/s, est. speed input: 3723.99 toks/s, output: 3.64 toks/s]
Processed prompts:  98%|| 252/256 [01:09<00:01,  3.52it/s, est. speed input: 3723.16 toks/s, output: 3.64 toks/s]
Processed prompts:  99%|| 254/256 [01:09<00:00,  3.52it/s, est. speed input: 3722.25 toks/s, output: 3.64 toks/s]
Processed prompts: 100%|| 256/256 [01:10<00:00,  4.15it/s, est. speed input: 3736.48 toks/s, output: 3.65 toks/s]
Processed prompts: 100%|| 256/256 [01:10<00:00,  4.15it/s, est. speed input: 3736.48 toks/s, output: 3.65 toks/s]
Processed prompts: 100%|| 256/256 [01:10<00:00,  3.65it/s, est. speed input: 3736.48 toks/s, output: 3.65 toks/s]
[rank0]:[W127 00:56:36.960234571 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-27 00:56:52
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 00:56:59 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 00:56:59 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1930468) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1930468) WARNING 01-27 00:59:07 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.46 requests/s, 3545.25 total tokens/s, 3.46 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-27 00:56:59] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 00:56:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 00:56:59] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 00:56:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:56:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:56:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:56:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:56:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:56:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 00:56:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 00:56:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 00:56:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 00:56:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 00:56:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 00:57:03] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 00:57:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 00:57:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 00:57:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:57:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:57:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:57:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:57:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 00:57:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 00:57:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 00:57:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 00:57:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 00:57:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 00:57:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1930468) [2026-01-27 00:57:04] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1930468) [2026-01-27 00:57:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1930468) [2026-01-27 00:57:04] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1930468) [2026-01-27 00:57:04] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1930468) [2026-01-27 00:57:04] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1930468) [2026-01-27 00:57:04] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1930468) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1930468) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.45s/it]
(EngineCore_DP0 pid=1930468) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:43<00:47, 23.88s/it]
(EngineCore_DP0 pid=1930468) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:15<00:27, 27.58s/it]
(EngineCore_DP0 pid=1930468) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:48<00:00, 30.07s/it]
(EngineCore_DP0 pid=1930468) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:48<00:00, 27.25s/it]
(EngineCore_DP0 pid=1930468) 
(EngineCore_DP0 pid=1930468) [2026-01-27 00:58:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1930468) [2026-01-27 00:58:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36929536 bytes
(EngineCore_DP0 pid=1930468) [2026-01-27 00:58:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1930468) [2026-01-27 00:58:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26378240 bytes
(EngineCore_DP0 pid=1930468) [2026-01-27 00:58:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1930468) [2026-01-27 00:58:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 142442496 bytes
(EngineCore_DP0 pid=1930468) [2026-01-27 00:58:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1930468) [2026-01-27 00:58:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70778880 bytes
(EngineCore_DP0 pid=1930468) 2026-01-27 00:59:05,499 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1930468) 2026-01-27 00:59:05,974 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/512 [00:01<08:55,  1.05s/it]
Adding requests:   0%|          | 2/512 [00:01<04:45,  1.79it/s]
Adding requests:   1%|          | 3/512 [00:01<03:03,  2.77it/s]
Adding requests:   1%|          | 5/512 [00:01<01:44,  4.85it/s]
Adding requests:   1%|         | 7/512 [00:01<01:09,  7.29it/s]
Adding requests:   2%|         | 11/512 [00:01<00:38, 13.04it/s]
Adding requests:   3%|         | 14/512 [00:01<00:30, 16.33it/s]
Adding requests:   5%|         | 25/512 [00:01<00:13, 37.07it/s]
Adding requests:   8%|         | 41/512 [00:02<00:07, 65.94it/s]
Adding requests:  12%|        | 63/512 [00:02<00:04, 104.81it/s]
Adding requests:  18%|        | 92/512 [00:02<00:02, 153.52it/s]
Adding requests:  25%|       | 128/512 [00:02<00:01, 209.15it/s]
Adding requests:  32%|      | 165/512 [00:02<00:01, 252.57it/s]
Adding requests:  41%|      | 210/512 [00:02<00:00, 306.82it/s]
Adding requests:  49%|     | 251/512 [00:02<00:00, 335.43it/s]
Adding requests:  57%|    | 294/512 [00:02<00:00, 362.38it/s]
Adding requests:  66%|   | 336/512 [00:02<00:00, 379.04it/s]
Adding requests:  74%|  | 381/512 [00:03<00:00, 399.27it/s]
Adding requests:  84%| | 428/512 [00:03<00:00, 418.87it/s]
Adding requests:  92%|| 471/512 [00:03<00:00, 420.87it/s]
Adding requests: 100%|| 512/512 [00:03<00:00, 154.30it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 8/512 [00:00<01:02,  8.03it/s, est. speed input: 8219.55 toks/s, output: 8.03 toks/s]
Processed prompts:   2%|         | 12/512 [00:02<01:35,  5.22it/s, est. speed input: 5748.06 toks/s, output: 5.61 toks/s]
Processed prompts:   3%|         | 16/512 [00:03<01:52,  4.41it/s, est. speed input: 4995.42 toks/s, output: 4.88 toks/s]
Processed prompts:   4%|         | 20/512 [00:04<02:01,  4.05it/s, est. speed input: 4633.07 toks/s, output: 4.52 toks/s]
Processed prompts:   5%|         | 24/512 [00:05<02:07,  3.84it/s, est. speed input: 4412.27 toks/s, output: 4.31 toks/s]
Processed prompts:   5%|         | 28/512 [00:06<02:10,  3.72it/s, est. speed input: 4270.65 toks/s, output: 4.17 toks/s]
Processed prompts:   6%|         | 32/512 [00:07<02:11,  3.65it/s, est. speed input: 4170.35 toks/s, output: 4.07 toks/s]
Processed prompts:   7%|         | 36/512 [00:08<02:12,  3.61it/s, est. speed input: 4097.77 toks/s, output: 4.00 toks/s]
Processed prompts:   8%|         | 40/512 [00:10<02:12,  3.57it/s, est. speed input: 4039.24 toks/s, output: 3.94 toks/s]
Processed prompts:   9%|         | 44/512 [00:11<02:11,  3.55it/s, est. speed input: 3992.52 toks/s, output: 3.90 toks/s]
Processed prompts:   9%|         | 48/512 [00:12<02:11,  3.54it/s, est. speed input: 3956.03 toks/s, output: 3.86 toks/s]
Processed prompts:  10%|         | 52/512 [00:13<02:10,  3.52it/s, est. speed input: 3923.93 toks/s, output: 3.83 toks/s]
Processed prompts:  11%|         | 56/512 [00:14<02:09,  3.51it/s, est. speed input: 3895.82 toks/s, output: 3.80 toks/s]
Processed prompts:  12%|        | 60/512 [00:15<02:09,  3.50it/s, est. speed input: 3871.78 toks/s, output: 3.78 toks/s]
Processed prompts:  12%|        | 64/512 [00:17<02:08,  3.49it/s, est. speed input: 3850.53 toks/s, output: 3.76 toks/s]
Processed prompts:  13%|        | 68/512 [00:18<02:07,  3.49it/s, est. speed input: 3831.94 toks/s, output: 3.74 toks/s]
Processed prompts:  14%|        | 72/512 [00:19<02:06,  3.49it/s, est. speed input: 3816.36 toks/s, output: 3.73 toks/s]
Processed prompts:  15%|        | 76/512 [00:20<02:05,  3.49it/s, est. speed input: 3802.36 toks/s, output: 3.71 toks/s]
Processed prompts:  16%|        | 80/512 [00:21<02:03,  3.49it/s, est. speed input: 3790.43 toks/s, output: 3.70 toks/s]
Processed prompts:  16%|        | 84/512 [00:22<02:02,  3.48it/s, est. speed input: 3778.80 toks/s, output: 3.69 toks/s]
Processed prompts:  17%|        | 88/512 [00:23<02:01,  3.48it/s, est. speed input: 3768.38 toks/s, output: 3.68 toks/s]
Processed prompts:  18%|        | 92/512 [00:25<02:00,  3.49it/s, est. speed input: 3759.98 toks/s, output: 3.67 toks/s]
Processed prompts:  19%|        | 96/512 [00:26<01:59,  3.49it/s, est. speed input: 3751.56 toks/s, output: 3.66 toks/s]
Processed prompts:  20%|        | 100/512 [00:27<01:58,  3.48it/s, est. speed input: 3743.66 toks/s, output: 3.66 toks/s]
Processed prompts:  20%|        | 104/512 [00:28<01:57,  3.48it/s, est. speed input: 3735.70 toks/s, output: 3.65 toks/s]
Processed prompts:  21%|        | 108/512 [00:29<01:56,  3.47it/s, est. speed input: 3728.27 toks/s, output: 3.64 toks/s]
Processed prompts:  22%|       | 112/512 [00:30<01:55,  3.48it/s, est. speed input: 3722.48 toks/s, output: 3.64 toks/s]
Processed prompts:  23%|       | 116/512 [00:31<01:53,  3.48it/s, est. speed input: 3716.87 toks/s, output: 3.63 toks/s]
Processed prompts:  23%|       | 120/512 [00:33<01:52,  3.48it/s, est. speed input: 3711.20 toks/s, output: 3.62 toks/s]
Processed prompts:  24%|       | 124/512 [00:34<01:51,  3.47it/s, est. speed input: 3705.39 toks/s, output: 3.62 toks/s]
Processed prompts:  25%|       | 128/512 [00:35<01:50,  3.47it/s, est. speed input: 3700.95 toks/s, output: 3.61 toks/s]
Processed prompts:  26%|       | 132/512 [00:36<01:49,  3.48it/s, est. speed input: 3696.66 toks/s, output: 3.61 toks/s]
Processed prompts:  27%|       | 136/512 [00:37<01:48,  3.47it/s, est. speed input: 3691.98 toks/s, output: 3.61 toks/s]
Processed prompts:  27%|       | 140/512 [00:38<01:47,  3.47it/s, est. speed input: 3687.95 toks/s, output: 3.60 toks/s]
Processed prompts:  28%|       | 144/512 [00:40<01:46,  3.47it/s, est. speed input: 3684.01 toks/s, output: 3.60 toks/s]
Processed prompts:  29%|       | 148/512 [00:41<01:44,  3.47it/s, est. speed input: 3680.17 toks/s, output: 3.59 toks/s]
Processed prompts:  30%|       | 152/512 [00:42<01:43,  3.47it/s, est. speed input: 3676.60 toks/s, output: 3.59 toks/s]
Processed prompts:  30%|       | 156/512 [00:43<01:42,  3.47it/s, est. speed input: 3673.23 toks/s, output: 3.59 toks/s]
Processed prompts:  31%|      | 160/512 [00:44<01:41,  3.47it/s, est. speed input: 3670.35 toks/s, output: 3.58 toks/s]
Processed prompts:  32%|      | 164/512 [00:45<01:40,  3.47it/s, est. speed input: 3667.43 toks/s, output: 3.58 toks/s]
Processed prompts:  33%|      | 168/512 [00:46<01:39,  3.47it/s, est. speed input: 3664.73 toks/s, output: 3.58 toks/s]
Processed prompts:  34%|      | 172/512 [00:48<01:37,  3.47it/s, est. speed input: 3662.09 toks/s, output: 3.58 toks/s]
Processed prompts:  34%|      | 176/512 [00:49<01:36,  3.47it/s, est. speed input: 3659.25 toks/s, output: 3.57 toks/s]
Processed prompts:  35%|      | 180/512 [00:50<01:35,  3.48it/s, est. speed input: 3657.54 toks/s, output: 3.57 toks/s]
Processed prompts:  36%|      | 184/512 [00:51<01:34,  3.48it/s, est. speed input: 3655.68 toks/s, output: 3.57 toks/s]
Processed prompts:  37%|      | 188/512 [00:52<01:33,  3.48it/s, est. speed input: 3653.60 toks/s, output: 3.57 toks/s]
Processed prompts:  38%|      | 192/512 [00:53<01:32,  3.48it/s, est. speed input: 3651.47 toks/s, output: 3.57 toks/s]
Processed prompts:  38%|      | 196/512 [00:55<01:31,  3.47it/s, est. speed input: 3648.97 toks/s, output: 3.56 toks/s]
Processed prompts:  39%|      | 200/512 [00:55<01:24,  3.67it/s, est. speed input: 3661.00 toks/s, output: 3.58 toks/s]
Processed prompts:  40%|      | 204/512 [00:57<01:25,  3.61it/s, est. speed input: 3659.11 toks/s, output: 3.57 toks/s]
Processed prompts:  41%|      | 208/512 [00:58<01:25,  3.56it/s, est. speed input: 3656.33 toks/s, output: 3.57 toks/s]
Processed prompts:  41%|     | 212/512 [00:59<01:24,  3.53it/s, est. speed input: 3654.45 toks/s, output: 3.57 toks/s]
Processed prompts:  42%|     | 216/512 [01:00<01:24,  3.52it/s, est. speed input: 3652.59 toks/s, output: 3.57 toks/s]
Processed prompts:  43%|     | 220/512 [01:01<01:23,  3.50it/s, est. speed input: 3650.54 toks/s, output: 3.56 toks/s]
Processed prompts:  44%|     | 224/512 [01:02<01:22,  3.49it/s, est. speed input: 3648.84 toks/s, output: 3.56 toks/s]
Processed prompts:  45%|     | 228/512 [01:04<01:21,  3.48it/s, est. speed input: 3647.00 toks/s, output: 3.56 toks/s]
Processed prompts:  45%|     | 232/512 [01:05<01:20,  3.48it/s, est. speed input: 3645.15 toks/s, output: 3.56 toks/s]
Processed prompts:  46%|     | 236/512 [01:06<01:19,  3.47it/s, est. speed input: 3643.50 toks/s, output: 3.56 toks/s]
Processed prompts:  47%|     | 240/512 [01:07<01:18,  3.47it/s, est. speed input: 3641.70 toks/s, output: 3.56 toks/s]
Processed prompts:  48%|     | 244/512 [01:08<01:17,  3.47it/s, est. speed input: 3640.08 toks/s, output: 3.55 toks/s]
Processed prompts:  48%|     | 248/512 [01:09<01:16,  3.47it/s, est. speed input: 3638.60 toks/s, output: 3.55 toks/s]
Processed prompts:  49%|     | 252/512 [01:10<01:15,  3.46it/s, est. speed input: 3636.70 toks/s, output: 3.55 toks/s]
Processed prompts:  50%|     | 256/512 [01:12<01:13,  3.46it/s, est. speed input: 3635.52 toks/s, output: 3.55 toks/s]
Processed prompts:  51%|     | 260/512 [01:13<01:12,  3.47it/s, est. speed input: 3634.51 toks/s, output: 3.55 toks/s]
Processed prompts:  52%|    | 264/512 [01:14<01:11,  3.48it/s, est. speed input: 3633.54 toks/s, output: 3.55 toks/s]
Processed prompts:  52%|    | 268/512 [01:15<01:10,  3.47it/s, est. speed input: 3632.21 toks/s, output: 3.55 toks/s]
Processed prompts:  53%|    | 272/512 [01:16<01:09,  3.47it/s, est. speed input: 3630.88 toks/s, output: 3.55 toks/s]
Processed prompts:  54%|    | 276/512 [01:17<01:08,  3.47it/s, est. speed input: 3629.74 toks/s, output: 3.54 toks/s]
Processed prompts:  55%|    | 280/512 [01:19<01:06,  3.47it/s, est. speed input: 3628.46 toks/s, output: 3.54 toks/s]
Processed prompts:  55%|    | 284/512 [01:20<01:05,  3.47it/s, est. speed input: 3627.53 toks/s, output: 3.54 toks/s]
Processed prompts:  56%|    | 288/512 [01:21<01:04,  3.47it/s, est. speed input: 3626.52 toks/s, output: 3.54 toks/s]
Processed prompts:  57%|    | 292/512 [01:22<01:03,  3.47it/s, est. speed input: 3625.55 toks/s, output: 3.54 toks/s]
Processed prompts:  58%|    | 296/512 [01:23<01:02,  3.47it/s, est. speed input: 3624.43 toks/s, output: 3.54 toks/s]
Processed prompts:  59%|    | 300/512 [01:24<01:01,  3.47it/s, est. speed input: 3623.33 toks/s, output: 3.54 toks/s]
Processed prompts:  59%|    | 304/512 [01:25<00:56,  3.69it/s, est. speed input: 3632.07 toks/s, output: 3.55 toks/s]
Processed prompts:  60%|    | 308/512 [01:26<00:56,  3.61it/s, est. speed input: 3630.83 toks/s, output: 3.55 toks/s]
Processed prompts:  61%|    | 312/512 [01:28<00:56,  3.57it/s, est. speed input: 3629.84 toks/s, output: 3.54 toks/s]
Processed prompts:  62%|   | 316/512 [01:29<00:55,  3.54it/s, est. speed input: 3628.95 toks/s, output: 3.54 toks/s]
Processed prompts:  62%|   | 320/512 [01:30<00:54,  3.52it/s, est. speed input: 3627.91 toks/s, output: 3.54 toks/s]
Processed prompts:  63%|   | 324/512 [01:31<00:53,  3.50it/s, est. speed input: 3626.81 toks/s, output: 3.54 toks/s]
Processed prompts:  64%|   | 328/512 [01:32<00:52,  3.49it/s, est. speed input: 3625.73 toks/s, output: 3.54 toks/s]
Processed prompts:  65%|   | 332/512 [01:33<00:51,  3.49it/s, est. speed input: 3625.15 toks/s, output: 3.54 toks/s]
Processed prompts:  66%|   | 336/512 [01:34<00:50,  3.48it/s, est. speed input: 3624.18 toks/s, output: 3.54 toks/s]
Processed prompts:  66%|   | 340/512 [01:36<00:49,  3.48it/s, est. speed input: 3623.33 toks/s, output: 3.54 toks/s]
Processed prompts:  67%|   | 344/512 [01:37<00:48,  3.47it/s, est. speed input: 3622.37 toks/s, output: 3.54 toks/s]
Processed prompts:  68%|   | 348/512 [01:38<00:47,  3.46it/s, est. speed input: 3621.21 toks/s, output: 3.54 toks/s]
Processed prompts:  69%|   | 352/512 [01:39<00:46,  3.46it/s, est. speed input: 3620.39 toks/s, output: 3.54 toks/s]
Processed prompts:  70%|   | 356/512 [01:40<00:44,  3.47it/s, est. speed input: 3619.72 toks/s, output: 3.53 toks/s]
Processed prompts:  70%|   | 360/512 [01:41<00:43,  3.47it/s, est. speed input: 3618.90 toks/s, output: 3.53 toks/s]
Processed prompts:  71%|   | 364/512 [01:43<00:42,  3.46it/s, est. speed input: 3618.04 toks/s, output: 3.53 toks/s]
Processed prompts:  72%|  | 368/512 [01:44<00:41,  3.46it/s, est. speed input: 3617.09 toks/s, output: 3.53 toks/s]
Processed prompts:  73%|  | 372/512 [01:45<00:40,  3.46it/s, est. speed input: 3616.42 toks/s, output: 3.53 toks/s]
Processed prompts:  73%|  | 376/512 [01:46<00:39,  3.47it/s, est. speed input: 3615.74 toks/s, output: 3.53 toks/s]
Processed prompts:  74%|  | 380/512 [01:47<00:38,  3.46it/s, est. speed input: 3614.96 toks/s, output: 3.53 toks/s]
Processed prompts:  75%|  | 384/512 [01:48<00:36,  3.47it/s, est. speed input: 3614.32 toks/s, output: 3.53 toks/s]
Processed prompts:  76%|  | 388/512 [01:49<00:35,  3.47it/s, est. speed input: 3613.67 toks/s, output: 3.53 toks/s]
Processed prompts:  77%|  | 392/512 [01:51<00:34,  3.46it/s, est. speed input: 3612.91 toks/s, output: 3.53 toks/s]
Processed prompts:  77%|  | 396/512 [01:52<00:33,  3.46it/s, est. speed input: 3612.10 toks/s, output: 3.53 toks/s]
Processed prompts:  78%|  | 400/512 [01:53<00:32,  3.47it/s, est. speed input: 3611.63 toks/s, output: 3.53 toks/s]
Processed prompts:  79%|  | 404/512 [01:54<00:31,  3.47it/s, est. speed input: 3611.06 toks/s, output: 3.53 toks/s]
Processed prompts:  80%|  | 408/512 [01:55<00:29,  3.47it/s, est. speed input: 3610.49 toks/s, output: 3.53 toks/s]
Processed prompts:  80%|  | 412/512 [01:56<00:28,  3.47it/s, est. speed input: 3609.98 toks/s, output: 3.53 toks/s]
Processed prompts:  81%| | 416/512 [01:58<00:27,  3.47it/s, est. speed input: 3609.51 toks/s, output: 3.52 toks/s]
Processed prompts:  82%| | 420/512 [01:59<00:26,  3.47it/s, est. speed input: 3608.90 toks/s, output: 3.52 toks/s]
Processed prompts:  83%| | 424/512 [02:00<00:25,  3.47it/s, est. speed input: 3608.39 toks/s, output: 3.52 toks/s]
Processed prompts:  84%| | 428/512 [02:01<00:24,  3.47it/s, est. speed input: 3607.86 toks/s, output: 3.52 toks/s]
Processed prompts:  84%| | 432/512 [02:02<00:23,  3.47it/s, est. speed input: 3607.29 toks/s, output: 3.52 toks/s]
Processed prompts:  85%| | 436/512 [02:03<00:20,  3.69it/s, est. speed input: 3613.42 toks/s, output: 3.53 toks/s]
Processed prompts:  86%| | 440/512 [02:04<00:19,  3.62it/s, est. speed input: 3612.91 toks/s, output: 3.53 toks/s]
Processed prompts:  87%| | 444/512 [02:05<00:19,  3.57it/s, est. speed input: 3612.29 toks/s, output: 3.53 toks/s]
Processed prompts:  88%| | 448/512 [02:07<00:18,  3.53it/s, est. speed input: 3611.48 toks/s, output: 3.53 toks/s]
Processed prompts:  88%| | 452/512 [02:08<00:17,  3.52it/s, est. speed input: 3611.05 toks/s, output: 3.53 toks/s]
Processed prompts:  89%| | 456/512 [02:09<00:15,  3.50it/s, est. speed input: 3610.50 toks/s, output: 3.53 toks/s]
Processed prompts:  90%| | 460/512 [02:10<00:14,  3.49it/s, est. speed input: 3609.93 toks/s, output: 3.53 toks/s]
Processed prompts:  91%| | 464/512 [02:11<00:13,  3.48it/s, est. speed input: 3609.43 toks/s, output: 3.52 toks/s]
Processed prompts:  91%|| 468/512 [02:12<00:12,  3.48it/s, est. speed input: 3608.84 toks/s, output: 3.52 toks/s]
Processed prompts:  92%|| 472/512 [02:13<00:11,  3.47it/s, est. speed input: 3608.22 toks/s, output: 3.52 toks/s]
Processed prompts:  93%|| 476/512 [02:15<00:10,  3.47it/s, est. speed input: 3607.76 toks/s, output: 3.52 toks/s]
Processed prompts:  94%|| 480/512 [02:16<00:09,  3.47it/s, est. speed input: 3607.21 toks/s, output: 3.52 toks/s]
Processed prompts:  95%|| 484/512 [02:17<00:08,  3.47it/s, est. speed input: 3606.74 toks/s, output: 3.52 toks/s]
Processed prompts:  95%|| 488/512 [02:18<00:06,  3.47it/s, est. speed input: 3606.33 toks/s, output: 3.52 toks/s]
Processed prompts:  96%|| 492/512 [02:19<00:05,  3.46it/s, est. speed input: 3605.69 toks/s, output: 3.52 toks/s]
Processed prompts:  97%|| 496/512 [02:20<00:04,  3.46it/s, est. speed input: 3605.15 toks/s, output: 3.52 toks/s]
Processed prompts:  98%|| 500/512 [02:22<00:03,  3.46it/s, est. speed input: 3604.64 toks/s, output: 3.52 toks/s]
Processed prompts:  98%|| 504/512 [02:23<00:02,  3.46it/s, est. speed input: 3604.23 toks/s, output: 3.52 toks/s]
Processed prompts:  99%|| 508/512 [02:24<00:01,  3.46it/s, est. speed input: 3603.75 toks/s, output: 3.52 toks/s]
Processed prompts: 100%|| 512/512 [02:24<00:00,  4.47it/s, est. speed input: 3624.94 toks/s, output: 3.54 toks/s]
Processed prompts: 100%|| 512/512 [02:24<00:00,  4.47it/s, est. speed input: 3624.94 toks/s, output: 3.54 toks/s]
Processed prompts: 100%|| 512/512 [02:24<00:00,  3.54it/s, est. speed input: 3624.94 toks/s, output: 3.54 toks/s]
[rank0]:[W127 01:01:36.372670722 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-27 01:01:50
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 01:02:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 01:02:01 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1934792) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1934792) WARNING 01-27 01:04:15 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.48 requests/s, 3562.52 total tokens/s, 3.48 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-27 01:02:00] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 01:02:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 01:02:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 01:02:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:02:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:02:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:02:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:02:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:02:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 01:02:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 01:02:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 01:02:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 01:02:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 01:02:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 01:02:04] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 01:02:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 01:02:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 01:02:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:02:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:02:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:02:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:02:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:02:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 01:02:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 01:02:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 01:02:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 01:02:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 01:02:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1934792) [2026-01-27 01:02:05] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1934792) [2026-01-27 01:02:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1934792) [2026-01-27 01:02:05] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1934792) [2026-01-27 01:02:05] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1934792) [2026-01-27 01:02:05] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1934792) [2026-01-27 01:02:05] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1934792) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1934792) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.49s/it]
(EngineCore_DP0 pid=1934792) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:43<00:48, 24.24s/it]
(EngineCore_DP0 pid=1934792) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:15<00:27, 27.76s/it]
(EngineCore_DP0 pid=1934792) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:50<00:00, 30.53s/it]
(EngineCore_DP0 pid=1934792) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:50<00:00, 27.62s/it]
(EngineCore_DP0 pid=1934792) 
(EngineCore_DP0 pid=1934792) [2026-01-27 01:03:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1934792) [2026-01-27 01:03:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36929536 bytes
(EngineCore_DP0 pid=1934792) [2026-01-27 01:03:57] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1934792) [2026-01-27 01:03:57] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26378240 bytes
(EngineCore_DP0 pid=1934792) [2026-01-27 01:03:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1934792) [2026-01-27 01:03:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 142442496 bytes
(EngineCore_DP0 pid=1934792) [2026-01-27 01:03:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1934792) [2026-01-27 01:03:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70778880 bytes
(EngineCore_DP0 pid=1934792) 2026-01-27 01:04:09,580 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1934792) 2026-01-27 01:04:10,688 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/1024 [00:00<13:27,  1.27it/s]
Adding requests:   0%|          | 2/1024 [00:00<07:20,  2.32it/s]
Adding requests:   0%|          | 3/1024 [00:01<04:45,  3.57it/s]
Adding requests:   0%|          | 5/1024 [00:01<02:43,  6.22it/s]
Adding requests:   1%|          | 8/1024 [00:01<01:35, 10.69it/s]
Adding requests:   1%|          | 12/1024 [00:01<01:00, 16.62it/s]
Adding requests:   2%|         | 19/1024 [00:01<00:34, 28.75it/s]
Adding requests:   4%|         | 36/1024 [00:01<00:15, 63.71it/s]
Adding requests:   5%|         | 54/1024 [00:01<00:10, 91.82it/s]
Adding requests:   8%|         | 80/1024 [00:01<00:06, 136.03it/s]
Adding requests:  11%|         | 111/1024 [00:01<00:04, 183.54it/s]
Adding requests:  14%|        | 146/1024 [00:02<00:03, 230.28it/s]
Adding requests:  18%|        | 189/1024 [00:02<00:02, 286.45it/s]
Adding requests:  23%|       | 232/1024 [00:02<00:02, 327.39it/s]
Adding requests:  27%|       | 273/1024 [00:02<00:02, 348.17it/s]
Adding requests:  31%|       | 313/1024 [00:02<00:01, 360.81it/s]
Adding requests:  35%|      | 355/1024 [00:02<00:01, 374.56it/s]
Adding requests:  39%|      | 398/1024 [00:02<00:01, 389.80it/s]
Adding requests:  43%|     | 440/1024 [00:02<00:01, 397.67it/s]
Adding requests:  47%|     | 481/1024 [00:02<00:01, 399.42it/s]
Adding requests:  52%|    | 530/1024 [00:02<00:01, 424.06it/s]
Adding requests:  56%|    | 573/1024 [00:03<00:01, 417.06it/s]
Adding requests:  60%|    | 617/1024 [00:03<00:00, 420.07it/s]
Adding requests:  64%|   | 660/1024 [00:03<00:00, 419.79it/s]
Adding requests:  69%|   | 703/1024 [00:03<00:00, 418.37it/s]
Adding requests:  73%|  | 745/1024 [00:03<00:00, 415.21it/s]
Adding requests:  77%|  | 788/1024 [00:03<00:00, 416.81it/s]
Adding requests:  82%| | 835/1024 [00:03<00:00, 431.11it/s]
Adding requests:  86%| | 879/1024 [00:03<00:00, 423.34it/s]
Adding requests:  90%| | 923/1024 [00:03<00:00, 427.77it/s]
Adding requests:  94%|| 966/1024 [00:04<00:00, 420.57it/s]
Adding requests:  99%|| 1009/1024 [00:04<00:00, 416.15it/s]
Adding requests: 100%|| 1024/1024 [00:04<00:00, 246.19it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 5/1024 [00:00<00:36, 27.85it/s, est. speed input: 28522.90 toks/s, output: 27.85 toks/s]
Processed prompts:   1%|         | 13/1024 [00:02<03:32,  4.75it/s, est. speed input: 5378.24 toks/s, output: 5.25 toks/s] 
Processed prompts:   2%|         | 21/1024 [00:04<04:09,  4.03it/s, est. speed input: 4510.44 toks/s, output: 4.40 toks/s]
Processed prompts:   3%|         | 29/1024 [00:07<04:23,  3.78it/s, est. speed input: 4204.76 toks/s, output: 4.11 toks/s]
Processed prompts:   4%|         | 37/1024 [00:09<04:29,  3.67it/s, est. speed input: 4048.63 toks/s, output: 3.95 toks/s]
Processed prompts:   4%|         | 45/1024 [00:11<04:32,  3.60it/s, est. speed input: 3952.98 toks/s, output: 3.86 toks/s]
Processed prompts:   5%|         | 53/1024 [00:13<04:32,  3.56it/s, est. speed input: 3891.18 toks/s, output: 3.80 toks/s]
Processed prompts:   6%|         | 61/1024 [00:16<04:32,  3.54it/s, est. speed input: 3845.53 toks/s, output: 3.76 toks/s]
Processed prompts:   7%|         | 69/1024 [00:18<04:31,  3.52it/s, est. speed input: 3810.75 toks/s, output: 3.72 toks/s]
Processed prompts:   8%|         | 77/1024 [00:20<04:30,  3.51it/s, est. speed input: 3783.48 toks/s, output: 3.69 toks/s]
Processed prompts:   8%|         | 85/1024 [00:23<04:28,  3.50it/s, est. speed input: 3760.48 toks/s, output: 3.67 toks/s]
Processed prompts:   9%|         | 93/1024 [00:25<04:26,  3.49it/s, est. speed input: 3743.18 toks/s, output: 3.66 toks/s]
Processed prompts:  10%|         | 101/1024 [00:27<04:24,  3.49it/s, est. speed input: 3728.59 toks/s, output: 3.64 toks/s]
Processed prompts:  11%|         | 109/1024 [00:30<04:22,  3.49it/s, est. speed input: 3716.19 toks/s, output: 3.63 toks/s]
Processed prompts:  11%|        | 117/1024 [00:32<04:19,  3.49it/s, est. speed input: 3706.33 toks/s, output: 3.62 toks/s]
Processed prompts:  12%|        | 125/1024 [00:34<04:17,  3.48it/s, est. speed input: 3696.49 toks/s, output: 3.61 toks/s]
Processed prompts:  13%|        | 133/1024 [00:36<04:16,  3.48it/s, est. speed input: 3687.53 toks/s, output: 3.60 toks/s]
Processed prompts:  14%|        | 141/1024 [00:39<04:13,  3.48it/s, est. speed input: 3680.37 toks/s, output: 3.59 toks/s]
Processed prompts:  15%|        | 149/1024 [00:41<04:11,  3.48it/s, est. speed input: 3673.57 toks/s, output: 3.59 toks/s]
Processed prompts:  15%|        | 157/1024 [00:43<04:09,  3.48it/s, est. speed input: 3667.81 toks/s, output: 3.58 toks/s]
Processed prompts:  16%|        | 165/1024 [00:46<04:06,  3.48it/s, est. speed input: 3662.38 toks/s, output: 3.58 toks/s]
Processed prompts:  17%|        | 173/1024 [00:48<04:04,  3.48it/s, est. speed input: 3657.71 toks/s, output: 3.57 toks/s]
Processed prompts:  18%|        | 181/1024 [00:50<04:02,  3.48it/s, est. speed input: 3652.87 toks/s, output: 3.57 toks/s]
Processed prompts:  18%|        | 189/1024 [00:53<04:00,  3.48it/s, est. speed input: 3649.22 toks/s, output: 3.56 toks/s]
Processed prompts:  19%|        | 197/1024 [00:55<03:51,  3.58it/s, est. speed input: 3659.90 toks/s, output: 3.57 toks/s]
Processed prompts:  20%|        | 205/1024 [00:57<03:50,  3.55it/s, est. speed input: 3656.04 toks/s, output: 3.57 toks/s]
Processed prompts:  21%|        | 213/1024 [00:59<03:49,  3.53it/s, est. speed input: 3652.34 toks/s, output: 3.57 toks/s]
Processed prompts:  22%|       | 221/1024 [01:02<03:48,  3.51it/s, est. speed input: 3648.86 toks/s, output: 3.56 toks/s]
Processed prompts:  22%|       | 229/1024 [01:04<03:47,  3.50it/s, est. speed input: 3645.76 toks/s, output: 3.56 toks/s]
Processed prompts:  23%|       | 237/1024 [01:06<03:45,  3.49it/s, est. speed input: 3642.35 toks/s, output: 3.56 toks/s]
Processed prompts:  24%|       | 245/1024 [01:08<03:43,  3.49it/s, est. speed input: 3639.68 toks/s, output: 3.55 toks/s]
Processed prompts:  25%|       | 253/1024 [01:11<03:41,  3.48it/s, est. speed input: 3637.23 toks/s, output: 3.55 toks/s]
Processed prompts:  25%|       | 261/1024 [01:13<03:38,  3.48it/s, est. speed input: 3635.09 toks/s, output: 3.55 toks/s]
Processed prompts:  26%|       | 269/1024 [01:15<03:36,  3.48it/s, est. speed input: 3632.58 toks/s, output: 3.55 toks/s]
Processed prompts:  27%|       | 277/1024 [01:18<03:34,  3.48it/s, est. speed input: 3630.54 toks/s, output: 3.55 toks/s]
Processed prompts:  28%|       | 285/1024 [01:20<03:32,  3.48it/s, est. speed input: 3628.33 toks/s, output: 3.54 toks/s]
Processed prompts:  29%|       | 293/1024 [01:22<03:30,  3.48it/s, est. speed input: 3626.52 toks/s, output: 3.54 toks/s]
Processed prompts:  29%|       | 301/1024 [01:24<03:21,  3.59it/s, est. speed input: 3634.67 toks/s, output: 3.55 toks/s]
Processed prompts:  30%|       | 309/1024 [01:27<03:21,  3.55it/s, est. speed input: 3632.74 toks/s, output: 3.55 toks/s]
Processed prompts:  31%|       | 317/1024 [01:29<03:20,  3.53it/s, est. speed input: 3630.83 toks/s, output: 3.55 toks/s]
Processed prompts:  32%|      | 325/1024 [01:31<03:18,  3.51it/s, est. speed input: 3629.11 toks/s, output: 3.54 toks/s]
Processed prompts:  33%|      | 333/1024 [01:34<03:17,  3.50it/s, est. speed input: 3627.45 toks/s, output: 3.54 toks/s]
Processed prompts:  33%|      | 341/1024 [01:36<03:15,  3.49it/s, est. speed input: 3625.54 toks/s, output: 3.54 toks/s]
Processed prompts:  34%|      | 349/1024 [01:38<03:13,  3.49it/s, est. speed input: 3624.09 toks/s, output: 3.54 toks/s]
Processed prompts:  35%|      | 357/1024 [01:40<03:11,  3.49it/s, est. speed input: 3622.73 toks/s, output: 3.54 toks/s]
Processed prompts:  36%|      | 365/1024 [01:43<03:09,  3.48it/s, est. speed input: 3621.26 toks/s, output: 3.54 toks/s]
Processed prompts:  36%|      | 373/1024 [01:45<03:07,  3.48it/s, est. speed input: 3619.83 toks/s, output: 3.53 toks/s]
Processed prompts:  37%|      | 381/1024 [01:47<03:04,  3.48it/s, est. speed input: 3618.63 toks/s, output: 3.53 toks/s]
Processed prompts:  38%|      | 389/1024 [01:50<03:02,  3.48it/s, est. speed input: 3617.16 toks/s, output: 3.53 toks/s]
Processed prompts:  39%|      | 397/1024 [01:52<03:00,  3.48it/s, est. speed input: 3616.00 toks/s, output: 3.53 toks/s]
Processed prompts:  40%|      | 405/1024 [01:54<02:58,  3.48it/s, est. speed input: 3614.97 toks/s, output: 3.53 toks/s]
Processed prompts:  40%|      | 413/1024 [01:57<02:55,  3.48it/s, est. speed input: 3613.94 toks/s, output: 3.53 toks/s]
Processed prompts:  41%|      | 421/1024 [01:59<02:53,  3.48it/s, est. speed input: 3612.90 toks/s, output: 3.53 toks/s]
Processed prompts:  42%|     | 429/1024 [02:01<02:45,  3.59it/s, est. speed input: 3618.99 toks/s, output: 3.53 toks/s]
Processed prompts:  43%|     | 437/1024 [02:03<02:45,  3.55it/s, est. speed input: 3617.80 toks/s, output: 3.53 toks/s]
Processed prompts:  43%|     | 445/1024 [02:05<02:44,  3.53it/s, est. speed input: 3616.70 toks/s, output: 3.53 toks/s]
Processed prompts:  44%|     | 453/1024 [02:08<02:42,  3.51it/s, est. speed input: 3615.74 toks/s, output: 3.53 toks/s]
Processed prompts:  45%|     | 461/1024 [02:10<02:40,  3.50it/s, est. speed input: 3614.67 toks/s, output: 3.53 toks/s]
Processed prompts:  46%|     | 469/1024 [02:12<02:38,  3.49it/s, est. speed input: 3613.65 toks/s, output: 3.53 toks/s]
Processed prompts:  47%|     | 477/1024 [02:15<02:36,  3.49it/s, est. speed input: 3612.73 toks/s, output: 3.53 toks/s]
Processed prompts:  47%|     | 485/1024 [02:17<02:34,  3.49it/s, est. speed input: 3611.99 toks/s, output: 3.53 toks/s]
Processed prompts:  48%|     | 493/1024 [02:19<02:32,  3.48it/s, est. speed input: 3610.91 toks/s, output: 3.53 toks/s]
Processed prompts:  49%|     | 501/1024 [02:22<02:30,  3.48it/s, est. speed input: 3610.15 toks/s, output: 3.53 toks/s]
Processed prompts:  50%|     | 509/1024 [02:24<02:28,  3.48it/s, est. speed input: 3609.28 toks/s, output: 3.52 toks/s]
Processed prompts:  50%|     | 517/1024 [02:26<02:25,  3.48it/s, est. speed input: 3608.50 toks/s, output: 3.52 toks/s]
Processed prompts:  51%|    | 525/1024 [02:29<02:23,  3.48it/s, est. speed input: 3607.71 toks/s, output: 3.52 toks/s]
Processed prompts:  52%|    | 533/1024 [02:31<02:21,  3.48it/s, est. speed input: 3607.14 toks/s, output: 3.52 toks/s]
Processed prompts:  53%|    | 541/1024 [02:33<02:18,  3.48it/s, est. speed input: 3606.28 toks/s, output: 3.52 toks/s]
Processed prompts:  54%|    | 549/1024 [02:35<02:16,  3.48it/s, est. speed input: 3605.65 toks/s, output: 3.52 toks/s]
Processed prompts:  54%|    | 557/1024 [02:38<02:14,  3.48it/s, est. speed input: 3605.01 toks/s, output: 3.52 toks/s]
Processed prompts:  55%|    | 565/1024 [02:40<02:12,  3.48it/s, est. speed input: 3604.26 toks/s, output: 3.52 toks/s]
Processed prompts:  56%|    | 573/1024 [02:42<02:09,  3.48it/s, est. speed input: 3603.73 toks/s, output: 3.52 toks/s]
Processed prompts:  57%|    | 581/1024 [02:45<02:07,  3.48it/s, est. speed input: 3603.05 toks/s, output: 3.52 toks/s]
Processed prompts:  58%|    | 589/1024 [02:47<02:05,  3.47it/s, est. speed input: 3602.40 toks/s, output: 3.52 toks/s]
Processed prompts:  58%|    | 597/1024 [02:49<02:02,  3.48it/s, est. speed input: 3601.99 toks/s, output: 3.52 toks/s]
Processed prompts:  59%|    | 605/1024 [02:52<02:00,  3.48it/s, est. speed input: 3601.50 toks/s, output: 3.52 toks/s]
Processed prompts:  60%|    | 613/1024 [02:54<01:58,  3.48it/s, est. speed input: 3600.92 toks/s, output: 3.52 toks/s]
Processed prompts:  61%|    | 621/1024 [02:56<01:55,  3.48it/s, est. speed input: 3600.43 toks/s, output: 3.52 toks/s]
Processed prompts:  61%|   | 629/1024 [02:58<01:53,  3.47it/s, est. speed input: 3599.74 toks/s, output: 3.52 toks/s]
Processed prompts:  62%|   | 637/1024 [03:01<01:51,  3.48it/s, est. speed input: 3599.26 toks/s, output: 3.51 toks/s]
Processed prompts:  63%|   | 645/1024 [03:03<01:49,  3.48it/s, est. speed input: 3598.77 toks/s, output: 3.51 toks/s]
Processed prompts:  64%|   | 653/1024 [03:05<01:46,  3.48it/s, est. speed input: 3598.39 toks/s, output: 3.51 toks/s]
Processed prompts:  65%|   | 661/1024 [03:08<01:44,  3.48it/s, est. speed input: 3597.94 toks/s, output: 3.51 toks/s]
Processed prompts:  65%|   | 669/1024 [03:10<01:42,  3.48it/s, est. speed input: 3597.49 toks/s, output: 3.51 toks/s]
Processed prompts:  66%|   | 677/1024 [03:12<01:39,  3.47it/s, est. speed input: 3596.88 toks/s, output: 3.51 toks/s]
Processed prompts:  67%|   | 685/1024 [03:15<01:37,  3.47it/s, est. speed input: 3596.45 toks/s, output: 3.51 toks/s]
Processed prompts:  68%|   | 693/1024 [03:17<01:35,  3.48it/s, est. speed input: 3596.03 toks/s, output: 3.51 toks/s]
Processed prompts:  68%|   | 701/1024 [03:19<01:32,  3.48it/s, est. speed input: 3595.60 toks/s, output: 3.51 toks/s]
Processed prompts:  69%|   | 709/1024 [03:21<01:30,  3.47it/s, est. speed input: 3595.15 toks/s, output: 3.51 toks/s]
Processed prompts:  70%|   | 717/1024 [03:24<01:28,  3.48it/s, est. speed input: 3594.76 toks/s, output: 3.51 toks/s]
Processed prompts:  71%|   | 725/1024 [03:26<01:26,  3.47it/s, est. speed input: 3594.26 toks/s, output: 3.51 toks/s]
Processed prompts:  72%|  | 733/1024 [03:28<01:23,  3.47it/s, est. speed input: 3593.84 toks/s, output: 3.51 toks/s]
Processed prompts:  72%|  | 741/1024 [03:31<01:21,  3.47it/s, est. speed input: 3593.49 toks/s, output: 3.51 toks/s]
Processed prompts:  73%|  | 749/1024 [03:33<01:19,  3.48it/s, est. speed input: 3593.15 toks/s, output: 3.51 toks/s]
Processed prompts:  74%|  | 757/1024 [03:35<01:16,  3.48it/s, est. speed input: 3592.86 toks/s, output: 3.51 toks/s]
Processed prompts:  75%|  | 765/1024 [03:38<01:14,  3.47it/s, est. speed input: 3592.42 toks/s, output: 3.51 toks/s]
Processed prompts:  75%|  | 773/1024 [03:40<01:12,  3.47it/s, est. speed input: 3591.99 toks/s, output: 3.51 toks/s]
Processed prompts:  76%|  | 781/1024 [03:42<01:07,  3.59it/s, est. speed input: 3595.57 toks/s, output: 3.51 toks/s]
Processed prompts:  77%|  | 789/1024 [03:44<01:06,  3.55it/s, est. speed input: 3595.22 toks/s, output: 3.51 toks/s]
Processed prompts:  78%|  | 797/1024 [03:47<01:04,  3.53it/s, est. speed input: 3594.89 toks/s, output: 3.51 toks/s]
Processed prompts:  79%|  | 805/1024 [03:49<01:02,  3.51it/s, est. speed input: 3594.51 toks/s, output: 3.51 toks/s]
Processed prompts:  79%|  | 813/1024 [03:51<01:00,  3.50it/s, est. speed input: 3594.18 toks/s, output: 3.51 toks/s]
Processed prompts:  80%|  | 821/1024 [03:53<00:58,  3.50it/s, est. speed input: 3593.86 toks/s, output: 3.51 toks/s]
Processed prompts:  81%|  | 829/1024 [03:56<00:55,  3.49it/s, est. speed input: 3593.47 toks/s, output: 3.51 toks/s]
Processed prompts:  82%| | 837/1024 [03:58<00:53,  3.48it/s, est. speed input: 3593.13 toks/s, output: 3.51 toks/s]
Processed prompts:  83%| | 845/1024 [04:00<00:51,  3.48it/s, est. speed input: 3592.72 toks/s, output: 3.51 toks/s]
Processed prompts:  83%| | 853/1024 [04:03<00:49,  3.48it/s, est. speed input: 3592.39 toks/s, output: 3.51 toks/s]
Processed prompts:  84%| | 861/1024 [04:05<00:46,  3.48it/s, est. speed input: 3592.06 toks/s, output: 3.51 toks/s]
Processed prompts:  85%| | 869/1024 [04:07<00:44,  3.47it/s, est. speed input: 3591.70 toks/s, output: 3.51 toks/s]
Processed prompts:  86%| | 877/1024 [04:10<00:42,  3.47it/s, est. speed input: 3591.33 toks/s, output: 3.51 toks/s]
Processed prompts:  86%| | 885/1024 [04:12<00:40,  3.47it/s, est. speed input: 3591.07 toks/s, output: 3.51 toks/s]
Processed prompts:  87%| | 893/1024 [04:14<00:37,  3.48it/s, est. speed input: 3590.80 toks/s, output: 3.51 toks/s]
Processed prompts:  88%| | 901/1024 [04:16<00:35,  3.47it/s, est. speed input: 3590.49 toks/s, output: 3.51 toks/s]
Processed prompts:  89%| | 909/1024 [04:19<00:33,  3.47it/s, est. speed input: 3590.21 toks/s, output: 3.51 toks/s]
Processed prompts:  90%| | 917/1024 [04:21<00:30,  3.47it/s, est. speed input: 3589.86 toks/s, output: 3.51 toks/s]
Processed prompts:  90%| | 925/1024 [04:23<00:28,  3.47it/s, est. speed input: 3589.57 toks/s, output: 3.51 toks/s]
Processed prompts:  91%| | 933/1024 [04:26<00:26,  3.47it/s, est. speed input: 3589.33 toks/s, output: 3.51 toks/s]
Processed prompts:  92%|| 941/1024 [04:28<00:23,  3.48it/s, est. speed input: 3589.08 toks/s, output: 3.50 toks/s]
Processed prompts:  93%|| 949/1024 [04:30<00:21,  3.47it/s, est. speed input: 3588.80 toks/s, output: 3.50 toks/s]
Processed prompts:  93%|| 957/1024 [04:33<00:19,  3.47it/s, est. speed input: 3588.52 toks/s, output: 3.50 toks/s]
Processed prompts:  94%|| 965/1024 [04:35<00:17,  3.47it/s, est. speed input: 3588.15 toks/s, output: 3.50 toks/s]
Processed prompts:  95%|| 973/1024 [04:37<00:14,  3.47it/s, est. speed input: 3587.88 toks/s, output: 3.50 toks/s]
Processed prompts:  96%|| 981/1024 [04:40<00:12,  3.47it/s, est. speed input: 3587.63 toks/s, output: 3.50 toks/s]
Processed prompts:  97%|| 989/1024 [04:42<00:10,  3.47it/s, est. speed input: 3587.35 toks/s, output: 3.50 toks/s]
Processed prompts:  97%|| 997/1024 [04:44<00:07,  3.47it/s, est. speed input: 3587.13 toks/s, output: 3.50 toks/s]
Processed prompts:  98%|| 1005/1024 [04:46<00:05,  3.47it/s, est. speed input: 3586.83 toks/s, output: 3.50 toks/s]
Processed prompts:  99%|| 1013/1024 [04:49<00:03,  3.47it/s, est. speed input: 3586.54 toks/s, output: 3.50 toks/s]
Processed prompts: 100%|| 1021/1024 [04:50<00:00,  4.08it/s, est. speed input: 3600.45 toks/s, output: 3.52 toks/s]
Processed prompts: 100%|| 1024/1024 [04:50<00:00,  4.08it/s, est. speed input: 3611.03 toks/s, output: 3.53 toks/s]
Processed prompts: 100%|| 1024/1024 [04:50<00:00,  3.53it/s, est. speed input: 3611.03 toks/s, output: 3.53 toks/s]
[rank0]:[W127 01:09:11.453469823 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-27 01:09:25
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 01:09:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 01:09:38 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1941298) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1941298) WARNING 01-27 01:12:01 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.46 requests/s, 3549.51 total tokens/s, 3.46 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-27 01:09:38] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 01:09:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 01:09:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 01:09:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:09:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:09:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:09:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:09:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:09:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 01:09:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 01:09:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 01:09:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 01:09:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 01:09:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 01:09:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 01:09:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 01:09:41] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 01:09:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:09:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:09:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:09:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:09:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:09:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 01:09:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 01:09:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 01:09:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 01:09:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 01:09:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1941298) [2026-01-27 01:09:42] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1941298) [2026-01-27 01:09:42] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1941298) [2026-01-27 01:09:42] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1941298) [2026-01-27 01:09:42] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1941298) [2026-01-27 01:09:42] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1941298) [2026-01-27 01:09:42] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1941298) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1941298) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.46s/it]
(EngineCore_DP0 pid=1941298) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:43<00:48, 24.22s/it]
(EngineCore_DP0 pid=1941298) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:16<00:27, 27.92s/it]
(EngineCore_DP0 pid=1941298) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:50<00:00, 30.38s/it]
(EngineCore_DP0 pid=1941298) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:50<00:00, 27.54s/it]
(EngineCore_DP0 pid=1941298) 
(EngineCore_DP0 pid=1941298) [2026-01-27 01:11:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1941298) [2026-01-27 01:11:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36929536 bytes
(EngineCore_DP0 pid=1941298) [2026-01-27 01:11:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1941298) [2026-01-27 01:11:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26378240 bytes
(EngineCore_DP0 pid=1941298) [2026-01-27 01:11:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1941298) [2026-01-27 01:11:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 142442496 bytes
(EngineCore_DP0 pid=1941298) [2026-01-27 01:11:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1941298) [2026-01-27 01:11:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70778880 bytes
(EngineCore_DP0 pid=1941298) 2026-01-27 01:11:48,284 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1941298) 2026-01-27 01:11:50,349 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/2048 [00:00<24:40,  1.38it/s]
Adding requests:   0%|          | 2/2048 [00:00<13:34,  2.51it/s]
Adding requests:   0%|          | 4/2048 [00:01<06:53,  4.94it/s]
Adding requests:   0%|          | 6/2048 [00:01<04:31,  7.53it/s]
Adding requests:   0%|          | 9/2048 [00:01<02:56, 11.57it/s]
Adding requests:   1%|          | 13/2048 [00:01<01:55, 17.58it/s]
Adding requests:   1%|          | 25/2048 [00:01<00:48, 41.35it/s]
Adding requests:   3%|         | 52/2048 [00:01<00:20, 98.17it/s]
Adding requests:   4%|         | 84/2048 [00:01<00:12, 156.06it/s]
Adding requests:   6%|         | 124/2048 [00:01<00:08, 221.37it/s]
Adding requests:   8%|         | 166/2048 [00:01<00:06, 276.15it/s]
Adding requests:  10%|         | 210/2048 [00:02<00:05, 321.48it/s]
Adding requests:  12%|        | 252/2048 [00:02<00:05, 348.26it/s]
Adding requests:  14%|        | 295/2048 [00:02<00:04, 369.85it/s]
Adding requests:  16%|        | 334/2048 [00:02<00:04, 375.19it/s]
Adding requests:  18%|        | 375/2048 [00:02<00:04, 382.75it/s]
Adding requests:  21%|        | 420/2048 [00:02<00:04, 400.98it/s]
Adding requests:  23%|       | 464/2048 [00:02<00:03, 409.46it/s]
Adding requests:  25%|       | 509/2048 [00:02<00:03, 420.66it/s]
Adding requests:  27%|       | 556/2048 [00:02<00:03, 433.97it/s]
Adding requests:  29%|       | 600/2048 [00:02<00:03, 423.19it/s]
Adding requests:  31%|      | 643/2048 [00:03<00:03, 418.46it/s]
Adding requests:  33%|      | 685/2048 [00:03<00:03, 406.45it/s]
Adding requests:  35%|      | 726/2048 [00:03<00:03, 406.57it/s]
Adding requests:  37%|      | 767/2048 [00:03<00:03, 394.96it/s]
Adding requests:  39%|      | 808/2048 [00:03<00:03, 399.10it/s]
Adding requests:  42%|     | 853/2048 [00:10<01:01, 19.42it/s] 
Adding requests:  43%|     | 886/2048 [00:10<00:45, 25.35it/s]
Adding requests:  45%|     | 926/2048 [00:10<00:31, 35.29it/s]
Adding requests:  47%|     | 968/2048 [00:10<00:21, 49.32it/s]
Adding requests:  49%|     | 1011/2048 [00:10<00:15, 68.16it/s]
Adding requests:  51%|     | 1049/2048 [00:11<00:11, 88.54it/s]
Adding requests:  53%|    | 1092/2048 [00:11<00:08, 117.82it/s]
Adding requests:  56%|    | 1140/2048 [00:11<00:05, 157.12it/s]
Adding requests:  58%|    | 1183/2048 [00:11<00:04, 193.86it/s]
Adding requests:  60%|    | 1229/2048 [00:11<00:03, 236.08it/s]
Adding requests:  62%|   | 1272/2048 [00:11<00:02, 267.36it/s]
Adding requests:  64%|   | 1315/2048 [00:11<00:02, 299.77it/s]
Adding requests:  66%|   | 1357/2048 [00:11<00:02, 326.63it/s]
Adding requests:  68%|   | 1399/2048 [00:11<00:01, 347.91it/s]
Adding requests:  70%|   | 1441/2048 [00:11<00:01, 359.95it/s]
Adding requests:  73%|  | 1486/2048 [00:12<00:01, 383.16it/s]
Adding requests:  75%|  | 1529/2048 [00:12<00:01, 391.66it/s]
Adding requests:  77%|  | 1571/2048 [00:12<00:01, 397.07it/s]
Adding requests:  79%|  | 1613/2048 [00:12<00:01, 401.25it/s]
Adding requests:  81%|  | 1655/2048 [00:12<00:00, 401.21it/s]
Adding requests:  83%| | 1697/2048 [00:12<00:00, 402.32it/s]
Adding requests:  85%| | 1741/2048 [00:12<00:00, 411.02it/s]
Adding requests:  87%| | 1788/2048 [00:12<00:00, 425.98it/s]
Adding requests:  89%| | 1831/2048 [00:12<00:00, 406.33it/s]
Adding requests:  92%|| 1874/2048 [00:13<00:00, 412.18it/s]
Adding requests:  94%|| 1920/2048 [00:13<00:00, 424.49it/s]
Adding requests:  96%|| 1963/2048 [00:13<00:00, 423.09it/s]
Adding requests:  98%|| 2006/2048 [00:13<00:00, 412.86it/s]
Adding requests: 100%|| 2048/2048 [00:13<00:00, 388.75it/s]
Adding requests: 100%|| 2048/2048 [00:13<00:00, 152.10it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 38/2048 [00:02<02:21, 14.17it/s, est. speed input: 14508.79 toks/s, output: 14.17 toks/s]
Processed prompts:   3%|         | 54/2048 [00:07<05:03,  6.57it/s, est. speed input: 7585.94 toks/s, output: 7.41 toks/s]  
Processed prompts:   3%|         | 70/2048 [00:11<06:34,  5.01it/s, est. speed input: 6023.90 toks/s, output: 5.88 toks/s]
Processed prompts:   4%|         | 86/2048 [00:16<07:29,  4.37it/s, est. speed input: 5335.19 toks/s, output: 5.21 toks/s]
Processed prompts:   5%|         | 102/2048 [00:21<08:02,  4.03it/s, est. speed input: 4946.59 toks/s, output: 4.83 toks/s]
Processed prompts:   6%|         | 118/2048 [00:25<08:23,  3.83it/s, est. speed input: 4695.91 toks/s, output: 4.59 toks/s]
Processed prompts:   7%|         | 134/2048 [00:30<08:35,  3.71it/s, est. speed input: 4522.60 toks/s, output: 4.42 toks/s]
Processed prompts:   7%|         | 150/2048 [00:34<08:42,  3.63it/s, est. speed input: 4394.04 toks/s, output: 4.29 toks/s]
Processed prompts:   8%|         | 166/2048 [00:39<08:45,  3.58it/s, est. speed input: 4295.26 toks/s, output: 4.19 toks/s]
Processed prompts:   9%|         | 182/2048 [00:44<08:46,  3.55it/s, est. speed input: 4217.54 toks/s, output: 4.12 toks/s]
Processed prompts:  10%|         | 198/2048 [00:48<08:38,  3.57it/s, est. speed input: 4172.34 toks/s, output: 4.07 toks/s]
Processed prompts:  10%|         | 214/2048 [00:53<08:38,  3.54it/s, est. speed input: 4117.42 toks/s, output: 4.02 toks/s]
Processed prompts:  11%|         | 230/2048 [00:57<08:37,  3.52it/s, est. speed input: 4072.17 toks/s, output: 3.98 toks/s]
Processed prompts:  12%|        | 246/2048 [01:02<08:34,  3.50it/s, est. speed input: 4033.46 toks/s, output: 3.94 toks/s]
Processed prompts:  13%|        | 262/2048 [01:07<08:31,  3.49it/s, est. speed input: 4000.43 toks/s, output: 3.91 toks/s]
Processed prompts:  14%|        | 278/2048 [01:11<08:28,  3.48it/s, est. speed input: 3971.57 toks/s, output: 3.88 toks/s]
Processed prompts:  14%|        | 294/2048 [01:16<08:16,  3.53it/s, est. speed input: 3957.74 toks/s, output: 3.86 toks/s]
Processed prompts:  15%|        | 310/2048 [01:20<08:15,  3.51it/s, est. speed input: 3934.20 toks/s, output: 3.84 toks/s]
Processed prompts:  16%|        | 326/2048 [01:25<08:12,  3.50it/s, est. speed input: 3913.48 toks/s, output: 3.82 toks/s]
Processed prompts:  17%|        | 342/2048 [01:29<08:09,  3.49it/s, est. speed input: 3894.92 toks/s, output: 3.80 toks/s]
Processed prompts:  17%|        | 358/2048 [01:34<08:05,  3.48it/s, est. speed input: 3878.10 toks/s, output: 3.79 toks/s]
Processed prompts:  18%|        | 374/2048 [01:39<08:01,  3.48it/s, est. speed input: 3863.10 toks/s, output: 3.77 toks/s]
Processed prompts:  19%|        | 390/2048 [01:43<07:56,  3.48it/s, est. speed input: 3849.61 toks/s, output: 3.76 toks/s]
Processed prompts:  20%|        | 406/2048 [01:48<07:52,  3.47it/s, est. speed input: 3836.57 toks/s, output: 3.75 toks/s]
Processed prompts:  21%|        | 422/2048 [01:52<07:41,  3.52it/s, est. speed input: 3832.45 toks/s, output: 3.74 toks/s]
Processed prompts:  21%|       | 438/2048 [01:57<07:39,  3.51it/s, est. speed input: 3821.38 toks/s, output: 3.73 toks/s]
Processed prompts:  22%|       | 454/2048 [02:01<07:35,  3.50it/s, est. speed input: 3811.48 toks/s, output: 3.72 toks/s]
Processed prompts:  23%|       | 470/2048 [02:06<07:32,  3.49it/s, est. speed input: 3801.74 toks/s, output: 3.71 toks/s]
Processed prompts:  24%|       | 486/2048 [02:11<07:28,  3.48it/s, est. speed input: 3792.91 toks/s, output: 3.70 toks/s]
Processed prompts:  25%|       | 502/2048 [02:15<07:24,  3.48it/s, est. speed input: 3784.57 toks/s, output: 3.70 toks/s]
Processed prompts:  25%|       | 518/2048 [02:20<07:20,  3.47it/s, est. speed input: 3776.96 toks/s, output: 3.69 toks/s]
Processed prompts:  26%|       | 534/2048 [02:25<07:15,  3.47it/s, est. speed input: 3769.92 toks/s, output: 3.68 toks/s]
Processed prompts:  27%|       | 550/2048 [02:29<07:11,  3.47it/s, est. speed input: 3763.01 toks/s, output: 3.67 toks/s]
Processed prompts:  28%|       | 566/2048 [02:34<07:07,  3.47it/s, est. speed input: 3756.36 toks/s, output: 3.67 toks/s]
Processed prompts:  28%|       | 582/2048 [02:38<07:02,  3.47it/s, est. speed input: 3750.73 toks/s, output: 3.66 toks/s]
Processed prompts:  29%|       | 598/2048 [02:43<06:58,  3.47it/s, est. speed input: 3744.85 toks/s, output: 3.66 toks/s]
Processed prompts:  30%|       | 614/2048 [02:48<06:53,  3.47it/s, est. speed input: 3739.60 toks/s, output: 3.65 toks/s]
Processed prompts:  31%|       | 630/2048 [02:52<06:49,  3.47it/s, est. speed input: 3734.44 toks/s, output: 3.65 toks/s]
Processed prompts:  32%|      | 646/2048 [02:57<06:44,  3.47it/s, est. speed input: 3729.66 toks/s, output: 3.64 toks/s]
Processed prompts:  32%|      | 662/2048 [03:01<06:39,  3.47it/s, est. speed input: 3725.08 toks/s, output: 3.64 toks/s]
Processed prompts:  33%|      | 678/2048 [03:06<06:35,  3.47it/s, est. speed input: 3720.64 toks/s, output: 3.63 toks/s]
Processed prompts:  34%|      | 694/2048 [03:11<06:30,  3.47it/s, est. speed input: 3716.54 toks/s, output: 3.63 toks/s]
Processed prompts:  35%|      | 710/2048 [03:15<06:25,  3.47it/s, est. speed input: 3712.69 toks/s, output: 3.63 toks/s]
Processed prompts:  35%|      | 726/2048 [03:20<06:21,  3.47it/s, est. speed input: 3708.91 toks/s, output: 3.62 toks/s]
Processed prompts:  36%|      | 742/2048 [03:25<06:16,  3.46it/s, est. speed input: 3705.20 toks/s, output: 3.62 toks/s]
Processed prompts:  37%|      | 758/2048 [03:29<06:12,  3.46it/s, est. speed input: 3701.72 toks/s, output: 3.61 toks/s]
Processed prompts:  38%|      | 774/2048 [03:34<06:02,  3.51it/s, est. speed input: 3702.13 toks/s, output: 3.62 toks/s]
Processed prompts:  39%|      | 790/2048 [03:38<05:59,  3.50it/s, est. speed input: 3698.88 toks/s, output: 3.61 toks/s]
Processed prompts:  39%|      | 806/2048 [03:43<05:55,  3.49it/s, est. speed input: 3695.83 toks/s, output: 3.61 toks/s]
Processed prompts:  40%|      | 822/2048 [03:47<05:52,  3.48it/s, est. speed input: 3692.72 toks/s, output: 3.61 toks/s]
Processed prompts:  41%|      | 838/2048 [03:52<05:48,  3.48it/s, est. speed input: 3689.87 toks/s, output: 3.60 toks/s]
Processed prompts:  42%|     | 854/2048 [03:57<05:43,  3.47it/s, est. speed input: 3687.05 toks/s, output: 3.60 toks/s]
Processed prompts:  42%|     | 870/2048 [04:01<05:39,  3.47it/s, est. speed input: 3684.26 toks/s, output: 3.60 toks/s]
Processed prompts:  43%|     | 886/2048 [04:06<05:35,  3.47it/s, est. speed input: 3681.67 toks/s, output: 3.60 toks/s]
Processed prompts:  44%|     | 902/2048 [04:11<05:30,  3.47it/s, est. speed input: 3679.27 toks/s, output: 3.59 toks/s]
Processed prompts:  45%|     | 918/2048 [04:15<05:26,  3.46it/s, est. speed input: 3676.78 toks/s, output: 3.59 toks/s]
Processed prompts:  46%|     | 934/2048 [04:20<05:21,  3.46it/s, est. speed input: 3674.41 toks/s, output: 3.59 toks/s]
Processed prompts:  46%|     | 950/2048 [04:24<05:16,  3.46it/s, est. speed input: 3672.21 toks/s, output: 3.59 toks/s]
Processed prompts:  47%|     | 966/2048 [04:29<05:12,  3.46it/s, est. speed input: 3670.04 toks/s, output: 3.58 toks/s]
Processed prompts:  48%|     | 982/2048 [04:34<05:07,  3.46it/s, est. speed input: 3667.90 toks/s, output: 3.58 toks/s]
Processed prompts:  49%|     | 998/2048 [04:38<05:03,  3.46it/s, est. speed input: 3665.96 toks/s, output: 3.58 toks/s]
Processed prompts:  50%|     | 1014/2048 [04:43<04:58,  3.46it/s, est. speed input: 3663.96 toks/s, output: 3.58 toks/s]
Processed prompts:  50%|     | 1030/2048 [04:48<04:54,  3.46it/s, est. speed input: 3662.05 toks/s, output: 3.58 toks/s]
Processed prompts:  51%|     | 1046/2048 [04:52<04:49,  3.46it/s, est. speed input: 3660.09 toks/s, output: 3.57 toks/s]
Processed prompts:  52%|    | 1062/2048 [04:57<04:44,  3.46it/s, est. speed input: 3658.28 toks/s, output: 3.57 toks/s]
Processed prompts:  53%|    | 1078/2048 [05:01<04:40,  3.46it/s, est. speed input: 3656.57 toks/s, output: 3.57 toks/s]
Processed prompts:  53%|    | 1094/2048 [05:06<04:35,  3.46it/s, est. speed input: 3654.74 toks/s, output: 3.57 toks/s]
Processed prompts:  54%|    | 1110/2048 [05:11<04:31,  3.46it/s, est. speed input: 3653.09 toks/s, output: 3.57 toks/s]
Processed prompts:  55%|    | 1126/2048 [05:15<04:26,  3.46it/s, est. speed input: 3651.49 toks/s, output: 3.57 toks/s]
Processed prompts:  56%|    | 1142/2048 [05:20<04:22,  3.46it/s, est. speed input: 3649.79 toks/s, output: 3.56 toks/s]
Processed prompts:  57%|    | 1158/2048 [05:25<04:17,  3.46it/s, est. speed input: 3648.28 toks/s, output: 3.56 toks/s]
Processed prompts:  57%|    | 1174/2048 [05:29<04:12,  3.46it/s, est. speed input: 3646.68 toks/s, output: 3.56 toks/s]
Processed prompts:  58%|    | 1190/2048 [05:34<04:08,  3.46it/s, est. speed input: 3645.14 toks/s, output: 3.56 toks/s]
Processed prompts:  59%|    | 1206/2048 [05:38<04:00,  3.51it/s, est. speed input: 3646.11 toks/s, output: 3.56 toks/s]
Processed prompts:  60%|    | 1222/2048 [05:43<03:56,  3.49it/s, est. speed input: 3644.68 toks/s, output: 3.56 toks/s]
Processed prompts:  60%|    | 1238/2048 [05:47<03:52,  3.48it/s, est. speed input: 3643.20 toks/s, output: 3.56 toks/s]
Processed prompts:  61%|    | 1254/2048 [05:52<03:48,  3.47it/s, est. speed input: 3641.88 toks/s, output: 3.56 toks/s]
Processed prompts:  62%|   | 1270/2048 [05:57<03:44,  3.47it/s, est. speed input: 3640.53 toks/s, output: 3.56 toks/s]
Processed prompts:  63%|   | 1286/2048 [06:01<03:39,  3.47it/s, est. speed input: 3639.28 toks/s, output: 3.55 toks/s]
Processed prompts:  64%|   | 1302/2048 [06:06<03:35,  3.46it/s, est. speed input: 3638.00 toks/s, output: 3.55 toks/s]
Processed prompts:  64%|   | 1318/2048 [06:11<03:31,  3.46it/s, est. speed input: 3636.70 toks/s, output: 3.55 toks/s]
Processed prompts:  65%|   | 1334/2048 [06:15<03:26,  3.46it/s, est. speed input: 3635.48 toks/s, output: 3.55 toks/s]
Processed prompts:  66%|   | 1350/2048 [06:20<03:21,  3.46it/s, est. speed input: 3634.28 toks/s, output: 3.55 toks/s]
Processed prompts:  67%|   | 1366/2048 [06:25<03:17,  3.45it/s, est. speed input: 3633.02 toks/s, output: 3.55 toks/s]
Processed prompts:  67%|   | 1382/2048 [06:29<03:12,  3.45it/s, est. speed input: 3631.89 toks/s, output: 3.55 toks/s]
Processed prompts:  68%|   | 1398/2048 [06:34<03:08,  3.45it/s, est. speed input: 3630.77 toks/s, output: 3.55 toks/s]
Processed prompts:  69%|   | 1414/2048 [06:38<03:03,  3.45it/s, est. speed input: 3629.65 toks/s, output: 3.54 toks/s]
Processed prompts:  70%|   | 1430/2048 [06:43<02:58,  3.45it/s, est. speed input: 3628.56 toks/s, output: 3.54 toks/s]
Processed prompts:  71%|   | 1446/2048 [06:48<02:54,  3.45it/s, est. speed input: 3627.47 toks/s, output: 3.54 toks/s]
Processed prompts:  71%|  | 1462/2048 [06:52<02:49,  3.45it/s, est. speed input: 3626.35 toks/s, output: 3.54 toks/s]
Processed prompts:  72%|  | 1478/2048 [06:57<02:45,  3.45it/s, est. speed input: 3625.33 toks/s, output: 3.54 toks/s]
Processed prompts:  73%|  | 1494/2048 [07:02<02:40,  3.45it/s, est. speed input: 3624.19 toks/s, output: 3.54 toks/s]
Processed prompts:  74%|  | 1510/2048 [07:06<02:35,  3.45it/s, est. speed input: 3623.24 toks/s, output: 3.54 toks/s]
Processed prompts:  75%|  | 1526/2048 [07:11<02:31,  3.45it/s, est. speed input: 3622.25 toks/s, output: 3.54 toks/s]
Processed prompts:  75%|  | 1542/2048 [07:16<02:26,  3.45it/s, est. speed input: 3621.27 toks/s, output: 3.54 toks/s]
Processed prompts:  76%|  | 1558/2048 [07:20<02:20,  3.50it/s, est. speed input: 3622.15 toks/s, output: 3.54 toks/s]
Processed prompts:  77%|  | 1574/2048 [07:25<02:16,  3.48it/s, est. speed input: 3621.25 toks/s, output: 3.54 toks/s]
Processed prompts:  78%|  | 1590/2048 [07:29<02:11,  3.47it/s, est. speed input: 3620.33 toks/s, output: 3.54 toks/s]
Processed prompts:  78%|  | 1606/2048 [07:34<02:07,  3.47it/s, est. speed input: 3619.43 toks/s, output: 3.53 toks/s]
Processed prompts:  79%|  | 1622/2048 [07:38<02:01,  3.51it/s, est. speed input: 3620.36 toks/s, output: 3.54 toks/s]
Processed prompts:  80%|  | 1638/2048 [07:43<01:57,  3.49it/s, est. speed input: 3619.44 toks/s, output: 3.53 toks/s]
Processed prompts:  81%|  | 1654/2048 [07:48<01:53,  3.48it/s, est. speed input: 3618.55 toks/s, output: 3.53 toks/s]
Processed prompts:  82%| | 1670/2048 [07:52<01:48,  3.47it/s, est. speed input: 3617.73 toks/s, output: 3.53 toks/s]
Processed prompts:  82%| | 1686/2048 [07:57<01:44,  3.46it/s, est. speed input: 3616.82 toks/s, output: 3.53 toks/s]
Processed prompts:  83%| | 1702/2048 [08:01<01:40,  3.46it/s, est. speed input: 3616.00 toks/s, output: 3.53 toks/s]
Processed prompts:  84%| | 1718/2048 [08:06<01:35,  3.46it/s, est. speed input: 3615.20 toks/s, output: 3.53 toks/s]
Processed prompts:  85%| | 1734/2048 [08:11<01:30,  3.45it/s, est. speed input: 3614.39 toks/s, output: 3.53 toks/s]
Processed prompts:  85%| | 1750/2048 [08:15<01:25,  3.50it/s, est. speed input: 3615.19 toks/s, output: 3.53 toks/s]
Processed prompts:  86%| | 1766/2048 [08:20<01:20,  3.48it/s, est. speed input: 3614.41 toks/s, output: 3.53 toks/s]
Processed prompts:  87%| | 1782/2048 [08:24<01:16,  3.47it/s, est. speed input: 3613.60 toks/s, output: 3.53 toks/s]
Processed prompts:  88%| | 1798/2048 [08:29<01:12,  3.47it/s, est. speed input: 3612.85 toks/s, output: 3.53 toks/s]
Processed prompts:  89%| | 1814/2048 [08:34<01:07,  3.46it/s, est. speed input: 3612.09 toks/s, output: 3.53 toks/s]
Processed prompts:  89%| | 1830/2048 [08:38<01:03,  3.46it/s, est. speed input: 3611.37 toks/s, output: 3.53 toks/s]
Processed prompts:  90%| | 1846/2048 [08:43<00:58,  3.45it/s, est. speed input: 3610.62 toks/s, output: 3.53 toks/s]
Processed prompts:  91%| | 1862/2048 [08:48<00:53,  3.45it/s, est. speed input: 3609.93 toks/s, output: 3.53 toks/s]
Processed prompts:  92%|| 1878/2048 [08:52<00:49,  3.45it/s, est. speed input: 3609.20 toks/s, output: 3.52 toks/s]
Processed prompts:  92%|| 1894/2048 [08:57<00:44,  3.45it/s, est. speed input: 3608.47 toks/s, output: 3.52 toks/s]
Processed prompts:  93%|| 1910/2048 [09:02<00:40,  3.44it/s, est. speed input: 3607.68 toks/s, output: 3.52 toks/s]
Processed prompts:  94%|| 1926/2048 [09:06<00:35,  3.44it/s, est. speed input: 3607.00 toks/s, output: 3.52 toks/s]
Processed prompts:  95%|| 1942/2048 [09:11<00:30,  3.44it/s, est. speed input: 3606.29 toks/s, output: 3.52 toks/s]
Processed prompts:  96%|| 1958/2048 [09:16<00:26,  3.44it/s, est. speed input: 3605.59 toks/s, output: 3.52 toks/s]
Processed prompts:  96%|| 1974/2048 [09:20<00:21,  3.44it/s, est. speed input: 3604.93 toks/s, output: 3.52 toks/s]
Processed prompts:  97%|| 1990/2048 [09:25<00:16,  3.44it/s, est. speed input: 3604.23 toks/s, output: 3.52 toks/s]
Processed prompts:  98%|| 2006/2048 [09:30<00:12,  3.44it/s, est. speed input: 3603.54 toks/s, output: 3.52 toks/s]
Processed prompts:  99%|| 2022/2048 [09:34<00:07,  3.44it/s, est. speed input: 3602.90 toks/s, output: 3.52 toks/s]
Processed prompts: 100%|| 2038/2048 [09:37<00:02,  3.80it/s, est. speed input: 3611.37 toks/s, output: 3.53 toks/s]
Processed prompts: 100%|| 2048/2048 [09:37<00:00,  3.80it/s, est. speed input: 3629.09 toks/s, output: 3.54 toks/s]
Processed prompts: 100%|| 2048/2048 [09:37<00:00,  3.54it/s, est. speed input: 3629.09 toks/s, output: 3.54 toks/s]
[rank0]:[W127 01:21:53.998518109 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-27 01:22:01
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 01:22:22 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 01:22:22 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1951984) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1951984) WARNING 01-27 01:24:57 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.46 requests/s, 3548.70 total tokens/s, 3.46 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-27 01:22:22] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 01:22:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 01:22:22] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 01:22:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:22:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:22:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:22:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:22:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:22:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 01:22:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 01:22:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 01:22:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 01:22:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 01:22:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 01:22:25] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 01:22:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 01:22:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 01:22:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:22:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:22:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:22:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:22:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:22:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 01:22:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 01:22:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 01:22:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 01:22:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 01:22:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1951984) [2026-01-27 01:22:27] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1951984) [2026-01-27 01:22:27] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1951984) [2026-01-27 01:22:27] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1951984) [2026-01-27 01:22:27] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1951984) [2026-01-27 01:22:27] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1951984) [2026-01-27 01:22:27] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1951984) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1951984) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.62s/it]
(EngineCore_DP0 pid=1951984) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:43<00:48, 24.13s/it]
(EngineCore_DP0 pid=1951984) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:15<00:27, 27.82s/it]
(EngineCore_DP0 pid=1951984) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:50<00:00, 30.46s/it]
(EngineCore_DP0 pid=1951984) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:50<00:00, 27.58s/it]
(EngineCore_DP0 pid=1951984) 
(EngineCore_DP0 pid=1951984) [2026-01-27 01:24:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1951984) [2026-01-27 01:24:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36929536 bytes
(EngineCore_DP0 pid=1951984) [2026-01-27 01:24:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1951984) [2026-01-27 01:24:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26378240 bytes
(EngineCore_DP0 pid=1951984) [2026-01-27 01:24:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1951984) [2026-01-27 01:24:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 142442496 bytes
(EngineCore_DP0 pid=1951984) [2026-01-27 01:24:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1951984) [2026-01-27 01:24:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70778880 bytes
(EngineCore_DP0 pid=1951984) 2026-01-27 01:24:37,001 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1951984) 2026-01-27 01:24:41,901 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/4096 [00:00<1:08:12,  1.00it/s]
Adding requests:   0%|          | 2/4096 [00:01<38:13,  1.79it/s]  
Adding requests:   0%|          | 3/4096 [00:01<24:51,  2.74it/s]
Adding requests:   0%|          | 5/4096 [00:01<14:12,  4.80it/s]
Adding requests:   0%|          | 7/4096 [00:01<09:36,  7.09it/s]
Adding requests:   0%|          | 10/4096 [00:01<06:11, 11.01it/s]
Adding requests:   0%|          | 13/4096 [00:01<04:48, 14.16it/s]
Adding requests:   0%|          | 18/4096 [00:02<03:10, 21.45it/s]
Adding requests:   1%|          | 33/4096 [00:02<01:20, 50.46it/s]
Adding requests:   1%|          | 49/4096 [00:02<00:52, 76.42it/s]
Adding requests:   2%|         | 67/4096 [00:02<00:39, 102.04it/s]
Adding requests:   2%|         | 89/4096 [00:02<00:30, 133.27it/s]
Adding requests:   3%|         | 119/4096 [00:02<00:22, 178.45it/s]
Adding requests:   4%|         | 152/4096 [00:02<00:17, 219.80it/s]
Adding requests:   5%|         | 196/4096 [00:02<00:13, 281.93it/s]
Adding requests:   6%|         | 232/4096 [00:02<00:12, 302.98it/s]
Adding requests:   7%|         | 272/4096 [00:02<00:11, 328.97it/s]
Adding requests:   8%|         | 311/4096 [00:03<00:10, 346.81it/s]
Adding requests:   9%|         | 352/4096 [00:03<00:10, 364.74it/s]
Adding requests:  10%|         | 399/4096 [00:03<00:09, 393.73it/s]
Adding requests:  11%|         | 442/4096 [00:03<00:09, 403.80it/s]
Adding requests:  12%|        | 488/4096 [00:03<00:08, 419.01it/s]
Adding requests:  13%|        | 535/4096 [00:03<00:08, 431.56it/s]
Adding requests:  14%|        | 580/4096 [00:03<00:08, 435.37it/s]
Adding requests:  15%|        | 624/4096 [00:03<00:08, 431.23it/s]
Adding requests:  16%|        | 668/4096 [00:03<00:08, 421.37it/s]
Adding requests:  17%|        | 711/4096 [00:03<00:08, 420.64it/s]
Adding requests:  18%|        | 754/4096 [00:04<00:08, 409.72it/s]
Adding requests:  19%|        | 798/4096 [00:04<00:07, 415.75it/s]
Adding requests:  21%|        | 842/4096 [00:04<00:07, 421.99it/s]
Adding requests:  22%|       | 888/4096 [00:04<00:07, 431.93it/s]
Adding requests:  23%|       | 932/4096 [00:04<00:07, 420.42it/s]
Adding requests:  24%|       | 976/4096 [00:04<00:07, 424.51it/s]
Adding requests:  25%|       | 1019/4096 [00:04<00:07, 420.72it/s]
Adding requests:  26%|       | 1062/4096 [00:04<00:07, 414.36it/s]
Adding requests:  27%|       | 1104/4096 [00:04<00:07, 413.30it/s]
Adding requests:  28%|       | 1147/4096 [00:05<00:07, 416.10it/s]
Adding requests:  29%|       | 1189/4096 [00:05<00:07, 408.00it/s]
Adding requests:  30%|       | 1233/4096 [00:05<00:06, 416.39it/s]
Adding requests:  31%|       | 1275/4096 [00:05<00:06, 414.69it/s]
Adding requests:  32%|      | 1317/4096 [00:05<00:07, 395.01it/s]
Adding requests:  33%|      | 1361/4096 [00:05<00:06, 406.97it/s]
Adding requests:  34%|      | 1402/4096 [00:05<00:06, 392.49it/s]
Adding requests:  35%|      | 1442/4096 [00:05<00:06, 387.93it/s]
Adding requests:  36%|      | 1486/4096 [00:05<00:06, 402.00it/s]
Adding requests:  37%|      | 1529/4096 [00:05<00:06, 408.67it/s]
Adding requests:  38%|      | 1571/4096 [00:06<00:06, 411.81it/s]
Adding requests:  39%|      | 1613/4096 [00:06<00:06, 400.19it/s]
Adding requests:  40%|      | 1654/4096 [00:06<00:06, 398.68it/s]
Adding requests:  41%|     | 1694/4096 [00:06<00:06, 397.44it/s]
Adding requests:  42%|     | 1736/4096 [00:06<00:05, 403.40it/s]
Adding requests:  44%|     | 1782/4096 [00:06<00:05, 419.01it/s]
Adding requests:  45%|     | 1824/4096 [00:06<00:05, 410.97it/s]
Adding requests:  46%|     | 1867/4096 [00:06<00:05, 414.91it/s]
Adding requests:  47%|     | 1909/4096 [00:06<00:05, 413.98it/s]
Adding requests:  48%|     | 1956/4096 [00:07<00:04, 429.03it/s]
Adding requests:  49%|     | 1999/4096 [00:07<00:05, 407.98it/s]
Adding requests:  50%|     | 2042/4096 [00:07<00:05, 409.60it/s]
Adding requests:  51%|     | 2084/4096 [00:07<00:04, 410.43it/s]
Adding requests:  52%|    | 2127/4096 [00:07<00:04, 414.22it/s]
Adding requests:  53%|    | 2169/4096 [00:07<00:04, 415.05it/s]
Adding requests:  54%|    | 2211/4096 [00:07<00:04, 406.11it/s]
Adding requests:  55%|    | 2252/4096 [00:07<00:04, 390.12it/s]
Adding requests:  56%|    | 2296/4096 [00:07<00:04, 404.26it/s]
Adding requests:  57%|    | 2342/4096 [00:07<00:04, 419.64it/s]
Adding requests:  58%|    | 2390/4096 [00:08<00:03, 435.33it/s]
Adding requests:  59%|    | 2434/4096 [00:08<00:03, 421.35it/s]
Adding requests:  60%|    | 2477/4096 [00:08<00:03, 419.28it/s]
Adding requests:  62%|   | 2522/4096 [00:08<00:03, 409.63it/s]
Adding requests:  63%|   | 2565/4096 [00:08<00:03, 415.36it/s]
Adding requests:  64%|   | 2607/4096 [00:08<00:03, 409.64it/s]
Adding requests:  65%|   | 2650/4096 [00:08<00:03, 413.99it/s]
Adding requests:  66%|   | 2692/4096 [00:08<00:03, 410.14it/s]
Adding requests:  67%|   | 2734/4096 [00:08<00:03, 410.11it/s]
Adding requests:  68%|   | 2776/4096 [00:09<00:03, 412.85it/s]
Adding requests:  69%|   | 2818/4096 [00:09<00:03, 401.70it/s]
Adding requests:  70%|   | 2859/4096 [00:09<00:03, 399.19it/s]
Adding requests:  71%|   | 2903/4096 [00:09<00:02, 409.57it/s]
Adding requests:  72%|  | 2948/4096 [00:09<00:02, 419.53it/s]
Adding requests:  73%|  | 2992/4096 [00:09<00:02, 421.54it/s]
Adding requests:  74%|  | 3037/4096 [00:09<00:02, 428.36it/s]
Adding requests:  75%|  | 3080/4096 [00:09<00:02, 426.59it/s]
Adding requests:  76%|  | 3126/4096 [00:09<00:02, 435.68it/s]
Adding requests:  77%|  | 3170/4096 [00:09<00:02, 428.41it/s]
Adding requests:  78%|  | 3213/4096 [00:10<00:02, 427.92it/s]
Adding requests:  80%|  | 3258/4096 [00:10<00:01, 432.25it/s]
Adding requests:  81%|  | 3302/4096 [00:10<00:01, 422.47it/s]
Adding requests:  82%| | 3345/4096 [00:10<00:01, 424.08it/s]
Adding requests:  83%| | 3388/4096 [00:10<00:01, 424.42it/s]
Adding requests:  84%| | 3431/4096 [00:10<00:01, 424.93it/s]
Adding requests:  85%| | 3478/4096 [00:10<00:01, 436.46it/s]
Adding requests:  86%| | 3523/4096 [00:10<00:01, 440.25it/s]
Adding requests:  87%| | 3572/4096 [00:10<00:01, 453.38it/s]
Adding requests:  88%| | 3618/4096 [00:10<00:01, 438.14it/s]
Adding requests:  89%| | 3662/4096 [00:11<00:01, 420.36it/s]
Adding requests:  90%| | 3705/4096 [00:11<00:00, 419.62it/s]
Adding requests:  92%|| 3748/4096 [00:11<00:00, 412.04it/s]
Adding requests:  93%|| 3790/4096 [00:11<00:00, 393.33it/s]
Adding requests:  94%|| 3830/4096 [00:11<00:00, 393.48it/s]
Adding requests:  95%|| 3877/4096 [00:11<00:00, 412.79it/s]
Adding requests:  96%|| 3920/4096 [00:11<00:00, 417.42it/s]
Adding requests:  97%|| 3962/4096 [00:11<00:00, 406.08it/s]
Adding requests:  98%|| 4008/4096 [00:11<00:00, 419.94it/s]
Adding requests:  99%|| 4051/4096 [00:12<00:00, 400.60it/s]
Adding requests: 100%|| 4092/4096 [00:12<00:00, 395.58it/s]
Adding requests: 100%|| 4096/4096 [00:12<00:00, 336.81it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 18/4096 [00:03<11:45,  5.78it/s, est. speed input: 5920.05 toks/s, output: 5.78 toks/s]
Processed prompts:   1%|          | 50/4096 [00:12<17:09,  3.93it/s, est. speed input: 4167.51 toks/s, output: 4.07 toks/s]
Processed prompts:   2%|         | 82/4096 [00:21<18:07,  3.69it/s, est. speed input: 3910.11 toks/s, output: 3.82 toks/s]
Processed prompts:   3%|         | 114/4096 [00:30<18:26,  3.60it/s, est. speed input: 3807.41 toks/s, output: 3.72 toks/s]
Processed prompts:   4%|         | 146/4096 [00:39<18:31,  3.55it/s, est. speed input: 3751.13 toks/s, output: 3.66 toks/s]
Processed prompts:   4%|         | 178/4096 [00:48<18:21,  3.56it/s, est. speed input: 3732.43 toks/s, output: 3.64 toks/s]
Processed prompts:   5%|         | 210/4096 [00:58<18:20,  3.53it/s, est. speed input: 3705.55 toks/s, output: 3.62 toks/s]
Processed prompts:   6%|         | 242/4096 [01:07<18:17,  3.51it/s, est. speed input: 3685.31 toks/s, output: 3.60 toks/s]
Processed prompts:   7%|         | 274/4096 [01:16<18:11,  3.50it/s, est. speed input: 3670.42 toks/s, output: 3.58 toks/s]
Processed prompts:   7%|         | 306/4096 [01:25<17:56,  3.52it/s, est. speed input: 3668.41 toks/s, output: 3.58 toks/s]
Processed prompts:   8%|         | 338/4096 [01:34<17:51,  3.51it/s, est. speed input: 3657.86 toks/s, output: 3.57 toks/s]
Processed prompts:   9%|         | 370/4096 [01:43<17:45,  3.50it/s, est. speed input: 3649.02 toks/s, output: 3.56 toks/s]
Processed prompts:  10%|         | 402/4096 [01:53<17:37,  3.49it/s, est. speed input: 3642.00 toks/s, output: 3.56 toks/s]
Processed prompts:  11%|         | 434/4096 [02:02<17:22,  3.51it/s, est. speed input: 3642.66 toks/s, output: 3.56 toks/s]
Processed prompts:  11%|        | 466/4096 [02:11<17:16,  3.50it/s, est. speed input: 3636.72 toks/s, output: 3.55 toks/s]
Processed prompts:  12%|        | 498/4096 [02:20<17:09,  3.50it/s, est. speed input: 3631.93 toks/s, output: 3.55 toks/s]
Processed prompts:  13%|        | 530/4096 [02:29<17:01,  3.49it/s, est. speed input: 3627.64 toks/s, output: 3.54 toks/s]
Processed prompts:  14%|        | 562/4096 [02:38<16:53,  3.49it/s, est. speed input: 3623.61 toks/s, output: 3.54 toks/s]
Processed prompts:  15%|        | 594/4096 [02:48<16:45,  3.48it/s, est. speed input: 3620.20 toks/s, output: 3.54 toks/s]
Processed prompts:  15%|        | 626/4096 [02:57<16:36,  3.48it/s, est. speed input: 3617.21 toks/s, output: 3.53 toks/s]
Processed prompts:  16%|        | 658/4096 [03:06<16:27,  3.48it/s, est. speed input: 3614.34 toks/s, output: 3.53 toks/s]
Processed prompts:  17%|        | 690/4096 [03:15<16:19,  3.48it/s, est. speed input: 3611.78 toks/s, output: 3.53 toks/s]
Processed prompts:  18%|        | 722/4096 [03:24<16:09,  3.48it/s, est. speed input: 3609.52 toks/s, output: 3.52 toks/s]
Processed prompts:  18%|        | 754/4096 [03:34<16:01,  3.48it/s, est. speed input: 3607.22 toks/s, output: 3.52 toks/s]
Processed prompts:  19%|        | 786/4096 [03:43<15:45,  3.50it/s, est. speed input: 3608.80 toks/s, output: 3.52 toks/s]
Processed prompts:  20%|        | 818/4096 [03:52<15:38,  3.49it/s, est. speed input: 3606.73 toks/s, output: 3.52 toks/s]
Processed prompts:  21%|        | 850/4096 [04:01<15:30,  3.49it/s, est. speed input: 3604.77 toks/s, output: 3.52 toks/s]
Processed prompts:  22%|       | 882/4096 [04:10<15:22,  3.48it/s, est. speed input: 3602.94 toks/s, output: 3.52 toks/s]
Processed prompts:  22%|       | 914/4096 [04:19<15:14,  3.48it/s, est. speed input: 3601.21 toks/s, output: 3.52 toks/s]
Processed prompts:  23%|       | 946/4096 [04:29<15:06,  3.48it/s, est. speed input: 3599.44 toks/s, output: 3.52 toks/s]
Processed prompts:  24%|       | 978/4096 [04:38<14:57,  3.47it/s, est. speed input: 3597.78 toks/s, output: 3.51 toks/s]
Processed prompts:  25%|       | 1010/4096 [04:47<14:49,  3.47it/s, est. speed input: 3596.16 toks/s, output: 3.51 toks/s]
Processed prompts:  25%|       | 1042/4096 [04:56<14:40,  3.47it/s, est. speed input: 3594.74 toks/s, output: 3.51 toks/s]
Processed prompts:  26%|       | 1074/4096 [05:06<14:31,  3.47it/s, est. speed input: 3593.45 toks/s, output: 3.51 toks/s]
Processed prompts:  27%|       | 1106/4096 [05:15<14:22,  3.47it/s, est. speed input: 3592.17 toks/s, output: 3.51 toks/s]
Processed prompts:  28%|       | 1138/4096 [05:24<14:13,  3.47it/s, est. speed input: 3590.95 toks/s, output: 3.51 toks/s]
Processed prompts:  29%|       | 1170/4096 [05:33<14:03,  3.47it/s, est. speed input: 3589.80 toks/s, output: 3.51 toks/s]
Processed prompts:  29%|       | 1202/4096 [05:42<13:48,  3.49it/s, est. speed input: 3590.95 toks/s, output: 3.51 toks/s]
Processed prompts:  30%|       | 1234/4096 [05:52<13:41,  3.48it/s, est. speed input: 3589.82 toks/s, output: 3.51 toks/s]
Processed prompts:  31%|       | 1266/4096 [06:01<13:33,  3.48it/s, est. speed input: 3588.69 toks/s, output: 3.50 toks/s]
Processed prompts:  32%|      | 1298/4096 [06:10<13:25,  3.47it/s, est. speed input: 3587.62 toks/s, output: 3.50 toks/s]
Processed prompts:  32%|      | 1330/4096 [06:19<13:17,  3.47it/s, est. speed input: 3586.48 toks/s, output: 3.50 toks/s]
Processed prompts:  33%|      | 1362/4096 [06:28<13:08,  3.47it/s, est. speed input: 3585.46 toks/s, output: 3.50 toks/s]
Processed prompts:  34%|      | 1394/4096 [06:38<12:59,  3.46it/s, est. speed input: 3584.48 toks/s, output: 3.50 toks/s]
Processed prompts:  35%|      | 1426/4096 [06:47<12:50,  3.46it/s, est. speed input: 3583.62 toks/s, output: 3.50 toks/s]
Processed prompts:  36%|      | 1458/4096 [06:56<12:42,  3.46it/s, est. speed input: 3582.59 toks/s, output: 3.50 toks/s]
Processed prompts:  36%|      | 1490/4096 [07:05<12:32,  3.46it/s, est. speed input: 3581.78 toks/s, output: 3.50 toks/s]
Processed prompts:  37%|      | 1522/4096 [07:15<12:23,  3.46it/s, est. speed input: 3580.91 toks/s, output: 3.50 toks/s]
Processed prompts:  38%|      | 1554/4096 [07:24<12:09,  3.48it/s, est. speed input: 3581.85 toks/s, output: 3.50 toks/s]
Processed prompts:  39%|      | 1586/4096 [07:33<12:02,  3.48it/s, est. speed input: 3580.96 toks/s, output: 3.50 toks/s]
Processed prompts:  40%|      | 1618/4096 [07:42<11:49,  3.49it/s, est. speed input: 3581.81 toks/s, output: 3.50 toks/s]
Processed prompts:  40%|      | 1650/4096 [07:51<11:42,  3.48it/s, est. speed input: 3580.97 toks/s, output: 3.50 toks/s]
Processed prompts:  41%|      | 1682/4096 [08:01<11:34,  3.47it/s, est. speed input: 3580.10 toks/s, output: 3.50 toks/s]
Processed prompts:  42%|     | 1714/4096 [08:10<11:26,  3.47it/s, est. speed input: 3579.31 toks/s, output: 3.50 toks/s]
Processed prompts:  43%|     | 1746/4096 [08:19<11:13,  3.49it/s, est. speed input: 3579.99 toks/s, output: 3.50 toks/s]
Processed prompts:  43%|     | 1778/4096 [08:28<11:06,  3.48it/s, est. speed input: 3579.12 toks/s, output: 3.50 toks/s]
Processed prompts:  44%|     | 1810/4096 [08:37<10:59,  3.47it/s, est. speed input: 3578.34 toks/s, output: 3.49 toks/s]
Processed prompts:  45%|     | 1842/4096 [08:47<10:50,  3.46it/s, est. speed input: 3577.53 toks/s, output: 3.49 toks/s]
Processed prompts:  46%|     | 1874/4096 [08:56<10:42,  3.46it/s, est. speed input: 3576.76 toks/s, output: 3.49 toks/s]
Processed prompts:  47%|     | 1906/4096 [09:05<10:33,  3.46it/s, est. speed input: 3575.93 toks/s, output: 3.49 toks/s]
Processed prompts:  47%|     | 1938/4096 [09:15<10:24,  3.45it/s, est. speed input: 3575.24 toks/s, output: 3.49 toks/s]
Processed prompts:  48%|     | 1970/4096 [09:24<10:15,  3.45it/s, est. speed input: 3574.57 toks/s, output: 3.49 toks/s]
Processed prompts:  49%|     | 2002/4096 [09:33<10:06,  3.45it/s, est. speed input: 3573.81 toks/s, output: 3.49 toks/s]
Processed prompts:  50%|     | 2034/4096 [09:42<09:57,  3.45it/s, est. speed input: 3573.18 toks/s, output: 3.49 toks/s]
Processed prompts:  50%|     | 2066/4096 [09:52<09:48,  3.45it/s, est. speed input: 3572.59 toks/s, output: 3.49 toks/s]
Processed prompts:  51%|     | 2098/4096 [10:01<09:38,  3.45it/s, est. speed input: 3572.00 toks/s, output: 3.49 toks/s]
Processed prompts:  52%|    | 2130/4096 [10:10<09:29,  3.45it/s, est. speed input: 3571.38 toks/s, output: 3.49 toks/s]
Processed prompts:  53%|    | 2162/4096 [10:19<09:19,  3.45it/s, est. speed input: 3571.01 toks/s, output: 3.49 toks/s]
Processed prompts:  54%|    | 2194/4096 [10:29<09:06,  3.48it/s, est. speed input: 3571.69 toks/s, output: 3.49 toks/s]
Processed prompts:  54%|    | 2226/4096 [10:38<08:58,  3.47it/s, est. speed input: 3571.15 toks/s, output: 3.49 toks/s]
Processed prompts:  55%|    | 2258/4096 [10:47<08:50,  3.46it/s, est. speed input: 3570.61 toks/s, output: 3.49 toks/s]
Processed prompts:  56%|    | 2290/4096 [10:56<08:42,  3.46it/s, est. speed input: 3570.05 toks/s, output: 3.49 toks/s]
Processed prompts:  57%|    | 2322/4096 [11:06<08:33,  3.46it/s, est. speed input: 3569.50 toks/s, output: 3.49 toks/s]
Processed prompts:  57%|    | 2354/4096 [11:15<08:24,  3.45it/s, est. speed input: 3568.95 toks/s, output: 3.49 toks/s]
Processed prompts:  58%|    | 2386/4096 [11:24<08:15,  3.45it/s, est. speed input: 3568.49 toks/s, output: 3.48 toks/s]
Processed prompts:  59%|    | 2418/4096 [11:33<08:06,  3.45it/s, est. speed input: 3567.96 toks/s, output: 3.48 toks/s]
Processed prompts:  60%|    | 2450/4096 [11:43<07:57,  3.45it/s, est. speed input: 3567.48 toks/s, output: 3.48 toks/s]
Processed prompts:  61%|    | 2482/4096 [11:52<07:47,  3.45it/s, est. speed input: 3567.02 toks/s, output: 3.48 toks/s]
Processed prompts:  61%|   | 2514/4096 [12:01<07:38,  3.45it/s, est. speed input: 3566.55 toks/s, output: 3.48 toks/s]
Processed prompts:  62%|   | 2546/4096 [12:11<07:36,  3.40it/s, est. speed input: 3563.86 toks/s, output: 3.48 toks/s]
Processed prompts:  63%|   | 2578/4096 [12:20<07:21,  3.44it/s, est. speed input: 3564.49 toks/s, output: 3.48 toks/s]
Processed prompts:  64%|   | 2610/4096 [12:29<07:11,  3.44it/s, est. speed input: 3564.08 toks/s, output: 3.48 toks/s]
Processed prompts:  65%|   | 2642/4096 [12:39<07:02,  3.44it/s, est. speed input: 3563.63 toks/s, output: 3.48 toks/s]
Processed prompts:  65%|   | 2674/4096 [12:48<06:52,  3.45it/s, est. speed input: 3563.29 toks/s, output: 3.48 toks/s]
Processed prompts:  66%|   | 2706/4096 [12:57<06:43,  3.45it/s, est. speed input: 3562.93 toks/s, output: 3.48 toks/s]
Processed prompts:  67%|   | 2738/4096 [13:06<06:31,  3.47it/s, est. speed input: 3563.49 toks/s, output: 3.48 toks/s]
Processed prompts:  68%|   | 2770/4096 [13:16<06:22,  3.46it/s, est. speed input: 3563.08 toks/s, output: 3.48 toks/s]
Processed prompts:  68%|   | 2802/4096 [13:25<06:14,  3.46it/s, est. speed input: 3562.73 toks/s, output: 3.48 toks/s]
Processed prompts:  69%|   | 2834/4096 [13:34<06:05,  3.46it/s, est. speed input: 3562.37 toks/s, output: 3.48 toks/s]
Processed prompts:  70%|   | 2866/4096 [13:43<05:56,  3.45it/s, est. speed input: 3561.95 toks/s, output: 3.48 toks/s]
Processed prompts:  71%|   | 2898/4096 [13:52<05:41,  3.51it/s, est. speed input: 3563.72 toks/s, output: 3.48 toks/s]
Processed prompts:  72%|  | 2930/4096 [14:02<05:34,  3.49it/s, est. speed input: 3563.32 toks/s, output: 3.48 toks/s]
Processed prompts:  72%|  | 2962/4096 [14:11<05:26,  3.48it/s, est. speed input: 3562.94 toks/s, output: 3.48 toks/s]
Processed prompts:  73%|  | 2994/4096 [14:20<05:17,  3.47it/s, est. speed input: 3562.55 toks/s, output: 3.48 toks/s]
Processed prompts:  74%|  | 3026/4096 [14:29<05:09,  3.46it/s, est. speed input: 3562.16 toks/s, output: 3.48 toks/s]
Processed prompts:  75%|  | 3058/4096 [14:39<05:00,  3.45it/s, est. speed input: 3561.78 toks/s, output: 3.48 toks/s]
Processed prompts:  75%|  | 3090/4096 [14:48<04:51,  3.45it/s, est. speed input: 3561.40 toks/s, output: 3.48 toks/s]
Processed prompts:  76%|  | 3122/4096 [14:57<04:42,  3.45it/s, est. speed input: 3561.04 toks/s, output: 3.48 toks/s]
Processed prompts:  77%|  | 3154/4096 [15:07<04:33,  3.45it/s, est. speed input: 3560.68 toks/s, output: 3.48 toks/s]
Processed prompts:  78%|  | 3186/4096 [15:16<04:24,  3.45it/s, est. speed input: 3560.30 toks/s, output: 3.48 toks/s]
Processed prompts:  79%|  | 3218/4096 [15:25<04:15,  3.44it/s, est. speed input: 3559.87 toks/s, output: 3.48 toks/s]
Processed prompts:  79%|  | 3250/4096 [15:35<04:06,  3.43it/s, est. speed input: 3559.23 toks/s, output: 3.48 toks/s]
Processed prompts:  80%|  | 3282/4096 [15:44<03:57,  3.43it/s, est. speed input: 3558.78 toks/s, output: 3.48 toks/s]
Processed prompts:  81%|  | 3314/4096 [15:53<03:48,  3.43it/s, est. speed input: 3558.13 toks/s, output: 3.47 toks/s]
Processed prompts:  82%| | 3346/4096 [16:03<03:39,  3.41it/s, est. speed input: 3557.15 toks/s, output: 3.47 toks/s]
Processed prompts:  82%| | 3378/4096 [16:12<03:30,  3.42it/s, est. speed input: 3556.66 toks/s, output: 3.47 toks/s]
Processed prompts:  83%| | 3410/4096 [16:21<03:20,  3.42it/s, est. speed input: 3556.28 toks/s, output: 3.47 toks/s]
Processed prompts:  84%| | 3442/4096 [16:31<03:10,  3.43it/s, est. speed input: 3556.06 toks/s, output: 3.47 toks/s]
Processed prompts:  85%| | 3474/4096 [16:40<03:00,  3.44it/s, est. speed input: 3555.88 toks/s, output: 3.47 toks/s]
Processed prompts:  86%| | 3506/4096 [16:49<02:51,  3.44it/s, est. speed input: 3555.61 toks/s, output: 3.47 toks/s]
Processed prompts:  86%| | 3538/4096 [16:58<02:38,  3.52it/s, est. speed input: 3557.82 toks/s, output: 3.47 toks/s]
Processed prompts:  87%| | 3570/4096 [17:07<02:30,  3.50it/s, est. speed input: 3557.52 toks/s, output: 3.47 toks/s]
Processed prompts:  88%| | 3602/4096 [17:16<02:21,  3.48it/s, est. speed input: 3557.26 toks/s, output: 3.47 toks/s]
Processed prompts:  89%| | 3634/4096 [17:26<02:13,  3.47it/s, est. speed input: 3557.04 toks/s, output: 3.47 toks/s]
Processed prompts:  90%| | 3666/4096 [17:35<02:03,  3.48it/s, est. speed input: 3557.33 toks/s, output: 3.47 toks/s]
Processed prompts:  90%| | 3698/4096 [17:44<01:54,  3.47it/s, est. speed input: 3556.92 toks/s, output: 3.47 toks/s]
Processed prompts:  91%| | 3730/4096 [17:53<01:45,  3.46it/s, est. speed input: 3556.66 toks/s, output: 3.47 toks/s]
Processed prompts:  92%|| 3762/4096 [18:03<01:36,  3.46it/s, est. speed input: 3556.44 toks/s, output: 3.47 toks/s]
Processed prompts:  93%|| 3794/4096 [18:12<01:27,  3.45it/s, est. speed input: 3556.20 toks/s, output: 3.47 toks/s]
Processed prompts:  93%|| 3826/4096 [18:21<01:18,  3.45it/s, est. speed input: 3555.97 toks/s, output: 3.47 toks/s]
Processed prompts:  94%|| 3858/4096 [18:31<01:09,  3.45it/s, est. speed input: 3555.73 toks/s, output: 3.47 toks/s]
Processed prompts:  95%|| 3890/4096 [18:40<00:59,  3.45it/s, est. speed input: 3555.49 toks/s, output: 3.47 toks/s]
Processed prompts:  96%|| 3922/4096 [18:49<00:50,  3.47it/s, est. speed input: 3556.00 toks/s, output: 3.47 toks/s]
Processed prompts:  97%|| 3954/4096 [18:58<00:40,  3.47it/s, est. speed input: 3555.80 toks/s, output: 3.47 toks/s]
Processed prompts:  97%|| 3986/4096 [19:07<00:31,  3.48it/s, est. speed input: 3556.24 toks/s, output: 3.47 toks/s]
Processed prompts:  98%|| 4018/4096 [19:17<00:22,  3.47it/s, est. speed input: 3556.03 toks/s, output: 3.47 toks/s]
Processed prompts:  99%|| 4050/4096 [19:26<00:13,  3.47it/s, est. speed input: 3555.85 toks/s, output: 3.47 toks/s]
Processed prompts: 100%|| 4082/4096 [19:30<00:03,  4.12it/s, est. speed input: 3570.59 toks/s, output: 3.49 toks/s]
Processed prompts: 100%|| 4096/4096 [19:30<00:00,  4.12it/s, est. speed input: 3582.84 toks/s, output: 3.50 toks/s]
Processed prompts: 100%|| 4096/4096 [19:30<00:00,  3.50it/s, est. speed input: 3582.84 toks/s, output: 3.50 toks/s]
[rank0]:[W127 01:44:48.989347711 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-27 01:44:56
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-INT8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 01:45:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 01:45:32 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1971486) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1971486) WARNING 01-27 01:48:21 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.47 requests/s, 3558.88 total tokens/s, 3.47 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-27 01:45:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 01:45:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 01:45:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 01:45:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:45:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:45:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:45:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:45:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:45:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 01:45:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 01:45:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 01:45:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 01:45:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 01:45:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 01:45:35] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 01:45:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-27 01:45:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-27 01:45:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:45:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:45:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:45:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:45:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-27 01:45:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-27 01:45:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 01:45:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 01:45:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 01:45:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 01:45:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1971486) [2026-01-27 01:45:37] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1971486) [2026-01-27 01:45:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1971486) [2026-01-27 01:45:37] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1971486) [2026-01-27 01:45:37] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1971486) [2026-01-27 01:45:37] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=1971486) [2026-01-27 01:45:37] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=1971486) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1971486) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.48s/it]
(EngineCore_DP0 pid=1971486) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:43<00:48, 24.16s/it]
(EngineCore_DP0 pid=1971486) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:15<00:27, 27.53s/it]
(EngineCore_DP0 pid=1971486) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:47<00:00, 29.62s/it]
(EngineCore_DP0 pid=1971486) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:47<00:00, 27.00s/it]
(EngineCore_DP0 pid=1971486) 
(EngineCore_DP0 pid=1971486) [2026-01-27 01:47:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=1971486) [2026-01-27 01:47:27] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 36929536 bytes
(EngineCore_DP0 pid=1971486) [2026-01-27 01:47:27] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=1971486) [2026-01-27 01:47:27] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 26378240 bytes
(EngineCore_DP0 pid=1971486) [2026-01-27 01:47:27] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=1971486) [2026-01-27 01:47:27] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 142442496 bytes
(EngineCore_DP0 pid=1971486) [2026-01-27 01:47:27] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=1971486) [2026-01-27 01:47:27] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 70778880 bytes
(EngineCore_DP0 pid=1971486) 2026-01-27 01:47:53,187 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1971486) 2026-01-27 01:48:01,522 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/8192 [00:00<2:05:29,  1.09it/s]
Adding requests:   0%|          | 2/8192 [00:01<1:10:30,  1.94it/s]
Adding requests:   0%|          | 3/8192 [00:01<46:57,  2.91it/s]  
Adding requests:   0%|          | 4/8192 [00:01<34:00,  4.01it/s]
Adding requests:   0%|          | 6/8192 [00:01<20:31,  6.64it/s]
Adding requests:   0%|          | 9/8192 [00:01<12:45, 10.69it/s]
Adding requests:   0%|          | 12/8192 [00:01<09:33, 14.27it/s]
Adding requests:   0%|          | 17/8192 [00:01<06:11, 21.98it/s]
Adding requests:   0%|          | 29/8192 [00:01<03:00, 45.22it/s]
Adding requests:   1%|          | 45/8192 [00:02<01:49, 74.23it/s]
Adding requests:   1%|          | 63/8192 [00:02<01:19, 101.82it/s]
Adding requests:   1%|          | 80/8192 [00:02<01:07, 119.96it/s]
Adding requests:   1%|         | 112/8192 [00:02<00:46, 174.18it/s]
Adding requests:   2%|         | 146/8192 [00:02<00:36, 220.25it/s]
Adding requests:   2%|         | 179/8192 [00:02<00:31, 251.73it/s]
Adding requests:   3%|         | 213/8192 [00:02<00:28, 277.23it/s]
Adding requests:   3%|         | 244/8192 [00:02<00:27, 286.63it/s]
Adding requests:   3%|         | 278/8192 [00:02<00:26, 301.18it/s]
Adding requests:   4%|         | 309/8192 [00:02<00:26, 299.52it/s]
Adding requests:   4%|         | 344/8192 [00:03<00:25, 313.72it/s]
Adding requests:   5%|         | 382/8192 [00:03<00:23, 331.52it/s]
Adding requests:   5%|         | 424/8192 [00:03<00:21, 355.34it/s]
Adding requests:   6%|         | 463/8192 [00:03<00:21, 363.96it/s]
Adding requests:   6%|         | 504/8192 [00:03<00:20, 377.14it/s]
Adding requests:   7%|         | 543/8192 [00:03<00:20, 380.84it/s]
Adding requests:   7%|         | 583/8192 [00:03<00:19, 384.32it/s]
Adding requests:   8%|         | 624/8192 [00:03<00:19, 390.28it/s]
Adding requests:   8%|         | 665/8192 [00:03<00:19, 393.84it/s]
Adding requests:   9%|         | 705/8192 [00:04<00:19, 392.72it/s]
Adding requests:   9%|         | 745/8192 [00:04<00:19, 381.09it/s]
Adding requests:  10%|         | 784/8192 [00:04<00:19, 380.13it/s]
Adding requests:  10%|         | 823/8192 [00:04<00:19, 372.84it/s]
Adding requests:  11%|         | 864/8192 [00:04<00:19, 383.51it/s]
Adding requests:  11%|         | 905/8192 [00:04<00:18, 389.21it/s]
Adding requests:  12%|        | 945/8192 [00:04<00:18, 388.59it/s]
Adding requests:  12%|        | 986/8192 [00:04<00:18, 391.67it/s]
Adding requests:  13%|        | 1026/8192 [00:04<00:18, 388.36it/s]
Adding requests:  13%|        | 1066/8192 [00:04<00:18, 390.80it/s]
Adding requests:  14%|        | 1106/8192 [00:05<00:18, 386.13it/s]
Adding requests:  14%|        | 1147/8192 [00:05<00:17, 392.51it/s]
Adding requests:  15%|        | 1188/8192 [00:05<00:17, 395.74it/s]
Adding requests:  15%|        | 1229/8192 [00:05<00:17, 396.89it/s]
Adding requests:  15%|        | 1269/8192 [00:05<00:18, 381.20it/s]
Adding requests:  16%|        | 1309/8192 [00:05<00:17, 383.73it/s]
Adding requests:  16%|        | 1348/8192 [00:05<00:18, 374.81it/s]
Adding requests:  17%|        | 1388/8192 [00:05<00:17, 381.30it/s]
Adding requests:  17%|        | 1427/8192 [00:05<00:17, 383.02it/s]
Adding requests:  18%|        | 1467/8192 [00:05<00:17, 385.28it/s]
Adding requests:  18%|        | 1507/8192 [00:06<00:17, 387.52it/s]
Adding requests:  19%|        | 1546/8192 [00:06<00:17, 386.61it/s]
Adding requests:  19%|        | 1587/8192 [00:06<00:16, 392.24it/s]
Adding requests:  20%|        | 1627/8192 [00:06<00:17, 385.32it/s]
Adding requests:  20%|        | 1667/8192 [00:06<00:16, 387.41it/s]
Adding requests:  21%|        | 1708/8192 [00:06<00:16, 391.77it/s]
Adding requests:  21%|       | 1749/8192 [00:06<00:16, 396.22it/s]
Adding requests:  22%|       | 1793/8192 [00:06<00:15, 407.70it/s]
Adding requests:  22%|       | 1834/8192 [00:06<00:16, 388.12it/s]
Adding requests:  23%|       | 1878/8192 [00:07<00:15, 401.14it/s]
Adding requests:  23%|       | 1919/8192 [00:07<00:15, 393.92it/s]
Adding requests:  24%|       | 1959/8192 [00:07<00:15, 394.27it/s]
Adding requests:  24%|       | 1999/8192 [00:07<00:16, 371.18it/s]
Adding requests:  25%|       | 2042/8192 [00:07<00:15, 385.20it/s]
Adding requests:  25%|       | 2081/8192 [00:07<00:16, 379.18it/s]
Adding requests:  26%|       | 2120/8192 [00:07<00:16, 379.07it/s]
Adding requests:  26%|       | 2162/8192 [00:07<00:15, 390.58it/s]
Adding requests:  27%|       | 2202/8192 [00:07<00:15, 386.80it/s]
Adding requests:  27%|       | 2241/8192 [00:07<00:15, 374.16it/s]
Adding requests:  28%|       | 2279/8192 [00:08<00:15, 374.39it/s]
Adding requests:  28%|       | 2328/8192 [00:08<00:14, 405.26it/s]
Adding requests:  29%|       | 2369/8192 [00:08<00:14, 397.08it/s]
Adding requests:  29%|       | 2413/8192 [00:08<00:14, 407.68it/s]
Adding requests:  30%|       | 2454/8192 [00:08<00:14, 396.89it/s]
Adding requests:  31%|       | 2499/8192 [00:08<00:13, 410.70it/s]
Adding requests:  31%|       | 2541/8192 [00:08<00:14, 398.10it/s]
Adding requests:  32%|      | 2581/8192 [00:08<00:14, 396.37it/s]
Adding requests:  32%|      | 2623/8192 [00:08<00:13, 400.96it/s]
Adding requests:  33%|      | 2664/8192 [00:09<00:13, 402.32it/s]
Adding requests:  33%|      | 2705/8192 [00:09<00:13, 404.02it/s]
Adding requests:  34%|      | 2747/8192 [00:09<00:13, 408.10it/s]
Adding requests:  34%|      | 2793/8192 [00:09<00:12, 421.55it/s]
Adding requests:  35%|      | 2836/8192 [00:09<00:12, 416.32it/s]
Adding requests:  35%|      | 2878/8192 [00:09<00:12, 415.60it/s]
Adding requests:  36%|      | 2920/8192 [00:09<00:13, 396.61it/s]
Adding requests:  36%|      | 2968/8192 [00:09<00:12, 419.82it/s]
Adding requests:  37%|      | 3011/8192 [00:09<00:12, 416.91it/s]
Adding requests:  37%|      | 3053/8192 [00:09<00:12, 417.79it/s]
Adding requests:  38%|      | 3095/8192 [00:10<00:12, 412.93it/s]
Adding requests:  38%|      | 3138/8192 [00:10<00:12, 415.16it/s]
Adding requests:  39%|      | 3180/8192 [00:10<00:12, 412.22it/s]
Adding requests:  39%|      | 3222/8192 [00:10<00:12, 409.52it/s]
Adding requests:  40%|      | 3267/8192 [00:10<00:11, 419.57it/s]
Adding requests:  40%|      | 3309/8192 [00:10<00:12, 396.95it/s]
Adding requests:  41%|      | 3351/8192 [00:10<00:12, 402.83it/s]
Adding requests:  41%|     | 3392/8192 [00:10<00:12, 372.94it/s]
Adding requests:  42%|     | 3436/8192 [00:10<00:12, 389.90it/s]
Adding requests:  42%|     | 3480/8192 [00:11<00:11, 403.76it/s]
Adding requests:  43%|     | 3521/8192 [00:11<00:11, 395.04it/s]
Adding requests:  44%|     | 3568/8192 [00:11<00:11, 414.45it/s]
Adding requests:  44%|     | 3610/8192 [00:11<00:11, 400.21it/s]
Adding requests:  45%|     | 3654/8192 [00:11<00:11, 409.07it/s]
Adding requests:  45%|     | 3696/8192 [00:11<00:11, 399.80it/s]
Adding requests:  46%|     | 3740/8192 [00:11<00:10, 409.60it/s]
Adding requests:  46%|     | 3782/8192 [00:11<00:11, 399.36it/s]
Adding requests:  47%|     | 3823/8192 [00:11<00:11, 388.50it/s]
Adding requests:  47%|     | 3866/8192 [00:12<00:10, 400.20it/s]
Adding requests:  48%|     | 3907/8192 [00:12<00:11, 388.76it/s]
Adding requests:  48%|     | 3947/8192 [00:12<00:10, 387.08it/s]
Adding requests:  49%|     | 3986/8192 [00:12<00:11, 378.27it/s]
Adding requests:  49%|     | 4033/8192 [00:12<00:10, 402.59it/s]
Adding requests:  50%|     | 4074/8192 [00:12<00:10, 394.08it/s]
Adding requests:  50%|     | 4116/8192 [00:12<00:10, 399.16it/s]
Adding requests:  51%|     | 4157/8192 [00:12<00:10, 401.43it/s]
Adding requests:  51%|    | 4201/8192 [00:12<00:09, 409.68it/s]
Adding requests:  52%|    | 4243/8192 [00:12<00:09, 410.42it/s]
Adding requests:  52%|    | 4285/8192 [00:13<00:09, 401.28it/s]
Adding requests:  53%|    | 4328/8192 [00:13<00:09, 407.52it/s]
Adding requests:  53%|    | 4369/8192 [00:13<00:09, 405.58it/s]
Adding requests:  54%|    | 4410/8192 [00:13<00:09, 406.78it/s]
Adding requests:  54%|    | 4451/8192 [00:13<00:09, 401.93it/s]
Adding requests:  55%|    | 4498/8192 [00:13<00:08, 419.11it/s]
Adding requests:  55%|    | 4540/8192 [00:13<00:08, 407.15it/s]
Adding requests:  56%|    | 4581/8192 [00:13<00:09, 400.36it/s]
Adding requests:  56%|    | 4624/8192 [00:13<00:08, 407.51it/s]
Adding requests:  57%|    | 4667/8192 [00:13<00:08, 412.72it/s]
Adding requests:  57%|    | 4710/8192 [00:14<00:08, 414.94it/s]
Adding requests:  58%|    | 4752/8192 [00:14<00:08, 383.64it/s]
Adding requests:  59%|    | 4800/8192 [00:14<00:08, 409.74it/s]
Adding requests:  59%|    | 4842/8192 [00:14<00:08, 403.67it/s]
Adding requests:  60%|    | 4885/8192 [00:14<00:08, 410.41it/s]
Adding requests:  60%|    | 4927/8192 [00:14<00:07, 411.30it/s]
Adding requests:  61%|    | 4974/8192 [00:14<00:07, 427.47it/s]
Adding requests:  61%|    | 5017/8192 [00:14<00:07, 426.89it/s]
Adding requests:  62%|   | 5061/8192 [00:14<00:07, 427.73it/s]
Adding requests:  62%|   | 5105/8192 [00:15<00:07, 431.20it/s]
Adding requests:  63%|   | 5150/8192 [00:15<00:06, 436.64it/s]
Adding requests:  63%|   | 5194/8192 [00:15<00:07, 428.02it/s]
Adding requests:  64%|   | 5237/8192 [00:15<00:07, 401.98it/s]
Adding requests:  65%|   | 5284/8192 [00:15<00:06, 419.30it/s]
Adding requests:  65%|   | 5327/8192 [00:15<00:07, 406.01it/s]
Adding requests:  66%|   | 5368/8192 [00:15<00:07, 401.70it/s]
Adding requests:  66%|   | 5409/8192 [00:15<00:06, 397.88it/s]
Adding requests:  67%|   | 5450/8192 [00:15<00:06, 398.30it/s]
Adding requests:  67%|   | 5490/8192 [00:15<00:06, 398.28it/s]
Adding requests:  68%|   | 5530/8192 [00:16<00:06, 395.67it/s]
Adding requests:  68%|   | 5570/8192 [00:16<00:06, 395.81it/s]
Adding requests:  68%|   | 5611/8192 [00:16<00:06, 399.64it/s]
Adding requests:  69%|   | 5652/8192 [00:16<00:06, 398.97it/s]
Adding requests:  69%|   | 5692/8192 [00:16<00:06, 392.53it/s]
Adding requests:  70%|   | 5741/8192 [00:16<00:05, 418.75it/s]
Adding requests:  71%|   | 5783/8192 [00:16<00:05, 405.09it/s]
Adding requests:  71%|   | 5825/8192 [00:16<00:05, 409.28it/s]
Adding requests:  72%|  | 5867/8192 [00:16<00:05, 408.44it/s]
Adding requests:  72%|  | 5911/8192 [00:17<00:05, 415.64it/s]
Adding requests:  73%|  | 5953/8192 [00:17<00:05, 414.73it/s]
Adding requests:  73%|  | 5995/8192 [00:17<00:05, 414.72it/s]
Adding requests:  74%|  | 6038/8192 [00:17<00:05, 418.67it/s]
Adding requests:  74%|  | 6081/8192 [00:17<00:05, 419.46it/s]
Adding requests:  75%|  | 6123/8192 [00:17<00:05, 390.63it/s]
Adding requests:  75%|  | 6164/8192 [00:17<00:05, 393.39it/s]
Adding requests:  76%|  | 6209/8192 [00:17<00:04, 407.82it/s]
Adding requests:  76%|  | 6251/8192 [00:17<00:04, 399.10it/s]
Adding requests:  77%|  | 6292/8192 [00:17<00:04, 400.43it/s]
Adding requests:  77%|  | 6335/8192 [00:18<00:04, 408.93it/s]
Adding requests:  78%|  | 6381/8192 [00:18<00:04, 423.09it/s]
Adding requests:  78%|  | 6424/8192 [00:18<00:04, 402.20it/s]
Adding requests:  79%|  | 6465/8192 [00:18<00:04, 388.33it/s]
Adding requests:  79%|  | 6507/8192 [00:18<00:04, 395.80it/s]
Adding requests:  80%|  | 6547/8192 [00:18<00:04, 393.28it/s]
Adding requests:  80%|  | 6587/8192 [00:18<00:04, 392.55it/s]
Adding requests:  81%|  | 6627/8192 [00:18<00:03, 392.38it/s]
Adding requests:  81%| | 6672/8192 [00:18<00:03, 408.49it/s]
Adding requests:  82%| | 6713/8192 [00:19<00:03, 390.32it/s]
Adding requests:  82%| | 6754/8192 [00:19<00:03, 394.61it/s]
Adding requests:  83%| | 6794/8192 [00:19<00:03, 390.02it/s]
Adding requests:  83%| | 6836/8192 [00:19<00:03, 397.00it/s]
Adding requests:  84%| | 6879/8192 [00:19<00:03, 405.58it/s]
Adding requests:  84%| | 6920/8192 [00:19<00:03, 403.91it/s]
Adding requests:  85%| | 6963/8192 [00:19<00:02, 410.02it/s]
Adding requests:  86%| | 7010/8192 [00:19<00:02, 424.29it/s]
Adding requests:  86%| | 7053/8192 [00:19<00:02, 415.35it/s]
Adding requests:  87%| | 7095/8192 [00:19<00:02, 407.26it/s]
Adding requests:  87%| | 7137/8192 [00:20<00:02, 410.17it/s]
Adding requests:  88%| | 7179/8192 [00:20<00:02, 396.95it/s]
Adding requests:  88%| | 7219/8192 [00:20<00:02, 397.30it/s]
Adding requests:  89%| | 7259/8192 [00:20<00:02, 389.70it/s]
Adding requests:  89%| | 7303/8192 [00:20<00:02, 403.77it/s]
Adding requests:  90%| | 7344/8192 [00:20<00:02, 396.78it/s]
Adding requests:  90%| | 7384/8192 [00:20<00:02, 387.83it/s]
Adding requests:  91%| | 7424/8192 [00:20<00:01, 389.58it/s]
Adding requests:  91%| | 7465/8192 [00:20<00:01, 390.16it/s]
Adding requests:  92%|| 7505/8192 [00:21<00:01, 365.51it/s]
Adding requests:  92%|| 7542/8192 [00:21<00:01, 358.94it/s]
Adding requests:  93%|| 7586/8192 [00:21<00:01, 379.94it/s]
Adding requests:  93%|| 7625/8192 [00:21<00:01, 370.93it/s]
Adding requests:  94%|| 7665/8192 [00:21<00:01, 378.15it/s]
Adding requests:  94%|| 7709/8192 [00:21<00:01, 394.68it/s]
Adding requests:  95%|| 7749/8192 [00:21<00:01, 388.36it/s]
Adding requests:  95%|| 7790/8192 [00:21<00:01, 393.58it/s]
Adding requests:  96%|| 7830/8192 [00:21<00:00, 392.56it/s]
Adding requests:  96%|| 7870/8192 [00:21<00:00, 394.71it/s]
Adding requests:  97%|| 7910/8192 [00:22<00:00, 379.68it/s]
Adding requests:  97%|| 7953/8192 [00:22<00:00, 393.36it/s]
Adding requests:  98%|| 7993/8192 [00:22<00:00, 394.51it/s]
Adding requests:  98%|| 8038/8192 [00:22<00:00, 410.50it/s]
Adding requests:  99%|| 8080/8192 [00:22<00:00, 408.15it/s]
Adding requests:  99%|| 8121/8192 [00:22<00:00, 396.37it/s]
Adding requests: 100%|| 8163/8192 [00:22<00:00, 403.04it/s]
Adding requests: 100%|| 8192/8192 [00:22<00:00, 359.71it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 21/8192 [00:02<15:43,  8.66it/s, est. speed input: 8868.61 toks/s, output: 8.66 toks/s]
Processed prompts:   1%|          | 85/8192 [00:20<34:31,  3.91it/s, est. speed input: 4176.74 toks/s, output: 4.08 toks/s]
Processed prompts:   2%|         | 149/8192 [00:39<36:24,  3.68it/s, est. speed input: 3902.20 toks/s, output: 3.81 toks/s]
Processed prompts:   3%|         | 213/8192 [00:57<36:58,  3.60it/s, est. speed input: 3797.57 toks/s, output: 3.71 toks/s]
Processed prompts:   3%|         | 277/8192 [01:15<36:55,  3.57it/s, est. speed input: 3754.55 toks/s, output: 3.67 toks/s]
Processed prompts:   4%|         | 341/8192 [01:33<36:54,  3.54it/s, est. speed input: 3720.49 toks/s, output: 3.63 toks/s]
Processed prompts:   5%|         | 405/8192 [01:51<36:39,  3.54it/s, est. speed input: 3703.54 toks/s, output: 3.62 toks/s]
Processed prompts:   6%|         | 469/8192 [02:10<36:37,  3.51it/s, est. speed input: 3680.84 toks/s, output: 3.59 toks/s]
Processed prompts:   7%|         | 533/8192 [02:28<36:28,  3.50it/s, est. speed input: 3665.24 toks/s, output: 3.58 toks/s]
Processed prompts:   7%|         | 597/8192 [02:46<35:49,  3.53it/s, est. speed input: 3668.60 toks/s, output: 3.58 toks/s]
Processed prompts:   8%|         | 661/8192 [03:05<36:01,  3.48it/s, est. speed input: 3646.90 toks/s, output: 3.56 toks/s]
Processed prompts:   9%|         | 725/8192 [03:23<35:36,  3.49it/s, est. speed input: 3643.22 toks/s, output: 3.56 toks/s]
Processed prompts:  10%|         | 789/8192 [03:42<35:19,  3.49it/s, est. speed input: 3637.33 toks/s, output: 3.55 toks/s]
Processed prompts:  10%|         | 853/8192 [04:00<35:01,  3.49it/s, est. speed input: 3632.66 toks/s, output: 3.55 toks/s]
Processed prompts:  11%|         | 917/8192 [04:18<34:44,  3.49it/s, est. speed input: 3628.15 toks/s, output: 3.54 toks/s]
Processed prompts:  12%|        | 981/8192 [04:37<34:27,  3.49it/s, est. speed input: 3624.06 toks/s, output: 3.54 toks/s]
Processed prompts:  13%|        | 1045/8192 [04:55<34:10,  3.49it/s, est. speed input: 3620.26 toks/s, output: 3.54 toks/s]
Processed prompts:  14%|        | 1109/8192 [05:14<33:59,  3.47it/s, est. speed input: 3614.56 toks/s, output: 3.53 toks/s]
Processed prompts:  14%|        | 1173/8192 [05:32<33:36,  3.48it/s, est. speed input: 3613.10 toks/s, output: 3.53 toks/s]
Processed prompts:  15%|        | 1237/8192 [05:50<33:16,  3.48it/s, est. speed input: 3610.80 toks/s, output: 3.53 toks/s]
Processed prompts:  16%|        | 1301/8192 [06:09<32:59,  3.48it/s, est. speed input: 3608.27 toks/s, output: 3.52 toks/s]
Processed prompts:  17%|        | 1365/8192 [06:27<32:45,  3.47it/s, est. speed input: 3604.95 toks/s, output: 3.52 toks/s]
Processed prompts:  17%|        | 1429/8192 [06:46<32:27,  3.47it/s, est. speed input: 3602.77 toks/s, output: 3.52 toks/s]
Processed prompts:  18%|        | 1493/8192 [07:04<32:08,  3.47it/s, est. speed input: 3600.89 toks/s, output: 3.52 toks/s]
Processed prompts:  19%|        | 1557/8192 [07:22<31:44,  3.48it/s, est. speed input: 3600.59 toks/s, output: 3.52 toks/s]
Processed prompts:  20%|        | 1621/8192 [07:41<31:21,  3.49it/s, est. speed input: 3600.29 toks/s, output: 3.52 toks/s]
Processed prompts:  21%|        | 1685/8192 [07:59<31:07,  3.49it/s, est. speed input: 3598.45 toks/s, output: 3.51 toks/s]
Processed prompts:  21%|       | 1749/8192 [08:17<30:51,  3.48it/s, est. speed input: 3596.71 toks/s, output: 3.51 toks/s]
Processed prompts:  22%|       | 1813/8192 [08:36<30:36,  3.47it/s, est. speed input: 3594.81 toks/s, output: 3.51 toks/s]
Processed prompts:  23%|       | 1877/8192 [08:54<30:19,  3.47it/s, est. speed input: 3593.11 toks/s, output: 3.51 toks/s]
Processed prompts:  24%|       | 1941/8192 [09:13<30:02,  3.47it/s, est. speed input: 3591.54 toks/s, output: 3.51 toks/s]
Processed prompts:  24%|       | 2005/8192 [09:31<29:42,  3.47it/s, est. speed input: 3590.45 toks/s, output: 3.51 toks/s]
Processed prompts:  25%|       | 2069/8192 [09:50<29:21,  3.48it/s, est. speed input: 3589.83 toks/s, output: 3.51 toks/s]
Processed prompts:  26%|       | 2133/8192 [10:08<28:59,  3.48it/s, est. speed input: 3589.66 toks/s, output: 3.51 toks/s]
Processed prompts:  27%|       | 2197/8192 [10:26<28:44,  3.48it/s, est. speed input: 3588.29 toks/s, output: 3.50 toks/s]
Processed prompts:  28%|       | 2261/8192 [10:45<28:29,  3.47it/s, est. speed input: 3586.79 toks/s, output: 3.50 toks/s]
Processed prompts:  28%|       | 2325/8192 [11:04<28:12,  3.47it/s, est. speed input: 3585.53 toks/s, output: 3.50 toks/s]
Processed prompts:  29%|       | 2389/8192 [11:22<27:48,  3.48it/s, est. speed input: 3585.60 toks/s, output: 3.50 toks/s]
Processed prompts:  30%|       | 2453/8192 [11:40<27:31,  3.48it/s, est. speed input: 3584.76 toks/s, output: 3.50 toks/s]
Processed prompts:  31%|       | 2517/8192 [11:59<27:20,  3.46it/s, est. speed input: 3582.69 toks/s, output: 3.50 toks/s]
Processed prompts:  32%|      | 2581/8192 [12:17<26:57,  3.47it/s, est. speed input: 3582.58 toks/s, output: 3.50 toks/s]
Processed prompts:  32%|      | 2645/8192 [12:36<26:39,  3.47it/s, est. speed input: 3581.72 toks/s, output: 3.50 toks/s]
Processed prompts:  33%|      | 2709/8192 [12:54<26:16,  3.48it/s, est. speed input: 3581.80 toks/s, output: 3.50 toks/s]
Processed prompts:  34%|      | 2773/8192 [13:12<26:00,  3.47it/s, est. speed input: 3580.95 toks/s, output: 3.50 toks/s]
Processed prompts:  35%|      | 2837/8192 [13:31<25:43,  3.47it/s, est. speed input: 3580.16 toks/s, output: 3.50 toks/s]
Processed prompts:  35%|      | 2901/8192 [13:49<25:12,  3.50it/s, est. speed input: 3581.66 toks/s, output: 3.50 toks/s]
Processed prompts:  36%|      | 2965/8192 [14:07<24:59,  3.49it/s, est. speed input: 3580.82 toks/s, output: 3.50 toks/s]
Processed prompts:  37%|      | 3029/8192 [14:26<24:44,  3.48it/s, est. speed input: 3580.05 toks/s, output: 3.50 toks/s]
Processed prompts:  38%|      | 3093/8192 [14:44<24:28,  3.47it/s, est. speed input: 3579.19 toks/s, output: 3.50 toks/s]
Processed prompts:  39%|      | 3157/8192 [15:03<24:12,  3.47it/s, est. speed input: 3578.38 toks/s, output: 3.49 toks/s]
Processed prompts:  39%|      | 3221/8192 [15:21<23:54,  3.46it/s, est. speed input: 3577.64 toks/s, output: 3.49 toks/s]
Processed prompts:  40%|      | 3285/8192 [15:39<23:25,  3.49it/s, est. speed input: 3578.78 toks/s, output: 3.49 toks/s]
Processed prompts:  41%|      | 3349/8192 [15:58<23:10,  3.48it/s, est. speed input: 3578.13 toks/s, output: 3.49 toks/s]
Processed prompts:  42%|     | 3413/8192 [16:16<22:50,  3.49it/s, est. speed input: 3578.22 toks/s, output: 3.49 toks/s]
Processed prompts:  42%|     | 3477/8192 [16:35<22:33,  3.48it/s, est. speed input: 3577.85 toks/s, output: 3.49 toks/s]
Processed prompts:  43%|     | 3541/8192 [16:53<22:22,  3.46it/s, est. speed input: 3576.49 toks/s, output: 3.49 toks/s]
Processed prompts:  44%|     | 3605/8192 [17:12<22:05,  3.46it/s, est. speed input: 3575.73 toks/s, output: 3.49 toks/s]
Processed prompts:  45%|     | 3669/8192 [17:30<21:42,  3.47it/s, est. speed input: 3575.86 toks/s, output: 3.49 toks/s]
Processed prompts:  46%|     | 3733/8192 [17:49<21:24,  3.47it/s, est. speed input: 3575.40 toks/s, output: 3.49 toks/s]
Processed prompts:  46%|     | 3797/8192 [18:07<21:05,  3.47it/s, est. speed input: 3575.15 toks/s, output: 3.49 toks/s]
Processed prompts:  47%|     | 3861/8192 [18:26<20:48,  3.47it/s, est. speed input: 3574.63 toks/s, output: 3.49 toks/s]
Processed prompts:  48%|     | 3925/8192 [18:44<20:26,  3.48it/s, est. speed input: 3574.81 toks/s, output: 3.49 toks/s]
Processed prompts:  49%|     | 3989/8192 [19:02<20:10,  3.47it/s, est. speed input: 3574.31 toks/s, output: 3.49 toks/s]
Processed prompts:  49%|     | 4053/8192 [19:21<19:48,  3.48it/s, est. speed input: 3574.50 toks/s, output: 3.49 toks/s]
Processed prompts:  50%|     | 4117/8192 [19:39<19:32,  3.48it/s, est. speed input: 3574.03 toks/s, output: 3.49 toks/s]
Processed prompts:  51%|     | 4181/8192 [19:58<19:15,  3.47it/s, est. speed input: 3573.56 toks/s, output: 3.49 toks/s]
Processed prompts:  52%|    | 4245/8192 [20:16<19:03,  3.45it/s, est. speed input: 3572.23 toks/s, output: 3.49 toks/s]
Processed prompts:  53%|    | 4309/8192 [20:35<18:45,  3.45it/s, est. speed input: 3571.63 toks/s, output: 3.49 toks/s]
Processed prompts:  53%|    | 4373/8192 [20:54<18:29,  3.44it/s, est. speed input: 3570.62 toks/s, output: 3.49 toks/s]
Processed prompts:  54%|    | 4437/8192 [21:12<18:05,  3.46it/s, est. speed input: 3570.79 toks/s, output: 3.49 toks/s]
Processed prompts:  55%|    | 4501/8192 [21:30<17:42,  3.47it/s, est. speed input: 3571.14 toks/s, output: 3.49 toks/s]
Processed prompts:  56%|    | 4565/8192 [21:49<17:26,  3.47it/s, est. speed input: 3570.62 toks/s, output: 3.49 toks/s]
Processed prompts:  57%|    | 4629/8192 [22:07<17:09,  3.46it/s, est. speed input: 3570.05 toks/s, output: 3.49 toks/s]
Processed prompts:  57%|    | 4693/8192 [22:26<16:50,  3.46it/s, est. speed input: 3569.70 toks/s, output: 3.49 toks/s]
Processed prompts:  58%|    | 4757/8192 [22:44<16:32,  3.46it/s, est. speed input: 3569.38 toks/s, output: 3.49 toks/s]
Processed prompts:  59%|    | 4821/8192 [23:03<16:13,  3.46it/s, est. speed input: 3569.02 toks/s, output: 3.49 toks/s]
Processed prompts:  60%|    | 4885/8192 [23:21<15:55,  3.46it/s, est. speed input: 3568.67 toks/s, output: 3.49 toks/s]
Processed prompts:  60%|    | 4949/8192 [23:40<15:34,  3.47it/s, est. speed input: 3568.76 toks/s, output: 3.49 toks/s]
Processed prompts:  61%|    | 5013/8192 [23:58<15:17,  3.47it/s, est. speed input: 3568.37 toks/s, output: 3.48 toks/s]
Processed prompts:  62%|   | 5077/8192 [24:17<14:59,  3.46it/s, est. speed input: 3568.00 toks/s, output: 3.48 toks/s]
Processed prompts:  63%|   | 5141/8192 [24:35<14:40,  3.47it/s, est. speed input: 3567.87 toks/s, output: 3.48 toks/s]
Processed prompts:  64%|   | 5205/8192 [24:53<14:17,  3.48it/s, est. speed input: 3568.31 toks/s, output: 3.48 toks/s]
Processed prompts:  64%|   | 5269/8192 [25:12<13:58,  3.48it/s, est. speed input: 3568.36 toks/s, output: 3.48 toks/s]
Processed prompts:  65%|   | 5333/8192 [25:30<13:42,  3.47it/s, est. speed input: 3567.95 toks/s, output: 3.48 toks/s]
Processed prompts:  66%|   | 5397/8192 [25:49<13:25,  3.47it/s, est. speed input: 3567.60 toks/s, output: 3.48 toks/s]
Processed prompts:  67%|   | 5461/8192 [26:07<13:05,  3.48it/s, est. speed input: 3567.75 toks/s, output: 3.48 toks/s]
Processed prompts:  67%|   | 5525/8192 [26:25<12:45,  3.48it/s, est. speed input: 3567.94 toks/s, output: 3.48 toks/s]
Processed prompts:  68%|   | 5589/8192 [26:44<12:28,  3.48it/s, est. speed input: 3567.66 toks/s, output: 3.48 toks/s]
Processed prompts:  69%|   | 5653/8192 [27:02<12:11,  3.47it/s, est. speed input: 3567.42 toks/s, output: 3.48 toks/s]
Processed prompts:  70%|   | 5717/8192 [27:21<11:52,  3.47it/s, est. speed input: 3567.25 toks/s, output: 3.48 toks/s]
Processed prompts:  71%|   | 5781/8192 [27:39<11:34,  3.47it/s, est. speed input: 3567.04 toks/s, output: 3.48 toks/s]
Processed prompts:  71%|  | 5845/8192 [27:58<11:16,  3.47it/s, est. speed input: 3566.78 toks/s, output: 3.48 toks/s]
Processed prompts:  72%|  | 5909/8192 [28:16<10:56,  3.48it/s, est. speed input: 3566.99 toks/s, output: 3.48 toks/s]
Processed prompts:  73%|  | 5973/8192 [28:34<10:36,  3.49it/s, est. speed input: 3567.22 toks/s, output: 3.48 toks/s]
Processed prompts:  74%|  | 6037/8192 [28:52<10:14,  3.51it/s, est. speed input: 3567.97 toks/s, output: 3.48 toks/s]
Processed prompts:  74%|  | 6101/8192 [29:11<09:57,  3.50it/s, est. speed input: 3567.87 toks/s, output: 3.48 toks/s]
Processed prompts:  75%|  | 6165/8192 [29:29<09:39,  3.50it/s, est. speed input: 3568.15 toks/s, output: 3.48 toks/s]
Processed prompts:  76%|  | 6229/8192 [29:47<09:22,  3.49it/s, est. speed input: 3567.95 toks/s, output: 3.48 toks/s]
Processed prompts:  77%|  | 6293/8192 [30:06<09:05,  3.48it/s, est. speed input: 3567.79 toks/s, output: 3.48 toks/s]
Processed prompts:  78%|  | 6357/8192 [30:24<08:47,  3.48it/s, est. speed input: 3567.63 toks/s, output: 3.48 toks/s]
Processed prompts:  78%|  | 6421/8192 [30:43<08:29,  3.47it/s, est. speed input: 3567.41 toks/s, output: 3.48 toks/s]
Processed prompts:  79%|  | 6485/8192 [31:01<08:11,  3.47it/s, est. speed input: 3567.24 toks/s, output: 3.48 toks/s]
Processed prompts:  80%|  | 6549/8192 [31:20<07:53,  3.47it/s, est. speed input: 3567.08 toks/s, output: 3.48 toks/s]
Processed prompts:  81%|  | 6613/8192 [31:38<07:35,  3.47it/s, est. speed input: 3566.90 toks/s, output: 3.48 toks/s]
Processed prompts:  82%| | 6677/8192 [31:56<07:16,  3.47it/s, est. speed input: 3566.71 toks/s, output: 3.48 toks/s]
Processed prompts:  82%| | 6741/8192 [32:15<06:58,  3.47it/s, est. speed input: 3566.55 toks/s, output: 3.48 toks/s]
Processed prompts:  83%| | 6805/8192 [32:33<06:40,  3.47it/s, est. speed input: 3566.39 toks/s, output: 3.48 toks/s]
Processed prompts:  84%| | 6869/8192 [32:52<06:21,  3.47it/s, est. speed input: 3566.25 toks/s, output: 3.48 toks/s]
Processed prompts:  85%| | 6933/8192 [33:10<06:03,  3.47it/s, est. speed input: 3566.11 toks/s, output: 3.48 toks/s]
Processed prompts:  85%| | 6997/8192 [33:29<05:44,  3.47it/s, est. speed input: 3565.98 toks/s, output: 3.48 toks/s]
Processed prompts:  86%| | 7061/8192 [33:47<05:26,  3.47it/s, est. speed input: 3565.85 toks/s, output: 3.48 toks/s]
Processed prompts:  87%| | 7125/8192 [34:06<05:07,  3.47it/s, est. speed input: 3565.73 toks/s, output: 3.48 toks/s]
Processed prompts:  88%| | 7189/8192 [34:24<04:49,  3.47it/s, est. speed input: 3565.63 toks/s, output: 3.48 toks/s]
Processed prompts:  89%| | 7253/8192 [34:43<04:30,  3.47it/s, est. speed input: 3565.53 toks/s, output: 3.48 toks/s]
Processed prompts:  89%| | 7317/8192 [35:01<04:12,  3.47it/s, est. speed input: 3565.43 toks/s, output: 3.48 toks/s]
Processed prompts:  90%| | 7381/8192 [35:19<03:53,  3.47it/s, est. speed input: 3565.33 toks/s, output: 3.48 toks/s]
Processed prompts:  91%| | 7445/8192 [35:38<03:35,  3.47it/s, est. speed input: 3565.21 toks/s, output: 3.48 toks/s]
Processed prompts:  92%|| 7509/8192 [35:56<03:16,  3.47it/s, est. speed input: 3565.14 toks/s, output: 3.48 toks/s]
Processed prompts:  92%|| 7573/8192 [36:15<02:58,  3.47it/s, est. speed input: 3565.02 toks/s, output: 3.48 toks/s]
Processed prompts:  93%|| 7637/8192 [36:33<02:39,  3.47it/s, est. speed input: 3564.90 toks/s, output: 3.48 toks/s]
Processed prompts:  94%|| 7701/8192 [36:52<02:21,  3.47it/s, est. speed input: 3564.80 toks/s, output: 3.48 toks/s]
Processed prompts:  95%|| 7765/8192 [37:10<02:03,  3.47it/s, est. speed input: 3564.71 toks/s, output: 3.48 toks/s]
Processed prompts:  96%|| 7829/8192 [37:29<01:44,  3.47it/s, est. speed input: 3564.59 toks/s, output: 3.48 toks/s]
Processed prompts:  96%|| 7893/8192 [37:47<01:26,  3.47it/s, est. speed input: 3564.48 toks/s, output: 3.48 toks/s]
Processed prompts:  97%|| 7957/8192 [38:05<01:07,  3.47it/s, est. speed input: 3564.37 toks/s, output: 3.48 toks/s]
Processed prompts:  98%|| 8021/8192 [38:24<00:49,  3.47it/s, est. speed input: 3564.31 toks/s, output: 3.48 toks/s]
Processed prompts:  99%|| 8085/8192 [38:42<00:30,  3.47it/s, est. speed input: 3564.21 toks/s, output: 3.48 toks/s]
Processed prompts:  99%|| 8149/8192 [38:55<00:11,  3.82it/s, est. speed input: 3572.84 toks/s, output: 3.49 toks/s]
Processed prompts: 100%|| 8192/8192 [38:55<00:00,  3.82it/s, est. speed input: 3591.69 toks/s, output: 3.51 toks/s]
Processed prompts: 100%|| 8192/8192 [38:55<00:00,  3.51it/s, est. speed input: 3591.69 toks/s, output: 3.51 toks/s]
[rank0]:[W127 02:27:50.973895950 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-28 07:57:35
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/BitNet-2B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 07:57:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 07:57:38 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3662922) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3662922) WARNING 01-28 07:58:06 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 20.99 requests/s, 10766.71 total tokens/s, 20.99 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-28 07:57:38] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 07:57:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 07:57:38] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 07:57:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:57:38] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:57:38] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:57:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:57:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:57:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 07:57:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 07:57:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 07:57:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 07:57:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 07:57:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 07:57:42] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 07:57:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 07:57:42] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 07:57:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:57:42] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:57:42] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:57:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:57:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:57:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 07:57:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 07:57:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 07:57:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 07:57:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 07:57:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3662922) [2026-01-28 07:57:43] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3662922) [2026-01-28 07:57:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3662922) [2026-01-28 07:57:43] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3662922) [2026-01-28 07:57:43] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3662922) [2026-01-28 07:57:43] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3662922) [2026-01-28 07:57:43] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3662922) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3662922) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.10s/it]
(EngineCore_DP0 pid=3662922) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.10s/it]
(EngineCore_DP0 pid=3662922) 
(EngineCore_DP0 pid=3662922) [2026-01-28 07:57:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3662922) [2026-01-28 07:57:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9891840 bytes
(EngineCore_DP0 pid=3662922) [2026-01-28 07:57:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3662922) [2026-01-28 07:57:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6594560 bytes
(EngineCore_DP0 pid=3662922) [2026-01-28 07:57:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3662922) [2026-01-28 07:57:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 35610624 bytes
(EngineCore_DP0 pid=3662922) [2026-01-28 07:57:59] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3662922) [2026-01-28 07:57:59] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=3662922) 2026-01-28 07:58:05,398 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3662922) 2026-01-28 07:58:05,422 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:   1%|          | 1/128 [00:00<01:49,  1.16it/s]
Adding requests:   2%|         | 2/128 [00:01<01:03,  2.00it/s]
Adding requests:   2%|         | 3/128 [00:01<00:43,  2.85it/s]
Adding requests:   3%|         | 4/128 [00:01<00:31,  3.90it/s]
Adding requests:   5%|         | 6/128 [00:01<00:20,  5.96it/s]
Adding requests:   6%|         | 8/128 [00:01<00:14,  8.10it/s]
Adding requests:   8%|         | 10/128 [00:01<00:11, 10.31it/s]
Adding requests:  10%|         | 13/128 [00:01<00:07, 14.45it/s]
Adding requests:  13%|        | 17/128 [00:02<00:05, 19.38it/s]
Adding requests:  16%|        | 21/128 [00:02<00:04, 23.79it/s]
Adding requests:  20%|        | 26/128 [00:02<00:03, 30.02it/s]
Adding requests:  27%|       | 34/128 [00:02<00:02, 43.11it/s]
Adding requests:  38%|      | 48/128 [00:02<00:01, 68.47it/s]
Adding requests:  52%|    | 66/128 [00:02<00:00, 98.38it/s]
Adding requests:  84%| | 107/128 [00:02<00:00, 185.81it/s]
Adding requests: 100%|| 128/128 [00:02<00:00, 47.35it/s] 

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  29%|       | 37/128 [00:00<00:00, 368.61it/s, est. speed input: 188784.84 toks/s, output: 368.64 toks/s]
Processed prompts:  58%|    | 74/128 [00:01<00:01, 46.05it/s, est. speed input: 27138.60 toks/s, output: 53.00 toks/s]   
Processed prompts:  71%|   | 91/128 [00:01<00:00, 39.26it/s, est. speed input: 23361.15 toks/s, output: 45.63 toks/s]
Processed prompts:  80%|  | 102/128 [00:02<00:00, 36.58it/s, est. speed input: 21991.66 toks/s, output: 42.95 toks/s]
Processed prompts:  86%| | 110/128 [00:02<00:00, 34.81it/s, est. speed input: 21197.83 toks/s, output: 41.40 toks/s]
Processed prompts:  91%| | 116/128 [00:02<00:00, 33.70it/s, est. speed input: 20728.46 toks/s, output: 40.49 toks/s]
Processed prompts:  95%|| 121/128 [00:03<00:00, 32.83it/s, est. speed input: 20389.10 toks/s, output: 39.82 toks/s]
Processed prompts:  98%|| 126/128 [00:03<00:00, 31.92it/s, est. speed input: 20070.60 toks/s, output: 39.20 toks/s]
Processed prompts: 100%|| 128/128 [00:03<00:00, 31.92it/s, est. speed input: 19940.58 toks/s, output: 38.95 toks/s]
Processed prompts: 100%|| 128/128 [00:03<00:00, 38.94it/s, est. speed input: 19940.58 toks/s, output: 38.95 toks/s]
[rank0]:[W128 07:58:12.643126840 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-28 07:58:25
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/BitNet-2B-INT8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 07:58:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 07:58:29 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3663889) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3663889) WARNING 01-28 07:58:55 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 15.22 requests/s, 15605.06 total tokens/s, 15.22 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-28 07:58:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 07:58:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 07:58:29] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 07:58:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:58:29] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:58:29] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:58:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:58:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:58:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 07:58:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 07:58:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 07:58:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 07:58:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 07:58:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 07:58:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 07:58:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 07:58:33] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 07:58:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:58:33] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:58:33] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:58:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:58:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:58:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 07:58:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 07:58:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 07:58:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 07:58:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 07:58:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3663889) [2026-01-28 07:58:33] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3663889) [2026-01-28 07:58:33] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3663889) [2026-01-28 07:58:33] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3663889) [2026-01-28 07:58:33] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3663889) [2026-01-28 07:58:33] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3663889) [2026-01-28 07:58:33] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3663889) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3663889) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.55s/it]
(EngineCore_DP0 pid=3663889) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.55s/it]
(EngineCore_DP0 pid=3663889) 
(EngineCore_DP0 pid=3663889) [2026-01-28 07:58:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3663889) [2026-01-28 07:58:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9891840 bytes
(EngineCore_DP0 pid=3663889) [2026-01-28 07:58:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3663889) [2026-01-28 07:58:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6594560 bytes
(EngineCore_DP0 pid=3663889) [2026-01-28 07:58:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3663889) [2026-01-28 07:58:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 35610624 bytes
(EngineCore_DP0 pid=3663889) [2026-01-28 07:58:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3663889) [2026-01-28 07:58:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=3663889) 2026-01-28 07:58:55,012 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3663889) 2026-01-28 07:58:55,023 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  51%|     | 65/128 [00:00<00:00, 639.82it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 654.94it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:18,  7.01it/s, est. speed input: 7178.52 toks/s, output: 7.01 toks/s]
Processed prompts:   2%|         | 3/128 [00:00<00:10, 11.85it/s, est. speed input: 11348.36 toks/s, output: 11.08 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:09, 13.51it/s, est. speed input: 12827.81 toks/s, output: 12.53 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:08, 14.35it/s, est. speed input: 13607.79 toks/s, output: 13.29 toks/s]
Processed prompts:   7%|         | 9/128 [00:00<00:07, 14.95it/s, est. speed input: 14153.64 toks/s, output: 13.82 toks/s]
Processed prompts:   9%|         | 11/128 [00:00<00:07, 15.23it/s, est. speed input: 14478.88 toks/s, output: 14.14 toks/s]
Processed prompts:  10%|         | 13/128 [00:00<00:07, 15.48it/s, est. speed input: 14743.47 toks/s, output: 14.40 toks/s]
Processed prompts:  12%|        | 15/128 [00:01<00:07, 15.68it/s, est. speed input: 14954.52 toks/s, output: 14.60 toks/s]
Processed prompts:  13%|        | 17/128 [00:01<00:07, 15.42it/s, est. speed input: 14987.96 toks/s, output: 14.64 toks/s]
Processed prompts:  15%|        | 19/128 [00:01<00:07, 15.46it/s, est. speed input: 15080.06 toks/s, output: 14.73 toks/s]
Processed prompts:  16%|        | 21/128 [00:01<00:06, 15.53it/s, est. speed input: 15168.56 toks/s, output: 14.81 toks/s]
Processed prompts:  18%|        | 23/128 [00:01<00:06, 15.54it/s, est. speed input: 15233.13 toks/s, output: 14.88 toks/s]
Processed prompts:  20%|        | 25/128 [00:01<00:06, 15.65it/s, est. speed input: 15311.46 toks/s, output: 14.95 toks/s]
Processed prompts:  21%|        | 27/128 [00:01<00:06, 15.74it/s, est. speed input: 15382.44 toks/s, output: 15.02 toks/s]
Processed prompts:  23%|       | 29/128 [00:01<00:06, 15.84it/s, est. speed input: 15452.70 toks/s, output: 15.09 toks/s]
Processed prompts:  24%|       | 31/128 [00:02<00:06, 15.92it/s, est. speed input: 15516.08 toks/s, output: 15.15 toks/s]
Processed prompts:  26%|       | 33/128 [00:02<00:05, 15.94it/s, est. speed input: 15565.37 toks/s, output: 15.20 toks/s]
Processed prompts:  27%|       | 35/128 [00:02<00:05, 15.58it/s, est. speed input: 15541.45 toks/s, output: 15.18 toks/s]
Processed prompts:  29%|       | 37/128 [00:02<00:05, 15.59it/s, est. speed input: 15564.28 toks/s, output: 15.20 toks/s]
Processed prompts:  30%|       | 39/128 [00:02<00:05, 15.65it/s, est. speed input: 15595.33 toks/s, output: 15.23 toks/s]
Processed prompts:  32%|      | 41/128 [00:02<00:05, 15.74it/s, est. speed input: 15629.42 toks/s, output: 15.26 toks/s]
Processed prompts:  34%|      | 43/128 [00:02<00:05, 15.71it/s, est. speed input: 15647.55 toks/s, output: 15.28 toks/s]
Processed prompts:  35%|      | 45/128 [00:02<00:05, 15.81it/s, est. speed input: 15680.59 toks/s, output: 15.31 toks/s]
Processed prompts:  37%|      | 47/128 [00:03<00:05, 15.90it/s, est. speed input: 15713.30 toks/s, output: 15.34 toks/s]
Processed prompts:  38%|      | 49/128 [00:03<00:05, 15.79it/s, est. speed input: 15721.50 toks/s, output: 15.35 toks/s]
Processed prompts:  40%|      | 51/128 [00:03<00:04, 15.53it/s, est. speed input: 15704.72 toks/s, output: 15.34 toks/s]
Processed prompts:  41%|     | 53/128 [00:03<00:04, 15.54it/s, est. speed input: 15713.91 toks/s, output: 15.35 toks/s]
Processed prompts:  43%|     | 55/128 [00:03<00:04, 15.70it/s, est. speed input: 15739.84 toks/s, output: 15.37 toks/s]
Processed prompts:  45%|     | 57/128 [00:03<00:04, 15.78it/s, est. speed input: 15761.09 toks/s, output: 15.39 toks/s]
Processed prompts:  46%|     | 59/128 [00:03<00:04, 15.85it/s, est. speed input: 15781.49 toks/s, output: 15.41 toks/s]
Processed prompts:  48%|     | 61/128 [00:03<00:04, 15.93it/s, est. speed input: 15804.48 toks/s, output: 15.43 toks/s]
Processed prompts:  49%|     | 63/128 [00:04<00:04, 15.95it/s, est. speed input: 15821.90 toks/s, output: 15.45 toks/s]
Processed prompts:  51%|     | 65/128 [00:04<00:03, 15.94it/s, est. speed input: 15836.41 toks/s, output: 15.47 toks/s]
Processed prompts:  52%|    | 67/128 [00:04<00:03, 15.59it/s, est. speed input: 15815.97 toks/s, output: 15.45 toks/s]
Processed prompts:  54%|    | 69/128 [00:04<00:03, 15.59it/s, est. speed input: 15820.57 toks/s, output: 15.45 toks/s]
Processed prompts:  55%|    | 71/128 [00:04<00:03, 15.58it/s, est. speed input: 15823.91 toks/s, output: 15.45 toks/s]
Processed prompts:  57%|    | 73/128 [00:04<00:03, 15.69it/s, est. speed input: 15837.38 toks/s, output: 15.47 toks/s]
Processed prompts:  59%|    | 75/128 [00:04<00:03, 15.67it/s, est. speed input: 15841.90 toks/s, output: 15.47 toks/s]
Processed prompts:  60%|    | 77/128 [00:04<00:03, 15.79it/s, est. speed input: 15856.79 toks/s, output: 15.49 toks/s]
Processed prompts:  62%|   | 79/128 [00:05<00:03, 15.87it/s, est. speed input: 15871.25 toks/s, output: 15.50 toks/s]
Processed prompts:  63%|   | 81/128 [00:05<00:02, 15.91it/s, est. speed input: 15883.47 toks/s, output: 15.51 toks/s]
Processed prompts:  65%|   | 83/128 [00:05<00:02, 15.61it/s, est. speed input: 15869.27 toks/s, output: 15.50 toks/s]
Processed prompts:  66%|   | 85/128 [00:05<00:02, 15.58it/s, est. speed input: 15869.98 toks/s, output: 15.50 toks/s]
Processed prompts:  68%|   | 87/128 [00:05<00:02, 15.63it/s, est. speed input: 15875.81 toks/s, output: 15.50 toks/s]
Processed prompts:  70%|   | 89/128 [00:05<00:02, 15.65it/s, est. speed input: 15879.63 toks/s, output: 15.51 toks/s]
Processed prompts:  71%|   | 91/128 [00:05<00:02, 15.75it/s, est. speed input: 15890.66 toks/s, output: 15.52 toks/s]
Processed prompts:  73%|  | 93/128 [00:05<00:02, 15.84it/s, est. speed input: 15901.68 toks/s, output: 15.53 toks/s]
Processed prompts:  74%|  | 95/128 [00:06<00:02, 15.81it/s, est. speed input: 15906.65 toks/s, output: 15.53 toks/s]
Processed prompts:  76%|  | 97/128 [00:06<00:01, 15.73it/s, est. speed input: 15906.83 toks/s, output: 15.53 toks/s]
Processed prompts:  77%|  | 99/128 [00:06<00:01, 15.81it/s, est. speed input: 15916.06 toks/s, output: 15.54 toks/s]
Processed prompts:  79%|  | 101/128 [00:06<00:01, 15.51it/s, est. speed input: 15901.16 toks/s, output: 15.53 toks/s]
Processed prompts:  80%|  | 103/128 [00:06<00:01, 15.61it/s, est. speed input: 15907.52 toks/s, output: 15.53 toks/s]
Processed prompts:  82%| | 105/128 [00:06<00:01, 15.68it/s, est. speed input: 15913.41 toks/s, output: 15.54 toks/s]
Processed prompts:  84%| | 107/128 [00:06<00:01, 15.81it/s, est. speed input: 15923.91 toks/s, output: 15.55 toks/s]
Processed prompts:  85%| | 109/128 [00:07<00:01, 15.85it/s, est. speed input: 15931.19 toks/s, output: 15.56 toks/s]
Processed prompts:  87%| | 111/128 [00:07<00:01, 15.92it/s, est. speed input: 15940.92 toks/s, output: 15.57 toks/s]
Processed prompts:  88%| | 113/128 [00:07<00:00, 15.93it/s, est. speed input: 15947.51 toks/s, output: 15.57 toks/s]
Processed prompts:  90%| | 115/128 [00:07<00:00, 15.95it/s, est. speed input: 15954.79 toks/s, output: 15.58 toks/s]
Processed prompts:  91%|| 117/128 [00:07<00:00, 15.65it/s, est. speed input: 15944.06 toks/s, output: 15.57 toks/s]
Processed prompts:  93%|| 119/128 [00:07<00:00, 15.76it/s, est. speed input: 15951.93 toks/s, output: 15.58 toks/s]
Processed prompts:  95%|| 121/128 [00:07<00:00, 15.79it/s, est. speed input: 15956.24 toks/s, output: 15.58 toks/s]
Processed prompts:  96%|| 123/128 [00:07<00:00, 15.75it/s, est. speed input: 15957.68 toks/s, output: 15.58 toks/s]
Processed prompts:  98%|| 125/128 [00:08<00:00, 15.72it/s, est. speed input: 15958.57 toks/s, output: 15.58 toks/s]
Processed prompts:  99%|| 127/128 [00:08<00:00, 15.73it/s, est. speed input: 15961.37 toks/s, output: 15.59 toks/s]
Processed prompts: 100%|| 128/128 [00:08<00:00, 15.73it/s, est. speed input: 15963.76 toks/s, output: 15.59 toks/s]
Processed prompts: 100%|| 128/128 [00:08<00:00, 15.59it/s, est. speed input: 15963.76 toks/s, output: 15.59 toks/s]
[rank0]:[W128 07:59:04.222205499 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-28 07:59:06
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/BitNet-2B-INT8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 07:59:10 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 07:59:10 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3664655) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3664655) WARNING 01-28 07:59:36 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 15.89 requests/s, 16292.02 total tokens/s, 15.89 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-28 07:59:10] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 07:59:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 07:59:10] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 07:59:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:59:10] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:59:10] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:59:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:59:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:59:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 07:59:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 07:59:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 07:59:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 07:59:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 07:59:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 07:59:14] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 07:59:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 07:59:14] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 07:59:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:59:14] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:59:14] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:59:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:59:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 07:59:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 07:59:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 07:59:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 07:59:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 07:59:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 07:59:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3664655) [2026-01-28 07:59:15] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3664655) [2026-01-28 07:59:15] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3664655) [2026-01-28 07:59:15] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3664655) [2026-01-28 07:59:15] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3664655) [2026-01-28 07:59:15] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3664655) [2026-01-28 07:59:15] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3664655) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3664655) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.60s/it]
(EngineCore_DP0 pid=3664655) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.60s/it]
(EngineCore_DP0 pid=3664655) 
(EngineCore_DP0 pid=3664655) [2026-01-28 07:59:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3664655) [2026-01-28 07:59:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9891840 bytes
(EngineCore_DP0 pid=3664655) [2026-01-28 07:59:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3664655) [2026-01-28 07:59:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6594560 bytes
(EngineCore_DP0 pid=3664655) [2026-01-28 07:59:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3664655) [2026-01-28 07:59:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 35610624 bytes
(EngineCore_DP0 pid=3664655) [2026-01-28 07:59:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3664655) [2026-01-28 07:59:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=3664655) 2026-01-28 07:59:36,208 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3664655) 2026-01-28 07:59:36,220 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  14%|        | 36/256 [00:00<00:00, 357.75it/s]
Adding requests:  37%|      | 95/256 [00:00<00:00, 491.63it/s]
Adding requests:  59%|    | 151/256 [00:00<00:00, 520.82it/s]
Adding requests:  82%| | 209/256 [00:00<00:00, 543.04it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 528.44it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 8/256 [00:00<00:06, 38.59it/s, est. speed input: 39522.94 toks/s, output: 38.59 toks/s]
Processed prompts:   5%|         | 12/256 [00:00<00:09, 24.41it/s, est. speed input: 26983.81 toks/s, output: 26.35 toks/s]
Processed prompts:   6%|         | 15/256 [00:00<00:09, 24.45it/s, est. speed input: 26589.51 toks/s, output: 25.97 toks/s]
Processed prompts:   7%|         | 18/256 [00:00<00:12, 18.43it/s, est. speed input: 22168.60 toks/s, output: 21.65 toks/s]
Processed prompts:   8%|         | 20/256 [00:00<00:13, 17.85it/s, est. speed input: 21431.07 toks/s, output: 20.93 toks/s]
Processed prompts:   9%|         | 22/256 [00:01<00:13, 17.36it/s, est. speed input: 20846.08 toks/s, output: 20.36 toks/s]
Processed prompts:   9%|         | 24/256 [00:01<00:13, 16.97it/s, est. speed input: 20379.67 toks/s, output: 19.90 toks/s]
Processed prompts:  10%|         | 26/256 [00:01<00:13, 16.80it/s, est. speed input: 20043.46 toks/s, output: 19.57 toks/s]
Processed prompts:  11%|         | 28/256 [00:01<00:13, 16.55it/s, est. speed input: 19723.07 toks/s, output: 19.26 toks/s]
Processed prompts:  12%|        | 30/256 [00:01<00:13, 16.43it/s, est. speed input: 19472.76 toks/s, output: 19.02 toks/s]
Processed prompts:  12%|        | 32/256 [00:01<00:13, 16.29it/s, est. speed input: 19240.96 toks/s, output: 18.79 toks/s]
Processed prompts:  13%|        | 34/256 [00:01<00:13, 16.02it/s, est. speed input: 18993.96 toks/s, output: 18.55 toks/s]
Processed prompts:  14%|        | 36/256 [00:01<00:13, 16.04it/s, est. speed input: 18833.27 toks/s, output: 18.39 toks/s]
Processed prompts:  15%|        | 38/256 [00:02<00:13, 16.11it/s, est. speed input: 18705.68 toks/s, output: 18.27 toks/s]
Processed prompts:  16%|        | 40/256 [00:02<00:13, 16.06it/s, est. speed input: 18571.50 toks/s, output: 18.14 toks/s]
Processed prompts:  16%|        | 42/256 [00:02<00:13, 16.06it/s, est. speed input: 18457.96 toks/s, output: 18.03 toks/s]
Processed prompts:  17%|        | 44/256 [00:02<00:13, 16.09it/s, est. speed input: 18360.51 toks/s, output: 17.93 toks/s]
Processed prompts:  18%|        | 46/256 [00:02<00:12, 16.20it/s, est. speed input: 18289.32 toks/s, output: 17.86 toks/s]
Processed prompts:  19%|        | 48/256 [00:02<00:12, 16.20it/s, est. speed input: 18212.96 toks/s, output: 17.79 toks/s]
Processed prompts:  20%|        | 50/256 [00:02<00:12, 15.97it/s, est. speed input: 18103.62 toks/s, output: 17.68 toks/s]
Processed prompts:  20%|        | 52/256 [00:02<00:12, 16.01it/s, est. speed input: 18036.13 toks/s, output: 17.61 toks/s]
Processed prompts:  21%|        | 54/256 [00:03<00:12, 16.08it/s, est. speed input: 17979.36 toks/s, output: 17.56 toks/s]
Processed prompts:  22%|       | 56/256 [00:03<00:12, 16.12it/s, est. speed input: 17927.10 toks/s, output: 17.51 toks/s]
Processed prompts:  23%|       | 58/256 [00:03<00:12, 16.12it/s, est. speed input: 17873.38 toks/s, output: 17.45 toks/s]
Processed prompts:  23%|       | 60/256 [00:03<00:12, 16.14it/s, est. speed input: 17827.16 toks/s, output: 17.41 toks/s]
Processed prompts:  24%|       | 62/256 [00:03<00:11, 16.21it/s, est. speed input: 17790.92 toks/s, output: 17.37 toks/s]
Processed prompts:  25%|       | 64/256 [00:03<00:11, 16.23it/s, est. speed input: 17753.17 toks/s, output: 17.34 toks/s]
Processed prompts:  26%|       | 66/256 [00:03<00:11, 16.26it/s, est. speed input: 17719.92 toks/s, output: 17.30 toks/s]
Processed prompts:  27%|       | 68/256 [00:03<00:11, 15.89it/s, est. speed input: 17644.23 toks/s, output: 17.23 toks/s]
Processed prompts:  27%|       | 70/256 [00:04<00:11, 15.97it/s, est. speed input: 17610.62 toks/s, output: 17.20 toks/s]
Processed prompts:  28%|       | 72/256 [00:04<00:11, 16.03it/s, est. speed input: 17579.55 toks/s, output: 17.17 toks/s]
Processed prompts:  29%|       | 74/256 [00:04<00:11, 16.06it/s, est. speed input: 17549.25 toks/s, output: 17.14 toks/s]
Processed prompts:  30%|       | 76/256 [00:04<00:11, 16.15it/s, est. speed input: 17527.46 toks/s, output: 17.12 toks/s]
Processed prompts:  30%|       | 78/256 [00:04<00:11, 16.16it/s, est. speed input: 17501.51 toks/s, output: 17.09 toks/s]
Processed prompts:  31%|      | 80/256 [00:04<00:10, 16.09it/s, est. speed input: 17469.73 toks/s, output: 17.06 toks/s]
Processed prompts:  32%|      | 82/256 [00:04<00:10, 16.10it/s, est. speed input: 17444.95 toks/s, output: 17.04 toks/s]
Processed prompts:  33%|      | 84/256 [00:04<00:10, 15.82it/s, est. speed input: 17395.28 toks/s, output: 16.99 toks/s]
Processed prompts:  34%|      | 86/256 [00:05<00:10, 15.83it/s, est. speed input: 17366.32 toks/s, output: 16.96 toks/s]
Processed prompts:  34%|      | 88/256 [00:05<00:10, 15.91it/s, est. speed input: 17344.99 toks/s, output: 16.94 toks/s]
Processed prompts:  35%|      | 90/256 [00:05<00:10, 15.97it/s, est. speed input: 17325.72 toks/s, output: 16.92 toks/s]
Processed prompts:  36%|      | 92/256 [00:05<00:10, 16.08it/s, est. speed input: 17311.77 toks/s, output: 16.91 toks/s]
Processed prompts:  37%|      | 94/256 [00:05<00:10, 16.10it/s, est. speed input: 17294.81 toks/s, output: 16.89 toks/s]
Processed prompts:  38%|      | 96/256 [00:05<00:09, 16.05it/s, est. speed input: 17273.41 toks/s, output: 16.87 toks/s]
Processed prompts:  38%|      | 98/256 [00:05<00:09, 16.05it/s, est. speed input: 17255.49 toks/s, output: 16.85 toks/s]
Processed prompts:  39%|      | 100/256 [00:05<00:09, 16.19it/s, est. speed input: 17248.89 toks/s, output: 16.84 toks/s]
Processed prompts:  40%|      | 102/256 [00:06<00:09, 15.88it/s, est. speed input: 17212.52 toks/s, output: 16.81 toks/s]
Processed prompts:  41%|      | 104/256 [00:06<00:09, 15.94it/s, est. speed input: 17197.06 toks/s, output: 16.79 toks/s]
Processed prompts:  41%|     | 106/256 [00:06<00:09, 16.03it/s, est. speed input: 17186.10 toks/s, output: 16.78 toks/s]
Processed prompts:  42%|     | 108/256 [00:06<00:09, 16.05it/s, est. speed input: 17172.67 toks/s, output: 16.77 toks/s]
Processed prompts:  43%|     | 110/256 [00:06<00:09, 16.12it/s, est. speed input: 17163.22 toks/s, output: 16.76 toks/s]
Processed prompts:  44%|     | 112/256 [00:06<00:08, 16.06it/s, est. speed input: 17147.14 toks/s, output: 16.75 toks/s]
Processed prompts:  45%|     | 114/256 [00:06<00:08, 16.14it/s, est. speed input: 17139.79 toks/s, output: 16.74 toks/s]
Processed prompts:  45%|     | 116/256 [00:06<00:08, 16.25it/s, est. speed input: 17135.32 toks/s, output: 16.73 toks/s]
Processed prompts:  46%|     | 118/256 [00:07<00:08, 16.04it/s, est. speed input: 17113.97 toks/s, output: 16.71 toks/s]
Processed prompts:  47%|     | 120/256 [00:07<00:08, 16.04it/s, est. speed input: 17101.92 toks/s, output: 16.70 toks/s]
Processed prompts:  48%|     | 122/256 [00:07<00:08, 16.09it/s, est. speed input: 17093.22 toks/s, output: 16.69 toks/s]
Processed prompts:  48%|     | 124/256 [00:07<00:08, 16.13it/s, est. speed input: 17085.36 toks/s, output: 16.68 toks/s]
Processed prompts:  49%|     | 126/256 [00:07<00:08, 16.16it/s, est. speed input: 17077.80 toks/s, output: 16.68 toks/s]
Processed prompts:  50%|     | 128/256 [00:07<00:07, 16.20it/s, est. speed input: 17071.37 toks/s, output: 16.67 toks/s]
Processed prompts:  51%|     | 130/256 [00:07<00:07, 16.15it/s, est. speed input: 17060.92 toks/s, output: 16.66 toks/s]
Processed prompts:  52%|    | 132/256 [00:07<00:07, 16.14it/s, est. speed input: 17052.09 toks/s, output: 16.65 toks/s]
Processed prompts:  52%|    | 134/256 [00:08<00:07, 16.06it/s, est. speed input: 17039.79 toks/s, output: 16.64 toks/s]
Processed prompts:  53%|    | 136/256 [00:08<00:07, 15.88it/s, est. speed input: 17020.90 toks/s, output: 16.62 toks/s]
Processed prompts:  54%|    | 138/256 [00:08<00:07, 15.95it/s, est. speed input: 17013.33 toks/s, output: 16.61 toks/s]
Processed prompts:  55%|    | 140/256 [00:08<00:07, 15.99it/s, est. speed input: 17005.33 toks/s, output: 16.61 toks/s]
Processed prompts:  55%|    | 142/256 [00:08<00:07, 16.06it/s, est. speed input: 16999.49 toks/s, output: 16.60 toks/s]
Processed prompts:  56%|    | 144/256 [00:08<00:06, 16.09it/s, est. speed input: 16993.27 toks/s, output: 16.59 toks/s]
Processed prompts:  57%|    | 146/256 [00:08<00:06, 16.09it/s, est. speed input: 16985.89 toks/s, output: 16.59 toks/s]
Processed prompts:  58%|    | 148/256 [00:08<00:06, 16.17it/s, est. speed input: 16982.59 toks/s, output: 16.58 toks/s]
Processed prompts:  59%|    | 150/256 [00:09<00:06, 16.06it/s, est. speed input: 16971.46 toks/s, output: 16.57 toks/s]
Processed prompts:  59%|    | 152/256 [00:09<00:06, 15.77it/s, est. speed input: 16950.06 toks/s, output: 16.55 toks/s]
Processed prompts:  60%|    | 154/256 [00:09<00:06, 15.83it/s, est. speed input: 16942.14 toks/s, output: 16.55 toks/s]
Processed prompts:  61%|    | 156/256 [00:09<00:06, 15.92it/s, est. speed input: 16936.85 toks/s, output: 16.54 toks/s]
Processed prompts:  62%|   | 158/256 [00:09<00:06, 16.04it/s, est. speed input: 16933.78 toks/s, output: 16.54 toks/s]
Processed prompts:  62%|   | 160/256 [00:09<00:05, 16.06it/s, est. speed input: 16928.04 toks/s, output: 16.53 toks/s]
Processed prompts:  63%|   | 162/256 [00:09<00:05, 16.08it/s, est. speed input: 16923.01 toks/s, output: 16.53 toks/s]
Processed prompts:  64%|   | 164/256 [00:09<00:05, 16.07it/s, est. speed input: 16916.86 toks/s, output: 16.52 toks/s]
Processed prompts:  65%|   | 166/256 [00:10<00:05, 16.08it/s, est. speed input: 16911.32 toks/s, output: 16.51 toks/s]
Processed prompts:  66%|   | 168/256 [00:10<00:05, 16.10it/s, est. speed input: 16906.84 toks/s, output: 16.51 toks/s]
Processed prompts:  66%|   | 170/256 [00:10<00:05, 15.85it/s, est. speed input: 16891.11 toks/s, output: 16.50 toks/s]
Processed prompts:  67%|   | 172/256 [00:10<00:05, 15.89it/s, est. speed input: 16884.93 toks/s, output: 16.49 toks/s]
Processed prompts:  68%|   | 174/256 [00:10<00:05, 15.99it/s, est. speed input: 16881.64 toks/s, output: 16.49 toks/s]
Processed prompts:  69%|   | 176/256 [00:10<00:05, 15.98it/s, est. speed input: 16875.26 toks/s, output: 16.48 toks/s]
Processed prompts:  70%|   | 178/256 [00:10<00:04, 16.01it/s, est. speed input: 16870.79 toks/s, output: 16.48 toks/s]
Processed prompts:  70%|   | 180/256 [00:10<00:04, 16.05it/s, est. speed input: 16866.87 toks/s, output: 16.47 toks/s]
Processed prompts:  71%|   | 182/256 [00:11<00:04, 16.05it/s, est. speed input: 16862.14 toks/s, output: 16.47 toks/s]
Processed prompts:  72%|  | 184/256 [00:11<00:04, 15.95it/s, est. speed input: 16853.40 toks/s, output: 16.46 toks/s]
Processed prompts:  73%|  | 186/256 [00:11<00:04, 15.76it/s, est. speed input: 16840.21 toks/s, output: 16.45 toks/s]
Processed prompts:  73%|  | 188/256 [00:11<00:04, 15.83it/s, est. speed input: 16835.23 toks/s, output: 16.44 toks/s]
Processed prompts:  74%|  | 190/256 [00:11<00:04, 15.89it/s, est. speed input: 16830.58 toks/s, output: 16.44 toks/s]
Processed prompts:  75%|  | 192/256 [00:11<00:04, 15.85it/s, est. speed input: 16822.92 toks/s, output: 16.43 toks/s]
Processed prompts:  76%|  | 194/256 [00:11<00:03, 15.96it/s, est. speed input: 16820.75 toks/s, output: 16.43 toks/s]
Processed prompts:  77%|  | 196/256 [00:11<00:03, 15.94it/s, est. speed input: 16814.90 toks/s, output: 16.42 toks/s]
Processed prompts:  77%|  | 198/256 [00:12<00:03, 16.06it/s, est. speed input: 16814.24 toks/s, output: 16.42 toks/s]
Processed prompts:  78%|  | 200/256 [00:12<00:03, 16.04it/s, est. speed input: 16809.91 toks/s, output: 16.42 toks/s]
Processed prompts:  79%|  | 202/256 [00:12<00:03, 15.79it/s, est. speed input: 16797.05 toks/s, output: 16.40 toks/s]
Processed prompts:  80%|  | 204/256 [00:12<00:03, 15.91it/s, est. speed input: 16794.71 toks/s, output: 16.40 toks/s]
Processed prompts:  80%|  | 206/256 [00:12<00:03, 16.06it/s, est. speed input: 16794.93 toks/s, output: 16.40 toks/s]
Processed prompts:  81%| | 208/256 [00:12<00:02, 16.10it/s, est. speed input: 16793.07 toks/s, output: 16.40 toks/s]
Processed prompts:  82%| | 210/256 [00:12<00:02, 16.13it/s, est. speed input: 16790.89 toks/s, output: 16.40 toks/s]
Processed prompts:  83%| | 212/256 [00:12<00:02, 16.05it/s, est. speed input: 16785.51 toks/s, output: 16.39 toks/s]
Processed prompts:  84%| | 214/256 [00:13<00:02, 16.06it/s, est. speed input: 16782.63 toks/s, output: 16.39 toks/s]
Processed prompts:  84%| | 216/256 [00:13<00:02, 16.05it/s, est. speed input: 16779.04 toks/s, output: 16.39 toks/s]
Processed prompts:  85%| | 218/256 [00:13<00:02, 16.05it/s, est. speed input: 16775.92 toks/s, output: 16.38 toks/s]
Processed prompts:  86%| | 220/256 [00:13<00:02, 15.75it/s, est. speed input: 16762.99 toks/s, output: 16.37 toks/s]
Processed prompts:  87%| | 222/256 [00:13<00:02, 15.90it/s, est. speed input: 16762.01 toks/s, output: 16.37 toks/s]
Processed prompts:  88%| | 224/256 [00:13<00:02, 15.98it/s, est. speed input: 16760.00 toks/s, output: 16.37 toks/s]
Processed prompts:  88%| | 226/256 [00:13<00:01, 16.07it/s, est. speed input: 16759.34 toks/s, output: 16.37 toks/s]
Processed prompts:  89%| | 228/256 [00:13<00:01, 16.14it/s, est. speed input: 16758.89 toks/s, output: 16.37 toks/s]
Processed prompts:  90%| | 230/256 [00:14<00:01, 16.10it/s, est. speed input: 16755.64 toks/s, output: 16.36 toks/s]
Processed prompts:  91%| | 232/256 [00:14<00:01, 16.07it/s, est. speed input: 16752.39 toks/s, output: 16.36 toks/s]
Processed prompts:  91%|| 234/256 [00:14<00:01, 16.10it/s, est. speed input: 16750.75 toks/s, output: 16.36 toks/s]
Processed prompts:  92%|| 236/256 [00:14<00:01, 15.94it/s, est. speed input: 16743.72 toks/s, output: 16.35 toks/s]
Processed prompts:  93%|| 238/256 [00:14<00:01, 15.97it/s, est. speed input: 16740.85 toks/s, output: 16.35 toks/s]
Processed prompts:  94%|| 240/256 [00:14<00:00, 16.08it/s, est. speed input: 16740.80 toks/s, output: 16.35 toks/s]
Processed prompts:  95%|| 242/256 [00:14<00:00, 16.09it/s, est. speed input: 16738.72 toks/s, output: 16.35 toks/s]
Processed prompts:  95%|| 244/256 [00:14<00:00, 16.06it/s, est. speed input: 16735.80 toks/s, output: 16.34 toks/s]
Processed prompts:  96%|| 246/256 [00:15<00:00, 16.11it/s, est. speed input: 16734.89 toks/s, output: 16.34 toks/s]
Processed prompts:  97%|| 248/256 [00:15<00:00, 16.06it/s, est. speed input: 16731.52 toks/s, output: 16.34 toks/s]
Processed prompts:  98%|| 250/256 [00:15<00:00, 16.11it/s, est. speed input: 16730.66 toks/s, output: 16.34 toks/s]
Processed prompts:  98%|| 252/256 [00:15<00:00, 16.19it/s, est. speed input: 16730.84 toks/s, output: 16.34 toks/s]
Processed prompts:  99%|| 254/256 [00:15<00:00, 15.84it/s, est. speed input: 16719.89 toks/s, output: 16.33 toks/s]
Processed prompts: 100%|| 256/256 [00:15<00:00, 15.84it/s, est. speed input: 16782.19 toks/s, output: 16.39 toks/s]
Processed prompts: 100%|| 256/256 [00:15<00:00, 16.39it/s, est. speed input: 16782.19 toks/s, output: 16.39 toks/s]
[rank0]:[W128 07:59:53.246449524 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-28 07:59:55
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/BitNet-2B-INT8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 08:00:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 08:00:00 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3665536) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3665536) WARNING 01-28 08:00:26 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.76 requests/s, 15128.11 total tokens/s, 14.76 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-28 08:00:00] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 08:00:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:00:00] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:00:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:00:00] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:00:00] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:00:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:00:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:00:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:00:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:00:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:00:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:00:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:00:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 08:00:03] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 08:00:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:00:03] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:00:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:00:03] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:00:03] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:00:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:00:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:00:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:00:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:00:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:00:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:00:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:00:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3665536) [2026-01-28 08:00:04] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3665536) [2026-01-28 08:00:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3665536) [2026-01-28 08:00:04] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3665536) [2026-01-28 08:00:04] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3665536) [2026-01-28 08:00:04] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3665536) [2026-01-28 08:00:04] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3665536) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3665536) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.72s/it]
(EngineCore_DP0 pid=3665536) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.72s/it]
(EngineCore_DP0 pid=3665536) 
(EngineCore_DP0 pid=3665536) [2026-01-28 08:00:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3665536) [2026-01-28 08:00:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9891840 bytes
(EngineCore_DP0 pid=3665536) [2026-01-28 08:00:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3665536) [2026-01-28 08:00:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6594560 bytes
(EngineCore_DP0 pid=3665536) [2026-01-28 08:00:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3665536) [2026-01-28 08:00:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 35610624 bytes
(EngineCore_DP0 pid=3665536) [2026-01-28 08:00:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3665536) [2026-01-28 08:00:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=3665536) 2026-01-28 08:00:26,193 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3665536) 2026-01-28 08:00:26,205 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   8%|         | 41/512 [00:00<00:01, 408.67it/s]
Adding requests:  20%|        | 102/512 [00:00<00:00, 522.26it/s]
Adding requests:  31%|       | 159/512 [00:00<00:00, 543.02it/s]
Adding requests:  42%|     | 215/512 [00:00<00:00, 549.48it/s]
Adding requests:  53%|    | 273/512 [00:00<00:00, 558.09it/s]
Adding requests:  64%|   | 329/512 [00:00<00:00, 550.42it/s]
Adding requests:  75%|  | 385/512 [00:00<00:00, 553.25it/s]
Adding requests:  86%| | 441/512 [00:00<00:00, 549.06it/s]
Adding requests:  97%|| 496/512 [00:00<00:00, 547.54it/s]
Adding requests: 100%|| 512/512 [00:00<00:00, 542.69it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 14/512 [00:00<00:12, 40.46it/s, est. speed input: 41438.59 toks/s, output: 40.46 toks/s]
Processed prompts:   4%|         | 19/512 [00:00<00:17, 28.91it/s, est. speed input: 31599.10 toks/s, output: 30.86 toks/s]
Processed prompts:   4%|         | 22/512 [00:00<00:23, 21.06it/s, est. speed input: 25263.92 toks/s, output: 24.67 toks/s]
Processed prompts:   5%|         | 26/512 [00:01<00:25, 18.79it/s, est. speed input: 22988.84 toks/s, output: 22.45 toks/s]
Processed prompts:   6%|         | 30/512 [00:01<00:27, 17.50it/s, est. speed input: 21582.11 toks/s, output: 21.08 toks/s]
Processed prompts:   7%|         | 34/512 [00:01<00:28, 16.59it/s, est. speed input: 20554.23 toks/s, output: 20.07 toks/s]
Processed prompts:   7%|         | 38/512 [00:01<00:29, 15.94it/s, est. speed input: 19774.61 toks/s, output: 19.31 toks/s]
Processed prompts:   8%|         | 42/512 [00:02<00:30, 15.58it/s, est. speed input: 19215.06 toks/s, output: 18.76 toks/s]
Processed prompts:   9%|         | 46/512 [00:02<00:30, 15.37it/s, est. speed input: 18793.41 toks/s, output: 18.35 toks/s]
Processed prompts:  10%|         | 50/512 [00:02<00:30, 15.18it/s, est. speed input: 18432.78 toks/s, output: 18.00 toks/s]
Processed prompts:  11%|         | 54/512 [00:03<00:30, 14.97it/s, est. speed input: 18109.02 toks/s, output: 17.68 toks/s]
Processed prompts:  11%|        | 58/512 [00:03<00:30, 14.94it/s, est. speed input: 17875.48 toks/s, output: 17.46 toks/s]
Processed prompts:  12%|        | 62/512 [00:03<00:30, 14.96it/s, est. speed input: 17688.03 toks/s, output: 17.27 toks/s]
Processed prompts:  13%|        | 66/512 [00:03<00:29, 14.91it/s, est. speed input: 17510.47 toks/s, output: 17.10 toks/s]
Processed prompts:  14%|        | 70/512 [00:04<00:29, 14.83it/s, est. speed input: 17344.91 toks/s, output: 16.94 toks/s]
Processed prompts:  14%|        | 74/512 [00:04<00:29, 14.87it/s, est. speed input: 17222.07 toks/s, output: 16.82 toks/s]
Processed prompts:  15%|        | 78/512 [00:04<00:29, 14.90it/s, est. speed input: 17113.80 toks/s, output: 16.71 toks/s]
Processed prompts:  16%|        | 82/512 [00:04<00:28, 14.83it/s, est. speed input: 16998.38 toks/s, output: 16.60 toks/s]
Processed prompts:  17%|        | 86/512 [00:05<00:28, 14.79it/s, est. speed input: 16896.75 toks/s, output: 16.50 toks/s]
Processed prompts:  18%|        | 90/512 [00:05<00:28, 14.80it/s, est. speed input: 16811.89 toks/s, output: 16.42 toks/s]
Processed prompts:  18%|        | 94/512 [00:05<00:28, 14.83it/s, est. speed input: 16738.93 toks/s, output: 16.35 toks/s]
Processed prompts:  19%|        | 98/512 [00:06<00:28, 14.77it/s, est. speed input: 16659.63 toks/s, output: 16.27 toks/s]
Processed prompts:  20%|        | 102/512 [00:06<00:27, 14.75it/s, est. speed input: 16590.97 toks/s, output: 16.20 toks/s]
Processed prompts:  21%|        | 106/512 [00:06<00:27, 14.79it/s, est. speed input: 16534.72 toks/s, output: 16.15 toks/s]
Processed prompts:  21%|       | 110/512 [00:06<00:27, 14.81it/s, est. speed input: 16482.85 toks/s, output: 16.10 toks/s]
Processed prompts:  22%|       | 114/512 [00:07<00:27, 14.72it/s, est. speed input: 16419.93 toks/s, output: 16.04 toks/s]
Processed prompts:  23%|       | 118/512 [00:07<00:26, 14.69it/s, est. speed input: 16366.43 toks/s, output: 15.98 toks/s]
Processed prompts:  24%|       | 122/512 [00:07<00:26, 14.74it/s, est. speed input: 16325.44 toks/s, output: 15.94 toks/s]
Processed prompts:  25%|       | 126/512 [00:07<00:26, 14.82it/s, est. speed input: 16293.53 toks/s, output: 15.91 toks/s]
Processed prompts:  25%|       | 130/512 [00:08<00:25, 14.72it/s, est. speed input: 16244.52 toks/s, output: 15.86 toks/s]
Processed prompts:  26%|       | 134/512 [00:08<00:25, 14.78it/s, est. speed input: 16213.80 toks/s, output: 15.83 toks/s]
Processed prompts:  27%|       | 138/512 [00:08<00:25, 14.85it/s, est. speed input: 16188.48 toks/s, output: 15.81 toks/s]
Processed prompts:  28%|       | 142/512 [00:08<00:24, 14.92it/s, est. speed input: 16166.36 toks/s, output: 15.79 toks/s]
Processed prompts:  29%|       | 146/512 [00:09<00:24, 14.76it/s, est. speed input: 16124.05 toks/s, output: 15.75 toks/s]
Processed prompts:  29%|       | 150/512 [00:09<00:24, 14.82it/s, est. speed input: 16101.29 toks/s, output: 15.72 toks/s]
Processed prompts:  30%|       | 154/512 [00:09<00:24, 14.80it/s, est. speed input: 16073.97 toks/s, output: 15.70 toks/s]
Processed prompts:  31%|       | 158/512 [00:10<00:23, 14.84it/s, est. speed input: 16052.97 toks/s, output: 15.68 toks/s]
Processed prompts:  32%|      | 162/512 [00:10<00:23, 14.83it/s, est. speed input: 16029.45 toks/s, output: 15.65 toks/s]
Processed prompts:  32%|      | 166/512 [00:10<00:23, 14.83it/s, est. speed input: 16008.37 toks/s, output: 15.63 toks/s]
Processed prompts:  33%|      | 170/512 [00:10<00:23, 14.87it/s, est. speed input: 15991.17 toks/s, output: 15.62 toks/s]
Processed prompts:  34%|      | 174/512 [00:11<00:22, 14.87it/s, est. speed input: 15973.05 toks/s, output: 15.60 toks/s]
Processed prompts:  35%|      | 178/512 [00:11<00:22, 14.73it/s, est. speed input: 15943.77 toks/s, output: 15.57 toks/s]
Processed prompts:  36%|      | 182/512 [00:11<00:22, 14.77it/s, est. speed input: 15927.11 toks/s, output: 15.55 toks/s]
Processed prompts:  36%|      | 186/512 [00:11<00:21, 14.84it/s, est. speed input: 15914.35 toks/s, output: 15.54 toks/s]
Processed prompts:  37%|      | 190/512 [00:12<00:21, 14.87it/s, est. speed input: 15901.03 toks/s, output: 15.53 toks/s]
Processed prompts:  38%|      | 194/512 [00:12<00:21, 14.77it/s, est. speed input: 15879.13 toks/s, output: 15.51 toks/s]
Processed prompts:  39%|      | 198/512 [00:12<00:21, 14.74it/s, est. speed input: 15860.86 toks/s, output: 15.49 toks/s]
Processed prompts:  39%|      | 202/512 [00:13<00:20, 14.81it/s, est. speed input: 15850.03 toks/s, output: 15.48 toks/s]
Processed prompts:  40%|      | 206/512 [00:13<00:20, 14.85it/s, est. speed input: 15838.82 toks/s, output: 15.47 toks/s]
Processed prompts:  41%|      | 210/512 [00:13<00:20, 14.76it/s, est. speed input: 15820.34 toks/s, output: 15.45 toks/s]
Processed prompts:  42%|     | 214/512 [00:13<00:20, 14.80it/s, est. speed input: 15809.42 toks/s, output: 15.44 toks/s]
Processed prompts:  43%|     | 218/512 [00:14<00:19, 14.81it/s, est. speed input: 15797.10 toks/s, output: 15.43 toks/s]
Processed prompts:  43%|     | 222/512 [00:14<00:19, 14.84it/s, est. speed input: 15787.31 toks/s, output: 15.42 toks/s]
Processed prompts:  44%|     | 226/512 [00:14<00:19, 14.77it/s, est. speed input: 15772.03 toks/s, output: 15.40 toks/s]
Processed prompts:  45%|     | 230/512 [00:14<00:19, 14.80it/s, est. speed input: 15762.02 toks/s, output: 15.39 toks/s]
Processed prompts:  46%|     | 234/512 [00:15<00:18, 14.80it/s, est. speed input: 15751.41 toks/s, output: 15.38 toks/s]
Processed prompts:  46%|     | 238/512 [00:15<00:18, 14.85it/s, est. speed input: 15744.18 toks/s, output: 15.38 toks/s]
Processed prompts:  47%|     | 242/512 [00:15<00:18, 14.73it/s, est. speed input: 15727.36 toks/s, output: 15.36 toks/s]
Processed prompts:  48%|     | 246/512 [00:16<00:17, 14.79it/s, est. speed input: 15720.21 toks/s, output: 15.35 toks/s]
Processed prompts:  49%|     | 250/512 [00:16<00:17, 14.81it/s, est. speed input: 15711.61 toks/s, output: 15.34 toks/s]
Processed prompts:  50%|     | 254/512 [00:16<00:17, 14.87it/s, est. speed input: 15706.21 toks/s, output: 15.34 toks/s]
Processed prompts:  50%|     | 258/512 [00:16<00:17, 14.80it/s, est. speed input: 15694.42 toks/s, output: 15.33 toks/s]
Processed prompts:  51%|     | 262/512 [00:17<00:16, 14.83it/s, est. speed input: 15687.66 toks/s, output: 15.32 toks/s]
Processed prompts:  52%|    | 266/512 [00:17<00:16, 14.84it/s, est. speed input: 15680.21 toks/s, output: 15.31 toks/s]
Processed prompts:  53%|    | 270/512 [00:17<00:16, 14.85it/s, est. speed input: 15673.61 toks/s, output: 15.31 toks/s]
Processed prompts:  54%|    | 274/512 [00:17<00:16, 14.78it/s, est. speed input: 15662.79 toks/s, output: 15.30 toks/s]
Processed prompts:  54%|    | 278/512 [00:18<00:15, 14.82it/s, est. speed input: 15657.01 toks/s, output: 15.29 toks/s]
Processed prompts:  55%|    | 282/512 [00:18<00:15, 14.85it/s, est. speed input: 15651.61 toks/s, output: 15.28 toks/s]
Processed prompts:  56%|    | 286/512 [00:18<00:15, 14.77it/s, est. speed input: 15641.04 toks/s, output: 15.27 toks/s]
Processed prompts:  57%|    | 290/512 [00:18<00:14, 14.80it/s, est. speed input: 15635.34 toks/s, output: 15.27 toks/s]
Processed prompts:  57%|    | 294/512 [00:19<00:14, 14.79it/s, est. speed input: 15628.07 toks/s, output: 15.26 toks/s]
Processed prompts:  58%|    | 298/512 [00:19<00:14, 14.81it/s, est. speed input: 15622.16 toks/s, output: 15.26 toks/s]
Processed prompts:  59%|    | 302/512 [00:19<00:14, 14.76it/s, est. speed input: 15613.61 toks/s, output: 15.25 toks/s]
Processed prompts:  60%|    | 306/512 [00:20<00:13, 14.74it/s, est. speed input: 15605.91 toks/s, output: 15.24 toks/s]
Processed prompts:  61%|    | 310/512 [00:20<00:13, 14.79it/s, est. speed input: 15601.41 toks/s, output: 15.24 toks/s]
Processed prompts:  61%|   | 314/512 [00:20<00:13, 14.80it/s, est. speed input: 15595.77 toks/s, output: 15.23 toks/s]
Processed prompts:  62%|   | 318/512 [00:20<00:13, 14.73it/s, est. speed input: 15586.87 toks/s, output: 15.22 toks/s]
Processed prompts:  63%|   | 322/512 [00:21<00:12, 14.75it/s, est. speed input: 15581.37 toks/s, output: 15.22 toks/s]
Processed prompts:  64%|   | 326/512 [00:21<00:12, 14.75it/s, est. speed input: 15575.46 toks/s, output: 15.21 toks/s]
Processed prompts:  64%|   | 330/512 [00:21<00:12, 14.74it/s, est. speed input: 15569.08 toks/s, output: 15.20 toks/s]
Processed prompts:  65%|   | 334/512 [00:21<00:12, 14.76it/s, est. speed input: 15563.99 toks/s, output: 15.20 toks/s]
Processed prompts:  66%|   | 338/512 [00:22<00:11, 14.78it/s, est. speed input: 15559.26 toks/s, output: 15.19 toks/s]
Processed prompts:  67%|   | 342/512 [00:22<00:10, 15.58it/s, est. speed input: 15586.21 toks/s, output: 15.22 toks/s]
Processed prompts:  68%|   | 346/512 [00:22<00:10, 15.36it/s, est. speed input: 15581.90 toks/s, output: 15.22 toks/s]
Processed prompts:  68%|   | 350/512 [00:23<00:10, 15.13it/s, est. speed input: 15574.80 toks/s, output: 15.21 toks/s]
Processed prompts:  69%|   | 354/512 [00:23<00:10, 15.05it/s, est. speed input: 15570.61 toks/s, output: 15.21 toks/s]
Processed prompts:  70%|   | 358/512 [00:23<00:10, 15.00it/s, est. speed input: 15566.86 toks/s, output: 15.20 toks/s]
Processed prompts:  71%|   | 362/512 [00:23<00:10, 14.98it/s, est. speed input: 15563.85 toks/s, output: 15.20 toks/s]
Processed prompts:  71%|  | 366/512 [00:24<00:09, 14.88it/s, est. speed input: 15557.59 toks/s, output: 15.19 toks/s]
Processed prompts:  72%|  | 370/512 [00:24<00:09, 14.95it/s, est. speed input: 15556.69 toks/s, output: 15.19 toks/s]
Processed prompts:  73%|  | 374/512 [00:24<00:09, 14.92it/s, est. speed input: 15552.77 toks/s, output: 15.19 toks/s]
Processed prompts:  74%|  | 378/512 [00:24<00:09, 14.83it/s, est. speed input: 15546.51 toks/s, output: 15.18 toks/s]
Processed prompts:  75%|  | 382/512 [00:25<00:08, 14.77it/s, est. speed input: 15540.29 toks/s, output: 15.18 toks/s]
Processed prompts:  75%|  | 386/512 [00:25<00:08, 14.76it/s, est. speed input: 15535.60 toks/s, output: 15.17 toks/s]
Processed prompts:  76%|  | 390/512 [00:25<00:08, 14.76it/s, est. speed input: 15531.23 toks/s, output: 15.17 toks/s]
Processed prompts:  77%|  | 394/512 [00:25<00:07, 14.77it/s, est. speed input: 15527.01 toks/s, output: 15.16 toks/s]
Processed prompts:  78%|  | 398/512 [00:26<00:07, 14.71it/s, est. speed input: 15520.72 toks/s, output: 15.16 toks/s]
Processed prompts:  79%|  | 402/512 [00:26<00:07, 14.77it/s, est. speed input: 15518.24 toks/s, output: 15.15 toks/s]
Processed prompts:  79%|  | 406/512 [00:26<00:07, 14.79it/s, est. speed input: 15515.06 toks/s, output: 15.15 toks/s]
Processed prompts:  80%|  | 410/512 [00:27<00:06, 14.79it/s, est. speed input: 15511.31 toks/s, output: 15.15 toks/s]
Processed prompts:  81%|  | 414/512 [00:27<00:06, 14.72it/s, est. speed input: 15505.31 toks/s, output: 15.14 toks/s]
Processed prompts:  82%| | 418/512 [00:27<00:06, 14.78it/s, est. speed input: 15503.01 toks/s, output: 15.14 toks/s]
Processed prompts:  82%| | 422/512 [00:27<00:06, 14.82it/s, est. speed input: 15500.73 toks/s, output: 15.14 toks/s]
Processed prompts:  83%| | 426/512 [00:28<00:05, 14.82it/s, est. speed input: 15497.68 toks/s, output: 15.13 toks/s]
Processed prompts:  84%| | 430/512 [00:28<00:05, 14.69it/s, est. speed input: 15490.44 toks/s, output: 15.13 toks/s]
Processed prompts:  85%| | 434/512 [00:28<00:05, 14.71it/s, est. speed input: 15486.89 toks/s, output: 15.12 toks/s]
Processed prompts:  86%| | 438/512 [00:28<00:05, 14.76it/s, est. speed input: 15484.36 toks/s, output: 15.12 toks/s]
Processed prompts:  86%| | 442/512 [00:29<00:04, 14.76it/s, est. speed input: 15481.00 toks/s, output: 15.12 toks/s]
Processed prompts:  87%| | 446/512 [00:29<00:04, 14.72it/s, est. speed input: 15476.35 toks/s, output: 15.11 toks/s]
Processed prompts:  88%| | 450/512 [00:29<00:03, 15.64it/s, est. speed input: 15500.53 toks/s, output: 15.14 toks/s]
Processed prompts:  89%| | 454/512 [00:29<00:03, 15.43it/s, est. speed input: 15498.92 toks/s, output: 15.14 toks/s]
Processed prompts:  89%| | 458/512 [00:30<00:03, 15.24it/s, est. speed input: 15495.84 toks/s, output: 15.13 toks/s]
Processed prompts:  90%| | 462/512 [00:30<00:03, 15.02it/s, est. speed input: 15490.48 toks/s, output: 15.13 toks/s]
Processed prompts:  91%| | 466/512 [00:30<00:03, 14.96it/s, est. speed input: 15487.78 toks/s, output: 15.12 toks/s]
Processed prompts:  92%|| 470/512 [00:31<00:02, 14.92it/s, est. speed input: 15485.12 toks/s, output: 15.12 toks/s]
Processed prompts:  93%|| 474/512 [00:31<00:02, 14.94it/s, est. speed input: 15483.76 toks/s, output: 15.12 toks/s]
Processed prompts:  93%|| 478/512 [00:31<00:02, 14.84it/s, est. speed input: 15479.33 toks/s, output: 15.12 toks/s]
Processed prompts:  94%|| 482/512 [00:31<00:02, 14.83it/s, est. speed input: 15476.70 toks/s, output: 15.11 toks/s]
Processed prompts:  95%|| 486/512 [00:32<00:01, 14.82it/s, est. speed input: 15473.97 toks/s, output: 15.11 toks/s]
Processed prompts:  96%|| 490/512 [00:32<00:01, 14.39it/s, est. speed input: 15458.59 toks/s, output: 15.10 toks/s]
Processed prompts:  96%|| 494/512 [00:32<00:01, 14.50it/s, est. speed input: 15455.95 toks/s, output: 15.09 toks/s]
Processed prompts:  97%|| 498/512 [00:32<00:00, 14.68it/s, est. speed input: 15456.08 toks/s, output: 15.09 toks/s]
Processed prompts:  98%|| 502/512 [00:33<00:00, 14.74it/s, est. speed input: 15454.20 toks/s, output: 15.09 toks/s]
Processed prompts:  99%|| 506/512 [00:33<00:00, 14.70it/s, est. speed input: 15450.26 toks/s, output: 15.09 toks/s]
Processed prompts: 100%|| 510/512 [00:33<00:00, 15.80it/s, est. speed input: 15475.84 toks/s, output: 15.11 toks/s]
Processed prompts: 100%|| 512/512 [00:33<00:00, 15.80it/s, est. speed input: 15536.48 toks/s, output: 15.17 toks/s]
Processed prompts: 100%|| 512/512 [00:33<00:00, 15.17it/s, est. speed input: 15536.48 toks/s, output: 15.17 toks/s]
[rank0]:[W128 08:01:01.840939148 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-28 08:01:04
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/BitNet-2B-INT8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 08:01:10 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 08:01:10 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3666692) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3666692) WARNING 01-28 08:01:37 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.57 requests/s, 14933.18 total tokens/s, 14.57 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-28 08:01:10] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 08:01:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:01:10] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:01:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:01:10] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:01:10] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:01:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:01:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:01:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:01:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:01:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:01:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:01:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:01:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 08:01:13] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 08:01:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:01:13] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:01:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:01:13] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:01:13] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:01:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:01:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:01:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:01:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:01:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:01:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:01:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:01:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3666692) [2026-01-28 08:01:14] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3666692) [2026-01-28 08:01:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3666692) [2026-01-28 08:01:14] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3666692) [2026-01-28 08:01:14] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3666692) [2026-01-28 08:01:14] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3666692) [2026-01-28 08:01:14] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3666692) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3666692) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.64s/it]
(EngineCore_DP0 pid=3666692) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.64s/it]
(EngineCore_DP0 pid=3666692) 
(EngineCore_DP0 pid=3666692) [2026-01-28 08:01:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3666692) [2026-01-28 08:01:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9891840 bytes
(EngineCore_DP0 pid=3666692) [2026-01-28 08:01:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3666692) [2026-01-28 08:01:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6594560 bytes
(EngineCore_DP0 pid=3666692) [2026-01-28 08:01:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3666692) [2026-01-28 08:01:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 35610624 bytes
(EngineCore_DP0 pid=3666692) [2026-01-28 08:01:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3666692) [2026-01-28 08:01:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=3666692) 2026-01-28 08:01:36,333 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3666692) 2026-01-28 08:01:36,396 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   6%|         | 63/1024 [00:00<00:01, 626.49it/s]
Adding requests:  12%|        | 126/1024 [00:00<00:01, 599.23it/s]
Adding requests:  18%|        | 187/1024 [00:00<00:01, 562.33it/s]
Adding requests:  24%|       | 244/1024 [00:00<00:01, 552.98it/s]
Adding requests:  29%|       | 300/1024 [00:00<00:01, 547.86it/s]
Adding requests:  35%|      | 356/1024 [00:00<00:01, 548.58it/s]
Adding requests:  40%|      | 411/1024 [00:00<00:01, 543.79it/s]
Adding requests:  46%|     | 466/1024 [00:00<00:01, 536.60it/s]
Adding requests:  51%|     | 520/1024 [00:00<00:00, 526.22it/s]
Adding requests:  56%|    | 573/1024 [00:01<00:00, 514.22it/s]
Adding requests:  61%|   | 629/1024 [00:01<00:00, 525.10it/s]
Adding requests:  67%|   | 684/1024 [00:01<00:00, 532.11it/s]
Adding requests:  72%|  | 738/1024 [00:01<00:00, 531.69it/s]
Adding requests:  77%|  | 792/1024 [00:01<00:00, 522.97it/s]
Adding requests:  83%| | 845/1024 [00:01<00:00, 511.24it/s]
Adding requests:  88%| | 900/1024 [00:01<00:00, 521.01it/s]
Adding requests:  93%|| 954/1024 [00:01<00:00, 525.83it/s]
Adding requests:  98%|| 1008/1024 [00:01<00:00, 527.68it/s]
Adding requests: 100%|| 1024/1024 [00:01<00:00, 535.31it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 26/1024 [00:00<00:18, 55.08it/s, est. speed input: 56402.04 toks/s, output: 55.08 toks/s]
Processed prompts:   3%|         | 34/1024 [00:01<00:32, 30.00it/s, est. speed input: 34305.99 toks/s, output: 33.50 toks/s]
Processed prompts:   4%|         | 42/1024 [00:01<00:43, 22.61it/s, est. speed input: 27422.01 toks/s, output: 26.78 toks/s]
Processed prompts:   5%|         | 50/1024 [00:02<00:50, 19.36it/s, est. speed input: 24163.47 toks/s, output: 23.60 toks/s]
Processed prompts:   6%|         | 58/1024 [00:02<00:54, 17.64it/s, est. speed input: 22281.69 toks/s, output: 21.76 toks/s]
Processed prompts:   6%|         | 66/1024 [00:03<00:57, 16.61it/s, est. speed input: 21040.33 toks/s, output: 20.55 toks/s]
Processed prompts:   7%|         | 74/1024 [00:03<00:59, 15.96it/s, est. speed input: 20156.58 toks/s, output: 19.68 toks/s]
Processed prompts:   8%|         | 82/1024 [00:04<01:00, 15.48it/s, est. speed input: 19470.39 toks/s, output: 19.01 toks/s]
Processed prompts:   9%|         | 90/1024 [00:04<01:01, 15.20it/s, est. speed input: 18962.11 toks/s, output: 18.52 toks/s]
Processed prompts:  10%|         | 98/1024 [00:05<01:01, 15.00it/s, est. speed input: 18548.99 toks/s, output: 18.11 toks/s]
Processed prompts:  10%|         | 106/1024 [00:05<01:01, 14.89it/s, est. speed input: 18220.63 toks/s, output: 17.79 toks/s]
Processed prompts:  11%|         | 114/1024 [00:06<01:01, 14.75it/s, est. speed input: 17929.77 toks/s, output: 17.51 toks/s]
Processed prompts:  12%|        | 122/1024 [00:07<01:01, 14.73it/s, est. speed input: 17704.37 toks/s, output: 17.29 toks/s]
Processed prompts:  13%|        | 130/1024 [00:07<01:01, 14.65it/s, est. speed input: 17495.14 toks/s, output: 17.09 toks/s]
Processed prompts:  13%|        | 138/1024 [00:08<01:00, 14.65it/s, est. speed input: 17328.60 toks/s, output: 16.92 toks/s]
Processed prompts:  14%|        | 146/1024 [00:08<01:00, 14.61it/s, est. speed input: 17171.69 toks/s, output: 16.77 toks/s]
Processed prompts:  15%|        | 154/1024 [00:09<00:59, 14.61it/s, est. speed input: 17041.05 toks/s, output: 16.64 toks/s]
Processed prompts:  16%|        | 162/1024 [00:09<00:59, 14.57it/s, est. speed input: 16916.23 toks/s, output: 16.52 toks/s]
Processed prompts:  17%|        | 170/1024 [00:10<00:58, 14.61it/s, est. speed input: 16818.21 toks/s, output: 16.42 toks/s]
Processed prompts:  17%|        | 178/1024 [00:10<00:58, 14.56it/s, est. speed input: 16716.19 toks/s, output: 16.32 toks/s]
Processed prompts:  18%|        | 186/1024 [00:11<00:57, 14.57it/s, est. speed input: 16631.54 toks/s, output: 16.24 toks/s]
Processed prompts:  19%|        | 194/1024 [00:12<00:57, 14.55it/s, est. speed input: 16549.71 toks/s, output: 16.16 toks/s]
Processed prompts:  20%|        | 202/1024 [00:12<00:56, 14.56it/s, est. speed input: 16478.38 toks/s, output: 16.09 toks/s]
Processed prompts:  21%|        | 210/1024 [00:13<00:56, 14.52it/s, est. speed input: 16407.30 toks/s, output: 16.02 toks/s]
Processed prompts:  21%|       | 218/1024 [00:13<00:55, 14.55it/s, est. speed input: 16348.85 toks/s, output: 15.97 toks/s]
Processed prompts:  22%|       | 226/1024 [00:14<00:54, 14.52it/s, est. speed input: 16288.88 toks/s, output: 15.91 toks/s]
Processed prompts:  23%|       | 234/1024 [00:14<00:54, 14.55it/s, est. speed input: 16240.08 toks/s, output: 15.86 toks/s]
Processed prompts:  24%|       | 242/1024 [00:15<00:53, 14.51it/s, est. speed input: 16186.35 toks/s, output: 15.81 toks/s]
Processed prompts:  24%|       | 250/1024 [00:15<00:53, 14.52it/s, est. speed input: 16141.74 toks/s, output: 15.76 toks/s]
Processed prompts:  25%|       | 258/1024 [00:16<00:52, 14.49it/s, est. speed input: 16095.66 toks/s, output: 15.72 toks/s]
Processed prompts:  26%|       | 266/1024 [00:16<00:52, 14.51it/s, est. speed input: 16056.42 toks/s, output: 15.68 toks/s]
Processed prompts:  27%|       | 274/1024 [00:17<00:51, 14.53it/s, est. speed input: 16021.44 toks/s, output: 15.65 toks/s]
Processed prompts:  28%|       | 282/1024 [00:18<00:51, 14.53it/s, est. speed input: 15986.11 toks/s, output: 15.61 toks/s]
Processed prompts:  28%|       | 290/1024 [00:18<00:50, 14.56it/s, est. speed input: 15957.15 toks/s, output: 15.58 toks/s]
Processed prompts:  29%|       | 298/1024 [00:19<00:49, 14.54it/s, est. speed input: 15924.88 toks/s, output: 15.55 toks/s]
Processed prompts:  30%|       | 306/1024 [00:19<00:49, 14.57it/s, est. speed input: 15899.27 toks/s, output: 15.53 toks/s]
Processed prompts:  31%|       | 314/1024 [00:20<00:48, 14.57it/s, est. speed input: 15872.04 toks/s, output: 15.50 toks/s]
Processed prompts:  31%|      | 322/1024 [00:20<00:48, 14.56it/s, est. speed input: 15846.15 toks/s, output: 15.47 toks/s]
Processed prompts:  32%|      | 330/1024 [00:21<00:47, 14.53it/s, est. speed input: 15819.50 toks/s, output: 15.45 toks/s]
Processed prompts:  33%|      | 338/1024 [00:21<00:46, 14.91it/s, est. speed input: 15829.35 toks/s, output: 15.46 toks/s]
Processed prompts:  34%|      | 346/1024 [00:22<00:45, 14.79it/s, est. speed input: 15805.60 toks/s, output: 15.44 toks/s]
Processed prompts:  35%|      | 354/1024 [00:22<00:45, 14.74it/s, est. speed input: 15785.71 toks/s, output: 15.42 toks/s]
Processed prompts:  35%|      | 362/1024 [00:23<00:45, 14.66it/s, est. speed input: 15762.96 toks/s, output: 15.39 toks/s]
Processed prompts:  36%|      | 370/1024 [00:24<00:44, 14.64it/s, est. speed input: 15744.34 toks/s, output: 15.38 toks/s]
Processed prompts:  37%|      | 378/1024 [00:24<00:44, 14.59it/s, est. speed input: 15724.06 toks/s, output: 15.36 toks/s]
Processed prompts:  38%|      | 386/1024 [00:25<00:43, 14.59it/s, est. speed input: 15707.14 toks/s, output: 15.34 toks/s]
Processed prompts:  38%|      | 394/1024 [00:25<00:43, 14.56it/s, est. speed input: 15688.36 toks/s, output: 15.32 toks/s]
Processed prompts:  39%|      | 402/1024 [00:26<00:42, 14.62it/s, est. speed input: 15676.38 toks/s, output: 15.31 toks/s]
Processed prompts:  40%|      | 410/1024 [00:26<00:42, 14.59it/s, est. speed input: 15660.06 toks/s, output: 15.29 toks/s]
Processed prompts:  41%|      | 418/1024 [00:27<00:41, 14.58it/s, est. speed input: 15644.95 toks/s, output: 15.28 toks/s]
Processed prompts:  42%|     | 426/1024 [00:27<00:41, 14.55it/s, est. speed input: 15628.85 toks/s, output: 15.26 toks/s]
Processed prompts:  42%|     | 434/1024 [00:28<00:40, 14.56it/s, est. speed input: 15615.44 toks/s, output: 15.25 toks/s]
Processed prompts:  43%|     | 442/1024 [00:29<00:40, 14.53it/s, est. speed input: 15600.27 toks/s, output: 15.23 toks/s]
Processed prompts:  44%|     | 450/1024 [00:29<00:38, 15.04it/s, est. speed input: 15619.37 toks/s, output: 15.25 toks/s]
Processed prompts:  45%|     | 458/1024 [00:30<00:38, 14.88it/s, est. speed input: 15605.90 toks/s, output: 15.24 toks/s]
Processed prompts:  46%|     | 466/1024 [00:30<00:37, 14.79it/s, est. speed input: 15593.97 toks/s, output: 15.23 toks/s]
Processed prompts:  46%|     | 474/1024 [00:31<00:37, 14.71it/s, est. speed input: 15581.10 toks/s, output: 15.22 toks/s]
Processed prompts:  47%|     | 482/1024 [00:31<00:36, 14.67it/s, est. speed input: 15569.79 toks/s, output: 15.20 toks/s]
Processed prompts:  48%|     | 490/1024 [00:32<00:36, 14.59it/s, est. speed input: 15555.60 toks/s, output: 15.19 toks/s]
Processed prompts:  49%|     | 498/1024 [00:32<00:36, 14.58it/s, est. speed input: 15544.62 toks/s, output: 15.18 toks/s]
Processed prompts:  49%|     | 506/1024 [00:33<00:35, 14.56it/s, est. speed input: 15533.26 toks/s, output: 15.17 toks/s]
Processed prompts:  50%|     | 514/1024 [00:33<00:35, 14.56it/s, est. speed input: 15523.07 toks/s, output: 15.16 toks/s]
Processed prompts:  51%|     | 522/1024 [00:34<00:34, 14.57it/s, est. speed input: 15513.75 toks/s, output: 15.15 toks/s]
Processed prompts:  52%|    | 530/1024 [00:35<00:33, 14.55it/s, est. speed input: 15503.22 toks/s, output: 15.14 toks/s]
Processed prompts:  53%|    | 538/1024 [00:35<00:33, 14.54it/s, est. speed input: 15493.41 toks/s, output: 15.13 toks/s]
Processed prompts:  53%|    | 546/1024 [00:36<00:32, 14.49it/s, est. speed input: 15481.70 toks/s, output: 15.12 toks/s]
Processed prompts:  54%|    | 554/1024 [00:36<00:32, 14.53it/s, est. speed input: 15473.82 toks/s, output: 15.11 toks/s]
Processed prompts:  55%|    | 562/1024 [00:37<00:31, 14.52it/s, est. speed input: 15464.90 toks/s, output: 15.10 toks/s]
Processed prompts:  56%|    | 570/1024 [00:37<00:31, 14.57it/s, est. speed input: 15458.45 toks/s, output: 15.10 toks/s]
Processed prompts:  56%|    | 578/1024 [00:38<00:30, 14.54it/s, est. speed input: 15449.54 toks/s, output: 15.09 toks/s]
Processed prompts:  57%|    | 586/1024 [00:38<00:30, 14.59it/s, est. speed input: 15443.73 toks/s, output: 15.08 toks/s]
Processed prompts:  58%|    | 594/1024 [00:39<00:29, 14.54it/s, est. speed input: 15434.42 toks/s, output: 15.07 toks/s]
Processed prompts:  59%|    | 602/1024 [00:39<00:28, 14.57it/s, est. speed input: 15428.23 toks/s, output: 15.07 toks/s]
Processed prompts:  60%|    | 610/1024 [00:40<00:28, 14.52it/s, est. speed input: 15419.04 toks/s, output: 15.06 toks/s]
Processed prompts:  60%|    | 618/1024 [00:41<00:27, 14.55it/s, est. speed input: 15413.11 toks/s, output: 15.05 toks/s]
Processed prompts:  61%|    | 626/1024 [00:41<00:27, 14.52it/s, est. speed input: 15405.01 toks/s, output: 15.04 toks/s]
Processed prompts:  62%|   | 634/1024 [00:42<00:26, 14.55it/s, est. speed input: 15399.33 toks/s, output: 15.04 toks/s]
Processed prompts:  63%|   | 642/1024 [00:42<00:26, 14.58it/s, est. speed input: 15394.12 toks/s, output: 15.03 toks/s]
Processed prompts:  63%|   | 650/1024 [00:43<00:25, 14.58it/s, est. speed input: 15388.13 toks/s, output: 15.03 toks/s]
Processed prompts:  64%|   | 658/1024 [00:43<00:25, 14.55it/s, est. speed input: 15381.25 toks/s, output: 15.02 toks/s]
Processed prompts:  65%|   | 666/1024 [00:44<00:24, 14.56it/s, est. speed input: 15375.66 toks/s, output: 15.02 toks/s]
Processed prompts:  66%|   | 674/1024 [00:44<00:24, 14.50it/s, est. speed input: 15367.33 toks/s, output: 15.01 toks/s]
Processed prompts:  67%|   | 682/1024 [00:45<00:23, 14.53it/s, est. speed input: 15362.44 toks/s, output: 15.00 toks/s]
Processed prompts:  67%|   | 690/1024 [00:46<00:23, 14.52it/s, est. speed input: 15356.09 toks/s, output: 15.00 toks/s]
Processed prompts:  68%|   | 698/1024 [00:46<00:22, 14.56it/s, est. speed input: 15352.14 toks/s, output: 14.99 toks/s]
Processed prompts:  69%|   | 706/1024 [00:47<00:21, 14.55it/s, est. speed input: 15346.53 toks/s, output: 14.99 toks/s]
Processed prompts:  70%|   | 714/1024 [00:47<00:21, 14.56it/s, est. speed input: 15341.70 toks/s, output: 14.98 toks/s]
Processed prompts:  71%|   | 722/1024 [00:48<00:20, 14.52it/s, est. speed input: 15335.30 toks/s, output: 14.98 toks/s]
Processed prompts:  71%|  | 730/1024 [00:48<00:20, 14.50it/s, est. speed input: 15329.32 toks/s, output: 14.97 toks/s]
Processed prompts:  72%|  | 738/1024 [00:49<00:19, 14.54it/s, est. speed input: 15325.34 toks/s, output: 14.97 toks/s]
Processed prompts:  73%|  | 746/1024 [00:49<00:19, 14.52it/s, est. speed input: 15319.81 toks/s, output: 14.96 toks/s]
Processed prompts:  74%|  | 754/1024 [00:50<00:18, 14.55it/s, est. speed input: 15315.83 toks/s, output: 14.96 toks/s]
Processed prompts:  74%|  | 762/1024 [00:50<00:18, 14.51it/s, est. speed input: 15309.90 toks/s, output: 14.95 toks/s]
Processed prompts:  75%|  | 770/1024 [00:51<00:17, 14.54it/s, est. speed input: 15306.17 toks/s, output: 14.95 toks/s]
Processed prompts:  76%|  | 778/1024 [00:52<00:16, 14.51it/s, est. speed input: 15300.86 toks/s, output: 14.94 toks/s]
Processed prompts:  77%|  | 786/1024 [00:52<00:16, 14.55it/s, est. speed input: 15297.45 toks/s, output: 14.94 toks/s]
Processed prompts:  78%|  | 794/1024 [00:53<00:15, 14.53it/s, est. speed input: 15292.51 toks/s, output: 14.93 toks/s]
Processed prompts:  78%|  | 802/1024 [00:53<00:15, 14.57it/s, est. speed input: 15289.82 toks/s, output: 14.93 toks/s]
Processed prompts:  79%|  | 810/1024 [00:54<00:14, 14.53it/s, est. speed input: 15284.79 toks/s, output: 14.93 toks/s]
Processed prompts:  80%|  | 818/1024 [00:54<00:14, 14.55it/s, est. speed input: 15281.26 toks/s, output: 14.92 toks/s]
Processed prompts:  81%|  | 826/1024 [00:55<00:13, 14.54it/s, est. speed input: 15277.09 toks/s, output: 14.92 toks/s]
Processed prompts:  81%| | 834/1024 [00:55<00:13, 14.56it/s, est. speed input: 15274.13 toks/s, output: 14.92 toks/s]
Processed prompts:  82%| | 842/1024 [00:56<00:12, 14.57it/s, est. speed input: 15270.86 toks/s, output: 14.91 toks/s]
Processed prompts:  83%| | 850/1024 [00:57<00:11, 14.59it/s, est. speed input: 15268.05 toks/s, output: 14.91 toks/s]
Processed prompts:  84%| | 858/1024 [00:57<00:11, 14.56it/s, est. speed input: 15263.90 toks/s, output: 14.91 toks/s]
Processed prompts:  85%| | 866/1024 [00:58<00:10, 14.57it/s, est. speed input: 15260.94 toks/s, output: 14.90 toks/s]
Processed prompts:  85%| | 874/1024 [00:58<00:10, 14.53it/s, est. speed input: 15256.41 toks/s, output: 14.90 toks/s]
Processed prompts:  86%| | 882/1024 [00:59<00:09, 14.53it/s, est. speed input: 15252.99 toks/s, output: 14.90 toks/s]
Processed prompts:  87%| | 890/1024 [00:59<00:09, 14.49it/s, est. speed input: 15248.35 toks/s, output: 14.89 toks/s]
Processed prompts:  88%| | 898/1024 [01:00<00:08, 14.55it/s, est. speed input: 15246.35 toks/s, output: 14.89 toks/s]
Processed prompts:  88%| | 906/1024 [01:00<00:08, 14.51it/s, est. speed input: 15241.96 toks/s, output: 14.88 toks/s]
Processed prompts:  89%| | 914/1024 [01:01<00:07, 14.57it/s, est. speed input: 15240.48 toks/s, output: 14.88 toks/s]
Processed prompts:  90%| | 922/1024 [01:01<00:07, 14.54it/s, est. speed input: 15236.70 toks/s, output: 14.88 toks/s]
Processed prompts:  91%| | 930/1024 [01:02<00:06, 14.58it/s, est. speed input: 15234.76 toks/s, output: 14.88 toks/s]
Processed prompts:  92%|| 938/1024 [01:03<00:05, 15.04it/s, est. speed input: 15245.60 toks/s, output: 14.89 toks/s]
Processed prompts:  92%|| 946/1024 [01:03<00:05, 14.90it/s, est. speed input: 15242.82 toks/s, output: 14.89 toks/s]
Processed prompts:  93%|| 954/1024 [01:04<00:04, 14.73it/s, est. speed input: 15238.01 toks/s, output: 14.88 toks/s]
Processed prompts:  94%|| 962/1024 [01:04<00:04, 14.67it/s, est. speed input: 15235.01 toks/s, output: 14.88 toks/s]
Processed prompts:  95%|| 970/1024 [01:05<00:03, 14.62it/s, est. speed input: 15231.78 toks/s, output: 14.87 toks/s]
Processed prompts:  96%|| 978/1024 [01:05<00:03, 14.57it/s, est. speed input: 15228.17 toks/s, output: 14.87 toks/s]
Processed prompts:  96%|| 986/1024 [01:06<00:02, 15.14it/s, est. speed input: 15241.42 toks/s, output: 14.88 toks/s]
Processed prompts:  97%|| 994/1024 [01:06<00:01, 15.01it/s, est. speed input: 15240.13 toks/s, output: 14.88 toks/s]
Processed prompts:  98%|| 1002/1024 [01:07<00:01, 14.85it/s, est. speed input: 15236.83 toks/s, output: 14.88 toks/s]
Processed prompts:  99%|| 1010/1024 [01:07<00:00, 14.74it/s, est. speed input: 15233.60 toks/s, output: 14.88 toks/s]
Processed prompts:  99%|| 1018/1024 [01:08<00:00, 15.27it/s, est. speed input: 15246.41 toks/s, output: 14.89 toks/s]
Processed prompts: 100%|| 1024/1024 [01:08<00:00, 15.27it/s, est. speed input: 15336.22 toks/s, output: 14.98 toks/s]
Processed prompts: 100%|| 1024/1024 [01:08<00:00, 14.98it/s, est. speed input: 15336.22 toks/s, output: 14.98 toks/s]
[rank0]:[W128 08:02:47.901224078 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-28 08:02:50
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/BitNet-2B-INT8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 08:02:59 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 08:02:59 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3668383) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3668383) WARNING 01-28 08:03:27 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.69 requests/s, 15057.82 total tokens/s, 14.69 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-28 08:02:59] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 08:02:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:02:59] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:02:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:02:59] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:02:59] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:02:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:02:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:02:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:02:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:02:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:02:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:02:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:02:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 08:03:02] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 08:03:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:03:02] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:03:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:03:02] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:03:02] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:03:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:03:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:03:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:03:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:03:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:03:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:03:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:03:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3668383) [2026-01-28 08:03:03] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3668383) [2026-01-28 08:03:03] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3668383) [2026-01-28 08:03:03] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3668383) [2026-01-28 08:03:03] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3668383) [2026-01-28 08:03:03] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3668383) [2026-01-28 08:03:03] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3668383) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3668383) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.59s/it]
(EngineCore_DP0 pid=3668383) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.59s/it]
(EngineCore_DP0 pid=3668383) 
(EngineCore_DP0 pid=3668383) [2026-01-28 08:03:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3668383) [2026-01-28 08:03:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9891840 bytes
(EngineCore_DP0 pid=3668383) [2026-01-28 08:03:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3668383) [2026-01-28 08:03:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6594560 bytes
(EngineCore_DP0 pid=3668383) [2026-01-28 08:03:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3668383) [2026-01-28 08:03:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 35610624 bytes
(EngineCore_DP0 pid=3668383) [2026-01-28 08:03:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3668383) [2026-01-28 08:03:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=3668383) 2026-01-28 08:03:25,651 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3668383) 2026-01-28 08:03:25,762 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 61/2048 [00:00<00:03, 607.24it/s]
Adding requests:   6%|         | 122/2048 [00:00<00:03, 579.90it/s]
Adding requests:   9%|         | 181/2048 [00:00<00:03, 547.10it/s]
Adding requests:  12%|        | 237/2048 [00:00<00:03, 549.54it/s]
Adding requests:  14%|        | 293/2048 [00:00<00:03, 536.28it/s]
Adding requests:  17%|        | 347/2048 [00:00<00:03, 528.22it/s]
Adding requests:  20%|        | 402/2048 [00:00<00:03, 534.13it/s]
Adding requests:  22%|       | 458/2048 [00:00<00:02, 539.86it/s]
Adding requests:  25%|       | 513/2048 [00:00<00:02, 530.30it/s]
Adding requests:  28%|       | 567/2048 [00:01<00:02, 533.14it/s]
Adding requests:  30%|       | 623/2048 [00:01<00:02, 538.33it/s]
Adding requests:  33%|      | 679/2048 [00:01<00:02, 542.56it/s]
Adding requests:  36%|      | 734/2048 [00:01<00:02, 544.41it/s]
Adding requests:  39%|      | 789/2048 [00:01<00:02, 514.80it/s]
Adding requests:  41%|      | 841/2048 [00:01<00:02, 509.00it/s]
Adding requests:  44%|     | 893/2048 [00:02<00:05, 213.17it/s]
Adding requests:  46%|     | 946/2048 [00:02<00:04, 258.74it/s]
Adding requests:  49%|     | 999/2048 [00:02<00:03, 304.44it/s]
Adding requests:  51%|    | 1051/2048 [00:02<00:02, 346.58it/s]
Adding requests:  54%|    | 1104/2048 [00:02<00:02, 385.87it/s]
Adding requests:  56%|    | 1156/2048 [00:02<00:02, 416.55it/s]
Adding requests:  59%|    | 1212/2048 [00:02<00:01, 452.78it/s]
Adding requests:  62%|   | 1264/2048 [00:02<00:01, 464.22it/s]
Adding requests:  64%|   | 1318/2048 [00:02<00:01, 484.26it/s]
Adding requests:  67%|   | 1373/2048 [00:03<00:01, 500.85it/s]
Adding requests:  70%|   | 1430/2048 [00:03<00:01, 517.25it/s]
Adding requests:  73%|  | 1485/2048 [00:03<00:01, 526.35it/s]
Adding requests:  75%|  | 1539/2048 [00:03<00:00, 526.37it/s]
Adding requests:  78%|  | 1596/2048 [00:03<00:00, 537.83it/s]
Adding requests:  81%|  | 1651/2048 [00:03<00:00, 531.82it/s]
Adding requests:  83%| | 1705/2048 [00:03<00:00, 526.62it/s]
Adding requests:  86%| | 1759/2048 [00:03<00:00, 530.30it/s]
Adding requests:  89%| | 1814/2048 [00:03<00:00, 534.30it/s]
Adding requests:  91%| | 1868/2048 [00:04<00:00, 527.02it/s]
Adding requests:  94%|| 1922/2048 [00:04<00:00, 529.21it/s]
Adding requests:  96%|| 1976/2048 [00:04<00:00, 528.45it/s]
Adding requests:  99%|| 2029/2048 [00:04<00:00, 514.23it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 470.41it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 50/2048 [00:00<00:08, 224.14it/s, est. speed input: 229545.07 toks/s, output: 224.15 toks/s]
Processed prompts:   4%|         | 73/2048 [00:01<00:42, 46.56it/s, est. speed input: 56949.72 toks/s, output: 55.61 toks/s]   
Processed prompts:   4%|         | 84/2048 [00:02<01:14, 26.25it/s, est. speed input: 35743.17 toks/s, output: 34.91 toks/s]
Processed prompts:   5%|         | 98/2048 [00:03<01:36, 20.29it/s, est. speed input: 28664.06 toks/s, output: 27.99 toks/s]
Processed prompts:   6%|         | 114/2048 [00:04<01:46, 18.12it/s, est. speed input: 25427.66 toks/s, output: 24.83 toks/s]
Processed prompts:   6%|         | 130/2048 [00:05<01:53, 16.88it/s, est. speed input: 23418.91 toks/s, output: 22.87 toks/s]
Processed prompts:   7%|         | 146/2048 [00:06<01:57, 16.12it/s, est. speed input: 22061.36 toks/s, output: 21.54 toks/s]
Processed prompts:   8%|         | 162/2048 [00:07<02:00, 15.66it/s, est. speed input: 21091.19 toks/s, output: 20.60 toks/s]
Processed prompts:   9%|         | 178/2048 [00:08<02:01, 15.35it/s, est. speed input: 20354.68 toks/s, output: 19.88 toks/s]
Processed prompts:   9%|         | 194/2048 [00:10<02:02, 15.15it/s, est. speed input: 19782.58 toks/s, output: 19.32 toks/s]
Processed prompts:  10%|         | 210/2048 [00:11<02:02, 15.00it/s, est. speed input: 19314.07 toks/s, output: 18.86 toks/s]
Processed prompts:  11%|         | 226/2048 [00:12<02:02, 14.91it/s, est. speed input: 18935.54 toks/s, output: 18.49 toks/s]
Processed prompts:  12%|        | 242/2048 [00:13<02:01, 14.84it/s, est. speed input: 18616.27 toks/s, output: 18.18 toks/s]
Processed prompts:  13%|        | 258/2048 [00:14<02:00, 14.79it/s, est. speed input: 18345.42 toks/s, output: 17.92 toks/s]
Processed prompts:  13%|        | 274/2048 [00:15<02:00, 14.75it/s, est. speed input: 18109.36 toks/s, output: 17.68 toks/s]
Processed prompts:  14%|        | 290/2048 [00:16<01:59, 14.73it/s, est. speed input: 17907.03 toks/s, output: 17.49 toks/s]
Processed prompts:  15%|        | 306/2048 [00:17<01:58, 14.72it/s, est. speed input: 17730.28 toks/s, output: 17.31 toks/s]
Processed prompts:  16%|        | 322/2048 [00:18<01:57, 14.70it/s, est. speed input: 17572.16 toks/s, output: 17.16 toks/s]
Processed prompts:  17%|        | 338/2048 [00:19<01:55, 14.86it/s, est. speed input: 17468.46 toks/s, output: 17.06 toks/s]
Processed prompts:  17%|        | 354/2048 [00:20<01:54, 14.81it/s, est. speed input: 17342.52 toks/s, output: 16.94 toks/s]
Processed prompts:  18%|        | 370/2048 [00:21<01:53, 14.77it/s, est. speed input: 17227.31 toks/s, output: 16.82 toks/s]
Processed prompts:  19%|        | 386/2048 [00:23<01:52, 14.72it/s, est. speed input: 17120.63 toks/s, output: 16.72 toks/s]
Processed prompts:  20%|        | 402/2048 [00:24<01:51, 14.70it/s, est. speed input: 17024.02 toks/s, output: 16.62 toks/s]
Processed prompts:  20%|        | 418/2048 [00:25<01:51, 14.68it/s, est. speed input: 16935.42 toks/s, output: 16.54 toks/s]
Processed prompts:  21%|        | 434/2048 [00:26<01:50, 14.67it/s, est. speed input: 16855.34 toks/s, output: 16.46 toks/s]
Processed prompts:  22%|       | 450/2048 [00:27<01:47, 14.92it/s, est. speed input: 16820.17 toks/s, output: 16.43 toks/s]
Processed prompts:  23%|       | 466/2048 [00:28<01:46, 14.83it/s, est. speed input: 16749.66 toks/s, output: 16.36 toks/s]
Processed prompts:  24%|       | 482/2048 [00:29<01:45, 14.79it/s, est. speed input: 16686.47 toks/s, output: 16.30 toks/s]
Processed prompts:  24%|       | 498/2048 [00:30<01:45, 14.74it/s, est. speed input: 16626.09 toks/s, output: 16.24 toks/s]
Processed prompts:  25%|       | 514/2048 [00:31<01:44, 14.71it/s, est. speed input: 16569.94 toks/s, output: 16.18 toks/s]
Processed prompts:  26%|       | 530/2048 [00:32<01:43, 14.69it/s, est. speed input: 16517.35 toks/s, output: 16.13 toks/s]
Processed prompts:  27%|       | 546/2048 [00:33<01:42, 14.67it/s, est. speed input: 16467.66 toks/s, output: 16.08 toks/s]
Processed prompts:  27%|       | 562/2048 [00:35<01:41, 14.66it/s, est. speed input: 16421.10 toks/s, output: 16.04 toks/s]
Processed prompts:  28%|       | 578/2048 [00:36<01:40, 14.66it/s, est. speed input: 16378.26 toks/s, output: 15.99 toks/s]
Processed prompts:  29%|       | 594/2048 [00:37<01:39, 14.64it/s, est. speed input: 16336.11 toks/s, output: 15.95 toks/s]
Processed prompts:  30%|       | 610/2048 [00:38<01:38, 14.63it/s, est. speed input: 16296.83 toks/s, output: 15.91 toks/s]
Processed prompts:  31%|       | 626/2048 [00:39<01:37, 14.63it/s, est. speed input: 16260.06 toks/s, output: 15.88 toks/s]
Processed prompts:  31%|      | 642/2048 [00:40<01:36, 14.63it/s, est. speed input: 16225.72 toks/s, output: 15.85 toks/s]
Processed prompts:  32%|      | 658/2048 [00:41<01:34, 14.63it/s, est. speed input: 16193.43 toks/s, output: 15.81 toks/s]
Processed prompts:  33%|      | 674/2048 [00:42<01:33, 14.63it/s, est. speed input: 16161.83 toks/s, output: 15.78 toks/s]
Processed prompts:  34%|      | 690/2048 [00:43<01:32, 14.63it/s, est. speed input: 16132.71 toks/s, output: 15.75 toks/s]
Processed prompts:  34%|      | 706/2048 [00:44<01:31, 14.65it/s, est. speed input: 16106.45 toks/s, output: 15.73 toks/s]
Processed prompts:  35%|      | 722/2048 [00:45<01:30, 14.64it/s, est. speed input: 16079.51 toks/s, output: 15.70 toks/s]
Processed prompts:  36%|      | 738/2048 [00:47<01:29, 14.62it/s, est. speed input: 16052.12 toks/s, output: 15.68 toks/s]
Processed prompts:  37%|      | 754/2048 [00:48<01:28, 14.62it/s, est. speed input: 16027.93 toks/s, output: 15.65 toks/s]
Processed prompts:  38%|      | 770/2048 [00:49<01:27, 14.63it/s, est. speed input: 16005.47 toks/s, output: 15.63 toks/s]
Processed prompts:  38%|      | 786/2048 [00:50<01:26, 14.63it/s, est. speed input: 15983.04 toks/s, output: 15.61 toks/s]
Processed prompts:  39%|      | 802/2048 [00:51<01:25, 14.63it/s, est. speed input: 15961.66 toks/s, output: 15.59 toks/s]
Processed prompts:  40%|      | 818/2048 [00:52<01:24, 14.64it/s, est. speed input: 15941.79 toks/s, output: 15.57 toks/s]
Processed prompts:  41%|      | 834/2048 [00:53<01:23, 14.62it/s, est. speed input: 15921.26 toks/s, output: 15.55 toks/s]
Processed prompts:  42%|     | 850/2048 [00:54<01:21, 14.62it/s, est. speed input: 15902.13 toks/s, output: 15.53 toks/s]
Processed prompts:  42%|     | 866/2048 [00:55<01:20, 14.63it/s, est. speed input: 15884.46 toks/s, output: 15.51 toks/s]
Processed prompts:  43%|     | 882/2048 [00:56<01:19, 14.62it/s, est. speed input: 15866.32 toks/s, output: 15.49 toks/s]
Processed prompts:  44%|     | 898/2048 [00:58<01:18, 14.63it/s, est. speed input: 15849.94 toks/s, output: 15.48 toks/s]
Processed prompts:  45%|     | 914/2048 [00:59<01:17, 14.62it/s, est. speed input: 15833.40 toks/s, output: 15.46 toks/s]
Processed prompts:  45%|     | 930/2048 [01:00<01:15, 14.88it/s, est. speed input: 15834.70 toks/s, output: 15.46 toks/s]
Processed prompts:  46%|     | 946/2048 [01:01<01:14, 14.81it/s, est. speed input: 15819.41 toks/s, output: 15.45 toks/s]
Processed prompts:  47%|     | 962/2048 [01:02<01:13, 14.74it/s, est. speed input: 15804.24 toks/s, output: 15.43 toks/s]
Processed prompts:  48%|     | 978/2048 [01:03<01:11, 14.99it/s, est. speed input: 15806.86 toks/s, output: 15.44 toks/s]
Processed prompts:  49%|     | 994/2048 [01:04<01:10, 14.89it/s, est. speed input: 15793.75 toks/s, output: 15.42 toks/s]
Processed prompts:  49%|     | 1010/2048 [01:05<01:10, 14.80it/s, est. speed input: 15779.44 toks/s, output: 15.41 toks/s]
Processed prompts:  50%|     | 1026/2048 [01:06<01:09, 14.74it/s, est. speed input: 15765.68 toks/s, output: 15.40 toks/s]
Processed prompts:  51%|     | 1042/2048 [01:07<01:08, 14.70it/s, est. speed input: 15752.55 toks/s, output: 15.38 toks/s]
Processed prompts:  52%|    | 1058/2048 [01:08<01:07, 14.67it/s, est. speed input: 15739.80 toks/s, output: 15.37 toks/s]
Processed prompts:  52%|    | 1074/2048 [01:09<01:06, 14.66it/s, est. speed input: 15727.85 toks/s, output: 15.36 toks/s]
Processed prompts:  53%|    | 1090/2048 [01:11<01:05, 14.66it/s, est. speed input: 15716.94 toks/s, output: 15.35 toks/s]
Processed prompts:  54%|    | 1106/2048 [01:12<01:04, 14.64it/s, est. speed input: 15705.37 toks/s, output: 15.34 toks/s]
Processed prompts:  55%|    | 1122/2048 [01:13<01:03, 14.64it/s, est. speed input: 15694.79 toks/s, output: 15.33 toks/s]
Processed prompts:  56%|    | 1138/2048 [01:14<01:02, 14.64it/s, est. speed input: 15684.16 toks/s, output: 15.32 toks/s]
Processed prompts:  56%|    | 1154/2048 [01:15<01:00, 14.88it/s, est. speed input: 15686.49 toks/s, output: 15.32 toks/s]
Processed prompts:  57%|    | 1170/2048 [01:16<00:59, 14.79it/s, est. speed input: 15675.84 toks/s, output: 15.31 toks/s]
Processed prompts:  58%|    | 1186/2048 [01:17<00:58, 14.73it/s, est. speed input: 15665.49 toks/s, output: 15.30 toks/s]
Processed prompts:  59%|    | 1202/2048 [01:18<00:57, 14.69it/s, est. speed input: 15655.60 toks/s, output: 15.29 toks/s]
Processed prompts:  59%|    | 1218/2048 [01:19<00:56, 14.67it/s, est. speed input: 15646.02 toks/s, output: 15.28 toks/s]
Processed prompts:  60%|    | 1234/2048 [01:20<00:55, 14.65it/s, est. speed input: 15636.69 toks/s, output: 15.27 toks/s]
Processed prompts:  61%|    | 1250/2048 [01:21<00:54, 14.64it/s, est. speed input: 15627.80 toks/s, output: 15.26 toks/s]
Processed prompts:  62%|   | 1266/2048 [01:22<00:52, 14.88it/s, est. speed input: 15630.56 toks/s, output: 15.26 toks/s]
Processed prompts:  63%|   | 1282/2048 [01:24<00:51, 14.81it/s, est. speed input: 15622.19 toks/s, output: 15.26 toks/s]
Processed prompts:  63%|   | 1298/2048 [01:25<00:49, 15.02it/s, est. speed input: 15625.56 toks/s, output: 15.26 toks/s]
Processed prompts:  64%|   | 1314/2048 [01:26<00:49, 14.89it/s, est. speed input: 15616.91 toks/s, output: 15.25 toks/s]
Processed prompts:  65%|   | 1330/2048 [01:27<00:48, 14.80it/s, est. speed input: 15608.69 toks/s, output: 15.24 toks/s]
Processed prompts:  66%|   | 1346/2048 [01:28<00:47, 14.74it/s, est. speed input: 15600.53 toks/s, output: 15.23 toks/s]
Processed prompts:  67%|   | 1362/2048 [01:29<00:46, 14.71it/s, est. speed input: 15592.93 toks/s, output: 15.23 toks/s]
Processed prompts:  67%|   | 1378/2048 [01:30<00:45, 14.68it/s, est. speed input: 15585.26 toks/s, output: 15.22 toks/s]
Processed prompts:  68%|   | 1394/2048 [01:31<00:44, 14.65it/s, est. speed input: 15577.52 toks/s, output: 15.21 toks/s]
Processed prompts:  69%|   | 1410/2048 [01:32<00:43, 14.63it/s, est. speed input: 15569.85 toks/s, output: 15.20 toks/s]
Processed prompts:  70%|   | 1426/2048 [01:33<00:42, 14.61it/s, est. speed input: 15562.20 toks/s, output: 15.20 toks/s]
Processed prompts:  70%|   | 1442/2048 [01:34<00:41, 14.62it/s, est. speed input: 15555.50 toks/s, output: 15.19 toks/s]
Processed prompts:  71%|   | 1458/2048 [01:36<00:40, 14.62it/s, est. speed input: 15548.91 toks/s, output: 15.18 toks/s]
Processed prompts:  72%|  | 1474/2048 [01:37<00:39, 14.60it/s, est. speed input: 15541.69 toks/s, output: 15.18 toks/s]
Processed prompts:  73%|  | 1490/2048 [01:38<00:38, 14.59it/s, est. speed input: 15534.60 toks/s, output: 15.17 toks/s]
Processed prompts:  74%|  | 1506/2048 [01:39<00:37, 14.60it/s, est. speed input: 15528.32 toks/s, output: 15.16 toks/s]
Processed prompts:  74%|  | 1522/2048 [01:40<00:36, 14.60it/s, est. speed input: 15522.07 toks/s, output: 15.16 toks/s]
Processed prompts:  75%|  | 1538/2048 [01:41<00:34, 14.60it/s, est. speed input: 15516.06 toks/s, output: 15.15 toks/s]
Processed prompts:  76%|  | 1554/2048 [01:42<00:33, 14.60it/s, est. speed input: 15509.96 toks/s, output: 15.15 toks/s]
Processed prompts:  77%|  | 1570/2048 [01:43<00:32, 14.61it/s, est. speed input: 15504.36 toks/s, output: 15.14 toks/s]
Processed prompts:  77%|  | 1586/2048 [01:44<00:31, 14.89it/s, est. speed input: 15508.76 toks/s, output: 15.15 toks/s]
Processed prompts:  78%|  | 1602/2048 [01:45<00:30, 14.81it/s, est. speed input: 15503.24 toks/s, output: 15.14 toks/s]
Processed prompts:  79%|  | 1618/2048 [01:46<00:29, 14.76it/s, est. speed input: 15498.11 toks/s, output: 15.13 toks/s]
Processed prompts:  80%|  | 1634/2048 [01:47<00:28, 14.73it/s, est. speed input: 15493.07 toks/s, output: 15.13 toks/s]
Processed prompts:  81%|  | 1650/2048 [01:49<00:26, 14.96it/s, est. speed input: 15497.08 toks/s, output: 15.13 toks/s]
Processed prompts:  81%| | 1666/2048 [01:50<00:25, 14.85it/s, est. speed input: 15491.48 toks/s, output: 15.13 toks/s]
Processed prompts:  82%| | 1682/2048 [01:51<00:24, 14.76it/s, est. speed input: 15485.66 toks/s, output: 15.12 toks/s]
Processed prompts:  83%| | 1698/2048 [01:52<00:23, 14.71it/s, est. speed input: 15480.52 toks/s, output: 15.12 toks/s]
Processed prompts:  84%| | 1714/2048 [01:53<00:22, 14.68it/s, est. speed input: 15475.45 toks/s, output: 15.11 toks/s]
Processed prompts:  84%| | 1730/2048 [01:54<00:21, 14.67it/s, est. speed input: 15470.92 toks/s, output: 15.11 toks/s]
Processed prompts:  85%| | 1746/2048 [01:55<00:20, 14.66it/s, est. speed input: 15466.42 toks/s, output: 15.10 toks/s]
Processed prompts:  86%| | 1762/2048 [01:56<00:19, 14.63it/s, est. speed input: 15461.25 toks/s, output: 15.10 toks/s]
Processed prompts:  87%| | 1778/2048 [01:57<00:18, 14.62it/s, est. speed input: 15456.25 toks/s, output: 15.09 toks/s]
Processed prompts:  88%| | 1794/2048 [01:58<00:17, 14.62it/s, est. speed input: 15451.94 toks/s, output: 15.09 toks/s]
Processed prompts:  88%| | 1810/2048 [01:59<00:16, 14.61it/s, est. speed input: 15447.26 toks/s, output: 15.09 toks/s]
Processed prompts:  89%| | 1826/2048 [02:01<00:15, 14.61it/s, est. speed input: 15442.68 toks/s, output: 15.08 toks/s]
Processed prompts:  90%| | 1842/2048 [02:02<00:14, 14.60it/s, est. speed input: 15438.21 toks/s, output: 15.08 toks/s]
Processed prompts:  91%| | 1858/2048 [02:03<00:13, 14.61it/s, est. speed input: 15434.01 toks/s, output: 15.07 toks/s]
Processed prompts:  92%|| 1874/2048 [02:04<00:11, 14.86it/s, est. speed input: 15437.64 toks/s, output: 15.08 toks/s]
Processed prompts:  92%|| 1890/2048 [02:05<00:10, 14.78it/s, est. speed input: 15433.43 toks/s, output: 15.07 toks/s]
Processed prompts:  93%|| 1906/2048 [02:06<00:09, 14.73it/s, est. speed input: 15429.30 toks/s, output: 15.07 toks/s]
Processed prompts:  94%|| 1922/2048 [02:07<00:08, 14.70it/s, est. speed input: 15425.39 toks/s, output: 15.06 toks/s]
Processed prompts:  95%|| 1938/2048 [02:08<00:07, 14.68it/s, est. speed input: 15421.64 toks/s, output: 15.06 toks/s]
Processed prompts:  95%|| 1954/2048 [02:09<00:06, 14.93it/s, est. speed input: 15425.66 toks/s, output: 15.06 toks/s]
Processed prompts:  96%|| 1970/2048 [02:10<00:05, 14.84it/s, est. speed input: 15421.98 toks/s, output: 15.06 toks/s]
Processed prompts:  97%|| 1986/2048 [02:11<00:04, 15.05it/s, est. speed input: 15425.93 toks/s, output: 15.06 toks/s]
Processed prompts:  98%|| 2002/2048 [02:12<00:03, 14.91it/s, est. speed input: 15421.98 toks/s, output: 15.06 toks/s]
Processed prompts:  99%|| 2018/2048 [02:14<00:02, 14.82it/s, est. speed input: 15418.34 toks/s, output: 15.06 toks/s]
Processed prompts:  99%|| 2034/2048 [02:15<00:00, 15.03it/s, est. speed input: 15422.16 toks/s, output: 15.06 toks/s]
Processed prompts: 100%|| 2048/2048 [02:15<00:00, 15.03it/s, est. speed input: 15528.28 toks/s, output: 15.16 toks/s]
Processed prompts: 100%|| 2048/2048 [02:15<00:00, 15.16it/s, est. speed input: 15528.28 toks/s, output: 15.16 toks/s]
[rank0]:[W128 08:05:47.352386565 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-28 08:05:49
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_INT8_py312_cu129_aarch64/cusparselt/2_6/json/BitNet-2B-INT8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 08:06:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 08:06:04 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3671118) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3671118) WARNING 01-28 08:06:34 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.91 requests/s, 15282.95 total tokens/s, 14.91 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-28 08:06:04] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 08:06:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:06:04] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:06:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:06:04] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:06:04] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:06:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:06:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:06:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:06:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:06:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:06:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:06:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:06:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 08:06:07] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 08:06:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 08:06:07] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 08:06:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:06:07] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:06:07] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:06:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:06:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 08:06:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 08:06:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 08:06:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 08:06:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 08:06:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 08:06:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3671118) [2026-01-28 08:06:08] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3671118) [2026-01-28 08:06:08] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3671118) [2026-01-28 08:06:08] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3671118) [2026-01-28 08:06:08] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3671118) [2026-01-28 08:06:08] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3671118) [2026-01-28 08:06:08] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3671118) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3671118) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.20s/it]
(EngineCore_DP0 pid=3671118) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.20s/it]
(EngineCore_DP0 pid=3671118) 
(EngineCore_DP0 pid=3671118) [2026-01-28 08:06:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3671118) [2026-01-28 08:06:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9891840 bytes
(EngineCore_DP0 pid=3671118) [2026-01-28 08:06:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3671118) [2026-01-28 08:06:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 6594560 bytes
(EngineCore_DP0 pid=3671118) [2026-01-28 08:06:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3671118) [2026-01-28 08:06:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 35610624 bytes
(EngineCore_DP0 pid=3671118) [2026-01-28 08:06:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3671118) [2026-01-28 08:06:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 17694720 bytes
(EngineCore_DP0 pid=3671118) 2026-01-28 08:06:31,579 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3671118) 2026-01-28 08:06:31,960 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   2%|         | 66/4096 [00:00<00:06, 658.69it/s]
Adding requests:   3%|         | 132/4096 [00:00<00:06, 625.67it/s]
Adding requests:   5%|         | 195/4096 [00:00<00:07, 557.23it/s]
Adding requests:   6%|         | 252/4096 [00:00<00:07, 544.96it/s]
Adding requests:   7%|         | 307/4096 [00:00<00:07, 529.95it/s]
Adding requests:   9%|         | 361/4096 [00:00<00:07, 525.05it/s]
Adding requests:  10%|         | 414/4096 [00:00<00:07, 516.09it/s]
Adding requests:  11%|        | 468/4096 [00:00<00:06, 520.04it/s]
Adding requests:  13%|        | 521/4096 [00:00<00:07, 508.80it/s]
Adding requests:  14%|        | 576/4096 [00:01<00:06, 519.78it/s]
Adding requests:  15%|        | 629/4096 [00:01<00:06, 518.18it/s]
Adding requests:  17%|        | 685/4096 [00:01<00:06, 529.93it/s]
Adding requests:  18%|        | 739/4096 [00:01<00:06, 528.73it/s]
Adding requests:  19%|        | 792/4096 [00:01<00:06, 519.20it/s]
Adding requests:  21%|        | 844/4096 [00:01<00:06, 505.61it/s]
Adding requests:  22%|       | 899/4096 [00:01<00:06, 516.43it/s]
Adding requests:  23%|       | 951/4096 [00:01<00:06, 516.65it/s]
Adding requests:  25%|       | 1004/4096 [00:01<00:05, 518.54it/s]
Adding requests:  26%|       | 1058/4096 [00:02<00:05, 523.44it/s]
Adding requests:  27%|       | 1111/4096 [00:02<00:05, 515.47it/s]
Adding requests:  28%|       | 1164/4096 [00:02<00:05, 518.30it/s]
Adding requests:  30%|       | 1216/4096 [00:02<00:05, 483.63it/s]
Adding requests:  31%|       | 1267/4096 [00:02<00:05, 488.99it/s]
Adding requests:  32%|      | 1317/4096 [00:02<00:05, 490.61it/s]
Adding requests:  33%|      | 1371/4096 [00:02<00:05, 503.34it/s]
Adding requests:  35%|      | 1424/4096 [00:02<00:05, 509.96it/s]
Adding requests:  36%|      | 1479/4096 [00:02<00:05, 520.58it/s]
Adding requests:  38%|      | 1536/4096 [00:02<00:04, 533.20it/s]
Adding requests:  39%|      | 1590/4096 [00:03<00:04, 534.66it/s]
Adding requests:  40%|      | 1644/4096 [00:03<00:04, 536.02it/s]
Adding requests:  41%|     | 1698/4096 [00:03<00:04, 534.58it/s]
Adding requests:  43%|     | 1752/4096 [00:03<00:04, 535.71it/s]
Adding requests:  44%|     | 1807/4096 [00:03<00:04, 537.78it/s]
Adding requests:  45%|     | 1861/4096 [00:03<00:04, 535.07it/s]
Adding requests:  47%|     | 1915/4096 [00:03<00:04, 530.88it/s]
Adding requests:  48%|     | 1969/4096 [00:03<00:04, 526.62it/s]
Adding requests:  49%|     | 2024/4096 [00:03<00:03, 532.89it/s]
Adding requests:  51%|     | 2078/4096 [00:03<00:03, 534.17it/s]
Adding requests:  52%|    | 2132/4096 [00:04<00:03, 531.22it/s]
Adding requests:  53%|    | 2186/4096 [00:04<00:03, 521.55it/s]
Adding requests:  55%|    | 2239/4096 [00:04<00:03, 520.82it/s]
Adding requests:  56%|    | 2295/4096 [00:04<00:03, 530.89it/s]
Adding requests:  57%|    | 2349/4096 [00:04<00:03, 523.03it/s]
Adding requests:  59%|    | 2402/4096 [00:04<00:03, 518.82it/s]
Adding requests:  60%|    | 2454/4096 [00:04<00:03, 482.47it/s]
Adding requests:  61%|   | 2509/4096 [00:04<00:03, 499.39it/s]
Adding requests:  63%|   | 2562/4096 [00:04<00:03, 505.38it/s]
Adding requests:  64%|   | 2615/4096 [00:05<00:02, 510.58it/s]
Adding requests:  65%|   | 2672/4096 [00:05<00:02, 526.74it/s]
Adding requests:  67%|   | 2725/4096 [00:05<00:02, 522.84it/s]
Adding requests:  68%|   | 2778/4096 [00:05<00:02, 524.79it/s]
Adding requests:  69%|   | 2831/4096 [00:05<00:02, 523.92it/s]
Adding requests:  70%|   | 2886/4096 [00:05<00:02, 531.59it/s]
Adding requests:  72%|  | 2940/4096 [00:05<00:02, 524.58it/s]
Adding requests:  73%|  | 2994/4096 [00:05<00:02, 528.97it/s]
Adding requests:  74%|  | 3047/4096 [00:05<00:01, 528.53it/s]
Adding requests:  76%|  | 3100/4096 [00:05<00:01, 519.80it/s]
Adding requests:  77%|  | 3153/4096 [00:06<00:01, 515.93it/s]
Adding requests:  78%|  | 3206/4096 [00:06<00:01, 518.63it/s]
Adding requests:  80%|  | 3260/4096 [00:06<00:01, 524.23it/s]
Adding requests:  81%|  | 3314/4096 [00:06<00:01, 525.93it/s]
Adding requests:  82%| | 3367/4096 [00:06<00:01, 517.00it/s]
Adding requests:  83%| | 3420/4096 [00:06<00:01, 518.31it/s]
Adding requests:  85%| | 3472/4096 [00:06<00:01, 505.69it/s]
Adding requests:  86%| | 3524/4096 [00:06<00:01, 508.40it/s]
Adding requests:  87%| | 3575/4096 [00:06<00:01, 506.32it/s]
Adding requests:  89%| | 3627/4096 [00:06<00:00, 507.54it/s]
Adding requests:  90%| | 3683/4096 [00:07<00:00, 520.10it/s]
Adding requests:  91%| | 3736/4096 [00:07<00:00, 520.09it/s]
Adding requests:  93%|| 3789/4096 [00:07<00:00, 512.53it/s]
Adding requests:  94%|| 3841/4096 [00:07<00:00, 503.84it/s]
Adding requests:  95%|| 3894/4096 [00:07<00:00, 510.77it/s]
Adding requests:  96%|| 3946/4096 [00:07<00:00, 510.61it/s]
Adding requests:  98%|| 3999/4096 [00:07<00:00, 514.95it/s]
Adding requests:  99%|| 4051/4096 [00:07<00:00, 515.89it/s]
Adding requests: 100%|| 4096/4096 [00:07<00:00, 520.35it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 98/4096 [00:01<00:41, 96.16it/s, est. speed input: 98475.79 toks/s, output: 96.16 toks/s]
Processed prompts:   3%|         | 130/4096 [00:03<01:53, 35.05it/s, est. speed input: 41917.30 toks/s, output: 40.93 toks/s]
Processed prompts:   4%|         | 162/4096 [00:05<02:40, 24.58it/s, est. speed input: 31104.36 toks/s, output: 30.38 toks/s]
Processed prompts:   5%|         | 194/4096 [00:07<03:10, 20.44it/s, est. speed input: 26524.95 toks/s, output: 25.90 toks/s]
Processed prompts:   6%|         | 226/4096 [00:09<03:31, 18.32it/s, est. speed input: 23991.74 toks/s, output: 23.43 toks/s]
Processed prompts:   6%|         | 258/4096 [00:11<03:44, 17.11it/s, est. speed input: 22390.80 toks/s, output: 21.87 toks/s]
Processed prompts:   7%|         | 290/4096 [00:13<03:52, 16.35it/s, est. speed input: 21279.58 toks/s, output: 20.78 toks/s]
Processed prompts:   8%|         | 322/4096 [00:16<03:56, 15.98it/s, est. speed input: 20527.61 toks/s, output: 20.05 toks/s]
Processed prompts:   9%|         | 354/4096 [00:18<03:59, 15.62it/s, est. speed input: 19895.13 toks/s, output: 19.43 toks/s]
Processed prompts:   9%|         | 386/4096 [00:20<04:01, 15.37it/s, est. speed input: 19396.95 toks/s, output: 18.94 toks/s]
Processed prompts:  10%|         | 418/4096 [00:22<04:01, 15.21it/s, est. speed input: 18993.78 toks/s, output: 18.55 toks/s]
Processed prompts:  11%|         | 450/4096 [00:24<03:59, 15.21it/s, est. speed input: 18701.39 toks/s, output: 18.26 toks/s]
Processed prompts:  12%|        | 482/4096 [00:26<03:59, 15.09it/s, est. speed input: 18416.65 toks/s, output: 17.98 toks/s]
Processed prompts:  13%|        | 514/4096 [00:28<03:58, 14.99it/s, est. speed input: 18172.07 toks/s, output: 17.75 toks/s]
Processed prompts:  13%|        | 546/4096 [00:31<03:57, 14.93it/s, est. speed input: 17962.06 toks/s, output: 17.54 toks/s]
Processed prompts:  14%|        | 578/4096 [00:33<03:56, 14.90it/s, est. speed input: 17782.03 toks/s, output: 17.37 toks/s]
Processed prompts:  15%|        | 610/4096 [00:35<03:54, 14.88it/s, est. speed input: 17623.31 toks/s, output: 17.21 toks/s]
Processed prompts:  16%|        | 642/4096 [00:37<03:52, 14.85it/s, est. speed input: 17480.97 toks/s, output: 17.07 toks/s]
Processed prompts:  16%|        | 674/4096 [00:39<03:50, 14.85it/s, est. speed input: 17357.26 toks/s, output: 16.95 toks/s]
Processed prompts:  17%|        | 706/4096 [00:41<03:48, 14.83it/s, est. speed input: 17243.35 toks/s, output: 16.84 toks/s]
Processed prompts:  18%|        | 738/4096 [00:44<03:46, 14.83it/s, est. speed input: 17142.42 toks/s, output: 16.74 toks/s]
Processed prompts:  19%|        | 770/4096 [00:46<03:44, 14.82it/s, est. speed input: 17049.80 toks/s, output: 16.65 toks/s]
Processed prompts:  20%|        | 802/4096 [00:48<03:42, 14.81it/s, est. speed input: 16964.24 toks/s, output: 16.57 toks/s]
Processed prompts:  20%|        | 834/4096 [00:50<03:40, 14.80it/s, est. speed input: 16886.13 toks/s, output: 16.49 toks/s]
Processed prompts:  21%|        | 866/4096 [00:52<03:38, 14.81it/s, est. speed input: 16816.79 toks/s, output: 16.42 toks/s]
Processed prompts:  22%|       | 898/4096 [00:54<03:35, 14.81it/s, est. speed input: 16752.22 toks/s, output: 16.36 toks/s]
Processed prompts:  23%|       | 930/4096 [00:56<03:31, 14.94it/s, est. speed input: 16709.82 toks/s, output: 16.32 toks/s]
Processed prompts:  23%|       | 962/4096 [00:59<03:28, 15.03it/s, est. speed input: 16670.92 toks/s, output: 16.28 toks/s]
Processed prompts:  24%|       | 994/4096 [01:01<03:27, 14.96it/s, est. speed input: 16617.91 toks/s, output: 16.23 toks/s]
Processed prompts:  25%|       | 1026/4096 [01:03<03:25, 14.90it/s, est. speed input: 16566.65 toks/s, output: 16.18 toks/s]
Processed prompts:  26%|       | 1058/4096 [01:05<03:24, 14.87it/s, est. speed input: 16520.05 toks/s, output: 16.13 toks/s]
Processed prompts:  27%|       | 1090/4096 [01:07<03:22, 14.86it/s, est. speed input: 16477.12 toks/s, output: 16.09 toks/s]
Processed prompts:  27%|       | 1122/4096 [01:09<03:20, 14.84it/s, est. speed input: 16435.84 toks/s, output: 16.05 toks/s]
Processed prompts:  28%|       | 1154/4096 [01:12<03:16, 14.95it/s, est. speed input: 16410.61 toks/s, output: 16.03 toks/s]
Processed prompts:  29%|       | 1186/4096 [01:14<03:15, 14.90it/s, est. speed input: 16374.24 toks/s, output: 15.99 toks/s]
Processed prompts:  30%|       | 1218/4096 [01:16<03:13, 14.87it/s, est. speed input: 16339.50 toks/s, output: 15.96 toks/s]
Processed prompts:  31%|       | 1250/4096 [01:18<03:10, 14.97it/s, est. speed input: 16319.00 toks/s, output: 15.94 toks/s]
Processed prompts:  31%|      | 1282/4096 [01:20<03:07, 15.04it/s, est. speed input: 16299.75 toks/s, output: 15.92 toks/s]
Processed prompts:  32%|      | 1314/4096 [01:22<03:05, 14.97it/s, est. speed input: 16269.90 toks/s, output: 15.89 toks/s]
Processed prompts:  33%|      | 1346/4096 [01:24<03:04, 14.92it/s, est. speed input: 16241.40 toks/s, output: 15.86 toks/s]
Processed prompts:  34%|      | 1378/4096 [01:27<03:02, 14.89it/s, est. speed input: 16214.90 toks/s, output: 15.83 toks/s]
Processed prompts:  34%|      | 1410/4096 [01:29<03:00, 14.88it/s, est. speed input: 16190.76 toks/s, output: 15.81 toks/s]
Processed prompts:  35%|      | 1442/4096 [01:31<02:58, 14.86it/s, est. speed input: 16166.46 toks/s, output: 15.79 toks/s]
Processed prompts:  36%|      | 1474/4096 [01:33<02:56, 14.84it/s, est. speed input: 16143.37 toks/s, output: 15.76 toks/s]
Processed prompts:  37%|      | 1506/4096 [01:35<02:54, 14.84it/s, est. speed input: 16121.63 toks/s, output: 15.74 toks/s]
Processed prompts:  38%|      | 1538/4096 [01:37<02:52, 14.82it/s, est. speed input: 16099.62 toks/s, output: 15.72 toks/s]
Processed prompts:  38%|      | 1570/4096 [01:39<02:49, 14.94it/s, est. speed input: 16088.79 toks/s, output: 15.71 toks/s]
Processed prompts:  39%|      | 1602/4096 [01:42<02:47, 14.90it/s, est. speed input: 16069.56 toks/s, output: 15.69 toks/s]
Processed prompts:  40%|      | 1634/4096 [01:44<02:44, 15.01it/s, est. speed input: 16060.62 toks/s, output: 15.68 toks/s]
Processed prompts:  41%|      | 1666/4096 [01:46<02:42, 14.94it/s, est. speed input: 16042.10 toks/s, output: 15.67 toks/s]
Processed prompts:  41%|     | 1698/4096 [01:48<02:40, 14.91it/s, est. speed input: 16024.88 toks/s, output: 15.65 toks/s]
Processed prompts:  42%|     | 1730/4096 [01:50<02:39, 14.88it/s, est. speed input: 16008.21 toks/s, output: 15.63 toks/s]
Processed prompts:  43%|     | 1762/4096 [01:52<02:37, 14.85it/s, est. speed input: 15991.58 toks/s, output: 15.62 toks/s]
Processed prompts:  44%|     | 1794/4096 [01:54<02:35, 14.83it/s, est. speed input: 15975.74 toks/s, output: 15.60 toks/s]
Processed prompts:  45%|     | 1826/4096 [01:57<02:33, 14.83it/s, est. speed input: 15960.82 toks/s, output: 15.59 toks/s]
Processed prompts:  45%|     | 1858/4096 [01:59<02:29, 14.95it/s, est. speed input: 15954.39 toks/s, output: 15.58 toks/s]
Processed prompts:  46%|     | 1890/4096 [02:01<02:27, 14.91it/s, est. speed input: 15940.57 toks/s, output: 15.57 toks/s]
Processed prompts:  47%|     | 1922/4096 [02:03<02:26, 14.88it/s, est. speed input: 15926.92 toks/s, output: 15.55 toks/s]
Processed prompts:  48%|     | 1954/4096 [02:05<02:22, 14.98it/s, est. speed input: 15921.35 toks/s, output: 15.55 toks/s]
Processed prompts:  48%|     | 1986/4096 [02:07<02:20, 15.06it/s, est. speed input: 15916.26 toks/s, output: 15.54 toks/s]
Processed prompts:  49%|     | 2018/4096 [02:09<02:18, 14.98it/s, est. speed input: 15903.44 toks/s, output: 15.53 toks/s]
Processed prompts:  50%|     | 2050/4096 [02:12<02:17, 14.92it/s, est. speed input: 15891.01 toks/s, output: 15.52 toks/s]
Processed prompts:  51%|     | 2082/4096 [02:14<02:15, 14.88it/s, est. speed input: 15879.17 toks/s, output: 15.51 toks/s]
Processed prompts:  52%|    | 2114/4096 [02:16<02:13, 14.86it/s, est. speed input: 15867.86 toks/s, output: 15.50 toks/s]
Processed prompts:  52%|    | 2146/4096 [02:18<02:11, 14.84it/s, est. speed input: 15856.64 toks/s, output: 15.48 toks/s]
Processed prompts:  53%|    | 2178/4096 [02:20<02:09, 14.83it/s, est. speed input: 15845.96 toks/s, output: 15.47 toks/s]
Processed prompts:  54%|    | 2210/4096 [02:22<02:05, 15.07it/s, est. speed input: 15848.42 toks/s, output: 15.48 toks/s]
Processed prompts:  55%|    | 2242/4096 [02:24<02:03, 14.99it/s, est. speed input: 15838.40 toks/s, output: 15.47 toks/s]
Processed prompts:  56%|    | 2274/4096 [02:27<02:00, 15.06it/s, est. speed input: 15834.94 toks/s, output: 15.46 toks/s]
Processed prompts:  56%|    | 2306/4096 [02:29<01:59, 14.97it/s, est. speed input: 15824.70 toks/s, output: 15.45 toks/s]
Processed prompts:  57%|    | 2338/4096 [02:31<01:56, 15.04it/s, est. speed input: 15820.91 toks/s, output: 15.45 toks/s]
Processed prompts:  58%|    | 2370/4096 [02:33<01:53, 15.24it/s, est. speed input: 15824.78 toks/s, output: 15.45 toks/s]
Processed prompts:  59%|    | 2402/4096 [02:35<01:51, 15.24it/s, est. speed input: 15821.60 toks/s, output: 15.45 toks/s]
Processed prompts:  59%|    | 2434/4096 [02:37<01:49, 15.11it/s, est. speed input: 15812.85 toks/s, output: 15.44 toks/s]
Processed prompts:  60%|    | 2466/4096 [02:39<01:48, 15.02it/s, est. speed input: 15804.04 toks/s, output: 15.43 toks/s]
Processed prompts:  61%|    | 2498/4096 [02:41<01:45, 15.08it/s, est. speed input: 15801.37 toks/s, output: 15.43 toks/s]
Processed prompts:  62%|   | 2530/4096 [02:44<01:44, 14.99it/s, est. speed input: 15792.47 toks/s, output: 15.42 toks/s]
Processed prompts:  63%|   | 2562/4096 [02:46<01:41, 15.06it/s, est. speed input: 15790.17 toks/s, output: 15.42 toks/s]
Processed prompts:  63%|   | 2594/4096 [02:48<01:40, 14.98it/s, est. speed input: 15781.98 toks/s, output: 15.41 toks/s]
Processed prompts:  64%|   | 2626/4096 [02:50<01:38, 14.94it/s, est. speed input: 15774.37 toks/s, output: 15.40 toks/s]
Processed prompts:  65%|   | 2658/4096 [02:52<01:36, 14.90it/s, est. speed input: 15766.84 toks/s, output: 15.40 toks/s]
Processed prompts:  66%|   | 2690/4096 [02:54<01:33, 15.00it/s, est. speed input: 15764.99 toks/s, output: 15.40 toks/s]
Processed prompts:  66%|   | 2722/4096 [02:56<01:31, 14.94it/s, est. speed input: 15757.56 toks/s, output: 15.39 toks/s]
Processed prompts:  67%|   | 2754/4096 [02:59<01:30, 14.90it/s, est. speed input: 15750.38 toks/s, output: 15.38 toks/s]
Processed prompts:  68%|   | 2786/4096 [03:01<01:28, 14.88it/s, est. speed input: 15743.48 toks/s, output: 15.37 toks/s]
Processed prompts:  69%|   | 2818/4096 [03:03<01:26, 14.85it/s, est. speed input: 15736.46 toks/s, output: 15.37 toks/s]
Processed prompts:  70%|   | 2850/4096 [03:05<01:23, 14.97it/s, est. speed input: 15735.00 toks/s, output: 15.37 toks/s]
Processed prompts:  70%|   | 2882/4096 [03:07<01:21, 14.91it/s, est. speed input: 15728.17 toks/s, output: 15.36 toks/s]
Processed prompts:  71%|   | 2914/4096 [03:09<01:19, 14.88it/s, est. speed input: 15721.61 toks/s, output: 15.35 toks/s]
Processed prompts:  72%|  | 2946/4096 [03:11<01:17, 14.85it/s, est. speed input: 15714.96 toks/s, output: 15.35 toks/s]
Processed prompts:  73%|  | 2978/4096 [03:14<01:15, 14.84it/s, est. speed input: 15708.81 toks/s, output: 15.34 toks/s]
Processed prompts:  73%|  | 3010/4096 [03:16<01:13, 14.83it/s, est. speed input: 15702.93 toks/s, output: 15.33 toks/s]
Processed prompts:  74%|  | 3042/4096 [03:18<01:11, 14.81it/s, est. speed input: 15696.68 toks/s, output: 15.33 toks/s]
Processed prompts:  75%|  | 3074/4096 [03:20<01:09, 14.80it/s, est. speed input: 15690.52 toks/s, output: 15.32 toks/s]
Processed prompts:  76%|  | 3106/4096 [03:22<01:05, 15.05it/s, est. speed input: 15694.12 toks/s, output: 15.33 toks/s]
Processed prompts:  77%|  | 3138/4096 [03:24<01:03, 15.11it/s, est. speed input: 15693.45 toks/s, output: 15.33 toks/s]
Processed prompts:  77%|  | 3170/4096 [03:26<01:01, 15.02it/s, est. speed input: 15687.95 toks/s, output: 15.32 toks/s]
Processed prompts:  78%|  | 3202/4096 [03:29<00:59, 14.95it/s, est. speed input: 15682.33 toks/s, output: 15.31 toks/s]
Processed prompts:  79%|  | 3234/4096 [03:31<00:57, 15.03it/s, est. speed input: 15681.25 toks/s, output: 15.31 toks/s]
Processed prompts:  80%|  | 3266/4096 [03:33<00:55, 14.95it/s, est. speed input: 15675.74 toks/s, output: 15.31 toks/s]
Processed prompts:  81%|  | 3298/4096 [03:35<00:53, 14.90it/s, est. speed input: 15670.14 toks/s, output: 15.30 toks/s]
Processed prompts:  81%| | 3330/4096 [03:37<00:51, 14.87it/s, est. speed input: 15665.02 toks/s, output: 15.30 toks/s]
Processed prompts:  82%| | 3362/4096 [03:39<00:49, 14.85it/s, est. speed input: 15659.94 toks/s, output: 15.29 toks/s]
Processed prompts:  83%| | 3394/4096 [03:42<00:47, 14.82it/s, est. speed input: 15654.72 toks/s, output: 15.29 toks/s]
Processed prompts:  84%| | 3426/4096 [03:44<00:44, 14.94it/s, est. speed input: 15654.11 toks/s, output: 15.29 toks/s]
Processed prompts:  84%| | 3458/4096 [03:46<00:42, 14.91it/s, est. speed input: 15649.57 toks/s, output: 15.28 toks/s]
Processed prompts:  85%| | 3490/4096 [03:48<00:40, 15.15it/s, est. speed input: 15653.72 toks/s, output: 15.29 toks/s]
Processed prompts:  86%| | 3522/4096 [03:50<00:38, 15.05it/s, est. speed input: 15649.29 toks/s, output: 15.28 toks/s]
Processed prompts:  87%| | 3554/4096 [03:52<00:36, 14.97it/s, est. speed input: 15644.73 toks/s, output: 15.28 toks/s]
Processed prompts:  88%| | 3586/4096 [03:54<00:34, 14.93it/s, est. speed input: 15640.50 toks/s, output: 15.27 toks/s]
Processed prompts:  88%| | 3618/4096 [03:56<00:32, 14.89it/s, est. speed input: 15636.08 toks/s, output: 15.27 toks/s]
Processed prompts:  89%| | 3650/4096 [03:59<00:29, 14.87it/s, est. speed input: 15631.90 toks/s, output: 15.27 toks/s]
Processed prompts:  90%| | 3682/4096 [04:01<00:27, 14.85it/s, est. speed input: 15627.67 toks/s, output: 15.26 toks/s]
Processed prompts:  91%| | 3714/4096 [04:03<00:25, 14.96it/s, est. speed input: 15627.29 toks/s, output: 15.26 toks/s]
Processed prompts:  91%|| 3746/4096 [04:05<00:23, 14.91it/s, est. speed input: 15623.20 toks/s, output: 15.26 toks/s]
Processed prompts:  92%|| 3778/4096 [04:07<00:21, 14.88it/s, est. speed input: 15619.19 toks/s, output: 15.25 toks/s]
Processed prompts:  93%|| 3810/4096 [04:09<00:19, 14.86it/s, est. speed input: 15615.37 toks/s, output: 15.25 toks/s]
Processed prompts:  94%|| 3842/4096 [04:11<00:16, 14.97it/s, est. speed input: 15615.09 toks/s, output: 15.25 toks/s]
Processed prompts:  95%|| 3874/4096 [04:14<00:14, 14.91it/s, est. speed input: 15611.07 toks/s, output: 15.25 toks/s]
Processed prompts:  95%|| 3906/4096 [04:16<00:12, 14.88it/s, est. speed input: 15607.28 toks/s, output: 15.24 toks/s]
Processed prompts:  96%|| 3938/4096 [04:18<00:10, 14.86it/s, est. speed input: 15603.49 toks/s, output: 15.24 toks/s]
Processed prompts:  97%|| 3970/4096 [04:20<00:08, 14.84it/s, est. speed input: 15599.71 toks/s, output: 15.23 toks/s]
Processed prompts:  98%|| 4002/4096 [04:22<00:06, 14.83it/s, est. speed input: 15596.07 toks/s, output: 15.23 toks/s]
Processed prompts:  98%|| 4034/4096 [04:24<00:04, 15.21it/s, est. speed input: 15603.37 toks/s, output: 15.24 toks/s]
Processed prompts:  99%|| 4066/4096 [04:26<00:01, 15.22it/s, est. speed input: 15603.45 toks/s, output: 15.24 toks/s]
Processed prompts: 100%|| 4096/4096 [04:26<00:00, 15.22it/s, est. speed input: 15718.56 toks/s, output: 15.35 toks/s]
Processed prompts: 100%|| 4096/4096 [04:26<00:00, 15.35it/s, est. speed input: 15718.56 toks/s, output: 15.35 toks/s]
[rank0]:[W128 08:11:09.878372058 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

